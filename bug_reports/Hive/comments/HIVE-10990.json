[hive> CREATE TABLE hbase_table_1(key int, value string)
    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
    > WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")
    > TBLPROPERTIES ("hbase.table.name" = "xyz");
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V, [~gurmukhd] I think we might have introduced a regression with HIVE-8898. We are currently discussing on that JIRA what is the best way to fix that. In mean time, I tried your query with hive 1.1 on hbase 1.0 and it worked just fine. Anyway you can try using that and see if it fixes your problem?

{noformat}
hive> CREATE TABLE test_hbase(key string, col1 string, col2 string) 
    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
    > WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf:col1,cf:col2")
    > TBLPROPERTIES ("hbase.table.name" = "test_hbase");
OK
Time taken: 1.812 seconds
{noformat}, [~gurmukhd] Digging deeper I am unfortunately not seeing anything non-passive between the two versions which might be causing this error. The HBaseStorageHandler makes a call to the HTableDescriptor#addFamily[1][2]. Would you be able to provide me with a full stack trace so I can dig deeper into this/

 That said, we still need to do a full scale compatibility testing with hbase 1.0. Stay tuned.

[1] https://github.com/apache/hive/blob/release-1.2.0/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java#L214
[2] https://github.com/apache/hbase/blob/1.0.1/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L786, Sorry, for the delay in response. Will update this details in the next 4 hrs., I also met the same problem in *spark on hbase* function.
{quote}
ERROR CliDriver: org.apache.spark.sql.execution.QueryExecutionException: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V
        at org.apache.spark.sql.hive.client.ClientWrapper$$anonfun$runHive$1.apply(ClientWrapper.scala:433)
        at org.apache.spark.sql.hive.client.ClientWrapper$$anonfun$runHive$1.apply(ClientWrapper.scala:418)
        at org.apache.spark.sql.hive.client.ClientWrapper$$anonfun$withHiveState$1.apply(ClientWrapper.scala:256)
        at org.apache.spark.sql.hive.client.ClientWrapper.retryLocked(ClientWrapper.scala:211)
        at org.apache.spark.sql.hive.client.ClientWrapper.withHiveState(ClientWrapper.scala:248)
        at org.apache.spark.sql.hive.client.ClientWrapper.runHive(ClientWrapper.scala:418)
        at org.apache.spark.sql.hive.client.ClientWrapper.runSqlHive(ClientWrapper.scala:408)
        at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:558)
        at org.apache.spark.sql.hive.execution.HiveNativeCommand.run(HiveNativeCommand.scala:33)
        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:57)
        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:57)
        at org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:69)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:140)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:138)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:138)
        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:927)
        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:927)
        at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:144)
        at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:129)
        at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)
        at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:719)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:61)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:304)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:223)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:675)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:183)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:208)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:123)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
{quote}, I build the hive by myself, with the version hbase-1.0, The problem is resolved.
So I think it's not a problem. , i have same issue, with hive 1.2.1 and hbase 1.1.0.1., so my create table is this:

bash-4.1# cat hbasetest.hql                                                 
CREATE TABLE hbasetest(key string, val string)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES("hbase.columns.mapping" = ":key,cf1:val")
TBLPROPERTIES("hbase.table.name" = "xyz");
bash-4.1#

And when I run it I get this:

bash-4.1# beeline -n hive -u jdbc:hive2://localhost:10001 -f ./hbasetest.hql
Connecting to jdbc:hive2://localhost:10001
Connected to: Apache Hive (version 1.2.1)
Driver: Hive JDBC (version 1.2.1)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://localhost:10001> set hbase.zookeeper.quorum=zookeeper;
No rows affected (0.081 seconds)
0: jdbc:hive2://localhost:10001> 
0: jdbc:hive2://localhost:10001> CREATE TABLE hbasetest(key string, val string)
0: jdbc:hive2://localhost:10001> STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
0: jdbc:hive2://localhost:10001> WITH SERDEPROPERTIES("hbase.columns.mapping" = ":key,cf1:val")
0: jdbc:hive2://localhost:10001> TBLPROPERTIES("hbase.table.name" = "xyz");
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V (state=08S01,code=1)

Closing: 0: jdbc:hive2://localhost:10001
bash-4.1#

And with verbose i get this:

bash-4.1# beeline -n hive -u jdbc:hive2://localhost:10001 -f ./hbasetest.hql --verbose
issuing: !connect jdbc:hive2://localhost:10001 hive '' 
Connecting to jdbc:hive2://localhost:10001
Connected to: Apache Hive (version 1.2.1)
Driver: Hive JDBC (version 1.2.1)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://localhost:10001> set hbase.zookeeper.quorum=zookeeper;
Getting log thread is interrupted, since query is done!
No rows affected (0.078 seconds)
0: jdbc:hive2://localhost:10001> 
0: jdbc:hive2://localhost:10001> CREATE TABLE hbasetest(key string, val string)
0: jdbc:hive2://localhost:10001> STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
0: jdbc:hive2://localhost:10001> WITH SERDEPROPERTIES("hbase.columns.mapping" = ":key,cf1:val")
0: jdbc:hive2://localhost:10001> TBLPROPERTIES("hbase.table.name" = "xyz");
Getting log thread is interrupted, since query is done!
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V (state=08S01,code=1)
java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V
	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.beeline.Commands.execute(Commands.java:848)
	at org.apache.hive.beeline.Commands.sql(Commands.java:713)
	at org.apache.hive.beeline.BeeLine.dispatch(BeeLine.java:973)
	at org.apache.hive.beeline.BeeLine.execute(BeeLine.java:813)
	at org.apache.hive.beeline.BeeLine.executeFile(BeeLine.java:794)
	at org.apache.hive.beeline.BeeLine.begin(BeeLine.java:763)
	at org.apache.hive.beeline.BeeLine.mainWithInputRedirection(BeeLine.java:484)
	at org.apache.hive.beeline.BeeLine.main(BeeLine.java:467)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)

Closing: 0: jdbc:hive2://localhost:10001
bash-4.1#

In a prior comment [~swarnim] suggested the error originates from https://github.com/apache/hive/blob/release-1.2.0/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java#L214, but I don't think this is the case. Because I can force the addFamily method to throw by omitting a column family from "hbase.columns.mapping", and I get a stack trace that points to the code referenced earlier:

bash-4.1# beeline -n hive -u jdbc:hive2://localhost:10001 -f ./hbasetest.hql          
Connecting to jdbc:hive2://localhost:10001
Connected to: Apache Hive (version 1.2.1)
Driver: Hive JDBC (version 1.2.1)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://localhost:10001> set hbase.zookeeper.quorum=zookeeper;
No rows affected (0.079 seconds)
0: jdbc:hive2://localhost:10001> 
0: jdbc:hive2://localhost:10001> CREATE TABLE hbasetest(key string, val string)
0: jdbc:hive2://localhost:10001> STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
0: jdbc:hive2://localhost:10001> WITH SERDEPROPERTIES("hbase.columns.mapping" = ":key,:val")
0: jdbc:hive2://localhost:10001> TBLPROPERTIES("hbase.table.name" = "xyz");
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.lang.IllegalArgumentException: Family name can not be empty
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)
	at org.apache.hadoop.hbase.HColumnDescriptor.isLegalFamilyName(HColumnDescriptor.java:487)
	at org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:440)
	at org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:398)
	at org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:366)
	at org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:317)
	at org.apache.hadoop.hive.hbase.HBaseStorageHandler.preCreateTable(HBaseStorageHandler.java:214)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:664)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:657)
	at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)
	at com.sun.proxy.$Proxy6.createTable(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:714)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4135)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:306)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1653)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1412)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1195)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1054)
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:154)
	at org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:71)
	at org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:206)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:218)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
) (state=08S01,code=1)

Closing: 0: jdbc:hive2://localhost:10001
bash-4.1#
, https://github.com/apache/hive/blob/release-1.2.1/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java#L296, [~kevinl] Can you post full logs for this query? They should be in /tmp/<user> folder., 
2015-08-25 18:50:11,406 ERROR [HiveServer2-Background-Pool: Thread-320]: operation.Operation (SQLOperation.java:run(209)) - Error running hive query: 
org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V
	at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:315)
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:156)
	at org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:71)
	at org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:206)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:218)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V
	at org.apache.hadoop.hive.hbase.HBaseStorageHandler.preCreateTable(HBaseStorageHandler.java:214)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:664)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:657)
	at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)
	at com.sun.proxy.$Proxy6.createTable(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:714)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4135)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:306)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1653)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1412)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1195)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1054)
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:154)
	... 11 more, so I'm guessing I need to add set hive.aux.jars.path to point to some hbase jar. Can someone point out which one that is? The integration wiki page suggests a jar that doesn't exist:

https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration indicates I should be adding hbase.<version>.jar but that doesn't exist in 1.1.0.1?, Tried this, doesn't work either:

https://issues.apache.org/jira/browse/HIVE-5518, And, I guess I would expect that adding this should work (it doesn't)

set hive.aux.jars.path=file:///opt/hbase/lib/hbase-client-1.0.1.1.jar;

since:

bash-4.1# jar tf /opt/hbase/lib/hbase-client-1.0.1.1.jar|grep HTableDescriptor
org/apache/hadoop/hbase/client/UnmodifyableHTableDescriptor.class
org/apache/hadoop/hbase/HTableDescriptor.class
bash-4.1#

But the error in /tmp/root/hive.log is the same:

java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V


, the signature of the method changed (return type):

https://github.com/apache/hbase/blob/0.98/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L789

https://github.com/apache/hbase/blob/1.1.0.1/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L824

so...the hbase storage handler jar needs to version bump its dependency and recompile(?) , [~kevinl] That is correct. However it should be noted that the branch 1.x of hive is going to stay on < hbase 1.0 still to maintain passivity with older versions of hbase. Please follow the discussion here[1]. Branch 2.x of hive would be moving over to hbase 1.x.

I created [2] to bump hbase version to 1.1.1.

[1] https://www.mail-archive.com/dev@hive.apache.org/msg114984.html
[2] https://issues.apache.org/jira/browse/HIVE-11647

 , {quote}
However it should be noted that the branch 1.x of hive is going to stay on < hbase 1.0 still to maintain passivity with older versions of hbase.
{quote}

[~leftylev] What do you think would be a good place to document this kind of information?, it is working fine on hive 1.1 and hbase 1.0 but not on hive 1.2 and hbase-1.0.1.1, I have tested this on hadoop 2.6.0 as well. Getting the same error.
Hive-1.2.0 and hbase-1.0.1.1

, I have a hard time believing this works with hbase 1.0 given the method return type changed in hbase 0.99.2:
https://github.com/apache/hbase/blob/0.99.2/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L789

, hive> CREATE TABLE hbase_table_1(key int, value string)
    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
    > WITH SERDEPROPERTIES
    > ("hbase.columns.mapping" = ":key,cf1:val")
    > TBLPROPERTIES ("hbase.table.name" = "xyz");
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V

============================


2015-08-26 19:58:58,095 ERROR [main]: exec.DDLTask (DDLTask.java:failed(520)) - java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V
	at org.apache.hadoop.hive.hbase.HBaseStorageHandler.preCreateTable(HBaseStorageHandler.java:214)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:664)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:657)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)
	at com.sun.proxy.$Proxy9.createTable(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:714)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4135)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:306)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1650)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1409)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1192)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:736)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)

2015-08-26 19:58:58,096 ERROR [main]: ql.Driver (SessionState.java:printError(957)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V
2015-08-26 19:58:58,096 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(148)) - </PERFLOG method=Driver.execute start=1440599336948 end=1440599338096 duration=1148 from=org.apache.hadoop.hive.ql.Driver>
2015-08-26 19:58:58,096 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(121)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-08-26 19:58:58,097 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(148)) - </PERFLOG method=releaseLocks start=1440599338096 end=1440599338097 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-08-26 19:58:58,098 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(121)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-08-26 19:58:58,098 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(148)) - </PERFLOG method=releaseLocks start=1440599338098 end=1440599338098 duration=0 from=org.apache.hadoop.hive.ql.Driver>, > However it should be noted that the branch 1.x of hive is going to stay on < hbase 1.0 still to maintain passivity with older versions of hbase

It seems unfortunate to have ended up in a situation where latest stable releases of hbase and hive are incompatible. , [~gurmukhd] Did you mention before that it was working on hive 1.1 and hbase 1.0?, I have to test that again, as it was long back. I might be missing something. 

Will test and update., [~kevinl] Since this change was introduced in hbase 0.99, one thing we could possibly do is  bump the version up to 0.99 in this branch so still keeping it under 1.0 and compile it. But again even with that, we might end up breaking compatibility with older version and for consumers who are not ready to consume > 0.99 hbase yet. The only option I am seeing right now is that if you want to get it running on hbase 1.0, you might have to bump the version and recompile hive yourself.

[~ndimiduk] Any suggestions from your end being the HBase champion? :), Diff people are posting different stack traces, I see two errors from folks' comments:

# {{java.lang.IllegalArgumentException: Family name can not be empty}}
# {{java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V}}

The first seems like an invalid DDL. Somehow you're trying to create a table without specifying a column family.

The second is a subtle ABI incompatibility around {{HTableDescriptor#addFamily}} introduced after HBASE-12046, a change present in HBase 1.0+. See [javadoc from master|http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html#addFamily(org.apache.hadoop.hbase.HColumnDescriptor)] vs. [javadoc from 0.94 branch|http://hbase.apache.org/0.94/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html#addFamily(org.apache.hadoop.hbase.HColumnDescriptor)]. Bottom line is you cannot use a client compiled vs. 0.98 with a runtime using 1.0+. In this case the difference is only in return type and the [hive code|https://github.com/apache/hive/blob/master/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java#L214] in question is ignoring it. Thus, you just need to recompile hive vs. the correct runtime hbase version; no source change required.

To create a binary that supports either version, you'll need to use reflection to invoke the {{addFamily}} method. That will fix this one API change, but there are probably others lurking.

Let me also point out that HBase has never guaranteed ABI compatibility between minor release versions. For the post-1.0 world, we're calling this out explicitly in the [compatibility promise|http://hbase.apache.org/book.html#hbase.versioning.post10] (see table 3, "compatibility matrix", there's a row for client binary compatibility). For the pre-1.0 releases, we always suggest clients recompile their applications vs. the newest hbase version jars after an upgrade., FYI [~enis], [~apurtell]., I think you meant major release versions [~ndimiduk]. If so, that's right, across major releases we might introduce changes that affect ABI compatibility. _Post_ 1.0 we'd take a harder look than in the past if the breaking change is necessary, but leading up to the 1.0 release we made API changes to help with long term maintainability once at 1.0.

bq. one thing we could possibly do is bump the version up to 0.99 in this branch
Please don't use any 0.99. This was a developer preview of 1.0 and is not meant for use by anyone other than HBase developers, and at this point is an artifact of historical interest at best. The next release after 0.98 is 1.0., bq. I think you meant major release versions Nick Dimiduk. 
Never mind, I reviewed that section of the book and yes the matrix marks minor release versions as potentially incompatible also. Note this is the degree of freedom the HBase developers have decided to advertise as possible and not a guarantee that such breakage would happen. I would be interested in helping you address post-1.0 ABI issues if they arise. , {quote}
Thus, you just need to recompile hive vs. the correct runtime hbase version; no source change required.
{quote}

Yeah that's what I was referring to do with my comment here[1]. Unfortunately though like I mentioned, not sure if we can do this in general and then release as that would break passivity for consumers < hbase 1.0. Primarily the reason why we are choosing to leave hive 1.x stream on hbase 0.98.x as that branch is currently maintaining backwards compatibility and then bump hive 2.x to hbase 1.x.

[1] https://issues.apache.org/jira/browse/HIVE-10990?focusedCommentId=14713591&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14713591, {quote}
Please don't use any 0.99. This was a developer preview of 1.0 and is not meant for use by anyone other than HBase developers, and at this point is an artifact of historical interest at best.
{quote}

Good call on this. I wasn't aware of that., Three places spring to mind:  the Hive HBase Integration doc (definitely) and two places that discuss version requirements, Getting Started and the Installation doc.  Here are their links:

* [Hive HBase Integration | https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration] -- add this information to the "Version information" box right after the table of contents
* [Getting Started -- Requirements | https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-Requirements]
* [Installing Hive | https://cwiki.apache.org/confluence/display/Hive/AdminManual+Installation#AdminManualInstallation-InstallingHive]

Another section of the wiki, Hive Versions and Branches, doesn't seem appropriate for this information but here's the link in case you disagree:

* [Home -- Hive Versions and Branches | https://cwiki.apache.org/confluence/display/Hive/Home#Home-HiveVersionsandBranches], Thanks [~leftylev]. I updated this info on the wiki[1]. Please do let me know if it looks fine to you.

[1] https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration, I have updated this info on the Hive/HBase Integration wiki[1] to avoid confusion for consumers of this integration.

[1] https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration, Looks good, thanks [~swarnim].  I agree that it isn't needed in the Getting Started and Installation docs., Since this constraint has been documented on the wiki, on the basis of the above conversation resolving this one.]