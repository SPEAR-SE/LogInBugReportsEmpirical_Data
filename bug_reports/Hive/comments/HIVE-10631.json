[This is just test case to explain the impact of this bug especially with HIVE-6727

Let's say I have 2 dummy existing locations for table partitions as the followings.

s3://bucket/table/dummy/partition=1/
s3://bucket/table/dummy/partition=2/
s3://bucket/table/dummy/partition=3/

s3://bucket/warehouse/dummy/partition=1/
s3://bucket/warehouse/dummy/partition=2/
s3://bucket/warehouse/dummy/partition=3/

And I created external table name "dummy" with table location "s3://bucket/table/dummy/" and set "hive.metastore.warehouse.dir=s3://bucket/warehouse/" and "hive.stats.autogather=true"

When this dummy table is created, HiveMetaStore scans warehouse directory recursively not table location and do nothing with data collected. 
So some edge cases when external table is created with above conditions, especially for large partitions, it takes quite of time than "hive.stats.autogather" off. , If the intention of line 1363(MetaStoreUtils.updateUnpartitionedTableStatsFast(db, tbl, wh, true)) is updating fast stats regardless of the fact the table is just created, (which means no MSCK REPAIR PARTITIONS, even if it's existing external table, I don't understand the reason why it tries to update stats before metastore know about partitions, this part, I still don't understand, however if this was the intention of HIVE-3959), 

Then I believe line 1363 should be something like below
{code}
 FileStatus[] fileStatus = wh.getFileStatusesForUnpartitionedTable(db, tbl);
MetaStoreUtils.updateUnpartitionedTableStatsFast(tbl, fileStatus, fileStatus.length == 0, false);
{code}

Otherwise it should be like the this, at least not to scan folders for unnecessary operation.

{code}
MetaStoreUtils.updateUnpartitionedTableStatsFast(tbl, null, true, false);
{code}

Just my thought., hive.stats.reliable requires that both numFiles and totalSize be set properly, regardless of the condition.  So if 'create table' or 'create external table' were to use a location already populated with partitions, it will traverse those partitions regardless.

As of writing, hive.stats.reliable appears to be set to false by default.  Perhaps stats calculation on creation of partitioned tables can be forgone when hive.stats.reliable is false only, as stats will be populated on MSCK REPAIR PARTITIONS or by adding partitions using ALTER TABLE ADD PARTITION.
, Reading more about hive.stats.reliable, it did not appear to be appropriate to use it in this case, and to instead it would be better to defer stats calculation for partitioned tables when partitions are being added to a table (MSCK/ALTER TABLE), and not on table creation (CREATE [EXTERNAL] TABLE), [~dongwook] If you are still working on this issue. Can you name your patch according to https://cwiki.apache.org/confluence/display/Hive/Hive+PreCommit+Patch+Testing so that we can get Hive QA run on this? Also, if you can create RB entry for this, it will be useful., Reuploaded as HIVE-10631.patch, Running precommit tests., 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12750006/HIVE-10631.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4936/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4936/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4936/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-4936/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
From https://github.com/apache/hive
   a6d3070..425273e  branch-1   -> origin/branch-1
   cafd555..a4eb78c  branch-1.0 -> origin/branch-1.0
   2ee30c4..0140df7  master     -> origin/master
+ git reset --hard HEAD
HEAD is now at 2ee30c4 HIVE-11449: "Capacity must be a power of two" error when HybridHashTableContainer memory threshold is too low (Jason Dere, reviewed by Sergey Shelukhin)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is behind 'origin/master' by 3 commits, and can be fast-forwarded.
+ git reset --hard origin/master
HEAD is now at 0140df7 HIVE-11480: CBO: Calcite Operator To Hive Operator (Calcite Return Path): char/varchar as input to GenericUDAF (Pengcheng Xiong, reviewed by Jesus Camacho Rodriguez)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12750006 - PreCommit-HIVE-TRUNK-Build, 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12750006/HIVE-10631.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4937/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4937/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4937/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-4937/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 0140df7 HIVE-11480: CBO: Calcite Operator To Hive Operator (Calcite Return Path): char/varchar as input to GenericUDAF (Pengcheng Xiong, reviewed by Jesus Camacho Rodriguez)
+ git clean -f -d
+ git checkout master
Already on 'master'
+ git reset --hard origin/master
HEAD is now at 0140df7 HIVE-11480: CBO: Calcite Operator To Hive Operator (Calcite Return Path): char/varchar as input to GenericUDAF (Pengcheng Xiong, reviewed by Jesus Camacho Rodriguez)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12750006 - PreCommit-HIVE-TRUNK-Build, Uploading a patch that cleanly applies to TRUNK as well as branch-1.0, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12750344/HIVE-10631.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 9357 tests executed
*Failed tests:*
{noformat}
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4955/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4955/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4955/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12750344 - PreCommit-HIVE-TRUNK-Build, When building and testing Hive-Trunk locally, the following test fails regardless of the patch.

org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation

Appears to fail in trunk before and after the change.  Also unrelated, the following URL in pom.xml appears to give 403's:
https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/

This should be (after removing the trailing '/'):
https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1
, Can you create a review board for this ?, Sure, here it is:

https://reviews.apache.org/r/37484/, Getting this:

You don't have access to this review request.
This review request is private. You must be a requested reviewer, either directly or on a requested group, and have permission to access the repository in order to view this review request., Sorry, fixed it just now., Code review posted:

https://reviews.apache.org/r/37484/, +1, Pushed to master & branch-1 Thanks [~aartokhy]]