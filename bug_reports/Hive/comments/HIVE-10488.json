[I can not reproduce this issue in hive 1.2.0
I created 2 tables 
t3 - textfile
t3o - Orc

{code}
hive> desc formatted t3;
OK
# col_name            	data_type           	comment             
	 	 
rnum                	int                 	                    
cdt                 	date                	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
Owner:              	apivovarov          	 
CreateTime:         	Sun Apr 26 23:58:29 PDT 2015	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	hdfs://localhost/apps/apivovarov/warehouse/t3	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	transient_lastDdlTime	1430117909          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
Time taken: 0.098 seconds, Fetched: 27 row(s)
{code}
{code}
hive> desc formatted t3o;
OK
# col_name            	data_type           	comment             
	 	 
rnum                	int                 	                    
cdt                 	date                	                    
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
Owner:              	apivovarov          	 
CreateTime:         	Mon Apr 27 00:00:11 PDT 2015	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	hdfs://localhost/apps/apivovarov/warehouse/t3o	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	true                
	numFiles            	1                   
	numRows             	4                   
	rawDataSize         	184                 
	totalSize           	302                 
	transient_lastDdlTime	1430118011          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
Time taken: 0.096 seconds, Fetched: 32 row(s)
{code}
{code}
hive> select * from t3;
OK
0	NULL
1	1996-01-01
2	2000-01-01
3	2000-12-31
Time taken: 0.086 seconds, Fetched: 4 row(s)
{code}
{code}
hive> select * from t3o;
OK
0	NULL
1	1996-01-01
2	2000-01-01
3	2000-12-31
Time taken: 0.086 seconds, Fetched: 4 row(s)
{code}
{code}
hive> select rnum, cdt, cast (cdt as timestamp) from t3;
OK
0	NULL	NULL
1	1996-01-01	1996-01-01 00:00:00
2	2000-01-01	2000-01-01 00:00:00
3	2000-12-31	2000-12-31 00:00:00
Time taken: 0.091 seconds, Fetched: 4 row(s)
{code}
{code}
hive> select rnum, cdt, cast (cdt as timestamp) from t3o;
OK
0	NULL	NULL
1	1996-01-01	1996-01-01 00:00:00
2	2000-01-01	2000-01-01 00:00:00
3	2000-12-31	2000-12-31 00:00:00
Time taken: 0.108 seconds, Fetched: 4 row(s)
{code}

MR
{code}
hive> select t3.rnum, t3.cdt, cast (t3.cdt as timestamp) cts, t3o.cdt cdt2, cast(t3o.cdt as timestamp) cts2 from t3 join t3o on (t3.rnum = t3o.rnum);
Query ID = apivovarov_20150427000533_2734a9a1-63eb-45d4-83a4-4129ae3e7afc
Total jobs = 1
15/04/27 00:05:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Execution log at: /tmp/apivovarov/apivovarov_20150427000533_2734a9a1-63eb-45d4-83a4-4129ae3e7afc.log
2015-04-27 00:05:37	Starting to launch local task to process map join;	maximum memory = 477102080
2015-04-27 00:05:39	Dump the side-table for tag: 0 with group count: 4 into file: file:/tmp/apivovarov/fe4b8d14-3414-4790-a737-7a5d00bd04d0/hive_2015-04-27_00-05-33_412_2029315734201436275-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile00--.hashtable
2015-04-27 00:05:39	Uploaded 1 File to: file:/tmp/apivovarov/fe4b8d14-3414-4790-a737-7a5d00bd04d0/hive_2015-04-27_00-05-33_412_2029315734201436275-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile00--.hashtable (345 bytes)
2015-04-27 00:05:39	End of local task; Time Taken: 1.612 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1429923083119_0002, Tracking URL = http://c11.example.com:8088/proxy/application_1429923083119_0002/
Kill Command = /usr/lib/hadoop-2.6.0/bin/hadoop job  -kill job_1429923083119_0002
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
2015-04-27 00:05:47,494 Stage-3 map = 0%,  reduce = 0%
2015-04-27 00:05:54,942 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
MapReduce Total cumulative CPU time: 2 seconds 30 msec
Ended Job = job_1429923083119_0002
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 2.03 sec   HDFS Read: 6756 HDFS Write: 206 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 30 msec
OK
0	NULL	NULL	NULL	NULL
1	1996-01-01	1996-01-01 00:00:00	1996-01-01	1996-01-01 00:00:00
2	2000-01-01	2000-01-01 00:00:00	2000-01-01	2000-01-01 00:00:00
3	2000-12-31	2000-12-31 00:00:00	2000-12-31	2000-12-31 00:00:00
Time taken: 22.631 seconds, Fetched: 4 row(s)
{code}, In Hive 1.2, I tried following three cases and got different results:
1. select cast(date '2015-01-02' as timestamp) from src limit 1;
returns 2015-01-02 00:00:00

2. select cast('2015-01-02' as timestamp) from src limit 1;
returns NULL;

3. select cast(2015-01-02 as timestamp) from src limit 1;
returns 1969-12-31 16:33:32

I believe what Campbell did fall into the 3rd one.
, Cast was using a column of type date and not literals or value expression.
Variance was the format the data was in.

, Put 2015-01-02 to quotes in the example 3
Otherwise you cast integer 2012 to timestamp, [~the6campbells] I was also not able to reproduce the issue in Hive 1.2. Here are my steps:
{code}
create table testcastts (key int, datevalue date);
insert into testcastts select 0, null from src limit 1;
insert into testcastts select 1, date '1996-01-01' from src limit 1;
insert into testcastts select 2, date '2000-01-01' from src limit 1;
insert into testcastts select 3, date '2000-12-31' from src limit 1;
---
select key, datevalue, cast(datevalue as timestamp) from testcastts;
0	NULL	NULL
1	1996-01-01	1996-01-01 00:00:00
2	2000-01-01	2000-01-01 00:00:00
3	2000-12-31	2000-12-31 00:00:00

---
create table if not exists testcastorcts (key int, datevalue date) stored as orc;
insert overwrite table testcastorcts select * from testcastts;
select key, datevalue, cast(datevalue as timestamp) from testcastorcts;
0	NULL	NULL
1	1996-01-01	1996-01-01 00:00:00
2	2000-01-01	2000-01-01 00:00:00
3	2000-12-31	2000-12-31 00:00:00
{code}
Do you see any difference between above my test case and yours? Otherwise, I will resolve this JIRA as "Not Reproducible". Thanks
, Chaoyu, testcastts should be Orc table. Is Orc default table format in your hive config?
Cast is working fine for textfile table for N., you do not have to put "from src limit 1" in select statement in hive-1.2, [~apivovarov] I have had two tables, one is text table testcasetts (create table testcastts (key int, datevalue date);) which was populated with 4 rows of src data. the other is orc table testcastorats (create table if not exists testcastorcts (key int, datevalue date) stored as orc;). I was not able reproduce the issue with these two tables., Here are the desc formatted from two tables (testcastts and testcastorcts) I tested:
{code}
# Detailed Table Information	 	 
Database:           	jira                	 
Owner:              	ctang               	 
CreateTime:         	Wed Apr 29 12:03:08 EDT 2015	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	file:/user/hive/warehouse/apache/jira.db/testcastts	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	true                
	numFiles            	4                   
	numRows             	4                   
	rawDataSize         	40                  
	totalSize           	44                  
	transient_lastDdlTime	1430323769          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1  

===
key                 	int                 	                    
datevalue           	date                	                    
	 	 
# Detailed Table Information	 	 
Database:           	jira                	 
Owner:              	ctang               	 
CreateTime:         	Wed Apr 29 12:12:42 EDT 2015	 
LastAccessTime:     	UNKNOWN             	 
Protect Mode:       	None                	 
Retention:          	0                   	 
Location:           	file:/user/hive/warehouse/apache/jira.db/testcastorcts	 
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	COLUMN_STATS_ACCURATE	true                
	numFiles            	1                   
	numRows             	4                   
	rawDataSize         	184                 
	totalSize           	304                 
	transient_lastDdlTime	1430324019          
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.ql.io.orc.OrcSerde	 
InputFormat:        	org.apache.hadoop.hive.ql.io.orc.OrcInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1  
{code}
BTW, I also queried with vectorized execution (set hive.vectorized.execution.enabled=true) for the ORC table testcastorcts, it also worked fine., Got it! Thank you.

BTW, I remember it was one issue with date to timestamp conversion for negative unix time HIVE-10178. But it is fixed already and has nothing to do with Orc.
{code}
select cast(cast('1966-01-01 00:00:01' as timestamp) as date);
1966-02-02
{code}, Yes, I looked through several timestamp related JIRAs, recently from Jason, Aihua and you (including HIVE-10178) and it seems none of them is related to this one., looks like Orc table contains int values instead of date values
e.g. 1996-01-01=1994

I got very similar results as in the description when I removed quotation marks wrapping date values:
{code}
--  1996-01-01=1994
hive> select cast(1996-01-01 as timestamp);
OK
1969-12-31 16:00:01.994

--  2000-01-01=1998
hive> select cast(2000-01-01 as timestamp);
OK
1969-12-31 16:00:01.998

--  2000-12-31=1957
hive> select cast(2000-12-31 as timestamp);
OK
1969-12-31 16:00:01.957
{code}
my TimeZone is US/Pacific - this is why time is -8hr from 1970   (1969 4pm)

The description shows 1969 7pm (-5 hours offset from 1970) - So, their timezone is US/Eastern, [~the6campbells] We are not able to reproduce the issue, so I resolve the JIRA this moment. If you see any further issue, please feel free to reopen it.]