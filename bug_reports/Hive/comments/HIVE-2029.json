[+1 for removing 'hive.metastore.force.reload.conf'. Tests should not be written in such a manner that they need to modify the code. This has opened up multiple paths in Metastore code which needs to be reasoned about. 
Is there an agreement on whether connectionURL hook should look for default DB and create it in case it doesn't exist?, bq. Is there an agreement on whether connectionURL hook should look for default DB and create it in case it doesn't exist?

I'm definitely +1 on this.

@John/Paul: do either of you see any problem with automatically creating the default DB if it does not exist?, Patch which removes reload.conf property., I've asked Paul to take a look.  Adding test-specific properties is sometimes necessary for getting coverage on hard-to-simulate situations, though I agree we should try to keep them to a minimum.

Regarding creating the DB, it seems like this should somehow be tied to datanucleus.autoCreateSchema.  Hive's 'default' database is a row to be populated in this schema, so from the point of view of the underlying DBMS it is data rather than schema, but from the point of Hive, it's all metadata.
, Thinking more about it, I think retrial is a responsibility of ORM layer (jdo/datanucleus) not of application (Metastore in this case). Datanucleus already provides this failover facility: http://www.datanucleus.org/products/accessplatform_3_0/rdbms/failover.html Looks like I am missing something here. Why retrials are implemented in Metastore and we don't make use of datanucleus feature here?, My question didn't get any answers. So, let me ask another question. I think failover is present in datanucleus  3.0 and Hive is still on 2.x. So, that may be the reason that Hive implemented its own failover. If this is correct, shall we first upgrade Datanucleus version to 3.x and then switch to Datanucleus functionality instead of our own retrials. If there is an agreement then patch on this ticket can be committed as is and I will open tickets for followup work. , Does anyone have any opinion on this?, Can you elaborate on how this retry feature works in datanucleus 3.0? The case that could be handled with the URL hook is as follows - a db host goes down. A failover is performed and a replica on a different host is promoted to be the new master. Using the hook, the client is able to re-execute the query on the new host and the Hive query succeeds without failure. Would it be possible to implement something similar in datanucleus 3.0?, @Paul,
From the url I quoted above:
bq. DataNucleus has the capability to switch to between DataSources upon failure of one while obtaining a datastore connection. The failover mechanism is useful for applications with multiple database nodes when the data is actually replicated/synchronized by the underlying database.
So, DN will try to connect to a slave automatically when it can't connect with master. But it won't promote the slave to master so metastore can proceed with read only queries on DB. This falls short of what you have described, but once we upgrade to 3.x via HIVE-2084 we can atleast simplify the reconnect logic.]