[Possibly version mismatch including thrift. Could you check that first?, I am suspecting that too. But which component versions must match?

, Thrift related ones. libfb303-*.jar, libthrift-*.jar and hive-service-*.jar. , Hmm, I'm seeing: libfb303-0.9.0.jar,  libthrift-0.9.0.jar,
and hive-service-0.12.0.jar
Are these not correct?



, This is how we build hive:
export HADOOP_VERSION=2.2.0
ant clean package tar -Dhadoop.version=${HADOOP_VERSION} -Dhadoop-0.23.version=${HADOOP_VERSION} -Dhadoop.mr.rev=23 -Dmvn.hadoop.profile=hadoop23 -Dhadoop23.version=${HADOOP_VERSION} , We realized the issue was with a curl we were doing to ensure that hiveserver2 is up.
/usr/bin/curl --silent localhost:10000  causes this., Ah, yes. You should never call  via http or telnet to hiveserver2, which only accepts valid thrift call. It would be good to there is some guard code for that case in thrift server but there is no such thing in current implementation (in thrift) as I know., bq.  You should never call via http or telnet to hiveserver2, which only accepts valid thrift call.

That could be noted in the user docs:

*  [HiveServer2 Clients |https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients]

Perhaps it belongs after the first paragraph of the Beeline section, before the example.
, Made some guard code in hacky way. If you set hive.server2.sasl.message.limit with positive value, any SASL message bigger than than would not be parsed (and closes underlying transport).

{noformat}
navis@navis-book:~/apache/oss-hive(HIVE-6468)$ curl localhost:10000
curl: (52) Empty reply from server
navis@navis-book:~/apache/oss-hive(HIVE-6468)$ telnet localhost 10000
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
asd
Connection closed by foreign host.
{noformat}, I agree that guard against this is good. Just curious,  however, why a http get request would put HS2 in OOM? It's understandable that HS2 doesn't understand the request, but how it runs out of memory seems interesting., The format of sasl message in SaslTransport is something like this : status(1)+length(4)+payload(n). There is no magic header, no CRC, no validity check in it. It just creates byte[] after reading int value from offset 1, resulting OOM. Even when I've coded first client/server program 20 years ago, I didn't make things like this., I added this sentence to the second paragraph of the wiki's Beeline section:

{quote}
In remote mode HiveServer2 only accepts valid Thrift calls; you cannot call it via http or telnet (HIVE-6468).
{quote}

Please review and correct if necessary.

* [Beeline -- New Command Line Shell |https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Beeline–NewCommandLineShell], [~leftylev] "cannot" -> "must not" would be better. You can call it but that will make hiveserver die., Thanks, I put it in a warning box with this wording:  "In remote mode HiveServer2 only accepts valid Thrift calls – do not attempt to call it via http or telnet (HIVE-6468)."

Should it also explain that HS2 will die, or is that just until this jira's patch gets added?  Readers can click the link to this jira if they want to know the reason for the warning, but we could make it explicit if you think that's better.

By the way, *hive.server2.sasl.message.limit* needs some user doc.  It can go in a HiveConf.java comment for now, or in a release note, until we know when HIVE-6037 will get committed.

Quick ref:

* [new warning in Beeline – New Command Line Shell |https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Beeline–NewCommandLineShell]
* [page history:  new changes |https://cwiki.apache.org/confluence/pages/diffpages.action?pageId=30758725&originalId=40505296], [~navis] HiveServer2 can run in http mode (I just updated the wiki [Setting+up+HiveServer2|https://cwiki.apache.org/confluence/display/Hive/Setting+up+HiveServer2]), where basically the thrift RPC calls happen over http. In the http mode, there is an embedded jetty instance listening on the port which HiveServer2 was started on. 

[~leftylev] I will modify the warning message to indicate that even in http mode, the message body is thrift payloads. 
Thanks!, Good doc, [~vaibhavgumashta].  I did some light editing (mostly capitalization) and fixed a typo.  Were the empty links on "jdbc:hive2://" intentional?  I removed them, but I'll put them back if you wanted them there for emphasis.  Your use of color on a default value is nice -- we might want to use that in other wikidocs., Thanks a lot for the edits & corrections [~leftylev]! The doc looks good., Just a reminder:

bq.  By the way, *hive.server2.sasl.message.limit* needs some user doc.  It can go in a HiveConf.java comment for now, or in a release note, until we know when HIVE-6037 will get committed., This is a pretty egregious bug! Any reviews for the patch Navis posted? Can we please check in some guard? , 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12633065/HIVE-6468.1.patch.txt

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/590/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/590/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-590/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.6.0_34/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.6.0_34/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-590/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n '' ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ egrep -v '^X|^Performing status on external'
++ awk '{print $2}'
++ svn status --no-ignore
+ rm -rf
+ svn update

Fetching external item into 'hcatalog/src/test/e2e/harness'
External at revision 1605453.

At revision 1605453.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12633065, Good to know that someone is interested in this. Rebased to trunk., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12652560/HIVE-6468.2.patch.txt

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 5654 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_stats_empty_partition
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/600/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/600/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-600/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12652560, Hi Navis! Thanks a lot for your patch! I'm glad at least someone is cognizant of the severity of this problem. Do you think we should increase the priority for this JIRA?

The patch looks good to me overall except for a few nits. FWIW, here they are:
HiveAuthFactory:
1. Could we just rewrite authTypeStr.equalsIgnoreCase(AuthTypes.KERBEROS.name()) -> authType == AuthTypes.KERBEROS
2. You're catching Exception. Any reason you changed this from IOException? IMHO IOException would have been preferable
3. This block is unnecessary {code}     } else {
      saslServer = null;
    } {code}
4. getAuthTransFactory() is throwing Exception now. Why did you have to change that from LoginException?

PlainSaslHelper:
1. public String mechanism; is never used
2. I'm not sure what the consequences of using WeakReferences and WeakHashMap will be. Could you please comment on that?
3. Can we also put a timeout on {code} underlyingTransport.readAll(messageHeader, 0, messageHeader.length); {code}  if there isn't one already?
, 1. ok, sure.
2. just wanted not to miss any runtime exceptions. Not much differences in action.
3. saslServer is final field. So must be assigned to null.
4. Thought wrapping AuthenticationException into LoginException is not that useful.

For PlainSaslHelper, most of codes are copied as-is from TSaslServerTransport.Factory. So, I believe there's a reason for weak references. 
For socket timeout, there are other issues for it (HIVE-6679, etc.). , Thanks Navis!
2. IMHO We should not catch RuntimeExceptions. There's a danger that we might end up covering the real exception (the OOM). Otherwise what's the point of having an exception hierarchy?
3. Good point. Thanks
4. Same as 2. getAuthTransFactory() could throw all the necessary exceptions
{code}public TTransportFactory getAuthTransFactory() throws TTransportException, AuthenticationException, LoginException {code}

I'm afraid I don't know enough about writing Thrift servers to review that code. 
Thanks for the pointer. I'm happy to add the timeout there., Thanks for the description of *hive.server2.sasl.message.limit* in hive-default.xml.template.  (If you're doing another patch, it would be good to capitalize SASL in the description.), It would also help add a check for the payload length detected as < 0 (i.e. negative number) aside of an upper message cap.

It also seems Thrift is doing this incorrectly so we should rather fix it there and consume it in, than duplicate its code at our end. I found this JIRA after I'd filed THRIFT-2660., Since THRIFT-2660 has been committed, it appears we can resolve this issue by upgrading thrift when released?, bq.  Since THRIFT-2660 has been committed, it appears we can resolve this issue by upgrading thrift when released?

Is this issue resolved?  (So *hive.server2.sasl.message.limit* won't ever be added to HiveConf.java?), The issue is not resolved. For the issue to be resolved, either Hive should update its thrift dependency to 0.9.2 (or higher), to pull in the THFIT-2660 fix, or Hive should RTC the alternative patch created here.

If the former is done, the config will not be introduced, nor needed., Okay, thanks.  I'll keep it on my "pending" list for docs., If there is a 0.14.1, I think we should get this in. For 0.15.0, bumping up the thrift version would work. However, this patch doesn't take care of having a max payload length for Kerberos auth mode. In addition, even Metastore running SASL (does that when it uses Kerberos) will go OOM if it gets non-thrift packets. 

[~navis] [~thejas] [~qwertymaniac] What do you guys think? I can put up a patch on top of #2 patch uploaded here which takes care of the remaining cases as well., Patch attached is based on 0.14.0 geared towards 0.14.1. Added fix for Metastore SASL and HiveServer2 Kerberos SASL in addition to the Plain SASL fix that the previous patch had.

cc [~thejas] [~navis], 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12681451/HIVE-6468.4.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1780/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1780/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1780/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
Starting Generation of: TestCompareCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestCompareCliDriver.java from template TestCompareCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestMinimrCliDriver
Include Files: auto_sortmerge_join_16.q,bucket4.q,bucket5.q,bucket6.q,bucket_num_reducers.q,bucket_num_reducers2.q,bucketizedhiveinputformat.q,bucketmapjoin6.q,bucketmapjoin7.q,disable_merge_for_bucketing.q,empty_dir_in_table.q,external_table_with_space_in_location_path.q,file_with_header_footer.q,groupby2.q,import_exported_table.q,index_bitmap3.q,index_bitmap_auto.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,input16_cc.q,join1.q,leftsemijoin_mr.q,list_bucket_dml_10.q,load_fs2.q,load_hdfs_file_with_space_in_the_name.q,optrstat_groupby.q,parallel_orderby.q,ql_rewrite_gbtoidx.q,quotedid_smb.q,reduce_deduplicate.q,remote_script.q,root_dir_external_table.q,schemeAuthority.q,schemeAuthority2.q,scriptfile1.q,scriptfile1_win.q,smb_mapjoin_8.q,stats_counter.q,stats_counter_partitioned.q,temp_table_external.q,truncate_column_buckets.q,uber_reduce.q,udf_using.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestMinimrCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestMiniTezCliDriver
Include Files: bucket_map_join_tez1.q,bucket_map_join_tez2.q,dynamic_partition_pruning.q,dynamic_partition_pruning_2.q,mapjoin_decimal.q,mrr.q,tez_bmj_schema_evolution.q,tez_dml.q,tez_fsstat.q,tez_insert_overwrite_local_directory_1.q,tez_join_hash.q,tez_join_tests.q,tez_joins_explain.q,tez_schema_evolution.q,tez_union.q,tez_union_decimal.q,tez_union_group_by.q,tez_smb_main.q,tez_smb_1.q,vectorized_dynamic_partition_pruning.q,alter_merge_2_orc.q,alter_merge_orc.q,alter_merge_stats_orc.q,auto_join0.q,auto_join1.q,bucket2.q,bucket3.q,bucket4.q,cbo_gby.q,cbo_gby_empty.q,cbo_join.q,cbo_limit.q,cbo_semijoin.q,cbo_simple_select.q,cbo_stats.q,cbo_subq_exists.q,cbo_subq_in.q,cbo_subq_not_in.q,cbo_udf_udaf.q,cbo_union.q,cbo_views.q,cbo_windowing.q,correlationoptimizer1.q,count.q,create_merge_compressed.q,cross_join.q,cross_product_check_1.q,cross_product_check_2.q,ctas.q,custom_input_output_format.q,delete_all_non_partitioned.q,delete_all_partitioned.q,delete_orig_table.q,delete_tmp_table.q,delete_where_no_match.q,delete_where_non_partitioned.q,delete_where_partitioned.q,delete_whole_partition.q,disable_merge_for_bucketing.q,dynpart_sort_opt_vectorization.q,dynpart_sort_optimization.q,dynpart_sort_optimization2.q,enforce_order.q,filter_join_breaktask.q,filter_join_breaktask2.q,groupby1.q,groupby2.q,groupby3.q,having.q,insert1.q,insert_into1.q,insert_into2.q,insert_orig_table.q,insert_values_dynamic_partitioned.q,insert_values_non_partitioned.q,insert_values_orig_table.qinsert_values_partitioned.q,insert_values_tmp_table.q,insert_update_delete.q,join0.q,join1.q,join_nullsafe.q,leftsemijoin.q,limit_pushdown.q,load_dyn_part1.q,load_dyn_part2.q,load_dyn_part3.q,mapjoin_mapjoin.q,mapreduce1.q,mapreduce2.q,merge1.q,merge2.q,metadataonly1.q,metadata_only_queries.q,optimize_nullscan.q,orc_analyze.q,orc_merge1.q,orc_merge2.q,orc_merge3.q,orc_merge4.q,orc_merge5.q,orc_merge6.q,orc_merge7.q,orc_merge_incompat1.q,orc_merge_incompat2.q,orc_vectorization_ppd.q,parallel.q,ptf.q,sample1.q,script_env_var1.q,script_env_var2.q,script_pipe.q,scriptfile1.q,select_dummy_source.q,skewjoin.q,stats_counter.q,stats_counter_partitioned.q,stats_noscan_1.q,subquery_exists.q,subquery_in.q,temp_table.q,transform1.q,transform2.q,transform_ppr1.q,transform_ppr2.q,union2.q,union3.q,union4.q,union5.q,union6.q,union7.q,union8.q,union9.q,update_after_multiple_inserts.q,update_all_non_partitioned.q,update_all_partitioned.q,update_all_types.q,update_orig_table.q,update_tmp_table.q,update_where_no_match.q,update_where_non_partitioned.q,update_where_partitioned.q,update_two_cols.q,vector_between_in.q,vector_bucket.q,vector_cast_constant.q,vector_char_4.q,vector_char_simple.q,vector_coalesce.q,vector_count_distinct.q,vector_data_types.q,vector_decimal_1.q,vector_decimal_10_0.q,vector_decimal_2.q,vector_decimal_3.q,vector_decimal_4.q,vector_decimal_5.q,vector_decimal_6.q,vector_decimal_aggregate.q,vector_decimal_cast.q,vector_decimal_expressions.q,vector_decimal_mapjoin.q,vector_decimal_math_funcs.q,vector_decimal_precision.q,vector_decimal_trailing.q,vector_decimal_udf.q,vector_decimal_udf2.q,vector_distinct_2.q,vector_elt.q,vector_groupby_3.q,vector_groupby_reduce.q,vector_left_outer_join.q,vector_mapjoin_reduce.q,vector_non_string_partition.q,vector_orderby_5.q,vector_partitioned_date_time.q,vector_reduce_groupby_decimal.q,vector_string_concat.q,vector_varchar_4.q,vector_varchar_simple.q,vectorization_0.q,vectorization_1.q,vectorization_10.q,vectorization_11.q,vectorization_12.q,vectorization_13.q,vectorization_14.q,vectorization_15.q,vectorization_16.q,vectorization_2.q,vectorization_3.q,vectorization_4.q,vectorization_5.q,vectorization_6.q,vectorization_7.q,vectorization_8.q,vectorization_9.q,vectorization_decimal_date.q,vectorization_div0.q,vectorization_limit.q,vectorization_nested_udf.q,vectorization_not.q,vectorization_part.q,vectorization_part_project.q,vectorization_pushdown.q,vectorization_short_regress.q,vectorized_bucketmapjoin1.q,vectorized_case.q,vectorized_casts.q,vectorized_context.q,vectorized_date_funcs.q,vectorized_distinct_gby.q,vectorized_mapjoin.q,vectorized_math_funcs.q,vectorized_nested_mapjoin.q,vectorized_parquet.q,vectorized_ptf.q,vectorized_rcfile_columnar.q,vectorized_shufflejoin.q,vectorized_string_funcs.q,vectorized_timestamp_funcs.q,auto_sortmerge_join_1.q,auto_sortmerge_join_10.q,auto_sortmerge_join_11.q,auto_sortmerge_join_12.q,auto_sortmerge_join_13.q,auto_sortmerge_join_14.q,auto_sortmerge_join_15.q,auto_sortmerge_join_16.q,auto_sortmerge_join_2.q,auto_sortmerge_join_3.q,auto_sortmerge_join_4.q,auto_sortmerge_join_5.q,auto_sortmerge_join_7.q,auto_sortmerge_join_8.q,auto_sortmerge_join_9.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestMiniTezCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestNegativeMinimrCliDriver
Include Files: cluster_tasklog_retrieval.q,file_with_header_footer_negative.q,local_mapred_error_cache.q,mapreduce_stack_trace.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_turnoff_hadoop20.q,minimr_broken_pipe.q,udf_local_resource.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestNegativeMinimrCliDriver.java from template TestNegativeCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseCliDriver.java from template TestHBaseCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseMinimrCliDriver
Include Files: null
Excluded Files: null
Query Files: hbase_bulk.m
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseMinimrCliDriver.java from template TestHBaseCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseNegativeCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseNegativeCliDriver.java from template TestHBaseNegativeCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/accumulo-handler/src/test/templates
Starting Generation of: TestAccumuloCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestAccumuloCliDriver.java from template TestAccumuloCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestContribCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestContribCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestContribNegativeCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestContribNegativeCliDriver.java from template TestNegativeCliDriver.vm
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-it-qfile ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-qfile ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-qfile ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-qfile ---
[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-qfile ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-qfile ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/hive-it-qfile-0.15.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-qfile ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-qfile ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/hive-it-qfile-0.15.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-qfile/0.15.0-SNAPSHOT/hive-it-qfile-0.15.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-qfile/0.15.0-SNAPSHOT/hive-it-qfile-0.15.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Unit Tests - Hadoop 2 0.15.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit-hadoop2 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit-hadoop2 ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit-hadoop2 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit-hadoop2 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit-hadoop2 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/scripts/metastore
     [copy] Copying 190 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/scripts/metastore
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit-hadoop2 ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java uses or overrides a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java uses unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java:[82,7] method does not override or implement a method from a supertype
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [7.095s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [14.309s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [17.487s]
[INFO] Hive Integration - Testing Utilities .............. SUCCESS [15.790s]
[INFO] Hive Integration - Unit Tests ..................... SUCCESS [12.896s]
[INFO] Hive Integration - Test Serde ..................... SUCCESS [1.267s]
[INFO] Hive Integration - QFile Tests .................... SUCCESS [9.204s]
[INFO] Hive Integration - Unit Tests - Hadoop 2 .......... FAILURE [4.064s]
[INFO] Hive Integration - Unit Tests with miniKdc ........ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:25.967s
[INFO] Finished at: Fri Nov 14 00:43:23 EST 2014
[INFO] Final Memory: 67M/214M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit-hadoop2: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java:[82,7] method does not override or implement a method from a supertype
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-it-unit-hadoop2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12681451 - PreCommit-HIVE-TRUNK-Build, Revised patch for 14.1. I'll upload one based on trunk just for precommit run (we're upgrading thrift version for trunk - not planning to use this patch)., Patch .0 based on trunk just for getting a precommit run. On trunk this issue has been resolved with a thrify version upgrade.

[~thejas] Does the latest patch (.5) look good for 14.1?, +1  pending tests.
Can you upload the patch file with the branch name to kick off tests against 0.14 branch ? As per - 
https://cwiki.apache.org/confluence/display/Hive/Hive+PreCommit+Patch+Testing
, [~thejas] Done., 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12685369/HIVE-6468.0.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1970/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1970/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1970/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestCompareCliDriver.java from template TestCompareCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestMinimrCliDriver
Include Files: auto_sortmerge_join_16.q,bucket4.q,bucket5.q,bucket6.q,bucket_num_reducers.q,bucket_num_reducers2.q,bucketizedhiveinputformat.q,bucketmapjoin6.q,bucketmapjoin7.q,disable_merge_for_bucketing.q,empty_dir_in_table.q,external_table_with_space_in_location_path.q,file_with_header_footer.q,groupby2.q,import_exported_table.q,index_bitmap3.q,index_bitmap_auto.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,input16_cc.q,join1.q,leftsemijoin_mr.q,list_bucket_dml_10.q,load_fs2.q,load_hdfs_file_with_space_in_the_name.q,optrstat_groupby.q,parallel_orderby.q,ql_rewrite_gbtoidx.q,quotedid_smb.q,reduce_deduplicate.q,remote_script.q,root_dir_external_table.q,schemeAuthority.q,schemeAuthority2.q,scriptfile1.q,scriptfile1_win.q,smb_mapjoin_8.q,stats_counter.q,stats_counter_partitioned.q,temp_table_external.q,truncate_column_buckets.q,uber_reduce.q,udf_using.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestMinimrCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestMiniTezCliDriver
Include Files: bucket_map_join_tez1.q,bucket_map_join_tez2.q,dynamic_partition_pruning.q,dynamic_partition_pruning_2.q,mapjoin_decimal.q,lvj_mapjoin.q, mrr.q,tez_bmj_schema_evolution.q,tez_dml.q,tez_fsstat.q,tez_insert_overwrite_local_directory_1.q,tez_join_hash.q,tez_join_tests.q,tez_joins_explain.q,tez_schema_evolution.q,tez_union.q,tez_union_decimal.q,tez_union_group_by.q,tez_smb_main.q,tez_smb_1.q,vectorized_dynamic_partition_pruning.q,alter_merge_2_orc.q,alter_merge_orc.q,alter_merge_stats_orc.q,auto_join0.q,auto_join1.q,bucket2.q,bucket3.q,bucket4.q,cbo_gby.q,cbo_gby_empty.q,cbo_join.q,cbo_limit.q,cbo_semijoin.q,cbo_simple_select.q,cbo_stats.q,cbo_subq_exists.q,cbo_subq_in.q,cbo_subq_not_in.q,cbo_udf_udaf.q,cbo_union.q,cbo_views.q,cbo_windowing.q,correlationoptimizer1.q,count.q,create_merge_compressed.q,cross_join.q,cross_product_check_1.q,cross_product_check_2.q,ctas.q,custom_input_output_format.q,delete_all_non_partitioned.q,delete_all_partitioned.q,delete_orig_table.q,delete_tmp_table.q,delete_where_no_match.q,delete_where_non_partitioned.q,delete_where_partitioned.q,delete_whole_partition.q,disable_merge_for_bucketing.q,dynpart_sort_opt_vectorization.q,dynpart_sort_optimization.q,dynpart_sort_optimization2.q,enforce_order.q,filter_join_breaktask.q,filter_join_breaktask2.q,groupby1.q,groupby2.q,groupby3.q,having.q,insert1.q,insert_into1.q,insert_into2.q,insert_orig_table.q,insert_values_dynamic_partitioned.q,insert_values_non_partitioned.q,insert_values_orig_table.qinsert_values_partitioned.q,insert_values_tmp_table.q,insert_update_delete.q,join0.q,join1.q,join_nullsafe.q,leftsemijoin.q,limit_pushdown.q,load_dyn_part1.q,load_dyn_part2.q,load_dyn_part3.q,mapjoin_mapjoin.q,mapreduce1.q,mapreduce2.q,merge1.q,merge2.q,metadataonly1.q,metadata_only_queries.q,optimize_nullscan.q,orc_analyze.q,orc_merge1.q,orc_merge2.q,orc_merge3.q,orc_merge4.q,orc_merge5.q,orc_merge6.q,orc_merge7.q,orc_merge_incompat1.q,orc_merge_incompat2.q,orc_vectorization_ppd.q,parallel.q,ptf.q,sample1.q,script_env_var1.q,script_env_var2.q,script_pipe.q,scriptfile1.q,select_dummy_source.q,skewjoin.q,stats_counter.q,stats_counter_partitioned.q,stats_noscan_1.q,subquery_exists.q,subquery_in.q,temp_table.q,transform1.q,transform2.q,transform_ppr1.q,transform_ppr2.q,union2.q,union3.q,union4.q,union5.q,union6.q,union7.q,union8.q,union9.q,update_after_multiple_inserts.q,update_all_non_partitioned.q,update_all_partitioned.q,update_all_types.q,update_orig_table.q,update_tmp_table.q,update_where_no_match.q,update_where_non_partitioned.q,update_where_partitioned.q,update_two_cols.q,vector_between_in.q,vector_bucket.q,vector_cast_constant.q,vector_char_4.q,vector_char_simple.q,vector_coalesce.q,vector_count_distinct.q,vector_data_types.q,vector_decimal_1.q,vector_decimal_10_0.q,vector_decimal_2.q,vector_decimal_3.q,vector_decimal_4.q,vector_decimal_5.q,vector_decimal_6.q,vector_decimal_aggregate.q,vector_decimal_cast.q,vector_decimal_expressions.q,vector_decimal_mapjoin.q,vector_decimal_math_funcs.q,vector_decimal_precision.q,vector_decimal_trailing.q,vector_decimal_udf.q,vector_decimal_udf2.q,vector_distinct_2.q,vector_elt.q,vector_groupby_3.q,vector_groupby_reduce.q,vector_left_outer_join.q,vector_mapjoin_reduce.q,vector_non_string_partition.q,vector_orderby_5.q,vector_partitioned_date_time.q,vector_reduce_groupby_decimal.q,vector_string_concat.q,vector_varchar_4.q,vector_varchar_simple.q,vectorization_0.q,vectorization_1.q,vectorization_10.q,vectorization_11.q,vectorization_12.q,vectorization_13.q,vectorization_14.q,vectorization_15.q,vectorization_16.q,vectorization_2.q,vectorization_3.q,vectorization_4.q,vectorization_5.q,vectorization_6.q,vectorization_7.q,vectorization_8.q,vectorization_9.q,vectorization_decimal_date.q,vectorization_div0.q,vectorization_limit.q,vectorization_nested_udf.q,vectorization_not.q,vectorization_part.q,vectorization_part_project.q,vectorization_pushdown.q,vectorization_short_regress.q,vectorized_bucketmapjoin1.q,vectorized_case.q,vectorized_casts.q,vectorized_context.q,vectorized_date_funcs.q,vectorized_distinct_gby.q,vectorized_mapjoin.q,vectorized_math_funcs.q,vectorized_nested_mapjoin.q,vectorized_parquet.q,vectorized_ptf.q,vectorized_rcfile_columnar.q,vectorized_shufflejoin.q,vectorized_string_funcs.q,vectorized_timestamp_funcs.q,auto_sortmerge_join_1.q,auto_sortmerge_join_10.q,auto_sortmerge_join_11.q,auto_sortmerge_join_12.q,auto_sortmerge_join_13.q,auto_sortmerge_join_14.q,auto_sortmerge_join_15.q,auto_sortmerge_join_16.q,auto_sortmerge_join_2.q,auto_sortmerge_join_3.q,auto_sortmerge_join_4.q,auto_sortmerge_join_5.q,auto_sortmerge_join_7.q,auto_sortmerge_join_8.q,auto_sortmerge_join_9.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestMiniTezCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestNegativeMinimrCliDriver
Include Files: cluster_tasklog_retrieval.q,file_with_header_footer_negative.q,local_mapred_error_cache.q,mapreduce_stack_trace.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_turnoff_hadoop20.q,minimr_broken_pipe.q,udf_local_resource.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestNegativeMinimrCliDriver.java from template TestNegativeCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseCliDriver.java from template TestHBaseCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseMinimrCliDriver
Include Files: null
Excluded Files: null
Query Files: hbase_bulk.m
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseMinimrCliDriver.java from template TestHBaseCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseNegativeCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseNegativeCliDriver.java from template TestHBaseNegativeCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/accumulo-handler/src/test/templates
Starting Generation of: TestAccumuloCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestAccumuloCliDriver.java from template TestAccumuloCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestContribCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestContribCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestContribNegativeCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestContribNegativeCliDriver.java from template TestNegativeCliDriver.vm
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-it-qfile ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-qfile ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-qfile ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-qfile ---
[INFO] Compiling 14 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-qfile ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-qfile ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/hive-it-qfile-0.15.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-qfile ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-qfile ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/hive-it-qfile-0.15.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-qfile/0.15.0-SNAPSHOT/hive-it-qfile-0.15.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-qfile/0.15.0-SNAPSHOT/hive-it-qfile-0.15.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Unit Tests - Hadoop 2 0.15.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit-hadoop2 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-unit-hadoop2 ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit-hadoop2 ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit-hadoop2 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit-hadoop2 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit-hadoop2 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/scripts/metastore
     [copy] Copying 192 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/scripts/metastore
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit-hadoop2 ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java uses or overrides a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java uses unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java:[82,7] method does not override or implement a method from a supertype
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [7.867s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [12.792s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [15.058s]
[INFO] Hive Integration - Testing Utilities .............. SUCCESS [14.114s]
[INFO] Hive Integration - Unit Tests ..................... SUCCESS [12.109s]
[INFO] Hive Integration - Test Serde ..................... SUCCESS [1.505s]
[INFO] Hive Integration - QFile Tests .................... SUCCESS [8.816s]
[INFO] Hive Integration - Unit Tests - Hadoop 2 .......... FAILURE [2.729s]
[INFO] Hive Integration - Unit Tests with miniKdc ........ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:19.016s
[INFO] Finished at: Fri Dec 05 14:04:09 EST 2014
[INFO] Final Memory: 70M/184M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit-hadoop2: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java:[82,7] method does not override or implement a method from a supertype
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-it-unit-hadoop2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12685369 - PreCommit-HIVE-TRUNK-Build, Removing .0 since this is only for 14.1. Thanks for the link Thejas., FYI - I don't think precommit is setup for the 0.14 branch., Thanks [~brocknoland]. I'll run it on the trunk then.  , Patch based on trunk for precommit run., 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12685543/HIVE-6468.0.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1981/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1981/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1981/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestCompareCliDriver.java from template TestCompareCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestMinimrCliDriver
Include Files: auto_sortmerge_join_16.q,bucket4.q,bucket5.q,bucket6.q,bucket_num_reducers.q,bucket_num_reducers2.q,bucketizedhiveinputformat.q,bucketmapjoin6.q,bucketmapjoin7.q,disable_merge_for_bucketing.q,empty_dir_in_table.q,external_table_with_space_in_location_path.q,file_with_header_footer.q,groupby2.q,import_exported_table.q,index_bitmap3.q,index_bitmap_auto.q,infer_bucket_sort_bucketed_table.q,infer_bucket_sort_dyn_part.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,input16_cc.q,join1.q,leftsemijoin_mr.q,list_bucket_dml_10.q,load_fs2.q,load_hdfs_file_with_space_in_the_name.q,optrstat_groupby.q,parallel_orderby.q,ql_rewrite_gbtoidx.q,quotedid_smb.q,reduce_deduplicate.q,remote_script.q,root_dir_external_table.q,schemeAuthority.q,schemeAuthority2.q,scriptfile1.q,scriptfile1_win.q,smb_mapjoin_8.q,stats_counter.q,stats_counter_partitioned.q,temp_table_external.q,truncate_column_buckets.q,uber_reduce.q,udf_using.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestMinimrCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestMiniTezCliDriver
Include Files: bucket_map_join_tez1.q,bucket_map_join_tez2.q,dynamic_partition_pruning.q,dynamic_partition_pruning_2.q,mapjoin_decimal.q,lvj_mapjoin.q, mrr.q,tez_bmj_schema_evolution.q,tez_dml.q,tez_fsstat.q,tez_insert_overwrite_local_directory_1.q,tez_join_hash.q,tez_join_tests.q,tez_joins_explain.q,tez_schema_evolution.q,tez_union.q,tez_union_decimal.q,tez_union_group_by.q,tez_smb_main.q,tez_smb_1.q,vectorized_dynamic_partition_pruning.q,alter_merge_2_orc.q,alter_merge_orc.q,alter_merge_stats_orc.q,auto_join0.q,auto_join1.q,bucket2.q,bucket3.q,bucket4.q,cbo_gby.q,cbo_gby_empty.q,cbo_join.q,cbo_limit.q,cbo_semijoin.q,cbo_simple_select.q,cbo_stats.q,cbo_subq_exists.q,cbo_subq_in.q,cbo_subq_not_in.q,cbo_udf_udaf.q,cbo_union.q,cbo_views.q,cbo_windowing.q,correlationoptimizer1.q,count.q,create_merge_compressed.q,cross_join.q,cross_product_check_1.q,cross_product_check_2.q,ctas.q,custom_input_output_format.q,delete_all_non_partitioned.q,delete_all_partitioned.q,delete_orig_table.q,delete_tmp_table.q,delete_where_no_match.q,delete_where_non_partitioned.q,delete_where_partitioned.q,delete_whole_partition.q,disable_merge_for_bucketing.q,dynpart_sort_opt_vectorization.q,dynpart_sort_optimization.q,dynpart_sort_optimization2.q,enforce_order.q,filter_join_breaktask.q,filter_join_breaktask2.q,groupby1.q,groupby2.q,groupby3.q,having.q,insert1.q,insert_into1.q,insert_into2.q,insert_orig_table.q,insert_values_dynamic_partitioned.q,insert_values_non_partitioned.q,insert_values_orig_table.qinsert_values_partitioned.q,insert_values_tmp_table.q,insert_update_delete.q,join0.q,join1.q,join_nullsafe.q,leftsemijoin.q,limit_pushdown.q,load_dyn_part1.q,load_dyn_part2.q,load_dyn_part3.q,mapjoin_mapjoin.q,mapreduce1.q,mapreduce2.q,merge1.q,merge2.q,metadataonly1.q,metadata_only_queries.q,optimize_nullscan.q,orc_analyze.q,orc_merge1.q,orc_merge2.q,orc_merge3.q,orc_merge4.q,orc_merge5.q,orc_merge6.q,orc_merge7.q,orc_merge_incompat1.q,orc_merge_incompat2.q,orc_vectorization_ppd.q,parallel.q,ptf.q,sample1.q,script_env_var1.q,script_env_var2.q,script_pipe.q,scriptfile1.q,select_dummy_source.q,skewjoin.q,stats_counter.q,stats_counter_partitioned.q,stats_noscan_1.q,subquery_exists.q,subquery_in.q,temp_table.q,transform1.q,transform2.q,transform_ppr1.q,transform_ppr2.q,union2.q,union3.q,union4.q,union5.q,union6.q,union7.q,union8.q,union9.q,update_after_multiple_inserts.q,update_all_non_partitioned.q,update_all_partitioned.q,update_all_types.q,update_orig_table.q,update_tmp_table.q,update_where_no_match.q,update_where_non_partitioned.q,update_where_partitioned.q,update_two_cols.q,vector_between_in.q,vector_bucket.q,vector_cast_constant.q,vector_char_4.q,vector_char_simple.q,vector_coalesce.q,vector_count_distinct.q,vector_data_types.q,vector_decimal_1.q,vector_decimal_10_0.q,vector_decimal_2.q,vector_decimal_3.q,vector_decimal_4.q,vector_decimal_5.q,vector_decimal_6.q,vector_decimal_aggregate.q,vector_decimal_cast.q,vector_decimal_expressions.q,vector_decimal_mapjoin.q,vector_decimal_math_funcs.q,vector_decimal_precision.q,vector_decimal_trailing.q,vector_decimal_udf.q,vector_decimal_udf2.q,vector_distinct_2.q,vector_elt.q,vector_groupby_3.q,vector_groupby_reduce.q,vector_left_outer_join.q,vector_mapjoin_reduce.q,vector_non_string_partition.q,vector_orderby_5.q,vector_partitioned_date_time.q,vector_reduce_groupby_decimal.q,vector_string_concat.q,vector_varchar_4.q,vector_varchar_simple.q,vectorization_0.q,vectorization_1.q,vectorization_10.q,vectorization_11.q,vectorization_12.q,vectorization_13.q,vectorization_14.q,vectorization_15.q,vectorization_16.q,vectorization_2.q,vectorization_3.q,vectorization_4.q,vectorization_5.q,vectorization_6.q,vectorization_7.q,vectorization_8.q,vectorization_9.q,vectorization_decimal_date.q,vectorization_div0.q,vectorization_limit.q,vectorization_nested_udf.q,vectorization_not.q,vectorization_part.q,vectorization_part_project.q,vectorization_pushdown.q,vectorization_short_regress.q,vectorized_bucketmapjoin1.q,vectorized_case.q,vectorized_casts.q,vectorized_context.q,vectorized_date_funcs.q,vectorized_distinct_gby.q,vectorized_mapjoin.q,vectorized_math_funcs.q,vectorized_nested_mapjoin.q,vectorized_parquet.q,vectorized_ptf.q,vectorized_rcfile_columnar.q,vectorized_shufflejoin.q,vectorized_string_funcs.q,vectorized_timestamp_funcs.q,auto_sortmerge_join_1.q,auto_sortmerge_join_10.q,auto_sortmerge_join_11.q,auto_sortmerge_join_12.q,auto_sortmerge_join_13.q,auto_sortmerge_join_14.q,auto_sortmerge_join_15.q,auto_sortmerge_join_16.q,auto_sortmerge_join_2.q,auto_sortmerge_join_3.q,auto_sortmerge_join_4.q,auto_sortmerge_join_5.q,auto_sortmerge_join_7.q,auto_sortmerge_join_8.q,auto_sortmerge_join_9.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestMiniTezCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestNegativeMinimrCliDriver
Include Files: cluster_tasklog_retrieval.q,file_with_header_footer_negative.q,local_mapred_error_cache.q,mapreduce_stack_trace.q,mapreduce_stack_trace_hadoop20.q,mapreduce_stack_trace_turnoff.q,mapreduce_stack_trace_turnoff_hadoop20.q,minimr_broken_pipe.q,udf_local_resource.q
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestNegativeMinimrCliDriver.java from template TestNegativeCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseCliDriver.java from template TestHBaseCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseMinimrCliDriver
Include Files: null
Excluded Files: null
Query Files: hbase_bulk.m
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseMinimrCliDriver.java from template TestHBaseCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/templates
Starting Generation of: TestHBaseNegativeCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestHBaseNegativeCliDriver.java from template TestHBaseNegativeCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/accumulo-handler/src/test/templates
Starting Generation of: TestAccumuloCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: null
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestAccumuloCliDriver.java from template TestAccumuloCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestContribCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestContribCliDriver.java from template TestCliDriver.vm
Template Path:/data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/templates
Starting Generation of: TestContribNegativeCliDriver
Include Files: null
Excluded Files: null
Query Files: 
Query Files Regex: 
Generated /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java/org/apache/hadoop/hive/cli/TestContribNegativeCliDriver.java from template TestNegativeCliDriver.vm
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-it-qfile ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-qfile ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-qfile ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-qfile ---
[INFO] Compiling 14 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-qfile ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-qfile ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/hive-it-qfile-0.15.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-qfile ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-qfile ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/target/hive-it-qfile-0.15.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-qfile/0.15.0-SNAPSHOT/hive-it-qfile-0.15.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/qtest/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-qfile/0.15.0-SNAPSHOT/hive-it-qfile-0.15.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Unit Tests - Hadoop 2 0.15.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit-hadoop2 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-unit-hadoop2 ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit-hadoop2 ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit-hadoop2 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit-hadoop2 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit-hadoop2 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/conf
     [copy] Copying 8 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit-hadoop2 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/scripts/metastore
     [copy] Copying 192 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/tmp/scripts/metastore
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit-hadoop2 ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java uses or overrides a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java: /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java uses unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestPasswordWithCredentialProvider.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java:[82,7] method does not override or implement a method from a supertype
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [7.558s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [12.972s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [17.416s]
[INFO] Hive Integration - Testing Utilities .............. SUCCESS [15.094s]
[INFO] Hive Integration - Unit Tests ..................... SUCCESS [13.740s]
[INFO] Hive Integration - Test Serde ..................... SUCCESS [1.446s]
[INFO] Hive Integration - QFile Tests .................... SUCCESS [10.098s]
[INFO] Hive Integration - Unit Tests - Hadoop 2 .......... FAILURE [3.625s]
[INFO] Hive Integration - Unit Tests with miniKdc ........ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:25.846s
[INFO] Finished at: Sat Dec 06 10:08:11 EST 2014
[INFO] Final Memory: 69M/183M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit-hadoop2: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/thrift/TestHadoop20SAuthBridge.java:[82,7] method does not override or implement a method from a supertype
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-it-unit-hadoop2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12685543 - PreCommit-HIVE-TRUNK-Build, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12685699/HIVE-6468.0.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 6698 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1998/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1998/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1998/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12685699 - PreCommit-HIVE-TRUNK-Build, Test failures are unrelated., Updated patch for 14. Will commit this shortly to 14., Committed to 14.1. Thanks for the patch [~navis] and thanks for reviewing [~thejas], [~raviprak]., Doc note:  Add *hive.thrift.sasl.message.limit* to the wiki in Configuration Properties.  But which section?  Perhaps it belongs in the Metastore section after *hive.metastore.sasl.enabled* -- most other mentions of SASL occur in the HiveServer2 section.

* [Configuration Properties -- Metastore | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-MetaStore]
** [hive.metastore.sasl.enabled | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.metastore.sasl.enabled]
* [Configuration Properties -- HiveServer2 | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-HiveServer2]
** [hive.server2.authentication | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.server2.authentication]
** [hive.server2.thrift.sasl.qop | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.server2.thrift.sasl.qop]

bq.  "On trunk this issue has been resolved with a thrift version upgrade."

Does that mean *hive.thrift.sasl.message.limit* will only exist in the 0.14.1 release?, Updating release version for jiras resolved in 1.0.0 .
, This issue has been fixed in Apache Hive 1.0.0. If there is any issue with the fix, please open a new jira to address it.
]