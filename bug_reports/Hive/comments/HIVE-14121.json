[[~wzheng] have you seen this one?, I got a similar error when running some queries (e.g. query17) of a large (10TB) TPC-DS dataset in parquet format on HDFS without setting hive.auto.convert.join.noconditionaltask.size, the root line is ReduceRecordSource.pushRecord instead of MapRecordSource.processRow. after setting hive.auto.convert.join.noconditionaltask.size to 300MB, some of the failed queries passed, but few of them (e.g. query88) still failed with the same Null Pointer exception.

Vertex failed, vertexName=Reducer 3, vertexId=vertex_1466060732175_0149_1_09, diagnostics=[Task failed, taskId=task_1466060732175_0149_1_09_000174, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1466060732175_0149_1_09_000174_0:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {"key":{"reducesinkkey0":1432165,"reducesinkkey1":282176},"value":{"_col0":282176,"_col2":214,"_col4":21,"_col5":2451624,"_col7":19,"_col8":2451676}}
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:198)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:160)
at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:355)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:72)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:60)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:60)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:36)
at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {"key":{"reducesinkkey0":1432165,"reducesinkkey1":282176},"value":{"_col0":282176,"_col2":214,"_col4":21,"_col5":2451624,"_col7":19,"_col8":2451676}}
at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:288)
at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:263)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:172)
... 14 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {"key":{"reducesinkkey0":1432165,"reducesinkkey1":282176},"value":{"_col0":282176,"_col2":214,"_col4":21,"_col5":2451624,"_col7":19,"_col8":2451676}}
at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:356)
at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:278)
... 16 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unexpected exception from MapJoinOperator : Unexpected exception from MapJoinOperator : null
at org.apache.hadoop.hive.ql.exec.MapJoinOperator.process(MapJoinOperator.java:454)
at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:878)
at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.internalForward(CommonJoinOperator.java:647)
at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genAllOneUniqueJoinObject(CommonJoinOperator.java:679)
at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:757)
at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.joinObject(CommonMergeJoinOperator.java:316)
at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.joinOneGroup(CommonMergeJoinOperator.java:279)
at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.joinOneGroup(CommonMergeJoinOperator.java:272)
at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.process(CommonMergeJoinOperator.java:258)
at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:347)
... 17 more
Caused by: java.lang.NullPointerException
at org.apache.hadoop.hive.ql.exec.persistence.HybridHashTableContainer$ReusableRowContainer.setFromOutput(HybridHashTableContainer.java:922)
at org.apache.hadoop.hive.ql.exec.persistence.HybridHashTableContainer$GetAdaptor.setFromRow(HybridHashTableContainer.java:802)
at org.apache.hadoop.hive.ql.exec.MapJoinOperator.setMapJoinKey(MapJoinOperator.java:339)
at org.apache.hadoop.hive.ql.exec.MapJoinOperator.process(MapJoinOperator.java:390), [~sershe] It's supposed to be fixed by HIVE-13809. Unfortunately it didn't make the 2.1.0 release (although the release note included it, it's not there: https://github.com/apache/hive/commits/release-2.1.0-rc3) [~jcamachorodriguez] Can you verify?, Current workaround is to turn off hybrid grace hash join:
set hive.mapjoin.hybridgrace.hashtable=false

The fix should go in for 2.1.1., Apparently fix version was set to 2.1.0 when it should have been set to 2.1.1. I changed it accordingly, as it is not part of 2.1.0 (btw, it is not in the RELEASE_NOTES.txt)., Thanks all!. It worked in the workaround. And, it was also confirmed to work with patch. I'll close this ticket.]