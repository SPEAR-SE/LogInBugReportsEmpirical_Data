[I've tried with trunk and hive-0.12.0 and all worked as expected (1 for distinct all). Could it be possible that there is a white space or something in 'tommy'?, I am consistently able to reproduce in 0.10.0 and 0.9.0... I checked the explain of the multi insert too.., I've seen hive-0.12.0 is included in affects versions, which might be removed. Anyway, It seemingly fixed in later versions. Could you try that?, I have removed affected versions. 0.11.0 and 0.12.0. Do you mind attaching the explain for the multi-insert in 0.12.0. I will compare it with what I get. , sure
{noformat}
hive> explain select a.dt,count(distinct a.user) as AllDist,count(distinct case when a.type = 111 then a.user else null end) as Type111User,
    > count(distinct case when a.type != 111 then a.user else null end) as Type123User from Table_A a
    > group by a.dt
    > ;
OK
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME Table_A) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) dt)) (TOK_SELEXPR (TOK_FUNCTIONDI count (. (TOK_TABLE_OR_COL a) user)) AllDist) (TOK_SELEXPR (TOK_FUNCTIONDI count (TOK_FUNCTION when (= (. (TOK_TABLE_OR_COL a) type) 111) (. (TOK_TABLE_OR_COL a) user) TOK_NULL)) Type111User) (TOK_SELEXPR (TOK_FUNCTIONDI count (TOK_FUNCTION when (!= (. (TOK_TABLE_OR_COL a) type) 111) (. (TOK_TABLE_OR_COL a) user) TOK_NULL)) Type123User)) (TOK_GROUPBY (. (TOK_TABLE_OR_COL a) dt))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            Select Operator
              expressions:
                    expr: dt
                    type: string
                    expr: user
                    type: string
                    expr: type
                    type: int
              outputColumnNames: dt, user, type
              Group By Operator
                aggregations:
                      expr: count(DISTINCT user)
                      expr: count(DISTINCT CASE WHEN ((type = 111)) THEN (user) ELSE (null) END)
                      expr: count(DISTINCT CASE WHEN ((type <> 111)) THEN (user) ELSE (null) END)
                bucketGroup: false
                keys:
                      expr: dt
                      type: string
                      expr: user
                      type: string
                      expr: CASE WHEN ((type = 111)) THEN (user) ELSE (null) END
                      type: string
                      expr: CASE WHEN ((type <> 111)) THEN (user) ELSE (null) END
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                        expr: _col2
                        type: string
                        expr: _col3
                        type: string
                  sort order: ++++
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
                  value expressions:
                        expr: _col4
                        type: bigint
                        expr: _col5
                        type: bigint
                        expr: _col6
                        type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(DISTINCT KEY._col1:0._col0)
                expr: count(DISTINCT KEY._col1:1._col0)
                expr: count(DISTINCT KEY._col1:2._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2, _col3
          Select Operator
            expressions:
                  expr: _col0
                  type: string
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: bigint
                  expr: _col3
                  type: bigint
            outputColumnNames: _col0, _col1, _col2, _col3
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
{noformat}, Ah, I've ran test wrong. I'll try it again., I got it. Ill check this., This is the explain for Hive 0.10.0. My guess is all higher versions might also have same issue. , Looks like "hive.optimize.multigroupby.common.distincts" optimization is not valid. I cannot imagine how to collect values of each distinct columns into single group when there are multiple distinct columns in the query. I think the optimization should be disabled.

[~pavangm] set hive.optimize.multigroupby.common.distincts=false might be helpful., [~navis] I tried with the setting you mentioned. The issue still exists. , [~pavangm] I've confirmed it's working with the option disabled on trunk. But it's hard to tell exactly the issue number fixed that., [~navis] Can you attach the hive logs with option enabled and then disabled. Also, make sure you are running with atleast two inserts together to simulate multi-insert as mentioned in the ticket. 
Then just mark it as Resolved if you are sure it does not occur in higher versions. 
, The query is same with the one you've mentioned in issue description. Attached query plan and result with the option enabled/disabled., Option enabled/disabled did not make any difference in query plan in version 0.10.0. May be this got resolved in 0.12.0 implicitly for some change made. , [~pavangm] I've found It's optionized in hive-0.12.0 (HIVE-3728), which cannot be disabled pre-0.12.0 versions. Sorry. , [~pavangm] Can we close this?, [~navis] This is still a problem for many who are using pre-hive-0.12.0. But, as you mentioned there is already a work around available for 0.12.0, You can close this. , I think this is still a problem. This conf is on by default on trunk. So, if you run the test query as above, you will get wrong results. , Just for the record:  HIVE-3728 introduced hive.optimize.multigroupby.common.distincts in release 0.11.0, not 0.12.0.  (The JIRA says so and branch-0.11 confirms it.), [~leftylev] You are right, as always. I've confirmed that it's included in hive-0.11.0. 
[~ashutoshc] I cannot sure but the optimization seemed not valid. If this will not be fixed till next release process, we should disabled it by default., [~ashutoshc] Could we remove this optimization? I'm sure this is not valid from the start., I will take a look for its validity. 
In the meanwhile, lets turn this off by default, until we decide whether it has any use case at all., Patch to disable this optimization by default., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12696235/HIVE-6099.patch

{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 7422 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8_map
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_covar_pop
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union17
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8_map
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8_map_skew
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8_noskew
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_insert_common_distinct
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2639/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2639/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2639/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 17 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12696235 - PreCommit-HIVE-TRUNK-Build, Funnily, plan generated with optimization off looks better, with one less stage. Not sure how this optimization is suppose to improve query performance. As you, I am also not sure how spraying by distinct keys first and than doing grouping in subsequent stages really works. Further, given that it has bugs which are unfixed for so long, I agree we should remove this optimization.
I will update the patch with removal of this optimization., https://reviews.apache.org/r/30602/diff/#, [~ashutoshc] Good! I've leaved some comments in rb. I think we are purging the most complicated parts in GroupByOperator., Updated patch per Navis suggestions. I am not sure firstRowInGroup/startGroup can be removed yet. Do you think they are safe for removal?, It's introduced to generated distinct keys for this optimization and seemed not used by other codes. The optimization seemed working with single common distinct column, but I think the overhead for it overrides the good part (and hard to read). But.. let's see the result of test., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12696543/HIVE-6099.3.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 7475 tests executed
*Failed tests:*
{noformat}
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2656/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2656/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2656/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12696543 - PreCommit-HIVE-TRUNK-Build, Updated patch incorporating RB comments., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12696678/HIVE-6099.4.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 7476 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testMetastoreProxyUser
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2675/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2675/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2675/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12696678 - PreCommit-HIVE-TRUNK-Build, Failures are unrelated to patch. , +1, Committed to trunk., Doc note:  This removes configuration parameter *hive.optimize.multigroupby.common.distincts* from HiveConf.java in version 1.2.0.  It was introduced in 0.11.0 by HIVE-3728 and hasn't been documented yet.  The Configuration Properties wikidoc should specify that it exists in versions 0.11.0 through 1.1.0, with links to HIVE-3728 and this issue (HIVE-6099).

* [Configuration Properties -- Query and DDL Execution | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-QueryandDDLExecution], This issue has been fixed and released as part of the 1.2.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.]