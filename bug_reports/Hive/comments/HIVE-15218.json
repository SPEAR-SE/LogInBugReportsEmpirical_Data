[[~gopalv] found that HIVE-8769 changed statistics object from being transient to non-transient. , [~gopalv] can you please review this change?, LGTM +1 - tests pending.

The Statistics object doesn't seem to be referred on the execution side at all.

The question remains about why the {{removeField(kryo, AbstractOperatorDesc.class, "statistics");}} doesn't remove this field when serializing in the first place., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12839101/HIVE-15218.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 189 failed/errored test(s), 10694 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_9] (batchId=33)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join0] (batchId=78)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join31] (batchId=40)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join_stats] (batchId=43)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join_without_localtask] (batchId=1)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_14] (batchId=11)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_15] (batchId=11)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_1] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=43)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_3] (batchId=1)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_4] (batchId=56)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_5] (batchId=78)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_7] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[bucketsortoptimize_insert_4] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[bucketsortoptimize_insert_5] (batchId=52)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_cross_product_check_2] (batchId=18)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[correlationoptimizer5] (batchId=63)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cross_product_check_2] (batchId=79)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[identity_project_remove_skip] (batchId=44)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join29] (batchId=39)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[runtime_skewjoin_mapjoin_spark] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[skewjoin] (batchId=21)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[skewjoin_onesideskew] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[smb_mapjoin_25] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subq_where_serialization] (batchId=77)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_in_having] (batchId=52)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_multiinsert] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[tez_join_hash] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union22] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_mapjoin_reduce] (batchId=70)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[dynamic_partition_pruning_2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[except_distinct] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[explainuser_2] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[intersect_all] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[intersect_distinct] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[intersect_merge] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_nullscan] (batchId=131)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_union_dynamic_partition] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[auto_sortmerge_join_10] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cluster] (batchId=141)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[column_access_stats] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[constprog_dpp] (batchId=138)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_partition_pruning] (batchId=141)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[hybridgrace_hashjoin_2] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mergejoin] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multi_insert] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ppd_union_view] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[selectDistinctStar] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[temp_table] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_join_hash] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union2] (batchId=136)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union_group_by] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union_multiinsert] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union2] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union3] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union4] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union5] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union6] (batchId=141)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union7] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union8] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union9] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_remove_26] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_stats] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_top_level] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_null_projection] (batchId=137)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_dynamic_partition_pruning] (batchId=141)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_1] (batchId=90)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=91)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=90)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[hybridgrace_hashjoin_2] (batchId=90)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query54] (batchId=219)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query66] (batchId=219)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query71] (batchId=219)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query75] (batchId=219)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query76] (batchId=219)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query80] (batchId=219)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_join27] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_10] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[column_access_stats] (batchId=116)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[dynamic_rdd_cache] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_sort_1_23] (batchId=126)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_sort_skew_1_23] (batchId=96)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join34] (batchId=122)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join35] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[load_dyn_part13] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[load_dyn_part14] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[multi_insert] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[multi_insert_move_tasks_share_dependencies] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[multi_join_union] (batchId=92)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[optimize_nullscan] (batchId=126)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[runtime_skewjoin_mapjoin_spark] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin] (batchId=102)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin_union_remove_1] (batchId=128)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin_union_remove_2] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt10] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt11] (batchId=122)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt12] (batchId=96)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt14] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt15] (batchId=97)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt16] (batchId=98)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt17] (batchId=128)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt19] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt1] (batchId=126)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt20] (batchId=124)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt2] (batchId=94)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt3] (batchId=102)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt4] (batchId=103)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt5] (batchId=103)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt6] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt7] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt8] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt9] (batchId=102)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[stats1] (batchId=98)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[temp_table] (batchId=129)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union10] (batchId=97)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union11] (batchId=120)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union12] (batchId=94)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union13] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union14] (batchId=96)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union15] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union16] (batchId=129)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union17] (batchId=122)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union18] (batchId=99)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union19] (batchId=117)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union20] (batchId=94)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union21] (batchId=92)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union22] (batchId=98)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union23] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=117)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union25] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union26] (batchId=120)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union27] (batchId=94)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union28] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union29] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union2] (batchId=113)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union30] (batchId=125)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union31] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union32] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union33] (batchId=103)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union34] (batchId=97)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union3] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union4] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union5] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union6] (batchId=105)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union7] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union8] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union9] (batchId=109)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_lateralview] (batchId=103)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_ppr] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_10] (batchId=102)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_11] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_12] (batchId=110)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_13] (batchId=129)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_14] (batchId=97)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_15] (batchId=128)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_16] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_17] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_18] (batchId=95)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_19] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_1] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_20] (batchId=128)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_21] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_22] (batchId=125)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_23] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_24] (batchId=98)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_25] (batchId=129)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_2] (batchId=109)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_3] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_4] (batchId=96)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_5] (batchId=117)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_6] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_6_subq] (batchId=108)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_7] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_8] (batchId=113)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_9] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_top_level] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_view] (batchId=98)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2145/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2145/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2145/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 189 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12839101 - PreCommit-HIVE-Build, This patch adds kryo tracing via hive config.
Also for cloning operator tree statistics and colExprMap fields get retained whereas for serializing/deserializing plan these fields gets removed. , [~gopalv] can you please review the new changes?, Does the removeFields persist when you return the Kryo object to the pool?, Good catch. It persists so a clone op tree after serialize plan will still lose statistics. 

I was trying to fix but even remove field is not working. Looks like we are hitting this issue https://github.com/EsotericSoftware/kryo/issues/285

I will see if there are any workarounds.. , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2182/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2182/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2182/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2016-11-18 06:39:57.945
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-2182/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2016-11-18 06:39:57.947
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2016-11-18 06:39:58.939
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: No such file or directory
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12839478 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2183/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2183/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2183/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2016-11-18 06:40:46.623
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-2183/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2016-11-18 06:40:46.625
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2016-11-18 06:40:47.509
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: No such file or directory
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12839478 - PreCommit-HIVE-Build, Review of configuration parameter:  Please change "kryo" to "Kryo" in the description.

{code}
+    HIVE_KRYO_TRACE_ENABLE("hive.kryo.trace.enable", false, "Enable kryo serialization trace. Trace log messages will" +
+      " go to System.out by default."),
{code}, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4382/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4382/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4382/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-03-26 03:10:37.312
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4382/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-03-26 03:10:37.314
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at b4a8af9 HIVE-16274: Support tuning of NDV of columns using lower/upper bounds (Pengcheng Xiong, reviewed by Jason Dere)
+ git clean -f -d
Removing ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java.orig
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at b4a8af9 HIVE-16274: Support tuning of NDV of columns using lower/upper bounds (Pengcheng Xiong, reviewed by Jason Dere)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-03-26 03:10:38.391
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: No such file or directory
error: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: No such file or directory
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12839478 - PreCommit-HIVE-Build, Is there a reason this was never committed?, Initially thought this was the issue but later figured out that this only happened when there was a stranded llap daemon which was not killed by yarn. After proper cleanup of all llap daemons this issue never occured., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/9574/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/9574/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-9574/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2018-03-09 17:36:59.309
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-9574/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2018-03-09 17:36:59.312
+ cd apache-github-source-source
+ git fetch origin
From https://github.com/apache/hive
   73ccc44..34eb9ed  master     -> origin/master
+ git reset --hard HEAD
HEAD is now at 73ccc44 HIVE-18889 : update all parts of Hive to use the same Guava version (Sergey Shelukhin, reviewed by Ashutosh Chauhan)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is behind 'origin/master' by 1 commit, and can be fast-forwarded.
  (use "git pull" to update your local branch)
+ git reset --hard origin/master
HEAD is now at 34eb9ed HIVE-18918 - Bad error message in CompactorMR.lanuchCompactionJob() (Eugene Koifman, reviewed by Jason Dere)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2018-03-09 17:37:00.900
+ rm -rf ../yetus_PreCommit-HIVE-Build-9574
+ mkdir ../yetus_PreCommit-HIVE-Build-9574
+ git gc
+ cp -R . ../yetus_PreCommit-HIVE-Build-9574
+ mkdir /data/hiveptest/logs/PreCommit-HIVE-Build-9574/yetus
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: does not exist in index
error: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: does not exist in index
error: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: does not exist in index
error: patch failed: common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:1167
Falling back to three-way merge...
Applied patch to 'common/src/java/org/apache/hadoop/hive/conf/HiveConf.java' with conflicts.
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/Driver.java:291
Falling back to three-way merge...
Applied patch to 'ql/src/java/org/apache/hadoop/hive/ql/Driver.java' with conflicts.
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java:1266
Falling back to three-way merge...
Applied patch to 'ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java' with conflicts.
Going to apply patch with: git apply -p1
error: patch failed: common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:1167
Falling back to three-way merge...
Applied patch to 'common/src/java/org/apache/hadoop/hive/conf/HiveConf.java' with conflicts.
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/Driver.java:291
Falling back to three-way merge...
Applied patch to 'ql/src/java/org/apache/hadoop/hive/ql/Driver.java' with conflicts.
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java:1266
Falling back to three-way merge...
Applied patch to 'ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java' with conflicts.
U common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
U ql/src/java/org/apache/hadoop/hive/ql/Driver.java
U ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12839478 - PreCommit-HIVE-Build]