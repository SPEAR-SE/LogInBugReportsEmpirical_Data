[For now, I'm disabling the setting by default and adding safety for the common case.
 [~ashutoshc] [~pxiong] can you take a look? I filed HIVE-15398 to follow up, will update the descriptions in both shortly, Another solution could be OneNullRowIF keeps instance of original IF within it and uses it at runtime to determine whether there are 0 or more rows., See follow-up.
In that case you might as well just add the limit to original table scan and not use NullScan, cause it's no longer a nullscan.
That will also require running a task, split generation etc., so it may be involved., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12842449/HIVE-15397.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 16 failed/errored test(s), 10773 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[limit_partition_metadataonly] (batchId=57)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partInit] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_date2] (batchId=16)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_timestamp2] (batchId=29)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample2] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample4] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample6] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample7] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample9] (batchId=38)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[metadataonly1] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[stats_based_fetch_decision] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver (batchId=159)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_4] (batchId=92)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[limit_partition_metadataonly] (batchId=119)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2507/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2507/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2507/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12842449 - PreCommit-HIVE-Build, Typo in parameter description:  "Whether to elimiate scans" --> eliminate., Interesting q file changes.. according to our take on 1=1 group by 1=1 they are correct.
E.g. table has 3 partitions, part=a, part=b, and part=c. Only a and c have data.
select distinct part from t
used to return "a, b, c". However, there are no rows in the table that actually have value b. So, the result has changed to "a, c".
[~ashutoshc] [~jcamachorodriguez] would you say it's the correct change and previous result is incorrect?
Same for max(partcol) from an empty table - should it be null? Cause there are no rows in the table to derive max from, similar how there are no rows in gby 1=1 to group by., Updated the out files, expanded one test to run with and without metadataonly enabled to make sure results are consistent, fixed the typo., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12842617/HIVE-15397.01.patch

{color:green}SUCCESS:{color} +1 due to 6 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 10793 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=44)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample2] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample4] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample6] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample7] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample9] (batchId=38)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[metadataonly1] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[stats_based_fetch_decision] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=91)
org.apache.hive.jdbc.TestJdbcDriver2.testSelectExecAsync2 (batchId=213)
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=215)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2529/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2529/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2529/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12842617 - PreCommit-HIVE-Build, This is interesting, because Hive allows you to create partitions without any data. That will result in a partitioning column having a value. So, shall we assume that table has row(s) with partitioning column taking supplied value and other columns being null. I think no. This was the case earlier and I think its wrong. I think behavior we are getting now is correct. If partition exists but its empty, we should consider partition has 0 rows, thus value for partitioning column should not matter during query evaluation. So, max(partCol) from empty_table should be null even when there is a partition which has partcol = 1.
So, I think behavior we are getting after patch is correct and desired. , Btw, I am too lazy to rerun it again now, but I think the current master is inconsistent, cause the out file changes that removed the rows on the first run removed the rows because I disabled metadata-only by default. So, non-optimized path on master doesn't return such rows, but metadata-only does return them. After the patch, neither does., Now all I need is a +1 :P, +1 for the typo fix, but that won't get you far., [~ashutoshc] ping?, +1, Committed to master. Thanks for the review, Doc note:  This changes the default value of *hive.optimize.metadataonly* and gives it a description.  It was created in 0.8.0 by HIVE-1003 and isn't documented in the wiki yet.  Note that the wiki description will need editing to cover the earlier default value of true.

* [Configuration Properties -- Query and DDL Execution | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-QueryandDDLExecution]

Added a TODOC2.2 label.]