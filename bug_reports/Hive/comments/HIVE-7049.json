[patch uploaded, RB at: https://reviews.apache.org/r/21353/, 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12644526/HIVE-7049.1.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/188/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/188/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12644526, Thanks for bringing this up.  I'm wondering if the situation you described is an issue of incompatibility of schemas rather than a bug. Record schema says that a field is union (nullable), while file schema says that the file is not a union, which seems suggesting that the data is not compatible with the schema. While we may need to provided a better error message for this, ignoring the file schema (by passing NULL down) will very likely break decimal support, which needs the file schema to read data correctly., Thank [~xuefuz] for the comments.

I believe it is a valid Avro schema evolution.
Please see the following comments copied from  the link:
http://avro.apache.org/docs/1.7.6/spec.html#Schema+Resolution
{noformat}
* if reader's is a union, but writer's is not
The first schema in the reader's union that matches the writer's schema is recursively resolved against it. If none match, an error is signalled.
* if writer's is a union, but reader's is not
If the reader's schema matches the selected writer's schema, it is recursively resolved against it. If they do not match, an error is signalled.
{noformat}

Moreover, i tested a similar scenarios using pure avro code where i wrote using schema "string" and read it using ["null","string"]., [~kamrul] If Hive can support the AVRO schema resolutions you mentioned, I don't see any obstacles. However, the fix in your patch seems having a problem with decimal, which may need more deliberation., Thanks @xzhang.
>However, the fix in your patch seems having a problem with decimal, which may need more deliberation.

What is the (potential) problem in decimal?
Any proposal what to do to address the decimal problem?

, [~xuefuz] : can you please help me to understand the problem mentioned in the previous comment?
, It seems that your patch tries to fix the issue by ignoring the file schema ( passing NULL down). File schema is needed to read decimal data correctly. Thus, we might need to fix in a different way., Null is passed only if record schema is null but file schema is not null.
Do you see any use case for decimal too?

>Thus, we might need to fix in a different way.

Do you want me to fix it differently? or you are looking to address this for decimal differently?

, {code}
+    if (AvroSerdeUtils.isNullableType(recordSchema)) {
+      Schema tmpFileSchema = fileSchema;
+      if (tmpFileSchema == null || !AvroSerdeUtils.isNullableType(tmpFileSchema)) {
+	tmpFileSchema = null;
+      }
+      return deserializeNullableUnion(datum, tmpFileSchema, recordSchema, columnType);
     }
{code}

If fileSchema is not null, but AvroSerdeUtils.isNullableType(tmpFileSchema) returns false, then tmpFileSchema = null. So you pass null as fileSchema in  deserializeNullableUnion(datum, tmpFileSchema, recordSchema, columnType).  This doesn't seem right.
, I'm seeing a similar issue but with "long" datatype. 

Hive version: 0.13.1

Here is the error:
{code}
exception java.io.IOException:org.apache.avro.AvroRuntimeException: Not a union: "long"
{code}

Here is the error from Log:
{code}
2014-09-10 23:45:05,679 ERROR CliDriver (SessionState.java:printError(545)) - Failed with exception java.io.IOException:org.apache.avro.AvroRuntimeException: Not a union: "long"
java.io.IOException: org.apache.avro.AvroRuntimeException: Not a union: "long"
        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:636)
        at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:534)
        at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:137)
        at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1519)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:285)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:220)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:423)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:792)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:686)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:625)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: org.apache.avro.AvroRuntimeException: Not a union: "long"
        at org.apache.avro.Schema.getTypes(Schema.java:266)
        at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.deserializeNullableUnion(AvroDeserializer.java:269)
        at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.worker(AvroDeserializer.java:200)
        at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.workerBase(AvroDeserializer.java:188)
        at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.deserialize(AvroDeserializer.java:174)
        at org.apache.hadoop.hive.serde2.avro.AvroSerDe.deserialize(AvroSerDe.java:99)
        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:620)
{code}
, Seems like we can get away with the following patch (confirm the fileSchema AKA writer's schema is actually a union type before trying to find the type that the reader schema expects).  If not, just use the schema as is (it should be promoted to a union by Avro).

This worked for me in local testing.

{noformat}
diff --git a/src/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java b/src/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
index ce933ff..032761c 100644
--- a/src/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
+++ b/src/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
@@ -265,9 +265,12 @@ private Object deserializeNullableUnion(Object datum, Schema fileSchema, Schema
     if(schema.getType().equals(Schema.Type.NULL)) {
       return null;
     }
+    Schema writerSchema = fileSchema;
+    if (writerSchema != null && writerSchema.getType().equals(Schema.Type.UNION)) {
+      writerSchema = writerSchema.getTypes().get(tag);  
+    }
 
-    return worker(datum, fileSchema == null ? null : fileSchema.getTypes().get(tag), schema,
-        SchemaToTypeInfo.generateTypeInfo(schema));
+    return worker(datum, writerSchema, schema, SchemaToTypeInfo.generateTypeInfo(schema));
 
   }
{noformat}, Hit the same issue and here is the reproducible steps:
{code}
CREATE TABLE Statistics10Min 
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe' 
STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat' 
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat' 
LOCATION '/user/daijy/data/Statistics10Min/' 
TBLPROPERTIES ('avro.schema.url'='/user/daijy/Statistics10Min/Statistics10Min.avsc');
{code}
select * from Statistics10Min fail with the message:
{code}
Failed with exception java.io.IOException:org.apache.avro.AvroRuntimeException: Not a record: ["null",{"type":"record","name":"Statistic","namespace":"SHARP","fields":[{"name":"WindFarm","type":["null","string"]},{"name":"WTG","type":["null","string"]},{"name":"LocalTS","type":["null","string"]},{"name":"TS","type":["null","string"]},{"name":"WindSpeedAvg","type":"string"},{"name":"WindSpeedMin","type":"string"},{"name":"WindSpeedMax","type":"string"},{"name":"WindSpeedStdDev","type":"string"},{"name":"ActPowAvg","type":"string"},{"name":"ActPowMin","type":"string"},{"name":"ActPowMax","type":"string"},{"name":"ActPowStdDev","type":"string"},{"name":"ReactPowAvg","type":"string"},{"name":"ReactPowMin","type":"string"},{"name":"ReactPowMax","type":"string"},{"name":"ReactPowStdDev","type":"string"},{"name":"GenSpeedAvg","type":"string"},{"name":"GenSpeedMin","type":"string"},{"name":"GenSpeedMax","type":"string"},{"name":"GenSpeedStdDev","type":"string"},{"name":"RotSpeedAvg","type":"string"},{"name":"RotSpeedMin","type":"string"},{"name":"RotSpeedMax","type":"string"},{"name":"RotSpeedStdDev","type":"string"},{"name":"YawDirAvg","type":"string"},{"name":"YawDirMin","type":"string"},{"name":"YawDirMax","type":"string"},{"name":"YawDirStdDev","type":"string"},{"name":"VibTowAvg","type":"string"},{"name":"VibTowMin","type":"string"},{"name":"VibTowMax","type":"string"},{"name":"VibTowStdDev","type":"string"},{"name":"PitchAvg","type":"string"},{"name":"PitchMin","type":"string"},{"name":"PitchMax","type":"string"},{"name":"PitchRateMin","type":"string"},{"name":"PitchRateMax","type":"string"},{"name":"PitchRateStdDev","type":"string"},{"name":"GridVoltAvg","type":"int"},{"name":"GridVoltMin","type":"int"},{"name":"GridVoltMax","type":"int"},{"name":"EnvTempAvg","type":"string"},{"name":"EnvTempMin","type":"string"},{"name":"EnvTempMax","type":"string"},{"name":"GbxTempAvg","type":"string"},{"name":"GbxTempMin","type":"string"},{"name":"GbxTempMax","type":"string"},{"name":"GenAccMin","type":"string"},{"name":"GenAccMax","type":"string"},{"name":"VibratAvg","type":"string"},{"name":"VibratMax","type":"string"},{"name":"GenU1TempAvg","type":"string"},{"name":"GenU1TempMin","type":"string"},{"name":"GenU1TempMax","type":"string"},{"name":"RotorSideLTempAvg","type":"string"},{"name":"RotorSideLTempMin","type":"string"},{"name":"RotorSideLTempMax","type":"string"},{"name":"WindBin","type":"int"},{"name":"FreqMean","type":"string"}]}]
{code}
Stack:
{code}
        at org.apache.avro.Schema.getField(Schema.java:184)
        at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.workerBase(AvroDeserializer.java:191)
        at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.deserialize(AvroDeserializer.java:178)
        at org.apache.hadoop.hive.serde2.avro.AvroSerDe.deserialize(AvroSerDe.java:199)
        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:488)
{code}

Note this is broken by HIVE-5823.

Attach HIVE-7049.2.patch. [~xuefuz], can you check if the new patch work with decimal?, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12708290/HIVE-7049.2.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 8693 tests executed
*Failed tests:*
{noformat}
TestMinimrCliDriver-smb_mapjoin_8.q - did not produce a TEST-*.xml file
org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testRevokeTimedOutWorkers
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3213/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3213/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3213/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12708290 - PreCommit-HIVE-TRUNK-Build, Daniel's approach of extracting actual type from a nullable type looks ok to me.
+1, Tests passed locally. Committed to trunk. Thanks [~daijy] and [~ashutoshc]!]