[While Hive is using similar precision/scale rules as SQL Server for arithmetic operations (https://msdn.microsoft.com/en-us/library/ms190476.aspx), things seem to be breaking down once we hit the max precision of 38. Looks like this sheds a bit of light on how SQL Server handles things in that case: https://blogs.msdn.microsoft.com/sqlprogrammability/2006/03/29/multiplication-and-division-with-numerics - basically it gives preference to the integer portion rather than the scale (Hive does the opposite), and setting a minimum scale of 6.

cc [~xuefuz], There are more than a couple of JIRAs on this topic. I think it can be argued both ways regarding which (int part vs dec part) to favor. As pointed by the blog post, user needs to quality the type matching the actually data. When not possible, use double/float instead.

What is missing in Hive is a mode in which error is thrown instead of null, but that's not decimal type specific., Yes the user ideally should qualify the type, but they often don't. And with the way this works now decimal multiplication is pretty much unusable without casts.
The precision/scale rules for division look like they have been changed because of similar issues (/HIVE-5866). We could try to match what was done there in multiplication, but I think it would be better to try to emulate the SQL Server behavior given that we were using their precision/scale rules
, I dont' think this can be made bullet proof. I can always construct an example that shows a rule that fails to accommodate., It cannot be bullet proof - even the Msft blogpost admits this. However I do think that we can do a little better here than the existing behavior, which punts multiplication of any value over 100., Initial patch. Let's see what changes in the golden files., Looks like precommit tests never ran - re-uploading patch., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12842017/HIVE-15331.2.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 16 failed/errored test(s), 10775 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=44)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[decimal_precision] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[decimal_udf] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample2] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample4] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample6] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample7] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample9] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_decimal_expressions] (batchId=48)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_decimal_precision] (batchId=45)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[stats_based_fetch_decision] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_decimal_expressions] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_decimal_precision] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_decimal_udf] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=92)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2450/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2450/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2450/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12842017 - PreCommit-HIVE-Build, Updating golden files., RB at https://reviews.apache.org/r/54505/, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12842239/HIVE-15331.3.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 10782 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample2] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample4] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample6] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample7] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample9] (batchId=38)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=134)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[stats_based_fetch_decision] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=92)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2481/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2481/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2481/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12842239 - PreCommit-HIVE-Build, I think this is ready for review now., [~sershe] can you review?, Looks good; it seems like it reduces precision even in cases where it's not needed though... is that intended? See out file changes, where last few (non-zero) digits of the result are rounded away, Which file in particular? These are all cases where the resulting precision/scale exceeds 38 - for example decimal_precision.q.out, the operation is decimal(20,10) * decimal(20,10), the precision/scale (assuming unlimited precision/scale) would be decimal(41,20), however we're already at the Hive limit of 38.
So this is where the updated logic would kick in terms of making the precision/scale fit within 38 digits., Decimal_precision:
{noformat}
-1234.5678901235	1524157.87532399036884525225
+1234.5678901235	1524157.87532399036884525
{noformat}, +1, Committed to master]