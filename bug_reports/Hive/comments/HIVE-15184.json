[Hi [~thejas],

Something like this was in your head?

I think this is quiet elegant solution for the DBTokenStore. Tested this patch, and it handles nicely when I switch on/off the database server. The testing method was the same as in HIVE-15090.

As for the ZooKeeperTokenStore I have yet to find such a nice solution. If you have any idea, I am open to any suggestions :)

Thanks,
Peter, I have tested this with ZooKeeperTokenStore too.
What I have found that the CuratorFramework handles failures in a RetryLoop.callWithRetry, so my guess is that the transient errors are handled by the framework. The specific error which caused HIVE-13090 and HIVE-13075 is handled by their specific patch.

So I think we are good to go if we agree on this solution., The results are not posted automatically, so I have copied them here:

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12838568/HIVE-15184.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10637 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=91)
org.apache.hive.spark.client.TestSparkClient.testJobSubmission (batchId=272)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2089/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2089/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2089/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.
, The errors are not related:
- HIVE-15116 Flaky test: TestMiniLlapLocalCliDriver.testCliDriver join_acid_non_acid
- HIVE-15115 Flaky test: TestMiniLlapLocalCliDriver.testCliDriver union_fast_stats
- HIVE-15084 Flaky test: TestMiniTezCliDriver:explainanalyze_2, 3, 4, 5
- HIVE-15168 Flaky test: TestSparkClient.testJobSubmission (still flaky), [~pvary], could you explain why we are calling runtime.exit() in case of unrecoverable error? It seems like we are saying that the metastore should not work anymore if we are not able to cleanup expired tokens. Seems a little extreme to me.

You mentioned that you tested this with shutting the db down, what would happen if it was a transient connection exception? In our environment, we are seeing this: 
{noformat}
2017-03-28 17:03:26,192 ERROR thrift.TokenStoreDelegationTokenSecretManager (TokenStoreDelegationTokenSecretManager.java:run(331)) - ExpiredTokenRemover thread received unexpected exception. org.apache.hadoop.hive.thrift
.DelegationTokenStore$TokenStoreException: javax.jdo.JDODataStoreException: Communications link failure
{noformat}

It appears that the above is triggered when we somehow end up reusing a "dead" connection (we are still investigating this). Anyway, just wanted to mention that it might be better to reconsider the exit() option., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12838568/HIVE-15184.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10514 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=231)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[comments] (batchId=35)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=153)
org.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure (batchId=172)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4417/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4417/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4417/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12838568 - PreCommit-HIVE-Build, [~sbeeram]: If the thread is stopped, then the TokeStore become a memory leak by accumulating the token objects forever. We will get an OOM error eventually, but after a longer period of time, and at that moment we will have very hard time to identify the original problem which caused this. That is why I think it is better for the long term, to exit immediately.
The {{JDODataStoreException}} is a subclass of {{JDOCanRetryException}}, so after this patch the MetaStore will try to recover., Thanks for the clarification [~pvary]. 

The memory leak would be a concern for MemoryTokenStore right? In case of a persistent store based TokenStore, specifically  in the db case, we'll accumulate rows infinitely, which may  ulltimately degrade the service. Let me know if I am missing something. For the latter (db/zk) case a metric/alert might be an option to consider?

If we do go down path of shutting the service down on failure to cleanup, would be great if we can make the documentation clearer as to why we think its one of the fatal errors. 

For this final point, I don't have a clear answer either yet, but did want to bring it up: is there a better way than using getRuntime.exit()? For ex, if we are writing unit-tests for the token-remover, it could result in the test jvm exiting unexpectedly if for some reason we end up tracing that block, right? Can we signal the main application thread to exit using a different approach?, Thanks [~sbeeram] for taking a look at this! I thought nobody will be interested about this patch :)

The {{TokenStoreDelegationTokenSecretManager}} extends {{DelegationTokenSecretManager}} which in turn extends {{AbstractDelegationTokenSecretManager}}. There is a cache for the currentTokens in {{AbstractDelegationTokenSecretManager}} which we are actively using in TokenStoreDelegationTokenSecretManager.

{code:title="AbstractDelegationTokenSecretManager"}
  /** 
   * Cache of currently valid tokens, mapping from DelegationTokenIdentifier 
   * to DelegationTokenInformation. Protected by this object lock.
   */
  protected final Map<TokenIdent, DelegationTokenInformation> currentTokens 
      = new HashMap<TokenIdent, DelegationTokenInformation>();
{code}

{code:title=TokenStoreDelegationTokenSecretManager}
  protected void rollMasterKeyExt() throws IOException {
    Map<Integer, DelegationKey> keys = reloadKeys();
    int currentKeyId = super.currentId;
    HiveDelegationTokenSupport.rollMasterKey(TokenStoreDelegationTokenSecretManager.this);
    List<DelegationKey> keysAfterRoll = Arrays.asList(getAllKeys());
[..]
  }
{code}
Reading the code above, I think the memory leak would be a concern independently of the actual TokenStore implementation, what do you think?

About the documentation of the exit, here it is what we do:
- Print out the original exception
- Print out that we think the exception is unrecoverable
- Call {{Runtime.getRuntime().exit(-1)}}
What kind of documentation is in your mind? More comments in the code? Better error message? Anything else?

About the way of exit, yeah, it is a little drastic way of exiting the metastore. To be honest I only replicated the solution which was used before https://github.com/apache/hive/blob/40a12d5535d4b81d297b3529bec7f35bf713b251/shims/common/src/main/java/org/apache/hadoop/hive/thrift/TokenStoreDelegationTokenSecretManager.java#L333
I am open for any suggestions :)

Thanks again for the review,
Peter 
, [~thejas] do you want to guide this thru to completion?
I looked at the patch and it mostly makes sense to me. Why is the pom change needed? Doesn't look like the new shims code uses jdo., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12838568/HIVE-15184.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 11200 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_predicate_pushdown] (batchId=232)
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_single_sourced_multi_insert] (batchId=232)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=171)
org.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query14] (batchId=240)
org.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query23] (batchId=240)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/7126/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/7126/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7126/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12838568 - PreCommit-HIVE-Build, IIRC we need the new jars, to be able to check the Exception thrown by JDBC:
{code}
if (cause instanceof JDOCanRetryException) {   <-- for this line only :)
{code}
Thanks for looking at this [~sershe]!

Peter]