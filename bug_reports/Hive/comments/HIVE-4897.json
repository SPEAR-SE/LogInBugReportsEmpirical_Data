[The patch throws the exception if the object already exists in the first try and the same exception will be ignored if it's a retry. 
 , 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12749104/HIVE-4897.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4859/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4859/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4859/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests exited with: ExecutionException: java.util.concurrent.ExecutionException: java.io.IOException: Error writing to /data/hive-ptest/working/scratch/hiveptest-TestErrorMsg.sh
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12749104 - PreCommit-HIVE-TRUNK-Build, Hmm... wouldn't it just retry after the first exception and then ignore the repeated exception on retry?
I think it may need to check that the object in question exists for each API and maybe that it matches the request, on retry.
I am not sure there's good way to add repeatable test for this..., Thanks Sergey. I will take a look if that's the possible., I think the simplest solution is actually to have a 2pc-like protocol, where first the operation will get a token from metastore, and then send this token with a create request. The tokens can be stored in MS memory and are unique (an incrementing number), they are GCed after a long period (an hour?). For generality, each operation with the token could have a client-maintained per-operation sequence number that is not incremented on retries; to start, just one expected operation per token could be permitted - e.g. createSomething. Success (or error) would be recorded with the token in MS.
If a retry comes with the same token(+seq num in case of multiple ops), it would be a no-op, or the original error would be re-thrown.
Comparing objects as originally suggested is both difficult and error-prone, and also not bullet-proof if someone alters the objects in the interim.

This approach is hard to use for ops that return result because it's not clear what result is to be returned, unless the result of original operation is saved, which is a PITA. We can either throw a special exception (succeeded, but cannot return the result), or return the latest state of the object for some ops; create* do not return any result so we are good here.
Tokens can be stored externally for failover, but I don't think this is really necessary for the first draft.

For the first draft in-memory, single-operation tokens with no result option would be easy to implement. Oh yeah, it will be configurable, of course :) On by default. [~thejas] should we do that? Opinions? Related to the timeout issue we were discussing., [~sershe] I haven't been able to work on that yet. Feel free to work on it if you have any idea. , [~sershe] Do you still notice the issue happens? I guess we may not have this issue anymore since before we have unsafe concurrent access to the HMS clients which could lead to this error. 

I went through the code, if some error happens when we create table or partitions, it should roll back properly. Let me know your thoughts. , I've seen this error fairly recently. It happens if the response was not delivered to client due to a network problem (or theoretically due to timing issue with retry it can also happen, if the retry is done after timeout but before the corresponding timeout on the server, and the original request finishes before the retry is processed.
I've also seen it happen when the connection to underlying DB was lost in commitTxn, but the commit still happened (that one time was due to BoneCP connection-closing bug, but it could presumably also happen because of a connection issue). commitTxn fails, but the table is already created. , Yeah. That scenario definitely will cause the issue, but should be rare? What we have seen seems to be caused by unsafe concurrent HMS access, which seems to be fixed. 

Let me investigate further how to completely fix this issue including the cases you mentioned. , I think the simplest path of the approach outlined above will work. I've done similar work in HBase to make increment operation retries idempotent (so the requirements were more stringent and tokens actually needed to survive restarts and failover), and it was pretty manageable. With relaxed requirements like no persistence it should be simpler still.]