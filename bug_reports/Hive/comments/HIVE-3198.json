[Try replacing.. 
{code}
PartitionDesc part = pathToPartitionInfo.get(hsplit.getPath().toString());
{code}
part with.. 
{code}
PartitionDesc part = HiveFileFormatUtils.getPartitionDescFromPathRecursively(pathToPartitionInfo,
                  hsplit.getPath(), IOPrepareCache.get().getPartitionDescMap());
{code}

It seemed to be a bug, IMHO., Hi Navis, sorry it took me so long to get back to you.

Your suggested fix also works & makes the problem go away. Thanks for helping, let me know if there's anything else w.r.t. getting this fixed., I wish I could provide patch for this issue, but I can't reproduce the situation you described., There is no patch for this, Here's a StorageHandler implementation which should help reproduce the bug. When I run it like this:
{code}
$ mkdir /tmp/test; touch /tmp/test/part-00000
hive> add jar test.jar;
hive> create external table test (a string) STORED BY 'TestStorageHandler' location '/tmp/test';
hive> select * from test;
{code}
I see "TESTPROP: hello world", which means that the properties are being setup correctly. But if you do:
{code}
hive> select a from test;
{code}
I see "TESTPROP: null", meaning that properties from configureInputJobProperties() don't get passed to the getRecordReader() call., For non-native tables hive delegates HiveInputFormat to create input splits and record readers. But most of input formats in hadoop replaces directories (which is location of table/partition) to concrete file names in it, which causes not finding appropriate partition desc by simple map access of pathToPartitionInfo.

It can be simply fixed by searching partition in recursive manner which is CombinHiveInputFormat is already doing as commented below. But it seemed to hard to make a proper test case for this case, so I'll just upload the code patch., For the Cassandra handler I coded the properties into the InputSplit to deal with them not being passed on to MR jobs., https://reviews.facebook.net/D4173]