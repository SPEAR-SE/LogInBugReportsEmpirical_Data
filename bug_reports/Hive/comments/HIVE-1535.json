[No negative tests included because hive is using local meta store, and throw exception if the partition does not exist. So there is no problem when running with local meta store., Committed. Thanks Yongqiang, We could test this in TestRemoteHiveMetaStore, right?, It seems some issue with my mailbox, could not able to send mail, so I'm posting here :-

As tested against latest Hive build and Hadoop 20.1.
 
Kindly provide me the query or the list of queries for which this defect was tested against, as I see no test case in it and when I'm running queries assuming which were being run by He Yongqiang while testing the scenarios, I'm not able to re-produce the scenario.
 
I'm ran queries in below sequence :-
 
1 . set hive.exec.drop.ignorenonexistent=false;
 
2 . create table page_test(view INT, userid INT, page_url STRING) PARTITIONED BY(dt STRING, country STRING) STORED AS A TEXTFILE;
 
3 . LOAD DATA LOCAL INPATH '/home/test.txt' OVERWRITE INTO TABLE page_test PARTITION(dt='10-10-2010',country='US');
 
4 . LOAD DATA LOCAL INPATH '/home/test.txt' OVERWRITE INTO TABLE page_test PARTITION(dt='10-12-2010',country='IN');
 
// This query fails during semantic analysis, since it is invalid partition and don't belong to partition spec of page_test.
 
5 . ALTER TABLE page_test DROP PARTITION(invalid='23-02-2010',notexist='UK'); 
and when I turn ON the property hive.exec.drop.ignorenonexistent, hive is silent and OK.
So far good, and no issues.
 
//However there is another case, in which partition is a valid spec but doesn't exists, as I have only [dt='10-10-2010',country='US'] and [dt='10-12-2010',country='IN']
 
6 . ALTER TABLE page_test DROP PARTITION (dt='23-02-2010',country='UK'); 
but it doesn't results in any exception, I'm getting OK response on console.
 
As per this defect  fix, it should actually fail with console error message 
Partition : [{dt='23-02-2010',country='UK'}] does not exist.
 
I may be wrong, or not aware of enough use cases covering the scope of this defect, kindly help me providing some insights., @Mohit: Please file a new JIRA ticket against this issue. Thanks!]