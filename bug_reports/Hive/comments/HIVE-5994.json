[Making it as patch available for precommit tests., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12617962/HIVE-5994.1.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 4762 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_precision
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/591/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/591/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12617962, +1, Test failure is unrelated. HIVE-5995 addresses the test failure., Committed to trunk. Thanks, Prasanth!, Will it affect positive values also?  I am trying to write long  4703275633953830000L and I see some issues while reading back.
When I write 10 rows of same long value and read back , I get value as 112 instead.
When I write 1 or 100 rows of same long value and read back , I get correct value back !  Not sure why ? 

, Hi Puneeth

I don't seem to reproduce your issue. Can you post the exact 10 rows that you are writing?, Hi Prasanth

This is the code I Used to reproduce the issue . 
1. I am using Hive binary from "hive-0.12.0.tar.gz" 
2. I am using a old hadoop version "hadoop-core-1.0.0.jar"   --- http://mvnrepository.com/artifact/org.apache.hadoop/hadoop-core
3. In the below code if  ROWS_TO_TEST is set to 1 or >10 , the problem does not occur.

---------------------------
package hive;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hive.ql.io.orc.CompressionKind;
import org.apache.hadoop.hive.ql.io.orc.OrcFile;
import org.apache.hadoop.hive.ql.io.orc.Reader;
import org.apache.hadoop.hive.ql.io.orc.RecordReader;
import org.apache.hadoop.hive.ql.io.orc.Writer;
import org.apache.hadoop.hive.ql.io.orc.OrcFile.WriterOptions;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;

public class TestLong {

	/**
	 * @param args
	 * @throws IOException 
	 */
	public static void main(String[] args) throws IOException
	{
		int ROWS_TO_TEST =10;
		Path path = new Path("E:/Test/file.orc");
		Configuration conf = new Configuration();
		FileSystem fs = FileSystem.getLocal(conf);
		if(fs.exists(path))
			fs.delete(path,true);
		
		ObjectInspector inspector = ObjectInspectorFactory
				.getReflectionObjectInspector(MyData.class,
						ObjectInspectorFactory.ObjectInspectorOptions.JAVA);

		WriterOptions options = OrcFile.writerOptions(conf)
				.inspector(inspector).compress(CompressionKind.SNAPPY);

		Writer writer = OrcFile.createWriter(path, options);

		for (int i = 0; i < ROWS_TO_TEST; i++) {
			writer.addRow(new MyData());
		}
		writer.close();

		Reader reader = OrcFile.createReader(fs, path);
		RecordReader rows = reader.rows(null);
		Object row = null;
		while (rows.hasNext()) {
			row = rows.next(row);
			System.out.println(row);
		}
	}
	
	
	private static class MyData
	{
		long data = 4703275633953830000L ;
	}
}
-----------
OUTPUT
{112}
{112}
{112}
{112}
{112}
{112}
{112}
{112}
{112}
{112}
, Puneeth,

This issue can happen with large positive values as well. The reason being when the number of repetitions of large number is >3 and <=10 SHORT_REPEAT encoding is used. https://github.com/apache/hive/blob/branch-0.12/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RunLengthIntegerWriterV2.java#L35

This encoding zigzag encodes the repeating value. So in your case when 4703275633953830000L is zigzag encoded, the MSB bit (64th) is set which will be considered as a negative value according to this bug. 

I tested your test case with trunk and it works fine. Applying the patch attached in this JIRA should also work., Hi Prasanth 
I also tested with the path mentioned in https://reviews.apache.org/r/16148/diff/ by merging the code in 0.12 .0 . It solves the issue :-).

Thanks for the help .

]