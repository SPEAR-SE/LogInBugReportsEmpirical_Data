[qtest for the above patch, There are a few approaches in my mind on how to solve this problem.

1. Do not use the current classloader as the parent when creating a new URLClassLoader in {{Utilities.addToClassPath}} method.  In this case, every URLClassLoader constructed will have, as its parent, the SystemClassLoader.  Also as per the {{addToClassPath}} method, every URLClassLoader  will  have all the jar paths from the parent (including the current jar to be registered).

Now looking at the above scenario again class-loader *u2* will have as its parent the system class-loader and will have the jar paths for jars *j1* and *j2* both. Now, when *c1* is instantiated using the classloader *u2*, *u2* will load and define the class *c1* as the parent classloader will not have the jar. Now class *c2* required by *c1* will also be found in *u2* and will be correctly loaded and defined by *u2*.

Note that {{Utilities.removeFromClassPath}} also creates new URLClassloaders without passing the current classloader as their parent.

2. Have a new classloader which extends the URLClassloader and uses the servlet spec to load classes. That is instead of delegating to parent first, it first tries to find the class in its own classpath.

3. Have a new classloader which extends the URLClassloader and which changes the scope of the {{addURL}} method from protected to public. Using this custom classloader we will not have to create fresh-classloaders for every jar being registered. We do have to think about how  delete/remove jars will be implemented.
, Complete patch which implements the first approach outlined, with more elaborate qtest, [~rdsr] Can you post the stack trace you get when bug happens ?, Also, this happens when doing create function or in select query which uses that created function ?, Hi [~ashutoshc]

Here's the complete stacktrace (You can generate this by applying patch HIVE-11878_qtest.patch )

{noformat}
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0
        at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:882)
        at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:149)
        at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:106)
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.getOptimizedAST(CalcitePlanner.java:617)
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:252)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10137)
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:212)
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:240)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:428)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:310)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1150)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1203)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1079)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1069)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:311)
        at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1033)
        at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1007)
        at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:146)
        at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_test_classloader(TestCliDriver.java:130)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:483)
        at junit.framework.TestCase.runTest(TestCase.java:176)
        at junit.framework.TestCase.runBare(TestCase.java:141)
        at junit.framework.TestResult$1.protect(TestResult.java:122)
        at junit.framework.TestResult.runProtected(TestResult.java:142)
        at junit.framework.TestResult.run(TestResult.java:125)
        at junit.framework.TestCase.run(TestCase.java:129)
        at junit.framework.TestSuite.runTest(TestSuite.java:255)
        at junit.framework.TestSuite.run(TestSuite.java:250)
        at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
Caused by: java.lang.ClassNotFoundException: TestClClassA
        at java.net.URLClassLoader$1.run(URLClassLoader.java:372)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:360)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 60 more
{noformat}, In this specific scenario, the exception occurs in the select statement, when the initialize method of the UDF is called which then tries to create an object of the class {{TestClClassA}}, Made the qtest patch (which highlights the problem) consistent (same file names etc.) with the main patch which implements approach 1., [~ashutoshc] Note that {{TestClClassA}} class is present in {{utility.jar}} which is registered after registering the udf jar as shown in the qfile {{test_classloader.q}}, Thanks, [~rdsr] for detailed report and digging into this. I can repro this even with just create function (no need of select) if I add following in TestClUDF1.java 
{code}
 public TestClUDF1 () {
    TestClClassA testClClassA = new TestClClassA();
}

{code}
This generates following stack trace (which is different then above), but essentially same root cause :
{code}
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.hive.ql.exec.Registry.registerGenericUDF(Registry.java:144)
	at org.apache.hadoop.hive.ql.exec.Registry.registerFunction(Registry.java:105)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.registerTemporaryUDF(FunctionRegistry.java:1536)
	at org.apache.hadoop.hive.ql.exec.FunctionTask.createTemporaryFunction(FunctionTask.java:166)
	at org.apache.hadoop.hive.ql.exec.FunctionTask.execute(FunctionTask.java:72)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:89)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1747)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1506)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1263)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1079)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1069)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:311)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1033)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1007)
	at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:146)
	at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_test_classloader(TestCliDriver.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:176)
	at junit.framework.TestCase.runBare(TestCase.java:141)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:129)
	at junit.framework.TestSuite.runTest(TestSuite.java:255)
	at junit.framework.TestSuite.run(TestSuite.java:250)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:129)
	... 39 more
Caused by: java.lang.NoClassDefFoundError: TestClClassA
	at TestClUDF1.<init>(TestClUDF1.java:29)
	... 44 more
Caused by: java.lang.ClassNotFoundException: TestClClassA
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 45 more
{code}

cc: [~vgumashta] [~thejas] [~jdere], Thanks for looking into this. Would there have been any good reason why Hive was originally keeping the old classloader around when resolving classes? One thing I can think of is that since it checks its parent classloader, when it loads a class it will end up using the oldest version of the classloader that is able to load this class.

So with this patch, if we had previously loaded a class with the previous classloader, and now load the class again with the current classloader, would there be any potential effects here? The 2 Class objects would not be considered the same, do we ever compare Class objects? Are there any other behavior differences between classes/objects from different class loaders?

Does this only apply for classes from JARs added using ADD JAR, since approach 1 still has the System class loader as its parent classloader?, bq.  if we had previously loaded a class with the previous classloader, and now load the class again with the current classloader, would there be any potential effects here? 

The two class objects will definitely be different. I'll try to look if we compare class-objects in the code. Some effects that come to mind are 
1. o instanceof c . If c is loaded by a classloader u1 and o is also an object of c, but the object's class was loaded by another classloader u2.
2. casting may not work. (similar reasoning as above)

[~jdere], [~ashutoshc] . I'd also like to get your opinion on approach 3, mentioned above, which is we do not create new classloaders for every jar, but add jars to the same classloader using the {{addURL}} method. We basically extend the URLClassLoader and change scope of the method addURL from protected to public. This can side step the potential problems that we are discussing here.  As for deleting jars in {{org.apache.hadoop.hive.ql.exec.Utilities#removeFromClassPath}}, it can be exactly as before, except that it will not create an instance of URLClassloader but a subclass of it (with scope of addURL changed) and set that as the currentThreadContext classloader  and the Hadoop Configuration classloader.

One way to think about approach 3 is that it is exactly like what is currently being done, except that we register all the jars at once.  I haven't implemented approach 3 yet, wanted to get some opinion on it before I proceeded further., Implemented approach 3 outlined in the ticket, RB for approach 3: https://reviews.apache.org/r/38663/, [~jdere], [~ashutoshc], I'd love to hear your thoughts on this., Hi Folks,
   I've implemented Approach 3 outlined above. Some points I find in favour of this approach is .
* We skip creating needless classloaders
* This is very close to the old implementation. Think of it like we are  registering all the jars at once (See: https://issues.apache.org/jira/browse/HIVE-3907), Hi [~rdsr], I left some comments on RB related to the testing approach. Everything else looks good. Thanks., For HiveServer2 there may potentially be multiple Sessions from different users, each of which may be issuing their own ADD/REMOVE JAR commands. Since this patch is now re-using/updating the class loader rather than creating a new one when adding JARs, it would be good to make sure that the class loader used by a one session does not get affected by ADD/REMOVE JAR commands happening from other/older sessions. Can you make sure that when a new session is started, that a new class loader is created for that session, with an appropriate parent class loader (is it the context class loader?)?, Hi [~cwsteinbach] . Thanks for the comments, I'll update the patch with your comments.
[~jdere] That's a very good point. I'll incorporate your suggestions, Hi [~jdere]
    I got some time to look into this today.  I incorporated your suggestion where I create a fresh classloader when a new session is created. I use, as parent, the thread context classloader for the freshly created session classloader (See RB: https://reviews.apache.org/r/38663/) .  I have some doubts about using the thread context classloader as the parent.  This does not seem to provide clean isolation between jars/resources between different sessions.  Case in point: a thread context classloader could be a previous session's classloader .This can happen when the same thread was used  to work on a previous session, and is now being used to work on the newer current session. The thread context classloaer  could contain a different implementation of the same class also present in the session classloader. Do you see this a a problem?


Another potential problem I'm thinking about -- which is present in the proposed approach (see RB) is --  in HiveServer2 any worker thread can serve any request by mapping it to a persistent session. Couldn't this lead to a situation where for a specific session the session specific classloader (conf.getClassLoader()) and the thread context classloader end up being  different?  Say we have  two worker thread t1 and t2 .The  very first query is handled by t1 where a fresh session s1 is created along with a fresh classloader c1, which is  set as the session specific classloader and the thread context classloader. The next query for the same session is handled by t2. I guess since it is the same session s1, we do not create a fresh classloader. The session specific classloader is c1, but since it is a different thread and no classloader has been set on it, the thread will have the system classloader as its context classloader.  Couldn't this cause potential CNF exceptions?  If I understood correctly   this problem also exists in the current implementation, doesn't it?, Also note: The above to problems, I think, should also exist in Hive currently. Am I missing something here?, s/above to/above two/, Apologies for not getting back to you on this before now. As to your comments:

{quote}
I have some doubts about using the thread context classloader as the parent. This does not seem to provide clean isolation between jars/resources between different sessions. Case in point: a thread context classloader could be a previous session's classloader .This can happen when the same thread was used to work on a previous session, and is now being used to work on the newer current session. The thread context classloaer could contain a different implementation of the same class also present in the session classloader. Do you see this a a problem?
{quote}
I think you are right, that the new session's classloader would be polluted with the loaded JARs from the thread's previous SessionState. What would be a better parent class loader to use here - the system class loader? Will it have any JARs added from the AUX_JARS options?
Checking some of the various AUX_JARS related options, not sure if I missed any others:
 - HIVE_AUX_JARS_PATH environment variable: This gets added to the CLASSPATH, so the System class loader will have these
 - hive.aux.jars: As far as I can tell this is used when shipping JARs to the Map/Reduce tasks, so this does not seem to get used by the SessionState. Someone correct me if I am wrong.
 - hive.reloadable.aux.jars.path: These jars are added at the start of a HiveServer2 session, so it may not matter that the System class loader does not have these jars.

{quote}
Another potential problem I'm thinking about – which is present in the proposed approach (see RB) is – in HiveServer2 any worker thread can serve any request by mapping it to a persistent session. Couldn't this lead to a situation where for a specific session the session specific classloader (conf.getClassLoader()) and the thread context classloader end up being different? Say we have two worker thread t1 and t2 .The very first query is handled by t1 where a fresh session s1 is created along with a fresh classloader c1, which is set as the session specific classloader and the thread context classloader. The next query for the same session is handled by t2. I guess since it is the same session s1, we do not create a fresh classloader. The session specific classloader is c1, but since it is a different thread and no classloader has been set on it, the thread will have the system classloader as its context classloader. Couldn't this cause potential CNF exceptions? If I understood correctly this problem also exists in the current implementation, doesn't it?
{quote}
I'm not sure if I understand the problem here - I believe that if a new thread handles an existing session, the thread calls Session.setCurrentSessionState() which should set the thread's context class loader to the SessionState's class loader. Or did I not understand the issue?, Hi [~jdere]
  Thanks for the comments. We can change the parent classloader when creating the {{UDFClassLoader}} to SessionState.class.getClassLoader() which will be the system classloader.  What do you think?

About the second point. I think you are right. I was mistaken., Hi [~rdsr], I think that sounds good., Using SystemClassLoader as parent for per session classloader, Incorporated [~jdere] comments., So removing JARs from the session will still require closing the existing classloader and creating a new one (with the specified JARs omitted from the list of URIs), correct?, Latest patch (HIVE-11878_approach3_with_review_comments1.patch) was not in the correct name format to kick off the pre-commit tests.  Re-uploading it as HIVE-11878.2.patch., That's correct [~jdere], 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12774196/HIVE-11878.2.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6145/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6145/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6145/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-6145/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 7984738 HIVE-12465: Hive might produce wrong results when (outer) joins are merged (Jesus Camacho Rodriguez, reviewed by Ashutosh Chauhan)
+ git clean -f -d
+ git checkout master
Already on 'master'
+ git reset --hard origin/master
HEAD is now at 7984738 HIVE-12465: Hive might produce wrong results when (outer) joins are merged (Jesus Camacho Rodriguez, reviewed by Ashutosh Chauhan)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12774196 - PreCommit-HIVE-TRUNK-Build, Patch no longer applies - rebasing, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12774703/HIVE-11878.3.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 9826 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
TestMiniLlapCliDriver - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_classloader_dynamic_dependency_resolution
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6169/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6169/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6169/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12774703 - PreCommit-HIVE-TRUNK-Build, The following test failures look like real errors and need to be fixed:

org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_classloader_dynamic_dependency_resolution
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters

TestHiveAuthorizerShowFilters is failing with the following error in hive-unit/target/tmp/log/hive.log:
{noformat}
2015-12-01T01:05:03,174 ERROR [main]: ql.Driver (SessionState.java:printError(1010)) - FAILED: MockitoException
Mockito cannot mock this class: class org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters$MockedHiveAuthorizerFactory$1AuthorizerWithFilterCmdImpl
Mockito can only mock visible & non-final classes.
If you're not sure why you're getting this error, please report to the mailing list.
org.mockito.exceptions.base.MockitoException:
Mockito cannot mock this class: class org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters$MockedHiveAuthorizerFactory$1AuthorizerWithFilterCmdImpl
Mockito can only mock visible & non-final classes.
If you're not sure why you're getting this error, please report to the mailing list.
        at org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters$MockedHiveAuthorizerFactory.createHiveAuthorizer(TestHiveAuthorizerShowFilters.java:98)
        at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:773)
        at org.apache.hadoop.hive.ql.session.SessionState.getAuthenticator(SessionState.java:1436)
        at org.apache.hadoop.hive.ql.session.SessionState.getUserFromAuthenticator(SessionState.java:1034)
        at org.apache.hadoop.hive.ql.metadata.Table.getEmptyTable(Table.java:179)
        at org.apache.hadoop.hive.ql.metadata.Table.<init>(Table.java:121)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.addDbAndTabToOutputs(SemanticAnalyzer.java:11016)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:10871)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:9960)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10060)
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:222)
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:237)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:462)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:317)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1227)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1276)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1152)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1140)
        at org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters.runCmd(TestHiveAuthorizerShowFilters.java:265)
        at org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters.beforeTest(TestHiveAuthorizerShowFilters.java:127)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
Caused by: org.mockito.cglib.core.CodeGenerationException: java.lang.reflect.InvocationTargetException-->null
        at org.mockito.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:238)
        at org.mockito.cglib.proxy.Enhancer.createHelper(Enhancer.java:378)
        at org.mockito.cglib.proxy.Enhancer.createClass(Enhancer.java:318)
        at org.mockito.internal.creation.jmock.ClassImposterizer.createProxyClass(ClassImposterizer.java:110)
        at org.mockito.internal.creation.jmock.ClassImposterizer.imposterise(ClassImposterizer.java:62)
        at org.mockito.internal.creation.jmock.ClassImposterizer.imposterise(ClassImposterizer.java:56)
        at org.mockito.internal.creation.CglibMockMaker.createMock(CglibMockMaker.java:23)
        at org.mockito.internal.util.MockUtil.createMock(MockUtil.java:26)
        at org.mockito.internal.MockitoCore.mock(MockitoCore.java:51)
        at org.mockito.Mockito.mock(Mockito.java:1243)
        ... 36 more
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.mockito.cglib.core.ReflectUtils.defineClass(ReflectUtils.java:385)
        at org.mockito.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:220)
        ... 45 more
Caused by: java.lang.IllegalAccessError: class org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters$MockedHiveAuthorizerFactory$1AuthorizerWithFilterCmdImpl$$EnhancerByMockitoWithCGLIB$$53d16709 cannot access its superclass org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters$MockedHiveAuthorizerFactory$1AuthorizerWithFilterCmdImpl
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:791)
        ... 51 more
{noformat}, [~rdsr] would you be able to look at these failures?, [~jdere] I'm unable to reproduce {{org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_classloader_dynamic_dependency_resolution}}

I'll check why {{org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters}} is failing.

, Any thoughts on what could be happening with {{udf_classloader_dynamic_dependency_resolution}} ? 
Seems like it is failing when registering the jar 
{code}
 running ADD JAR ivy://org.apache.hive.hive-it-custom-udfs:udf-classloader-udf1:+
{code}, I think this is happening because the changes in conf/ivysettings.xml assume the local maven repository is in file:${user.home}/.m2/repository. I set my MAVEN_OPTS to specify a non-default directory using -Dmaven.repo.local and also hit this error.

In the pom file, we use the maven.repo.local setting, would there be a way to specify this in the ivy settings?

{noformat}
<maven.local.repository>${maven.repo.local}</maven.local.repository>
{noformat}, Addressed failing tests, [~jdere] . I've fixed both the failing tests. Please have a look. Thanks, +1 if the test look good, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12776512/HIVE-11878.4.patch

{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 9874 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
TestSparkCliDriver-timestamp_lazy.q-bucketsortoptimize_insert_4.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_udf_max
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_order2
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.jdbc.miniHS2.TestHs2Metrics.testMetrics
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6299/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6299/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6299/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12776512 - PreCommit-HIVE-TRUNK-Build, Test failiures are not related, Since this has been seen at other sites also, it will be good to land this in 2.0 branch as well., I've committed this patch to master/branch-2.0
The patch does not build on branch-1, may need some modifications related to the hadoop.version setting .. [~ashutoshc] should this be ported to branch-1?, Attaching port of v4 to branch-1. The differences from master were changing the version numbers, as well as moving the hadoop-common dependency to the different hadoop-1/hadoop-2 profiles in itests/custom-udfs/pom.xml., Committed to branch-1]