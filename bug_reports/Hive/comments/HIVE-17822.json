[Users have to pass -DskipShade to skip druid and jdbc shading. hive-exec shading is not used as submodules depend on it in most cases. , Some numbers
{code}
# Base: Clean offline quite build
$ time mvn clean install -DskipTests -o -q
real	3m9.005s
user	7m14.864s
sys	0m40.295s

# Parallel (using 1C gave best build times) build
$ time mvn clean install -DskipTests -T 1C -o -q
real	2m24.415s
user	8m12.243s
sys	0m54.905s

# With MAVEN_OPTS
$ time MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1" mvn clean install -DskipTests -T 1C -o -q
real	2m12.872s
user	7m46.879s
sys	0m49.696s

# Skip clean
$ MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1"
$ time MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1" mvn install -DskipTests -T 1C -o -q
real	1m31.403s
user	5m13.439s
sys	0m37.885s

# Skip shade for jdbc and druid-handler (requires HIVE-17822)
# NOTE: if you are changing/testing jdbc or druid you may want to skip this step
$ time MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1" mvn install -DskipShade -DskipTests -T 1C -o -q
real	1m20.130s
user	4m37.645s
sys	0m39.897s

# Skip remote resource plugin
$ time MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1" mvn install -DskipShade -DskipTests -Dremoteresources.skip=true -T 1C -o -q
real	0m37.485s
user	0m52.652s
sys	0m14.118s

# Build ql and downstream modules
$ time MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1" mvn install -DskipShade -DskipTests -Dremoteresources.skip=true -T 1C -o -q -pl ql -amd
real	0m31.827s
user	1m50.349s
sys	0m9.494s

# Build llap-server and downstream modules
$ time MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1" mvn install -DskipShade -DskipTests -Dremoteresources.skip=true -T 1C -o -q -pl llap-server -amd
real	0m9.147s
user	0m20.189s
sys	0m3.056s
{code}, [~ashutoshc] Can you please review this change?, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12892483/HIVE-17822.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 11242 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=163)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multi] (batchId=110)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_notin] (batchId=133)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_scalar] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_select] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_views] (batchId=108)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query16] (batchId=243)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query94] (batchId=243)
org.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query14] (batchId=241)
org.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query16] (batchId=241)
org.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query94] (batchId=241)
org.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=204)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/7337/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/7337/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7337/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 12 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12892483 - PreCommit-HIVE-Build, +1, Committed to master. Thanks for the review!, Should this be documented in the wiki?  (If so, it needs a TODOC3.0 label.), This jira is resolved and released with Hive 3.0 If you find an issue with it, please create a new jira.]