[We've run into this same issue. As far as we can tell, it's due to the fact that hive-server2 passes through its environment, along with JVM startup options, to the MapRedLocalTask (which it runs in a separate process): 

{code}
      if (variables.containsKey(HADOOP_OPTS_KEY)) {
        variables.put(HADOOP_OPTS_KEY, variables.get(HADOOP_OPTS_KEY) + hadoopOpts);
      } else {
        variables.put(HADOOP_OPTS_KEY, hadoopOpts);
      }
{code}

(from [MapredLocalTask|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java#L245])

 When it tries to do this, the child JVM tries to listen on the same JMX port and fails to start, since the parent already owns it. This is of course a pain to debug, since for some reason the child job's stderr isn't bubbled up anywhere (that might be a separate ticket). After throwing in a debug log statement though, we can confirm this:

{code}
diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
index 9f3df99..8cd65c0 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
@@ -305,6 +305,7 @@ public int executeInChildVM(DriverContext driverContext) {
 
       if (exitVal != 0) {
         LOG.error("Execution failed with exit status: " + exitVal);
+        LOG.error(errPrintStream.getOutput());
         if (SessionState.get() != null) {
           SessionState.get().addLocalMapRedErrors(getId(), errPrintStream.getOutput());
         }
{code}
 will print:
{code}
2015-09-12 10:54:45,634 ERROR mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(308)) - [Error: Exception thrown by the agent : java.rmi.server.ExportException: Port already in use: 9099; nested exception is: , 	java.net.BindException: Address already in use]
{code}

, As far as actual fixes... we could have hive specialcase the JMX options, but that seems ugly/error prone. Perhaps it would make sense to split out the options for the child JVM from those of the parent? They seem like they might be quite different in general--you almost certainly don't want to give every local task the same amount of memory as hive-server2. Could either configure that by way of hive-site.xml, or by way of another environment variable (HIVE_LOCAL_TASK_CHILD_OPTS?), We can remove these settings when spining up the child process. Let me come up a patch., Attached a patch that uses HIVE_LOCAL_TASK_CHILD_OPTS instead of HADOOP_CLIENT_OPTS, if set., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12779894/HIVE-11369.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 19 failed/errored test(s), 9992 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_order2
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_multiple_part_clause
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.checkHiveOperationTypeMatch
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testRemoteClient
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6501/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6501/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6501/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 19 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12779894 - PreCommit-HIVE-TRUNK-Build, Thanks [~jxiang] for the patch. Here are a few comments.

1. Seems we are redefining the same constants in MapRedTask.java and MapRedLocalTask.java. Can we try to avoid that?
2. Since the patch only replaces the opts when HIVE_LOCAL_TASK_CHILD_OPTS exists, then it will still have the same issue for this scenario. Probably we should still replace HADOOP_OPTS by removing HADOOP_CLIENT_OPTS when HIVE_LOCAL_TASK_CHILD_OPTS is not set?, Thanks [~aihuaxu] a lot for the review. I fixed 1), and some existing constants.

For 2, I think it is better not do anything if HIVE_LOCAL_TASK_CHILD_OPTS doesn't exist, for backward compatibility. Right, in this case, the same issue still exists. This patch just provides a way to work around it., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12780059/HIVE-11369.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 21 failed/errored test(s), 9994 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_order2
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_multiple_part_clause
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.checkHiveOperationTypeMatch
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testRemoteClient
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6505/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6505/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6505/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 21 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12780059 - PreCommit-HIVE-TRUNK-Build, You are right. We need to keep such backward compatibility since usually we need to pass such opts to the child process. 

+1 on the new patch., Thanks Aihua for the review. Integrated v2 to master and branch 2.]