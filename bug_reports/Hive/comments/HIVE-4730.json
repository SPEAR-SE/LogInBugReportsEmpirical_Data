[Could you try to change join order something like, 
{noformat}
select a.p1 from small_table a join big_table b on (a.p1=b.p1);
{noformat}, navis requested code review of "HIVE-4730 [jira] Join on more than 2^31 records on single reducer failed (wrong results)".

Reviewers: JIRA

HIVE-4730 Join on more than 2^31 records on single reducer failed (wrong results)

join on more than 2^31 rows leads to wrong results. for example:

Create table small_table (p1 string) ROW FORMAT DELIMITED    LINES TERMINATED BY  '\n';
Create table big_table (p1 string) ROW FORMAT DELIMITED    LINES TERMINATED BY  '\n';

Loading 1 row to small_table (the value 1).
Loading 2149580800 rows to big_table with the same value (1 on this case).

create table output as select a.p1 from  big_table a join small_table b on (a.p1=b.p1);

select count from output ; will return only 1 row...

the reducer syslog:
...
2013-06-13 17:20:59,254 INFO ExecReducer: ExecReducer: processing 2147000000 rows: used memory = 32925960
2013-06-13 17:21:00,745 INFO ExecReducer: ExecReducer: processing 2148000000 rows: used memory = 12815184
2013-06-13 17:21:02,205 INFO ExecReducer: ExecReducer: processing 2149000000 rows: used memory = 26684552   <-- looks like wrong value..
...
2013-06-13 17:21:04,062 INFO ExecReducer: ExecReducer: processed 2149580801 rows: used memory = 17715896
2013-06-13 17:21:04,062 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 finished. closing...
2013-06-13 17:21:04,062 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 forwarded 1 rows
2013-06-13 17:21:05,791 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: SKEWJOINFOLLOWUPJOBS:0
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 finished. closing...
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 forwarded 1 rows
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 6 finished. closing...
2013-06-13 17:21:05,792 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 6 forwarded 0 rows
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: TABLE_ID_1_ROWCOUNT:1
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 5 Close done
2013-06-13 17:21:05,946 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: 4 Close done

TEST PLAN
  EMPTY

REVISION DETAIL
  https://reviews.facebook.net/D11283

AFFECTED FILES
  ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java

MANAGE HERALD RULES
  https://reviews.facebook.net/herald/view/differential/

WHY DID I GET THIS EMAIL?
  https://reviews.facebook.net/herald/transcript/26817/

To: JIRA, navis
, After patching and compiling, when i run the same join it fail:

......
2013-06-14 16:47:14,924 INFO ExecReducer: ExecReducer: processing 2149000000 rows: used memory = 45018992
2013-06-14 16:47:16,042 FATAL org.apache.hadoop.mapred.TaskTracker: Error running child : java.lang.NoSuchMethodError: org.apache.hadoop.hive.ql.exec.persistence.AbstractRowContainer.size()I
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:802)
        at org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:263)
        at org.apache.hadoop.hive.ql.exec.ExecReducer.close(ExecReducer.java:301)
        at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:473)
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:411)
        at org.apache.hadoop.mapred.Child.main(Child.java:170)

2013-06-14 16:47:19,051 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=CLEANUP, sessionId=
2013-06-14 16:47:19,305 INFO org.apache.hadoop.mapred.TaskRunner: Runnning cleanup for the task
2013-06-14 16:47:19,305 INFO org.apache.hadoop.mapred.TaskRunner: Task:attempt_201306121727_0032_r_000004_0 is done. And is in the process of commiting
2013-06-14 16:47:19,311 INFO org.apache.hadoop.mapred.TaskRunner: Task 'attempt_201306121727_0032_r_000004_0' done.

, I think you should do clean build., can you explain me how?
ant clean ?

Navis - thank you for your kindly and fast help!, You can just remove build/ql directory and build, which might be a little faster. 
I wish I could confirm this patch, but my notebook couldn't handle shuffling of 4G data., ok - i am trying now - building ql from scratch and running the join,
i will comment here the results.

Thanks. , do i need to copy the hive-exec jar only?  or did the patch changed another jar?

Thanks., exec only, Hi Navis - 
on hive 0.7.x is works,
on hive 0.10.0, i am compiling the exec jar and it build me hive-exec-0.10.0-SNAPSHOT.jar
when i am running hive on ver 0.10.0, i got the following massage (also after clean build):

[hdp@hive-1 gabi]$ hive
/hive/hive/bin/hive: line 72: [: /hive/hive/lib/hive-exec-0.10.0.jar: binary operator expected
Logging initialized using configuration in jar:file:/hive/hive-0.10.0/lib/hive-common-0.10.0.jar!/hive-log4j.properties
Hive history file=/tmp/hdp/hive_job_log_hdp_201306151610_458251040.txt
hive> show tables;
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.hive.metastore.api.MetaException javax.jdo.JDODataStoreException: An exception was thrown while adding/validating class(es) : Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
java.sql.SQLException: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatement(AbstractTable.java:730)
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatementList(AbstractTable.java:681)
        at org.datanucleus.store.rdbms.table.AbstractTable.create(AbstractTable.java:402)
        at org.datanucleus.store.rdbms.table.AbstractTable.exists(AbstractTable.java:458)
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.performTablesValidation(RDBMSStoreManager.java:2689)
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.addClassTablesAndValidate(RDBMSStoreManager.java:2503)
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.run(RDBMSStoreManager.java:2148)
        at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:113)
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:986)
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:952)
        at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:919)
        at org.datanucleus.store.mapped.MappedStoreManager.getDatastoreClass(MappedStoreManager.java:356)
        at org.datanucleus.store.rdbms.query.legacy.ExtentHelper.getExtent(ExtentHelper.java:48)
        at org.datanucleus.store.rdbms.RDBMSStoreManager.getExtent(RDBMSStoreManager.java:1332)
        at org.datanucleus.ObjectManagerImpl.getExtent(ObjectManagerImpl.java:4149)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compileCandidates(JDOQLQueryCompiler.java:411)
        at org.datanucleus.store.rdbms.query.legacy.QueryCompiler.executionCompile(QueryCompiler.java:312)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compile(JDOQLQueryCompiler.java:225)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.compileInternal(JDOQLQuery.java:175)
        at org.datanucleus.store.query.Query.executeQuery(Query.java:1628)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.executeQuery(JDOQLQuery.java:245)
        at org.datanucleus.store.query.Query.executeWithArray(Query.java:1499)
        at org.datanucleus.jdo.JDOQuery.execute(JDOQuery.java:243)
        at org.apache.hadoop.hive.metastore.ObjectStore.getTables(ObjectStore.java:781)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:111)
        at $Proxy6.getTables(Unknown Source)
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_tables(HiveMetaStore.java:2327)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)
        at $Proxy7.get_tables(Unknown Source)
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTables(HiveMetaStoreClient.java:817)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:74)
        at $Proxy8.getTables(Unknown Source)
        at org.apache.hadoop.hive.ql.metadata.Hive.getTablesByPattern(Hive.java:1009)
        at org.apache.hadoop.hive.ql.metadata.Hive.getAllTables(Hive.java:983)
        at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2215)
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:334)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:138)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1336)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1122)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:935)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:755)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:613)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
Caused by: java.sql.SQLException: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)
        ... 74 more
Caused by: ERROR X0Y32: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.duplicateDescriptorException(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addConstraintDescriptor(Unknown Source)
        at org.apache.derby.impl.sql.execute.CreateConstraintConstantAction.executeConstantAction(Unknown Source)
        at org.apache.derby.impl.sql.execute.AlterTableConstantAction.executeConstantAction(Unknown Source)
        at org.apache.derby.impl.sql.execute.MiscResultSet.open(Unknown Source)
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
        ... 68 more

NestedThrowables:
java.sql.SQLException: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask

Do i need to change something on 0.10.0 to get it work?

Thanks,
Gabi, ignore the script error line : /hive/hive/bin/hive: line 72: [: /hive/hive/lib/hive-exec-0.10.0.jar: binary operator expected
i had 2 jar files (old and new), fixed it, but i still have the exception:

hive> show tables;
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.hive.metastore.api.MetaException javax.jdo.JDODataStoreException: An exception was thrown while adding/validating class(es) : Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
java.sql.SQLException: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
        at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)
        at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264)
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatement(AbstractTable.java:730)
        at org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatementList(AbstractTable.java:681)
        at org.datanucleus.store.rdbms.table.AbstractTable.create(AbstractTable.java:402)
        at org.datanucleus.store.rdbms.table.AbstractTable.exists(AbstractTable.java:458)
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.performTablesValidation(RDBMSStoreManager.java:2689)
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.addClassTablesAndValidate(RDBMSStoreManager.java:2503)
        at org.datanucleus.store.rdbms.RDBMSStoreManager$ClassAdder.run(RDBMSStoreManager.java:2148)
        at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:113)
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:986)
        at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:952)
        at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:919)
        at org.datanucleus.store.mapped.MappedStoreManager.getDatastoreClass(MappedStoreManager.java:356)
        at org.datanucleus.store.rdbms.query.legacy.ExtentHelper.getExtent(ExtentHelper.java:48)
        at org.datanucleus.store.rdbms.RDBMSStoreManager.getExtent(RDBMSStoreManager.java:1332)
        at org.datanucleus.ObjectManagerImpl.getExtent(ObjectManagerImpl.java:4149)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compileCandidates(JDOQLQueryCompiler.java:411)
        at org.datanucleus.store.rdbms.query.legacy.QueryCompiler.executionCompile(QueryCompiler.java:312)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compile(JDOQLQueryCompiler.java:225)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.compileInternal(JDOQLQuery.java:175)
        at org.datanucleus.store.query.Query.executeQuery(Query.java:1628)
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.executeQuery(JDOQLQuery.java:245)
        at org.datanucleus.store.query.Query.executeWithArray(Query.java:1499)
        at org.datanucleus.jdo.JDOQuery.execute(JDOQuery.java:243)
        at org.apache.hadoop.hive.metastore.ObjectStore.getTables(ObjectStore.java:781)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:111)
        at $Proxy6.getTables(Unknown Source)
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_tables(HiveMetaStore.java:2327)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)
        at $Proxy7.get_tables(Unknown Source)
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTables(HiveMetaStoreClient.java:817)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:74)
        at $Proxy8.getTables(Unknown Source)
        at org.apache.hadoop.hive.ql.metadata.Hive.getTablesByPattern(Hive.java:1009)
        at org.apache.hadoop.hive.ql.metadata.Hive.getAllTables(Hive.java:983)
        at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2215)
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:334)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:138)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1336)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1122)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:935)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:755)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:613)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
Caused by: java.sql.SQLException: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)
        ... 74 more
Caused by: ERROR X0Y32: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.
        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.duplicateDescriptorException(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addDescriptor(Unknown Source)
        at org.apache.derby.impl.sql.catalog.DataDictionaryImpl.addConstraintDescriptor(Unknown Source)
        at org.apache.derby.impl.sql.execute.CreateConstraintConstantAction.executeConstantAction(Unknown Source)
        at org.apache.derby.impl.sql.execute.AlterTableConstantAction.executeConstantAction(Unknown Source)
        at org.apache.derby.impl.sql.execute.MiscResultSet.open(Unknown Source)
        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
        ... 68 more

NestedThrowables:
java.sql.SQLException: Constraint 'COLUMNS_PK' already exists in Schema 'APP'.)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
, I think the exception above is from change of metastore schema between 0.7.0 and 0.10.0. You need upgrade metastore via script (I haven't do that, yet) or make a new metastore., looks like you right, sorry for that.

will check and update here.

Thanks again!, Looks good, thanks!, Hi - i want to add it to git,
how can i get permissions to push?

Thanks, I have it here:
https://github.com/gabik/hive/tree/HIVE-4730
and merged into trunk:
https://github.com/gabik/hive/tree/trunk
, brock has commented on the revision "HIVE-4730 [jira] Join on more than 2^31 records on single reducer failed (wrong results)".

  Hi Navis,

  Thanks for the patch!  I noted a few style nits.  Just curious, how long did the query take to complete?  My guess is far too long to have a q-file test for this.

INLINE COMMENTS
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java:286 Is it possible to move this up near the rest of the member variable definitions?

  Ideally it'd be nice to change the LHS to be List but it's possible that something in the class requires ArrayList.

REVISION DETAIL
  https://reviews.facebook.net/D11283

To: JIRA, navis
Cc: brock
, ashutoshc has accepted the revision "HIVE-4730 [jira] Join on more than 2^31 records on single reducer failed (wrong results)".

  +1

REVISION DETAIL
  https://reviews.facebook.net/D11283

BRANCH
  HIVE-4730

ARCANIST PROJECT
  hive

To: JIRA, ashutoshc, navis
Cc: brock
, Test {{TestCliDriver_skewjoin.q}} failed. All others did pass., navis updated the revision "HIVE-4730 [jira] Join on more than 2^31 records on single reducer failed (wrong results)".

  Fixed test failure

Reviewers: ashutoshc, JIRA

REVISION DETAIL
  https://reviews.facebook.net/D11283

CHANGE SINCE LAST DIFF
  https://reviews.facebook.net/D11283?vs=34707&id=35805#toc

BRANCH
  HIVE-4730

ARCANIST PROJECT
  hive

AFFECTED FILES
  ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/AbstractRowContainer.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinObjectValue.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinRowContainer.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java

To: JIRA, ashutoshc, navis
Cc: brock
, I wish I could add a test case for this. But I couldn't run some query for table with 2G rows (job failed after 40min)., skewjoin.q test still fails for me. Canceling patch trying to trigger pre-commit test-patch, Marking Patch available to trigger pre-commit script to see if failure reproduces., 

{color:red}Overall{color}: -1 build exited with an error

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch

{color:green}SUCCESS:{color} +1 all tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/78/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/78/console

Messages:
Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests failed with: IllegalStateException: Too many bad hosts: 5 bad hosts out of 8 is greater than threshold of 30%

This message is automatically generated., OK interesting. Basically 5 of our 8 ec2 hosts went "bad" during testing. We'll see this from time to time. Uploading the patch again will start a new build, but I kicked off the pre-commit build manually., 

{color:red}Overall{color}: -1 build exited with an error

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch

{color:green}SUCCESS:{color} +1 all tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/79/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/79/console

Messages:
Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests failed with: IllegalStateException: Too many bad hosts: 5 bad hosts out of 8 is greater than threshold of 30%

This message is automatically generated., And there is a bug we aren't correctly replacing I created HIVE-4882 for this. I also kicked off the pre-commit job again., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12592716/HIVE-4730.D11283.2.patch

{color:green}SUCCESS:{color} +1 all tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/81/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/81/console

Messages:
Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase

This message is automatically generated., Q. Why do we cast down to int here?

{quote}
       // Different processing for key and value
       MapJoinRowContainer<Object[]> v = obj;
-      out.writeInt(v.size());
+      out.writeInt((int)v.size());
{quote}, Never mind I see its an array size issue., Committed to trunk. Thanks, Navis!, This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.]