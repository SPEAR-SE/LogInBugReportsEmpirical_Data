[The original exception is:
{quote}
org.apache.hadoop.hive.ql.metadata.HiveException: Hive internal error: cannot find parent in the child operator!
        at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:365)
        at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:133)
        at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.call(HiveMapFunction.java:60)
        at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.call(HiveMapFunction.java:35)
        at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:161)
        at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:161)
        at org.apache.spark.rdd.RDD$$anonfun$12.apply(RDD.scala:559)
        at org.apache.spark.rdd.RDD$$anonfun$12.apply(RDD.scala:559)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:158)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
        at org.apache.spark.scheduler.Task.run(Task.scala:51)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:183)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
{quote}, It seems that some malformed op tree caused this issue:
{noformat}
<MAP>Id =69
  <Children>
    <TS>Id =65
      <Children>
        <SEL>Id =66
          <Children>
            <GBY>Id =67
              <Children>
                <RS>Id =68
                  <Children>
                  <\Children>
                  <Parent>Id = 67 null<\Parent>
                <\RS>
              <\Children>
              <Parent>Id = 66 null<\Parent>
            <\GBY>
          <\Children>
          <Parent>Id = 65 null<\Parent>
        <\SEL>
      <\Children>
      <Parent>Id = 71
    <MAP>Id =71
      <Children>null
      <\Children>
      <Parent><\Parent>
    <\MAP><\Parent>
    <\TS>
  <\Children>
  <Parent><\Parent>
<\MAP>
{noformat}, [~lirui] Thanks for working on this. How to reproduce the problem? What query can produce this error?, [~xuefuz] This failure happens when I run select count ( * ) or max/min queries on a table.
Spark cluster is deployed in standalone mode.

I added some log to debug the issue. I found that the issue is due to setting parent for a TS more than once. Take the malformed op tree I mentioned earlier for example, when MAP (69) is created, we set TS (65) as its child and set TS (65)'s parent to MAP (69). But later when creating MAP (71), TS (65) is set as its child again. Now TS (65)'s parent doesn't contain MAP (69), which triggers the exception.

I'm not familiar with how the map operator is structured but I suppose a TS shouldn't be assigned to multiple MAPs right? Please note the successful tasks don't have such a malformed tree.

I'm still working to find the root cause. Any thoughts on this issue?, I also noted that when running on Tez, MapWork is cached in an ObjectCache. Now spark mode retrieves the MapWork from the plan file for each task. Not sure if this could be related to the issue here?, Since each spark task is a thread running in the same JVM, we should always deserialize the MapWork from the plan file for each task, rather than loading it from the cache.

I run several queries with this patch and all tasks finish successfully.

[~xuefuz]] please help to see if this is the right way to solve this issue., [~lirui] I wasn't able to reproduce the problem as my dataset is small and thus my test case doesn't involves multiple tasks.

I think you're right that multiple tasks shouldn't share MapWork in case of Spark as each thread running a task needs its own copy of operators. While it's okay to deserialize a MapWork for each task running in a JVM, for a longer term, maybe we should deserialize once and clone it as needed. Cloning should be more performing.

I guess this uncovers a concurrency issue. I expect there will be more issues like this. Thanks for identifying this one.

Could you clean up the patch a little by removing debugging code?, [~xuefuz], thanks for the review. I'll clean up the code and use clone instead., [~lirui] Let's not worry about cloning for now. It can be done later as optimization. Just clean up the code to remove unnecessary changes., [~xuefuz] I see. In HiveMapFunction.call, MapWork is retrieved and put to a global work map in Utilities. I think this is redundant since ExecMapper will later get MapWork itself. I commented these out in the current patch. Should I just remove them?, Sure. Please feel free to do so. That's just POC code., Hi [~xuefuz], I've updated the patch., Patch looks good to me. Will commit shortly., Patch committed to spark branch. Thanks to Rui for the contribution., FYI that I created a jira to re-introduce some caching of these objects in RSC in HIVE-9127.]