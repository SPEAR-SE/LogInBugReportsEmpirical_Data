[Those lists should never be null. Do, we know why they become null and its ok not to copy them? Also, a testcase will help to understand the issue better., Ashutosh-

Any table will cause this error. Try doing the import on

Create table test(
A int)

And exporting and importing that.

Thanks!, [~ashutoshc] Test was planed when patch is submitted.

As to the nullness of these lists, your assumption might be well correct, but that's not what I see in the code.

Here is the caller code in ImportSemanticAnalyzer.

{code}
        tblDesc =  new CreateTableDesc(
            table.getTableName(),
            false, // isExternal: set to false here, can be overwritten by the
                   // IMPORT stmt
            table.getSd().getCols(),
            table.getPartitionKeys(),
            table.getSd().getBucketCols(),
            table.getSd().getSortCols(),
            table.getSd().getNumBuckets(),
            null, null, null, null, null, // these 5 delims passed as serde params
            null, // comment passed as table params
            table.getSd().getInputFormat(),
            table.getSd().getOutputFormat(),
            null, // location: set to null here, can be
                  // overwritten by the IMPORT stmt
            table.getSd().getSerdeInfo().getSerializationLib(),
            null, // storagehandler passed as table params
            table.getSd().getSerdeInfo().getParameters(),
            table.getParameters(), false,
            (null == table.getSd().getSkewedInfo()) ? null : table.getSd().getSkewedInfo()
                .getSkewedColNames(),
            (null == table.getSd().getSkewedInfo()) ? null : table.getSd().getSkewedInfo()
                .getSkewedColValues());

{code}

From the snippet we can see that, it's possible that the last two lists can be null. Also, the partition columns was passed from the thrift "table" object, for which null is clearly a valid value.

For reference, this is the metadata for an exported, simple table with two columns and two rows of data:

{code}
{"partitions":[],"table":"{\"1\":{\"str\":\"j1_41\"},\"2\":{\"str\":\"default\"},\"3\":{\"str\":\"johndee\"},\"4\":{\"i32\":1371900915},\"5\":{\"i32\":0},\"6\":{\"i32\":0},\"7\":{\"rec\":{\"1\":{\"lst\":[\"rec\",2,{\"1\":{\"str\":\"a\"},\"2\":{\"str\":\"string\"}},{\"1\":{\"str\":\"b\"},\"2\":{\"str\":\"int\"}}]},\"2\":{\"str\":\"hdfs://hivebase01:8020/user/hive/warehouse/j1_41\"},\"3\":{\"str\":\"org.apache.hadoop.mapred.TextInputFormat\"},\"4\":{\"str\":\"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\"},\"5\":{\"tf\":0},\"6\":{\"i32\":-1},\"7\":{\"rec\":{\"2\":{\"str\":\"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\"},\"3\":{\"map\":[\"str\",\"str\",2,{\"serialization.format\":\",\",\"field.delim\":\",\"}]}}},\"8\":{\"lst\":[\"str\",0]},\"9\":{\"lst\":[\"rec\",0]},\"10\":{\"map\":[\"str\",\"str\",0,{}]}}},\"8\":{\"lst\":[\"rec\",0]},\"9\":{\"map\":[\"str\",\"str\",1,{\"transient_lastDdlTime\":\"1371900931\"}]},\"12\":{\"str\":\"MANAGED_TABLE\"}}","version":"0.1"}
{code}

This piece of meta data contains no partition columns, or skewedkey/values, etc.

Could you clarify if you meant to say that the list should not null but with zero element? For unknown reason, the code doesn't reflect that either. for instance, Utilities.getFieldSchemaString() has code to handle a null list of partition columns.

Any further insight is appreciated.
, Latest patch added test case., So this won't be available until hive 0.13?

Thanks!, Sorry I guess that was a bad way to phrase it. What i meant to ask is it possible for us to drop an updated jar to fix this issue as part of a 0.9 to 0.10 upgrade?

Thanks!, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12604694/HIVE-5318.1.patch

{color:green}SUCCESS:{color} +1 3143 tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/859/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/859/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated., [~bradruderman] It's possible to backport the patch to the previous versions of Hive. You can either build it by yourself, or talk to your service provider to do so., Review board request at https://reviews.apache.org/r/14321/., [~ashutoshc] Would you like to take a look at the patch again? Thanks., +1, Committed to trunk. Thanks, Xuefu!, Thanks goes to Ashutosh for the review and commit., SUCCESS: Integrated in Hive-trunk-hadoop1-ptest #182 (See [https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/182/])
HIVE-5318 : Import Throws Error when Importing from a table export Hive 0.9 to Hive 0.10 (Xuefu Zhang via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526325)
* /hive/trunk/build-common.xml
* /hive/trunk/data/files/exported_table
* /hive/trunk/data/files/exported_table/_metadata
* /hive/trunk/data/files/exported_table/data
* /hive/trunk/data/files/exported_table/data/data
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java
* /hive/trunk/ql/src/test/queries/clientpositive/import_exported_table.q
* /hive/trunk/ql/src/test/results/clientpositive/import_exported_table.q.out
, FAILURE: Integrated in Hive-trunk-h0.21 #2359 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2359/])
HIVE-5318 : Import Throws Error when Importing from a table export Hive 0.9 to Hive 0.10 (Xuefu Zhang via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526325)
* /hive/trunk/build-common.xml
* /hive/trunk/data/files/exported_table
* /hive/trunk/data/files/exported_table/_metadata
* /hive/trunk/data/files/exported_table/data
* /hive/trunk/data/files/exported_table/data/data
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java
* /hive/trunk/ql/src/test/queries/clientpositive/import_exported_table.q
* /hive/trunk/ql/src/test/results/clientpositive/import_exported_table.q.out
, ABORTED: Integrated in Hive-trunk-hadoop2 #458 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/458/])
HIVE-5318 : Import Throws Error when Importing from a table export Hive 0.9 to Hive 0.10 (Xuefu Zhang via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526325)
* /hive/trunk/build-common.xml
* /hive/trunk/data/files/exported_table
* /hive/trunk/data/files/exported_table/_metadata
* /hive/trunk/data/files/exported_table/data
* /hive/trunk/data/files/exported_table/data/data
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java
* /hive/trunk/ql/src/test/queries/clientpositive/import_exported_table.q
* /hive/trunk/ql/src/test/results/clientpositive/import_exported_table.q.out
, FAILURE: Integrated in Hive-trunk-hadoop2-ptest #117 (See [https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/117/])
HIVE-5318 : Import Throws Error when Importing from a table export Hive 0.9 to Hive 0.10 (Xuefu Zhang via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526325)
* /hive/trunk/build-common.xml
* /hive/trunk/data/files/exported_table
* /hive/trunk/data/files/exported_table/_metadata
* /hive/trunk/data/files/exported_table/data
* /hive/trunk/data/files/exported_table/data/data
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java
* /hive/trunk/ql/src/test/queries/clientpositive/import_exported_table.q
* /hive/trunk/ql/src/test/results/clientpositive/import_exported_table.q.out
]