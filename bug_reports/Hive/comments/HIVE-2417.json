[Test added, Good catch, this is a regression introduced in HIVE-2396.
Can you make the testcase more easy to reproduce the problem? I mean if without the change in this diff, should get an error or incorrect results when running with that testcase. 

1. remove this "+set mapred.output.compression.codec=org.apache.hadoop.io.compress.BZip2Codec;",
2. tgt_rc_merge_test only contains one file, so the 'alter table tgt_rc_merge_test concatenate;' will basically do nothing. Can you make sure this table at least contains 2 files? You can upload 2 gzip compressed rcfile if there is not.


, Yes, the test is designed to produce the error when run without the change. Are you finding that that's not the case? I get an EOFException while running the same steps in my development environment (i.e., not as a unit test).

1. This is needed so that the rcfiles in the target table are compressed with Bzip2. Do you mean that we should be using Default compression codec instead? Fine with me but why is that important?

2. tgt does contain more than one file.

[before alter]
+POSTHOOK: query: show table extended like `tgt_rc_merge_test`
...
+totalNumberFiles:2
...
[after alter]
+POSTHOOK: query: show table extended like `tgt_rc_merge_test`
...
+totalNumberFiles:1

The 'create' adds one file, and the insert adds another file. [OT: Does it make sense append a block merge task after an non-overwrite insert? Dunno...], bq.The 'create' adds one file, and the insert adds another file.
sorry, i thought you are doing an "insert overwrite ", can u do 2 inserts? 

bq.This is needed so that the rcfiles in the target table are compressed with Bzip2. Do you mean that we should be using Default compression codec instead? Fine with me but why is that important?

Yes. i mean if you remove this line and keep the line "set hive.exec.compress.output = true;". The output will be compressed using DefaultCodec. The reason is that BZip2 may not installed for all hive users/dev., by "2 inserts", i mean remove the "load" command, and use 2 inserts to pop the data. , Test changed after review comments
 - default codec instead of bzip2
 - Create + 2 inserts instead of CTAS + 1 insert, +1, will commit after tests pass, Committed, thanks Krishna Kumar!, Integrated in Hive-trunk-h0.21 #928 (See [https://builds.apache.org/job/Hive-trunk-h0.21/928/])
    HIVE-2417: Merging of compressed rcfiles fails to write the valuebuffer part correctly (Krishna Kumar via He Yongqiang)

heyongqiang : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1164278
Files : 
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/RCFile.java
* /hive/trunk/ql/src/test/queries/clientpositive/create_merge_compressed.q
* /hive/trunk/ql/src/test/results/clientpositive/create_merge_compressed.q.out
]