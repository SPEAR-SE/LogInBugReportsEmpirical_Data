[https://github.com/apache/hive/blob/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L746

?, Three rows are returned because hadoop method org.apache.hadoop.mapred.LineRecordReader.readDefaultLine  use \r and \n as line
terminator. So hive need to process the \r and \n chars before call the method.
 Map job uses LazyUtils.writeEscaped method to escape special chars (such as control characters). The method just blindly add escape chars before the chars needing escaped. There are two issues: first \r and \n not in the chars needed to be escaped. second, even they are added, they should be escaped differently: for just adding escape char (such as \ ) before them can not solve our problem, the char with value 13 and 10 still in the stream. So we should process the two chars differently. For example replace '\r' with two chars: escape char and char 'r' . These logic can be add in the LazyUtils.writeEscaped method. The processed stream can go through org.apache.hadoop.mapred.LineRecordReader.readDefaultLine method without logic error(such errors as one row becomes 3 rows). Then in LazyString.init method, when we remove the escape chars, we know convert '\' '\r' to char 13.
Attach the fix patch.
, Need code review. , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12688942/HIVE-9201.1.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 6723 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_query_result_fileformat
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_remote_script
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2185/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2185/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2185/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12688942 - PreCommit-HIVE-TRUNK-Build, Hi,

Is there any downsides of this approach? Assume that users already have data that contains actual newlines, {{\\n}}, and {{\n}} will anyone be impacted negatively?, we will escape new line, changing it to '\' 'n' in stream. We also escape  \ in the customer's data. So 
if customer's data is newline, char \ char n, then in the stream it will be \n\\n    , 
then later it will be converted back to newline char \ char n by the method copyAndEscapeStringDataToText, Hmm I am a little nervous about this and I don't have too much experience with the text serialized formats. [~ashutoshc] any thoughts on this one?, The four failed tests are not related to the change:
The first 2 tests are old failures aged 3 or more.
 I ran tests
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_remote_script
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
on my own machine, both succeeded., Wondering if MAPREDUCE-2602 is useful here, which lets you set multi-byte record delimiter via {{textinputformat.record.delimiter}} config param., [~ashutoshgupta17@gmail.com],
Are you trying to say we start to Implement "LINES TERMINATED BY" for hive? It is treated as not fixable by 
https://issues.apache.org/jira/browse/HIVE-302
In current hive code, it seems we just error out the line terminator other than \n, and many places just assume the \n is the only line terminator. 
        case HiveParser.TOK_TABLEROWFORMATLINES:
          String lineDelim = unescapeSQLString(rowChild.getChild(0).getText());
          tblDesc.getProperties().setProperty(serdeConstants.LINE_DELIM, lineDelim);
          if (!lineDelim.equals("\n") && !lineDelim.equals("10")) {
            throw new SemanticException(generateErrorMessage(rowChild,
                ErrorMsg.LINES_TERMINATED_BY_NON_NEWLINE.getMsg()));
          }
          break;
But with MAPREDUCE-2602  fixed, it is possible for hive to support changing the line terminator. Just wonder it may not be a easy change.

Thanks., Just found out, in SerDeUtils, escapeString and lightEscapeString use the same way to escape \n and \r as my fix for the issue:

https://github.com/apache/hive/blob/trunk/serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java#L98

https://github.com/apache/hive/blob/trunk/serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java#L129

, Even we will support line terminator other than \n in the future, we have to handle the case when line terminator used in string value. Any suggestions or corrections for my current approach? Or any better ideas? Thanks]