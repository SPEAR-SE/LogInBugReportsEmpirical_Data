[Patch-1: for various places, use utf-8 encoding when writing to output stream. We need to come up with hive specific escape() version since the common one also escapes unicode characters which causes the issue., Hi,

I have stumbled upon your patch, and I think it would be useful to apply your escaping to every comment field, like:

+++ ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java	(revision )
@@ -231,7 +233,7 @@
         appendColumnStatsNoFormatting(colBuffer, "", "", "", "", "", "", "", "");
       }
     }
-    colBuffer.append(comment == null ? "" : comment);
+    colBuffer.append(comment == null ? "" : HiveStringUtils.escapeJava(comment));
     colBuffer.append(LINE_DELIM);
   }
 
@@ -266,7 +268,7 @@
     IndexType indexType = HiveIndex.getIndexTypeByClassName(indexHandlerClass);
     indexColumns.add(indexType.getName());
 
-    indexColumns.add(index.getParameters().get("comment"));
+    indexColumns.add(HiveStringUtils.escapeJava(index.getParameters().get("comment")));
 
     formatOutput(indexColumns.toArray(new String[0]), indexInfo);
 
Regards,
Peter, Thanks Peter for reviewing and suggestion, but we don't want to escape internally while only when we are displaying to UI. I see that I may miss one index comment. I will fix that., Attached patch-2: added unicode support for index comment., Talked to Peter offline. He is investigating escape-specific issues for comments. Will file a separate jira for that since this jira is to handle unicode issue. , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12811140/HIVE-14013.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 10234 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_globallimit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_constantPropagateForSubQuery
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_repair
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_multiinsert
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_unicode_notation
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_table_nonprintable
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testPartitionsCheck
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testTableCheck
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/145/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/145/console
Test logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-145/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12811140 - PreCommit-HIVE-MASTER-Build, Patch-3: to fix one unit test failure. Field delimiter does need to show as unicode. So create separate functions to handle different cases., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12811388/HIVE-14013.3.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 10236 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_globallimit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_constantPropagateForSubQuery
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_repair
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_multiinsert
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_table_nonprintable
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testPartitionsCheck
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testTableCheck
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/168/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/168/console
Test logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-168/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12811388 - PreCommit-HIVE-MASTER-Build, The test failures are not related. [~ychena] Can you help review the code?, Should you do something similar to what it does in ?
{noformat}
 /**
     * Translator object for escaping Java. 
     * 
     * While {@link #escapeJava(String)} is the expected method of use, this 
     * object allows the Java escaping functionality to be used 
     * as the foundation for a custom translator. 
     *
     * @since 3.0
     */
    public static final CharSequenceTranslator ESCAPE_JAVA = 
          new LookupTranslator(
            new String[][] { 
              {"\"", "\\\""},
              {"\\", "\\\\"},
          }).with(
            new LookupTranslator(EntityArrays.JAVA_CTRL_CHARS_ESCAPE())
          ).with(
            UnicodeEscaper.outsideOf(32, 0x7f) 
        );

{noformat}

Just remove last .with(..)  ?, Patch-4: address comments. Use the similar way as common.lang3 does. Included the lib of common.lang3 in pom.xml., patch-4 LGTM, +1 pending on tests, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12813823/HIVE-14013.4.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10274 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_all
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_join
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/279/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/279/console
Test logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-279/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12813823 - PreCommit-HIVE-MASTER-Build, The tests are not related. Pushed to master. Thanks Yongzhi for reviewing., Hi Aihua
According to the status of this bug I think this bug has been resolved in version 2.3.0. However, I downloaded and installed the hive-2.3.0-bin which is released on July 19th 2017, I still hit the problem that 'Describe table doesn't show unicode properly for Chinese comments'. Would you guide me how to check and resolve it ?  
Expect your reply., [~hzfeng] Can you share the repro steps? Meantime I will try out a simple case., hi Aihua
Thanks for your replying;
I downloaded the tar ball from
http://ftp.cuhk.edu.hk/pub/packages/apache.org/hive/hive-2.3.0/apache-hive-2.3.0-src.tar.gz
, extracted and configured it with hadoop-2.7.3. Then I started interacted
hive and created a table with comments in Chinese. When I showed create
table or desc table, I found the comments displayed as ????.
My hive-site.xml is as bellow: please help to check , I am fresh with hive.
=================================================================
<configuration>
<property>
    <name>javax.jdo.option.ConnectionURL</name>

<value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>
    <description>JDBC connect string for a JDBC metastore</description>
</property>
<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
</property>
<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
    <description>username to use against metastore database</description>
</property>
<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
    <description>password to use against metastore database</description>
</property>
<property>
    <name>datanucleus.autoCreateSchema</name>
    <value>true</value>
</property>
<property>
    <name>datanucleus.autoCreateTables</name>
    <value>true</value>
</property>
<property>
    <name>datanucleus.autoCreateColumns</name>
    <value>true</value>
</property>
<!-- 设置 hive仓库的HDFS上的位置 -->
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/hive</value>
    <description>location of default database for the
warehouse</description>
</property>
<!--资源临时文件存放位置 -->
<property>
    <name>hive.downloaded.resources.dir</name>
    <value>/export/servers/software/hive/tmp/resources</value>
    <description>Temporary local directory for added resources in the
remote file system.</description>
 </property>
 <!-- Hive在0.9版本之前需要设置hive.exec.dynamic.partition为true, Hive在0.9版本之后默认为true
-->
<property>
    <name>hive.exec.dynamic.partition</name>
    <value>true</value>
 </property>
<property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
 </property>
<!-- 修改日志位置 -->
<property>
    <name>hive.exec.local.scratchdir</name>
    <value>/export/servers/software/hive/tmp/HiveJobsLog</value>
    <description>Local scratch space for Hive jobs</description>
</property>
<property>
    <name>hive.querylog.location</name>
    <value>/export/servers/software/hive/tmp/HiveRunLog</value>
    <description>Location of Hive run time structured log file</description>
</property>
<property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>/export/servers/software/hive/tmp/OpertitionLog</value>
    <description>Top level directory where operation tmp are stored if
logging functionality is enabled</description>
</property>
<!-- 配置HWI接口 -->
<property>
    <name>hive.server2.thrift.bind.host</name>
    <value>10.186.207.180</value>
</property>
<property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
</property>
<property>
    <name>hive.server2.thrift.http.port</name>
    <value>10001</value>
</property>
<property>
    <name>hive.server2.thrift.http.path</name>
    <value>cliservice</value>
</property>
<!-- HiveServer2的WEB UI -->
<property>
    <name>hive.server2.webui.host</name>
    <value>10.186.207.180</value>
</property>
<property>
    <name>hive.server2.webui.port</name>
    <value>10002</value>
</property>
<property>
    <name>hive.scratch.dir.permission</name>
    <value>755</value>
</property>
<property>
    <name>hive.server2.enable.doAs</name>
    <value>false</value>
</property>
<property>
    <name>hive.auto.convert.join</name>
    <value>false</value>
</property>
<property>
    <name>spark.dynamicAllocation.enabled</name>
    <value>true</value>
    <description>动态分配资源</description>
</property>
<!-- 使用Hive on spark时,若不设置下列该配置会出现内存溢出异常 -->
<property>
    <name>spark.driver.extraJavaOptions</name>
    <value>-XX:PermSize=128M -XX:MaxPermSize=512M</value>
</property>
</configuration>


, The part marked as red should be Chinese characters.
[image: Inline image 1]


, Reporter (fenghaizhu) does not have permission to create attachments in project HIVE. Following attachments found in the email have been discarded:
 - image.png, [~fenghaizhu] I can't see your attachment. But I tried simple test and it works fine.

{noformat}
hive> desc unicode_comments_tbl1;
OK
col1                    string                  第一列                 
p1                      string                  分割                  
                 
# Partition Information          
# col_name              data_type               comment             
                 
p1                      string                  分割        
{noformat}, Thanks a lot
Is it convenient for guiding me how you configured hive-2.3.0?
I will be appreciate.
, [~hzfeng] Sorry for the late reply. I didn't do any configuration change. What I did is just build hive and create a table with unicode in the comment. ]