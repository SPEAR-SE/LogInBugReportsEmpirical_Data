[I like it. Sounds like this will allow you to be more aggressive with caching/flushing params, while having a trigger that will flush out stuff when necessary.

+1 (assuming tests pass), Yes, also the ORC scenario is more complex for strings in dictionaries. 

A substring does not drop the rest of the data off the memory overhead because in vectorized mode, only the start:len get modified, no new allocations are made.

So a group by SUBSTR() will keep the entire string in  memory, except the VGBY does not know that it does., Can you somehow modify the LOG.debug at top of flush() to call out that the flush was triggered by the gcCanary.get() == null? I was thinking: keep a count of gcCanary allocations and print it in the LOG.debug message, this will tell us if the GC is the trigger and also will tell how often has occured in the operator lifetime, when debugging etc.
+1, Add DEBUG lines, Reuploading .2 for precommit., Resubmit for pre-commit tests, pre-commit is back. let's try again., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12634401/HIVE-6518.3.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 5389 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_auto_sortmerge_join_16
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucketmapjoin6
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1769/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1769/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12634401, The test failures don't seem to be related to this fix - they aren't vectorized., I have committed this trunk. Thanks to Gopal!

[~rhbutani] This is an important fix to vector group by because the aggregates must flush more aggressively in case of GC. Therefore, I intend to commit it to branch-0.13. as well., +1 for port to 0.13, Committed to branch-0.13 as well. ]