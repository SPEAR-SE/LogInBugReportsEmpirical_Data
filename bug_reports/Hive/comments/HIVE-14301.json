[ Both destPath & destFile are serving same purpose. You may want to get rid of one of those to simplify this., sorry.. my bad.. i read it wrong. +1, I worry about the code assuming that the return code of rename() is relevant. It's one of the key bits of API ambiguity, where HDFS sometimes behaves differently from Posix filesystems â€”nobody knows quite what to do. I'd rely on the filesystems throwing an exception if something serious went wrong, and just logging at warn here. , Pushed to master & branch-2.1 Thanks, Rajesh!, Hey [~rajesh.balamohan] I was testing this and found that the query still fails if the table is created in the root directory of the bucket (at s3://bucket-name/). I don't know how common of a use case that is, but thought I'd mention it., what's the stack trace?, not a complete stack trace (will post as soon as I locate the log file), but here's the output from running the query:
{noformat}
hive> insert overwrite table s3dummy values (1);
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = abdullah.yousufi_20160721114424_4c7b2d9d-88de-44f3-b2a1-ebc715e2dcbf
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Job running in-process (local Hadoop)
2016-07-21 11:44:32,888 Stage-1 map = 0%,  reduce = 0%
2016-07-21 11:44:36,906 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1593349645_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory s3a://dev-ayousufi/.hive-staging_hive_2016-07-21_11-44-24_590_2809548621359300870-1/-ext-10000
Loading data to table default.s3dummy
Failed with exception Error moving: s3a://dev-ayousufi/.hive-staging_hive_2016-07-21_11-44-24_590_2809548621359300870-1/-ext-10000 into: s3a://dev-ayousufi/
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask. Error moving: s3a://dev-ayousufi/.hive-staging_hive_2016-07-21_11-44-24_590_2809548621359300870-1/-ext-10000 into: s3a://dev-ayousufi/
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 5 HDFS Write: 5 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
{noformat}, {noformat}
2016-07-21T12:16:55,698 ERROR [515de560-6446-44e6-a9f3-c53dc628e357 main] exec.Task: Failed with exception Error moving: s3a://dev-ayousufi/.hive-staging_hive_2016-07-21_12-16-28_703_1653610595303080982-1/-ext-10000 into: s3a://dev-ayousufi/
org.apache.hadoop.hive.ql.metadata.HiveException: Error moving: s3a://dev-ayousufi/.hive-staging_hive_2016-07-21_12-16-28_703_1653610595303080982-1/-ext-10000 into: s3a://dev-ayousufi/
	at org.apache.hadoop.hive.ql.metadata.Hive.replaceFiles(Hive.java:3248)
	at org.apache.hadoop.hive.ql.metadata.Hive.loadTable(Hive.java:1817)
	at org.apache.hadoop.hive.ql.exec.MoveTask.execute(MoveTask.java:356)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:197)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1870)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1574)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1326)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1095)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1083)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:232)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:183)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:399)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:776)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:714)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
Caused by: java.io.IOException: Error moving: s3a://dev-ayousufi/.hive-staging_hive_2016-07-21_12-16-28_703_1653610595303080982-1/-ext-10000 into: s3a://dev-ayousufi/
	at org.apache.hadoop.hive.ql.metadata.Hive.replaceFiles(Hive.java:3238)
	... 21 more

2016-07-21T12:16:55,698 ERROR [515de560-6446-44e6-a9f3-c53dc628e357 main] ql.Driver: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask. Error moving: s3a://dev-ayousufi/.hive-staging_hive_2016-07-21_12-16-28_703_1653610595303080982-1/-ext-10000 into: s3a://dev-ayousufi/
{noformat}, [~stevel@apache.org]

The issue is that line 672 of S3AFileSystem.java returns false in the innerRename function since the dstKey is "":
{code}
if (srcKey.isEmpty() || dstKey.isEmpty()) {
  LOG.debug("rename: source {} or dest {}, is empty", srcKey, dstKey);
  return false;
}
{code}

Is there a reason for this check, especially with regards to the destination key?
, [~ayousufi] - Thanks for sharing the details. If table points to root in the bucket, it will be replaced completely when someone runs a "insert overwrite" and the rest of the contents could be lost from root (if any).  Need to check if this needs to be fixed in S3A, but from hive side this might not be common scenario IMHO., [~ayousufi], thank you for pointing out the issue with rename to root.  I'm going to propose that we change that behavior in S3A within scope of an issue I just filed: HADOOP-13402.  I think this is simply pre-validation logic that didn't fully consider the case of renaming to root.

I agree with Rajesh that it isn't a common case, but I'd still like to fix it in S3A for the sake of consistency in semantics., Doc note:  This changes the default value of *hive.mv.files.thread* (created by HIVE-12988 and modified by HIVE-13933 and HIVE-13984, all in release 2.1.0) so it will need to be documented in the wiki for release 2.1.1.

* [Configuration Properties -- Query and DDL Execution | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-QueryandDDLExecution]
* [DDL -- Recover Partitions (MSCK REPAIR TABLE) | https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-RecoverPartitions(MSCKREPAIRTABLE)]

Added a TODOC2.1.1 label., Hey, how can I get this patch into my environment (Amazon EMR service) ? The S3-link is super to have, and seems very broken right now., Hey [~dan0704090017@hotmail.com],

Recommend you ask questions like these on the AWS Forum [1], you'll get better answers there. Especially because EMR is a managed service, the Hive community won't be able to help as well as EMR themselves.

[1] https://forums.aws.amazon.com/index.jspa]