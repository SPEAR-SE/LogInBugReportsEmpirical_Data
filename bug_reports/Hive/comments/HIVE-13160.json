[I will take a look at the issue., Attached the patch-1: we will  throw the exception when function registering fails and the caller can decide to rethrow or consume it. The HiveServer will be notified and attempt to restart. 
 , [~sershe] Can you take a look at the change since you added the logic? I'm wondering if you are expecting other places to use registerAllFunctionsOnce(). Seems to me we should only call it once when the server starts., I only added the safety logic, not the original logic ;) 
The state still needs to be changed, otherwise as far as I see that will just leave it "in progress". 
Also, would someone register them later, even if the state is updated back to not-started?, Updated the patch-2 so if it fails the state will be marked as NO so HiveServer will attempt to register again and  start.

Thanks for the info. :) If start is updated to NO somehow, it will be reregistered.

I was a little concerned about the comment you put and kind of scared of making the change. :). We don't care about which metastore we are talking to since it's retrieving the data from the database, right?

{noformat}
  // Note that while this is an improvement over static initialization, it is still not,
  // technically, valid, cause nothing prevents us from connecting to several metastores in
  // the same process. This will still only get the functions from the first metastore.
{noformat}

, The second patch looks good.
+1, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12790232/HIVE-13160.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 24 failed/errored test(s), 9829 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.org.apache.hadoop.hive.cli.TestMiniTezCliDriver
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket4
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_having
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_insert_into2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mrr
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge_incompat2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_orc_vec_mapwork_part
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_dynpart_hashjoin_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_bucket
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_outer_join5
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_varchar_simple
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorization_short_regress
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_windowing_gby
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.createTable
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.insertOverwriteCreate
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testDummyTxnManagerOnAcidTable
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testLockRetryLimit
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.updateSelectUpdate
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7116/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7116/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7116/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 24 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12790232 - PreCommit-HIVE-TRUNK-Build, I was referring to a hypothetical scenario with multiple metastores with different DBs, that probably only happens on a dev cluster where I was running my own metastore and there were multiple configs coming from different places.

+1 on the 2nd patch. Can you check if test failures are related? They look unrelated to me., Don't look related to the change. Also tried some tests locally and they passed. , Pushed to master. Thanks to Yongzhi and Sergey for reviewing., This breaks compatibility when running CLI with old HMS. Earlier this exception was ignored by CLI when session is started but now it throws. I am not sure what the expected behavior here is, should the new clients (> 2.0) be compatible with old HMS?, [~prasanth_j] Can you clarify the incompatibility issue a little bit more? Does this only happen to CLI? Does it only happen to old HMS? 

With the patch hive will start when we have a functional HMS, allowing us to load the functions. Before, we will ignore the failure and continue but we would have issues later when we executing the queries since HMS is not ready. , [~aihuaxu] I have a setup that runs 1.2.0 version of HMS. Last week I was able to run latest 2.1.0-SNAPSHOT CLI client with 1.2.0 HMS. The thrift service of 1.2.0 does not have get_all_functions interface. When the cli starts a session, it will internally invoke registerAllFunctionOnce which in turn calls getAllFunctions(). Since getAllFunctions() does not exist in old HMS it will throw an error which will be ignored. This will let CLI start (and Session) without any issues. With this patch registerAllFunctionOnce() throws exception will not be caught by the CLI and fails to start. This means that new clients cannot work with old HMS. Following is the full stacktrace

{code}
Exception in thread "main" java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.thrift.TApplicationException: Invalid method name: 'get_all_functions'
at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:563)
at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:503)
at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:709)
at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:645)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:497)
at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.thrift.TApplicationException: Invalid method name: 'get_all_functions'
at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:211)
at org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:341)
at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:296)
at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:266)
at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:251)
at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:530)
... 9 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.thrift.TApplicationException: Invalid method name: 'get_all_functions'
at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3414)
at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:221)
at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:206)
... 14 more
Caused by: org.apache.thrift.TApplicationException: Invalid method name: 'get_all_functions'
at org.apache.thrift.TApplicationException.read(TApplicationException.java:111)
at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:79)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_all_functions(ThriftHiveMetastore.java:3490)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_all_functions(ThriftHiveMetastore.java:3478)
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getAllFunctions(HiveMetaStoreClient.java:2172)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:497)
at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:153)
at com.sun.proxy.$Proxy28.getAllFunctions(Unknown Source)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:497)
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2109)
at com.sun.proxy.$Proxy28.getAllFunctions(Unknown Source)
at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3411)
{code}, cc/ [~sershe], Yeah that might actually be a good idea to fix this. In fact, it doesn't make sense to retry later if it's throwing the Invalid method name error. It could be done in a separate JIRA., I see.

So if that's the case and we couldn't register all the functions, then later the queries with the functions would fail, right?  How do you register the functions for that scenario? 

, I am not sure how we were doing it before. I have to dig it up. [~sershe] do you know how it was done before when getAllFunctions failed and how the registration of functions happened?, [~prasanth_j] Can you file a followup jira and link to this one? It makes sense to me for HS2 to talk to newer version of HMS, not the lower version. But maybe I missed some use cases and let's discuss there., Well, backward compat is also important for HS2 (and cli), Sure. Do you know how we load all the functions for such scenario?, I met this issue these days when I was trying to upgrade hive from 1.2.1 to 2.1.0. Do you have a good solution to help hive 2.1.0 read metadata from hive 1.2.1 metastore?, To me, it may not be reasonable to keep the backward compatibility, such as HS2 2.1 to HMS1.2.1 since HMS1.2.1 may miss some APIs which HS2 2.1.0 are using.  Even if we let HS2 start, we still can't use UDFs e.g. 

So I think you need to upgrade both HMS and HS2.]