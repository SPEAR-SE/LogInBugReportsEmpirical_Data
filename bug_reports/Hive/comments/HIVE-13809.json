[[~wzheng]: before we actually subtract such a large amount of memory from the join algorithms, maybe we should figure out the input parameters to the bloom filter creation.

The reason it wasn't accounted for strictly was because of the relatively small size of bloom filters - a 4 million keyset with 0.5% false positive rate should result in a bloom filter which is approx ~6Mb.

Would be a good idea to figure out the false positive rate + estimated key count of the bloom filter which grew to hundreds of Mbs and see if there's an implementation issue there., [~gopalv] Sure, thanks for your input. Here's the snippet from application log. It can be seen in this case we got 266 million keys, thus 207 MB for bloom filter.
{code}
2016-05-20 11:29:56,600 [INFO] [pool-17-thread-2] |persistence.HybridHashTableContainer|: Total available memory: 2115483632
2016-05-20 11:29:56,601 [INFO] [pool-17-thread-2] |persistence.HybridHashTableContainer|: Estimated small table size: 1600000000
2016-05-20 11:29:56,601 [INFO] [pool-17-thread-2] |persistence.HybridHashTableContainer|: Number of hash partitions to be created: 16
2016-05-20 11:29:56,614 [INFO] [TezChild] |vector.VectorGroupByOperator|: VectorGroupByOperator is vector output false
2016-05-20 11:29:56,617 [INFO] [TezChild] |exec.ReduceSinkOperator|: Initializing operator RS[44]
2016-05-20 11:29:56,620 [INFO] [TezChild] |exec.ReduceSinkOperator|: Using tag = -1
2016-05-20 11:29:56,780 [INFO] [pool-17-thread-2] |persistence.HybridHashTableContainer|: Using a bloom-1 filter 266666672 keys of size 207840816 bytes
{code}, {{1,600,000,000}} doesn't look like a good scenario to fix around for a map-join.

Back of the envelope, 1.6 billion keys in a 2Gb hashtable comes down to <2 bytes per key, which is obvious going to OOM there, even divided by 16 (i.e 32 bytes per key+value).

I suspect the root issue has more to do with the statistics involved here, which might be completely bogus. 

Ideally, we should be capping the bloom filter estimates at 4 million keys, which is nearly the probe limit of useful hashtables - any real data-set bigger than 4M, the total number of rehashes at 2Gb will also OOM the hashtables.

So in this scenario, I'm nearly convinced that the 1.6 billion number is bogus or bad planning., OK, agree. Btw,
{code}
Estimated small table size: 1600000000
{code}
This is data size (in bytes), not number of keys. Estimated number of keys is 266666672 (still a big number)., Removing 2.1.0 target as issue is not tagged as Critical/Blocker and the RC will be created tomorrow. Please feel free to commit to branch-2.1 anyway and fix for 2.1.0 if this happens before the release., This ticket depends on HIVE-13934's work, [~gopalv] Can you take a look?, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12811158/HIVE-13809.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 10233 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_globallimit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_repair
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_multiinsert
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_table_nonprintable
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testPartitionsCheck
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testTableCheck
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/148/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/148/console
Test logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-148/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12811158 - PreCommit-HIVE-MASTER-Build, list_bucket_dml_12 failure is irrelevant. It passes locally., LGTM - +1.

The bloom filter sizing needs a revisit, since this is pre-allocated based on estimates, not on real row-counts - allowing more false positives at higher cardinalities, to keep the memory utilization under check., Thanks [~gopalv] for the review. Committed to master and branch-2.1.]