[I dig it a little bit further. And I think it may not be a issue in UT. This bug may affect the users who use protobuf 2.5.0 generated code in hive.

The root case of this bug is that the auto generated java code in protobuf 2.5.0 is totally different from 2.4.x.
If a struct field is of string type, in 2.4.x, The generate code is like
{code}
private java.lang.String aString_ = "";
{code}
But in 2.5.0, the code is like
{code}
private java.lang.Object aString_;
{code}
And then, the inspector of class type Object is "UNKNOWN". So the exception is thrown., I just added the following to HIVE-5112, but it seems like this issue is a better place to track the incompatibility between hadoop and hive with respect to protocol buffers:

The hive downloads page says that hive-0.12.0 is compatible with hadoop-2.x.y . However, I have hive-0.12.0 installed with hadoop-2.2.0 and I get the same error that Abin Shahab has. I noticed that if I moved all the protobuf-java-2.5.0.jar files under hadoop's lib dirs to protobuf-java-2.5.0.jar.bak, then I didn't get the error.

It looks like protobuf 2.5.0 is not compatible with generated code from 2.4.1, and if I move all of the newer jars out of the way, then the protobuf-java-2.4.1.jar file is found under hive's lib dir.

I think there needs to be a new release (0.12.1 or 0.13.0) with the upgrade to protobuf-2.5.0 and/or the compatibility note on the downloads page needs to be adjusted.]