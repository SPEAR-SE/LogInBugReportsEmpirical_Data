[[~xuefuz] - Seems this JIRA gets assigned to you automatically :), No problem, I was using it for testing the build, which we are having problems with. Yes, this seems to be a problem that also needs to be fixed., [~chengxiang li], any idea why this is happening? Could you quickly check if there is any easy fix? Thanks!, [~xuefuz], due to the limitation of Spark accumulator, the `SparkCounter` has to register the counter name before the job execution. The error message shows that specified counter name is not registered before. In default, all the default spark counters are collected with `SparkTask::getCounterPrefixes()`, `RECORDS_OUT_0`, `RECORDS_OUT_1_default.tmp_tmp` and `RECORDS_OUT_1_default.test_table` are not included, seems the counter logic changes in `ReduceSinkOperator` and 'FileSinkOperator', we need to update the logic of `SparkTask::getOperatorCounters`. , Hive support multiple insert
{noformat}
 from (select * from dec union all select * from dec2) s
insert overwrite table dec3 select s.name, sum(s.value) group by s.name
insert overwrite table dec4 select s.name, s.value order by s.value;
{noformat}
In order to distinguish records out for different table,Hive use  RECORDS_OUT + suffix for counters key in FileSinkOperator.
{noformat}
statsMap.put(Counter.RECORDS_OUT + "_" + suffix, row_count);
{noformat}, Yeah they're appending suffix to the counter name now. Maybe we can initialize the counter in the same way. I think the suffix is available in the operator conf., Yes, [~lirui], the suffix is available in the operator conf. As recently i didn't work on HoS, it would take some time to prepare a test environment, do you mind to give a quick fix on this issue? i can do the review work., Sure. Assigned this to me., LGTM, wait for the testing., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12773993/HIVE-12466.1-spark.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 9788 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_rp_annotate_stats_groupby
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_constantPropagateForSubQuery
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority2
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/1011/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/1011/console
Test logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-1011/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12773993 - PreCommit-HIVE-SPARK-Build, Thanks to Rui/Chengxiang for working on this. I happened to see that counter-based stats gathering is completely removed by HIVE-12411. I'd like to knows its implications. Does it mean that we don't even need SparkCounter at all? Are there any impacts on Spark regarding stats collection with the removal. Thanks., SparkCounters is only used for stats collection now, so yes, i think we may not need SparkCounters anymore if counter-based stats collection is removed. As far as i know, there is no other Hive features which depends on SparkCounters., If spark counter is removed, does HoS support other methods to collect stats, like fs-based?, Yes, it does, at least at the time i implemented the counter-based stats collection for Spark, it does not relate to any part of our work on HoS, so i assume it should work just as well now., Thanks, guys. Let's get this in and uses a separate JIRA to do the cleanup., Committed to spark branch, thanks Rui for this contribution., HIVE-12515 is created for the following cleanup work.]