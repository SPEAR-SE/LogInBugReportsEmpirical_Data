[Attached the patch, Another interesting piece. If we can write the entire configuration to a file it might make more sense to deprecate the passing individual elements entirely., Thanks Edward, I thought of removing the arguments option completely, but I felt that it can introduce a small perf hit on Linux unnecessarily as we are creating/deleting a temp files for every task execution. If we feel that this perf hit is negligible then I will remove the arguments option.
Thanks
, I vote we remove the arguments options entirely. Unix/Linux has the same max command line argument issue although people hit it less frequently because it is larger. We do not need two code paths and the performance of writing a file is nothing compared to overall mr time., Hive-3127.2.patch.txt – Removed the arguments option completely so have the same logic for Windows & Linux.

Unit Tests – Existing units will cover this scenarios completely.
, @Kanna: please post a review request on reviews.apache.org. Thanks., Thanks Carl. Submittied the code review.

https://reviews.apache.org/r/5491/
, Kanna,

Your missing something. The BlockMergeTask ask uses -jobconf  . You will need to patch that as well.

[edward@tablitha trunk]$ grep -R '\-jobconf' ./*

{noformat}
./ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java:        } else if (args[i].equals("-jobconf")) {
{noformat}, Thanks Edward, I will look into it. I wonder how I got 100% test pass. It looks like there are no unit tests to test this scenario  or they are passing with default conf values. 
Can you please suggest a query to create a unit test for this?
Thanks, Welcome to hive :) I am willing to bet we only hit the block merge if the input is larger then hdfs blocks size, or the defaults is high and it normally does not happen during the course of the unit tests., Updated the patch with modifications to BlockMergeTask.
, @Edward - Thanks for helping me understand the hive better. I couldn’t figure out the caller of for BlockMergeTask::main anywhere in the code. Thanks.
, So I have found a reference to BlockMergeTask in ./ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java . 

Also the last release note was. ./build/dist/RELEASE_NOTES.txt:    * [HIVE-2413] - BlockMergeTask ignores client-specified jars

vi ./ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java

You could be correct in that the main is unreachable now. Maybe someone added it as a hack for direct testing, it would be good to cut-it from the code if it is not reachable. Maybe one of the other devs will chime in.

If not one else has any insight I will review and +1 tomorrow.
, Thanks Edward., Committed. Thank you. , Integrated in Hive-trunk-h0.21 #1517 (See [https://builds.apache.org/job/Hive-trunk-h0.21/1517/])
    HIVE-3127 Pass hconf values as XML instead of command line arguments to child JVM. Kanna Karanam (via egc) (Revision 1354781)

     Result = FAILURE
ecapriolo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1354781
Files : 
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java
, Integrated in Hive-trunk-hadoop2 #54 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/54/])
    HIVE-3127 Pass hconf values as XML instead of command line arguments to child JVM. Kanna Karanam (via egc) (Revision 1354781)

     Result = ABORTED
ecapriolo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1354781
Files : 
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java
, This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.]