[Looks like this is due to MAPREDUCE-5756.  In the test case, when getSplits() is called on /, it returns InputSplits for the folllowing paths:

/000000_0
/Users/
/build/
/tmp/
/user/

Whereas in hadoop-1 it only used to return:

/000000_0

The query execution seems to expect the InputSplits to be files, and not directories.  

Stack trace for listStatus() was:
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:272)
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:217)
org.apache.hadoop.mapred.lib.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:75)
org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:343)
org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:309)
org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:427)
org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:520)
org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:512)
org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:394)
org.apache.hadoop.mapreduce.Job$10.run(Job.java:1285)
org.apache.hadoop.mapreduce.Job$10.run(Job.java:1282)
java.security.AccessController.doPrivileged(Native
javax.security.auth.Subject.doAs(Subject.java:396)
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
org.apache.hadoop.mapreduce.Job.submit(Job.java:1282)
org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:562)
org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:557)
java.security.AccessController.doPrivileged(Native
javax.security.auth.Subject.doAs(Subject.java:396)
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:557)
org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:548)
org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:419)
org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:136)
org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1548)
org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1321)
org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1152)
org.apache.hadoop.hive.ql.Driver.run(Driver.java:992)
org.apache.hadoop.hive.ql.Driver.run(Driver.java:982)
org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:268)
org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:220)
org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:424)
org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:359)
org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:907)
org.apache.hadoop.hive.cli.TestMinimrCliDriver.runTest(TestMinimrCliDriver.java:133)
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table(TestMinimrCliDriver.java:117)]