[{code}
2017-03-05T12:37:46,379  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = dt
2017-03-05T12:37:46,379  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = '2001-01-01'
2017-03-05T12:37:46,379  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = (dt = '2001-01-01')
2017-03-05T12:37:46,380  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = 1
2017-03-05T12:37:46,380  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = (null = 1)
2017-03-05T12:37:46,380  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = ((dt = '2001-01-01') and (null = 1))
2017-03-05T12:37:46,380  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = false
2017-03-05T12:37:46,380  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = NVL(((dt = '2001-01-01') and (null = 1)),false)
2017-03-05T12:37:47,153  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = dt
2017-03-05T12:37:47,153  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = '2001-01-01'
2017-03-05T12:37:47,153  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = (dt = '2001-01-01')
2017-03-05T12:37:47,153  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = null
2017-03-05T12:37:47,153  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = ((dt = '2001-01-01') and null)
2017-03-05T12:37:47,153  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = false
2017-03-05T12:37:47,153  WARN [6f053d71-6ad6-4ad0-833d-337f2d499c82 main] ppr.PartitionPruner: The expr = NVL(((dt = '2001-01-01') and null),false)
{code}, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12856193/HIVE-16113.1.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 10324 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=229)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[pcr] (batchId=55)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[push_or] (batchId=15)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cbo_rp_views] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cbo_views] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_table] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[special_character_in_tabnames_1] (batchId=147)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=224)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[pcr] (batchId=120)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=231)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3953/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3953/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3953/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 11 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12856193 - PreCommit-HIVE-Build, +1 assuming tests are unrelated, The test failures are related - looks like some of the existing golden files are broken plans too.

Will update them after reviewing., -1 on this approach for now - the TRUE constants are actually messing up the PartitionConditionRemover which removes entire expressions.

(partcol = 1 or col < 5) -> (partcol = 1 or false) -> (false), [~rusanu] You were working on this part of code recently.  Would you like to take a look at this one?, I think the issue is that the partition pruning logic expects {{null}} values to percolate through the expression tree and trigger the {{isUnknown}} case in {{PartitionPrunner.prunePartitionNames}}. But expressions like CASE, COALESCE or NVL (maybe other?) stop null bubbling and can evaluate the tree to a resolute {{false}} instead, causing overaggressive partition elimination. If the expression has these functions (NVL, COALESCE) to handle {{null}} values at a *row* level we're evaluating them and taking a decision at *partition* level (prune/not prune), and the 'prune' case is not safe. Perhaps we should consider functions like NVL/COALESCE 'special' and inject 'true' instead in the pruning expression? , {{OR}}: the partition pruner is reducing the expression to {{partcol = 1}} and this reduces the list of partitions retrieved from MD:
{code}
    ppList = getPartitionsFromServer(tab, (ExprNodeGenericFuncDesc)compactExpr, conf, alias, partColsUsedInFilter, oldFilter.equals(compactExpr.getExprString()));
{code}
By now things are already broken, but later the reduced partition list causes the {{PcrExprProcFactory.GenericFuncExprProcessor.handleUdfOr}} to see a definite TRUE instead of a correct DIVIDE (since the filter expression is only evaluated against a reduced list of partitions) and thus cause the {{PartitionConditionRemover}} to remove the entire Filter. , I don't think we should handle OR in removeNonPartCols, leaving it as NULL to bubble behaves correctly. I made that change and tested it, all good. 

But the NVL/COALESCE/CASE is trickier. I can write a filter like
{code}
where colpart=1 or col < 5
{code}
and works correct, but wrap it in an NVL:
{code}
where NVL(colpart=1 or col < 5, false)
{code}
and the result is no longer correct because the NULL is being replaced  with FALSE and this causes overaggressive partition pruning. My plan is to have these UDFs (NVL/COALESCE) replaced with NULL in the pruning expr tree., bq. My plan is to have these UDFs (NVL/COALESCE) replaced with NULL in the pruning expr tree.

Any UDF which gets a NULL arg because of a non-partition column can be replaced with NULL, right? 

That might be better instead of special-casing built-in UDFs?, Patch 2 makes any function that has any argument NULL transform into NULL, for the purpose of partition pruning logic. Only {{partcol AND NULL}} is replaced with {{partcoll AND TRUE}}., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12867771/HIVE-16113.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10700 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_windowing2] (batchId=10)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_3] (batchId=97)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=97)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5232/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5232/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5232/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12867771 - PreCommit-HIVE-Build, +1, Patch.3 rebased to current master for new test run, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12869114/HIVE-16113.3.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10741 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_3] (batchId=97)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=97)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5368/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5368/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5368/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12869114 - PreCommit-HIVE-Build, PAtch.4 add the explainuser_3/analyze_3 GF diff (altough they're gen 88)., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12869132/HIVE-16113.4.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10741 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[named_column_join] (batchId=72)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=144)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5371/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5371/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5371/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12869132 - PreCommit-HIVE-Build, Resolved via https://git-wip-us.apache.org/repos/asf?p=hive.git;a=commit;h=5f4eaa9b13e7beec8bb16fea94fec386e2bc1e00, Hive 3.0.0 has been released so closing this jira.]