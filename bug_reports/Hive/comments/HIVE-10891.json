[It seems that the [SimpleFetchOptimizer|https://github.com/apache/hive/blob/branch-1.1/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SimpleFetchOptimizer.java] acts a little bit to aggressive here. From my understanding of the code there's a check if the filter only affects columns that are partition keys. In this case the threshold check is bypassed (see [line 147 of SimpleFetchOptimizer|https://github.com/apache/hive/blob/branch-1.1/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SimpleFetchOptimizer.java#L147]). In the upper query, we filter on a different column, nevertheless the filter is bypassed due to [these lines|https://github.com/apache/hive/blob/branch-1.1/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SimpleFetchOptimizer.java#L200]:
{code:java}
if (PartitionPruner.onlyContainsPartnCols(table, pruner)) {
    bypassFilter = !pctx.getPrunedPartitions(alias, ts).hasUnknownPartitions();
}
{code}

A workaround seems to be, to put the optimizer on a leash by setting 

{code:xml}
<property>
    <name>hive.fetch.task.conversion</name>
    <value>minimal</value>
</property>
{code}]