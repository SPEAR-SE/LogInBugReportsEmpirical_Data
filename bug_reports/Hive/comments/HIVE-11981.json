[Give latest version a spin., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12765768/HIVE-11981.01.patch

{color:green}SUCCESS:{color} +1 due to 7 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 9662 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_nonvec_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_non_string_partition
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_partitioned_date_time
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_windowing_streaming
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_join_hash
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_leftsemi_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_ptf
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5598/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5598/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5598/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12765768 - PreCommit-HIVE-TRUNK-Build, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12766101/HIVE-11981.02.patch

{color:green}SUCCESS:{color} +1 due to 7 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 16 failed/errored test(s), 9665 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_int_type_promotion
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_join_partition_key
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_auto_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_bucketmapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_windowing_streaming
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_join_hash
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_auto_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_leftsemi_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5619/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5619/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5619/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12766101 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12766480/HIVE-11981.03.patch

{color:green}SUCCESS:{color} +1 due to 7 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 19 failed/errored test(s), 9686 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_ppr_all
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_windowing_streaming
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_tez_join_hash
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_join_hash
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_leftsemi_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBase
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5646/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5646/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5646/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 19 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12766480 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12766709/HIVE-11981.05.patch

{color:green}SUCCESS:{color} +1 due to 15 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 9704 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_orc_nonvec_fetchwork_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_orc_nonvec_mapwork_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_orc_vec_mapwork_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_nonvec_fetchwork_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_nonvec_mapwork_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_ppr_all
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5662/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5662/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5662/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12766709 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12767005/HIVE-11981.06.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5691/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5691/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5691/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-5691/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at ec07664 HIVE-12083 : HIVE-10965 introduces thrift error if partNames or colNames are empty (Sushanth Sowmyan, reviewed by Thejas Nair)
+ git clean -f -d
+ git checkout master
Already on 'master'
+ git reset --hard origin/master
HEAD is now at ec07664 HIVE-12083 : HIVE-10965 introduces thrift error if partNames or colNames are empty (Sushanth Sowmyan, reviewed by Thejas Nair)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file itests/src/test/resources/testconfiguration.properties
patching file llap-server/src/java/org/apache/hadoop/hive/llap/io/api/impl/LlapInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordProcessor.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorExtractRow.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorMapJoinBaseOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorSMBMapJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizationContext.java
Hunk #7 succeeded at 1043 (offset 1 line).
Hunk #8 succeeded at 2349 (offset 2 lines).
Hunk #9 succeeded at 2464 (offset 2 lines).
Hunk #10 succeeded at 2490 (offset 2 lines).
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizedBatchUtil.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizedRowBatchCtx.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/mapjoin/VectorMapJoinCommonOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/AcidInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/IOConstants.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/VectorizedRCFileInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/VectorizedRCFileRecordReader.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/ConversionTreeReaderFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
Hunk #1 succeeded at 1066 (offset 4 lines).
Hunk #2 succeeded at 1394 (offset 7 lines).
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRawRecordMerger.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/Reader.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/ReaderImpl.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/SchemaEvolution.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/TreeReaderFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowReader.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/ReaderImpl.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/parquet/VectorizedParquetInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/SimpleFetchOptimizer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
Hunk #6 succeeded at 314 (offset 1 line).
Hunk #7 succeeded at 396 (offset 1 line).
Hunk #8 succeeded at 410 (offset 1 line).
Hunk #9 succeeded at 767 (offset 1 line).
Hunk #10 succeeded at 784 (offset 1 line).
Hunk #11 succeeded at 796 (offset 1 line).
Hunk #12 succeeded at 832 (offset 1 line).
Hunk #13 succeeded at 843 (offset 1 line).
Hunk #14 succeeded at 855 (offset 1 line).
Hunk #15 succeeded at 885 (offset 1 line).
Hunk #16 succeeded at 896 (offset 1 line).
Hunk #17 succeeded at 911 (offset 1 line).
Hunk #18 succeeded at 981 (offset 1 line).
Hunk #19 succeeded at 1054 (offset 1 line).
Hunk #20 succeeded at 1076 (offset 1 line).
Hunk #21 succeeded at 1117 (offset 1 line).
Hunk #22 succeeded at 1127 (offset 1 line).
Hunk #23 succeeded at 1147 (offset 1 line).
Hunk #24 succeeded at 1215 (offset 1 line).
Hunk #25 succeeded at 1769 (offset 1 line).
Hunk #26 succeeded at 2127 (offset 1 line).
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java.orig
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
1 out of 1 hunk ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java.orig.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/BaseWork.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/VectorPartitionConversion.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/VectorPartitionDesc.java
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorRowObject.java
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorSerDeRow.java
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorizedRowBatchCtx.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcRawRecordMerger.java
patching file ql/src/test/queries/clientpositive/schema_evol_orc_acid_mapwork_part.q
patching file ql/src/test/queries/clientpositive/schema_evol_orc_nonvec_fetchwork_part.q
patching file ql/src/test/queries/clientpositive/schema_evol_orc_nonvec_fetchwork_table.q
patching file ql/src/test/queries/clientpositive/schema_evol_orc_nonvec_mapwork_part.q
patching file ql/src/test/queries/clientpositive/schema_evol_orc_nonvec_mapwork_table.q
patching file ql/src/test/queries/clientpositive/schema_evol_orc_vec_mapwork_part.q
patching file ql/src/test/queries/clientpositive/schema_evol_orc_vec_mapwork_table.q
patching file ql/src/test/queries/clientpositive/schema_evol_text_nonvec_fetchwork_part.q
patching file ql/src/test/queries/clientpositive/schema_evol_text_nonvec_fetchwork_table.q
patching file ql/src/test/queries/clientpositive/schema_evol_text_nonvec_mapwork_part.q
patching file ql/src/test/queries/clientpositive/schema_evol_text_nonvec_mapwork_table.q
patching file ql/src/test/results/clientpositive/schema_evol_orc_acid_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/schema_evol_orc_nonvec_fetchwork_part.q.out
patching file ql/src/test/results/clientpositive/schema_evol_orc_nonvec_fetchwork_table.q.out
patching file ql/src/test/results/clientpositive/schema_evol_orc_nonvec_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/schema_evol_orc_nonvec_mapwork_table.q.out
patching file ql/src/test/results/clientpositive/schema_evol_orc_vec_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/schema_evol_orc_vec_mapwork_table.q.out
patching file ql/src/test/results/clientpositive/schema_evol_text_nonvec_fetchwork_part.q.out
patching file ql/src/test/results/clientpositive/schema_evol_text_nonvec_fetchwork_table.q.out
patching file ql/src/test/results/clientpositive/schema_evol_text_nonvec_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/schema_evol_text_nonvec_mapwork_table.q.out
patching file ql/src/test/results/clientpositive/stats_ppr_all.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_orc_acid_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_orc_nonvec_fetchwork_part.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_orc_nonvec_fetchwork_table.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_orc_nonvec_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_orc_nonvec_mapwork_table.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_orc_vec_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_orc_vec_mapwork_table.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_text_nonvec_fetchwork_part.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_text_nonvec_fetchwork_table.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_text_nonvec_mapwork_part.q.out
patching file ql/src/test/results/clientpositive/tez/schema_evol_text_nonvec_mapwork_table.q.out
patching file storage-api/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizedRowBatch.java
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12767005 - PreCommit-HIVE-TRUNK-Build, Didn't build -- rebase and try again., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12767233/HIVE-11981.07.patch

{color:green}SUCCESS:{color} +1 due to 15 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 9718 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_ppr_all
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_explode
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_explode
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5700/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5700/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5700/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12767233 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12767920/HIVE-11981.08.patch

{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 9719 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_ppr_all
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5735/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5735/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5735/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12767920 - PreCommit-HIVE-TRUNK-Build, [~mmccline] As discussed, I feel like the reader side changes to ORC are intrusive and I don't think we need that many changes  to null out the additional columns that are being read. Your latest patch doesn't seem to address those changes. Ideally we should have OrcInputFormat add add additional columns to OrcStruct when it creates RecordReader. RecordReaderImpl should just fill those columns with nulls (for OrcStruct reuse) when reading old files that has missing columns., This is what I expect to see in TreeReaderFactory (please let me know if I am missing some feature that requires more changes to reader)

{code}
Object next(Object previous) {
..
Object result = null;
if (previous == null) {
  result = new OrcStruct(columnCount); // this should be from file metadata as we don't what schema that reader what hence we use file schema column count (hive does not use this codepath)
} else {
  // here we fill all the columns from the underlying file schema. If we see more columns in the provided OrcStruct then we just null it out
}
..
}
{code}, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12768225/HIVE-11981.09.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5761/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5761/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5761/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseConnection.java:[68,13] error: cannot find symbol
[ERROR] interface HBaseConnection
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseConnection.java:[84,2] error: cannot find symbol
[ERROR] interface HBaseConnection
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseConnection.java:[94,2] error: cannot find symbol
[ERROR] interface HBaseConnection
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[27,30] error: package org.apache.hadoop.hbase does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[28,30] error: package org.apache.hadoop.hbase does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[29,30] error: package org.apache.hadoop.hbase does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[30,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[31,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[32,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[33,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[34,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[35,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[36,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[37,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[38,37] error: package org.apache.hadoop.hbase.filter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[39,37] error: package org.apache.hadoop.hbase.filter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[40,37] error: package org.apache.hadoop.hbase.filter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[41,37] error: package org.apache.hadoop.hbase.filter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/PartitionKeyComparator.java:[30,37] error: package org.apache.hadoop.hbase.filter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/PartitionKeyComparator.java:[45,44] error: cannot find symbol
[ERROR] class ByteArrayComparable
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseConnection.java:[22,37] error: package org.apache.hadoop.hbase.client does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[749,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[810,55] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2006,10] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2025,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2030,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2029,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2034,46] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2034,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2039,58] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[2038,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseConnection.java:[68,13] error: cannot find symbol
[ERROR] interface HBaseConnection
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseConnection.java:[84,2] error: cannot find symbol
[ERROR] interface HBaseConnection
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseConnection.java:[94,2] error: cannot find symbol
[ERROR] interface HBaseConnection
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/PartitionKeyComparator.java:[179,2] error: method does not override or implement a method from a supertype
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/PartitionKeyComparator.java:[223,2] error: method does not override or implement a method from a supertype
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[210,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[354,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[356,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[356,42] error: package CompareFilter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[356,64] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[358,13] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[362,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[420,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[422,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[422,42] error: package CompareFilter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[422,64] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[424,13] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[428,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[512,10] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[512,35] error: unexpected type
[ERROR] 
[ERROR] E extends Object declared in class ArrayList
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[515,7] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[515,21] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[519,5] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[520,5] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[580,9] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[580,34] error: unexpected type
[ERROR] 
[ERROR] E extends Object declared in class ArrayList
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[586,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[586,18] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[591,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[600,9] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[600,34] error: unexpected type
[ERROR] 
[ERROR] E extends Object declared in class ArrayList
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[614,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[614,18] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[624,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[729,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[731,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[731,42] error: package CompareFilter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[812,13] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[818,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[867,9] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[867,34] error: unexpected type
[ERROR] 
[ERROR] E extends Object declared in class ArrayList
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[868,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[871,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[871,18] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[876,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[916,13] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[918,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1055,9] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1055,34] error: unexpected type
[ERROR] 
[ERROR] E extends Object declared in class ArrayList
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1070,8] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1070,22] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1082,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1104,8] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1104,22] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1111,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1127,12] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1127,26] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1136,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1161,13] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1164,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1194,15] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1196,8] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1244,9] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1244,34] error: unexpected type
[ERROR] 
[ERROR] E extends Object declared in class ArrayList
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1245,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1249,6] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1249,18] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1253,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1286,4] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1288,19] error: cannot find symbol
[ERROR] class HBaseReadWrite
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1288,42] error: package CompareFilter does not exist
[ERROR] /data/hive-ptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/hbase/HBaseReadWrite.java:[1288,64] error: cannot find symbol
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-metastore
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12768225 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12768497/HIVE-11981.091.patch

{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 9722 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
org.apache.hadoop.hive.ql.io.orc.TestColumnStatistics.testHasNull
org.apache.hadoop.hive.ql.io.orc.TestJsonFileDump.testJsonDump
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5779/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5779/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5779/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12768497 - PreCommit-HIVE-TRUNK-Build, [~prasanth_j] I removed some of the intrusive changes.  Now, no changes to ReaderImpl and one line change to RecordReaderImpl.  Common code (new class SchemaEvolution) for determining "schema on read" is called from two places: RecordReaderFactory and OrcRawRecordMerger.  TreeReaderFactory still has code for determining which columns to null since it seems to be in the best position to know how to do it instead of RecordReaderImpl...

Latest Hive QA run appears to be successful., Left some review comments in RB (page 1). Will look at other pages and will post more reviews., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12768863/HIVE-11981.092.patch

{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 9732 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hadoop.hive.ql.io.orc.TestJsonFileDump.testJsonDump
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5815/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5815/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5815/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12768863 - PreCommit-HIVE-TRUNK-Build, Left some more comments in RB. Still grokking through vectorizer changes which looks huge (page 3 in RB). , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12770240/HIVE-11981.093.patch

{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 64 failed/errored test(s), 9781 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testDefaultTypes
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testInOutFormat
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testMROutput
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming
org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatExternalDynamicCustomLocation[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.pig.TestE2EScenarios.testReadOrcAndRCFromPig
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testMapNullKey[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testMapWithComplexData[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testTupleInBagInTupleInBag[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[3]
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5900/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5900/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5900/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 64 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12770240 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12770579/HIVE-11981.094.patch

{color:green}SUCCESS:{color} +1 due to 17 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 46 failed/errored test(s), 9791 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_tez_union_with_udf
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_tez_union_with_udf
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_orc_vec_mapwork_part
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatExternalDynamicCustomLocation[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned.testHCatNonPartitionedTable[3]
org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[3]
org.apache.hive.hcatalog.pig.TestE2EScenarios.testReadOrcAndRCFromPig
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testMapNullKey[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testMapWithComplexData[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testTupleInBagInTupleInBag[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[3]
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5921/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5921/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5921/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 46 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12770579 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12770756/HIVE-11981.095.patch

{color:green}SUCCESS:{color} +1 due to 17 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 9791 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[3]
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5930/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5930/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5930/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12770756 - PreCommit-HIVE-TRUNK-Build, Made changes to HCatalog -- so:

{code}
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema and org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct
{code}

could be related.  So, now just 2 failures?, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12770975/HIVE-11981.096.patch

{color:green}SUCCESS:{color} +1 due to 22 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 15 failed/errored test(s), 9809 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_orc_acid_mapwork_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_orc_acidvec_mapwork_part
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_orc_acidvec_mapwork_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_partition_diff_num_cols
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_orc_acid_mapwork_part
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_orc_acid_mapwork_table
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_orc_acidvec_mapwork_part
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_orc_acidvec_mapwork_table
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_partition_diff_num_cols
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[3]
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5952/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5952/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5952/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 15 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12770975 - PreCommit-HIVE-TRUNK-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12771124/HIVE-11981.097.patch

{color:green}SUCCESS:{color} +1 due to 22 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 9810 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_histogram_numeric
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_partition_diff_num_cols
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_partition_diff_num_cols
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[3]
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5959/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5959/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5959/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12771124 - PreCommit-HIVE-TRUNK-Build, You should create a wiki page with the supported schema evolution., Ok, we need to do some work to avoid tying ORC back into Hive. In particular, we need should add to OrcFile.ReaderOptions a method to set the desired schema. It should look like:

{code}
  /**
   * Define the schema that the reader should read as.
   */
  public ReaderOptions schema(TypeDescription schema);

 /**
  * The accessor for the schema to read as.
  */
  TypeDescription getSchema();
{code}

The OrcInputFormat should use the SchemaEvolution code to figure out whether to call ReaderOptions.schema on the underlying Reader. (You could also put this into Reader.Options, which is the options object used to create RecordReaders.) The critical piece is that OrcFile and the parts under it can't depend on anything from serde or io.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12771702/HIVE-11981.098.patch

{color:green}SUCCESS:{color} +1 due to 22 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 9813 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_rp_annotate_stats_groupby
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_transform_acid
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_partition_diff_num_cols
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_partition_diff_num_cols
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hadoop.hive.metastore.hbase.TestHBaseImport.org.apache.hadoop.hive.metastore.hbase.TestHBaseImport
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5999/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5999/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5999/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12771702 - PreCommit-HIVE-TRUNK-Build, 
transform_acid.q could definitely be related to this change.

MR/Tez vector_partition_diff_num_cols.q need a minor golden file update (Execution mode: vectorized).

The others are old or seem unrelated., Thanks [~omalley].  I added schemaTypes to Reader.Options and segregated the ORC Hive related stuff like examining configuration variables into the OrcFileFormat and related classes.  When RecordReaderImpl gets the schemaTypes it then does validation against the actual fileTypes to make sure the schema evolution is ok.  Then, internally, it forms a TreeReaderSchema object to direct TreeReaderFactory on how to create the tree readers., FYI [~prasanth_j]., transform_acid.q Hive QA hive.log:

{code}
java.lang.Exception: java.lang.RuntimeException: Hive Runtime Error while closing operators
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462) ~[hadoop-mapreduce-client-common-2.6.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522) [hadoop-mapreduce-client-common-2.6.0.jar:?]
Caused by: java.lang.RuntimeException: Hive Runtime Error while closing operators
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.close(ExecMapper.java:204) ~[hive-exec-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61) ~[hadoop-mapreduce-client-core-2.6.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450) ~[hadoop-mapreduce-client-core-2.6.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343) ~[hadoop-mapreduce-client-core-2.6.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243) ~[hadoop-mapreduce-client-common-2.6.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[?:1.7.0_45]
	at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_45]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[?:1.7.0_45]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[?:1.7.0_45]
	at java.lang.Thread.run(Thread.java:744) ~[?:1.7.0_45]
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: [Error 20003]: An error occurred when trying to close the Operator running your custom script.
	at org.apache.hadoop.hive.ql.exec.ScriptOperator.close(ScriptOperator.java:562) ~[hive-exec-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:670) ~[hive-exec-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:670) ~[hive-exec-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:670) ~[hive-exec-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.close(ExecMapper.java:186) ~[hive-exec-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61) ~[hadoop-mapreduce-client-core-2.6.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450) ~[hadoop-mapreduce-client-core-2.6.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343) ~[hadoop-mapreduce-client-core-2.6.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243) ~[hadoop-mapreduce-client-common-2.6.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[?:1.7.0_45]
	at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_45]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[?:1.7.0_45]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[?:1.7.0_45]
	at java.lang.Thread.run(Thread.java:744) ~[?:1.7.0_45]
{code}

It doesn't fail on my laptop., Left some more comments in RB., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12771944/HIVE-11981.099.patch

{color:green}SUCCESS:{color} +1 due to 22 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 9814 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_rp_annotate_stats_groupby
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6014/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6014/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6014/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12771944 - PreCommit-HIVE-TRUNK-Build, [~prasanth_j] A clean Hive QA run!, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12772334/HIVE-11981.0991.patch

{color:green}SUCCESS:{color} +1 due to 22 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 9815 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_rp_annotate_stats_groupby
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6042/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6042/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6042/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12772334 - PreCommit-HIVE-TRUNK-Build, There is only one unaddressed comment in Vectorizer.java. Other than that patch looks good to me. +1, Rebase during very long Hive QA queue., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12772897/HIVE-11981.0992.patch

{color:green}SUCCESS:{color} +1 due to 22 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 9845 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6065/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6065/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6065/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12772897 - PreCommit-HIVE-TRUNK-Build, Committed to master.  Thanks [~prasanth_j] for your review., Doc note:  This adds *hive.exec.schema.evolution* to HiveConf.java, so it needs to be documented in the wiki.  Although it seems to be a general parameter, this JIRA issue is ORC-specific so the parameter should be cross-referenced at the beginning of the ORC File Format section.

* [Configuration Properties -- Query and DDL Execution | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-QueryandDDLExecution]
* [Configuration Properties -- ORC File Format | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-ORCFileFormat]

Also, as Owen wrote:  "You should create a wiki page with the supported schema evolution."

Here's the existing doc:  https://issues.apache.org/jira/secure/attachment/12764089/ORC%20Schema%20Evolution%20Issues.docx., bq. This adds hive.exec.schema.evolution to HiveConf.java ... Although it seems to be a general parameter, this JIRA issue is ORC-specific...

If this property is ORC specific then it seems like a mistake to name it hive.exec.orc.schema.evolution. Is there a good reason why "orc" doesn't appear in the property name or property description?, The new parameter  hive.exec.schema.evolution is intended to be general and not be ORC only.  Other file formats that contain schema metadata (e.g. parquet) could add the marker interface SelfDescribingInputFormatInterface and provide schema evolution functionality., The default for *hive.exec.schema.evolution* is changed to false by HIVE-12799 for release 2.1.0 and by HIVE-12625 for release 1.3.0 (except for ACID, which sets it to true)., When compacting ORC table, we got error as follows,

, kind: INT
] innerStructSubtype -1
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.<init>(TreeReaderFactory.java:2081)
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2504)
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.<init>(TreeReaderFactory.java:2084)
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2504)
	at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.<init>(RecordReaderImpl.java:210)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.rowsOptions(ReaderImpl.java:662)
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger$ReaderPair.<init>(OrcRawRecordMerger.java:212)
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.<init>(OrcRawRecordMerger.java:516)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1755)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:572)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:550)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

16/04/07 15:57:35 INFO mapreduce.Job:  map 100% reduce 0%
16/04/07 15:57:35 INFO mapreduce.Job: Job job_1458819387386_13740 failed with state FAILED due to: Task failed task_1458819387386_13740_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0

Env: hadoop 2.6.2+hive 2.0

p.s. our orc table contains tinyint column type., [~qiuzhuang] What is the DDL for the table?  Does it have a column of type STRUCT?, nope, our table doesn't have any struct. here is the DDL,

CREATE TABLE `my_orc_table`(
  `id` string, 
  `store_no_from` string, 
  `store_name_from` string, 
  `store_no_to` string, 
  `store_name_to` string, 
  `order_unit_no_from` string, 
  `order_unit_name_from` string, 
  `order_unit_no_to` string, 
  `order_unit_name_to` string, 
  `store_no` string, 
  `store_name` string, 
  `company_no` string, 
  `order_unit_no` string, 
  `order_unit_name` string, 
  `item_no` string, 
  `item_code` string, 
  `item_name` string, 
  `brand_no` string, 
  `brand_name` string, 
  `category_no` string, 
  `sku_no` string, 
  `size_no` string, 
  `size_kind` string, 
  `bill_no` string, 
  `status` tinyint, 
  `bill_type` int, 
  `in_out_flag` tinyint, 
  `ref_bill_no` string, 
  `ref_bill_type` int, 
  `biz_type` int, 
  `account_type` tinyint, 
  `bill_date` date, 
  `cost` decimal(12,2), 
  `balance_offset` int, 
  `balance_qty` int, 
  `factory_in_offset` int, 
  `factory_in_qty` int, 
  `factory_in_diff_offset` int, 
  `factory_in_diff_qty` int, 
  `transit_in_offset` int, 
  `transit_in_qty` int, 
  `transit_out_offset` int, 
  `transit_out_qty` int, 
  `in_diff_offset` int, 
  `in_diff_qty` int, 
  `out_diff_offset` int, 
  `out_diff_qty` int, 
  `transit_in_account_offset` int, 
  `transit_in_account_qty` int, 
  `transit_out_account_offset` int, 
  `transit_out_account_qty` int, 
  `in_diff_account_offset` int, 
  `in_diff_account_qty` int, 
  `out_diff_account_offset` int, 
  `out_diff_account_qty` int, 
  `lock_offset` int, 
  `lock_qty` int, 
  `occupied_offset` int, 
  `occupied_qty` int, 
  `backup_offset` int, 
  `backup_qty` int, 
  `guest_bad_offset` int, 
  `guest_bad_qty` int, 
  `original_bad_offset` int, 
  `original_bad_qty` int, 
  `bad_transit_offset` int, 
  `bad_transit_qty` int, 
  `bad_diff_offset` int, 
  `bad_diff_qty` int, 
  `return_offset` int, 
  `return_qty` int, 
  `borrow_offset` int, 
  `borrow_qty` int, 
  `create_time` timestamp, 
  `create_timestamp` timestamp, 
  `update_time` timestamp, 
  `sharding_flag` string, 
  `yw_update_time` timestamp, 
  `hive_create_time` timestamp, 
  `biz_date` int)
CLUSTERED BY ( 
  id) 
INTO 10 BUCKETS
ROW FORMAT SERDE 
  'org.apache.hadoop.hive.ql.io.orc.OrcSerde' 
STORED AS INPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat' 
OUTPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat'
LOCATION
  'hdfs://nn:9000/hive/warehouse/lqz.db/my_orc_table'
TBLPROPERTIES (
  'COLUMN_STATS_ACCURATE'='{\"BASIC_STATS\":\"true\"}', 
  'last_modified_by'='hive', 
  'last_modified_time'='1460015324', 
  'numFiles'='23', 
  'numRows'='33828471', 
  'orc.compress'='SNAPPY', 
  'orc.create.index'='true', 
  'orc.stripe.size'='67108864', 
  'rawDataSize'='92332902940', 
  'totalSize'='1474582939', 
  'transactional'='true', 
  'transient_lastDdlTime'='1460015745'), For more info, when I compact the table in hive 1.2 version, we see TreeReaderFactory errors as reported in this issue:

https://issues.apache.org/jira/browse/HIVE-13432]