[A few comments on this:

1. I think we should not have the number of rows as a session level parameter. Instead we should just estimate these by estimating the row size at run time (instead of the config time). I think we should just use that estimate and the session level max memory size set by the user to estimate the number of rows.
2. In order to estimate the size of the hash table we should do some simple experiments to see what the (hash table size/number of rows) factor is and then use that to scale our estimates.

Otherwise, this looks like a nice thing that can give us a lot of oomph in the performance side of things., one significant optimization we can/should make is when flushing - flush the entries that have been seen the least often (basically MFU caching). if we have a count aggregate function we can use that - or if not - might be worth keeping a count in any case.

default value of hashmaxmemory - perhaps this should be something like Runtime.getRuntime().maxMemory() - 512m (since we know mappers need some memory anyway).

i suspect Namit is using number of rows as an escape valve in case the memory computation is not correct. i do think that we are making life a little difficult for the user - remember that they not only have to manipulate the hash map memory - but they also have to size up the jvm spawning options so that heap size is increased. this is fairly obscure. it also turns out that the jvm options include non memory related stuff (although in later hadoop options - memory parameterization is separated out i think) - for example ours looks like this (-Xmx1024m -Djava.net.preferIPv4Stack=true)

it's worth asking if we can base it on the heap size only. the problem with the freememory approach was that it didn't account for garbage collection. on the other hand - we can call gc() every some time that we hit some higher free memory threshold and then flush out the map everytime we hit some lower free memory threshold (to guarantee that we dont hit OOM). wouldn't this be easier for the user (just set jvm option)

this would also be much preferable from the perspective of any future cluster scheduling based on memory. tasks should just need to specify total memory required and then figure out how to use it well. schedulers can work off this memory requirement. if the memory requirement has to be then subdivided into different components (like hive hashmap) - then things become complicated.

, I agree with the flushing optimization - but that can be a follow-up.

Default value of Runtime.getRuntime().maxMemory() - 512m is also OK.

I was using the number of rows as an escape value.

But I dont think invoking garbage collector explicitly is a good idea. 

A third category where developers often mistakenly think they are helping the garbage collector is the use of System.gc(), which triggers a garbage collection (actually, it merely suggests that this might be a good time for a garbage collection). Unfortunately, System.gc() triggers a full collection, which includes tracing all live objects in the heap and sweeping and compacting the old generation. This can be a lot of work. In general, it is better to let the system decide when it needs to collect the heap, and whether or not to do a full collection. Most of the time, a minor collection will do the job. Worse, calls to System.gc() are often deeply buried where developers may be unaware of their presence, and where they might get triggered far more often than necessary. If you are concerned that your application might have hidden calls to System.gc() buried in libraries, you can invoke the JVM with the -XX:+DisableExplicitGC option to prevent calls to System.gc() and triggering a garbage collection. 

I think it is too expensive to use that.

Instead of asking the user to specify hive hashmap memory, the user can specify that as a fraction of total task memory. The default will be close to 1 i.e all task memory will be used.

, Committed revision 727506., HIVE-170. Map-side aggregations to estimate memory size. (Namit via zshao)]