[Decimal and Date are also broken, Timestamp too. *sigh*, This adds the relevant fixes and tests., LGTM, +1. Pending tests, The test cover a.merge(b) where is wider, but not b.merge(a).  I'd test both directions to make sure someone doesn't introduce the opposite bug., You will need to bump the file version so a reader knows the stats are good.  You should also disable using these stats for predicate pushdown in the current version of the file.

And if you are bumping the version, you should fix the Timestamp epoch bug., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12679346/HIVE-8732.patch

{color:green}SUCCESS:{color} +1 6677 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1640/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1640/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1640/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12679346 - PreCommit-HIVE-TRUNK-Build, I've created the timestamp bug as HIVE-8746. The fix for that one is pretty touchy and I'll do it in 0.15 I think rather than risk the 0.14 release.

I don't want to create a new write format since the old reader will read the corrected files. I will add a flag that I can use to suppress using the split elimination code for files with broken stripe/file indexes.

Does that sound reasonable?, How will the code know that the stripe/file indexes are broken (i.e., written with the current writer and not the new one)?    BWT, the current  reader will read files with future version numbers; you only get a warning message:
{code:java}
      if (major > OrcFile.Version.CURRENT.getMajor() ||
          (major == OrcFile.Version.CURRENT.getMajor() &&
           minor > OrcFile.Version.CURRENT.getMinor())) {
        log.warn("ORC file " + path +
                 " was written by a future Hive version " +
                 versionString(version) +
                 ". This file may not be readable by this version of Hive.");
      }
{code}, DoubleStatisticsImpl merge and update methods don't handle NaN properly.  Any comparison with NaN returns false, so if the first value is NaN you end up with min and max of NaN, which implies that the column only contains NaNs.  We should consider tracking NaN specially in the stats.

Regardless, for now any code reading the DoubleStatistic should discard a stat containing a NaN., Here is what I had in mind. This patch:
* adds an optional writerVersion to the postscript, which tracks the bugs fixed in the writer
* uses the flag to disable predicate pushdown in split calculation, which seems to be the only usage of the stripe statistics within Hive
* tags any new files with having HIVE_8732 fixed
* adds tests for the merge where the original range is larger.

You're right that the Orc reader don't block reading future versions, but I think this is a little cleaner. Furthermore, if someone back ports this to Hive 0.13 they can do this without claiming to be writing a Hive 0.14 file. Thoughts?
, I missed one part of the previous iteration. Here is the corrected patch., This seems like a reasonable plan., The patch looks reasonable.  

We still need to decide how to deal with doubles with NaN. , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12679704/HIVE-8732.patch

{color:red}ERROR:{color} -1 due to 32 failed/errored test(s), 6680 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_merge_orc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_merge_stats_orc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_part
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_extrapolate_part_stats_full
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_extrapolate_part_stats_partial
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_analyze
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_merge5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_merge6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_split_elimination
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_alter_merge_orc
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_alter_merge_stats_orc
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_analyze
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge5
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge6
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_decimal_10_0
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_mapjoin_reduce
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDictionaryThreshold
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDump
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid
org.apache.hadoop.hive.ql.io.orc.TestOrcSplitElimination.testSplitEliminationComplexExpr
org.apache.hadoop.hive.ql.io.orc.TestOrcSplitElimination.testSplitEliminationLargeMaxSplit
org.apache.hadoop.hive.ql.io.orc.TestOrcSplitElimination.testSplitEliminationSmallMaxSplit
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1658/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1658/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1658/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 32 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12679704 - PreCommit-HIVE-TRUNK-Build, I had to fix some minor problems and update a bunch of qfile tests because the ORC files are now 2 bytes longer., The new changes looks good to me. +1.
Can you create a followup for dealing with NaN in double column statistics?, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12679999/HIVE-8732.patch

{color:green}SUCCESS:{color} +1 6665 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1678/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1678/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1678/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12679999 - PreCommit-HIVE-TRUNK-Build, +1 for hive .14, Committed to trunk and .14. Thanks [~owen.omalley] and [~prasanth_j]!, I should also point out that I added a line to the orcfiledump with a line about the version. New files will get the line:

File Version: 0.12 with HIVE_8732

Files written by the old writer will say either:

File Version: 0.12 with ORIGINAL
or
File Version: 0.11 with ORIGINAL

, I have verified that file version in file dump with old orc formats. , This has been fixed in 0.14 release. Please open new jira if you see any issues.
]