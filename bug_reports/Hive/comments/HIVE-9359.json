[To fix this completely would need a significant retrofit of the client side, as well as some ability to do paginated batch retrieves from the metastore.

A quick solution that goes a good deal of the way, however, is as follows:

a) Changing some usages of List<Partition> to Iterable<Partition>, and have a PartitionIterable that implements the above interface to replace usages of List<Partition>, and have that class lazily fetch partitions on need. While having a pagination scheme from the metastore would be great, a good short term solution that's possible is to simply store the partition names rather than the entire partition objects, so a PartitionIterable can, in the meanwhile, get the partition names, and then handle the pagination itself.

This solves the oom issues on the metastore completely, and gets rid of the thrift copy problem as well as the List<Partition> deepcopy problem. It introduces a load of storing all the partition names, but this is far less costly than the above.

b) Changing the json serialization to output each element as they come, rather than constructing one large JSONObject, and writing that out in one go. This solves the large JSONObject problem.

This still does not solve the problem of having a large number of ReadEntities, but that's something that's better tacked by doing something like a metadata-only-export, or changing export to be able to export a partial partition specification at a time, both of which are the subjects of further jiras I will be filing shortly., patch attached., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12691936/HIVE-9359.patch

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 7304 tests executed
*Failed tests:*
{noformat}
TestSparkClient - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
org.apache.hive.jdbc.TestSSL.testSSLFetchHttp
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2360/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2360/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2360/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12691936 - PreCommit-HIVE-TRUNK-Build, [~alangates], could you please review this patch?, [~vikram.dixit], this is another bug I'd like to see in 0.14.1, because it has a pretty significant memory impact on the metastore if a user runs an export on a table with too many partituons., One question: in EximUtil.createExportDump - is there a streaming JSON writer you could use so that we're not forced to hand-code JSON.  Maybe the JSON we're writing is simple enough, but this looks like it could end in a mess if our JSON gets complex., I see your concern. Jackson has a streaming api style with JSONGenerator, but I haven't yet been able to confirm if it generates the JSON object and then flushes as many others seem to do, or whether it actually writes out as it receives instructions. I can investigate a bit more on that end., Updated patch to use JsonGenerator., +1., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12693758/HIVE-9359.2.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 7347 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_histogram_numeric
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_percentile_approx_23
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2475/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2475/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2475/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12693758 - PreCommit-HIVE-TRUNK-Build, Patch 2 committed to trunk.  I don't believe the test failures are related, since they are all in code not even remotely close to export/import., +1 for 1.0, Committed to branch-1.0. Thanks, Vikram!, Updating release version for jiras resolved in 1.0.0 .
, This issue has been fixed in Apache Hive 1.0.0. If there is any issue with the fix, please open a new jira to address it.
]