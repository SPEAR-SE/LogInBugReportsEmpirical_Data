[This is related to ppd, when set hive.optimize.ppd=false; the query works fine., I tried to reproduce the problem too. If I remove "WHERE (filter = 1)", it also works. [~ashutoshc], could you please take a brief look and see if it is related to current improvement of PPD? Thanks., The root cause that I find is UnionOperator does not work well with ppd optimizer:
1. UnionOperator assume all its parents (most often SelectOperators) have same number of columns. 
2. When hive.optimize.ppd is true, the ppd try to push the FilterOperator up (to the parents). But for UnionOperator, it has several direct parents and each parent may has different conditions. In some cases, it makes the FilterOperators end up with different values in UnionOperator's ancestor trees. 
In this test case, the FilterOperator is (filter = 1), ppd make one filter end up as a direct parent of the UnionOperator, another filter further up in a different branch of parent tree until directly under TableScanOperator. After ppd optimizer, the ColumnPruner works to assign minimum number of columns to each operator. For UnionOperator, it gets one column(f1), but for the filterOperator that directly before the UnionOperator, it need (f1, filter) to do the work; the UnionOperator's the other parent which still a SelectOperator only has one column(f1). The two parents of the UnionOperator has different number of columns, so the java.lang.IndexOutOfBoundsException thrown when initialize UnionOperator in MR job. 
Attach a patch to fix the scenario when filter has different number columns from its direct child union all. , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12746122/HIVE-11271.1.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 9227 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4666/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4666/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4666/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12746122 - PreCommit-HIVE-TRUNK-Build, The failures are not related:
1. Tested on my own machine, all pass:
{noformat}

Excluded Files: null
Query Files: schemeAuthority.q
...

Running org.apache.hadoop.hive.cli.TestMinimrCliDriver
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 663.765 sec - in org.apache.hadoop.hive.cli.TestMinimrCliDriver

Results :

Tests run: 2, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hive.hcatalog.streaming.TestStreaming
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 124.281 sec - in org.apache.hive.hcatalog.streaming.TestStreaming

Results :

Tests run: 12, Failures: 0, Errors: 0, Skipped: 0

{noformat}

2.  The 3 hcatalog failures are all have error:
TestStreaming.<init>:157 ? SQL Table/View 'TXNS' already exists in Schema 'APP...
I have seen this in other builds without my fix.
3. All these failures have nothing to do with union all

[~szehon] and [~ashutoshc], could you review my patch? Thanks

, Sorry for late reply.  The overall idea makes sense (keeping track of corresponding columns in parent filter condition), so +1 from me., Thanks [~szehon] for reviewing it. , [~ychena] Can you check if this issue is fixed by HIVE-11333 ? If so, I think that is a better fix, since such issues should be resolved at compile time, not run time (ie Operators should not participate in this) cc: [~pxiong], [~ashutoshc], I do not think HIVE-11333 can solve this issue. This issue is, filter has one extra column than its child union and other parents of the union because the column is in predicate. When at the time process(prune) the filter, the union and other parents may already be processed, add back to them (maybe their parents or children) at compile time will be complicated and error-prone. And I need the flexible process in Operator to fix a similar issue in older hive version which hard to backport fixes for other issues (ppd, union, constant value...) Thanks, [~ashutoshc], thanks a lot for your attention. I applied the patch in HIVE-11333 and it seems that it can not solve the problem here.  The problem here is that we have FIL-UNION, FIL has to have 2 columns (1 for union and 1 for predicate). The problem in HIVE-11333 is that we have SEL-UNION, because of return path, the column in SEL got wrongly pruned. 

However, I still agree with you that a better fix should be at compile time, not run time. [~ychena], it seems that this problem is similar to the issue mentioned in https://issues.apache.org/jira/browse/HIVE-10996 although they are dealing with JOIN. A similar solution by adding a SEL may be like this: (1) In ColumnPruner, when dealing with FIL, check if the needed columns (from its child) and check the columns used in predicate. (2) If the former one contains the latter one, continue (no problem); else insert a SEL which just select the needed columns in between the FIL and its child. (3) This solution is happening at compile time, not run time. But it may involve many q files update. Thanks., [~pxiong], thanks for your advice. Your suggestion should work, I just do not understand why change run time code is not good. In your plan, you add extra  SEL which is just same as what the run time map in this patch do, and the extra select should not have better performance than the Filter with input to output map. And another good thing with my change is that I need 0 q file change. : )
I would be happy to make changes as you suggest if you or [~ashutoshc] can explain why the change has to be in compile time. Thanks, Plan which is broken at compile time but is patched up at runtime to work correctly is a *bad* idea because the notion of brokeness is only between this piece of code and at runtime and is opaque to everything in between. So, any subsequent code which mutates the plan (e.g, logical optimizer rules or physical compiler (MR/Tez/Spark compiler)) has to accomodate for this special condition. 
In general, at any time plan should be fully self-describing and not rely on subsequent patching. , [~ashutoshc], thanks for the explanation. 
I create a new patch according to the suggestion. Found another bug related to filter and union all when sel operator has no prunelist, this fix handle that case too. , I have a feeling that the fixes related to selector operator with empty or null prunelist may have big impact, I should separate the fix from the patch and create a new jira to work on it. Let's wait for the precommit build to see how big it is before I attach a new patch. , 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12746840/HIVE-11271.2.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4706/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4706/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4706/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-4706/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
From https://github.com/apache/hive
   393d690..2773b9d  master     -> origin/master
+ git reset --hard HEAD
HEAD is now at 393d690 HIVE-11301 : thrift metastore issue when getting stats results in disconnect (Pengcheng Xiong, reviewed by Sergey Shelukhin)
+ git clean -f -d
Removing ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java.orig
+ git checkout master
Already on 'master'
Your branch is behind 'origin/master' by 1 commit, and can be fast-forwarded.
+ git reset --hard origin/master
HEAD is now at 2773b9d HIVE-11333: ColumnPruner prunes columns of UnionOperator that should be kept (Pengcheng Xiong, via Jesus Camacho Rodriguez)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12746840 - PreCommit-HIVE-TRUNK-Build, My patch did not run because of conflict with the newly checkin. Patch the new one. , Thanks Yongzhi for doing this, this patch does look a lot simpler, +1 from my end., 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12747058/HIVE-11271.3.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4711/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4711/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4711/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-4711/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 92e9885 HIVE-11290 Cursor attributes %ISOPEN, %FOUND, %NOTFOUND and SYS_REFCURSOR variable (Dmitry Tolpeko via gates)
+ git clean -f -d
+ git checkout master
Already on 'master'
+ git reset --hard origin/master
HEAD is now at 92e9885 HIVE-11290 Cursor attributes %ISOPEN, %FOUND, %NOTFOUND and SYS_REFCURSOR variable (Dmitry Tolpeko via gates)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12747058 - PreCommit-HIVE-TRUNK-Build, Not sure, why the test does not run again. It seems conflict with another newly check-in again. Rebase and resubmit the patch. , 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12747155/HIVE-11271.4.patch

{color:green}SUCCESS:{color} +1 9259 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4716/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4716/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4716/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12747155 - PreCommit-HIVE-TRUNK-Build, version 4 is same as version 3, only difference is version 4 is rebase on the latest master branch.
Thanks [~szehon] for reviewing the code. , Committed to master.  Thanks Yongzhi for debugging the problem and spending time on the cleaner fix !, Also cherry-picked to branch-1., The patch maybe not work.I use the latest patches, but still have the same problem.]