[[~rhbutani] This should go into 0.13 as well, as HIVE-5687 will depend on it., This patch adds a call to allow a range of heartbeats to be sent together.  This way the streaming client can send a range for all open transactions.  If a transaction is aborted or missing that is in the range it is reported back to the caller, but the valid transactions still have a heartbeat recorded.  The caller must determine if it is acceptable for those transactions to be missing or aborted.

Review board posted: https://reviews.apache.org/r/19812/, +1, +1 for 0.13, 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12637576/HIVE-6721.patch

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/2025/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/2025/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n '' ]]
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-2025/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n '' ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted 'metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java'
Reverted 'metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/hive_metastoreConstants.java'
Reverted 'serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java'
Reverted 'ql/src/test/results/clientpositive/groupby_ppr.q.out'
Reverted 'ql/src/test/results/clientpositive/input_part7.q.out'
Reverted 'ql/src/test/results/clientpositive/pcr.q.out'
Reverted 'ql/src/test/results/clientpositive/join33.q.out'
Reverted 'ql/src/test/results/clientpositive/input_part2.q.out'
Reverted 'ql/src/test/results/clientpositive/alter_partition_coltype.q.out'
Reverted 'ql/src/test/results/clientpositive/load_dyn_part8.q.out'
Reverted 'ql/src/test/results/clientpositive/groupby_map_ppr.q.out'
Reverted 'ql/src/test/results/clientpositive/groupby_sort_6.q.out'
Reverted 'ql/src/test/results/clientpositive/push_or.q.out'
Reverted 'ql/src/test/results/clientpositive/stats13.q.out'
Reverted 'ql/src/test/results/clientpositive/combine2_hadoop20.q.out'
Reverted 'ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out'
Reverted 'ql/src/test/results/clientpositive/filter_join_breaktask.q.out'
Reverted 'ql/src/test/results/clientpositive/sort_merge_join_desc_5.q.out'
Reverted 'ql/src/test/results/clientpositive/input_part9.q.out'
Reverted 'ql/src/test/results/clientpositive/join26.q.out'
Reverted 'ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out'
Reverted 'ql/src/test/results/clientpositive/join_map_ppr.q.out'
Reverted 'ql/src/test/results/clientpositive/join9.q.out'
Reverted 'ql/src/test/results/clientpositive/smb_mapjoin_11.q.out'
Reverted 'ql/src/test/results/clientpositive/sample1.q.out'
Reverted 'ql/src/test/results/clientpositive/rand_partitionpruner3.q.out'
Reverted 'ql/src/test/results/clientpositive/merge3.q.out'
Reverted 'ql/src/test/results/clientpositive/sort_merge_join_desc_7.q.out'
Reverted 'ql/src/test/results/clientpositive/bucketmapjoin9.q.out'
Reverted 'ql/src/test/results/clientpositive/union22.q.out'
Reverted 'ql/src/test/results/clientpositive/join32.q.out'
Reverted 'ql/src/test/results/clientpositive/input_part1.q.out'
Reverted 'ql/src/test/results/clientpositive/columnstats_partlvl.q.out'
Reverted 'ql/src/test/results/clientpositive/auto_sortmerge_join_3.q.out'
Reverted 'ql/src/test/results/clientpositive/sample8.q.out'
Reverted 'ql/src/test/results/clientpositive/transform_ppr2.q.out'
Reverted 'ql/src/test/results/clientpositive/union_ppr.q.out'
Reverted 'ql/src/test/results/clientpositive/ppd_vc.q.out'
Reverted 'ql/src/test/results/clientpositive/dynamic_partition_skip_default.q.out'
Reverted 'ql/src/test/results/clientpositive/stats12.q.out'
Reverted 'ql/src/test/results/clientpositive/router_join_ppr.q.out'
Reverted 'ql/src/test/results/clientpositive/input42.q.out'
Reverted 'ql/src/test/results/clientpositive/sample10.q.out'
Reverted 'ql/src/test/results/clientpositive/louter_join_ppr.q.out'
Reverted 'ql/src/test/results/clientpositive/rand_partitionpruner2.q.out'
Reverted 'ql/src/test/results/clientpositive/bucket3.q.out'
Reverted 'ql/src/test/results/clientpositive/sort_merge_join_desc_6.q.out'
Reverted 'ql/src/test/results/clientpositive/bucketmapjoin8.q.out'
Reverted 'ql/src/test/results/clientpositive/annotate_stats_part.q.out'
Reverted 'ql/src/test/results/clientpositive/smb_mapjoin_12.q.out'
Reverted 'ql/src/test/results/clientpositive/metadataonly1.q.out'
Reverted 'ql/src/test/results/clientpositive/join32_lessSize.q.out'
Reverted 'ql/src/test/results/clientpositive/outer_join_ppr.q.out'
Reverted 'ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out'
Reverted 'ql/src/test/results/clientpositive/auto_sortmerge_join_2.q.out'
Reverted 'ql/src/test/results/clientpositive/transform_ppr1.q.out'
Reverted 'ql/src/test/results/clientpositive/ppd_union_view.q.out'
Reverted 'ql/src/test/results/clientpositive/stats11.q.out'
Reverted 'ql/src/test/results/clientpositive/input23.q.out'
Reverted 'ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorizedRowBatchCtx.java'
Reverted 'ql/src/test/queries/clientpositive/alter_partition_coltype.q'
Reverted 'ql/src/test/queries/clientpositive/pcr.q'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizedRowBatchCtx.java'
++ egrep -v '^X|^Performing status on external'
++ awk '{print $2}'
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen service/target contrib/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/results/clientpositive/vectorized_non_string_part.q.out ql/src/test/results/clientpositive/input23.q.out.orig ql/src/test/queries/clientpositive/vectorized_non_string_part.q
+ svn update

Fetching external item into 'hcatalog/src/test/e2e/harness'
External at revision 1582949.

At revision 1582949.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12637576, Ok, I'm not sure how to proceed here.  All the merge failures are in the generated code.  I don't know how to make thrift generate code that will merge properly.  If the committer applies the src-only patch and re-runs the thrift generation all should work.  Please let me know how to proceed., Alan, I suspect the merge failures are because of commits with thrift changes that went in yesterday. The patches with generated code usually applies fine in my experience. Can you try regenerating the patch on latest trunk ? I think it might just work.
, [~alangates]

One trick I notice about thrift is you should always add structs at the end. If you insert structs in the middle it tends to chance some internal numbering and make more noise then it should when mergin the generated code., Thanks [~thejas] and [~appodictic].  Re-running the thrift generation myself and rebuilding the patch as Thejas proposed seemed to do it., Canceling and resubmitting patch to get test run., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12637659/HIVE-6721.patch

{color:green}SUCCESS:{color} +1 5505 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/2035/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/2035/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12637659, Committed to trunk & 0.13. Thanks, Alan!]