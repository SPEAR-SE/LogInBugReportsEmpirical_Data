[Dupe of HIVE-3454 ?, Thanks Ashutosh. HIVE-3454 deals with specifying milliseconds for casting numerical unix timestamps to Timestamp type which it makes HIVE-3822 a duplicate of it. I will mark it as so. However, this issue still prevails whereby a file containing unix timestamps (regardless of whether they are in seconds or milliseconds) on HDFS can't be interpreted as a timestamp column in a Hive table. The workaround is to read it as a bigint and use cast ( my_col as timestamp) in the queries., {~mgrover} I am wondering whether you are working on this issue. If not, I would be happy to work on this issue., Venki,
I am not. Assigned it to you., Hi [~mgrover], Here is the initial patch https://reviews.apache.org/r/15105/. It covers the three formats mentioned [here | https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-Timestamps]. Please review it and provide feedback. , Venki,
Thanks for working on this!
I have added a comment to reviewboard. Catching an exception and converting it will be extremely slow.
It would be better to check the format and do the conversion appropriately. Also, BigDecimal is something that is considered to be slow. 

cc'ing [~jdere] who is a data type expert!
, For now, I have updated the doc to say what text format is supported - https://cwiki.apache.org/confluence/pages/diffpagesbyversion.action?pageId=27838462&selectedPageVersions=27&selectedPageVersions=26, Should we really be allowing numeric formats to be read as timestamp? If the data is in integer/floating point format, I'd think we should be treating those columns as integer/floating point and apply the appropriate cast or UDF to convert it to a timestamp type. In any case, I added a comment to the RB., Updated the patch to use Pattern/Matcher to identify the format of timestamp. I thought about not using the BigDecimal, but the output has floating point errors.

Reg: Should we really be allowing numeric formats to be read as timestamp?
I have seen multiple customers that have logs with different timestamp formats and they want to create one table with timestamp schema and read all sources of data.]