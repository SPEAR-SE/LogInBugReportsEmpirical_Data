[The patch is getting a bunch of compile errors.

Also, shouldn't the job have 1 split, since an empty file is present - I mean, how is it different from running a job with a empty
directory (or a directory with 0 size files). Seems like the code in HiveInputFormat and CombineFileInputFormat should be same
there., Sorry about the non-compiling patch -  it requires a few changes to get working and I thought I'd check on the approach before I do that. 

I believe the underlying issue is in Hadoop. FileInputFormat.getSplits actually creates an empty InputSplit for each empty input file: 

{code} 
if (length != 0) { 
        ... 
} else { 
  //Create empty hosts array for zero length files 
  splits.add(new FileSplit(path, 0, length, new String[0])); 
} 
{code} 

so if you pass all empty files, you'll still get a mapper per input file. However, with CombineFileInputFormat.getSplits, it looks at the list of blocks and creates splits made up of all the blocks it finds, so if you pass all empty files, it returns an empty list which hangs Hadoop. 

I'm using Cloudera's hadoop-0.20.1+152, so maybe this is fixed in a more recent Hadoop, but if not, I can file a bug in Hadoop and/or could add a workaround in Hive which creates an empty split if CombineFileInputFormat.getSplits returns an empty list.,  jar -xvf ./build/hadoopcore/hadoop-0.20.0/hadoop-0.20.0-core.jar

Using hadoop.version 0.20.0,

The following test works fine:

 t hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;

DROP TABLE nullscript;
CREATE TABLE nullscript(KEY STRING, VALUE STRING) STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH '../data/files/nullfile.txt' INTO TABLE nullscript;

select transform(key) using '/bin/cat' as key1 from nullscript;


DROP TABLE nullscript;



and we can 1 split:

    [junit] 09/12/22 10:45:24 INFO io.CombineHiveInputFormat: number of splits 1


Seems like a hadoop bug, Here's steps to reproduce:

Using Cloudera's Hadoop 0.20.1+152 (since the CombineFile functionality doesn't work in 0.20.1 without the extra patches), and latest Hive trunk (895060)

SET hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
DROP TABLE nullscript;
CREATE TABLE nullscript(KEY STRING, VALUE STRING) STORED AS TEXTFILE;
LOAD DATA LOCAL INPATH 'data/files/nullfile.txt' INTO TABLE nullscript;
select key from nullscript group by key;

From the log:
2010-01-01 15:36:18,372 INFO  io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(252)) - CombineHiveInputSplit creating pool for /user/hive/warehouse/nullscript
2010-01-01 15:36:18,584 INFO  mapred.FileInputFormat (FileInputFormat.java:listStatus(192)) - Total input paths to process : 1
2010-01-01 15:36:18,781 INFO  io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(262)) - number of splits 0

This yields a MR job with 0 mappers and 1 reducer which hangs in Hadoop at 0%., Is this still a problem - I think this problem has been fixed in open source some time back.
If yes, can you close the jira ?, Tried the steps above on Hadoop 0.20.2.  It still logs "number of splits 0", but instead of hanging at 0%, it completes the map, then fails with a "Shuffle Error: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out." in the reduce.  This is clearly preferable to hanging and doesn't seem like a totally unreasonable result when asking for data from an empty file -- should I close the ticket?]