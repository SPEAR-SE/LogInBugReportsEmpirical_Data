[HIVE-16832.01.patch is an incomplete WIP
VectorizedOrcAcidRowBatchReader assumes that ROW__ID.bucketId is the same in each split (and each bucket file of a delete_delta) which is no longer the case

SortedDynPartitionOptimizer needs to ensure that data is sorted by 
by (ROW__ID.bucketId%numBuckets) before it's sorted by ROW__ID so that
FileSinkOperator.process() sees all rows for a given bucket equivalence set before moving on to the next equivalence set.  , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12871718/HIVE-16832.01.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 48 failed/errored test(s), 10832 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=157)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query78] (batchId=232)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5559/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5559/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5559/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 48 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12871718 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12873581/HIVE-16832.03.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5682/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5682/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5682/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[68,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[73,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[74,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[75,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[80,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[81,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[84,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[89,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[90,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[91,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[96,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[97,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[98,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[99,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[100,39] no suitable constructor found for RecordIdentifier(long,int,int)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestRecordInspectorImpl.java:[38,41] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java:[150,34] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java:[43,33] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[57,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[58,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[59,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[60,58] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[245,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[302,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[313,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[324,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[326,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[372,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[501,95] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[504,83] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[506,53] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[507,98] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[521,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[523,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[525,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[533,59] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[541,63] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-hcatalog-streaming
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12873581 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12873614/HIVE-16832.04.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5687/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5687/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5687/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/token/Token.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Tool.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar(org/apache/thrift/TException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/conf/Configurable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Callable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/InterruptedException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Boolean.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/ClassNotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/ql/target/hive-exec-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/ql/ErrorMsg.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Integer.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/Log.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/LogFactory.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobProfile.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Long.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/JavaUtils.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileNotFoundException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URISyntaxException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URI.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/metastore/target/hive-metastore-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/metastore/api/MetaException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Credentials.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/InetAddress.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/UnknownHostException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/text/MessageFormat.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Matcher.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Pattern.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/DELETE.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/FormParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/GET.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/POST.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PUT.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Path.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PathParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Produces.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/QueryParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/Context.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/SecurityContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/UriInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-lang/commons-lang/2.6/commons-lang-2.6.jar(org/apache/commons/lang/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/fs/FileStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/BufferedReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStreamReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/PrintWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Map$Entry.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Semaphore.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/CommandLine.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/DefaultExecutor.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteWatchdog.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/PumpStreamHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Shell.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Thread.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Runnable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/ExceptionMapper.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/Provider.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/NotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Groups.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/HashSet.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Set.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ConcurrentHashMap.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hive/common/util/HiveVersionInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataInput.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataOutput.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/InputSplit.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar(org/apache/curator/framework/CuratorFramework.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/CreateMode.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/KeeperException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs$Ids.class)]]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:testCompile (default-testCompile) on project hive-hcatalog-streaming: Compilation failure: Compilation failure:
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestRecordInspectorImpl.java:[38,41] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java:[150,34] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java:[43,33] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[57,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[58,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[59,57] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[60,58] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[245,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[302,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[313,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[324,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[326,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[372,61] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[501,95] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[504,83] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[506,53] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[507,98] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[521,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[523,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[525,62] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[533,59] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[541,63] no suitable constructor found for RecordIdentifier(long,int,long)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable
[ERROR] (actual and formal argument lists differ in length)
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-hcatalog-streaming
Destroying 1 processes
Destroying process..
Destroyed 1 processes
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12873614 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12873702/HIVE-16832.05.patch

{color:green}SUCCESS:{color} +1 due to 15 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 304 failed/errored test(s), 10845 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_join] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_mapjoin] (batchId=10)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_partition] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_project] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=48)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_no_match] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_acid_dynamic_partition] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_nonacid_from_acid] (batchId=70)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_orig_table] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_partitioned] (batchId=72)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_tmp_table] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=76)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_reader] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_exception] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[transform_acid] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=65)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_no_match] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_acid3] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_join_part_col_char] (batchId=22)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_dynamic] (batchId=165)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_static] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_globallimit] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_no_match] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_orig_table] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_partitioned] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_tmp_table] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_no_match] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_acid3] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join_part_col_char] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[acid_overwrite] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnMR (batchId=217)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnTez (batchId=217)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnMR (batchId=217)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnTez (batchId=217)
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testErrors (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeCardinalityViolation (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAlterTable (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testFileSystemUnCaching (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testInitiatorWithMultipleFailedCompactions (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsertStatement (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNoHistory (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testSimpleRead (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAcidWithSchemaEvolution (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAlterTable (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testBucketizedInputFormat (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testETLSplitStrategyForACID (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFileSystemUnCaching (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testInitiatorWithMultipleFailedCompactions (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMergeWithPredicate (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsert (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsertStatement (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNoHistory (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion1 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testSimpleRead (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAcidWithSchemaEvolution (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAlterTable (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testBucketizedInputFormat (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testETLSplitStrategyForACID (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFileSystemUnCaching (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testInitiatorWithMultipleFailedCompactions (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMergeWithPredicate (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsert (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertStatement (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertVectorized (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNoHistory (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion1 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testSimpleRead (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=277)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBase (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPair (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPairNoMin (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.checkExpectedLocks2 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testCompletedTxnComponents (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testDynamicPartitionInsert (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way01 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way02 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned01 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned02 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned01 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned02 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMetastoreTablesCleanup (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMultiInsert (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking10 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking11 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking5 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking7 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking8 (batchId=281)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking9 (batchId=281)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningInsert (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithOnlyInserts (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testTableProperties (batchId=214)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5692/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5692/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5692/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 304 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12873702 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12873989/HIVE-16832.06.patch

{color:green}SUCCESS:{color} +1 due to 15 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 188 failed/errored test(s), 10839 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=76)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=65)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=59)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)
org.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=268)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMergeWithPredicate (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMergeWithPredicate (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertVectorized (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=277)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBase (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPair (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPairNoMin (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=214)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5728/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5728/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5728/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 188 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12873989 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12874171/HIVE-16832.08.patch

{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 76 failed/errored test(s), 10858 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=215)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=215)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=190)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5737/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5737/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5737/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 76 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12874171 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12874192/HIVE-16832.09.patch

{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 51 failed/errored test(s), 10858 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=227)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5744/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5744/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5744/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 51 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12874192 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch

{color:green}SUCCESS:{color} +1 due to 17 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 33 failed/errored test(s), 10857 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=269)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5757/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5757/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5757/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 33 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12874324 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch

{color:green}SUCCESS:{color} +1 due to 17 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 31 failed/errored test(s), 10857 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5758/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5758/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5758/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 31 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12874324 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12874793/HIVE-16832.14.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 26 failed/errored test(s), 10862 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[zero_rows_hdfs] (batchId=241)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)
org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=263)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=262)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5804/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5804/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5804/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 26 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12874793 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12874999/HIVE-16832.15.patch

{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 10841 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=98)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5824/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5824/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5824/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 17 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12874999 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12875110/HIVE-16832.16.patch

{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 20 failed/errored test(s), 10833 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=141)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=100)
org.apache.hadoop.hive.llap.security.TestLlapSignerImpl.testSigning (batchId=290)
org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5835/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5835/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5835/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 20 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12875110 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12875809/HIVE-16832.17.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5896/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5896/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5896/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-07-05 23:32:57.513
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-5896/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-07-05 23:32:57.516
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at c39b879 HIVE-16893: move replication dump related work in semantic analysis phase to execution phase using a task (Anishek Agarwal, reviewed by Sankar Hariappan, Daniel Dai)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at c39b879 HIVE-16893: move replication dump related work in semantic analysis phase to execution phase using a task (Anishek Agarwal, reviewed by Sankar Hariappan, Daniel Dai)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-07-05 23:33:02.202
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/BucketIdResolverImpl.java
patching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/MutatorCoordinator.java
patching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/MutatorImpl.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java
patching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorImpl.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/AcidOutputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/RecordIdentifier.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRawRecordMerger.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/UpdateDeleteSemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2WithSplitUpdate.java
patching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2WithSplitUpdateAndVectorization.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/TestAcidUtils.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcRawRecordMerger.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcRecordUpdater.java
patching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestVectorizedOrcAcidRowBatchReader.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
ANTLR Parser Generator  Version 3.5.2
Output file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g
org/apache/hadoop/hive/metastore/parser/Filter.g
DataNucleus Enhancer (version 4.1.17) for API "JDO"
DataNucleus Enhancer : Classpath
>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMetastoreDBProperties
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog
ENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId
DataNucleus Enhancer completed with success for 31 classes. Timings : input=153 ms, enhance=224 ms, total=377 ms. Consult the log for full details
ANTLR Parser Generator  Version 3.5.2
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveLexer.g
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g
org/apache/hadoop/hive/ql/parse/HintParser.g
Generating vector expression code
Generating vector expression test code
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[34,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java:[41,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java:[35,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java:[27,36] cannot find symbol
  symbol:   class BucketCodec
  location: package org.apache.hadoop.hive.ql.io
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[34,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java:[41,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java:[35,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java:[27,36] cannot find symbol
[ERROR] symbol:   class BucketCodec
[ERROR] location: package org.apache.hadoop.hive.ql.io
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-exec
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12875809 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12875831/HIVE-16832.18.patch

{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 10847 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5901/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5901/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5901/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 12 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12875831 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12876158/HIVE-16832.19.patch

{color:green}SUCCESS:{color} +1 due to 11 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10848 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5917/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5917/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5917/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12876158 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12876176/HIVE-16832.20.patch

{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10848 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5919/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5919/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5919/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12876176 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12876248/HIVE-16832.20.patch

{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10848 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5920/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5920/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5920/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12876248 - PreCommit-HIVE-Build, no related failures (for example, https://builds.apache.org/job/PreCommit-HIVE-Build/5916/#showFailuresLink has all the same ones)

[~gopalv], could you review please, LGTM - +1.

Minor comments - the bits used for bucket and statement ids are too big and misaligned (i.e 3:14:15), gets very hard to debug if looking at hex output (instead of raw binary). 

With 4k buckets & 4k statements, (3:1(reserved):12:4(reserved):12), allows the hex output to be much more easily read, with 3 hex digits there - also possibly those 5 bits can come of some use later. 

This patch is good and we can make the inner loops faster in a later iteration as the bucketproperty min-max is actually computed across the whole stripe/file (i.e if min==max, then no more checks needed).

Compressed OTID got a bit bigger with this, perhaps it is better to build lists per statement id instead of storing it - that extra int will eat up 1 long worth of space, but the txn push-down from the main split -> delete deltas should ensure we never read too much data into that structure., 
I agree that Compressed OTID is now bigger but I'm not sure how useful it's in the first place.
Suppose you populate a partition via 100 inserts and 1M rows.  So you have 100 OTIDs.
Now if you run an update/delete with some WHERE clause it will match rows randomly wrt OTIDs on average.
So if this delete generates 500 events, it seems likely that you get a lot of distinct OTIDs among them.  Perhaps simply relying on the "push down" to delete deltas is enough and we are better off just keeping 3 arrays.
, bq. Suppose you populate a partition via 100 inserts and 1M rows. So you have 100 OTIDs.

Yeah, this was an optimization for the possibility that you're doing an "update every row" merge which would otherwise cause a massive memory jump in deletes (& overflow the 2G limit on arrays).

bq. Perhaps simply relying on the "push down" to delete deltas is enough and we are better off just keeping 3 arrays

Yes, it might be better - I've yet to really look into the delete distribution for a regular CDC workload. The push-down into deletes is a big win anyway.

Not too worried about the extra size here., patch 21 addresses Gopal's comments, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12876708/HIVE-16832.21.patch

{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 10853 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.ql.TestTxnCommands.testNonAcidToAcidConversion01 (batchId=282)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion02 (batchId=269)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion02 (batchId=280)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion02 (batchId=277)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5969/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5969/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5969/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12876708 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12876914/HIVE-16832.22.patch

{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 10888 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver[hbase_queries] (batchId=94)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5989/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5989/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5989/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12876914 - PreCommit-HIVE-Build, no related failures (see builds 5985,5984 for same failures)
HIVE-16832.22.patch committed to master (3.0)
thanks Gopal for the review, No-doc note:  This adds *hive.test.bucketcodec.version* to HiveConf.java, but it's for testing only so no user documentation is needed., Hive 3.0.0 has been released so closing this jira.]