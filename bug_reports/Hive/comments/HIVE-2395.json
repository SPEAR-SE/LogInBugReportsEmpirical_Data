[> .lzo files require that an LzoIndexer is run on them.

This is not a requirement. You need the index file only if you want split large lzo files. You could just remove the index files as a quick workaround (in which case you might as well use just TextInputFormat ).
, Right, of course, and that's the workaround we went with. With smaller-than-block files it really doesn't matter.

After I filed this ticket I did a quick and dirty hack on DeprecatedLzoTextInputFormat to ignore .lzo.index files. However, I actually found that it doesn't read larger-than-block-size .lzo files correctly at all - it either crashes with things like ArrayIndexOutOfBoundsException in LzoDecompressor.setInput() or just outright ignores all data beyond the block size. This would happen even if .lzo.index files were absent.

So then I recreated tables without using INPUTFORMAT "DeprecatedLzoTextInputFormat" and it's returning correct data. It still attempts to read .lzo.index files as data so we are going un-indexed as a workaround (with the lack of splitting as the side effect, obviously). At this point, I wasn't sure why we were using DeprecatedLzoTextInputFormat in the first place, other than Google "told" us to. Maybe Hive codebase moved beyond needing it?

I will try code changes from https://github.com/kevinweil/hadoop-lzo/pull/28 when I have some free time.

PS. Our hadoop-lzo.jar is from January 2011 release (v0.4.8) built by Gerrit., Latest hadoop-lzo libraries do not exhibit this behavior.]