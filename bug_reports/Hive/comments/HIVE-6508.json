[The value 0 comes in the input vector unscaled (scale 0). As aggregates (SUM, STDxx) are being updated, they us the scale of the input value, not the scale of the input column. So any 0 in the input will round the intermediate fractional part of the intermediate. Final result is off. AVG uses a special scale so is not affected. MIN/MAX use the input value scale, but has no side effects. Fix is to pass in the column scale explictly, rather than assume the input value scale has the column scale. Ultimately the behavior of passing in unscaled 0s is wrong, but this comes from the row-mode join modus-operandi and I don't want to change that. Hardening the aggregates against this case is more robust., +1. The patch looks good to me., Same patch re-uploaded to trigger pre-commit build., It might make sense to add a test to ./ql/src/test/queries/clientcompare :), [~sershe] There is a new test case testSumDecimalHive6508 the covers possible regression, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12633294/HIVE-6508.1.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 5374 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_parallel_orderby
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1660/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1660/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12633294, The failure is unrelated to the patch, Committed to trunk. It is a correctness bug, therefore I will port it to hive-13 branch as well., Committed to branch-0.13, This has been fixed in 0.14 release. Please open new jira if you see any issues.
]