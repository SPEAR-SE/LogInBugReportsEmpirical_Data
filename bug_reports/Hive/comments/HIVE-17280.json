[Do you happen to know the filenames generated by spark? 
Hive has some assumptions around filenames when moving the files from staging to final target directory. Recently encountered similar issue (HIVE-17403) which could be related to this as well., The names of the files are:

{noformat}
/apps/hive/warehouse/aa/part-00000
/apps/hive/warehouse/aa/part-00000_copy_1
/apps/hive/warehouse/aa/part-00001
/apps/hive/warehouse/aa/part-00001_copy_1
/apps/hive/warehouse/aa/part-00001_copy_2
/apps/hive/warehouse/aa/part-00002
/apps/hive/warehouse/aa/part-00002_copy_1
/apps/hive/warehouse/aa/part-00003
/apps/hive/warehouse/aa/part-00003_copy_1
{noformat}
, That is certainly not the format that hive expects. After concatenation, merged and unmerged (incompatible) files gets moved to a staging directory. Then MoveTask moves the files from staging directory to final destination directory (which is also the source directory in case of concatenation). There are certain assumptions around filenames for bucketing, speculative execution etc. in move task. In the example files that you had provided, part-00000_copy_1 and part-00001_copy_1 will be considered same file written by different tasks (from speculative execution) and the largest file will be picked as the winner of speculated execution. This is the same issue as HIVE-17403. Hive usually writes files with format 000000_0 where 000000 is task id/bucket id and digit after _  is considered a task attempt. I am working on a patch that will restrict concatenation for external tables. And for hive managed tables, load data command will make sure the filenames conform to Hive's expectation. , I see, but this won't fix the problem with files written by Spark. This is the way Spark names files to managed tables. Thus the issue will still be there., [~mgaido] Posted a patch to HIVE-17403 that will fix the issue (along with adding restrictions). Tested this locally and it worked. If concatenation finds incompatible file, it will rename to Hive's convention to avoid the issue that I mentioned above. , Fix for this got committed via HIVE-17403. Closing this as done., Hive 3.0.0 has been released so closing this jira.]