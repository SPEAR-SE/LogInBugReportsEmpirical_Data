[Seems this is introduced with Hive 0.13. Have tested with Hive 0.12 MR and got correct result., This seems to be an issue with PPD.
[~apivovarov] are you working on this?, if we look at hive-0.12 plan then we can see that it has "brn is not null" predicate in Filter Operator
{code}
acct 
          TableScan
            alias: acct
            Filter Operator
              predicate:
                  expr: brn is not null
                  type: boolean
{code}

But in hive-1.3.0 plan I do not see "brn" at all. It only has "predicate: aid is not null" for acct table.
Does it mean that hive-1.3.0 plan is wrong?

I checked ppd folder diff btw 0.12.0 and 0.13.0
It was two fixes
HIVE-4293 : Predicates following UDTF operator are removed by PPD 
HIVE-5411 : Migrate expression serialization to Kryo

, hive-0.12.0 plan
{code}
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_JOIN (TOK_JOIN (TOK_JOIN (TOK_TABREF (TOK_TABNAME L)) (TOK_TABREF (TOK_TABNAME LA)) (= (. (TOK_TABLE_OR_COL L) id) (. (TOK_TABLE_OR_COL LA) loan_id))) (TOK_TABREF (TOK_TABNAME FR)) (= (. (TOK_TABLE_OR_COL L) id) (. (TOK_TABLE_OR_COL FR) loan_id))) (TOK_TABREF (TOK_TABNAME A)) (= (. (TOK_TABLE_OR_COL LA) aid) (. (TOK_TABLE_OR_COL A) id))) (TOK_TABREF (TOK_TABNAME PI)) (= (. (TOK_TABLE_OR_COL PI) id) (. (TOK_TABLE_OR_COL LA) pi_id))) (TOK_TABREF (TOK_TABNAME acct)) (= (. (TOK_TABLE_OR_COL A) id) (. (TOK_TABLE_OR_COL acct) aid)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL acct) ACC_N)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL acct) brn))) (TOK_WHERE (and (= (. (TOK_TABLE_OR_COL L) id) 4436) (TOK_FUNCTION TOK_ISNOTNULL (. (TOK_TABLE_OR_COL acct) brn))))))

STAGE DEPENDENCIES:
  Stage-11 is a root stage
  Stage-8 depends on stages: Stage-11
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-11
    Map Reduce Local Work
      Alias -> Map Local Tables:
        a 
          Fetch Operator
            limit: -1
        acct 
          Fetch Operator
            limit: -1
        fr 
          Fetch Operator
            limit: -1
        l 
          Fetch Operator
            limit: -1
        pi 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        a 
          TableScan
            alias: a
            HashTable Sink Operator
              condition expressions:
                0 {_col5}
                1 
                2 {acc_n} {brn}
              handleSkewJoin: false
              keys:
                0 [Column[_col4]]
                1 [Column[id]]
                2 [Column[aid]]
              Position of Big Table: 0
        acct 
          TableScan
            alias: acct
            Filter Operator
              predicate:
                  expr: brn is not null
                  type: boolean
              HashTable Sink Operator
                condition expressions:
                  0 {_col5}
                  1 
                  2 {acc_n} {brn}
                handleSkewJoin: false
                keys:
                  0 [Column[_col4]]
                  1 [Column[id]]
                  2 [Column[aid]]
                Position of Big Table: 0
        fr 
          TableScan
            alias: fr
            Filter Operator
              predicate:
                  expr: (loan_id = 4436)
                  type: boolean
              HashTable Sink Operator
                condition expressions:
                  0 
                  1 {aid} {pi_id}
                  2 
                handleSkewJoin: false
                keys:
                  0 [Column[id]]
                  1 [Column[loan_id]]
                  2 [Column[loan_id]]
                Position of Big Table: 1
        l 
          TableScan
            alias: l
            Filter Operator
              predicate:
                  expr: (id = 4436)
                  type: boolean
              HashTable Sink Operator
                condition expressions:
                  0 
                  1 {aid} {pi_id}
                  2 
                handleSkewJoin: false
                keys:
                  0 [Column[id]]
                  1 [Column[loan_id]]
                  2 [Column[loan_id]]
                Position of Big Table: 1
        pi 
          TableScan
            alias: pi
            HashTable Sink Operator
              condition expressions:
                0 {_col15} {_col16}
                1 
              handleSkewJoin: false
              keys:
                0 [Column[_col2]]
                1 [Column[id]]
              Position of Big Table: 0

  Stage: Stage-8
    Map Reduce
      Alias -> Map Operator Tree:
        la 
          TableScan
            alias: la
            Filter Operator
              predicate:
                  expr: (loan_id = 4436)
                  type: boolean
              Map Join Operator
                condition map:
                     Inner Join 0 to 1
                     Inner Join 0 to 2
                condition expressions:
                  0 
                  1 {aid} {pi_id}
                  2 
                handleSkewJoin: false
                keys:
                  0 [Column[id]]
                  1 [Column[loan_id]]
                  2 [Column[loan_id]]
                outputColumnNames: _col4, _col5
                Position of Big Table: 1
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                       Inner Join 1 to 2
                  condition expressions:
                    0 {_col5}
                    1 
                    2 {acc_n} {brn}
                  handleSkewJoin: false
                  keys:
                    0 [Column[_col4]]
                    1 [Column[id]]
                    2 [Column[aid]]
                  outputColumnNames: _col2, _col15, _col16
                  Position of Big Table: 0
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                    condition expressions:
                      0 {_col15} {_col16}
                      1 
                    handleSkewJoin: false
                    keys:
                      0 [Column[_col2]]
                      1 [Column[id]]
                    outputColumnNames: _col1, _col2
                    Position of Big Table: 0
                    Select Operator
                      expressions:
                            expr: _col1
                            type: int
                            expr: _col2
                            type: int
                      outputColumnNames: _col0, _col1
                      File Output Operator
                        compressed: false
                        GlobalTableId: 0
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
{code}, if we change "is not null" to "is null" or to " = 122" then all 3 rows will be NULL or 122 for column "brn" (second column).

and acct.brn is null;
{code}
10	NULL
NULL	NULL
NULL	NULL
{code}

and acct.brn = 122;
{code}
10	122
NULL	122
NULL	122
{code}

and acct.brn is null;
{code}
10	122
NULL	NULL
NULL	NULL
{code}, I found that "JOIN FR" can be removed - the result still will be 3 rows
But adding or removing "JOIN PI" changes Filter Operator predicate for acct table

if we remove "JOIN PI" then acct table Filter Operator predicate has "brn is not null" and query returns 1 row
{code}
        acct 
          TableScan
            alias: acct
            Statistics: Num rows: 5 Data size: 63 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (aid is not null and brn is not null) (type: boolean)
{code}

How it can be possible that removing "JOIN PI" changes Filter Operator predicate for acct table?

The query below returns 1 row. Query plan has "brn is not null" predicate in Filter Operator for acct table.
But if we remove comment before "JOIN PI" then query plan will not have "brn is not null" predicate.
{code}
explain select
  acct.ACC_N,
  acct.brn
FROM L
JOIN LA ON L.id = LA.loan_id
JOIN A ON LA.aid = A.id
--JOIN PI ON PI.id = LA.pi_id
JOIN acct ON A.id = acct.aid
WHERE
  L.id = 4436
  and acct.brn is not null;
{code}
, can you try this with 

set hive.optimize.ppd=false;

?, L tables also can be removed from the query - it does not affect the result.

But I found that order of JOIN statements matters.
I tries the following combinations of the JOIN statements
(PI,acct,A) (PI,A,acct) (A,PI,acct) (acct,PI,A) (A,act,PI) (act,A,PI)

3 rows are returned only for (A,PI,acct) combination
FROM LA
JOIN A
JOIN PI
JOIN acct

{code}
select
  acct.ACC_N,
  acct.brn
FROM LA
JOIN A ON LA.aid = A.id
JOIN PI ON PI.id = LA.pi_id
JOIN acct ON LA.aid = acct.aid
WHERE
  LA.loan_id = 4436
  and acct.brn is not null;
OK
10	122
NULL	NULL
NULL	NULL
{code}, if I set hive.optimize.ppd=false then query returns 1 row BUT the plan does not have "brn is not null"

if I  set hive.optimize.ppd=true and change JOIN statements order to (A,acct,PI) then query returns 1 row AND the plan HAS "brn is not null".
{code}
set hive.optimize.ppd=true;

select
  acct.ACC_N,
  acct.brn
FROM LA
JOIN A ON LA.aid = A.id
JOIN acct ON LA.aid = acct.aid
JOIN PI ON PI.id = LA.pi_id
WHERE
  LA.loan_id = 4436
  and acct.brn is not null;
OK
10	122
{code}


, I tested one of my queries with "set hive.optimize.ppd=false;"
Disabling ppd kills the performance. 9min vs 60 min., disabling hive.ppd.remove.duplicatefilters helps
{code}
set hive.ppd.remove.duplicatefilters=false;
{code}, I looked at the query plans for both cases - remove.duplicatefilters false and true
if remove.duplicatefilters is false then
- Filter Operator predicates are added to Reduce step (including the predicates for "acct" table)
- But Filter Operator predicates still not added to Map step for "acct" table.

I did some performance tests - looks like duplicating Filter Operator predicates to Reduce step does not affect the performance noticeably.
So, disabling hive.ppd.remove.duplicatefilters can be used as a good workaround until we find a way on how to fix query plan to include Filter Operator predicates on Map step for "acct" table.

, Changing the order of JOIN operators fixes the plan.
Filter Operator predicates are added to Map step for "acct" table., I have attached an exploratory patch. This fixes the issue but needs to be revised further.
It seems like HIVE-4293 introduced this bug.
Will upload a revised patch later., Thank you Laljo John for looking at the issue. I tried the patch #1. Yes, it makes output to contain just 1 row. Probably the filter is added to Reduce step.
BUT, IMHO the patch #1 does not fix the root cause of the problem. I still do not see Filter Operator predicate (brn is not null) for acct table on Map step.
{code}
select
  acct.ACC_N,
  acct.brn
FROM L
JOIN LA ON L.id = LA.loan_id
JOIN FR ON L.id = FR.loan_id
JOIN A ON LA.aid = A.id
JOIN PI ON PI.id = LA.pi_id
JOIN acct ON A.id = acct.aid
WHERE
  L.id = 4436
  and acct.brn is not null;
{code}
{code}
        acct 
          TableScan
            alias: acct
            Statistics: Num rows: 5 Data size: 63 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: aid is not null (type: boolean)
              Statistics: Num rows: 3 Data size: 37 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col5 (type: int)
                  1 id (type: int)
                  2 aid (type: int)
{code}

Hovewer, if you change JOIN order and put "acct" before "PI" then the plan will be correct - Map Local Operator Tree for acct table will have Filter Operator predicate (brn is not null)
{code}
select
  acct.ACC_N,
  acct.brn
FROM L
JOIN LA ON L.id = LA.loan_id
JOIN FR ON L.id = FR.loan_id
JOIN A ON LA.aid = A.id
JOIN acct ON A.id = acct.aid
JOIN PI ON PI.id = LA.pi_id
WHERE
  L.id = 4436
  and acct.brn is not null;
{code}
{code}
          TableScan
            alias: acct
            Statistics: Num rows: 5 Data size: 63 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (aid is not null and brn is not null) (type: boolean)
              Statistics: Num rows: 2 Data size: 25 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col5 (type: int)
                  1 id (type: int)
                  2 aid (type: int)
{code}, LOG info for the queries with different JOIN operators order

L, LA, FR, A, PI, acct - only 2 log messages from ppd.OpProcFactory contain "= 120"
{code}
explain
select
  acct.ACC_N,
  acct.brn
FROM L
JOIN LA ON L.id = LA.loan_id
JOIN FR ON L.id = FR.loan_id
JOIN A ON LA.aid = A.id
JOIN PI ON PI.id = LA.pi_id
JOIN acct ON A.id = acct.aid
WHERE
  L.id = 4436
  and acct.brn = 120;

15/06/03 16:31:47 [main]: INFO ppd.OpProcFactory: Processing for FIL(25)
15/06/03 16:31:47 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of FIL For Alias : acct
15/06/03 16:31:47 [main]: INFO ppd.OpProcFactory: 	(_col20 = 120)

15/06/03 16:31:47 [main]: INFO ppd.OpProcFactory: Processing for JOIN(24)
15/06/03 16:31:47 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of JOIN For Alias : acct
15/06/03 16:31:47 [main]: INFO ppd.OpProcFactory: 	(VALUE._col19 = 120)

  Stage: Stage-9
    Map Reduce
                    Select Operator
                      expressions: _col19 (type: int), 120 (type: int)
{code}

L, LA, FR, A, acct, PI - 8 log lines from  ppd.OpProcFactory contain "= 120"

{code}
explain
select
  acct.ACC_N,
  acct.brn
FROM L
JOIN LA ON L.id = LA.loan_id
JOIN FR ON L.id = FR.loan_id
JOIN A ON LA.aid = A.id
JOIN acct ON A.id = acct.aid
JOIN PI ON PI.id = LA.pi_id
WHERE
  L.id = 4436
  and acct.brn = 120;

15/06/03 15:45:25 [main]: INFO ppd.OpProcFactory: Processing for FIL(25)
15/06/03 15:45:39 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of FIL For Alias : acct
15/06/03 15:45:39 [main]: INFO ppd.OpProcFactory: 	(_col20 = 120)

15/06/03 15:46:23 [main]: INFO ppd.OpProcFactory: Processing for JOIN(24)
15/06/03 15:46:23 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of JOIN For Alias : acct
15/06/03 15:46:23 [main]: INFO ppd.OpProcFactory: 	(VALUE._col19 = 120)

15/06/03 15:46:26 [main]: INFO ppd.OpProcFactory: Processing for RS(21)
15/06/03 15:46:26 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of RS For Alias : acct
15/06/03 15:46:26 [main]: INFO ppd.OpProcFactory: 	(_col20 = 120)

15/06/03 15:46:43 [main]: INFO ppd.OpProcFactory: Processing for FIL(20)
15/06/03 15:46:49 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of FIL For Alias : acct
15/06/03 15:46:49 [main]: INFO ppd.OpProcFactory: 	(_col20 = 120)

15/06/03 15:46:52 [main]: INFO ppd.OpProcFactory: Processing for JOIN(19)
15/06/03 15:46:52 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of JOIN For Alias : acct
15/06/03 15:46:52 [main]: INFO ppd.OpProcFactory: 	(VALUE._col1 = 120)

15/06/03 15:59:18 [main]: INFO ppd.OpProcFactory: Processing for RS(18)
15/06/03 15:59:18 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of RS For Alias : acct
15/06/03 15:59:18 [main]: INFO ppd.OpProcFactory: 	(brn = 120)

15/06/03 15:59:19 [main]: INFO ppd.OpProcFactory: Processing for FIL(17)
15/06/03 15:59:50 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of FIL For Alias : acct
15/06/03 15:59:50 [main]: INFO ppd.OpProcFactory: 	(brn = 120)

15/06/03 16:00:20 [main]: INFO ppd.OpProcFactory: Processing for TS(4)
15/06/03 16:00:20 [main]: INFO ppd.OpProcFactory: Pushdown Predicates of TS For Alias : acct
15/06/03 16:00:20 [main]: INFO ppd.OpProcFactory: 	aid is not null
15/06/03 16:00:20 [main]: INFO ppd.OpProcFactory: 	(brn = 120)

15/06/03 16:01:38 [main]: INFO optimizer.ConstantPropagateProcFactory: expr Const int 120 fold from Column[VALUE._col19] is removed.

15/06/03 16:01:38 [main]: INFO optimizer.ColumnPrunerProcFactory: RS 21 oldColExprMap: {VALUE._col5=Column[_col5], VALUE._col4=Const int 4436, VALUE._col3=Column[_col3], VALUE._col2=Column[_col2], VALUE._col1=Column[_col1], VALUE._col0=Const int 4436, KEY.reducesinkkey0=Column[_col6], VALUE._col14=Column[_col15], VALUE._col13=Column[_col14], VALUE._col16=Column[_col17], VALUE._col15=Column[_col16], VALUE._col18=Column[_col19], VALUE._col9=Const int 4436, VALUE._col17=Column[_col18], VALUE._col8=Column[_col9], VALUE._col7=Column[_col8], VALUE._col19=Const int 120, VALUE._col6=Column[_col7], VALUE._col20=Column[_col21], VALUE._col11=Column[_col12], VALUE._col21=Column[_col22], VALUE._col12=Column[_col13], VALUE._col22=Column[_col23], VALUE._col10=Column[_col11]}

15/06/03 16:01:38 [main]: INFO optimizer.ColumnPrunerProcFactory: RS 18 oldColExprMap: {VALUE._col4=Column[ROW__ID], VALUE._col3=Column[INPUT__FILE__NAME], VALUE._col2=Column[BLOCK__OFFSET__INSIDE__FILE], VALUE._col1=Const int 120, VALUE._col0=Column[acc_n], KEY.reducesinkkey0=Column[aid]}

STAGE PLANS:
  Stage: Stage-12
        acct 
          TableScan
            alias: acct
            Statistics: Num rows: 5 Data size: 63 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (aid is not null and (brn = 120)) (type: boolean


  Stage: Stage-9
    Map Reduce
                    Select Operator
                      expressions: _col19 (type: int), 120 (type: int)
{code}, [~apivovarov] I see that predicate is being pushed down with the patch. See the attached explain below:
hive> explain select acct.ACC_N,  acct.brn FROM L JOIN LA ON L.id = LA.loan_id JOIN FR ON L.id = FR.loan_id JOIN A ON LA.aid = A.id JOIN PI ON PI.id = LA.pi_id JOIN acct ON A.id = acct.aid and acct.brn is not null WHERE  L.id = 4436; 
OK
STAGE DEPENDENCIES:
  Stage-12 is a root stage
  Stage-9 depends on stages: Stage-12
  Stage-0 depends on stages: Stage-9

STAGE PLANS:
  Stage: Stage-12
    Map Reduce Local Work
      Alias -> Map Local Tables:
        a 
          Fetch Operator
            limit: -1
        acct 
          Fetch Operator
            limit: -1
        fr 
          Fetch Operator
            limit: -1
        l 
          Fetch Operator
            limit: -1
        pi 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        a 
          TableScan
            alias: a
            filterExpr: id is not null (type: boolean)
            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: id is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col5 (type: int)
                  1 id (type: int)
                  2 aid (type: int)
        acct 
          TableScan
            alias: acct
            filterExpr: (brn is not null and aid is not null) (type: boolean)
            Statistics: Num rows: 3 Data size: 31 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (brn is not null and aid is not null) (type: boolean)
              Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col5 (type: int)
                  1 id (type: int)
                  2 aid (type: int)
        fr 
          TableScan
            alias: fr
            filterExpr: (loan_id = 4436) (type: boolean)
            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (loan_id = 4436) (type: boolean)
              Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 4436 (type: int)
                  1 4436 (type: int)
                  2 4436 (type: int)
        l 
          TableScan
            alias: l
            filterExpr: (id = 4436) (type: boolean)
            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (id = 4436) (type: boolean)
              Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 4436 (type: int)
                  1 4436 (type: int)
                  2 4436 (type: int)
        pi 
          TableScan
            alias: pi
            filterExpr: id is not null (type: boolean)
            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: id is not null (type: boolean)
              Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 _col6 (type: int)
                  1 id (type: int)

  Stage: Stage-9
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: la
            filterExpr: (((loan_id is not null and aid is not null) and pi_id is not null) and (loan_id = 4436)) (type: boolean)
            Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (((loan_id is not null and aid is not null) and pi_id is not null) and (loan_id = 4436)) (type: boolean)
              Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE
              Map Join Operator
                condition map:
                     Inner Join 0 to 1
                     Inner Join 0 to 2
                keys:
                  0 4436 (type: int)
                  1 4436 (type: int)
                  2 4436 (type: int)
                outputColumnNames: _col5, _col6
                Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                Filter Operator
                  predicate: _col5 is not null (type: boolean)
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Map Join Operator
                    condition map:
                         Inner Join 0 to 1
                         Inner Join 1 to 2
                    keys:
                      0 _col5 (type: int)
                      1 id (type: int)
                      2 aid (type: int)
                    outputColumnNames: _col6, _col19, _col20
                    Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                    Filter Operator
                      predicate: _col6 is not null (type: boolean)
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col6 (type: int)
                          1 id (type: int)
                        outputColumnNames: _col19, _col20
                        Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                        Select Operator
                          expressions: _col19 (type: int), _col20 (type: int)
                          outputColumnNames: _col0, _col1
                          Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                          File Output Operator
                            compressed: false
                            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                            table:
                                input format: org.apache.hadoop.mapred.TextInputFormat
                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

Time taken: 3143.501 seconds, Fetched: 154 row(s)
hive> 
, Never Mind thats the wrong query.
I think i can report the filter not getting in to mapper with the original query., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12736779/HIVE-10841.patch

{color:red}ERROR:{color} -1 due to 101 failed/errored test(s), 8998 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_autogen_colalias
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_filter_cond_pushdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_filter_join_breaktask
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join28
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join33
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_alt_syntax
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_hive_626
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_vc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_ppd
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_join_union
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_no_hooks
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_outer_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_nondeterministic
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_json_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_parse_url_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_unionDistinct_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_inner_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_mr_diff_schema_alias
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_12
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_filter_join_breaktask
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_hybridgrace_hashjoin_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_lvj_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_unionDistinct_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_inner_join
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_mr_diff_schema_alias
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_2
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_subq_in
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_filter_join_breaktask
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_index_auto_self_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join28
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join33
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_alt_syntax
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_hive_626
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_vc
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_view
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_join_union
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_in
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union22
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_mapjoin_reduce
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4172/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4172/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4172/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 101 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12736779 - PreCommit-HIVE-TRUNK-Build, Better to put code/sql/plan to \{code\}...\{code\} blocks. It will be easier to read, Attached modified patch.
This patch address correctness & predicate push down to mapper., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12738118/HIVE-10841.1.patch

{color:red}ERROR:{color} -1 due to 98 failed/errored test(s), 9002 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_autogen_colalias
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_filter_cond_pushdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_filter_join_breaktask
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join28
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join33
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_alt_syntax
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_cond_pushdown_unqual4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_hive_626
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_vc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_ppd
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_join_union
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_no_hooks
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_outer_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_json_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_parse_url_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_unionDistinct_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_inner_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_mr_diff_schema_alias
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_12
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_filter_join_breaktask
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_hybridgrace_hashjoin_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_lvj_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_unionDistinct_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_inner_join
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_mr_diff_schema_alias
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_subq_in
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_filter_join_breaktask
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_index_auto_self_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join28
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join33
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_alt_syntax
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_hive_626
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_vc
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_view
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_join_union
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_in
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union22
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_mapjoin_reduce
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4204/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4204/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4204/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 98 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12738118 - PreCommit-HIVE-TRUNK-Build, [~jpullokkaran], thank you for HIVE-10841.1.patch.
It changes 2 files:
- SemanticAnalyzer.java
- OpProcFactory.java

I tried the fix in SemanticAnalyzer.java only. It solve the issue with my test query.
So, looks like the fix in SemanticAnalyzer.java is enough to solve the issue.

Why do we need fixes in OpProcFactory.java? Should we open separate Jira for them?

2. Looks like we need to rerun bunch of Cli, Tez and Spark tests..., [~a.semyannikov]
#1. We need both: SemanticAnalyzer(JoinTree) change for predicate push down & OpProc factory to prevent illegal push downs.
#2 Yes, the failed tests need to be analyzed

, [~a.semyannikov] I hope you don't mind; i have assigned the bug to myself., Sure, np. Btw, my apache id is apivovarov, 3. New integration test which reproduces the issue is also needed
4. Is it possible to add JUnit tests for the fixes?, 5. Can you add RB link?, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12738988/HIVE-10841.2.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 9005 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join28
org.apache.hive.beeline.TestSchemaTool.testSchemaInit
org.apache.hive.beeline.TestSchemaTool.testSchemaUpgrade
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4246/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4246/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4246/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12738988 - PreCommit-HIVE-TRUNK-Build, [~jpullokkaran], I verified that test fails are unrelated.

I uploaded a new version of the patch that includes the test case provided by [~apivovarov]. It will trigger a new QA run., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12739033/HIVE-10841.03.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9008 tests executed
*Failed tests:*
{noformat}
org.apache.hive.beeline.TestSchemaTool.testSchemaInit
org.apache.hive.beeline.TestSchemaTool.testSchemaUpgrade
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4248/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4248/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4248/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12739033 - PreCommit-HIVE-TRUNK-Build, RB Link posted., +1 LGTM, Committed to 1.2.1, Laljo, I noticed that in patches 2 and 03 you removed the change to OpProc.
So, looks like the fix in SemanticAnalyzer.java is enough to solve the issue.

Do you want to cherry-pick the fix to master branch and mark Jira as Resolved?, yes, adding the check in OpProc would have preserved pushed predicates in some cases.
I will start back porting the fixes to other branches., Committed to trunk., [~vikram.dixit] Can i get approval for back porting this to Hive 0.14 maintenance branch?
[~rhbutani] Can i get approval for back porting this to Hive 0.13 maintenance branch?, Laljo, could you cherry-pick the commit to branch-1  (hive-1.3.0)?
https://github.com/apache/hive/commits/branch-1, Committed to branch-1., +1 for 0.14 branch., Resolving. This has been committed to 1.2, 1 and master., Committed to branch 1.0., Does branch-1.0 mean version 1.0.1 or is it the same as branch-1 (version 1.3.0)?

Today I've seen three commits to "refs/heads/branch-1.0" but they don't show Fix Version 1.0.1 on the jira (HIVE-10273, HIVE-10685, and HIVE-10841).  Many other commits go to "refs/heads/branch-1" so I'm confused.  Perhaps we need more details in the wiki.

* [Understanding Hive Branches | https://cwiki.apache.org/confluence/display/Hive/HowToContribute#HowToContribute-UnderstandingHiveBranches], Currently the patch is committed to

https://github.com/apache/hive/commits/branch-1
https://github.com/apache/hive/commits/branch-1.0
https://github.com/apache/hive/commits/branch-1.2
https://github.com/apache/hive/commits/master

I updated Fix Version/s field accordingly, So what is branch-1.0?  I thought it was 1.0.1 but don't see it in Fix Version (currently 1.3.0, 1.2.1, 2.0.0)., [~leftylev] I am told 1.0 is the branch that i should commit to.
cc, [~vikram.dixit], [~leftylev] 1.0.1 is a release tag not a branch by itself. Branch 1.0 is the branch where 1.0.1 was spun off from. If we have a 1.0.2, it would be from the top of branch-1.0. The fix versions cannot say 1.0.0 though. We can say it is going to be in 1.0.2., 1.0.1 was released on May 20. How it can be fixed in 1.0.1?  http://apache.mirrors.lucidnetworks.net/hive/hive-1.0.1/, Yes, 1.0.2 is better, Thanks, The light dawns!  Thanks, all.]