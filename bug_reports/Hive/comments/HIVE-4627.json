[These are my steps to reproduce:

{noformat}
## load the input data
$ wget http://dumps.wikimedia.org/other/pagecounts-raw/2008/2008-10/pagecounts-20081001-000000.gz
$ hadoop fs -mkdir /tmp/wikistats
$ hadoop fs -put pagecounts-20081001-000000.gz /tmp/wikistats/

## create the necessary tables.
$ hcat -f /tmp/00_tables.ddl
OK
Time taken: 1.886 seconds
OK
Time taken: 0.654 seconds
OK
Time taken: 0.047 seconds
OK
Time taken: 0.115 seconds

## verify
$ hive -e "select * from pagecounts limit 10;"
...
OK
aa      Main_Page       4       41431
aa      Special:ListUsers       1       5555
aa      Special:Listusers       1       1052
...
$ hive -e "select * from pgc limit 10;"
...
OK
aa/Main_Page/20081001-000000    4       41431
aa/Special:ListUsers/20081001-000000    1       5555
aa/Special:Listusers/20081001-000000    1       1052
...

## produce the hfile splits file
$ hive -f /tmp/01_sample.hql
...
OK
Time taken: 54.681 seconds
[hrt_qa] $ hadoop fs -ls /tmp/hbase_splits
Found 1 items
-rwx------   3 hrt_qa hdfs        270 2013-05-17 19:05 /tmp/hbase_splits

## verify
$ hadoop jar /usr/lib/hadoop/contrib/streaming/hadoop-streaming-1.2.0.1.3.0.0-104.jar -libjars /usr/lib/hive/lib/hive-exec-0.11.0.1.3.0.0-104.jar -input /tmp/hbase_splits -output /tmp/hbase_splits_txt -inputformat SequenceFileAsTextInputFormat
...
13/05/17 19:08:38 INFO streaming.StreamJob: Output: /tmp/hbase_splits_txt
$ hadoop fs -cat /tmp/hbase_splits_txt/*
01 61 66 2e 71 2f 4d 61 69 6e 5f 50 61 67 65 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00 (null)
01 61 66 2f 31 35 35 30 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00      (null)
01 61 66 2f 32 38 5f 4d 61 61 72 74 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00  (null)
01 61 66 2f 42 65 65 6c 64 3a 31 30 30 5f 31 38 33 30 2e 4a 50 47 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00    (null)

## decoding the first line from utf8 bytes to String yields "af.q/Main_Page/20081001-000000," which is correct

## generate the hfiles
$ HADOOP_CLASSPATH=/usr/lib/hbase/hbase-0.94.6.1.3.0.0-104-security.jar hive -f /tmp/02_hfiles.hql
{noformat}
, This is the patch to TOP to support Hive., Can I ask the hadoop version you've used?, hadoop-1.2.0, bump. updating wiki link.]