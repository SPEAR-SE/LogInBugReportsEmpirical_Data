[Is it correct to add extra zeros to the decimal places if the scale value is less than the desired decimal scale value?

For instance:
0.0   in decimal(5,4)  may be  0.0000
2.56 in decimal(5,4)  may be  2.5600

I have seen this format is enforced in other databases and applications, and it helps users to have a better view of its decimal data., For the same reason as we don't trim trailing zeros, personally I don't think we should append zeros either. Some databases may choose to do so in formatting the output, to me this seems questionable, non-essential at least.

This JIRA is to deal with trailing zero cases., What's the desired behavior then? If we have a field that says it holds values that are decimal(5,4), should someone including a 0.0 get a NULL or an implicit cast?, It will preserve the trailing zeros up to the scale allows.

For instance:
  0 in decimal(5,4) would be 0
  0.0 in decimal(5,4) would be 0.0
  0.00 in decimal(5,4) would be 0.00
  0.00000000 in decimal(5,4) would be 0.0000

Is that correct [~xuefuz] ?, {quote}
What's the desired behavior then? If we have a field that says it holds values that are decimal(5,4), should someone including a 0.0 get a NULL or an implicit cast?
{quote}

decimal(5,4) is perfectly okay to hold 0.0, which has precision of 1 and scale of 1. Maybe I misunderstood the question., {quote}
It will preserve the trailing zeros up to the scale allows.
{quote}

That's what I think right. Please feel free to assigned this to yourself, [~spena]. Removing the method trim() from HiveDecimal is pretty what needs to be done., Thanks [~xuefuz].

Btw, I cannot assign it to myself. Could you assign it to me? 
How can I get permissions to assign tickets?, [~spena] Enrolled you to contributor list. Now you can assign issues to yourself freely., What will happen with the trailing zeros when calling a math function on decimals? [~xuefuz]

For instance,
3.14000 * 2.1  =  6.28? or 6.28000?
5.34000 - 0.3  = 5.04000?

Should I use leave the zeros up to the bigger scale? Or should I trim them as well?, This is what BigDecimal returns when doing some basic maths:

3.140 * 1.0000 = 3.1400000
3.140 / 1.0000 = 3.14
3.140 + 1.0000 = 4.1400
3.140 - 1.0000 = 2.1400
3.140 * 3.140   = 9.859600
, RB: https://reviews.apache.org/r/24467/, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12660634/HIVE-7373.1.patch

{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 5885 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_char_pad_convert
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_precision
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_data_types
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_decimal
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_data_types
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/236/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/236/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-236/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 12 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12660634, Canceling patch as HIVE-7373.1.patch is failing. , Update new patch that fix tests failures., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12661065/HIVE-7373.2.patch

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 5891 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal_native
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_decimal
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_join_hash
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/265/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/265/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-265/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12661065, Cancel patch to fix failed tests., Add  patch that fix Avro decimal failed tests.

org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal_native
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_decimal

The other filed tests are not related with this fix., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12661736/HIVE-7373.3.patch

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 5896 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal_native
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hive.jdbc.TestJdbcDriver2.testDatabaseMetaData
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/309/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/309/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-309/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12661736, cancel patch because avro_decimal filed tests, Add patch with avro decimal query results fixed to pass the tests., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12661864/HIVE-7373.4.patch

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 5896 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_decimal_native
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hive.jdbc.TestJdbcDriver2.testDatabaseMetaData
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/311/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/311/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-311/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12661864, [~spena] I see there is a slight difference in trailing space of the avro_decimal test. I wonder if you have the latest HEAD?, cancel patch to reattach a patch with trailing spaces issue, Attach new patch with the avro_decimal*.q trailing spaces issue., [~brocknoland] I thought I fixed that issue with the .4.patch
I attached the new one, I had to checkout the two files again, and then do the changes manually instead with -Dtest.output.overwrite=true., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12662102/HIVE-7373.5.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 5810 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_trailing
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/338/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/338/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-338/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12662102, decimal_trailing.q failed after I rebase origin/trunk (9be9bd7f663e421f9f50cb3b3bc054b7eb9ef647). 

I am canceling this patch to upload a new one., 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12662144/HIVE-7373.6.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/343/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/343/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-343/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as "KW_STRUCT" using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as "KW_ARRAY" using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as "KW_UNIONTYPE" using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as "KW_NULL" using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as "KW_TRUE" using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as "KW_DATE StringLiteral" using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:261:5: 
Decision can match input such as "KW_FALSE" using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "KW_BETWEEN KW_MAP LPAREN" using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:393:5: 
Decision can match input such as "{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:518:5: 
Decision can match input such as "{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}" using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1736 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-exec ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-exec ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
     [copy] Copying 7 files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-exec ---
[INFO] Compiling 209 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/exec/tez/TestTezTask.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/exec/tez/TestTezTask.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/TestSQLStdHiveAccessController.java:[47,51] constructor SQLStdHiveAccessController in class org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController cannot be applied to given types;
  required: org.apache.hadoop.hive.ql.security.authorization.plugin.HiveMetastoreClientFactory,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider,org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthzSessionContext
  found: <nulltype>,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
  reason: actual and formal argument lists differ in length
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/TestSQLStdHiveAccessController.java:[97,51] constructor SQLStdHiveAccessController in class org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController cannot be applied to given types;
  required: org.apache.hadoop.hive.ql.security.authorization.plugin.HiveMetastoreClientFactory,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider,org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthzSessionContext
  found: <nulltype>,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
  reason: actual and formal argument lists differ in length
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [10.200s]
[INFO] Hive Ant Utilities ................................ SUCCESS [5.791s]
[INFO] Hive Shims Common ................................. SUCCESS [4.019s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.868s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [3.875s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [2.521s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [7.182s]
[INFO] Hive Shims ........................................ SUCCESS [0.894s]
[INFO] Hive Common ....................................... SUCCESS [8.663s]
[INFO] Hive Serde ........................................ SUCCESS [17.085s]
[INFO] Hive Metastore .................................... SUCCESS [39.328s]
[INFO] Hive Query Language ............................... FAILURE [1:11.759s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:56.874s
[INFO] Finished at: Fri Aug 15 18:01:29 EDT 2014
[INFO] Final Memory: 96M/682M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/TestSQLStdHiveAccessController.java:[47,51] constructor SQLStdHiveAccessController in class org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController cannot be applied to given types;
[ERROR] required: org.apache.hadoop.hive.ql.security.authorization.plugin.HiveMetastoreClientFactory,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider,org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthzSessionContext
[ERROR] found: <nulltype>,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
[ERROR] reason: actual and formal argument lists differ in length
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/test/org/apache/hadoop/hive/ql/security/authorization/plugin/sqlstd/TestSQLStdHiveAccessController.java:[97,51] constructor SQLStdHiveAccessController in class org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController cannot be applied to given types;
[ERROR] required: org.apache.hadoop.hive.ql.security.authorization.plugin.HiveMetastoreClientFactory,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider,org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthzSessionContext
[ERROR] found: <nulltype>,org.apache.hadoop.hive.conf.HiveConf,org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
[ERROR] reason: actual and formal argument lists differ in length
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-exec
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12662144, Looks like the build was broken. Re-uploading the same patch., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12662389/HIVE-7373.6.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 5819 tests executed
*Failed tests:*
{noformat}
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/370/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/370/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-370/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12662389, Whats the change in BinarySortableSerDe for?, There is a problem when storing the factor value when serializing the value 0. When serializing 0, it was deserializing 0.00

The bug is that factor was being serialized with no changes only when its sign was 1 (positive). The other signs, 0 and negative, were negating the factor.
Then, in the deserialize function, the factor was deserializing positive and 0 values. And only the negative value was negating the factor.

(serialize)
    int sign = dec.compareTo(HiveDecimal.ZERO);
    int factor = dec.precision() - dec.scale();
    factor = sign == 1 ? factor : -factor;                                 (BUG)
    writeByte(buffer, (byte) ( sign + 1), invert);

(deserialize)
    int b = buffer.read(invert) - 1;
    boolean positive = b != -1;
    if (!positive) {
           factor = -factor;
    }

Here's a data example about the bug:
length=1                  prec-scal	serialize |	deserialize scale = factor-length
-1.0    decimal(1,1)  factor=0  factor=-0 |	factor=0    scale =  0-1 (-1)
-1       decimal(1,0)  factor=1  factor=-1 |	factor=1    scale =  1-1  (0)
 0       decimal(1,0)  factor=1  factor=-1 |	factor=-1   scale = -1-1 (-2) BUG
 0.0    decimal(1,1)  factor=0  factor=-0 |	factor=-0   scale =  0-1 (-1)
 1       decimal(1,0)  factor=1  factor=1  |	factor=1    scale =  1-1  (0)
 1.0    decimal(1,1)  factor=0  factor=0  |	factor=0    scale =  0-1 (-1)

And with the fix on serialize:
   factor = sign != -1 ? factor : -factor;                                 (FIX)

 length=1                 prec-scal	serialize |	deserialize scale = factor-length
-1.0    decimal(1,1)  factor=0  factor=-0 |	factor=0    scale =  0-1 (-1)
-1       decimal(1,0)  factor=1  factor=-1 |	factor=1    scale =  1-1  (0)
 0       decimal(1,0)  factor=1  factor=1  |	factor=1    scale = -1-1  (0) FIX
 0.0    decimal(1,1)  factor=0  factor=0  |	factor=0    scale =  0-1 (-1)
 1       decimal(1,0)  factor=1  factor=1  |	factor=1    scale =  1-1  (0)
 1.0    decimal(1,1)  factor=0  factor=0  |	factor=0    scale =  0-1 (-1), Nice. I am +1 on this change., Thank you very much for your contribution! I have committed this to trunk!, Should this change in behavior be mentioned in the user docs?, Hi Lefty,

Great point. I added TODOC14. 

[~spena] can you come up with a good user facing statement for this one? Something like 

"Prior to 0.14 trailing zeros on decimals were unnecessarily trimmed ...", [~leftylev] Here's the statement. 
Does it need more explanation or examples?

"Prior to 0.14, Hive used to trim trailing zeros for decimal numbers. Currently, the trailing zeros are preserved up to what the scale allows (HIVE-7373).", Thanks [~spena], that's clear and doesn't need examples except for math functions.  Even those should probably just have examples in these comments, then the wiki can refer to them here.

Did you implement the same thing BigDecimal does?

{quote}
This is what BigDecimal returns when doing some basic maths:
3.140 * 1.0000 = 3.1400000
3.140 / 1.0000 = 3.14
3.140 + 1.0000 = 4.1400
3.140 - 1.0000 = 2.1400
3.140 * 3.140 = 9.859600
{quote}, It is true only if the calculations are made between the fields and/or using cast().
For instance:
{noformat}
0: jdbc:hive2://localhost:10000> select a, b, a*b, a/b, a+b, a-b, a*a from decimal;
+--------+-------+----------+-------+--------+--------+-----------+--+
|   a    |   b   |   _c2    |  _c3  |  _c4   |  _c5   |    _c6    |
+--------+-------+----------+-------+--------+--------+-----------+--+
| 3.140  | 1.00  | 3.14000  | 3.14  | 4.140  | 2.140  | 9.859600  |
+--------+-------+----------+-------+--------+--------+-----------+--+
{noformat}

I've just tested a calculation using constants, and they're not working as expected
- select 3.140 * 1.00;   <-- You need to use a cast() on these values in order to get 
  the correct results., I am investigating why vector_decimal_aggregate.q has a different output (extra trailing decimal zeroes for some query output values).  When you edit vector_decimal_aggregate.q to turn off vectorization and then re-run with it on, the outputs are different.

(The same is true for vector_decimal_cast.q, vector_decimal_math_funcs.q, etc)

I have looked at the patch #6 and it looks to me like this is point where outputs diverged...  That is, the divergence may have been caused by -Dtest.output.overwrite=true, Hi [~mmccline],

The trailing zeros are left on the values because the casting is indicating so. But, I confirmed that the outputs are different when the vectorization is off.

I will take a look at this issue., Please handle the difference when vectorization is off on a new jira and link to it here., This has been fixed in 0.14 release. Please open new jira if you see any issues.
, Doc note:  Removed the TODOC14 label because this was reverted by HIVE-8745 in 0.14.0.]