[The loop in CopactorInputFormat.getSplits() is expecting delta/base or original file but ends up seeing a bucket file in an acid delta dir, In the case of this test at least it's due to compaction being invoked via 
    txnHandler.compact(new CompactionRequest("default", Table.ACIDTBLPART.name(), CompactionType.MAJOR));
but the target table is Partitioned.  Thus in CompactorMR.run()
    AcidUtils.Directory dir = AcidUtils.getAcidState(new Path(sd.getLocation()), conf, txns, false, true);

ends up finding the delta.../bucket.. files but thinks they are "original" because they are not at the level where they are expected.

Compacting all partitions of a partition table in one command is not supported.
If compaction is invoked via Alter Table (as it should), DDLTask.compact() will check that if table is partitioned then partition spec is supplied.

todo: add some checks to getAcidState() to do some sanity checking to make sure it raises some error if it finds unexpected directory layout. 

, Just a savepoint. 
1. It turned out that "TestTxnCommands2.updateDeletePartitioned" test does not specify partition name 
   when it sends 'compact' request through 'TxnStore', a transaction related call handler from the Driver,
   on the partitioned table. 
2. The Hive Executor sets up a compaction MR task for a table (simply because of the fact that
   "partitionName" is missing assuming the compaction request is for a table. Even though it is for a partition.
3. The compator MR at CompactorInputFormat.addFileToMap() finds out the physical dir/file structure 
   for the table does not match the pattern built at 2. So generates the error "No match found". , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12893663/HIVE-17232.01.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 11315 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=101)
org.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=204)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=221)
org.apache.hadoop.hive.ql.parse.authorization.plugin.sqlstd.TestOperation2Privilege.checkHiveOperationTypeMatch (batchId=269)
org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testTempTable (batchId=231)
org.apache.hive.jdbc.TestTriggersTezSessionPoolManager.testTriggerHighShuffleBytes (batchId=228)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/7452/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/7452/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7452/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12893663 - PreCommit-HIVE-Build, [~ekoifman] please review the patch 01. 
Thanks, 
Steve. , Some comments:
1. Table.java is a generated class based on hive_metastore.thrift so anything you add to it manually will be lost next time it is regenerated
2. Instead of just "No match found" the error msg should include the file name that it was trying to process so that we can debug this if it happens again.
3. If you want the Work to check for table level compaction request for partitioned tables it should put the compaction request into failed state (markFailed()) - this way it is visible to the end user in SHOW COMPACTIONS.
, This can happen when a table level compaction via ALTER TABLE is requested for a partitioned table.
The error propagation for this was improved in HIVE-17361.  Now the error has the file name it couldn't parse.]