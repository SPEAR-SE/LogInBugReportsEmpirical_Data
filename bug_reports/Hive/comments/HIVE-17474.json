[the execution plan of hive on spark about DS/query70 is [attached|https://issues.apache.org/jira/secure/attachment/12886590/explain.70.vec].
Investigate the problem, i found that several points
1. the statistics for sub-query is not correct, it estimates nearly 36g about the result while actually the result is very small(nearly 30 rows about state info). Because of this, the join between part1 and part2(see jira description) is common join not map join. Maybe the calculation of statistics estimation need be more intelligent in such complex sub-query.
{code}
  Reducer 12 
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: double)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 4991930471 Data size: 109822470377 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: double
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col1 DESC NULLS LAST
                        partition by: _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col1
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 4991930471 Data size: 109822470377 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (rank_window_0 <= 5) (type: boolean)
                    Statistics: Num rows: 1663976823 Data size: 36607490111 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: string)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1663976823 Data size: 36607490111 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 1663976823 Data size: 36607490111 Basic stats: COMPLETE Column stats: NONE
{code}
, [~xuefuz], [~lirui]: can you help view above issue. Thanks!, after debugging code, i found part2 join part1 is a map join in tez, this is the difference with hive on spark.Will update the detail reason later., [~lirui] , [~xuefuz]: after debugging in tez, found the part2 join part1 is common merge join(CommonMergeJoinOperator).
{code}
  Reducer 2 
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col7 (type: string)
                  1 _col0 (type: string)

{code}


the implementation of CommonMergeJoin. Does hive on spark enable CommonMergeJoin?
{code}
/*
 * With an aim to consolidate the join algorithms to either hash based joins (MapJoinOperator) or
 * sort-merge based joins, this operator is being introduced. This operator executes a sort-merge
 * based algorithm. It replaces both the JoinOperator and the SMBMapJoinOperator for the tez side of
 * things. It works in either the map phase or reduce phase.
 *
 * The basic algorithm is as follows:
 *
 * 1. The processOp receives a row from a "big" table.
 * 2. In order to process it, the operator does a fetch for rows from the other tables.
 * 3. Once we have a set of rows from the other tables (till we hit a new key), more rows are
 *    brought in from the big table and a join is performed.
 */
{code}, [~kellyzly], I think CommonMergeJoinOperator is specific to Tez and HoS doesn't use it. But seems CommonMergeJoinOperator is not map join for Tez - Tez also uses MapJoinOperator for map join. And you can also look at the edge type - I think map join will use a BROADCAST_EDGE.

So the problem is the estimated data size of Reducer12 is too big right? The graph is something like {{Map9 -> Reducer10 -> Reducer11 -> Reducer12}}. Do you know at which step the statistics begin to go incorrect?, [~lirui]: thanks for reply. I am debugging whether there is problem about statistics.
By the way,can we solve the problem by converting the common join to skewed join?
As  all keys in part2 is very big and the distinct key is very few(less than 30), can we think this is a  skew case? I have tried to set hive.optimize.skewjoin as true and hive.skewjoin.key as 100000. But it seems not effect.  I am very curious  why skew join does not have effect. From the doc, it seems will 
{code}
A join B on A.id=B.id 
And A skews for id=1. Then we perform the following two joins: 
1.  A join B on A.id=B.id and A.id!=1 
2.  A join B on A.id=B.id and A.id=1 
If B doesnâ€™t skew on id=1, then #2 will be a map join.
{code}
I think after enabling skew join, all keys in part2 will be skewed keys, part2 will map join with part1. , [~kellyzly], skew is detected by simply counting the size of each key group. If you set hive.skewjoin.key=100000, it means a key is considered skew if it appears at least 100000 times. You can check whether your data has such keys. Usually we consider the join as skewed if there're lots of rows that have the same key. So if part2 has lots of rows with only 30 distinct keys, skew join might help. On the other hand, if part2 only has a small number of rows, skew join might not be a good idea., enlarged map join threshold size to cheat hive to think part1 is small table(in runtime, the size of part1 is very small). After that the execution plan changed, the execution time on 3TB is reduced from 12 min to 78 seconds. For such case where join on the data which keys are low cardinality, map join maybe the  best solution. , I found that we need execute
"analyze table xxx compute statistics for columns" before executing the query.
Attach the different explain([before_analyze|https://issues.apache.org/jira/secure/attachment/12887836/explain.70.before.analyze],[after_analyze|https://issues.apache.org/jira/secure/attachment/12887837/explain.70.after.analyze] )
give an example to show the influence of column statistics 
{code}(select s_state as s_state, sum(ss_net_profit),
                             rank() over ( partition by s_state order by sum(ss_net_profit) desc) as ranking
                      from   store_sales, store, date_dim
                      where  d_month_seq between 1193 and 1193+11
                            and date_dim.d_date_sk = store_sales.ss_sold_date_sk
                            and store.s_store_sk  = store_sales.ss_store_sk
                      group by s_state
                     ) {code}
before compute column statistics
{code}
 Map 9 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  filterExpr: (ss_store_sk is not null and ss_sold_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 27504814 Data size: 825144420 Basic stats: COMPLETE Column stats: PARTIAL
                  Filter Operator
                    predicate: ss_store_sk is not null (type: boolean)
                    Statistics: Num rows: 27504814 Data size: 220038512 Basic stats: COMPLETE Column stats: PARTIAL
                    Select Operator
                      expressions: ss_store_sk (type: bigint), ss_net_profit (type: double), ss_sold_date_sk (type: bigint)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 27504814 Data size: 220038512 Basic stats: COMPLETE Column stats: PARTIAL
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: bigint)
                          1 _col0 (type: bigint)
                        outputColumnNames: _col1, _col2, _col4
                        input vertices:
                          1 Map 12
                        Statistics: Num rows: 30255296 Data size: 242042368 Basic stats: COMPLETE Column stats: NONE
                        Map Join Operator
                          condition map:
                               Inner Join 0 to 1
                          keys:
                            0 _col2 (type: bigint)
                            1 _col0 (type: bigint)
                          outputColumnNames: _col1, _col4
                          input vertices:
                            1 Map 13
                          Statistics: Num rows: 33280826 Data size: 266246610 Basic stats: COMPLETE Column stats: NONE
                          Select Operator
                            expressions: _col4 (type: string), _col1 (type: double)
                            outputColumnNames: _col4, _col1
                            Statistics: Num rows: 33280826 Data size: 266246610 Basic stats: COMPLETE Column stats: NONE
                            Group By Operator
                              aggregations: sum(_col1)
                              keys: _col4 (type: string)
                              mode: hash
                              outputColumnNames: _col0, _col1
                              Statistics: Num rows: 33280826 Data size: 266246610 Basic stats: COMPLETE Column stats: NONE
                              Reduce Output Operator
                                key expressions: _col0 (type: string)
                                sort order: +
                                Map-reduce partition columns: _col0 (type: string)
                                Statistics: Num rows: 33280826 Data size: 266246610 Basic stats: COMPLETE Column stats: NONE
                                value expressions: _col1 (type: double)

{code}
the data size is 266246610

After computing column statistics
{code}
  Map 7 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  filterExpr: (ss_store_sk is not null and ss_sold_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 27504814 Data size: 649740104 Basic stats: COMPLETE Column stats: PARTIAL
                  Filter Operator
                    predicate: ss_store_sk is not null (type: boolean)
                    Statistics: Num rows: 26856871 Data size: 634433888 Basic stats: COMPLETE Column stats: PARTIAL
                    Select Operator
                      expressions: ss_store_sk (type: bigint), ss_net_profit (type: double), ss_sold_date_sk (type: bigint)
                      outputColumnNames: _col0, _col1, _col2
                      Statistics: Num rows: 26856871 Data size: 634433888 Basic stats: COMPLETE Column stats: PARTIAL
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col2 (type: bigint)
                          1 _col0 (type: bigint)
                        outputColumnNames: _col0, _col1
                        input vertices:
                          1 Map 10
                        Statistics: Num rows: 2983893 Data size: 47742288 Basic stats: COMPLETE Column stats: PARTIAL
                        Map Join Operator
                          condition map:
                               Inner Join 0 to 1
                          keys:
                            0 _col0 (type: bigint)
                            1 _col0 (type: bigint)
                          outputColumnNames: _col1, _col6
                          input vertices:
                            1 Map 11
                          Statistics: Num rows: 2983893 Data size: 280485942 Basic stats: COMPLETE Column stats: PARTIAL
                          Group By Operator
                            aggregations: sum(_col1)
                            keys: _col6 (type: string)
                            mode: hash
                            outputColumnNames: _col0, _col1
                            Statistics: Num rows: 9 Data size: 846 Basic stats: COMPLETE Column stats: PARTIAL
                            Reduce Output Operator
                              key expressions: _col0 (type: string)
                              sort order: +
                              Map-reduce partition columns: _col0 (type: string)
                              Statistics: Num rows: 9 Data size: 846 Basic stats: COMPLETE Column stats: PARTIAL
                              value expressions: _col1 (type: double)
{code}
the datasize is 846

 without analyzing column statistics, the cardinaltiy is parentNumRows and the datasize is parentDataSize
 [here|https://github.com/kellyzly/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats/annotation/StatsRulesProcFactory.java#L1204]
 {code}
  // Case 1: NO column stats, NO hash aggregation, NO grouping sets
                cardinality = parentNumRows;
 {code}
 with analyzing column statistics
 [here|https://github.com/kellyzly/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats/annotation/StatsRulesProcFactory.java#L1132] to calculate the cardinality of the Group By Operator, actually it use {{StatsUtils.safeMult(ndvProduct, parallelism)}}(ndvProduct is 3, parallelism is 3, parentNumRows is 2983893, cardinality=Math.min(2983893/2, 3*3)=9)
 the ndvProduct means the distinct value count of table store.Because the distinct value count of store is very small,thus the cardinality is very small. The new datasize is updated to smaller value 846.
 {code}
  // Case 3: column stats, hash aggregation, NO grouping sets
   cardinality = Math.min(parentNumRows / 2, StatsUtils.safeMult(ndvProduct, parallelism));
 {code}
, Thanks [~kellyzly] for the update. Good to know we can get the stats right with the analyze command.]