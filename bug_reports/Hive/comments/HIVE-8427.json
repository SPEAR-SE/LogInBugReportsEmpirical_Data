[Patch sets METASTORE_USE_THRIFT_SASL for secure streaming, How about you use {code} ShimLoader.getHadoopShims().isSecurityEnabled() {code} to determine whether it's a secure cluster or not?, Not a security expert. But here is my thoughts... 

The streaming client (like flume) does not run on the hadoop cluster. It may in fact be streaming to one or more clusters.

The reason for using ugi.hasKerberosCredentials() is not to detect if the hadoop cluster is security enabled, but to check if the streaming client has decided to use secure mode connection (by initializing kerberos on the ugi object). The client should be able to maintain  multiple connections .. one to a secure cluster, and another to a non-secure cluster., [~roshan_naik] Makes sense. Thanks for the note., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12674242/HIVE-8427.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 4137 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_tez_smb_1
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1225/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1225/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1225/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12674242, +1 from my side., +1 for 0.14. , Patch committed to 14 and trunk. Thanks for the patch [~roshan_naik]!, This has been fixed in 0.14 release. Please open new jira if you see any issues.
]