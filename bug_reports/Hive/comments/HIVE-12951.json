[cc: [~lirui], Hi [~xuefuz], Spark has configurations {{spark.scheduler.minRegisteredResourcesRatio}} and {{spark.scheduler.maxRegisteredResourcesWaitingTime}}, which I think serve the purpose of pre-warm. I suppose we do this on hive side because we use the number of executors to set the number of reducers?, Hi [~lirui], thanks for the information. Yes, these seem very relevant. However, I'm not 100% sure if they are equivalent. Looking the description of the first property, I'm not sure what's "expected resources". In Hive, user can specify the number of containers (executors) to prewarm (refer to HIVE-11363).

Yes, this is used to set higher parallelism by waiting briefly, which is important for performance for short-lived user sessions., Thanks Xuefu for the clarifications!
I think "expected resources" is something like {{spark.executor.instances}} (not considering dynamic allocation). These spark configurations are intended for job execution, i.e. pre-warm before scheduling any tasks. But they won't help deciding the parallelism on hive side. Therefore what we do here still makes sense.

The patch LGTM. One concern is that it may cause some tests diff. Otherwise +1., Hi [~xuefuz], I just thought more about this. Maybe we should use the "expected # executors" instead of "available # executors" to decide the parallelism (fall back to what we do now if "expected" is unavailable, e.g. standalone mode). Intuitively, users have more knowledge about their job and will set the expected # executors accordingly. We should honor that, even if the RM cannot grant the required amount. This way, each executor may be assigned more reducers, but the job is less likely to fail because each reducer handles the expected amount of data. Another benefit is our test outputs can be more deterministic.

We can do this in separate JIRA if you think it's OK., Hi [~lirui], that's an interesting idea. I can see that prewarming executors is no longer needed if parallelism is determined by the expected executors. However, prewarming is meant for shor-lived sessions, such as ETL job launched by Oozie. For interactive sessions, this feature doesn't matter much. Therefore, we probably don't want to change the way of determining parallelism just for a less common use case.

Now let's see if using expected number of executors to determine makes sense in the general case. In this case, we don't worry about the performance for the first query. Whether we have static or dynamic allocation, the parallelism is determined in the same way if we use the actual number of executors. On the other hand, if we use the expected number of executors, it seems the expected number of executors is undefined in case of dynamic allocation. Also, the expected may not always match the actual. If there is a big difference, there could be performance implications.

In conclusion, I can certainly see some benefits of using the expected number of executors. However, there also seem some unknowns as well. I think we don't have to make a call at this point. Maybe we can revisit once we learn more or get more user feedback?

What do you think? 

, Generally speaking, I think we have a better chance to get more reducers with expected resources, because RM won't allocate more resources than requested, right? But #reducers is not determined by #executors alone, and like you said we will need to handle dynamic allocations differently. So I agree we can decide this later when there's concrete need for it., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12785705/HIVE-12951.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10048 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testExecuteStatementAsync
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6851/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6851/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6851/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12785705 - PreCommit-HIVE-TRUNK-Build, +1., Committed to master. Thanks, Rui., Hi, we are facing issues while using hive-on-spark prewarm feature. (CDH 5.7.2, HIve 1.1.0, spark 1.6.1 on a small cluster of 5 hosts)
here is what we did:
1. on CM, we changed 
hive.prewarm.enabled to true, 
hive.execution.engine to spark; 
hive.prewarm.numcontainers to 5
spark.dynamicAllocation.minExecutors = 5; 
spark.dynamicAllocation.enabled=true
2. restart hive
3. when we start a new hive session, the first query is still slow, subsequent ones are much faster, It seems that the prewarm config didn't take effect.
Please advise what we have missed.
Thanks
, Hi [~richard_xin], pre-warm is intended to wait until some containers are launched before we decide the parallelism/start the job. In general, it helps us to have a higher parallelism and better task scheduling. However it doesn't remove the start-up overhead for the 1st query - anyway we have to wait for the containers to be launched to run the query.
[~xuefuz] please add if I missed anything., Besides more containers that are already active, the second run also benefits a lot from JIT code generation which cannot be done by prewarning containers.

The right comparison is to measure the performance with and without container prewarming to see if there is any benefit for your first run and make your decision accordingly., Thanks Rui and Xuefu for your quick replies.

>> The right comparison is to measure the performance with and without container prewarming to see if there is any benefit for your first run
we didn't feel any performance benefit with prewarming for the first run. I assume that "first run" here refers to first run per hive session, instead of first run after hive restarts.
We are trying to build a web service to run ad-hoc queries against hive, so each call could be the "first call" for the session.  do you have any recommendations on how we should implement the solution? Based to our tests, some sessions' first query under hive on spark is slower than hive on mr. 
Thanks in advance for your insight.
, Prawarming containers tends to help queries that run for a longer time and have multiple stages. It doesn't help and may have adverse impact if your query is small or has only map stage. The important thing for you is to have a configuration that works for most of your use case.

As to your webservice, you might want to consider pooling a list of HS2 sessions instead of creating a new one each time a request comes., thanks, we will try that]