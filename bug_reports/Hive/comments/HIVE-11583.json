[I have implemented a qtest for this issue, but it requires a rather big data file. What is the best way to submit this file? It is a gzip file, size = 204Kb. I can attach this file to the ticket., +1, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12755773/HIVE-11583.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9412 tests executed
*Failed tests:*
{noformat}
TestParseNegative - did not produce a TEST-*.xml file
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5276/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5276/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5276/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12755773 - PreCommit-HIVE-TRUNK-Build, Pushed to master. Thanks, [~yalovyyi], [~ashutoshc], I have a qTest for this issue, but includes rather big gz - compressed file. What is the best way to contribute it? The question is how to create a patch for this big binary file?
, Spilling is controlled by config {{hive.join.cache.size}} Perhaps, you can set that to very low value in q test so as to trigger spilling and thus testing this without needing a large input data., Oh... I was thinking about all possible ways to reduce the size of file. cahce size is only one piece of the puzzle. The important thing is physical file system blocks and it seems like I cannot control it from withing Hive script., Hive q tests use hive-shims-common/src/main/java/org/apache/hadoop/fs/ProxyLocalFileSystem.java I think you can configure its block size via {{fs.local.block.size}} , I tried, and when I did it from hive script it didn't take any effect. Is the any way to reconfigure it BEFORE the test? , Should this issue be backported to branch-1? It looks like a bug., Yes. It is a quite critical bug. , Committed to branch-1, What about a qtest for this issue? What is the best course of action?, This was committed a while ago... the test can be created in a separate JIRA if needed. I don't have background on this issue, I bulk commented yesterday on a large list of  issues whose title looks like a bug and that were committed to master but not to branch-1, obtained via a script, In  a nutshell the question is what is the best way to upload/provide a rather big binary file to the test? Should I just attach it to a ticket?, You could generate it in the test by repeatedly cross joining. Or does the file have to be in a specific form that is not reproducible by the queries? , I think it should be possible to generate that data set (size of files matter), but I didn't want to make qtest even slower... I'll think about this approach. ]