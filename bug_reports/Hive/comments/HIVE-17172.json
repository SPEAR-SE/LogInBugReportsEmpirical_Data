[[~prasanth_j] can you take a look?, This looks reasonable, but you need to add some unit tests., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12878852/HIVE-17172.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 11012 tests executed
*Failed tests:*
{noformat}
TestPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_uncompressed] (batchId=56)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[timestamptz_2] (batchId=76)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=100)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreStatsMerge.testStatsMerge (batchId=206)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=179)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6132/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6132/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6132/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12878852 - PreCommit-HIVE-Build, Added a test, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12879731/HIVE-17172.01.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 11019 tests executed
*Failed tests:*
{noformat}
TestPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_uncompressed] (batchId=56)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=99)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=179)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6206/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6206/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6206/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12879731 - PreCommit-HIVE-Build, [~prasanth_j] [~owen.omalley] [~djaiswal] ping, +1, actually there's a bug in the test :) will update it, +1 Lgtm., [~sershe] Can you please put the next patch in RB? It is much easier to review that way., Added some comments to the usage of the method (that I needed to look at to fix the test).
Fixed the test to actually test something, and altered one test case that is valid and shouldn't cause an error., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12879904/HIVE-17172.02.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 11041 tests executed
*Failed tests:*
{noformat}
TestPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=236)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=241)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_uncompressed] (batchId=56)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=100)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=179)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6219/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6219/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6219/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12879904 - PreCommit-HIVE-Build, Thanks for adding comments. As far as I understand it looks good. An RB link would have been more helpful in understanding the code though.

+1, Committed to master and branch-2. Thanks for the reviews!, Seems this patch cause {{llap_uncompressed}} test failed:  

{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_uncompressed] (batchId=56)
{noformat}

logs:

{noformat}
2017-08-07T02:02:51,187  INFO [LocalJobRunner Map Task Executor #0] LlapIoImpl: Llap counters: Fragment counters for [wangyuming01/192.16
8.77.55, warehouse.orc_llap, pfile:/root/dev/hive/itests/qtest/target/warehouse/orc_llap/000000_0 ([-4890527034409466364, 1502096569000, 
473356]), 0,1]: [ NUM_VECTOR_BATCHES=0, NUM_DECODED_BATCHES=0, SELECTED_ROWGROUPS=13, NUM_ERRORS=1, ROWS_EMITTED=0, METADATA_CACHE_HIT=0,
 METADATA_CACHE_MISS=2, CACHE_HIT_BYTES=0, CACHE_MISS_BYTES=466121, ALLOCATED_BYTES=0, ALLOCATED_USED_BYTES=0, TOTAL_IO_TIME_NS=18839425,
 DECODE_TIME_NS=0, HDFS_TIME_NS=11545686, CONSUMER_TIME_NS=0 ]
2017-08-07T02:02:51,187 DEBUG [LocalJobRunner Map Task Executor #0] encoded.OrcEncodedDataReader: Encoded reader is being stopped
2017-08-07T02:02:51,187  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Ignoring exception during close for org.apache.hadoop
.mapred.MapTask$TrackedRecordReader@4f92e7b2
java.io.IOException: java.lang.AssertionError: Elements not in order data range [5882, 472003), size: 466121 type: array-backed and data 
range [6070, 472003), size: 465933 type: array-backed; trying to insert into [{range start: -1 end: -1}, {data range [5882, 472003), size
: 466121 type: array-backed}]
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.rethrowErrorIfAny(LlapRecordReader.java:349) ~[hive-llap-server-3.0.0
-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.close(LlapRecordReader.java:340) ~[hive-llap-server-3.0.0-SNAPSHOT.ja
r:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doClose(CombineHiveRecordReader.java:135) ~[hive-exec-3.0.0-SNAPSHOT.jar:
3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.close(HiveContextAwareRecordReader.java:104) ~[hive-exec-3.0.0-SNAPS
HOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.close(HadoopShimsSecure.java:173) ~[hive-shims-common-3
.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.close(MapTask.java:210) ~[hadoop-mapreduce-client-core-2.8.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:1981) [hadoop-mapreduce-client-core-2.8.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:468) [hadoop-mapreduce-client-core-2.8.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343) [hadoop-mapreduce-client-core-2.8.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270) [hadoop-mapreduce-client-common-2.8.0
.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_77]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_77]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_77]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_77]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_77]
Caused by: java.lang.AssertionError: Elements not in order data range [5882, 472003), size: 466121 type: array-backed and data range [607
0, 472003), size: 465933 type: array-backed; trying to insert into [{range start: -1 end: -1}, {data range [5882, 472003), size: 466121 t
ype: array-backed}]
	at org.apache.hadoop.hive.common.io.DiskRangeList.assertInvalidOrder(DiskRangeList.java:64) ~[hive-storage-api-3.0.0-SNAPSHOT.jar
:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.common.io.DiskRangeList.checkOrder(DiskRangeList.java:56) ~[hive-storage-api-3.0.0-SNAPSHOT.jar:3.0.0-S
NAPSHOT]
	at org.apache.hadoop.hive.common.io.DiskRangeList.insertAfter(DiskRangeList.java:126) ~[hive-storage-api-3.0.0-SNAPSHOT.jar:3.0.0
-SNAPSHOT]
	at org.apache.hadoop.hive.common.io.DiskRangeList.split(DiskRangeList.java:183) ~[hive-storage-api-3.0.0-SNAPSHOT.jar:3.0.0-SNAPS
HOT]
	at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.preReadUncompressedStream(EncodedReaderImpl.java:1016) ~[hive-exec-
3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.readEncodedColumns(EncodedReaderImpl.java:382) ~[hive-exec-3.0.0-SN
APSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.performDataRead(OrcEncodedDataReader.java:426) ~[hive-llap-server-
3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader$4.run(OrcEncodedDataReader.java:250) ~[hive-llap-server-3.0.0-SNAP
SHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader$4.run(OrcEncodedDataReader.java:247) ~[hive-llap-server-3.0.0-SNAP
SHOT.jar:3.0.0-SNAPSHOT]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_77]
	at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_77]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807) ~[hadoop-common-2.8.0.jar:?]
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.callInternal(OrcEncodedDataReader.java:247) ~[hive-llap-server-3.0
.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.callInternal(OrcEncodedDataReader.java:96) ~[hive-llap-server-3.0.
0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) ~[tez-common-0.8.4.jar:0.8.4]
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110) ~[hiv
e-llap-server-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	... 4 more
{noformat}, Hmm, I forgot the special case of the mutation helper. Would need to fix before release, [~prasanth_j] can you please take a look? a tiny addendum patch, [~q79969786] thanks for catching this!, +1, Committed to branches., Hive 3.0.0 has been released so closing this jira.]