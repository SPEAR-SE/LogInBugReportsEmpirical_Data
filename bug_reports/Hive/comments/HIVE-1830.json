[After HIVE-1642, joins are automatically converted into map-joins at physical optimization time.

However, this may lead to problems.


For eg:  consider the query:

select T1.val, count(1) from T1 join T2 on T1.key=T2.key group by T1.val


This will have 2 map-reduce jobs, one for the join and the other for group by.

Before HIVE-1642, the partial group for aggregation will be performed in the reducer where the join is performed.
However, after HIVE-1642, the same will be performed in the mapper. The local task will confirm that there is  just
enough memory to hold the map-join data. Hoever, it does not take into account the memory needed for partial group
by.

So, in case there is group by followed by join, it is a good idea to reduce the memory given to the local task to validate
if there is enough memory to fit small table - it can be controlled by a new configuration paramter, but it can be some
default: say 70% of total memory (instead of 90%).

Also, the group by may still run out of memory, so it might be a good idea to check in group by for free memory and
periodically flush memory, Add a new test: auto_join26.q , Carefully measure the memory usage of map side group by.
Flush frequently, if the left memory is less than a threshold., I will take a look , Add the new parameters description in hive-default.xml.
Move the memory threshold in the descriptors (for eg. all the needed confs should be copied in groupbydesc.
and accessed from there, instead of being accessed from HiveConf at runtime) - you already did it from
HashTableSinkOperator
, 1) Add more descriptions in the config file
2) Set the memory usage of hashtable sink op and group by op into their desc. 
The memory usage is deterministic after compiling stage.
,       if (groupByOp.getConf() == null) {
91	        System.out.println("Group by desc is null");
92	        return null;
93	      }




This should never happen


GroupByOperator:
    memoryThreshold = HiveConf.getFloatVar(hconf, HiveConf.ConfVars.HIVEMAPAGGRMâ¬…
EMORYTHRESHOLD);


This should also be in groupByDesc

, 1) Remove the debug statements
2) Add the memory threshold to group by desc., +1, Committed. Thanks Liyin, Doc note:  This added three configuration parameters to HiveConf.java, with descriptions in the template file.  They are documented in the wiki.

* [hive.mapjoin.followby.map.aggr.hash.percentmemory | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.mapjoin.followby.map.aggr.hash.percentmemory]
* [hive.map.aggr.hash.force.flush.memory.threshold | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.map.aggr.hash.force.flush.memory.threshold]
* [hive.mapjoin.followby.gby.localtask.max.memory.usage | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.mapjoin.followby.gby.localtask.max.memory.usage]]