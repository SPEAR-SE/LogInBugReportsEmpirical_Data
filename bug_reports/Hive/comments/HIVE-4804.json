[navis requested code review of "HIVE-4804 [jira] parallel_orderby.q in trunk fails consistently".

Reviewers: JIRA

HIVE-4804 parallel_orderby.q in trunk fails consistently

java.lang.RuntimeException: Error in configuring object
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
	at org.apache.hadoop.mapred.MapTask$OldOutputCollector.<init>(MapTask.java:481)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:390)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:324)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:266)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1278)
	at org.apache.hadoop.mapred.Child.main(Child.java:260)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)
	... 10 more
Caused by: java.lang.IllegalArgumentException: Can't read partitions file
	at org.apache.hadoop.mapred.lib.TotalOrderPartitioner.configure(TotalOrderPartitioner.java:91)
	at org.apache.hadoop.hive.ql.exec.HiveTotalOrderPartitioner.configure(HiveTotalOrderPartitioner.java:37)
	... 15 more
Caused by: java.io.IOException: Split points are out of order
	at org.apache.hadoop.mapred.lib.TotalOrderPartitioner.configure(TotalOrderPartitioner.java:78)
	... 16 more

TEST PLAN
  EMPTY

REVISION DETAIL
  https://reviews.facebook.net/D11571

AFFECTED FILES
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java
  ql/src/test/queries/clientpositive/parallel_orderby.q
  ql/src/test/results/clientpositive/parallel_orderby.q.out

MANAGE HERALD RULES
  https://reviews.facebook.net/herald/view/differential/

WHY DID I GET THIS EMAIL?
  https://reviews.facebook.net/herald/transcript/27351/

To: JIRA, navis
, +1 testing now., Thanks Navis, Integrated in Hive-trunk-hadoop1-ptest #24 (See [https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/24/])
    HIVE-4804 parallel order by fails for small datasets (Navis via egc)

Submitted by:	Navis
Reviewed by:	Edward Capriolo (Revision 1500071)

     Result = SUCCESS
ecapriolo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500071
Files : 
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java
* /hive/trunk/ql/src/test/queries/clientpositive/parallel_orderby.q
* /hive/trunk/ql/src/test/results/clientpositive/parallel_orderby.q.out
, Integrated in Hive-trunk-hadoop2-ptest #7 (See [https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/7/])
    HIVE-4804 parallel order by fails for small datasets (Navis via egc)

Submitted by:	Navis
Reviewed by:	Edward Capriolo (Revision 1500071)

     Result = ABORTED
ecapriolo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500071
Files : 
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java
* /hive/trunk/ql/src/test/queries/clientpositive/parallel_orderby.q
* /hive/trunk/ql/src/test/results/clientpositive/parallel_orderby.q.out
, I apologize for being late on this. I didn't understand the fix completely. Hopefully, [~navis] or [~appodictic] can explain. This testcase was working initially. Both Navis and Ed did run this test before checking in. Than test started to fail randomly. In various runs on apache build machine it used to pass some time and fail at other time. So, there is some randomness going on.
Per my understanding, fix in this patch is to restore number of reducers to 1 in case there are not sufficient number of samples. What I don't understand is how come this scenario of too few samples occur only randomly, shouldn't that be always the case for the test. What further worries me was we were generating wrong results (order by clause was getting ignored before this fix). Are we now guaranteed to never giving out wrong results to end users?, Integrated in Hive-trunk-h0.21 #2181 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2181/])
    HIVE-4804 parallel order by fails for small datasets (Navis via egc)

Submitted by:	Navis
Reviewed by:	Edward Capriolo (Revision 1500071)

     Result = FAILURE
ecapriolo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500071
Files : 
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java
* /hive/trunk/ql/src/test/queries/clientpositive/parallel_orderby.q
* /hive/trunk/ql/src/test/results/clientpositive/parallel_orderby.q.out
, {quote}
What further worries me was we were generating wrong results (order by clause was getting ignored before this fix). Are we now guaranteed to never giving out wrong results to end users?
{quote}

This is a new feature which is not on by default. When we decide to enable it by default by default (in a follow on issue) we should get a good idea of how it works across the board.

I think because the input file is sorted it could be easy for this test to give a false positive. Possibly this is what happened with the initial patch. 

I can not speak to the unpredictable-nests of the build server. Being that it takes my machine ~ 12 hours to run tests, one test run passing is all I can do.

This is a feature hive desperately needs. Probably the most important feature! Order by is a huge bottleneck in many of our processing pipelines. If I had a nickel for every 1 reducer order by job I have seen since I started using hive, I could start my own big data software company without any VC.

Adding a feature enhancement off by default and then turning it on later after we get familiar with it is something we have done quite often.
, Integrated in Hive-trunk-hadoop2 #273 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/273/])
    HIVE-4804 parallel order by fails for small datasets (Navis via egc)

Submitted by:	Navis
Reviewed by:	Edward Capriolo (Revision 1500071)

     Result = ABORTED
ecapriolo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500071
Files : 
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java
* /hive/trunk/ql/src/test/queries/clientpositive/parallel_orderby.q
* /hive/trunk/ql/src/test/results/clientpositive/parallel_orderby.q.out
, [~navis] Do you know the reason for randomness of failure of tests? , I've used kv5.txt for input data (has 25 rows) and default sampling rate was 0.1f. For 4 reducer, sampler need unique 3 keys but by the total number and the sampling rate on it, the sampler could not attain this requirements randomly. 

All I've done in latest patch was to make separate conditions which has enough sample(0.66) and which was not(0.0000.1) by setting sampling rate. 
, What is the next step? what jobs run faster with the single reducer vs the sampling approach? Should this be the default option (I think yes) or something to turn on?, Currently it acts on final RS only. To apply this feature to intermediate RS, we need hand over some context to next fetch operator. It might not needed for HDFS, but still need some tests., That seems fine. Hive already has sort by, I can not see a reason why we would need order by on anything but the final result., [~appodictic] / [~navis] This test still fails on hadoop-2 Would you guys want to take a look : https://builds.apache.org/job/Hive-trunk-hadoop2/288/#showFailuresLink, {quote}
java.lang.NoSuchMethodError: org.apache.hadoop.mapred.lib.TotalOrderPartitioner.setPartitionFile(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/Path;)V
	at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.handleSampling(ExecDriver.java:557)
	at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:438)
	at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:140)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:150)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1423)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1203)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1008)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:880)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:348)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:790)
	at org.apache.hadoop.hive.cli.TestMinimrCliDriver.runTest(TestMinimrCliDriver.java:264)
	at org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_parallel_orderby(TestMinimrCliDriver.java:224)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:243)
	at junit.framework.TestSuite.run(TestSuite.java:238)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:518)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1052)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:906)
junit.framework.AssertionFailedError: Client Execution failed with error code = -101
{quote}

This looks like something we will have to make a shim for or exclude it from Hadoop 2, Lets open another Jira., This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.]