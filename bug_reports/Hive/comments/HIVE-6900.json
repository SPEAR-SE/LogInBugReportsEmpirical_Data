[[~navis] I spoke with some Hadoop core engineers and they commented that Hive should not use HostUtil as it is marked as private (and unstable).

Also, TaskLogServlet is not supported in MR2, so we just need to handle the case where mapreduce.framework.name != yarn (and yarn-tez I assume). We might want to add yarn-tez to the condition., [~cdrome] Yes. I've seen that (the annotation). So I didn't assigned to me, believing there would be someone to know better about this. Could you handle this? I've been stuck still in hive-0.11.0 and I didn't know even that TaskLogServlet is not supported in MR2., I looked at the issue together with [~jdere]. Haven't reviewed the patch but overall this can let the compilation pass. The eventual link is used elsewhere in Hive to pull the logs and do some processing. The link used in the patch will still not work as the URLs changed completely.

We can do this in two halves
 - Fix compilation for now
 - And then follow up in YARN with a right API that can expose logs to users and change Hive to use that.

For the compilation fix, we can put back the previous API in YARN via MAPREDUCE-5830 or we can do the fix as done here in Hive.

Thoughts?, Hadoop 2.4 is already released, right? So even Hadoop-2.5 restored the original API Hive would be broken against 2.4.  So I'd say we should just fix the compilation issue in Hive.  [~vinodkv] you mentioned that even with the compilation fix, whatever we're doing with HostUtil in Hive isn't going to work properly?  If so then maybe we should just remove this code completely from Hadoop23Shims, until we get the proper API from YARN to do what we want.

On the subject of getting a proper YARN API for this, is there already an existing mapreduce Jira for this?, We can fix it in 2.4.1 and Hive can depend on that release if that is the route.

I see you filed MAPREDUCE-5857. It is strictly a YARN issue, I'll move it to the right sub-project., Would like to get this fixed sooner than later, as I'd like for Hive to be able to use 2.4.0.  Using Hadoop 2.4.0 in the Hive build will fix a number of unit test failures that we've been seeing.  I'm thinking to remove use of the HostUtil call since based on Vinod's comment it sounds like the URL we're generating isn't supposed to work anymore.

When MAPREDUCE-5857 is fixed we can add this functionality back to Hadoop23Shims., Patch v2 simply removes use of the HostUtil API.  If folks would still prefer to call into that API, we can use Navis' patch., [~hagleitn],[~ashutoshc] can you take a look?, url on hadoop-2 is incorrect anyway today, so not printing it makes things less-confusing to users. When right api is available from hadoop, we should switch to that. +1, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12642048/HIVE-6900.2.patch

{color:red}ERROR:{color} -1 due to 46 failed/errored test(s), 5418 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_filter_numeric
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby2_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_skew_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_infer_bucket_sort_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_test_outer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nullformatCTAS
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nullgroup3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_createas1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_select_dummy_source
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_show_create_table_alter
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_show_tblproperties
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_partscan_1_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_symlink_text_input_format
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_truncate_column_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_current_database
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_21
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_24
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_unset_table_view_property
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucketizedhiveinputformat
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_dynamic_partitions_with_whitelist
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_partialscan_autogether
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_unset_table_property
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/52/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/52/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 46 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12642048, Committed to trunk. Thanks, Jason!, [~jdere] We were looking at this change and were wondering, why is the log talking about MR1 when it is a Hadoop23Shims?  Isn't the condition of the else statement still MR2, but to handle local mode case?  Seems like TaskServlet is in MR1., Hi Szehon, i don't really know much about the particulars of this issue, the logging statement made reference to MR1 because the original code had a comment about being in MR1 mode if it was in that particular point of the logic.  Definitely feel free to correct it if it is incorrect., This has been fixed in 0.14 release. Please open new jira if you see any issues.
, Btw, I think this issue is still not completely fixed, in that compilation succeeds, but this fails now at runtime because https://issues.apache.org/jira/secure/attachment/12651497/MAPREDUCE-5830.patch was committed in hadoop - The result is that our reflection check to see if the 23_METHOD exists succeeds, which means 23_METHOD will not be null, and 24_METHOD will be null, and thus, at runtime, we will wind up calling 23_METHOD. If hadoop had not "fixed" this bug, with this fix, our shim works, but with their fix, it looks like we still have a runtime problem. :)

I'm going to open a new jira for this and link them, but wanted to mention the rationale here, so that watchers of this jira are notified., Actually, nvm - ignore my comment - that was based on looking at the code for .1.patch. .2.patch makes it so this should never happen. However, I saw that happening in a user's log and assumed that was still the problem. Clearly, though, that user has a weird hive version.]