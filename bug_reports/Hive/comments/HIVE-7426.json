[From: Jason Dere
12:52 AM (13 hours ago)

Looking at the stack trace and code, GenericUDFBasePad (line 65) expects the 3 UDF arguments to be of type Text, IntWritable, Text, respectively.  However, the argument checking done in initialize() only enforces that all 3 arg types are text/int, but it doesn't check that arg 1 is text, arg 2 is int, arg3 is text. So it looks like the query passed in an int value to arg1, and the converter returned an IntWritable where it expected a Text. The generic checkArguments() didn't do its job here - probably needed to have an additional param specifying what the expected type should be.

What it probably should have done is allow arg1/arg3 to be almost any type, but to convert the value to string/text during evaluate().  That would allow the int passed in arg1 to be implicitly cast to string, and the query as written would work.  Or if we want to be strict with the types, Hive could actually throw an error when checking the param types in initialize().  In this case then the user would have to explicitly cast the integer value to string such as LPAD(CAST(<integer_expression> AS STRING), 2, 0)., One of the reasons I believe that Hive TypeChecking should do stricter job of making sure that the input parameters are entered correctly to the fn. In most of the cases, the non-vectorized code path does not run into these kind of issues since the UDF uses  ObjectInspectorConverters to convert from the source object type to the destination object type before performing any operation on it where as vectorized code path needs to do this conversion prior to runtime.

About this jira, this looks like an implementation issue with GenericUDFBasePad.initialize().     

converter1 = checkArguments(arguments, 0);
    converter2 = checkArguments(arguments, 1);
    converter3 = checkArguments(arguments, 2);

These should be replaced with ObjectInspectorVonverters.getConverter() calls . For eg. for the 0th argument , the correct inputOI is checkArguments(arguments, 0), outputOI is WritableStringObjectInspector.
So the call should be
 converter1 = ObjectInspectorConverters.getConverter(checkArguments(arguments, 0), WritableStringObjectInspector)

... and so on.

Thanks
Hari, +1, Thanks Jason !!!, +1 for the changes. [~mmccline] is it possible to add negative tests as well so that we are sure about which type conversions are possible for GenericUDFBasePad.

Thanks
Hari, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12659796/HIVE-7426.2.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 5865 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/172/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/172/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-172/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12659796, Test failures don't appear to be related. TestDDLWithRemoteMetastoreSecondNamenode looks like it's failing on trunk as well., Added a few negative tests., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12659988/HIVE-7426.3.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 5882 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_mixed_case
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/191/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/191/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-191/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12659988, Committed to trunk. Thanks, Matt!, Thank You, This has been fixed in 0.14 release. Please open new jira if you see any issues.
]