[GitHub user thejasmn opened a pull request:

    https://github.com/apache/hive/pull/58

    HIVE-12698 : introduce HiveAuthorizationTranslator interface for isolating authori…

    …zation impls from hive internal classes

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/thejasmn/hive HIVE-12698

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/hive/pull/58.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #58
    
----
commit 27e73f2a45aa3e5a158c14fb0693567158cef0d7
Author: Thejas Nair <thejas@hortonworks.com>
Date:   2015-12-17T02:36:52Z

    introduce HiveAuthorizationTranslator interface for isolating authorization impls from hive internal classes

----
, [~dapengsun] [~Ferd] 
I am wondering if the api HiveAuthorizationTranslator, should have methods that operate on a single element instead of a list of them. That seems more generic and captures the basic logic - 
ie instead of -
{code} public List<HivePrincipal> getHivePrincipals(List<PrincipalDesc> principals)  {code}
have - 

{code} public HivePrincipal getHivePrincipals(PrincipalDesc principals) {code}
What are your thoughts ?
, Also, I noticed that DDLTask.java still calls AuthorizationUtils.getHivePrincipal at a few places. I guess that needs to be fixed as well.
, Agree. It will be great to be 
{code}
public HivePrincipal getHivePrincipal(PrincipalDesc principal) 
{code}
which is the same as
{code}
public HivePrivilegeObject getHivePrivilegeObject(PrivilegeObjectDesc privSubjectDesc)
    throws HiveException;
{code}, I'm agreed with you, we can also fix getHivePrincipal() at {{DDLTask}}, I'm agreed with you, we can also fix getHivePrincipal() at {{DDLTask}}, I'm agreed with you, we can also fix getHivePrincipal() at {{DDLTask}}, I'm agreed with you, we can also fix getHivePrincipal() at {{DDLTask}}, I'm agreed with you, we can also fix getHivePrincipal() at {{DDLTask}}, I'm agreed with you, we can also fix getHivePrincipal() at {{DDLTask}}, Sorry for the repeat messages, there are something wrong with my web brower, Updated patch to address comments, [~sershe] I think we should get this interface update into 2.0.0 as well. This improves on what is currently in the branch, which is an unreleased change.
, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12778179/HIVE-12698.2.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6383/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6383/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6383/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-llap-client ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-llap-client ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/llap-client/target/hive-llap-client-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-llap-client ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-llap-client ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-client/target/hive-llap-client-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-llap-client/2.1.0-SNAPSHOT/hive-llap-client-2.1.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-llap-client/2.1.0-SNAPSHOT/hive-llap-client-2.1.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Spark Remote Client 2.1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-client ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ spark-client ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-client ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ spark-client ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ spark-client ---
[INFO] Compiling 28 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/classes
[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java uses or overrides a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark-client ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ spark-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf
     [copy] Copying 16 files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-client ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/test-classes
[INFO] 
[INFO] --- maven-dependency-plugin:2.8:copy (copy-guava-14) @ spark-client ---
[INFO] Configured Artifact: com.google.guava:guava:14.0.1:jar
[INFO] Copying guava-14.0.1.jar to /data/hive-ptest/working/apache-github-source-source/spark-client/target/dependency/guava-14.0.1.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ spark-client ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ spark-client ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ spark-client ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ spark-client ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 2.1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-exec ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-github-source-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 2435 source files to /data/hive-ptest/working/apache-github-source-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveAuthorizerImpl.java:[147,38] getHiveAuthorizationTranslator() in org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthorizerImpl cannot implement getHiveAuthorizationTranslator() in org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthorizer
  overridden method does not throw org.apache.hadoop.hive.ql.metadata.HiveException
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [13.591s]
[INFO] Hive Shims Common ................................. SUCCESS [15.103s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [12.018s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [3.128s]
[INFO] Hive Shims ........................................ SUCCESS [2.566s]
[INFO] Hive Storage API .................................. SUCCESS [6.514s]
[INFO] Hive ORC .......................................... SUCCESS [12.430s]
[INFO] Hive Common ....................................... SUCCESS [21.706s]
[INFO] Hive Serde ........................................ SUCCESS [16.929s]
[INFO] Hive Metastore .................................... SUCCESS [50.815s]
[INFO] Hive Ant Utilities ................................ SUCCESS [1.862s]
[INFO] Hive Llap Client .................................. SUCCESS [12.658s]
[INFO] Spark Remote Client ............................... SUCCESS [24.978s]
[INFO] Hive Query Language ............................... FAILURE [1:21.251s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HPL/SQL ...................................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Llap Server .................................. SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 4:38.706s
[INFO] Finished at: Thu Dec 17 11:14:48 EST 2015
[INFO] Final Memory: 145M/1107M
[INFO] ------------------------------------------------------------------------
[WARNING] The requested profile "hadoop-2" could not be activated because it does not exist.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/plugin/HiveAuthorizerImpl.java:[147,38] getHiveAuthorizationTranslator() in org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthorizerImpl cannot implement getHiveAuthorizationTranslator() in org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthorizer
[ERROR] overridden method does not throw org.apache.hadoop.hive.ql.metadata.HiveException
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-exec
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12778179 - PreCommit-HIVE-TRUNK-Build, HIVE-12698.3.patch - addressing more review comments
, +1 pending to the test, HIVE-12698.4.patch - made a minor change so that the interface does not require the new class being introduced. That way implementations like Ranger don't have to create a shim layer just for this, to be able to compile against older and newer versions of hive.
Alternatives to this would have necessiated creation of an extended interface and then checking if the authorizer implementation implements the extended interface as well. That would increase the complexity of the hive side of the code.

Also updated in the git pull request.

[~Ferd] Can you please take a look at this minor change ?
, +1 for the .4 patch pending to the test, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12778425/HIVE-12698.4.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 16 failed/errored test(s), 9965 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_order2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union9
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testRemoteClient
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6396/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6396/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6396/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12778425 - PreCommit-HIVE-TRUNK-Build, Patch committed to master, branch-1 and branch-2.0 .
Thanks for the review [~Ferd]!

I will also create an abstract class in a follow up patch, so that it gets easier to modify the interface if necessary, without affecting the implementations.
]