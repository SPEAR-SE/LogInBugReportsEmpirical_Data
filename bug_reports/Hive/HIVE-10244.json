{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046"
            },
            "displayName": "Matt McCline",
            "key": "mmccline",
            "name": "mmccline",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=mmccline",
            "timeZone": "America/Chicago"
        },
        "components": [{
            "description": "Vectorized query execution",
            "id": "12321300",
            "name": "Vectorization",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321300"
        }],
        "created": "2015-04-07T21:25:05.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863"
            },
            "displayName": "Mostafa Mokhtar",
            "key": "mmokhtar",
            "name": "mmokhtar",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar",
            "timeZone": "America/Los_Angeles"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2015-05-11T03:47:10.479+0000",
        "customfield_12310222": "10002_*:*_1_*:*_596290769_*|*_1_*:*_1_*:*_3816995514_*|*_5_*:*_1_*:*_0",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "2.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i2cxnj:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Thu May 28 23:20:34 UTC 2015",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Query \n{code}\nset hive.vectorized.execution.reduce.enabled=true;\nwith ssr as\n (select  s_store_id as store_id,\n          sum(ss_ext_sales_price) as sales,\n          sum(coalesce(sr_return_amt, 0)) as returns,\n          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit\n  from store_sales left outer join store_returns on\n         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),\n     date_dim,\n     store,\n     item,\n     promotion\n where ss_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-04' as date) \n                  and (cast('1998-09-04' as date))\n       and ss_store_sk = s_store_sk\n       and ss_item_sk = i_item_sk\n       and i_current_price > 50\n       and ss_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\n group by s_store_id)\n ,\n csr as\n (select  cp_catalog_page_id as catalog_page_id,\n          sum(cs_ext_sales_price) as sales,\n          sum(coalesce(cr_return_amount, 0)) as returns,\n          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit\n  from catalog_sales left outer join catalog_returns on\n         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),\n     date_dim,\n     catalog_page,\n     item,\n     promotion\n where cs_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-04' as date)\n                  and (cast('1998-09-04' as date))\n        and cs_catalog_page_sk = cp_catalog_page_sk\n       and cs_item_sk = i_item_sk\n       and i_current_price > 50\n       and cs_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\ngroup by cp_catalog_page_id)\n ,\n wsr as\n (select  web_site_id,\n          sum(ws_ext_sales_price) as sales,\n          sum(coalesce(wr_return_amt, 0)) as returns,\n          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit\n  from web_sales left outer join web_returns on\n         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),\n     date_dim,\n     web_site,\n     item,\n     promotion\n where ws_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-04' as date)\n                  and (cast('1998-09-04' as date))\n        and ws_web_site_sk = web_site_sk\n       and ws_item_sk = i_item_sk\n       and i_current_price > 50\n       and ws_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\ngroup by web_site_id)\n  select  channel\n        , id\n        , sum(sales) as sales\n        , sum(returns) as returns\n        , sum(profit) as profit\n from \n (select 'store channel' as channel\n        , concat('store', store_id) as id\n        , sales\n        , returns\n        , profit\n from   ssr\n union all\n select 'catalog channel' as channel\n        , concat('catalog_page', catalog_page_id) as id\n        , sales\n        , returns\n        , profit\n from  csr\n union all\n select 'web channel' as channel\n        , concat('web_site', web_site_id) as id\n        , sales\n        , returns\n        , profit\n from   wsr\n ) x\n group by channel, id with rollup\n order by channel\n         ,id\n limit 100\n{code}\n\nException \n{code}\nVertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]\n15/04/07 05:14:52 [main]: ERROR SessionState: Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]\nVertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]\n15/04/07 05:14:52 [main]: ERROR SessionState: Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]\nDAG failed due to vertex failure. failedVertices:1 killedVertices:1\n15/04/07 05:14:52 [main]: ERROR SessionState: DAG failed due to vertex failure. failedVertices:1 killedVertices:1\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010â˜ƒ00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:1\n15/04/07 05:14:52 [main]: ERROR ql.Driver: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8â˜ƒ00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:1\n{code}\n\nPlan \n{code}\n\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Tez\n      Edges:\n        Map 12 <- Map 14 (BROADCAST_EDGE), Map 15 (BROADCAST_EDGE), Map 16 (BROADCAST_EDGE), Map 17 (BROADCAST_EDGE), Map 18 (BROADCAST_EDGE)\n        Map 19 <- Map 21 (BROADCAST_EDGE), Map 22 (BROADCAST_EDGE), Map 23 (BROADCAST_EDGE), Map 24 (BROADCAST_EDGE), Map 25 (BROADCAST_EDGE)\n        Reducer 13 <- Map 12 (SIMPLE_EDGE), Union 4 (CONTAINS)\n        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 10 (BROADCAST_EDGE), Map 11 (BROADCAST_EDGE), Map 7 (SIMPLE_EDGE), Map 8 (BROADCAST_EDGE), Map 9 (BROADCAST_EDGE)\n        Reducer 20 <- Map 19 (SIMPLE_EDGE), Union 4 (CONTAINS)\n        Reducer 3 <- Reducer 2 (SIMPLE_EDGE), Union 4 (CONTAINS)\n        Reducer 5 <- Union 4 (SIMPLE_EDGE)\n        Reducer 6 <- Reducer 5 (SIMPLE_EDGE)\n      DagName: mmokhtar_20150407051226_eb6d232e-cb00-4174-8b2f-d70aa2b3fb15:1\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: store_sales\n                  filterExpr: ((ss_item_sk is not null and ss_promo_sk is not null) and ss_store_sk is not null) (type: boolean)\n                  Statistics: Num rows: 550076554 Data size: 47370018896 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((ss_item_sk is not null and ss_promo_sk is not null) and ss_store_sk is not null) (type: boolean)\n                    Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: ss_item_sk (type: int), ss_store_sk (type: int), ss_promo_sk (type: int), ss_ticket_number (type: int), ss_ext_sales_price (type: float), ss_net_profit (type: float), ss_sold_date_sk (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6\n                      Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col3 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col3 (type: int)\n                        Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: int), _col2 (type: int), _col4 (type: float), _col5 (type: float), _col6 (type: int)\n            Execution mode: vectorized\n        Map 10 \n            Map Operator Tree:\n                TableScan\n                  alias: promotion\n                  filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                  Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                    Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: p_promo_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 11 \n            Map Operator Tree:\n                TableScan\n                  alias: store\n                  filterExpr: s_store_sk is not null (type: boolean)\n                  Statistics: Num rows: 212 Data size: 405680 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: s_store_sk is not null (type: boolean)\n                    Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: s_store_sk (type: int), s_store_id (type: string)\n                      outputColumnNames: _col0, _col1\n                      Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: string)\n            Execution mode: vectorized\n        Map 12 \n            Map Operator Tree:\n                TableScan\n                  alias: catalog_sales\n                  filterExpr: ((cs_item_sk is not null and cs_promo_sk is not null) and cs_catalog_page_sk is not null) (type: boolean)\n                  Statistics: Num rows: 286549727 Data size: 37743959324 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((cs_item_sk is not null and cs_promo_sk is not null) and cs_catalog_page_sk is not null) (type: boolean)\n                    Statistics: Num rows: 285112475 Data size: 7974560516 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: cs_catalog_page_sk (type: int), cs_item_sk (type: int), cs_promo_sk (type: int), cs_order_number (type: int), cs_ext_sales_price (type: float), cs_net_profit (type: float), cs_sold_date_sk (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6\n                      Statistics: Num rows: 285112475 Data size: 7974560516 Basic stats: COMPLETE Column stats: COMPLETE\n                      Map Join Operator\n                        condition map:\n                             Left Outer Join0 to 1\n                        keys:\n                          0 _col1 (type: int), _col3 (type: int)\n                          1 _col0 (type: int), _col1 (type: int)\n                        outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10\n                        input vertices:\n                          1 Map 14\n                        Statistics: Num rows: 3412616 Data size: 109203712 Basic stats: COMPLETE Column stats: COMPLETE\n                        Map Join Operator\n                          condition map:\n                               Inner Join 0 to 1\n                          keys:\n                            0 _col6 (type: int)\n                            1 _col0 (type: int)\n                          outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10\n                          input vertices:\n                            1 Map 15\n                          Statistics: Num rows: 3815661 Data size: 106838508 Basic stats: COMPLETE Column stats: COMPLETE\n                          Map Join Operator\n                            condition map:\n                                 Inner Join 0 to 1\n                            keys:\n                              0 _col1 (type: int)\n                              1 _col0 (type: int)\n                            outputColumnNames: _col0, _col2, _col4, _col5, _col9, _col10\n                            input vertices:\n                              1 Map 16\n                            Statistics: Num rows: 1271887 Data size: 30525288 Basic stats: COMPLETE Column stats: COMPLETE\n                            Map Join Operator\n                              condition map:\n                                   Inner Join 0 to 1\n                              keys:\n                                0 _col2 (type: int)\n                                1 _col0 (type: int)\n                              outputColumnNames: _col0, _col4, _col5, _col9, _col10\n                              input vertices:\n                                1 Map 17\n                              Statistics: Num rows: 635944 Data size: 12718880 Basic stats: COMPLETE Column stats: COMPLETE\n                              Map Join Operator\n                                condition map:\n                                     Inner Join 0 to 1\n                                keys:\n                                  0 _col0 (type: int)\n                                  1 _col0 (type: int)\n                                outputColumnNames: _col4, _col5, _col9, _col10, _col18\n                                input vertices:\n                                  1 Map 18\n                                Statistics: Num rows: 635944 Data size: 73769504 Basic stats: COMPLETE Column stats: COMPLETE\n                                Select Operator\n                                  expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float)\n                                  outputColumnNames: _col0, _col1, _col2, _col3\n                                  Statistics: Num rows: 635944 Data size: 73769504 Basic stats: COMPLETE Column stats: COMPLETE\n                                  Group By Operator\n                                    aggregations: sum(_col1), sum(_col2), sum(_col3)\n                                    keys: _col0 (type: string)\n                                    mode: hash\n                                    outputColumnNames: _col0, _col1, _col2, _col3\n                                    Statistics: Num rows: 10590 Data size: 1313160 Basic stats: COMPLETE Column stats: COMPLETE\n                                    Reduce Output Operator\n                                      key expressions: _col0 (type: string)\n                                      sort order: +\n                                      Map-reduce partition columns: _col0 (type: string)\n                                      Statistics: Num rows: 10590 Data size: 1313160 Basic stats: COMPLETE Column stats: COMPLETE\n                                      value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double)\n            Execution mode: vectorized\n        Map 14 \n            Map Operator Tree:\n                TableScan\n                  alias: catalog_returns\n                  filterExpr: cr_item_sk is not null (type: boolean)\n                  Statistics: Num rows: 28798881 Data size: 2942039156 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: cr_item_sk is not null (type: boolean)\n                    Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: cr_item_sk (type: int), cr_order_number (type: int), cr_return_amount (type: float), cr_net_loss (type: float)\n                      outputColumnNames: _col0, _col1, _col2, _col3\n                      Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col1 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)\n                        Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col2 (type: float), _col3 (type: float)\n            Execution mode: vectorized\n        Map 15 \n            Map Operator Tree:\n                TableScan\n                  alias: date_dim\n                  filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                    Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: d_date_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Select Operator\n                        expressions: _col0 (type: int)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                        Group By Operator\n                          keys: _col0 (type: int)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                          Dynamic Partitioning Event Operator\n                            Target Input: catalog_sales\n                            Partition key expr: cs_sold_date_sk\n                            Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                            Target column: cs_sold_date_sk\n                            Target Vertex: Map 12\n            Execution mode: vectorized\n        Map 16 \n            Map Operator Tree:\n                TableScan\n                  alias: item\n                  filterExpr: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                  Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                    Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: i_item_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 17 \n            Map Operator Tree:\n                TableScan\n                  alias: promotion\n                  filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                  Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                    Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: p_promo_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 18 \n            Map Operator Tree:\n                TableScan\n                  alias: catalog_page\n                  filterExpr: cp_catalog_page_sk is not null (type: boolean)\n                  Statistics: Num rows: 11718 Data size: 5400282 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: cp_catalog_page_sk is not null (type: boolean)\n                    Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: cp_catalog_page_sk (type: int), cp_catalog_page_id (type: string)\n                      outputColumnNames: _col0, _col1\n                      Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: string)\n            Execution mode: vectorized\n        Map 19 \n            Map Operator Tree:\n                TableScan\n                  alias: web_sales\n                  filterExpr: ((ws_item_sk is not null and ws_promo_sk is not null) and ws_web_site_sk is not null) (type: boolean)\n                  Statistics: Num rows: 143966864 Data size: 19001610332 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((ws_item_sk is not null and ws_promo_sk is not null) and ws_web_site_sk is not null) (type: boolean)\n                    Statistics: Num rows: 143930635 Data size: 4029840544 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: ws_item_sk (type: int), ws_web_site_sk (type: int), ws_promo_sk (type: int), ws_order_number (type: int), ws_ext_sales_price (type: float), ws_net_profit (type: float), ws_sold_date_sk (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6\n                      Statistics: Num rows: 143930635 Data size: 4029840544 Basic stats: COMPLETE Column stats: COMPLETE\n                      Map Join Operator\n                        condition map:\n                             Left Outer Join0 to 1\n                        keys:\n                          0 _col0 (type: int), _col3 (type: int)\n                          1 _col0 (type: int), _col1 (type: int)\n                        outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10\n                        input vertices:\n                          1 Map 21\n                        Statistics: Num rows: 2406359 Data size: 77003488 Basic stats: COMPLETE Column stats: COMPLETE\n                        Map Join Operator\n                          condition map:\n                               Inner Join 0 to 1\n                          keys:\n                            0 _col6 (type: int)\n                            1 _col0 (type: int)\n                          outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10\n                          input vertices:\n                            1 Map 22\n                          Statistics: Num rows: 2690560 Data size: 75335680 Basic stats: COMPLETE Column stats: COMPLETE\n                          Map Join Operator\n                            condition map:\n                                 Inner Join 0 to 1\n                            keys:\n                              0 _col0 (type: int)\n                              1 _col0 (type: int)\n                            outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col10\n                            input vertices:\n                              1 Map 23\n                            Statistics: Num rows: 896854 Data size: 21524496 Basic stats: COMPLETE Column stats: COMPLETE\n                            Map Join Operator\n                              condition map:\n                                   Inner Join 0 to 1\n                              keys:\n                                0 _col2 (type: int)\n                                1 _col0 (type: int)\n                              outputColumnNames: _col1, _col4, _col5, _col9, _col10\n                              input vertices:\n                                1 Map 24\n                              Statistics: Num rows: 448427 Data size: 8968540 Basic stats: COMPLETE Column stats: COMPLETE\n                              Map Join Operator\n                                condition map:\n                                     Inner Join 0 to 1\n                                keys:\n                                  0 _col1 (type: int)\n                                  1 _col0 (type: int)\n                                outputColumnNames: _col4, _col5, _col9, _col10, _col18\n                                input vertices:\n                                  1 Map 25\n                                Statistics: Num rows: 448427 Data size: 52017532 Basic stats: COMPLETE Column stats: COMPLETE\n                                Select Operator\n                                  expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float)\n                                  outputColumnNames: _col0, _col1, _col2, _col3\n                                  Statistics: Num rows: 448427 Data size: 52017532 Basic stats: COMPLETE Column stats: COMPLETE\n                                  Group By Operator\n                                    aggregations: sum(_col1), sum(_col2), sum(_col3)\n                                    keys: _col0 (type: string)\n                                    mode: hash\n                                    outputColumnNames: _col0, _col1, _col2, _col3\n                                    Statistics: Num rows: 17 Data size: 2108 Basic stats: COMPLETE Column stats: COMPLETE\n                                    Reduce Output Operator\n                                      key expressions: _col0 (type: string)\n                                      sort order: +\n                                      Map-reduce partition columns: _col0 (type: string)\n                                      Statistics: Num rows: 17 Data size: 2108 Basic stats: COMPLETE Column stats: COMPLETE\n                                      value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double)\n            Execution mode: vectorized\n        Map 21 \n            Map Operator Tree:\n                TableScan\n                  alias: web_returns\n                  filterExpr: wr_item_sk is not null (type: boolean)\n                  Statistics: Num rows: 13749816 Data size: 1237758344 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: wr_item_sk is not null (type: boolean)\n                    Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: wr_item_sk (type: int), wr_order_number (type: int), wr_return_amt (type: float), wr_net_loss (type: float)\n                      outputColumnNames: _col0, _col1, _col2, _col3\n                      Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col1 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)\n                        Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col2 (type: float), _col3 (type: float)\n            Execution mode: vectorized\n        Map 22 \n            Map Operator Tree:\n                TableScan\n                  alias: date_dim\n                  filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                    Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: d_date_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Select Operator\n                        expressions: _col0 (type: int)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                        Group By Operator\n                          keys: _col0 (type: int)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                          Dynamic Partitioning Event Operator\n                            Target Input: web_sales\n                            Partition key expr: ws_sold_date_sk\n                            Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                            Target column: ws_sold_date_sk\n                            Target Vertex: Map 19\n            Execution mode: vectorized\n        Map 23 \n            Map Operator Tree:\n                TableScan\n                  alias: item\n                  filterExpr: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                  Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                    Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: i_item_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 24 \n            Map Operator Tree:\n                TableScan\n                  alias: promotion\n                  filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                  Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                    Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: p_promo_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 25 \n            Map Operator Tree:\n                TableScan\n                  alias: web_site\n                  filterExpr: web_site_sk is not null (type: boolean)\n                  Statistics: Num rows: 38 Data size: 70614 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: web_site_sk is not null (type: boolean)\n                    Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: web_site_sk (type: int), web_site_id (type: string)\n                      outputColumnNames: _col0, _col1\n                      Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: string)\n            Execution mode: vectorized\n        Map 7 \n            Map Operator Tree:\n                TableScan\n                  alias: store_returns\n                  filterExpr: sr_item_sk is not null (type: boolean)\n                  Statistics: Num rows: 55578005 Data size: 4155315616 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: sr_item_sk is not null (type: boolean)\n                    Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: sr_item_sk (type: int), sr_ticket_number (type: int), sr_return_amt (type: float), sr_net_loss (type: float)\n                      outputColumnNames: _col0, _col1, _col2, _col3\n                      Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col1 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)\n                        Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col2 (type: float), _col3 (type: float)\n            Execution mode: vectorized\n        Map 8 \n            Map Operator Tree:\n                TableScan\n                  alias: date_dim\n                  filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                    Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: d_date_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Select Operator\n                        expressions: _col0 (type: int)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                        Group By Operator\n                          keys: _col0 (type: int)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                          Dynamic Partitioning Event Operator\n                            Target Input: store_sales\n                            Partition key expr: ss_sold_date_sk\n                            Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                            Target column: ss_sold_date_sk\n                            Target Vertex: Map 1\n            Execution mode: vectorized\n        Map 9 \n            Map Operator Tree:\n                TableScan\n                  alias: item\n                  filterExpr: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                  Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                    Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: i_item_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Reducer 13 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col2, _col3\n                Select Operator\n                  expressions: 'catalog channel' (type: string), concat('catalog_page', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Group By Operator\n                    aggregations: sum(_col2), sum(_col3), sum(_col4)\n                    keys: _col0 (type: string), _col1 (type: string), '0' (type: string)\n                    mode: hash\n                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      sort order: +++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double)\n        Reducer 2 \n            Reduce Operator Tree:\n              Merge Join Operator\n                condition map:\n                     Left Outer Join0 to 1\n                keys:\n                  0 _col0 (type: int), _col3 (type: int)\n                  1 _col0 (type: int), _col1 (type: int)\n                outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10\n                Statistics: Num rows: 7811006 Data size: 249952192 Basic stats: COMPLETE Column stats: COMPLETE\n                Map Join Operator\n                  condition map:\n                       Inner Join 0 to 1\n                  keys:\n                    0 _col6 (type: int)\n                    1 _col0 (type: int)\n                  outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10\n                  input vertices:\n                    1 Map 8\n                  Statistics: Num rows: 8733520 Data size: 244538560 Basic stats: COMPLETE Column stats: COMPLETE\n                  Map Join Operator\n                    condition map:\n                         Inner Join 0 to 1\n                    keys:\n                      0 _col0 (type: int)\n                      1 _col0 (type: int)\n                    outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col10\n                    input vertices:\n                      1 Map 9\n                    Statistics: Num rows: 2911174 Data size: 69868176 Basic stats: COMPLETE Column stats: COMPLETE\n                    Map Join Operator\n                      condition map:\n                           Inner Join 0 to 1\n                      keys:\n                        0 _col2 (type: int)\n                        1 _col0 (type: int)\n                      outputColumnNames: _col1, _col4, _col5, _col9, _col10\n                      input vertices:\n                        1 Map 10\n                      Statistics: Num rows: 1455587 Data size: 29111740 Basic stats: COMPLETE Column stats: COMPLETE\n                      Map Join Operator\n                        condition map:\n                             Inner Join 0 to 1\n                        keys:\n                          0 _col1 (type: int)\n                          1 _col0 (type: int)\n                        outputColumnNames: _col4, _col5, _col9, _col10, _col18\n                        input vertices:\n                          1 Map 11\n                        Statistics: Num rows: 1455587 Data size: 168848092 Basic stats: COMPLETE Column stats: COMPLETE\n                        Select Operator\n                          expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float)\n                          outputColumnNames: _col0, _col1, _col2, _col3\n                          Statistics: Num rows: 1455587 Data size: 168848092 Basic stats: COMPLETE Column stats: COMPLETE\n                          Group By Operator\n                            aggregations: sum(_col1), sum(_col2), sum(_col3)\n                            keys: _col0 (type: string)\n                            mode: hash\n                            outputColumnNames: _col0, _col1, _col2, _col3\n                            Statistics: Num rows: 234 Data size: 29016 Basic stats: COMPLETE Column stats: COMPLETE\n                            Reduce Output Operator\n                              key expressions: _col0 (type: string)\n                              sort order: +\n                              Map-reduce partition columns: _col0 (type: string)\n                              Statistics: Num rows: 234 Data size: 29016 Basic stats: COMPLETE Column stats: COMPLETE\n                              value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double)\n        Reducer 20 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col2, _col3\n                Select Operator\n                  expressions: 'web channel' (type: string), concat('web_site', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Group By Operator\n                    aggregations: sum(_col2), sum(_col3), sum(_col4)\n                    keys: _col0 (type: string), _col1 (type: string), '0' (type: string)\n                    mode: hash\n                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      sort order: +++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double)\n        Reducer 3 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col2, _col3\n                Select Operator\n                  expressions: 'store channel' (type: string), concat('store', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Group By Operator\n                    aggregations: sum(_col2), sum(_col3), sum(_col4)\n                    keys: _col0 (type: string), _col1 (type: string), '0' (type: string)\n                    mode: hash\n                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      sort order: +++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double)\n        Reducer 5 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col3, _col4, _col5\n                Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                pruneGroupingSetId: true\n                Select Operator\n                  expressions: _col0 (type: string), _col1 (type: string), _col3 (type: double), _col4 (type: double), _col5 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                  Reduce Output Operator\n                    key expressions: _col0 (type: string), _col1 (type: string)\n                    sort order: ++\n                    Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                    TopN Hash Memory Usage: 0.04\n                    value expressions: _col2 (type: double), _col3 (type: double), _col4 (type: double)\n            Execution mode: vectorized\n        Reducer 6 \n            Reduce Operator Tree:\n              Select Operator\n                expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: double), VALUE._col1 (type: double), VALUE._col2 (type: double)\n                outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                Limit\n                  Number of rows: 100\n                  Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                  File Output Operator\n                    compressed: false\n                    Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                    table:\n                        input format: org.apache.hadoop.mapred.TextInputFormat\n                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n            Execution mode: vectorized\n        Union 4 \n            Vertex: Union 4\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: 100\n      Processor Tree:\n        ListSink\n{code}",
        "duedate": null,
        "environment": null,
        "fixVersions": [{
            "archived": false,
            "id": "12332384",
            "name": "1.2.1",
            "releaseDate": "2015-06-26",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12332384"
        }],
        "issuelinks": [{
            "id": "12421540",
            "inwardIssue": {
                "fields": {
                    "issuetype": {
                        "avatarId": 21146,
                        "description": "The sub-task of the issue",
                        "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
                        "id": "7",
                        "name": "Sub-task",
                        "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
                        "subtask": true
                    },
                    "priority": {
                        "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                        "id": "3",
                        "name": "Major",
                        "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                    },
                    "status": {
                        "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                        "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                        "id": "5",
                        "name": "Resolved",
                        "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                        "statusCategory": {
                            "colorName": "green",
                            "id": 3,
                            "key": "done",
                            "name": "Done",
                            "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
                        }
                    },
                    "summary": "LLAP: query80 fails with vectorization cast issue "
                },
                "id": "12821392",
                "key": "HIVE-10356",
                "self": "https://issues.apache.org/jira/rest/api/2/issue/12821392"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12421540",
            "type": {
                "id": "12310000",
                "inward": "is duplicated by",
                "name": "Duplicate",
                "outward": "duplicates",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
            }
        }],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935"
            },
            "id": "12310843",
            "key": "HIVE",
            "name": "Hive",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310843"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863"
            },
            "displayName": "Mostafa Mokhtar",
            "key": "mmokhtar",
            "name": "mmokhtar",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar",
            "timeZone": "America/Los_Angeles"
        },
        "resolution": {
            "description": "A fix for this issue is checked into the tree and tested.",
            "id": "1",
            "name": "Fixed",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
        },
        "resolutiondate": "2015-05-28T23:19:50.000+0000",
        "status": {
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "id": "5",
            "name": "Resolved",
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Vectorization : TPC-DS Q80 fails with java.lang.ClassCastException when hive.vectorized.execution.reduce.enabled is enabled",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2015-06-05T20:57:42.000+0000",
        "versions": [{
            "archived": false,
            "description": "released",
            "id": "12326450",
            "name": "0.14.0",
            "releaseDate": "2014-11-12",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12326450"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-10244/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-10244/watchers",
            "watchCount": 7
        },
        "workratio": -1
    },
    "id": "12819081",
    "key": "HIVE-10244",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12819081"
}