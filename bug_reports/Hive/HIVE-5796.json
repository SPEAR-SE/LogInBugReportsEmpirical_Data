{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [{
            "description": "Provides rest interface for HCatalog ",
            "id": "12320912",
            "name": "WebHCat",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320912"
        }],
        "created": "2013-11-11T21:34:52.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hsubramaniyan&avatarId=23453",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hsubramaniyan&avatarId=23453",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hsubramaniyan&avatarId=23453",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hsubramaniyan&avatarId=23453"
            },
            "displayName": "Hari Sankar Sivarama Subramaniyan",
            "key": "hsubramaniyan",
            "name": "hsubramaniyan",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hsubramaniyan",
            "timeZone": "America/Los_Angeles"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": null,
        "customfield_12310222": null,
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "1.0",
        "customfield_12310320": null,
        "customfield_12310420": "358045",
        "customfield_12310920": "358335",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i1pq0v:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "2013-11-11 21:34:52.0",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Currently the WebHCat E2E test TestMapReduce_1 fails when comparing the job status field percentComplete which is returned as null, the expected value is \"map 100% reduce 100%\".\n\nIn the templeton.log I see the following message:\n{noformat}\norg.apache.hive.hcatalog.templeton.tool.TempletonControllerJob | Using Hadoop Version: 0.23\nINFO  | 07 Nov 2013 17:14:08,106 | org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob | WEBHCAT_CONF_DIR=null\nWARN  | 07 Nov 2013 17:14:08,106 | org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob | Could not find D:\\hdp\\hcatalog-0.12.0.2.0.6.0-1007\\bin\\null\\override-container-log4j.properties. Monitoring of Hadoop jobs submitted through WebHCat may be affected.\n{noformat}\nTo get past this problem I explicitly set the WEBHCAT_CONF_DIR environment variable to HCATALOG_HOME/etc/webhcat where override-container-log4j.properties is present.\n\nAfter fixing the above and rerunning, I still see the following error:\n{noformat}\nINFO  | 07 Nov 2013 18:29:39,517 | org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob | WEBHCAT_CONF_DIR=D:\\hdp\\\\hcatalog-0.12.0.2.0.6.0-1007\\etc\\webhcat\nINFO  | 07 Nov 2013 18:29:39,517 | org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob | Found D:\\hdp\\hcatalog-0.12.0.2.0.6.0-1007\\etc\\webhcat\\override-container-log4j.properties to use for job submission.\nERROR | 07 Nov 2013 18:29:39,519 | org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob | org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob is not properly initialized. Monitoring of Hadoop jobs submitted through WebHCat may be affected.\njava.lang.IllegalArgumentException: Pathname /d:/hadoop/hdfs/tmp from d:/hadoop/hdfs/tmp is not a valid DFS filename.\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:184)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:92)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1106)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1102)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1102)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1397)\n\tat org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob$1.run(TempletonControllerJob.java:93)\n\tat org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob$1.run(TempletonControllerJob.java:82)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Unknown Source)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)\n\tat org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob.copyLog4JtoFileSystem(TempletonControllerJob.java:82)\n\tat org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob.<clinit>(TempletonControllerJob.java:126)\n\tat org.apache.hive.hcatalog.templeton.LauncherDelegator$1.run(LauncherDelegator.java:104)\n\tat org.apache.hive.hcatalog.templeton.LauncherDelegator$1.run(LauncherDelegator.java:101)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Unknown Source)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)\n\tat org.apache.hive.hcatalog.templeton.LauncherDelegator.queueAsUser(LauncherDelegator.java:101)\n\tat org.apache.hive.hcatalog.templeton.LauncherDelegator.enqueueController(LauncherDelegator.java:82)\n\tat org.apache.hive.hcatalog.templeton.JarDelegator.run(JarDelegator.java:55)\n\tat org.apache.hive.hcatalog.templeton.Server.mapReduceJar(Server.java:690)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.lang.reflect.Method.invoke(Unknown Source)\n\tat com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n\tat com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n\tat com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n\tat com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1480)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1411)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1360)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1350)\n\tat com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:538)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:716)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:565)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1360)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:384)\n\tat org.apache.hadoop.hdfs.web.AuthFilter.doFilter(AuthFilter.java:85)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1331)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:477)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1031)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:406)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:965)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117)\n\tat org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:47)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:111)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:349)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:449)\n\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:925)\n\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:857)\n\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:76)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:609)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:45)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:599)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:534)\n\tat java.lang.Thread.run(Unknown Source)\n{noformat}\nI think the problem is due to the reliance on the value of hadoop.tmp.dir as a temporary HDFS directory which is a temporary file location and applies to both local file system and HDFS. There are some derived parameters that build on top of this location assuming its local (eg. mapred.local.dir) and sometimes assuming its on hdfs (eg. mapred.system.dir), in short it is very hairy to rely on hadoop.tmp.dir.",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935"
            },
            "id": "12310843",
            "key": "HIVE",
            "name": "Hive",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310843"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hsubramaniyan&avatarId=23453",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hsubramaniyan&avatarId=23453",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hsubramaniyan&avatarId=23453",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hsubramaniyan&avatarId=23453"
            },
            "displayName": "Hari Sankar Sivarama Subramaniyan",
            "key": "hsubramaniyan",
            "name": "hsubramaniyan",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hsubramaniyan",
            "timeZone": "America/Los_Angeles"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "A patch for this issue has been uploaded to JIRA by a contributor.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/document.png",
            "id": "10002",
            "name": "Patch Available",
            "self": "https://issues.apache.org/jira/rest/api/2/status/10002",
            "statusCategory": {
                "colorName": "yellow",
                "id": 4,
                "key": "indeterminate",
                "name": "In Progress",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/4"
            }
        },
        "subtasks": [],
        "summary": "percentjobcomplete returned by webhcat is null",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2016-05-04T08:14:22.000+0000",
        "versions": [{
            "archived": false,
            "description": "released",
            "id": "12324312",
            "name": "0.12.0",
            "releaseDate": "2013-10-15",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12324312"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-5796/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-5796/watchers",
            "watchCount": 1
        },
        "workratio": -1
    },
    "id": "12678678",
    "key": "HIVE-5796",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12678678"
}