{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533"
            },
            "displayName": "Oleksiy Sayankin",
            "key": "osayankin",
            "name": "osayankin",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=osayankin",
            "timeZone": "Etc/UTC"
        },
        "components": [{
            "id": "12313461",
            "name": "HBase Handler",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313461"
        }],
        "created": "2017-07-14T16:36:05.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533"
            },
            "displayName": "Oleksiy Sayankin",
            "key": "osayankin",
            "name": "osayankin",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=osayankin",
            "timeZone": "Etc/UTC"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2017-07-17T11:32:49.534+0000",
        "customfield_12310222": "1_*:*_1_*:*_15358_*|*_3_*:*_2_*:*_234397234_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_2_*:*_21881023569",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "2.0",
        "customfield_12310320": [{
            "archived": false,
            "id": "12340268",
            "name": "3.0.0",
            "releaseDate": "2018-05-21",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12340268"
        }],
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i3hjgn:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Tue May 22 23:57:43 UTC 2018",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "These steps simulate our customer production env.\r\n\r\n*STEP 1. Create test tables*\r\n\r\n{code}\r\nCREATE TABLE for_loading(\r\n  key int, \r\n  value string,\r\n  age int,\r\n  salary decimal (10,2)\r\n) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';\r\n{code}\r\n\r\nTable {{test_1}} belongs to user {{testuser1}}.\r\n\r\n{code}\r\nCREATE TABLE test_1(\r\n  key int, \r\n  value string,\r\n  age int,\r\n  salary decimal (10,2)\r\n)\r\nROW FORMAT SERDE \r\n  'org.apache.hadoop.hive.hbase.HBaseSerDe' \r\nSTORED BY \r\n  'org.apache.hadoop.hive.hbase.HBaseStorageHandler' \r\nWITH SERDEPROPERTIES ( \r\n  'hbase.columns.mapping'=':key, cf1:value, cf1:age, cf1:salary', \r\n  'serialization.format'='1')\r\nTBLPROPERTIES (\r\n  'COLUMN_STATS_ACCURATE'='{\\\"BASIC_STATS\\\":\\\"true\\\"}', \r\n  'hbase.table.name'='test_1', \r\n  'numFiles'='0', \r\n  'numRows'='0', \r\n  'rawDataSize'='0', \r\n  'totalSize'='0', \r\n  'transient_lastDdlTime'='1495769316');\r\n{code}\r\n\r\nTable {{test_2}} belongs to user {{testuser2}}.\r\n\r\n{code}\r\nCREATE TABLE test_2(\r\n  key int, \r\n  value string,\r\n  age int,\r\n  salary decimal (10,2)\r\n)\r\nROW FORMAT SERDE \r\n  'org.apache.hadoop.hive.hbase.HBaseSerDe' \r\nSTORED BY \r\n  'org.apache.hadoop.hive.hbase.HBaseStorageHandler' \r\nWITH SERDEPROPERTIES ( \r\n  'hbase.columns.mapping'=':key, cf1:value, cf1:age, cf1:salary', \r\n  'serialization.format'='1')\r\nTBLPROPERTIES (\r\n  'COLUMN_STATS_ACCURATE'='{\\\"BASIC_STATS\\\":\\\"true\\\"}', \r\n  'hbase.table.name'='test_2', \r\n  'numFiles'='0', \r\n  'numRows'='0', \r\n  'rawDataSize'='0', \r\n  'totalSize'='0', \r\n  'transient_lastDdlTime'='1495769316');\r\n{code}\r\n\r\n\r\n*STEP 2. Create test data*\r\n\r\n{code}\r\nimport java.io.IOException;\r\nimport java.math.BigDecimal;\r\nimport java.nio.charset.Charset;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Path;\r\nimport java.nio.file.Paths;\r\nimport java.nio.file.StandardOpenOption;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.List;\r\nimport java.util.Random;\r\n\r\nimport static java.lang.String.format;\r\n\r\npublic class Generator {\r\n    private static List<String> lines = new ArrayList<>();\r\n    private static List<String> name = Arrays.asList(\"Brian\", \"John\", \"Rodger\", \"Max\", \"Freddie\", \"Albert\", \"Fedor\", \"Lev\", \"Niccolo\");\r\n    private static List<BigDecimal> salary = new ArrayList<>();\r\n\r\n    public static void main(String[] args) {\r\n        generateData(Integer.parseInt(args[0]), args[1]);\r\n    }\r\n\r\n    public static void generateData(int rowNumber, String file) {\r\n\r\n        double maxValue = 20000.55;\r\n        double minValue = 1000.03;\r\n\r\n        Random random = new Random();\r\n        for (int i = 1; i <= rowNumber; i++) {\r\n            lines.add(\r\n                i + \",\" +\r\n                    name.get(random.nextInt(name.size())) + \",\" +\r\n                    (random.nextInt(62) + 18) + \",\" +\r\n                    format(\"%.2f\", (minValue + (maxValue - minValue) * random.nextDouble())));\r\n        }\r\n\r\n        Path path = Paths.get(file);\r\n\r\n        try {\r\n            Files.write(path, lines, Charset.forName(\"UTF-8\"), StandardOpenOption.APPEND);\r\n        } catch (IOException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n}\r\n{code}\r\n\r\n{code}\r\njavac Generator.java\r\njava Generator 3000000 dataset.csv\r\nhadoop fs -put dataset.csv /\r\n{code}\r\n\r\n\r\n*STEP 3. Upload test data*\r\n\r\n{code}\r\nload data local inpath '/home/myuser/dataset.csv' into table for_loading;\r\n{code}\r\n\r\n{code}\r\nfrom for_loading\r\ninsert into table test_1\r\nselect key,value,age,salary;\r\n{code}\r\n\r\n{code}\r\nfrom for_loading\r\ninsert into table test_2\r\nselect key,value,age,salary;\r\n{code}\r\n\r\n*STEP 4. Run test queries*\r\n\r\nRun in 5 parallel terminals for table {{test_1}}\r\n\r\n{code}\r\nfor i in {1..500}; do beeline -u \"jdbc:hive2://localhost:10000/default testuser1\" -e \"select * from test_1 limit 10;\" 1>/dev/null; done\r\n{code}\r\n\r\n\r\nRun in 5 parallel terminals for table {{test_2}}\r\n\r\n{code}\r\nfor i in {1..500}; do beeline -u \"jdbc:hive2://localhost:10000/default testuser2\" -e \"select * from test_2 limit 10;\" 1>/dev/null; done\r\n{code}\r\n\r\n*EXPECTED RESULT:*\r\n\r\nAll queris are OK.\r\n\r\n\r\n\r\n\r\n*ACTUAL RESULT*\r\n\r\n\r\n{code}\r\norg.apache.hive.service.cli.HiveSQLException: java.io.IOException: java.lang.IllegalStateException: The input format instance has not been properly ini\r\ntialized. Ensure you call initializeTable either in your constructor or initialize method\r\n        at org.apache.hive.service.cli.operation.SQLOperation.getNextRowSet(SQLOperation.java:484)\r\n        at org.apache.hive.service.cli.operation.OperationManager.getOperationNextRowSet(OperationManager.java:308)\r\n        at org.apache.hive.service.cli.session.HiveSessionImpl.fetchResults(HiveSessionImpl.java:847)\r\n        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:606)\r\n        at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:78)\r\n        at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:36)\r\n        at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:63)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at javax.security.auth.Subject.doAs(Subject.java:415)\r\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1595)\r\n        at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:59)\r\n        at com.sun.proxy.$Proxy25.fetchResults(Unknown Source)\r\n        at org.apache.hive.service.cli.CLIService.fetchResults(CLIService.java:504)\r\n        at org.apache.hive.service.cli.thrift.ThriftCLIService.FetchResults(ThriftCLIService.java:698)\r\n        at org.apache.hive.service.rpc.thrift.TCLIService$Processor$FetchResults.getResult(TCLIService.java:1717)\r\n        at org.apache.hive.service.rpc.thrift.TCLIService$Processor$FetchResults.getResult(TCLIService.java:1702)\r\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\r\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\r\n        at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)\r\n        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n        at java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.io.IOException: java.lang.IllegalStateException: The input format instance has not been properly initialized. Ensure you call initializeTable either in your constructor or initialize method\r\n        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:521)\r\n        at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:428)\r\n        at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:146)\r\n        at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:2099)\r\n        at org.apache.hive.service.cli.operation.SQLOperation.getNextRowSet(SQLOperation.java:479)\r\n        ... 24 more\r\nCaused by: java.lang.IllegalStateException: The input format instance has not been properly initialized. Ensure you call initializeTable either in your constructor or initialize method\r\n        at org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.getRegionLocator(TableInputFormatBase.java:579)\r\n        at org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.getStartEndKeys(TableInputFormatBase.java:225)\r\n        at org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.getSplits(TableInputFormatBase.java:261)\r\n        at org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat.getSplitsInternal(HiveHBaseTableInputFormat.java:525)\r\n        at org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat.getSplits(HiveHBaseTableInputFormat.java:452)\r\n        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextSplits(FetchOperator.java:372)\r\n        at org.apache.hadoop.hive.ql.exec.FetchOperator.getRecordReader(FetchOperator.java:304)\r\n        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:459)\r\n        ... 28 more\r\n{code}\r\n",
        "duedate": null,
        "environment": null,
        "fixVersions": [{
            "archived": false,
            "id": "12340268",
            "name": "3.0.0",
            "releaseDate": "2018-05-21",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12340268"
        }],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
            "id": "2",
            "name": "Critical",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/2"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935"
            },
            "id": "12310843",
            "key": "HIVE",
            "name": "Hive",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310843"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533"
            },
            "displayName": "Oleksiy Sayankin",
            "key": "osayankin",
            "name": "osayankin",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=osayankin",
            "timeZone": "Etc/UTC"
        },
        "resolution": {
            "description": "A fix for this issue is checked into the tree and tested.",
            "id": "1",
            "name": "Fixed",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
        },
        "resolutiondate": "2018-03-27T15:46:41.000+0000",
        "status": {
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "id": "6",
            "name": "Closed",
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Race condition in Hbase tables",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2018-05-22T23:57:43.000+0000",
        "versions": [{
            "archived": false,
            "description": "Maintenance branch for 2.1 ",
            "id": "12335838",
            "name": "2.1.1",
            "releaseDate": "2016-12-08",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12335838"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-17098/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-17098/watchers",
            "watchCount": 3
        },
        "workratio": -1
    },
    "id": "13087242",
    "key": "HIVE-17098",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13087242"
}