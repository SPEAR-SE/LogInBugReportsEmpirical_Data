{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12837393","self":"https://issues.apache.org/jira/rest/api/2/issue/12837393","key":"HIVE-10990","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-08-11T23:13:01.799+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Sep 08 02:04:47 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_7565961128_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-09-08T02:04:53.960+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10990/watchers","watchCount":8,"isWatching":false},"created":"2015-06-12T12:25:32.856+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329345","id":"12329345","description":"Hive 1.2.0","name":"1.2.0","archived":false,"released":true,"releaseDate":"2015-05-18"}],"issuelinks":[{"id":"12435620","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12435620","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"inwardIssue":{"id":"12743082","key":"HBASE-12046","self":"https://issues.apache.org/jira/rest/api/2/issue/12743082","fields":{"summary":"HTD/HCD setters should be builder-style","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-09-08T02:04:53.981+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12324409","id":"12324409","name":"Beeline"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12313461","id":"12313461","name":"HBase Handler"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12320408","id":"12320408","name":"HiveServer2","description":"Tracks issues related to HiveServer2"}],"timeoriginalestimate":null,"description":"Hive external table works fine with Hbase.\n\nHive-1.2 and hbase-1.0.1.1, hadoop-2.5.2\n\nNot able to create a table from hive in hbase.\n\n1: jdbc:hive2://edge1.dilithium.com:10000/def> TBLPROPERTIES (\"hbase.table.name\" = \"xyz\");\nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V (state=08S01,code=1)\n\n\n[hdfs@edge1 cluster]$ hive\n2015-06-12 17:56:49,952 WARN  [main] conf.HiveConf: HiveConf of name hive.metastore.local does not exist\n\nLogging initialized using configuration in jar:file:/usr/local/cluster/apache-hive-1.2.0-bin/lib/hive-common-1.2.0.jar!/hive-log4j.properties\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/local/cluster/apache-hive-1.2.0-bin/auxlib/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/cluster/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nhive> CREATE TABLE hbase_table_1(key int, value string)\n    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n    > WITH SERDEPROPERTIES (\"hbase.columns.mapping\" = \":key,cf1:val\")\n    > TBLPROPERTIES (\"hbase.table.name\" = \"xyz\");\nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n\n=======================\n\nscan complete in 1535ms\n14 driver classes found\nCompliant Version Driver Class\nno        5.1     com.mysql.jdbc.Driver\nno        5.1     com.mysql.jdbc.NonRegisteringDriver\nno        5.1     com.mysql.jdbc.NonRegisteringReplicationDriver\nno        5.1     com.mysql.jdbc.ReplicationDriver\nyes       1.2     org.apache.calcite.avatica.remote.Driver\nyes       1.2     org.apache.calcite.jdbc.Driver\nyes       1.0     org.apache.commons.dbcp.PoolingDriver\nyes       10.11   org.apache.derby.jdbc.AutoloadedDriver\nyes       10.11   org.apache.derby.jdbc.Driver42\nyes       10.11   org.apache.derby.jdbc.EmbeddedDriver\nyes       10.11   org.apache.derby.jdbc.InternalDriver\nno        1.2     org.apache.hive.jdbc.HiveDriver\nyes       1.0     org.datanucleus.store.rdbms.datasource.dbcp.PoolingDriver\nno        5.1     org.gjt.mm.mysql.Driver\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Compatibility Hive-1.2 an hbase-1.0.1.1","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":"2015-06-30","customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14583334","id":"14583334","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"body":"hive> CREATE TABLE hbase_table_1(key int, value string)\n    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n    > WITH SERDEPROPERTIES (\"hbase.columns.mapping\" = \":key,cf1:val\")\n    > TBLPROPERTIES (\"hbase.table.name\" = \"xyz\");\nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"created":"2015-06-12T12:29:32.609+0000","updated":"2015-06-12T12:29:32.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14692457","id":"14692457","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"[~gurmukhd] I think we might have introduced a regression with HIVE-8898. We are currently discussing on that JIRA what is the best way to fix that. In mean time, I tried your query with hive 1.1 on hbase 1.0 and it worked just fine. Anyway you can try using that and see if it fixes your problem?\n\n{noformat}\nhive> CREATE TABLE test_hbase(key string, col1 string, col2 string) \n    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n    > WITH SERDEPROPERTIES (\"hbase.columns.mapping\" = \":key,cf:col1,cf:col2\")\n    > TBLPROPERTIES (\"hbase.table.name\" = \"test_hbase\");\nOK\nTime taken: 1.812 seconds\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-11T23:13:01.799+0000","updated":"2015-08-11T23:13:01.799+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14693672","id":"14693672","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"[~gurmukhd] Digging deeper I am unfortunately not seeing anything non-passive between the two versions which might be causing this error. The HBaseStorageHandler makes a call to the HTableDescriptor#addFamily[1][2]. Would you be able to provide me with a full stack trace so I can dig deeper into this/\n\n That said, we still need to do a full scale compatibility testing with hbase 1.0. Stay tuned.\n\n[1] https://github.com/apache/hive/blob/release-1.2.0/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java#L214\n[2] https://github.com/apache/hbase/blob/1.0.1/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L786","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-12T15:25:31.050+0000","updated":"2015-08-12T15:25:31.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14707960","id":"14707960","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"body":"Sorry, for the delay in response. Will update this details in the next 4 hrs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"created":"2015-08-22T09:33:48.722+0000","updated":"2015-08-22T09:33:48.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14708003","id":"14708003","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=meiyoula","name":"meiyoula","key":"meiyoula","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"meiyoula","active":true,"timeZone":"Etc/UTC"},"body":"I also met the same problem in *spark on hbase* function.\n{quote}\nERROR CliDriver: org.apache.spark.sql.execution.QueryExecutionException: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n        at org.apache.spark.sql.hive.client.ClientWrapper$$anonfun$runHive$1.apply(ClientWrapper.scala:433)\n        at org.apache.spark.sql.hive.client.ClientWrapper$$anonfun$runHive$1.apply(ClientWrapper.scala:418)\n        at org.apache.spark.sql.hive.client.ClientWrapper$$anonfun$withHiveState$1.apply(ClientWrapper.scala:256)\n        at org.apache.spark.sql.hive.client.ClientWrapper.retryLocked(ClientWrapper.scala:211)\n        at org.apache.spark.sql.hive.client.ClientWrapper.withHiveState(ClientWrapper.scala:248)\n        at org.apache.spark.sql.hive.client.ClientWrapper.runHive(ClientWrapper.scala:418)\n        at org.apache.spark.sql.hive.client.ClientWrapper.runSqlHive(ClientWrapper.scala:408)\n        at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:558)\n        at org.apache.spark.sql.hive.execution.HiveNativeCommand.run(HiveNativeCommand.scala:33)\n        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:57)\n        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:57)\n        at org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:69)\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:140)\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:138)\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)\n        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:138)\n        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:927)\n        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:927)\n        at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:144)\n        at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:129)\n        at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)\n        at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:719)\n        at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:61)\n        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:304)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\n        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:223)\n        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:675)\n        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:183)\n        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:208)\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:123)\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=meiyoula","name":"meiyoula","key":"meiyoula","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"meiyoula","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-22T11:41:19.978+0000","updated":"2015-08-22T11:41:19.978+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14708082","id":"14708082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=meiyoula","name":"meiyoula","key":"meiyoula","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"meiyoula","active":true,"timeZone":"Etc/UTC"},"body":"I build the hive by myself, with the version hbase-1.0, The problem is resolved.\nSo I think it's not a problem. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=meiyoula","name":"meiyoula","key":"meiyoula","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"meiyoula","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-22T16:25:58.057+0000","updated":"2015-08-22T16:25:58.057+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14711938","id":"14711938","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"i have same issue, with hive 1.2.1 and hbase 1.1.0.1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T20:40:00.734+0000","updated":"2015-08-25T20:40:00.734+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712035","id":"14712035","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"so my create table is this:\n\nbash-4.1# cat hbasetest.hql                                                 \nCREATE TABLE hbasetest(key string, val string)\nSTORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\nWITH SERDEPROPERTIES(\"hbase.columns.mapping\" = \":key,cf1:val\")\nTBLPROPERTIES(\"hbase.table.name\" = \"xyz\");\nbash-4.1#\n\nAnd when I run it I get this:\n\nbash-4.1# beeline -n hive -u jdbc:hive2://localhost:10001 -f ./hbasetest.hql\nConnecting to jdbc:hive2://localhost:10001\nConnected to: Apache Hive (version 1.2.1)\nDriver: Hive JDBC (version 1.2.1)\nTransaction isolation: TRANSACTION_REPEATABLE_READ\n0: jdbc:hive2://localhost:10001> set hbase.zookeeper.quorum=zookeeper;\nNo rows affected (0.081 seconds)\n0: jdbc:hive2://localhost:10001> \n0: jdbc:hive2://localhost:10001> CREATE TABLE hbasetest(key string, val string)\n0: jdbc:hive2://localhost:10001> STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n0: jdbc:hive2://localhost:10001> WITH SERDEPROPERTIES(\"hbase.columns.mapping\" = \":key,cf1:val\")\n0: jdbc:hive2://localhost:10001> TBLPROPERTIES(\"hbase.table.name\" = \"xyz\");\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V (state=08S01,code=1)\n\nClosing: 0: jdbc:hive2://localhost:10001\nbash-4.1#\n\nAnd with verbose i get this:\n\nbash-4.1# beeline -n hive -u jdbc:hive2://localhost:10001 -f ./hbasetest.hql --verbose\nissuing: !connect jdbc:hive2://localhost:10001 hive '' \nConnecting to jdbc:hive2://localhost:10001\nConnected to: Apache Hive (version 1.2.1)\nDriver: Hive JDBC (version 1.2.1)\nTransaction isolation: TRANSACTION_REPEATABLE_READ\n0: jdbc:hive2://localhost:10001> set hbase.zookeeper.quorum=zookeeper;\nGetting log thread is interrupted, since query is done!\nNo rows affected (0.078 seconds)\n0: jdbc:hive2://localhost:10001> \n0: jdbc:hive2://localhost:10001> CREATE TABLE hbasetest(key string, val string)\n0: jdbc:hive2://localhost:10001> STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n0: jdbc:hive2://localhost:10001> WITH SERDEPROPERTIES(\"hbase.columns.mapping\" = \":key,cf1:val\")\n0: jdbc:hive2://localhost:10001> TBLPROPERTIES(\"hbase.table.name\" = \"xyz\");\nGetting log thread is interrupted, since query is done!\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V (state=08S01,code=1)\njava.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n\tat org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)\n\tat org.apache.hive.beeline.Commands.execute(Commands.java:848)\n\tat org.apache.hive.beeline.Commands.sql(Commands.java:713)\n\tat org.apache.hive.beeline.BeeLine.dispatch(BeeLine.java:973)\n\tat org.apache.hive.beeline.BeeLine.execute(BeeLine.java:813)\n\tat org.apache.hive.beeline.BeeLine.executeFile(BeeLine.java:794)\n\tat org.apache.hive.beeline.BeeLine.begin(BeeLine.java:763)\n\tat org.apache.hive.beeline.BeeLine.mainWithInputRedirection(BeeLine.java:484)\n\tat org.apache.hive.beeline.BeeLine.main(BeeLine.java:467)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n\nClosing: 0: jdbc:hive2://localhost:10001\nbash-4.1#\n\nIn a prior comment [~swarnim] suggested the error originates from https://github.com/apache/hive/blob/release-1.2.0/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java#L214, but I don't think this is the case. Because I can force the addFamily method to throw by omitting a column family from \"hbase.columns.mapping\", and I get a stack trace that points to the code referenced earlier:\n\nbash-4.1# beeline -n hive -u jdbc:hive2://localhost:10001 -f ./hbasetest.hql          \nConnecting to jdbc:hive2://localhost:10001\nConnected to: Apache Hive (version 1.2.1)\nDriver: Hive JDBC (version 1.2.1)\nTransaction isolation: TRANSACTION_REPEATABLE_READ\n0: jdbc:hive2://localhost:10001> set hbase.zookeeper.quorum=zookeeper;\nNo rows affected (0.079 seconds)\n0: jdbc:hive2://localhost:10001> \n0: jdbc:hive2://localhost:10001> CREATE TABLE hbasetest(key string, val string)\n0: jdbc:hive2://localhost:10001> STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n0: jdbc:hive2://localhost:10001> WITH SERDEPROPERTIES(\"hbase.columns.mapping\" = \":key,:val\")\n0: jdbc:hive2://localhost:10001> TBLPROPERTIES(\"hbase.table.name\" = \"xyz\");\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.lang.IllegalArgumentException: Family name can not be empty\n\tat com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)\n\tat org.apache.hadoop.hbase.HColumnDescriptor.isLegalFamilyName(HColumnDescriptor.java:487)\n\tat org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:440)\n\tat org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:398)\n\tat org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:366)\n\tat org.apache.hadoop.hbase.HColumnDescriptor.<init>(HColumnDescriptor.java:317)\n\tat org.apache.hadoop.hive.hbase.HBaseStorageHandler.preCreateTable(HBaseStorageHandler.java:214)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:664)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:657)\n\tat sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)\n\tat com.sun.proxy.$Proxy6.createTable(Unknown Source)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:714)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4135)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:306)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)\n\tat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1653)\n\tat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1412)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1195)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1054)\n\tat org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:154)\n\tat org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:71)\n\tat org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:206)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:218)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n) (state=08S01,code=1)\n\nClosing: 0: jdbc:hive2://localhost:10001\nbash-4.1#\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T21:47:18.765+0000","updated":"2015-08-25T21:47:18.765+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712047","id":"14712047","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"https://github.com/apache/hive/blob/release-1.2.1/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java#L296","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T21:55:38.746+0000","updated":"2015-08-25T21:55:38.746+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712102","id":"14712102","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"[~kevinl] Can you post full logs for this query? They should be in /tmp/<user> folder.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T22:36:34.418+0000","updated":"2015-08-25T22:36:34.418+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712124","id":"14712124","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"\n2015-08-25 18:50:11,406 ERROR [HiveServer2-Background-Pool: Thread-320]: operation.Operation (SQLOperation.java:run(209)) - Error running hive query: \norg.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n\tat org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:315)\n\tat org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:156)\n\tat org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:71)\n\tat org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:206)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:218)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n\tat org.apache.hadoop.hive.hbase.HBaseStorageHandler.preCreateTable(HBaseStorageHandler.java:214)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:664)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:657)\n\tat sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)\n\tat com.sun.proxy.$Proxy6.createTable(Unknown Source)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:714)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4135)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:306)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)\n\tat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1653)\n\tat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1412)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1195)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1054)\n\tat org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:154)\n\t... 11 more","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T22:52:03.836+0000","updated":"2015-08-25T22:52:03.836+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712145","id":"14712145","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"so I'm guessing I need to add set hive.aux.jars.path to point to some hbase jar. Can someone point out which one that is? The integration wiki page suggests a jar that doesn't exist:\n\nhttps://cwiki.apache.org/confluence/display/Hive/HBaseIntegration indicates I should be adding hbase.<version>.jar but that doesn't exist in 1.1.0.1?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T23:04:14.504+0000","updated":"2015-08-25T23:04:14.504+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712172","id":"14712172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"Tried this, doesn't work either:\n\nhttps://issues.apache.org/jira/browse/HIVE-5518","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T23:21:02.205+0000","updated":"2015-08-25T23:21:02.205+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712175","id":"14712175","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"And, I guess I would expect that adding this should work (it doesn't)\n\nset hive.aux.jars.path=file:///opt/hbase/lib/hbase-client-1.0.1.1.jar;\n\nsince:\n\nbash-4.1# jar tf /opt/hbase/lib/hbase-client-1.0.1.1.jar|grep HTableDescriptor\norg/apache/hadoop/hbase/client/UnmodifyableHTableDescriptor.class\norg/apache/hadoop/hbase/HTableDescriptor.class\nbash-4.1#\n\nBut the error in /tmp/root/hive.log is the same:\n\njava.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T23:24:40.405+0000","updated":"2015-08-25T23:24:40.405+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712179","id":"14712179","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"the signature of the method changed (return type):\n\nhttps://github.com/apache/hbase/blob/0.98/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L789\n\nhttps://github.com/apache/hbase/blob/1.1.0.1/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L824\n\nso...the hbase storage handler jar needs to version bump its dependency and recompile(?) ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T23:33:10.377+0000","updated":"2015-08-25T23:33:10.377+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712215","id":"14712215","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"[~kevinl] That is correct. However it should be noted that the branch 1.x of hive is going to stay on < hbase 1.0 still to maintain passivity with older versions of hbase. Please follow the discussion here[1]. Branch 2.x of hive would be moving over to hbase 1.x.\n\nI created [2] to bump hbase version to 1.1.1.\n\n[1] https://www.mail-archive.com/dev@hive.apache.org/msg114984.html\n[2] https://issues.apache.org/jira/browse/HIVE-11647\n\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T00:03:17.665+0000","updated":"2015-08-26T00:03:17.665+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712387","id":"14712387","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"{quote}\nHowever it should be noted that the branch 1.x of hive is going to stay on < hbase 1.0 still to maintain passivity with older versions of hbase.\n{quote}\n\n[~leftylev] What do you think would be a good place to document this kind of information?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T02:38:44.674+0000","updated":"2015-08-26T02:38:44.674+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712733","id":"14712733","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"body":"it is working fine on hive 1.1 and hbase 1.0 but not on hive 1.2 and hbase-1.0.1.1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"created":"2015-08-26T08:53:19.879+0000","updated":"2015-08-26T08:53:19.879+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712744","id":"14712744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"body":"I have tested this on hadoop 2.6.0 as well. Getting the same error.\nHive-1.2.0 and hbase-1.0.1.1\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"created":"2015-08-26T08:56:12.655+0000","updated":"2015-08-26T08:56:12.655+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712787","id":"14712787","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"I have a hard time believing this works with hbase 1.0 given the method return type changed in hbase 0.99.2:\nhttps://github.com/apache/hbase/blob/0.99.2/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java#L789\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T09:23:25.078+0000","updated":"2015-08-26T09:23:25.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14712933","id":"14712933","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"body":"hive> CREATE TABLE hbase_table_1(key int, value string)\n    > STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n    > WITH SERDEPROPERTIES\n    > (\"hbase.columns.mapping\" = \":key,cf1:val\")\n    > TBLPROPERTIES (\"hbase.table.name\" = \"xyz\");\nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n\n============================\n\n\n2015-08-26 19:58:58,095 ERROR [main]: exec.DDLTask (DDLTask.java:failed(520)) - java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n\tat org.apache.hadoop.hive.hbase.HBaseStorageHandler.preCreateTable(HBaseStorageHandler.java:214)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:664)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:657)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)\n\tat com.sun.proxy.$Proxy9.createTable(Unknown Source)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:714)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4135)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:306)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)\n\tat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1650)\n\tat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1409)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1192)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)\n\tat org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\n\tat org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:736)\n\tat org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)\n\tat org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n\n2015-08-26 19:58:58,096 ERROR [main]: ql.Driver (SessionState.java:printError(957)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V\n2015-08-26 19:58:58,096 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(148)) - </PERFLOG method=Driver.execute start=1440599336948 end=1440599338096 duration=1148 from=org.apache.hadoop.hive.ql.Driver>\n2015-08-26 19:58:58,096 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(121)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>\n2015-08-26 19:58:58,097 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(148)) - </PERFLOG method=releaseLocks start=1440599338096 end=1440599338097 duration=1 from=org.apache.hadoop.hive.ql.Driver>\n2015-08-26 19:58:58,098 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(121)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>\n2015-08-26 19:58:58,098 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(148)) - </PERFLOG method=releaseLocks start=1440599338098 end=1440599338098 duration=0 from=org.apache.hadoop.hive.ql.Driver>","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"created":"2015-08-26T10:52:49.681+0000","updated":"2015-08-26T10:52:49.681+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14713354","id":"14713354","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"body":"> However it should be noted that the branch 1.x of hive is going to stay on < hbase 1.0 still to maintain passivity with older versions of hbase\n\nIt seems unfortunate to have ended up in a situation where latest stable releases of hbase and hive are incompatible. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kevinl","name":"kevinl","key":"kevinl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Ludwig","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T13:09:39.148+0000","updated":"2015-08-26T13:09:39.148+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14713477","id":"14713477","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"[~gurmukhd] Did you mention before that it was working on hive 1.1 and hbase 1.0?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T14:09:34.220+0000","updated":"2015-08-26T14:09:34.220+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14713483","id":"14713483","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"body":"I have to test that again, as it was long back. I might be missing something. \n\nWill test and update.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gurmukhd","name":"gurmukhd","key":"gurmukhd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"gurmukh singh","active":true,"timeZone":"Australia/Sydney"},"created":"2015-08-26T14:11:40.925+0000","updated":"2015-08-26T14:11:40.925+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14713591","id":"14713591","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"[~kevinl] Since this change was introduced in hbase 0.99, one thing we could possibly do is  bump the version up to 0.99 in this branch so still keeping it under 1.0 and compile it. But again even with that, we might end up breaking compatibility with older version and for consumers who are not ready to consume > 0.99 hbase yet. The only option I am seeing right now is that if you want to get it running on hbase 1.0, you might have to bump the version and recompile hive yourself.\n\n[~ndimiduk] Any suggestions from your end being the HBase champion? :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T14:53:33.649+0000","updated":"2015-08-26T14:53:33.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14715152","id":"14715152","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"body":"Diff people are posting different stack traces, I see two errors from folks' comments:\n\n# {{java.lang.IllegalArgumentException: Family name can not be empty}}\n# {{java.lang.NoSuchMethodError: org.apache.hadoop.hbase.HTableDescriptor.addFamily(Lorg/apache/hadoop/hbase/HColumnDescriptor;)V}}\n\nThe first seems like an invalid DDL. Somehow you're trying to create a table without specifying a column family.\n\nThe second is a subtle ABI incompatibility around {{HTableDescriptor#addFamily}} introduced after HBASE-12046, a change present in HBase 1.0+. See [javadoc from master|http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html#addFamily(org.apache.hadoop.hbase.HColumnDescriptor)] vs. [javadoc from 0.94 branch|http://hbase.apache.org/0.94/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html#addFamily(org.apache.hadoop.hbase.HColumnDescriptor)]. Bottom line is you cannot use a client compiled vs. 0.98 with a runtime using 1.0+. In this case the difference is only in return type and the [hive code|https://github.com/apache/hive/blob/master/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java#L214] in question is ignoring it. Thus, you just need to recompile hive vs. the correct runtime hbase version; no source change required.\n\nTo create a binary that supports either version, you'll need to use reflection to invoke the {{addFamily}} method. That will fix this one API change, but there are probably others lurking.\n\nLet me also point out that HBase has never guaranteed ABI compatibility between minor release versions. For the post-1.0 world, we're calling this out explicitly in the [compatibility promise|http://hbase.apache.org/book.html#hbase.versioning.post10] (see table 3, \"compatibility matrix\", there's a row for client binary compatibility). For the pre-1.0 releases, we always suggest clients recompile their applications vs. the newest hbase version jars after an upgrade.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-26T17:00:38.397+0000","updated":"2015-08-26T17:00:38.397+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14715155","id":"14715155","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"body":"FYI [~enis], [~apurtell].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-26T17:02:00.485+0000","updated":"2015-08-26T17:02:00.485+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14715164","id":"14715164","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apurtell","name":"apurtell","key":"apurtell","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apurtell&avatarId=20553","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apurtell&avatarId=20553","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apurtell&avatarId=20553","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apurtell&avatarId=20553"},"displayName":"Andrew Purtell","active":true,"timeZone":"America/Los_Angeles"},"body":"I think you meant major release versions [~ndimiduk]. If so, that's right, across major releases we might introduce changes that affect ABI compatibility. _Post_ 1.0 we'd take a harder look than in the past if the breaking change is necessary, but leading up to the 1.0 release we made API changes to help with long term maintainability once at 1.0.\n\nbq. one thing we could possibly do is bump the version up to 0.99 in this branch\nPlease don't use any 0.99. This was a developer preview of 1.0 and is not meant for use by anyone other than HBase developers, and at this point is an artifact of historical interest at best. The next release after 0.98 is 1.0.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apurtell","name":"apurtell","key":"apurtell","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apurtell&avatarId=20553","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apurtell&avatarId=20553","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apurtell&avatarId=20553","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apurtell&avatarId=20553"},"displayName":"Andrew Purtell","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-26T17:08:01.758+0000","updated":"2015-08-26T17:08:01.758+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14715177","id":"14715177","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apurtell","name":"apurtell","key":"apurtell","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apurtell&avatarId=20553","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apurtell&avatarId=20553","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apurtell&avatarId=20553","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apurtell&avatarId=20553"},"displayName":"Andrew Purtell","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I think you meant major release versions Nick Dimiduk. \nNever mind, I reviewed that section of the book and yes the matrix marks minor release versions as potentially incompatible also. Note this is the degree of freedom the HBase developers have decided to advertise as possible and not a guarantee that such breakage would happen. I would be interested in helping you address post-1.0 ABI issues if they arise. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apurtell","name":"apurtell","key":"apurtell","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apurtell&avatarId=20553","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apurtell&avatarId=20553","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apurtell&avatarId=20553","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apurtell&avatarId=20553"},"displayName":"Andrew Purtell","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-26T17:13:29.678+0000","updated":"2015-08-26T17:13:29.678+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14715187","id":"14715187","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"{quote}\nThus, you just need to recompile hive vs. the correct runtime hbase version; no source change required.\n{quote}\n\nYeah that's what I was referring to do with my comment here[1]. Unfortunately though like I mentioned, not sure if we can do this in general and then release as that would break passivity for consumers < hbase 1.0. Primarily the reason why we are choosing to leave hive 1.x stream on hbase 0.98.x as that branch is currently maintaining backwards compatibility and then bump hive 2.x to hbase 1.x.\n\n[1] https://issues.apache.org/jira/browse/HIVE-10990?focusedCommentId=14713591&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14713591","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T17:21:33.472+0000","updated":"2015-08-26T17:21:33.472+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14715202","id":"14715202","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"{quote}\nPlease don't use any 0.99. This was a developer preview of 1.0 and is not meant for use by anyone other than HBase developers, and at this point is an artifact of historical interest at best.\n{quote}\n\nGood call on this. I wasn't aware of that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-26T17:32:02.067+0000","updated":"2015-08-26T17:32:02.067+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14715469","id":"14715469","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"Three places spring to mind:  the Hive HBase Integration doc (definitely) and two places that discuss version requirements, Getting Started and the Installation doc.  Here are their links:\n\n* [Hive HBase Integration | https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration] -- add this information to the \"Version information\" box right after the table of contents\n* [Getting Started -- Requirements | https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-Requirements]\n* [Installing Hive | https://cwiki.apache.org/confluence/display/Hive/AdminManual+Installation#AdminManualInstallation-InstallingHive]\n\nAnother section of the wiki, Hive Versions and Branches, doesn't seem appropriate for this information but here's the link in case you disagree:\n\n* [Home -- Hive Versions and Branches | https://cwiki.apache.org/confluence/display/Hive/Home#Home-HiveVersionsandBranches]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2015-08-26T20:38:04.737+0000","updated":"2015-08-26T20:38:04.737+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14721410","id":"14721410","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~leftylev]. I updated this info on the wiki[1]. Please do let me know if it looks fine to you.\n\n[1] https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-30T06:18:52.344+0000","updated":"2015-08-30T06:18:52.344+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14721411","id":"14721411","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"I have updated this info on the Hive/HBase Integration wiki[1] to avoid confusion for consumers of this integration.\n\n[1] https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-30T06:20:00.172+0000","updated":"2015-08-30T06:20:00.172+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14727117","id":"14727117","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"Looks good, thanks [~swarnim].  I agree that it isn't needed in the Getting Started and Installation docs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2015-09-02T10:06:52.215+0000","updated":"2015-09-02T10:06:52.215+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12837393/comment/14734132","id":"14734132","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"body":"Since this constraint has been documented on the wiki, on the basis of the above conversation resolving this one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=swarnim","name":"swarnim","key":"swarnim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Swarnim Kulkarni","active":true,"timeZone":"Etc/UTC"},"created":"2015-09-08T02:04:47.200+0000","updated":"2015-09-08T02:04:47.200+0000"}],"maxResults":36,"total":36,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10990/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2fz0v:"}}