{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13029740","self":"https://issues.apache.org/jira/rest/api/2/issue/13029740","key":"HIVE-15485","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340269","id":"12340269","name":"2.3.0","archived":false,"released":true,"releaseDate":"2017-07-18"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-01-25T11:12:21.622+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Nov 27 01:11:09 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_2990439876_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_476912411","customfield_12312321":null,"resolutiondate":"2017-01-30T16:31:21.347+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15485/watchers","watchCount":6,"isWatching":false},"created":"2016-12-21T13:22:09.120+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12490424","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12490424","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12993590","key":"HIVE-14383","self":"https://issues.apache.org/jira/rest/api/2/issue/12993590","fields":{"summary":"SparkClientImpl should pass principal and keytab to spark-submit instead of calling kinit explicitely","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12507120","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12507120","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13081326","key":"HIVE-16930","self":"https://issues.apache.org/jira/rest/api/2/issue/13081326","fields":{"summary":"HoS should verify the value of Kerberos principal and keytab file before adding them to spark-submit command parameters","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-11-27T01:11:09.031+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"With DoAs enabled, HoS failed with following errors:\n{code}\nException in thread \"main\" org.apache.hadoop.security.AccessControlException: systest tries to renew a token with renewer hive\n\tat org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:484)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken(FSNamesystem.java:7543)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewDelegationToken(NameNodeRpcServer.java:555)\n\tat org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.renewDelegationToken(AuthorizationProviderProxyClientProtocol.java:674)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:999)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2141)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2137)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1783)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2135)\n{code}\nIt is related to the change from HIVE-14383. It looks like that SparkSubmit logs in Kerberos with passed in hive principal/keytab and then tries to create a hdfs delegation token for user systest with renewer hive.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12849642","id":"12849642","filename":"HIVE-15485.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-27T04:07:44.202+0000","size":3375,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12849642/HIVE-15485.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12849876","id":"12849876","filename":"HIVE-15485.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-29T15:28:49.665+0000","size":3289,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12849876/HIVE-15485.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12849217","id":"12849217","filename":"HIVE-15485.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-25T04:02:36.356+0000","size":3031,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12849217/HIVE-15485.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Investigate the DoAs failure in HoS","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15771202","id":"15771202","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"HIVE-14383 is the right way to renew the delegation token for a long running HoS session. Spark needs the principal/keytab passed in via --principal and --keytab options, and does the renewal by copying the keytab to the cluster and handling login to kerberos inside the application. \nBut the option --principal, --keytab could not work with --proxy-user in spark-submit.sh as suggested by [~vanzin], so at this moment we could support either the token renewal or the impersonation, but not both.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2016-12-22T21:56:20.147+0000","updated":"2016-12-22T21:56:20.147+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15837148","id":"15837148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"Given that we are not able to support both doAs and delegation token renewal in Spark at this moment (see comments in SPARK-5493, SPARK-19143 etc), and doAs is more common case in Hive, so when doAs is enabled, we will use kinit instead of passing the principal/keytab to Spark. I could not thought of other ways to make both work. [~xuefuz], do you have any thought? If you agree on that, could you help review the patch? Thanks. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-25T04:02:36.366+0000","updated":"2017-01-25T04:02:36.366+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15837578","id":"15837578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12849217/HIVE-15485.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 10983 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=98)\n\t[ptf_general_queries.q,auto_join_reordering_values.q,sample2.q,join1.q,decimal_join.q,mapjoin_subquery2.q,join32_lessSize.q,mapjoin1.q,order2.q,skewjoinopt18.q,union_remove_18.q,join25.q,groupby9.q,bucketsortoptimize_insert_6.q,ctas.q]\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[offset_limit_ppd_optimizer] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=93)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3169/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3169/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3169/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 7 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12849217 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-01-25T11:12:21.622+0000","updated":"2017-01-25T11:12:21.622+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15839755","id":"15839755","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"[~xuefuz], [~csun], [~jxiang], could you review the patch to see if it makes sense, so that we can at lease unblock the doAs issue? Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-26T14:34:33.520+0000","updated":"2017-01-26T14:34:33.520+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15840049","id":"15840049","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"body":"Could you put the two changes in your patch in the same place to make it a little easier to understand?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-26T17:03:58.711+0000","updated":"2017-01-26T17:03:58.711+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15840222","id":"15840222","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"Thanks, Jimmy, for looking into this. When doAs is enabled, we use kinit to login Kerberos and this kinit command need be put before the spark-submit.sh, but when doAs is disabled, the principal/keytab should be after spark-submit.sh as its parameters. I was also wondering how to combine these two changes into one, but have not found a good way. Any suggestion?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-26T18:58:17.995+0000","updated":"2017-01-26T18:58:17.995+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15840465","id":"15840465","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"body":"For doAs, add kinit etc to the beginning of the list; for the other add principal etc at the end. If you are concerned with performance, will LinkedList be better than ArrayList here?\n\nBy the way, should keyTabFile + \";\" be two argvs?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-26T21:10:17.597+0000","updated":"2017-01-26T21:10:17.597+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15840922","id":"15840922","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"Thanks [~jxiang]. Please take a look to see if it is you suggested. The keytab + \";\" do not have to be in two argv. Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-27T04:07:44.210+0000","updated":"2017-01-27T04:07:44.210+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15843082","id":"15843082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for making the change. Looks good to me. +1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-27T16:34:03.355+0000","updated":"2017-01-27T16:34:03.355+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15843696","id":"15843696","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12849642/HIVE-15485.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 43 failed/errored test(s), 10419 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=93)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=100)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=101)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=102)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=103)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=104)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=105)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=106)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=107)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=108)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=109)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=110)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=111)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=112)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=113)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=114)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=115)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=116)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=117)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=118)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=119)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=120)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=121)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=122)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=124)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=125)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=126)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=127)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=128)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=129)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=130)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=131)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=132)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=133)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=95)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=96)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=97)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=98)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=99)\norg.apache.hive.spark.client.TestSparkClient.testRemoteClient (batchId=278)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3226/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3226/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3226/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 43 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12849642 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-01-28T00:22:18.163+0000","updated":"2017-01-28T00:22:18.163+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15843793","id":"15843793","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"Fixed the test failures.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-28T03:06:37.711+0000","updated":"2017-01-28T03:06:37.711+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15844057","id":"15844057","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12849796/HIVE-15485.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10973 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=109)\n\t[union_remove_1.q,ppd_outer_join2.q,date_udf.q,groupby1_noskew.q,join20.q,smb_mapjoin_13.q,groupby_rollup1.q,temp_table_gb1.q,vector_string_concat.q,smb_mapjoin_6.q,metadata_only_queries.q,auto_sortmerge_join_12.q,groupby_bigdata.q,groupby3_map_multi_distinct.q,innerjoin.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=125)\n\t[table_access_keys_stats.q,bucketmapjoin11.q,auto_join4.q,mapjoin_decimal.q,join34.q,nullgroup.q,mergejoins_mixed.q,sort.q,stats8.q,auto_join28.q,join17.q,union17.q,skewjoinopt11.q,groupby1_map.q,load_dyn_part11.q]\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_varchar_simple] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=93)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3240/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3240/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3240/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 8 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12849796 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-01-28T13:33:27.565+0000","updated":"2017-01-28T13:33:27.565+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15844102","id":"15844102","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"The test failures are not related to this patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-28T16:07:35.365+0000","updated":"2017-01-28T16:07:35.365+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15844215","id":"15844215","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry for my late reply. (I'm currently OOO.) The patch looks good to me too. While these test failures are caused by something else, the fact that some Spark tests didn't actually run is a little concern. Is there a way to validate these tests locally?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-28T22:40:45.075+0000","updated":"2017-01-28T22:40:45.075+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15844487","id":"15844487","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"Thanks [~xuefuz] for looking into this patch. I have attached a new patch to trigger the build test. The patch has been verified in my local environment. The TestSparkCliDriver tests ran successfully. I also manually validated cases (e.g. kerberos w/ or w/o doAs) in my local cluster, they all passed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-29T15:48:07.786+0000","updated":"2017-01-29T15:48:07.786+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15844510","id":"15844510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12849876/HIVE-15485.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 11003 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_char_simple] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_3] (batchId=93)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=93)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3249/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3249/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3249/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 7 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12849876 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-01-29T16:29:59.801+0000","updated":"2017-01-29T16:29:59.801+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15844526","id":"15844526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"The failed tests are not related to this patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-29T16:49:06.935+0000","updated":"2017-01-29T16:49:06.935+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15844657","id":"15844657","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"+1. Thanks for looking into this, [~ctang.ma].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-29T21:10:04.445+0000","updated":"2017-01-29T21:10:04.445+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/15845408","id":"15845408","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"Committed to 2.2.0. Thanks [~xuefuz] and [~jxiang] for review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-01-30T16:31:21.380+0000","updated":"2017-01-30T16:31:21.380+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/16265585","id":"16265585","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linzhangbing","name":"linzhangbing","key":"linzhangbing","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhangBing Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi,[~ctang.ma],when I use you patch in my cluster,the cluster use hive2.2.0 and spark-assembly-1.6.0,I use beeline to commit spark task occuring some error:\r\nSLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\r\nException in thread \"main\" java.lang.reflect.UndeclaredThrowableException\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1643)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:161)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:232)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:384)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:328)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:308)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:284)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:606)\r\n\tat org.apache.spark.deploy.yarn.YarnSparkHadoopUtil.obtainTokenForHiveMetastoreInner(YarnSparkHadoopUtil.scala:204)\r\n\tat org.apache.spark.deploy.yarn.YarnSparkHadoopUtil.obtainTokenForHiveMetastore(YarnSparkHadoopUtil.scala:159)\r\n\tat org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$obtainTokenForHiveMetastore(Client.scala:1365)\r\n\tat org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:350)\r\n\tat org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:722)\r\n\tat org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142)\r\n\tat org.apache.spark.deploy.yarn.Client.run(Client.scala:1016)\r\n\tat org.apache.spark.deploy.yarn.Client$.main(Client.scala:1076)\r\n\tat org.apache.spark.deploy.yarn.Client.main(Client.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:606)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$1.run(SparkSubmit.scala:163)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$1.run(SparkSubmit.scala:161)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\r\n\t... 4 more\r\nCaused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\r\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1654)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3496)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3548)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3528)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3790)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:244)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:227)\r\n\t... 31 more\r\nCaused by: java.lang.reflect.InvocationTargetException\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\r\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1652)\r\n\t... 40 more\r\nCaused by: MetaException(message:Could not connect to meta store using any of the URIs provided. Most recent failure: org.apache.thrift.transport.TTransportException: GSS initiate failed\r\n\tat org.apache.thrift.transport.TSaslTransport.sendAndThrowMessage(TSaslTransport.java:232)\r\n\tat org.apache.thrift.transport.TSaslTransport.open(TSaslTransport.java:316)\r\n\tat org.apache.thrift.transport.TSaslClientTransport.open(TSaslClientTransport.java:37)\r\n\tat org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport$1.run(TUGIAssumingTransport.java:52)\r\n\tat org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport$1.run(TUGIAssumingTransport.java:49)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\r\n\tat org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport.open(TUGIAssumingTransport.java:49)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:484)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:292)\r\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\r\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1652)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\r\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3496)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3548)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3528)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3790)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:244)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:227)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:384)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:328)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:308)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:284)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:606)\r\n\tat org.apache.spark.deploy.yarn.YarnSparkHadoopUtil.obtainTokenForHiveMetastoreInner(YarnSparkHadoopUtil.scala:204)\r\n\tat org.apache.spark.deploy.yarn.YarnSparkHadoopUtil.obtainTokenForHiveMetastore(YarnSparkHadoopUtil.scala:159)\r\n\tat org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$obtainTokenForHiveMetastore(Client.scala:1365)\r\n\tat org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:350)\r\n\tat org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:722)\r\n\tat org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142)\r\n\tat org.apache.spark.deploy.yarn.Client.run(Client.scala:1016)\r\n\tat org.apache.spark.deploy.yarn.Client$.main(Client.scala:1076)\r\n\tat org.apache.spark.deploy.yarn.Client.main(Client.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:606)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$1.run(SparkSubmit.scala:163)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$1.run(SparkSubmit.scala:161)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:161)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:531)\r\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:292)\r\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\r\n\t... 45 more\r\n\r\n\tat io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:37)\r\n\tat org.apache.hive.spark.client.SparkClientImpl.<init>(SparkClientImpl.java:106)\r\n\t... 27 more","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linzhangbing","name":"linzhangbing","key":"linzhangbing","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhangBing Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-11-25T03:13:46.477+0000","updated":"2017-11-25T03:13:46.477+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/16265873","id":"16265873","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"body":"[~linzhangbing] I assume that you used beeline via HoS. Please try this Spark property spark.yarn.security.tokens.hive.enabled=true to see if it helps.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctang.ma","name":"ctang.ma","key":"ctang.ma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chaoyu Tang","active":true,"timeZone":"America/New_York"},"created":"2017-11-25T22:45:42.958+0000","updated":"2017-11-25T22:45:42.958+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13029740/comment/16266282","id":"16266282","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linzhangbing","name":"linzhangbing","key":"linzhangbing","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhangBing Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"Thank you,[~ctang.ma],i will try it with your suggest.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linzhangbing","name":"linzhangbing","key":"linzhangbing","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhangBing Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-11-27T01:11:09.031+0000","updated":"2017-11-27T01:11:09.031+0000"}],"maxResults":22,"total":22,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15485/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i37vgv:"}}