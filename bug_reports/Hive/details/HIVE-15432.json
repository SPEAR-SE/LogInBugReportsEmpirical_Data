{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13028324","self":"https://issues.apache.org/jira/rest/api/2/issue/13028324","key":"HIVE-15432","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2016-12-15T08:38:32.345+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Dec 15 08:38:32 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_366369_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2016-12-15T08:27:18.577+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15432/watchers","watchCount":2,"isWatching":false},"created":"2016-12-15T08:21:13.027+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-12-15T08:38:32.345+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"set \"hive.input.format\" as \"org.apache.hadoop.hive.ql.io.CombineHiveInputFormat\" in itests/qtest/target/testconf/spark/standalone/hive-site.xml and run qtest like following cmd:\n{code}\nmvn test -Dtest=TestSparkCliDriver -Dtest.output.overwrite=true -Dqfile=union.q  >log.TestSparkCliDriver 2>&1\n{code}\n\nfound following exception in itests/qtest-spark/target/tmp/log/hive.log\n{code}\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl: java.lang.ClassCastException: Cannot cast org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombineHiveInputSplit to org.apache.hadoop.mapred.InputSplitWithLocationInfo\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at java.lang.Class.cast(Class.java:3094)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.rdd.HadoopRDD.getPreferredLocations(HadoopRDD.scala:318)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.rdd.RDD$$anonfun$preferredLocations$2.apply(RDD.scala:270)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.rdd.RDD$$anonfun$preferredLocations$2.apply(RDD.scala:270)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at scala.Option.getOrElse(Option.scala:121)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.rdd.RDD.preferredLocations(RDD.scala:269)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal(DAGScheduler.scala:1564)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2$$anonfun$apply$1.apply$mcVI$sp(DAGScheduler.scala:1575)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2$$anonfun$apply$1.apply(DAGScheduler.scala:1574)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2$$anonfun$apply$1.apply(DAGScheduler.scala:1574)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at scala.collection.immutable.List.foreach(List.scala:381)\n2016-12-14T23:43:17,819  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2.apply(DAGScheduler.scala:1574)\n2016-12-14T23:43:17,820  INFO [stderr-redir-1] client.SparkClientImpl:  at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2.apply(DAGScheduler.scala:1572)\n2016-12-14T23:43:17,820  INFO [stderr-redir-1] client.SparkClientImpl:  at scala.collection.immutable.List.foreach(List.scala:381)\n\n{code}\n\n\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"java.lang.ClassCastException is thrown when setting \"hive.input.format\" as \"org.apache.hadoop.hive.ql.io.CombineHiveInputFormat\" in hive on spark","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028324/comment/15750760","id":"15750760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui] : do we support \"org.apache.hadoop.hive.ql.io.CombineHiveInputFormat\" on hive on spark?\nI saw following in  itests/qtest/target/testconf/spark/standalone/hive-site.xml, it suggests to override CombineHiveInputFormat with HiveInputFormat if users meet error.\n{code}\n<property>\n  <name>hive.input.format</name>\n  <value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value>\n  <description>The default input format, if it is not specified, the system assigns it. It is set to HiveInputFormat for hadoop versions 17, 18 and 19, whereas it is set to CombineHiveInputFormat for hadoop 20. The user can always overwrite it - if there is a bug in CombineHiveInputFormat, it can always be manually set to HiveInputFormat. </description>\n</property>\n\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-12-15T08:24:16.951+0000","updated":"2016-12-15T08:24:16.951+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028324/comment/15750766","id":"15750766","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"duplicated with HIVE-8722","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-12-15T08:27:18.722+0000","updated":"2016-12-15T08:27:18.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028324/comment/15750782","id":"15750782","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], I think this is just a warning in the log and doesn't cause test failure right? I also had a very old task HIVE-9227 to solve it. I had some difficulties with it, although don't remember what they were exactly.\nIn my opinion, the issue doesn't have a big impact on performance. But let me know if you want to work on it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-12-15T08:38:32.345+0000","updated":"2016-12-15T08:38:32.345+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15432/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i37mqf:"}}