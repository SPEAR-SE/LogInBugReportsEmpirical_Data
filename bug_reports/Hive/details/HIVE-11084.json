{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12839907","self":"https://issues.apache.org/jira/rest/api/2/issue/12839907","key":"HIVE-11084","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2015-06-24T19:40:34.685+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jun 25 14:55:36 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_39907568419_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2016-09-27T15:19:57.834+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11084/watchers","watchCount":2,"isWatching":false},"created":"2015-06-23T17:53:49.681+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12317742","id":"12317742","description":"released","name":"0.9.0","archived":false,"released":true,"releaseDate":"2012-04-30"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-09-27T15:19:58.029+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320633","id":"12320633","name":"File Formats","description":"File Formats"}],"timeoriginalestimate":null,"description":"{code}\nhive> CREATE TABLE intable_p (\n    >   sr_no int,\n    >   name string,\n    >   emp_id int\n    > ) PARTITIONED BY (\n    >   a string,\n    >   b string,\n    >   c string\n    > ) ROW FORMAT DELIMITED\n    >   FIELDS TERMINATED BY '\\t'\n    >   LINES TERMINATED BY '\\n'\n    > STORED AS PARQUET;\n\nhive> insert overwrite table intable_p partition (a='a', b='b', c='c') select * from intable;\nTotal jobs = 3\nLaunching Job 1 out of 3\nNumber of reduce tasks is set to 0 since there's no reduce operator\n....\nMapReduce Jobs Launched:\nStage-Stage-1: Map: 1   Cumulative CPU: 2.59 sec   HDFS Read: 247 HDFS Write: 410 SUCCESS\nTotal MapReduce CPU Time Spent: 2 seconds 590 msec\nOK\nTime taken: 30.382 seconds\nhive> show create table intable_p;\nOK\nCREATE  TABLE `intable_p`(\n  `sr_no` int,\n  `name` string,\n  `emp_id` int)\nPARTITIONED BY (\n  `a` string,\n  `b` string,\n  `c` string)\nROW FORMAT DELIMITED\n  FIELDS TERMINATED BY '\\t'\n  LINES TERMINATED BY '\\n'\nSTORED AS INPUTFORMAT\n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\nOUTPUTFORMAT\n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\nLOCATION\n  'hdfs://nameservice1/hive/db/intable_p'\nTBLPROPERTIES (\n  'transient_lastDdlTime'='1435080569')\nTime taken: 0.212 seconds, Fetched: 19 row(s)\nhive> CREATE  TABLE `intable_p2`(\n    >   `sr_no` int,\n    >   `name` string,\n    >   `emp_id` int)\n    > PARTITIONED BY (\n    >   `a` string,\n    >   `b` string,\n    >   `c` string)\n    > ROW FORMAT DELIMITED\n    >   FIELDS TERMINATED BY '\\t'\n    >   LINES TERMINATED BY '\\n'\n    > STORED AS INPUTFORMAT\n    >   'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n    > OUTPUTFORMAT\n    >   'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat';\nOK\nTime taken: 0.179 seconds\nhive> insert overwrite table intable_p2 partition (a='a', b='b', c='c') select * from intable;\nTotal jobs = 3\nLaunching Job 1 out of 3\nNumber of reduce tasks is set to 0 since there's no reduce operator\n...\nHadoop job information for Stage-1: number of mappers: 1; number of reducers: 0\n2015-06-23 17:34:40,471 Stage-1 map = 0%,  reduce = 0%\n2015-06-23 17:35:10,753 Stage-1 map = 100%,  reduce = 0%\nEnded Job = job_1433246369760_7947 with errors\nError during job, obtaining debugging information...\nExamining task ID: task_xxxx (and more) from job job_xxxx\n\nTask with the most failures(4):\n-----\nTask ID:\n  task_xxxx\n\nURL:\n  xxxx\n-----\nDiagnostic Messages for this Task:\nError: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"sr_no\":1,\"name\":\"ABC\",\"emp_id\":1001}\n        at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:198)\n        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)\n        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"sr_no\":1,\"name\":\"ABC\",\"emp_id\":1001}\n        at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:549)\n        at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:180)\n        ... 8 more\nCaused by: {color:red}java.lang.ClassCastException: org.apache.hadoop.io.Text cannot be cast to org.apache.hadoop.io.ArrayWritable{color}\n        at org.apache.hadoop.hive.ql.io.parquet.write.ParquetRecordWriterWrapper.write(ParquetRecordWriterWrapper.java:105)\n        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:628)\n        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796)\n        at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87)\n        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796)\n        at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)\n        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796)\n        at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:539)\n        ... 9 more\n\n\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask\nMapReduce Jobs Launched:\nStage-Stage-1: Map: 1   HDFS Read: 0 HDFS Write: 0 FAIL\nTotal MapReduce CPU Time Spent: 0 msec\nhive>\n{code}\n\nWhat is the issue with my second table?","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Issue in Parquet Hive Table","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chanchal1987","name":"chanchal1987","key":"chanchal1987","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chanchal Kumar Ghosh","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chanchal1987","name":"chanchal1987","key":"chanchal1987","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chanchal Kumar Ghosh","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"GNU/Linux","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12839907/comment/14600006","id":"14600006","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"body":"This bug happens with any other table format, like orc and avro. Seems the problem happens only when creating tables with INPUTFORMAT and OUTPUTFORMAT keywords.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"created":"2015-06-24T19:40:34.685+0000","updated":"2015-06-24T19:40:34.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12839907/comment/14600109","id":"14600109","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"body":"I found the problem with your statement. You need to pass the ROW FORMAT SERDE parameter as you are using custom input/output format.\nThis CREATE TABLE should work:\n\n{noformat}\nhive> CREATE  TABLE `intable_p2`(\n    >   `sr_no` int,\n    >   `name` string,\n    >   `emp_id` int)\n    > PARTITIONED BY (\n    >   `a` string,\n    >   `b` string,\n    >   `c` string)\n    > ROW FORMAT SERDE\n    >   'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n    > STORED AS INPUTFORMAT\n    >   'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n    > OUTPUTFORMAT\n    >   'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat';\n{noformat}\n\nThe use of STORE AS PARQUET allows Hive to use default serde/inputformat/outputformat classes. But for custom parameters, you need to specify specific classes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"created":"2015-06-24T20:40:50.948+0000","updated":"2015-06-24T20:40:50.948+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12839907/comment/14600407","id":"14600407","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chanchal1987","name":"chanchal1987","key":"chanchal1987","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chanchal Kumar Ghosh","active":true,"timeZone":"America/Los_Angeles"},"body":"But in <code>show create table<code> command it is showing <code>ROW FORMAT DELIMITED<code>","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chanchal1987","name":"chanchal1987","key":"chanchal1987","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chanchal Kumar Ghosh","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-24T23:59:32.940+0000","updated":"2015-06-24T23:59:32.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12839907/comment/14601303","id":"14601303","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"body":"That is a bug on the Hive side. It should have shown {{ROW FORMAT SERDE}} because you are using an alias to specify the file format. Or, the create command should have failed mentioned you cannot specify a row format delimited if you use an alias.\n\nI'll create a jira to fix this bug, and shows the correct information on {{SHOW CREATE TABLE}}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"created":"2015-06-25T14:55:36.302+0000","updated":"2015-06-25T14:55:36.302+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11084/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2gean:"}}