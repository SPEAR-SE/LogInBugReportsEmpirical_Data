{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12819081","self":"https://issues.apache.org/jira/rest/api/2/issue/12819081","key":"HIVE-10244","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-05-11T03:47:10.479+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu May 28 23:20:34 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_596290769_*|*_1_*:*_1_*:*_3816995514_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-05-28T23:19:50.873+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10244/watchers","watchCount":7,"isWatching":false},"created":"2015-04-07T21:25:05.214+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326450","id":"12326450","description":"released","name":"0.14.0","archived":false,"released":true,"releaseDate":"2014-11-12"}],"issuelinks":[{"id":"12421540","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12421540","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12821392","key":"HIVE-10356","self":"https://issues.apache.org/jira/rest/api/2/issue/12821392","fields":{"summary":"LLAP: query80 fails with vectorization cast issue ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-06-05T20:57:42.144+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12321300","id":"12321300","name":"Vectorization","description":"Vectorized query execution"}],"timeoriginalestimate":null,"description":"Query \n{code}\nset hive.vectorized.execution.reduce.enabled=true;\nwith ssr as\n (select  s_store_id as store_id,\n          sum(ss_ext_sales_price) as sales,\n          sum(coalesce(sr_return_amt, 0)) as returns,\n          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit\n  from store_sales left outer join store_returns on\n         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),\n     date_dim,\n     store,\n     item,\n     promotion\n where ss_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-04' as date) \n                  and (cast('1998-09-04' as date))\n       and ss_store_sk = s_store_sk\n       and ss_item_sk = i_item_sk\n       and i_current_price > 50\n       and ss_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\n group by s_store_id)\n ,\n csr as\n (select  cp_catalog_page_id as catalog_page_id,\n          sum(cs_ext_sales_price) as sales,\n          sum(coalesce(cr_return_amount, 0)) as returns,\n          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit\n  from catalog_sales left outer join catalog_returns on\n         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),\n     date_dim,\n     catalog_page,\n     item,\n     promotion\n where cs_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-04' as date)\n                  and (cast('1998-09-04' as date))\n        and cs_catalog_page_sk = cp_catalog_page_sk\n       and cs_item_sk = i_item_sk\n       and i_current_price > 50\n       and cs_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\ngroup by cp_catalog_page_id)\n ,\n wsr as\n (select  web_site_id,\n          sum(ws_ext_sales_price) as sales,\n          sum(coalesce(wr_return_amt, 0)) as returns,\n          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit\n  from web_sales left outer join web_returns on\n         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),\n     date_dim,\n     web_site,\n     item,\n     promotion\n where ws_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-04' as date)\n                  and (cast('1998-09-04' as date))\n        and ws_web_site_sk = web_site_sk\n       and ws_item_sk = i_item_sk\n       and i_current_price > 50\n       and ws_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\ngroup by web_site_id)\n  select  channel\n        , id\n        , sum(sales) as sales\n        , sum(returns) as returns\n        , sum(profit) as profit\n from \n (select 'store channel' as channel\n        , concat('store', store_id) as id\n        , sales\n        , returns\n        , profit\n from   ssr\n union all\n select 'catalog channel' as channel\n        , concat('catalog_page', catalog_page_id) as id\n        , sales\n        , returns\n        , profit\n from  csr\n union all\n select 'web channel' as channel\n        , concat('web_site', web_site_id) as id\n        , sales\n        , returns\n        , profit\n from   wsr\n ) x\n group by channel, id with rollup\n order by channel\n         ,id\n limit 100\n{code}\n\nException \n{code}\nVertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]\n15/04/07 05:14:52 [main]: ERROR SessionState: Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]\nVertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]\n15/04/07 05:14:52 [main]: ERROR SessionState: Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]\nDAG failed due to vertex failure. failedVertices:1 killedVertices:1\n15/04/07 05:14:52 [main]: ERROR SessionState: DAG failed due to vertex failure. failedVertices:1 killedVertices:1\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010☃00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:1\n15/04/07 05:14:52 [main]: ERROR ql.Driver: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8☃00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \\N\u0001\\N\u00010\u00019.285817653506076E8\u00014.639990363237801E7\u0001-1.1814318134887291E8\n\\N\u0001\\N\u00010\u00014.682909323885761E8\u00012.2415242712669864E7\u0001-5.966176123188091E7\n\\N\u0001\\N\u00010\u00011.2847032699693155E9\u00016.300096113768728E7\u0001-5.94963316209578E8\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252)\n\t... 16 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378)\n\t... 17 more\n]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:1\n{code}\n\nPlan \n{code}\n\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Tez\n      Edges:\n        Map 12 <- Map 14 (BROADCAST_EDGE), Map 15 (BROADCAST_EDGE), Map 16 (BROADCAST_EDGE), Map 17 (BROADCAST_EDGE), Map 18 (BROADCAST_EDGE)\n        Map 19 <- Map 21 (BROADCAST_EDGE), Map 22 (BROADCAST_EDGE), Map 23 (BROADCAST_EDGE), Map 24 (BROADCAST_EDGE), Map 25 (BROADCAST_EDGE)\n        Reducer 13 <- Map 12 (SIMPLE_EDGE), Union 4 (CONTAINS)\n        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 10 (BROADCAST_EDGE), Map 11 (BROADCAST_EDGE), Map 7 (SIMPLE_EDGE), Map 8 (BROADCAST_EDGE), Map 9 (BROADCAST_EDGE)\n        Reducer 20 <- Map 19 (SIMPLE_EDGE), Union 4 (CONTAINS)\n        Reducer 3 <- Reducer 2 (SIMPLE_EDGE), Union 4 (CONTAINS)\n        Reducer 5 <- Union 4 (SIMPLE_EDGE)\n        Reducer 6 <- Reducer 5 (SIMPLE_EDGE)\n      DagName: mmokhtar_20150407051226_eb6d232e-cb00-4174-8b2f-d70aa2b3fb15:1\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: store_sales\n                  filterExpr: ((ss_item_sk is not null and ss_promo_sk is not null) and ss_store_sk is not null) (type: boolean)\n                  Statistics: Num rows: 550076554 Data size: 47370018896 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((ss_item_sk is not null and ss_promo_sk is not null) and ss_store_sk is not null) (type: boolean)\n                    Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: ss_item_sk (type: int), ss_store_sk (type: int), ss_promo_sk (type: int), ss_ticket_number (type: int), ss_ext_sales_price (type: float), ss_net_profit (type: float), ss_sold_date_sk (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6\n                      Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col3 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col3 (type: int)\n                        Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: int), _col2 (type: int), _col4 (type: float), _col5 (type: float), _col6 (type: int)\n            Execution mode: vectorized\n        Map 10 \n            Map Operator Tree:\n                TableScan\n                  alias: promotion\n                  filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                  Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                    Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: p_promo_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 11 \n            Map Operator Tree:\n                TableScan\n                  alias: store\n                  filterExpr: s_store_sk is not null (type: boolean)\n                  Statistics: Num rows: 212 Data size: 405680 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: s_store_sk is not null (type: boolean)\n                    Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: s_store_sk (type: int), s_store_id (type: string)\n                      outputColumnNames: _col0, _col1\n                      Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: string)\n            Execution mode: vectorized\n        Map 12 \n            Map Operator Tree:\n                TableScan\n                  alias: catalog_sales\n                  filterExpr: ((cs_item_sk is not null and cs_promo_sk is not null) and cs_catalog_page_sk is not null) (type: boolean)\n                  Statistics: Num rows: 286549727 Data size: 37743959324 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((cs_item_sk is not null and cs_promo_sk is not null) and cs_catalog_page_sk is not null) (type: boolean)\n                    Statistics: Num rows: 285112475 Data size: 7974560516 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: cs_catalog_page_sk (type: int), cs_item_sk (type: int), cs_promo_sk (type: int), cs_order_number (type: int), cs_ext_sales_price (type: float), cs_net_profit (type: float), cs_sold_date_sk (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6\n                      Statistics: Num rows: 285112475 Data size: 7974560516 Basic stats: COMPLETE Column stats: COMPLETE\n                      Map Join Operator\n                        condition map:\n                             Left Outer Join0 to 1\n                        keys:\n                          0 _col1 (type: int), _col3 (type: int)\n                          1 _col0 (type: int), _col1 (type: int)\n                        outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10\n                        input vertices:\n                          1 Map 14\n                        Statistics: Num rows: 3412616 Data size: 109203712 Basic stats: COMPLETE Column stats: COMPLETE\n                        Map Join Operator\n                          condition map:\n                               Inner Join 0 to 1\n                          keys:\n                            0 _col6 (type: int)\n                            1 _col0 (type: int)\n                          outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10\n                          input vertices:\n                            1 Map 15\n                          Statistics: Num rows: 3815661 Data size: 106838508 Basic stats: COMPLETE Column stats: COMPLETE\n                          Map Join Operator\n                            condition map:\n                                 Inner Join 0 to 1\n                            keys:\n                              0 _col1 (type: int)\n                              1 _col0 (type: int)\n                            outputColumnNames: _col0, _col2, _col4, _col5, _col9, _col10\n                            input vertices:\n                              1 Map 16\n                            Statistics: Num rows: 1271887 Data size: 30525288 Basic stats: COMPLETE Column stats: COMPLETE\n                            Map Join Operator\n                              condition map:\n                                   Inner Join 0 to 1\n                              keys:\n                                0 _col2 (type: int)\n                                1 _col0 (type: int)\n                              outputColumnNames: _col0, _col4, _col5, _col9, _col10\n                              input vertices:\n                                1 Map 17\n                              Statistics: Num rows: 635944 Data size: 12718880 Basic stats: COMPLETE Column stats: COMPLETE\n                              Map Join Operator\n                                condition map:\n                                     Inner Join 0 to 1\n                                keys:\n                                  0 _col0 (type: int)\n                                  1 _col0 (type: int)\n                                outputColumnNames: _col4, _col5, _col9, _col10, _col18\n                                input vertices:\n                                  1 Map 18\n                                Statistics: Num rows: 635944 Data size: 73769504 Basic stats: COMPLETE Column stats: COMPLETE\n                                Select Operator\n                                  expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float)\n                                  outputColumnNames: _col0, _col1, _col2, _col3\n                                  Statistics: Num rows: 635944 Data size: 73769504 Basic stats: COMPLETE Column stats: COMPLETE\n                                  Group By Operator\n                                    aggregations: sum(_col1), sum(_col2), sum(_col3)\n                                    keys: _col0 (type: string)\n                                    mode: hash\n                                    outputColumnNames: _col0, _col1, _col2, _col3\n                                    Statistics: Num rows: 10590 Data size: 1313160 Basic stats: COMPLETE Column stats: COMPLETE\n                                    Reduce Output Operator\n                                      key expressions: _col0 (type: string)\n                                      sort order: +\n                                      Map-reduce partition columns: _col0 (type: string)\n                                      Statistics: Num rows: 10590 Data size: 1313160 Basic stats: COMPLETE Column stats: COMPLETE\n                                      value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double)\n            Execution mode: vectorized\n        Map 14 \n            Map Operator Tree:\n                TableScan\n                  alias: catalog_returns\n                  filterExpr: cr_item_sk is not null (type: boolean)\n                  Statistics: Num rows: 28798881 Data size: 2942039156 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: cr_item_sk is not null (type: boolean)\n                    Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: cr_item_sk (type: int), cr_order_number (type: int), cr_return_amount (type: float), cr_net_loss (type: float)\n                      outputColumnNames: _col0, _col1, _col2, _col3\n                      Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col1 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)\n                        Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col2 (type: float), _col3 (type: float)\n            Execution mode: vectorized\n        Map 15 \n            Map Operator Tree:\n                TableScan\n                  alias: date_dim\n                  filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                    Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: d_date_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Select Operator\n                        expressions: _col0 (type: int)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                        Group By Operator\n                          keys: _col0 (type: int)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                          Dynamic Partitioning Event Operator\n                            Target Input: catalog_sales\n                            Partition key expr: cs_sold_date_sk\n                            Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                            Target column: cs_sold_date_sk\n                            Target Vertex: Map 12\n            Execution mode: vectorized\n        Map 16 \n            Map Operator Tree:\n                TableScan\n                  alias: item\n                  filterExpr: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                  Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                    Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: i_item_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 17 \n            Map Operator Tree:\n                TableScan\n                  alias: promotion\n                  filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                  Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                    Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: p_promo_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 18 \n            Map Operator Tree:\n                TableScan\n                  alias: catalog_page\n                  filterExpr: cp_catalog_page_sk is not null (type: boolean)\n                  Statistics: Num rows: 11718 Data size: 5400282 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: cp_catalog_page_sk is not null (type: boolean)\n                    Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: cp_catalog_page_sk (type: int), cp_catalog_page_id (type: string)\n                      outputColumnNames: _col0, _col1\n                      Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: string)\n            Execution mode: vectorized\n        Map 19 \n            Map Operator Tree:\n                TableScan\n                  alias: web_sales\n                  filterExpr: ((ws_item_sk is not null and ws_promo_sk is not null) and ws_web_site_sk is not null) (type: boolean)\n                  Statistics: Num rows: 143966864 Data size: 19001610332 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((ws_item_sk is not null and ws_promo_sk is not null) and ws_web_site_sk is not null) (type: boolean)\n                    Statistics: Num rows: 143930635 Data size: 4029840544 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: ws_item_sk (type: int), ws_web_site_sk (type: int), ws_promo_sk (type: int), ws_order_number (type: int), ws_ext_sales_price (type: float), ws_net_profit (type: float), ws_sold_date_sk (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6\n                      Statistics: Num rows: 143930635 Data size: 4029840544 Basic stats: COMPLETE Column stats: COMPLETE\n                      Map Join Operator\n                        condition map:\n                             Left Outer Join0 to 1\n                        keys:\n                          0 _col0 (type: int), _col3 (type: int)\n                          1 _col0 (type: int), _col1 (type: int)\n                        outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10\n                        input vertices:\n                          1 Map 21\n                        Statistics: Num rows: 2406359 Data size: 77003488 Basic stats: COMPLETE Column stats: COMPLETE\n                        Map Join Operator\n                          condition map:\n                               Inner Join 0 to 1\n                          keys:\n                            0 _col6 (type: int)\n                            1 _col0 (type: int)\n                          outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10\n                          input vertices:\n                            1 Map 22\n                          Statistics: Num rows: 2690560 Data size: 75335680 Basic stats: COMPLETE Column stats: COMPLETE\n                          Map Join Operator\n                            condition map:\n                                 Inner Join 0 to 1\n                            keys:\n                              0 _col0 (type: int)\n                              1 _col0 (type: int)\n                            outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col10\n                            input vertices:\n                              1 Map 23\n                            Statistics: Num rows: 896854 Data size: 21524496 Basic stats: COMPLETE Column stats: COMPLETE\n                            Map Join Operator\n                              condition map:\n                                   Inner Join 0 to 1\n                              keys:\n                                0 _col2 (type: int)\n                                1 _col0 (type: int)\n                              outputColumnNames: _col1, _col4, _col5, _col9, _col10\n                              input vertices:\n                                1 Map 24\n                              Statistics: Num rows: 448427 Data size: 8968540 Basic stats: COMPLETE Column stats: COMPLETE\n                              Map Join Operator\n                                condition map:\n                                     Inner Join 0 to 1\n                                keys:\n                                  0 _col1 (type: int)\n                                  1 _col0 (type: int)\n                                outputColumnNames: _col4, _col5, _col9, _col10, _col18\n                                input vertices:\n                                  1 Map 25\n                                Statistics: Num rows: 448427 Data size: 52017532 Basic stats: COMPLETE Column stats: COMPLETE\n                                Select Operator\n                                  expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float)\n                                  outputColumnNames: _col0, _col1, _col2, _col3\n                                  Statistics: Num rows: 448427 Data size: 52017532 Basic stats: COMPLETE Column stats: COMPLETE\n                                  Group By Operator\n                                    aggregations: sum(_col1), sum(_col2), sum(_col3)\n                                    keys: _col0 (type: string)\n                                    mode: hash\n                                    outputColumnNames: _col0, _col1, _col2, _col3\n                                    Statistics: Num rows: 17 Data size: 2108 Basic stats: COMPLETE Column stats: COMPLETE\n                                    Reduce Output Operator\n                                      key expressions: _col0 (type: string)\n                                      sort order: +\n                                      Map-reduce partition columns: _col0 (type: string)\n                                      Statistics: Num rows: 17 Data size: 2108 Basic stats: COMPLETE Column stats: COMPLETE\n                                      value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double)\n            Execution mode: vectorized\n        Map 21 \n            Map Operator Tree:\n                TableScan\n                  alias: web_returns\n                  filterExpr: wr_item_sk is not null (type: boolean)\n                  Statistics: Num rows: 13749816 Data size: 1237758344 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: wr_item_sk is not null (type: boolean)\n                    Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: wr_item_sk (type: int), wr_order_number (type: int), wr_return_amt (type: float), wr_net_loss (type: float)\n                      outputColumnNames: _col0, _col1, _col2, _col3\n                      Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col1 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)\n                        Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col2 (type: float), _col3 (type: float)\n            Execution mode: vectorized\n        Map 22 \n            Map Operator Tree:\n                TableScan\n                  alias: date_dim\n                  filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                    Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: d_date_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Select Operator\n                        expressions: _col0 (type: int)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                        Group By Operator\n                          keys: _col0 (type: int)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                          Dynamic Partitioning Event Operator\n                            Target Input: web_sales\n                            Partition key expr: ws_sold_date_sk\n                            Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                            Target column: ws_sold_date_sk\n                            Target Vertex: Map 19\n            Execution mode: vectorized\n        Map 23 \n            Map Operator Tree:\n                TableScan\n                  alias: item\n                  filterExpr: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                  Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                    Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: i_item_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 24 \n            Map Operator Tree:\n                TableScan\n                  alias: promotion\n                  filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                  Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean)\n                    Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: p_promo_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Map 25 \n            Map Operator Tree:\n                TableScan\n                  alias: web_site\n                  filterExpr: web_site_sk is not null (type: boolean)\n                  Statistics: Num rows: 38 Data size: 70614 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: web_site_sk is not null (type: boolean)\n                    Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: web_site_sk (type: int), web_site_id (type: string)\n                      outputColumnNames: _col0, _col1\n                      Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col1 (type: string)\n            Execution mode: vectorized\n        Map 7 \n            Map Operator Tree:\n                TableScan\n                  alias: store_returns\n                  filterExpr: sr_item_sk is not null (type: boolean)\n                  Statistics: Num rows: 55578005 Data size: 4155315616 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: sr_item_sk is not null (type: boolean)\n                    Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: sr_item_sk (type: int), sr_ticket_number (type: int), sr_return_amt (type: float), sr_net_loss (type: float)\n                      outputColumnNames: _col0, _col1, _col2, _col3\n                      Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int), _col1 (type: int)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: int), _col1 (type: int)\n                        Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE\n                        value expressions: _col2 (type: float), _col3 (type: float)\n            Execution mode: vectorized\n        Map 8 \n            Map Operator Tree:\n                TableScan\n                  alias: date_dim\n                  filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean)\n                    Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: d_date_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                      Select Operator\n                        expressions: _col0 (type: int)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE\n                        Group By Operator\n                          keys: _col0 (type: int)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                          Dynamic Partitioning Event Operator\n                            Target Input: store_sales\n                            Partition key expr: ss_sold_date_sk\n                            Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE\n                            Target column: ss_sold_date_sk\n                            Target Vertex: Map 1\n            Execution mode: vectorized\n        Map 9 \n            Map Operator Tree:\n                TableScan\n                  alias: item\n                  filterExpr: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                  Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE\n                  Filter Operator\n                    predicate: ((i_current_price > 50.0) and i_item_sk is not null) (type: boolean)\n                    Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE\n                    Select Operator\n                      expressions: i_item_sk (type: int)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: vectorized\n        Reducer 13 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col2, _col3\n                Select Operator\n                  expressions: 'catalog channel' (type: string), concat('catalog_page', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Group By Operator\n                    aggregations: sum(_col2), sum(_col3), sum(_col4)\n                    keys: _col0 (type: string), _col1 (type: string), '0' (type: string)\n                    mode: hash\n                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      sort order: +++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double)\n        Reducer 2 \n            Reduce Operator Tree:\n              Merge Join Operator\n                condition map:\n                     Left Outer Join0 to 1\n                keys:\n                  0 _col0 (type: int), _col3 (type: int)\n                  1 _col0 (type: int), _col1 (type: int)\n                outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10\n                Statistics: Num rows: 7811006 Data size: 249952192 Basic stats: COMPLETE Column stats: COMPLETE\n                Map Join Operator\n                  condition map:\n                       Inner Join 0 to 1\n                  keys:\n                    0 _col6 (type: int)\n                    1 _col0 (type: int)\n                  outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10\n                  input vertices:\n                    1 Map 8\n                  Statistics: Num rows: 8733520 Data size: 244538560 Basic stats: COMPLETE Column stats: COMPLETE\n                  Map Join Operator\n                    condition map:\n                         Inner Join 0 to 1\n                    keys:\n                      0 _col0 (type: int)\n                      1 _col0 (type: int)\n                    outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col10\n                    input vertices:\n                      1 Map 9\n                    Statistics: Num rows: 2911174 Data size: 69868176 Basic stats: COMPLETE Column stats: COMPLETE\n                    Map Join Operator\n                      condition map:\n                           Inner Join 0 to 1\n                      keys:\n                        0 _col2 (type: int)\n                        1 _col0 (type: int)\n                      outputColumnNames: _col1, _col4, _col5, _col9, _col10\n                      input vertices:\n                        1 Map 10\n                      Statistics: Num rows: 1455587 Data size: 29111740 Basic stats: COMPLETE Column stats: COMPLETE\n                      Map Join Operator\n                        condition map:\n                             Inner Join 0 to 1\n                        keys:\n                          0 _col1 (type: int)\n                          1 _col0 (type: int)\n                        outputColumnNames: _col4, _col5, _col9, _col10, _col18\n                        input vertices:\n                          1 Map 11\n                        Statistics: Num rows: 1455587 Data size: 168848092 Basic stats: COMPLETE Column stats: COMPLETE\n                        Select Operator\n                          expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float)\n                          outputColumnNames: _col0, _col1, _col2, _col3\n                          Statistics: Num rows: 1455587 Data size: 168848092 Basic stats: COMPLETE Column stats: COMPLETE\n                          Group By Operator\n                            aggregations: sum(_col1), sum(_col2), sum(_col3)\n                            keys: _col0 (type: string)\n                            mode: hash\n                            outputColumnNames: _col0, _col1, _col2, _col3\n                            Statistics: Num rows: 234 Data size: 29016 Basic stats: COMPLETE Column stats: COMPLETE\n                            Reduce Output Operator\n                              key expressions: _col0 (type: string)\n                              sort order: +\n                              Map-reduce partition columns: _col0 (type: string)\n                              Statistics: Num rows: 234 Data size: 29016 Basic stats: COMPLETE Column stats: COMPLETE\n                              value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double)\n        Reducer 20 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col2, _col3\n                Select Operator\n                  expressions: 'web channel' (type: string), concat('web_site', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Group By Operator\n                    aggregations: sum(_col2), sum(_col3), sum(_col4)\n                    keys: _col0 (type: string), _col1 (type: string), '0' (type: string)\n                    mode: hash\n                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      sort order: +++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double)\n        Reducer 3 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col2, _col3\n                Select Operator\n                  expressions: 'store channel' (type: string), concat('store', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Group By Operator\n                    aggregations: sum(_col2), sum(_col3), sum(_col4)\n                    keys: _col0 (type: string), _col1 (type: string), '0' (type: string)\n                    mode: hash\n                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      sort order: +++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string)\n                      value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double)\n        Reducer 5 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2)\n                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col3, _col4, _col5\n                Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                pruneGroupingSetId: true\n                Select Operator\n                  expressions: _col0 (type: string), _col1 (type: string), _col3 (type: double), _col4 (type: double), _col5 (type: double)\n                  outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                  Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                  Reduce Output Operator\n                    key expressions: _col0 (type: string), _col1 (type: string)\n                    sort order: ++\n                    Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                    TopN Hash Memory Usage: 0.04\n                    value expressions: _col2 (type: double), _col3 (type: double), _col4 (type: double)\n            Execution mode: vectorized\n        Reducer 6 \n            Reduce Operator Tree:\n              Select Operator\n                expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: double), VALUE._col1 (type: double), VALUE._col2 (type: double)\n                outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                Limit\n                  Number of rows: 100\n                  Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                  File Output Operator\n                    compressed: false\n                    Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE\n                    table:\n                        input format: org.apache.hadoop.mapred.TextInputFormat\n                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n            Execution mode: vectorized\n        Union 4 \n            Vertex: Union 4\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: 100\n      Processor Tree:\n        ListSink\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12723756","id":"12723756","filename":"explain_q80_vectorized_reduce_on.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar","name":"mmokhtar","key":"mmokhtar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863"},"displayName":"Mostafa Mokhtar","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-07T22:21:44.701+0000","size":2197833,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12723756/explain_q80_vectorized_reduce_on.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12734715","id":"12734715","filename":"HIVE-10244.01.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-22T01:35:49.189+0000","size":27044,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12734715/HIVE-10244.01.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Vectorization : TPC-DS Q80 fails with java.lang.ClassCastException when hive.vectorized.execution.reduce.enabled is enabled","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar","name":"mmokhtar","key":"mmokhtar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863"},"displayName":"Mostafa Mokhtar","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar","name":"mmokhtar","key":"mmokhtar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863"},"displayName":"Mostafa Mokhtar","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14537525","id":"14537525","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"\nThis information is from TPC-DS 67, but I think it is probably the same problem:\n\nThe exception occurs in (vectorized) Reducer 3 fed from Map 2.\n\nThe type shown in the Explain plan for Map 2 shows _col8 as type string.\nAnd, Reducer 3 shows _col8 as type string.  Yet, we seem to create the Vectorized Row Batch in the Tez Reduce code as Decimal?\n\nThe COALESCE in the last column of Select Operator expressions shows type decimal(18,2).\nYet, the following Group By operator shows the last column with a funny name \"0\" and type string.\nSomething is not right here.\n\nPartial explain output from the end of Map 2:\n{noformat}\n                              Select Operator\n                                expressions: _col3 (type: string), _col2 (type: string), _col1 (type: string), _col4 (type: string), _col12 (type: int), _col14 (type: int), _col13 (type: int), _col16 (type: string), COALESCE((_col8 * CAST( _col7 AS decimal(10,0))),0) (type: decimal(18,2))\n                                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8\n                                Statistics: Num rows: 915185 Data size: 1236889305 Basic stats: COMPLETE Column stats: NONE\n                                Group By Operator\n                                  aggregations: sum(_col8)\n                                  keys: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), '0' (type: string)\n                                  mode: hash\n                                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9\n                                  Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE\n                                  Reduce Output Operator\n                                    key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)\n                                    sort order: +++++++++\n                                    Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)\n                                    Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE\n                                    value expressions: _col9 (type: decimal(28,2))\n{noformat}\n\nFull explain output:\n\n{noformat}\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Tez\n      Edges:\n        Map 2 <- Map 1 (BROADCAST_EDGE), Map 6 (BROADCAST_EDGE), Map 7 (BROADCAST_EDGE)\n        Reducer 3 <- Map 2 (SIMPLE_EDGE)\n        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)\n        Reducer 5 <- Reducer 4 (SIMPLE_EDGE)\n#### A masked pattern was here ####\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: item\n                  Statistics: Num rows: 18000 Data size: 29671008 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: i_item_sk is not null (type: boolean)\n                    Statistics: Num rows: 9000 Data size: 14835504 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: i_item_sk (type: int), i_brand (type: string), i_class (type: string), i_category (type: string), i_product_name (type: string)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                      Statistics: Num rows: 9000 Data size: 14835504 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 9000 Data size: 14835504 Basic stats: COMPLETE Column stats: NONE\n                        value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string)\n        Map 2 \n            Map Operator Tree:\n                TableScan\n                  alias: store_sales\n                  Statistics: Num rows: 2750370 Data size: 3717170032 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: (ss_sold_date_sk is not null and ss_item_sk is not null) (type: boolean)\n                    Statistics: Num rows: 687593 Data size: 929293183 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ss_sold_date_sk (type: int), ss_item_sk (type: int), ss_quantity (type: int), ss_sales_price (type: decimal(7,2)), ss_store_sk (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4\n                      Statistics: Num rows: 687593 Data size: 929293183 Basic stats: COMPLETE Column stats: NONE\n                      Map Join Operator\n                        condition map:\n                             Inner Join 0 to 1\n                        keys:\n                          0 _col0 (type: int)\n                          1 _col0 (type: int)\n                        outputColumnNames: _col1, _col2, _col3, _col4, _col7, _col8, _col9\n                        input vertices:\n                          1 Map 6\n                        Statistics: Num rows: 756352 Data size: 1022222523 Basic stats: COMPLETE Column stats: NONE\n                        HybridGraceHashJoin: true\n                        Map Join Operator\n                          condition map:\n                               Inner Join 0 to 1\n                          keys:\n                            0 _col4 (type: int)\n                            1 _col0 (type: int)\n                          outputColumnNames: _col1, _col2, _col3, _col7, _col8, _col9, _col11\n                          input vertices:\n                            1 Map 7\n                          Statistics: Num rows: 831987 Data size: 1124444799 Basic stats: COMPLETE Column stats: NONE\n                          HybridGraceHashJoin: true\n                          Select Operator\n                            expressions: _col1 (type: int), _col11 (type: string), _col2 (type: int), _col3 (type: decimal(7,2)), _col7 (type: int), _col8 (type: int), _col9 (type: int)\n                            outputColumnNames: _col1, _col11, _col2, _col3, _col7, _col8, _col9\n                            Statistics: Num rows: 831987 Data size: 1124444799 Basic stats: COMPLETE Column stats: NONE\n                            Map Join Operator\n                              condition map:\n                                   Inner Join 0 to 1\n                              keys:\n                                0 _col0 (type: int)\n                                1 _col1 (type: int)\n                              outputColumnNames: _col1, _col2, _col3, _col4, _col7, _col8, _col12, _col13, _col14, _col16\n                              input vertices:\n                                0 Map 1\n                              Statistics: Num rows: 915185 Data size: 1236889305 Basic stats: COMPLETE Column stats: NONE\n                              HybridGraceHashJoin: true\n                              Select Operator\n                                expressions: _col3 (type: string), _col2 (type: string), _col1 (type: string), _col4 (type: string), _col12 (type: int), _col14 (type: int), _col13 (type: int), _col16 (type: string), COALESCE((_col8 * CAST( _col7 AS decimal(10,0))),0) (type: decimal(18,2))\n                                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8\n                                Statistics: Num rows: 915185 Data size: 1236889305 Basic stats: COMPLETE Column stats: NONE\n                                Group By Operator\n                                  aggregations: sum(_col8)\n                                  keys: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), '0' (type: string)\n                                  mode: hash\n                                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9\n                                  Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE\n                                  Reduce Output Operator\n                                    key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)\n                                    sort order: +++++++++\n                                    Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)\n                                    Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE\n                                    value expressions: _col9 (type: decimal(28,2))\n        Map 6 \n            Map Operator Tree:\n                TableScan\n                  alias: date_dim\n                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: (d_month_seq BETWEEN 1176 AND 1187 and d_date_sk is not null) (type: boolean)\n                    Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: d_date_sk (type: int), d_year (type: int), d_moy (type: int), d_qoy (type: int)\n                      outputColumnNames: _col0, _col2, _col3, _col4\n                      Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE\n                        value expressions: _col2 (type: int), _col3 (type: int), _col4 (type: int)\n        Map 7 \n            Map Operator Tree:\n                TableScan\n                  alias: store\n                  Statistics: Num rows: 12 Data size: 25632 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: s_store_sk is not null (type: boolean)\n                    Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: s_store_sk (type: int), s_store_id (type: string)\n                      outputColumnNames: _col0, _col1\n                      Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: int)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: int)\n                        Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE\n                        value expressions: _col1 (type: string)\n                      Select Operator\n                        expressions: _col0 (type: int)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: int)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE\n                          Dynamic Partitioning Event Operator\n                            Target Input: store_sales\n                            Partition key expr: ss_store_sk\n                            Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE\n                            Target column: ss_store_sk\n                            Target Vertex: Map 2\n        Reducer 3 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: sum(VALUE._col0)\n                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: string), KEY._col3 (type: string), KEY._col4 (type: int), KEY._col5 (type: int), KEY._col6 (type: int), KEY._col7 (type: string), KEY._col8 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col9\n                Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE\n                pruneGroupingSetId: true\n                Reduce Output Operator\n                  key expressions: _col0 (type: string), _col9 (type: decimal(28,2))\n                  sort order: +-\n                  Map-reduce partition columns: _col0 (type: string)\n                  Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE\n                  value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col9 (type: decimal(28,2))\n        Reducer 4 \n            Reduce Operator Tree:\n              Select Operator\n                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: int), VALUE._col4 (type: int), VALUE._col5 (type: int), VALUE._col6 (type: string), VALUE._col8 (type: decimal(28,2))\n                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col9\n                Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE\n                PTF Operator\n                  Function definitions:\n                      Input definition\n                        input alias: ptf_0\n                        output shape: _col0: string, _col1: string, _col2: string, _col3: string, _col4: int, _col5: int, _col6: int, _col7: string, _col9: decimal(28,2)\n                        type: WINDOWING\n                      Windowing table definition\n                        input alias: ptf_1\n                        name: windowingtablefunction\n                        order by: _col9(DESC)\n                        partition by: _col0\n                        raw input shape:\n                        window functions:\n                            window function definition\n                              alias: rank_window_0\n                              arguments: _col9\n                              name: rank\n                              window function: GenericUDAFRankEvaluator\n                              window frame: PRECEDING(MAX)~FOLLOWING(MAX)\n                              isPivotResult: true\n                  Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: (rank_window_0 <= 100) (type: boolean)\n                    Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col9 (type: decimal(28,2)), rank_window_0 (type: int)\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9\n                      Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: decimal(28,2)), _col9 (type: int)\n                        sort order: ++++++++++\n                        Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE\n        Reducer 5 \n            Reduce Operator Tree:\n              Select Operator\n                expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string), KEY.reducesinkkey4 (type: int), KEY.reducesinkkey5 (type: int), KEY.reducesinkkey6 (type: int), KEY.reducesinkkey7 (type: string), KEY.reducesinkkey8 (type: decimal(28,2)), KEY.reducesinkkey9 (type: int)\n                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9\n                Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE\n                Limit\n                  Number of rows: 100\n                  Statistics: Num rows: 100 Data size: 135100 Basic stats: COMPLETE Column stats: NONE\n                  File Output Operator\n                    compressed: false\n                    Statistics: Num rows: 100 Data size: 135100 Basic stats: COMPLETE Column stats: NONE\n                    table:\n                        input format: org.apache.hadoop.mapred.TextInputFormat\n                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: 100\n      Processor Tree:\n        ListSink\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-11T03:47:10.479+0000","updated":"2015-05-11T03:47:10.479+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14537537","id":"14537537","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar","name":"mmokhtar","key":"mmokhtar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863"},"displayName":"Mostafa Mokhtar","active":true,"timeZone":"America/Los_Angeles"},"body":"[~jpullokkaran]\nCan you please take a look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar","name":"mmokhtar","key":"mmokhtar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863"},"displayName":"Mostafa Mokhtar","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-11T04:03:38.734+0000","updated":"2015-05-11T04:03:38.734+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14538297","id":"14538297","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"[~jcamachorodriguez] Could you take a look?\nMay be we screwed the types going in/out.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-11T18:00:48.811+0000","updated":"2015-05-11T18:00:48.811+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14541724","id":"14541724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jcamachorodriguez","name":"jcamachorodriguez","key":"jcamachorodriguez","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jesus Camacho Rodriguez","active":true,"timeZone":"America/Los_Angeles"},"body":"I cannot reproduce this one in my environment with {{hive.vectorized.execution.enabled}} and {{hive.vectorized.execution.reduce.enabled}}, is it still an issue?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jcamachorodriguez","name":"jcamachorodriguez","key":"jcamachorodriguez","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jesus Camacho Rodriguez","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-13T11:02:36.543+0000","updated":"2015-05-13T11:02:36.543+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14546223","id":"14546223","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"I struggled with the environment variables necessary for a repro.\n\nThe default for is hive.vectorized.execution.mapjoin.native.enabled is true, but for the repro it needs to be set to false.\n\n(Here is the whole list of variables I used in my Q file:)\n{noformat}\nSET hive.vectorized.execution.enabled=true;\nset hive.mapjoin.hybridgrace.hashtable=true;\nSET hive.vectorized.execution.mapjoin.native.enabled=false;\nset hive.cbo.enable=true;\nset hive.fetch.task.conversion=none;\nSET hive.auto.convert.join=true;\nSET hive.auto.convert.join.noconditionaltask=true;\nSET hive.auto.convert.join.noconditionaltask.size=100000000;\nset hive.exec.dynamic.partition.mode=nonstrict;\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-15T21:47:01.972+0000","updated":"2015-05-15T21:47:01.972+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14551376","id":"14551376","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jcamachorodriguez","name":"jcamachorodriguez","key":"jcamachorodriguez","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jesus Camacho Rodriguez","active":true,"timeZone":"America/Los_Angeles"},"body":"[~mmccline], the problem is not in CBO; in fact, with CBO disabled, the problem appears too. There seems to be a problem in the vectorization code when grouping sets are used (wrong indices? not taking into account grouping__id?). The following simplified query can be used to reproduce the error:\n\n{code}\n select s_store_id\n from store\n group by s_store_id with rollup;\n{code}\n\nwhile this query does not show the error \n\n{code}\n select s_store_id, GROUPING__ID\n from store\n group by s_store_id with rollup;\n{code}\n\nWhat do you think?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jcamachorodriguez","name":"jcamachorodriguez","key":"jcamachorodriguez","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jesus Camacho Rodriguez","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T22:36:23.373+0000","updated":"2015-05-19T22:36:23.373+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14555386","id":"14555386","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"I think this is directly related to HIVE-9347.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-22T00:49:51.609+0000","updated":"2015-05-22T00:49:51.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14555389","id":"14555389","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"For 1.2.1, I would prefer to not vectorize if there is GroupByDesc.pruneGroupingSetId is true....","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-22T00:51:30.317+0000","updated":"2015-05-22T00:51:30.317+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14556342","id":"14556342","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12734715/HIVE-10244.01.patch\n\n{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 8969 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_static\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4002/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4002/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4002/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 1 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12734715 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-05-22T15:43:27.303+0000","updated":"2015-05-22T15:43:27.303+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14556572","id":"14556572","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"Test failure is unrelated to changes (has build age 6).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-22T18:31:48.685+0000","updated":"2015-05-22T18:31:48.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14559797","id":"14559797","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"[~mmccline] How can you end up grouping id without grouping sets?\nLanguage prevents referring to grouping id without grouping sets.\n\nIf grouping sets are present then previous line should bail out right?\n\nif (desc.isGroupingSetsPresent()) {\n      LOG.info(\"Grouping sets not supported in vector mode\");\n      return false;\n    }","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-26T20:23:58.601+0000","updated":"2015-05-26T20:23:58.601+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14559918","id":"14559918","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"Ya, I know, that is what I thought.  But the new prune flag seems to be on in the Reducer even though isGroupingSetsPresent is false.  We should talk to the author and reviewer of the change.\n\nJedi Master [~ashutoshc], can you explain to us Padawan Learners [~jpullokkaran] [~mmccline] [~jcamachorodriguez] all about the prune flag?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-26T21:35:22.168+0000","updated":"2015-05-26T21:35:22.168+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563741","id":"14563741","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"Ok i looked further.\nLogical GB gets translated to different GB-RS-GB pipelines based on config (skew, no of grip sets..).\nGrpID Col is always added only for the last operator; rest of the physical GB will not include it.\n\nSo on an individual GB its legal to have groupingset set to false & prunegroupingid set to true.\nEx: MapSide GB + SkewInData where grouping__id is not in the projection list.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T21:45:40.707+0000","updated":"2015-05-28T21:45:40.707+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563743","id":"14563743","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"Example Query:\nset hive.groupby.skewindata=true;\nselect key from t1 group by key,value grouping sets((key), (value));","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T21:47:46.573+0000","updated":"2015-05-28T21:47:46.573+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563744","id":"14563744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"Example Query:\nset hive.groupby.skewindata=true;\nselect key from t1 group by key,value grouping sets((key), (value));","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T21:47:50.722+0000","updated":"2015-05-28T21:47:50.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563745","id":"14563745","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"Example Query:\nset hive.groupby.skewindata=true;\nselect key from t1 group by key,value grouping sets((key), (value));","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T21:47:56.521+0000","updated":"2015-05-28T21:47:56.521+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563746","id":"14563746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"Example Query:\nset hive.groupby.skewindata=true;\nselect key from t1 group by key,value grouping sets((key), (value));","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T21:48:05.365+0000","updated":"2015-05-28T21:48:05.365+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563747","id":"14563747","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"Example Query:\nset hive.groupby.skewindata=true;\nselect key from t1 group by key,value grouping sets((key), (value));","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T21:48:10.878+0000","updated":"2015-05-28T21:48:10.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563752","id":"14563752","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jpullokkaran","name":"jpullokkaran","key":"jpullokkaran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laljo John Pullokkaran","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T21:49:25.467+0000","updated":"2015-05-28T21:49:25.467+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563756","id":"14563756","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"[~jpullokkaran] thank you for digging into the GroupBy logical/physical pipeline and figuring it out!  And, your review +1.  And, and thank you and [~ashutoshc] for discussing it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2015-05-28T21:54:24.401+0000","updated":"2015-05-28T21:54:24.401+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819081/comment/14563873","id":"14563873","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to master and branch-1.2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-28T23:20:34.376+0000","updated":"2015-05-28T23:20:34.376+0000"}],"maxResults":21,"total":21,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10244/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2cxnj:"}}