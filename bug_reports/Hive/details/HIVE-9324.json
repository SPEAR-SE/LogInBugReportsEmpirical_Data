{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12765949","self":"https://issues.apache.org/jira/rest/api/2/issue/12765949","key":"HIVE-9324","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jan 09 08:52:17 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-9324/watchers","watchCount":5,"isWatching":false},"created":"2015-01-09T05:39:55.829+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326829","id":"12326829","description":"0.13 maintenance release 1","name":"0.13.1","archived":false,"released":true,"releaseDate":"2014-06-06"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-01-09T08:52:17.820+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312586","id":"12312586","name":"Query Processor","description":"Tracks issues dealing with query processing."}],"timeoriginalestimate":null,"description":"We are seeing some reduce side join mapreduce jobs failing with following exception :\n\n{noformat}\n2014-12-14 16:58:51,296 ERROR org.apache.hadoop.hive.ql.exec.persistence.RowContainer: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\njava.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2435)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:76)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:360)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:230)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:74)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:644)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:758)\n\tat org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:256)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:216)\n\tat org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:506)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:447)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:268)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:416)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:262)\n2014-12-14 16:58:51,334 FATAL ExecReducer: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:237)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:74)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:644)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:758)\n\tat org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:256)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:216)\n\tat org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:506)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:447)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:268)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:416)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:262)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:385)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:230)\n\t... 12 more\nCaused by: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2435)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:76)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:360)\n\t... 13 more\n\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Reduce side joins failing with IOException from RowContainer.nextBlock","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12765949/comment/14270588","id":"14270588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"More task log :\n\n{noformat}\n2014-12-14 16:58:03,905 INFO org.apache.hadoop.hive.ql.exec.mr.ObjectCache: Ignoring retrieval request: __REDUCE_PLAN__\n2014-12-14 16:58:03,945 INFO org.apache.hadoop.hive.ql.log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>\n2014-12-14 16:58:03,945 INFO org.apache.hadoop.hive.ql.exec.Utilities: Deserializing ReduceWork via kryo\n2014-12-14 16:58:04,987 INFO org.apache.hadoop.hive.ql.log.PerfLogger: </PERFLOG method=deserializePlan start=1418576283945 end=1418576284987 duration=1042 from=org.apache.hadoop.hive.ql.exec.Utilities>\n2014-12-14 16:58:04,988 INFO org.apache.hadoop.hive.ql.exec.mr.ObjectCache: Ignoring cache key: __REDUCE_PLAN__\n2014-12-14 16:58:05,327 INFO ExecReducer: \n<JOIN>Id =0\n  <Children>\n    <FS>Id =1\n      <Children>\n      <\\Children>\n      <Parent>Id = 0 null<\\Parent>\n    <\\FS>\n  <\\Children>\n  <Parent><\\Parent>\n<\\JOIN>\n2014-12-14 16:58:05,327 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: Initializing Self 0 JOIN\n2014-12-14 16:58:05,377 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: JOIN struct<_col23:string,_col65:double,_col99:double,_col237:double,_col240:double,_col250:string,_col367:int> totalsz = 7\n2014-12-14 16:58:05,377 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: Operator 0 JOIN initialized\n2014-12-14 16:58:05,377 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: Initializing children of 0 JOIN\n2014-12-14 16:58:05,377 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initializing child 1 FS\n2014-12-14 16:58:05,377 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initializing Self 1 FS\n2014-12-14 16:58:05,394 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Operator 1 FS initialized\n2014-12-14 16:58:05,394 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initialization Done 1 FS\n2014-12-14 16:58:05,395 INFO org.apache.hadoop.hive.ql.exec.JoinOperator: Initialization Done 0 JOIN\n2014-12-14 16:58:05,401 INFO ExecReducer: ExecReducer: processing 1 rows: used memory = 242598168\n2014-12-14 16:58:05,406 INFO ExecReducer: ExecReducer: processing 10 rows: used memory = 242759392\n2014-12-14 16:58:05,437 INFO ExecReducer: ExecReducer: processing 100 rows: used memory = 242759392\n2014-12-14 16:58:05,657 INFO ExecReducer: ExecReducer: processing 1000 rows: used memory = 243653240\n2014-12-14 16:58:06,976 INFO ExecReducer: ExecReducer: processing 10000 rows: used memory = 247197944\n2014-12-14 16:58:07,646 INFO ExecReducer: ExecReducer: processing 100000 rows: used memory = 277801256\n2014-12-14 16:58:11,511 INFO ExecReducer: ExecReducer: processing 1000000 rows: used memory = 283150744\n2014-12-14 16:58:14,993 INFO ExecReducer: ExecReducer: processing 2000000 rows: used memory = 293036992\n2014-12-14 16:58:18,497 INFO ExecReducer: ExecReducer: processing 3000000 rows: used memory = 311449488\n2014-12-14 16:58:20,815 INFO ExecReducer: ExecReducer: processing 4000000 rows: used memory = 285251752\n2014-12-14 16:58:26,460 INFO ExecReducer: ExecReducer: processing 5000000 rows: used memory = 328223864\n2014-12-14 16:58:29,412 INFO ExecReducer: ExecReducer: processing 6000000 rows: used memory = 263175576\n2014-12-14 16:58:31,331 INFO ExecReducer: ExecReducer: processing 7000000 rows: used memory = 282021320\n2014-12-14 16:58:35,099 INFO ExecReducer: ExecReducer: processing 8000000 rows: used memory = 299301184\n2014-12-14 16:58:37,981 INFO ExecReducer: ExecReducer: processing 9000000 rows: used memory = 306925648\n2014-12-14 16:58:40,506 INFO ExecReducer: ExecReducer: processing 10000000 rows: used memory = 307407920\n2014-12-14 16:58:42,242 INFO ExecReducer: ExecReducer: processing 11000000 rows: used memory = 304664048\n2014-12-14 16:58:46,142 INFO ExecReducer: ExecReducer: processing 12000000 rows: used memory = 298347024\n2014-12-14 16:58:48,549 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [003b9de7876541c2bcce9029ff0d3873]\n2014-12-14 16:58:48,622 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [003b9de7876541c2bcce9029ff0d3873]\n2014-12-14 16:58:48,677 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 4000 rows for join key [003b9de7876541c2bcce9029ff0d3873]\n2014-12-14 16:58:48,679 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Final Path: FS hdfs://test-machine:8020/tmp/hive-dataqa/hive_2014-12-14_16-49-14_996_1630664550753106415-32/_tmp.-mr-10002/000000_0\n2014-12-14 16:58:48,680 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Writing to temp file: FS hdfs://test-machine:8020/tmp/hive-dataqa/hive_2014-12-14_16-49-14_996_1630664550753106415-32/_task_tmp.-mr-10002/_tmp.000000_0\n2014-12-14 16:58:48,680 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: New Final Path: FS hdfs://test-machine:8020/tmp/hive-dataqa/hive_2014-12-14_16-49-14_996_1630664550753106415-32/_tmp.-mr-10002/000000_0\n2014-12-14 16:58:49,620 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [00729c21c3bf4f4e9e1482da36444110]\n2014-12-14 16:58:49,626 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [00729c21c3bf4f4e9e1482da36444110]\n2014-12-14 16:58:49,827 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [009fdcb880ea42669189cdf23770d694]\n2014-12-14 16:58:49,848 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [009fdcb880ea42669189cdf23770d694]\n2014-12-14 16:58:49,896 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 4000 rows for join key [009fdcb880ea42669189cdf23770d694]\n2014-12-14 16:58:49,979 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 8000 rows for join key [009fdcb880ea42669189cdf23770d694]\n2014-12-14 16:58:50,339 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [0396225019a047b09469171877207c53]\n2014-12-14 16:58:50,341 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [0396225019a047b09469171877207c53]\n2014-12-14 16:58:50,396 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [040b5ed4eea348cfbd83b1c92648654b]\n2014-12-14 16:58:50,431 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [04eb04e3947244099d88df950db9d1da]\n2014-12-14 16:58:50,450 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [04eb04e3947244099d88df950db9d1da]\n2014-12-14 16:58:50,483 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [07a822d85c214d7fbecef2deb10e8a0c]\n2014-12-14 16:58:50,485 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [07a822d85c214d7fbecef2deb10e8a0c]\n2014-12-14 16:58:50,489 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 4000 rows for join key [07a822d85c214d7fbecef2deb10e8a0c]\n2014-12-14 16:58:50,496 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 8000 rows for join key [07a822d85c214d7fbecef2deb10e8a0c]\n2014-12-14 16:58:50,611 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [08829d0f49874ddda9f5fb3cf72a8983]\n2014-12-14 16:58:50,613 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [08829d0f49874ddda9f5fb3cf72a8983]\n2014-12-14 16:58:50,684 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [0b26c249f77a470eb5158a0aa0bcfde3]\n2014-12-14 16:58:50,686 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [0b26c249f77a470eb5158a0aa0bcfde3]\n2014-12-14 16:58:50,690 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 4000 rows for join key [0b26c249f77a470eb5158a0aa0bcfde3]\n2014-12-14 16:58:50,733 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [0ce237b24173426595c90107f0922265]\n2014-12-14 16:58:50,735 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [0ce237b24173426595c90107f0922265]\n2014-12-14 16:58:50,784 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [129a3aff8c9941e79181954c88dfd42a]\n2014-12-14 16:58:50,797 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [1346b3be4d764b35ba94aebd07f9151d]\n2014-12-14 16:58:50,812 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 1000 rows for join key [149564f947b543af84f1e439c572c6d8]\n2014-12-14 16:58:50,816 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 2000 rows for join key [149564f947b543af84f1e439c572c6d8]\n2014-12-14 16:58:50,821 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 4000 rows for join key [149564f947b543af84f1e439c572c6d8]\n2014-12-14 16:58:50,830 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 8000 rows for join key [149564f947b543af84f1e439c572c6d8]\n2014-12-14 16:58:50,847 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: table 0 has 16000 rows for join key [149564f947b543af84f1e439c572c6d8]\n2014-12-14 16:58:50,866 INFO org.apache.hadoop.hive.ql.exec.persistence.RowContainer: RowContainer created temp file /data0/hadoop/mapred/local/taskTracker/test/jobcache/job_201411270515_0443/attempt_201411270515_0443_r_000000_0/work/tmp/hive-rowcontainer6700226405284000754/RowContainer6659702872024238761.tmp\n2014-12-14 16:58:51,025 INFO org.apache.hadoop.mapred.FileInputFormat: Total input paths to process : 42\n2014-12-14 16:58:51,276 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.gz]\n2014-12-14 16:58:51,296 ERROR org.apache.hadoop.hive.ql.exec.persistence.RowContainer: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\njava.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2435)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:76)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:360)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:230)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:74)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:644)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:758)\n\tat org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:256)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:216)\n\tat org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:506)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:447)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:268)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:416)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:262)\n2014-12-14 16:58:51,334 FATAL ExecReducer: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:237)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:74)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:644)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:758)\n\tat org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:256)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:216)\n\tat org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:506)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:447)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:268)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:416)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:262)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:385)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:230)\n\t... 12 more\nCaused by: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2435)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:76)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:360)\n\t... 13 more\n\n2014-12-14 16:58:51,337 INFO org.apache.hadoop.mapred.TaskLogsTruncater: Initializing logs' truncater with mapRetainSize=-1 and reduceRetainSize=-1\n2014-12-14 16:58:51,340 WARN org.apache.hadoop.mapred.Child: Error running child\njava.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:283)\n\tat org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:506)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:447)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:268)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:416)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:262)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:237)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:74)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:644)\n\tat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:758)\n\tat org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:256)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:216)\n\t... 7 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:385)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.first(RowContainer.java:230)\n\t... 12 more\nCaused by: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2435)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:76)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:360)\n\t... 13 more\n2014-12-14 16:58:51,343 INFO org.apache.hadoop.mapred.Task: Runnning cleanup for the task\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-01-09T05:49:07.829+0000","updated":"2015-01-09T05:54:44.489+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12765949/comment/14270779","id":"14270779","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"After doing some code walkthrough, here is what i found,\n\nOn JoinOperator, whenever any key as more values than BLOCKSIZE(hardcoded to 25000), it spills the values to a file on disk, and spill uses SequenceFile format. \n\nHere is the table description for spill (from org.apache.hadoop.hive.ql.exec.JoinUtil.java)\n{noformat}\n      TableDesc tblDesc = new TableDesc(\n          SequenceFileInputFormat.class, HiveSequenceFileOutputFormat.class,\n          Utilities.makeProperties(\n          org.apache.hadoop.hive.serde.serdeConstants.SERIALIZATION_FORMAT, \"\"\n          + Utilities.ctrlaCode,\n          org.apache.hadoop.hive.serde.serdeConstants.LIST_COLUMNS, colNames\n          .toString(),\n          org.apache.hadoop.hive.serde.serdeConstants.LIST_COLUMN_TYPES,\n          colTypes.toString(),\n          serdeConstants.SERIALIZATION_LIB,LazyBinarySerDe.class.getName()));\n      spillTableDesc[tag] = tblDesc;\n{noformat}\nFrom the exception:\n{noformat}\nCaused by: java.io.IOException: org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer@42610e8 read 1 bytes, should read 27264\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2435)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:76)\n\tat org.apache.hadoop.hive.ql.exec.persistence.RowContainer.nextBlock(RowContainer.java:360)\n\t... 13 more\n{noformat}\n\nI see that the value in SequenceFile is RCFile$KeyBuffer, dont know why. Also couldnt figure out the reason why the reading went wrong.\n\nFollowing is the code snippet from SequenceFile.java for the exception we are hitting :\n{noformat}\n2417     public synchronized Object next(Object key) throws IOException {\n2418       if (key != null && key.getClass() != getKeyClass()) {\n2419         throw new IOException(\"wrong key class: \"+key.getClass().getName()\n2420                               +\" is not \"+keyClass);\n2421       }\n2422 \n2423       if (!blockCompressed) {\n2424         outBuf.reset();\n2425 \n2426         keyLength = next(outBuf);\n2427         if (keyLength < 0)\n2428           return null;\n2429 \n2430         valBuffer.reset(outBuf.getData(), outBuf.getLength());\n2431 \n2432         key = deserializeKey(key);\n2433         valBuffer.mark(0);\n2434         if (valBuffer.getPosition() != keyLength)\n2435           throw new IOException(key + \" read \" + valBuffer.getPosition()\n2436                                 + \" bytes, should read \" + keyLength);\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-01-09T08:52:17.820+0000","updated":"2015-01-09T08:52:17.820+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-9324/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i243zz:"}}