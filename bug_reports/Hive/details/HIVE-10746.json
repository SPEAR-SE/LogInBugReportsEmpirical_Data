{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12830899","self":"https://issues.apache.org/jira/rest/api/2/issue/12830899","key":"HIVE-10746","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-05-19T16:00:04.213+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jun 18 21:54:09 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_73335668_*|*_1_*:*_1_*:*_2584277612_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-06-18T20:39:08.651+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10746/watchers","watchCount":6,"isWatching":false},"created":"2015-05-19T02:25:35.484+0000","customfield_12310192":"Use sane split min-sizes when using legacy mapred.InputFormat::getSplits(job, num)","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326450","id":"12326450","description":"released","name":"0.14.0","archived":false,"released":true,"releaseDate":"2014-11-12"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12328976","id":"12328976","description":"Maintenance release for 0.14","name":"0.14.1","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12329345","id":"12329345","description":"Hive 1.2.0","name":"1.2.0","archived":false,"released":true,"releaseDate":"2015-05-18"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12329363","id":"12329363","name":"1.1.0","archived":false,"released":true,"releaseDate":"2015-03-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12329557","id":"12329557","name":"1.1.1","archived":false,"released":true,"releaseDate":"2015-05-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-02-16T23:50:17.062+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12325007","id":"12325007","name":"Hive"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12320810","id":"12320810","name":"Tez","description":"Hive utilizing Tez framework"}],"timeoriginalestimate":null,"description":"The following query: \n{code:sql}\nSELECT appl_user_id, arsn_cd, COUNT(*) as RecordCount FROM adw.crc_arsn GROUP BY appl_user_id,arsn_cd ORDER BY appl_user_id;\n{code}\n runs consistently fast in Spark and Mapreduce on Hive 1.2.0. When attempting to run this same query against Tez as the execution engine it consistently runs for over 300-500 seconds this seems extremely long. This is a basic external table delimited by tabs and is a single file in a folder. In Hive 0.13 this query with Tez runs fast and I tested with Hive 0.14, 0.14.1/1.0.0 and now Hive 1.2.0 and there clearly is something going awry with Hive w/Tez as an execution engine with Single or small file tables. I can attach further logs if someone needs them for deeper analysis.\n\nHDFS Output:\n{noformat}\nhadoop fs -ls /example_dw/crc/arsn\nFound 2 items\n-rwxr-x---   6 loaduser hadoopusers          0 2015-05-17 20:03 /example_dw/crc/arsn/_SUCCESS\n-rwxr-x---   6 loaduser hadoopusers    3883880 2015-05-17 20:03 /example_dw/crc/arsn/part-m-00000\n{noformat}\n\nHive Table Describe:\n{noformat}\nhive> describe formatted crc_arsn;\nOK\n# col_name              data_type               comment             \n                 \narsn_cd                 string                                      \nclmlvl_cd               string                                      \narclss_cd               string                                      \narclssg_cd              string                                      \narsn_prcsr_rmk_ind      string                                      \narsn_mbr_rspns_ind      string                                      \nsavtyp_cd               string                                      \narsn_eff_dt             string                                      \narsn_exp_dt             string                                      \narsn_pstd_dts           string                                      \narsn_lstupd_dts         string                                      \narsn_updrsn_txt         string                                      \nappl_user_id            string                                      \narsntyp_cd              string                                      \npre_d_indicator         string                                      \narsn_display_txt        string                                      \narstat_cd               string                                      \narsn_tracking_no        string                                      \narsn_cstspcfc_ind       string                                      \narsn_mstr_rcrd_ind      string                                      \nstate_specific_ind      string                                      \nregion_specific_in      string                                      \narsn_dpndnt_cd          string                                      \nunit_adjustment_in      string                                      \narsn_mbr_only_ind       string                                      \narsn_qrmb_ind           string                                      \n                 \n# Detailed Table Information             \nDatabase:               adw                      \nOwner:                  LOADUSER@EXA.EXAMPLE.COM   \nCreateTime:             Mon Apr 28 13:28:05 EDT 2014     \nLastAccessTime:         UNKNOWN                  \nProtect Mode:           None                     \nRetention:              0                        \nLocation:               hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn        \nTable Type:             EXTERNAL_TABLE           \nTable Parameters:                \n        EXTERNAL                TRUE                \n        transient_lastDdlTime   1398706085          \n                 \n# Storage Information            \nSerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       \nInputFormat:            org.apache.hadoop.mapred.TextInputFormat         \nOutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       \nCompressed:             No                       \nNum Buckets:            -1                       \nBucket Columns:         []                       \nSort Columns:           []                       \nStorage Desc Params:             \n        field.delim             \\t                  \n        line.delim              \\n                  \n        serialization.format    \\t                  \nTime taken: 1.245 seconds, Fetched: 54 row(s)\n{noformat}\n\n\nExplain Hive 1.2.0 w/Tez:\n{noformat}\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Tez\n      Edges:\n        Reducer 2 <- Map 1 (SIMPLE_EDGE)\n        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)\n\n\nExplain Hive 0.13 w/Tez:\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-0 is a root stage\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Tez\n      Edges:\n        Reducer 2 <- Map 1 (SIMPLE_EDGE)\n        Reducer 3 <- Reducer 2 (SIMPLE_EDGE) \n{noformat}\n\nResults:\n{noformat}\n\tHive 1.2.0 w/Spark 1.3.1:\n \t\tFinished successfully in 7.09 seconds\n\n\tHive 1.2.0 w/Mapreduce:\n\t\tStage 1: 32 Seconds\n\t\tStage 2: 35 Seconds\n\n\tHive 1.2.0 w/Tez 0.5.3:\n\t\tTime taken: 565.025 seconds, Fetched: 11516 row(s)\n\t\n\tHive 0.13 w/Tez 0.4.0:\n\t\tTime taken: 13.552 seconds, Fetched: 11516 row(s)\n{noformat}\n\nAnd finally looking at the Dag Attempt that is stuck for 500 seconds or so in Tez it looks to be stuck running the same method over and over again:\n\n{noformat}\n8 duration=2561 from=org.apache.hadoop.hive.ql.exec.tez.RecordProcessor>\n2015-05-18 19:58:41,719 INFO [TezChild] exec.Utilities: PLAN PATH = hdfs://xhadnnm1p.example.com:8020/tmp/hive/gss2002/dbc4b0b5-7859-4487-a56d-969440bc5e90/hive_2015-05-18_19-58-25_951_5497535752804149087-1/gss2002/_tez_scratch_dir/4e635121-c4cd-4e3f-b96b-9f08a6a7bf5d/map.xml\n2015-05-18 19:58:41,822 INFO [TezChild] exec.MapOperator: MAP[4]: records read - 1\n2015-05-18 19:58:41,835 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000\n2015-05-18 19:58:41,848 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000\n\n......\n\n\n2015-05-18 20:07:46,560 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000\n2015-05-18 20:07:46,574 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000\n2015-05-18 20:07:46,587 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000\n2015-05-18 20:07:46,603 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000\n2015-05-18 20:07:46,603 INFO [TezChild] log.PerfLogger: </PERFLOG method=TezRunProcessor start=1431993518764 end=1431994066603 duration=547839 from=org.apache.hadoop.hive.ql.exec.tez.TezProcessor>\n2015-05-18 20:07:46,603 INFO [TezChild] exec.MapOperator: 4 finished. closing... \n2015-05-18 20:07:46,603 INFO [TezChild] exec.MapOperator: RECORDS_IN_Map_1:13440\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12740251","id":"12740251","filename":"HIVE-10746.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-06-18T00:15:49.819+0000","size":2926,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12740251/HIVE-10746.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12740431","id":"12740431","filename":"HIVE-10746.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-06-18T17:00:37.158+0000","size":2931,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12740431/HIVE-10746.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12733910","id":"12733910","filename":"slow_query_output.zip","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-19T18:39:11.169+0000","size":457404,"mimeType":"application/zip","content":"https://issues.apache.org/jira/secure/attachment/12733910/slow_query_output.zip"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":" Hive 1.2.0+Tez produces 1-byte FileSplits from mapred.TextInputFormat","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14550669","id":"14550669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar","name":"mmokhtar","key":"mmokhtar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863"},"displayName":"Mostafa Mokhtar","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you please run \"set hive.tez.exec.print.summary=true;\" in the session and attach the output?\nAnother thing to check is the value of \"hive.exec.reducers.bytes.per.reducer\" this controls the parallelism in the reducer phase.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmokhtar","name":"mmokhtar","key":"mmokhtar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmokhtar&avatarId=21863","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmokhtar&avatarId=21863","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmokhtar&avatarId=21863","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmokhtar&avatarId=21863"},"displayName":"Mostafa Mokhtar","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T16:00:04.213+0000","updated":"2015-05-19T16:00:04.213+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14550862","id":"14550862","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"[~gss2002]: the only difference in codepath should be the split-generation - everything else is identical between all 3.\n\nBoth the MR and Spark impls ignore the actual FileInputFormat implementation and do not call FileInputFormat::getSplits().\n\nTez seems to be actually calling the FileInputFormat::getSplits() for TextInputFormat.\n\nCan you run the same query with compressed input data?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-05-19T17:48:01.137+0000","updated":"2015-05-19T17:48:01.137+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14550979","id":"14550979","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"Mostafa Mokhtar: This isn't happening in the reducer phase. It's occurring in the Map phase attempt. I've attached the Map Phase attempt output from the TezChild task.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-19T18:40:13.984+0000","updated":"2015-05-19T18:40:13.984+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14550985","id":"14550985","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"hive.exec.reducers.bytes.per.reducer=67108864; default?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-19T18:42:11.759+0000","updated":"2015-05-19T18:42:11.759+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14552508","id":"14552508","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"Seems to be that single file with a group by/order by is generating 40040 splits... I think the map file is needed at this point to determine why this is happening correct?\n\n2015-05-19 16:20:32,462 INFO [AsyncDispatcher event handler] impl.VertexImpl: Num tasks is -1. Expecting VertexManager/InputInitializers/1-1 split to set #tasks for the vertex vertex_1426958683478_171530_1_00\n2015-05-19 16:20:32,707 DEBUG [InputInitializer [Map 1] #0] security.UserGroupInformation: PrivilegedAction as:gss2002 (auth:SIMPLE) from:org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:239)\n2015-05-19 16:20:32,708 INFO [InputInitializer [Map 1] #0] dag.RootInputInitializerManager: Starting InputInitializer for Input: crc_arsn on vertex vertex_1426958683478_171530_1_00 [Map 1]\n2015-05-19 16:20:32,722 INFO [InputInitializer [Map 1] #0] log.PerfLogger: <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.HiveInputFormat>\n2015-05-19 16:20:32,723 INFO [InputInitializer [Map 1] #0] exec.Utilities: PLAN PATH = hdfs://xhadnnm1p.example.com:8020/tmp/hive/gss2002/431ae2bc-ebc9-48e7-bbb3-f03144198009/hive_2015-05-19_16-20-28_783_5570914503219655045-1/gss2002/_tez_scratch_dir/9da6870e-7388-40b1-bab6-9d0f242b1702/map.xml\n2015-05-19 16:20:32,723 DEBUG [InputInitializer [Map 1] #0] exec.Utilities: Found plan in cache for name: map.xml\n2015-05-19 16:20:32,744 INFO [InputInitializer [Map 1] #0] exec.Utilities: Processing alias crc_arsn\n2015-05-19 16:20:32,744 INFO [InputInitializer [Map 1] #0] exec.Utilities: Adding input file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn\n2015-05-19 16:20:32,747 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: hive.io.file.readcolumn.ids=\n2015-05-19 16:20:32,747 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: hive.io.file.readcolumn.names=,arsn_cd,appl_user_id\n2015-05-19 16:20:32,747 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: Generating splits\n2015-05-19 16:20:32,780 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-19 16:20:32,780 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-19 16:20:32,780 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-19 16:20:32,780 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_socket\n2015-05-19 16:20:32,781 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-19 16:20:32,782 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@7879a53d\n2015-05-19 16:20:32,785 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-19 16:20:32,785 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-19 16:20:32,785 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-19 16:20:32,785 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_socket\n2015-05-19 16:20:32,786 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-19 16:20:32,786 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@7879a53d\n2015-05-19 16:20:32,876 DEBUG [InputInitializer [Map 1] #0] mapred.FileInputFormat: Time taken to get FileStatuses: 87\n2015-05-19 16:20:32,876 INFO [InputInitializer [Map 1] #0] mapred.FileInputFormat: Total input paths to process : 1\n2015-05-19 16:20:32,881 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-19 16:20:32,881 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-19 16:20:32,881 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-19 16:20:32,881 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_socket\n2015-05-19 16:20:32,882 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-19 16:20:32,883 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@7879a53d\n2015-05-19 16:20:32,907 DEBUG [InputInitializer [Map 1] #0] mapred.FileInputFormat: Total # of splits generated by getSplits: 40040, TimeTaken: 124\n2015-05-19 16:20:32,916 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: number of splits 40040\n2015-05-19 16:20:32,916 INFO [InputInitializer [Map 1] #0] log.PerfLogger: </PERFLOG method=getSplits start=1432066832722 end=1432066832916 duration=194 from=org.apache.hadoop.hive.ql.io.HiveInputFormat>\n2015-05-19 16:20:32,917 INFO [InputInitializer [Map 1] #0] tez.HiveSplitGenerator: Number of input splits: 40040. 23542 available slots, 1.7 waves. Input format is: org.apache.hadoop.hive.ql.io.HiveInputFormat\n2015-05-19 16:20:32,917 INFO [InputInitializer [Map 1] #0] exec.Utilities: PLAN PATH = hdfs://xhadnnm1p.example.com:8020/tmp/hive/gss2002/431ae2bc-ebc9-48e7-bbb3-f03144198009/hive_2015-05-19_16-20-28_783_5570914503219655045-1/gss2002/_tez_scratch_dir/9da6870e-7388-40b1-bab6-9d0f242b1702/map.xml\n2015-05-19 16:20:32,918 INFO [InputInitializer [Map 1] #0] exec.Utilities: ***************non-local mode***************\n2015-05-19 16:20:32,918 INFO [InputInitializer [Map 1] #0] exec.Utilities: local path = hdfs://xhadnnm1p.example.com:8020/tmp/hive/gss2002/431ae2bc-ebc9-48e7-bbb3-f03144198009/hive_2015-05-19_16-20-28_783_5570914503219655045-1/gss2002/_tez_scratch_dir/9da6870e-7388-40b1-bab6-9d0f242b1702/map.xml\n2015-05-19 16:20:32,918 DEBUG [InputInitializer [Map 1] #0] exec.Utilities: Loading plan from string: /tmp/hive/gss2002/431ae2bc-ebc9-48e7-bbb3-f03144198009/hive_2015-05-19_16-20-28_783_5570914503219655045-1/gss2002/_tez_scratch_dir/9da6870e-7388-40b1-bab6-9d0f242b1702/map.xml\n2015-05-19 16:20:32,919 INFO [InputInitializer [Map 1] #0] log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>\n2015-05-19 16:20:32,919 INFO [InputInitializer [Map 1] #0] exec.Utilities: Deserializing MapWork via kryo\n2015-05-19 16:20:32,940 INFO [InputInitializer [Map 1] #0] log.PerfLogger: </PERFLOG method=deserializePlan start=1432066832919 end=1432066832940 duration=21 from=org.apache.hadoop.hive.ql.exec.Utilities>\n2015-05-19 16:20:32,941 DEBUG [InputInitializer [Map 1] #0] tez.SplitGrouper: Adding split hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000 to src new group? true","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-20T15:40:58.855+0000","updated":"2015-05-20T15:40:58.855+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14552793","id":"14552793","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"I am guessing this JIRA could be the root of this issue: https://issues.apache.org/jira/browse/HIVE-7156\n\n\"gss2002_20150520132600_e4199888_c149_4394_8231_238d9d9dee98_1.Map_1_crc_arsn\" -> \"gss2002_20150520132600_e4199888_c149_4394_8231_238d9d9dee98_1.Map_1\" [ label = \"Input [inputClass=MRInputLegacy,\\n initializer=HiveSplitGenerator]\" ]\n\n\n\n\n2015-05-20 13:26:03,760 INFO [IPC Server handler 0 on 33574] app.DAGAppMaster: JSON dump for submitted DAG, dagId=dag_1426958683478_173250_1, json={\"dagName\":\"gss2002_20150520132600_e4199888-c149-4394-8231-238d9d9dee98:1\",\"dagInfo\":\"{\\\"description\\\":\\\"\\\\nSELECT appl_user_id, arsn_cd, COUNT(*) as RecordCount FROM adw.crc_arsn GROUP BY appl_user_id,arsn_cd ORDER BY appl_user_id\\\",\\\"context\\\":\\\"Hive\\\"}\",\"version\":1,\"vertices\":[{\"vertexName\":\"Map 1\",\"processorClass\":\"org.apache.hadoop.hive.ql.exec.tez.MapTezProcessor\",\"outEdgeIds\":[\"196588160\"],\"additionalInputs\":[{\"name\":\"crc_arsn\",\"class\":\"org.apache.tez.mapreduce.input.MRInputLegacy\",\"initializer\":\"org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator\"}]},{\"vertexName\":\"Reducer 2\",\"processorClass\":\"org.apache.hadoop.hive.ql.exec.tez.ReduceTezProcessor\",\"inEdgeIds\":[\"196588160\"],\"outEdgeIds\":[\"1320926067\"]},{\"vertexName\":\"Reducer 3\",\"processorClass\":\"org.apache.hadoop.hive.ql.exec.tez.ReduceTezProcessor\",\"inEdgeIds\":[\"1320926067\"],\"additionalOutputs\":[{\"name\":\"out_Reducer 3\",\"class\":\"org.apache.tez.mapreduce.output.MROutput\"}]}],\"edges\":[{\"edgeId\":\"196588160\",\"inputVertexName\":\"Map 1\",\"outputVertexName\":\"Reducer 2\",\"dataMovementType\":\"SCATTER_GATHER\",\"dataSourceType\":\"PERSISTED\",\"schedulingType\":\"SEQUENTIAL\",\"edgeSourceClass\":\"org.apache.tez.runtime.library.output.OrderedPartitionedKVOutput\",\"edgeDestinationClass\":\"org.apache.tez.runtime.library.input.OrderedGroupedKVInput\"},{\"edgeId\":\"1320926067\",\"inputVertexName\":\"Reducer 2\",\"outputVertexName\":\"Reducer 3\",\"dataMovementType\":\"SCATTER_GATHER\",\"dataSourceType\":\"PERSISTED\",\"schedulingType\":\"SEQUENTIAL\",\"edgeSourceClass\":\"org.apache.tez.runtime.library.output.OrderedPartitionedKVOutput\",\"edgeDestinationClass\":\"org.apache.tez.runtime.library.input.OrderedGroupedKVInput\"}]}\n2015-05-20 13:26:03,762 INFO [IPC Server handler 0 on 33574] app.DAGAppMaster: Generating DAG graphviz file, dagId=dag_1426958683478_173250_1, filePath=/u01/hadoop/yarn/log/application_1426958683478_173250/container_1426958683478_173250_01_000001/dag_1426958683478_173250_1.dot\n\n\n2015-05-20 13:26:05,142 DEBUG [InputInitializer [Map 1] #0] mapred.FileInputFormat: Total # of splits generated by getSplits: 40040, TimeTaken: 168\n2015-05-20 13:26:05,144 DEBUG [Socket Reader #1 for port 33574] ipc.Server:  got #159\n2015-05-20 13:26:05,145 DEBUG [IPC Server handler 0 on 33574] ipc.Server: IPC Server handler 0 on 33574: org.apache.tez.dag.api.client.rpc.DAGClientAMProtocolBlockingPB.getDAGStatus from 167.69.200.206:54162 Call#159 Retry#0 for RpcKind RPC_PROTOCOL_BUFFER\n2015-05-20 13:26:05,145 DEBUG [IPC Server handler 0 on 33574] security.UserGroupInformation: PrivilegedAction as:gss2002@exa.example.COM (auth:TOKEN) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)\n2015-05-20 13:26:05,147 INFO [IPC Server handler 0 on 33574] ipc.Server: Served: getDAGStatus queueTime= 1 procesingTime= 2\n2015-05-20 13:26:05,147 DEBUG [IPC Server handler 0 on 33574] ipc.Server: IPC Server handler 0 on 33574: responding to org.apache.tez.dag.api.client.rpc.DAGClientAMProtocolBlockingPB.getDAGStatus from 167.69.200.206:54162 Call#159 Retry#0\n2015-05-20 13:26:05,147 DEBUG [IPC Server handler 0 on 33574] ipc.Server: IPC Server handler 0 on 33574: responding to org.apache.tez.dag.api.client.rpc.DAGClientAMProtocolBlockingPB.getDAGStatus from 167.69.200.206:54162 Call#159 Retry#0 Wrote 145 bytes.\n2015-05-20 13:26:05,154 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: number of splits 40040\n2015-05-20 13:26:05,154 INFO [InputInitializer [Map 1] #0] log.PerfLogger: </PERFLOG method=getSplits start=1432142764918 end=1432142765154 duration=236 from=org.apache.hadoop.hive.ql.io.HiveInputFormat>\n2015-05-20 13:26:05,155 INFO [InputInitializer [Map 1] #0] tez.HiveSplitGenerator: Number of input splits: 40040. 23542 available slots, 1.7 waves. Input format is: org.apache.hadoop.hive.ql.io.HiveInputFormat","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-20T18:07:34.069+0000","updated":"2015-05-20T18:07:34.069+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14552826","id":"14552826","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"[~gss2002]: No, that JIRA is irrelevant to this issue - that has to do with column statistics, which your job does not have.\n\nThe issue you're hitting has its origins in the hadoop-1 TextInputFormat::getSplits(), which seems to generate 1 split per row.\n\nCan you please test with a compressed input file & confirm if compressing the input makes a query faster?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-05-20T18:20:29.457+0000","updated":"2015-05-20T18:20:29.457+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14552831","id":"14552831","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"So it looks like it turned a 3MB file into 5GB worth of reads since it did 40040 read ops due to the SPLITS?? \n\nBYTES_READ=5,149,746,588, BYTES_WRITTEN=0, READ_OPS=40040\n\nhadoop fs -ls /example_dw/crc/arsn\nFound 2 items\n-rwxr-x---   6 loaduser hadoopusers          0 2015-05-17 20:03 /example_dw/crc/arsn/_SUCCESS\n-rwxr-x---   6 loaduser hadoopusers    3883880 2015-05-17 20:03 /example_dw/crc/arsn/part-m-00000\n\n2015-05-20 13:35:27,017 INFO [AsyncDispatcher event handler] history.HistoryEventHandler: [HISTORY][DAG:dag_1426958683478_173250_1][Event:TASK_FINISHED]: vertexName=Map 1, taskId=task_1426958683478_173250_1_00_000000, startTime=1432142771521, finishTime=1432143327014, timeTaken=555493, status=SUCCEEDED, successfulAttemptID=attempt_1426958683478_173250_1_00_000000_0, diagnostics=, counters=Counters: 28, org.apache.tez.common.counters.DAGCounter, RACK_LOCAL_TASKS=1, File System Counters, BYTES_READ=32, BYTES_WRITTEN=59817, READ_OPS=0, LARGE_READ_OPS=0, WRITE_OPS=0, BYTES_READ=5149746588, BYTES_WRITTEN=0, READ_OPS=40040, LARGE_READ_OPS=0, WRITE_OPS=0, org.apache.tez.common.counters.TaskCounter, SPILLED_RECORDS=11516, GC_TIME_MILLIS=19923, CPU_MILLISECONDS=890510, PHYSICAL_MEMORY_BYTES=1285681152, VIRTUAL_MEMORY_BYTES=5264326656, COMMITTED_HEAP_BYTES=3007840256, INPUT_RECORDS_PROCESSED=13440, OUTPUT_RECORDS=11516, OUTPUT_BYTES=218808, OUTPUT_BYTES_WITH_OVERHEAD=241846, OUTPUT_BYTES_PHYSICAL=59785, ADDITIONAL_SPILLS_BYTES_WRITTEN=0, ADDITIONAL_SPILLS_BYTES_READ=0, ADDITIONAL_SPILL_COUNT=0, HIVE, DESERIALIZE_ERRORS=0, RECORDS_IN_Map_1=13440, RECORDS_OUT_INTERMEDIATE_Map_1=11516","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-20T18:24:42.404+0000","updated":"2015-05-20T18:24:42.404+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14552833","id":"14552833","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"hadoop fs -cat /example_dw/crc/arsn/part-m-00000| wc -l \n13440\n\n\nso 13440 rows... with a repfactor of 6...\n\nWhat compression format are you looking for gz snappy etc?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-20T18:28:46.882+0000","updated":"2015-05-20T18:28:46.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14552843","id":"14552843","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"\"gzip -1 > part.gz\", which should do the trick.\n\nAlso, you might want to do \"hive --hiveconf hive.prewarm.enabled=true;\" if you're worried about latency within the CLI - the default config is for throughput.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-05-20T18:38:18.524+0000","updated":"2015-05-20T18:38:18.524+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14552976","id":"14552976","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"With Compression with Snappy it ran in 7 seconds...\n\nStatus: DAG finished successfully in 7.93 seconds\n\n\nMETHOD                         DURATION(ms) \nparse                                1,081\nsemanticAnalyze                      1,488\nTezBuildDag                            490\nTezSubmitToRunningDag                  374\nTotalPrepTime                        4,958\n\nVERTICES         TOTAL_TASKS  FAILED_ATTEMPTS KILLED_TASKS DURATION_SECONDS    CPU_TIME_MILLIS     GC_TIME_MILLIS  INPUT_RECORDS   OUTPUT_RECORDS \nMap 1                      1                0            0             2.23              3,790                 29         13,440           11,516\nReducer 2                  1                0            0             0.81              2,150                  0         11,516           11,516\nReducer 3                  1                0            0             0.61              1,110                  0         11,516                0\nOK\nBB166674         P16     1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-20T19:48:35.761+0000","updated":"2015-05-20T19:48:35.761+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14553018","id":"14553018","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"Just to clarify this data is tab delimited being loaded from SqoopV1... What is the difference between compressed vs uncompressed at this point?\n\nMap 1: 0(+1)/1  Reducer 2: 0/1  Reducer 3: 0/1  \nMap 1: 0(+1)/1  Reducer 2: 0/1  Reducer 3: 0/1  \nMap 1: 0(+1)/1  Reducer 2: 0/1  Reducer 3: 0/1  \nMap 1: 1/1      Reducer 2: 0/1  Reducer 3: 0/1  \nMap 1: 1/1      Reducer 2: 0(+1)/1      Reducer 3: 0/1  \nMap 1: 1/1      Reducer 2: 1/1  Reducer 3: 0(+1)/1      \nMap 1: 1/1      Reducer 2: 1/1  Reducer 3: 1/1  \nStatus: DAG finished successfully in 523.42 seconds\n\n\nMETHOD                         DURATION(ms) \nparse                                   17\nsemanticAnalyze                      1,593\nTezBuildDag                            585\nTezSubmitToRunningDag                  187\nTotalPrepTime                        3,522\n\nVERTICES         TOTAL_TASKS  FAILED_ATTEMPTS KILLED_TASKS DURATION_SECONDS    CPU_TIME_MILLIS     GC_TIME_MILLIS  INPUT_RECORDS   OUTPUT_RECORDS \nMap 1                      1                0            0           516.72            752,950             15,318         13,440           11,516\nReducer 2                  1                0            0             0.81              1,890                 24         11,516           11,516\nReducer 3                  1                0            0             0.61              1,460                 19         11,516                0\nOK\nBB166674         P16     1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-20T20:05:05.474+0000","updated":"2015-05-20T20:05:05.474+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14553061","id":"14553061","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"Debug logs from DAG with compressed it sets 1 split.. so how do we fix this issue?\n\n\n2015-05-20 16:15:12,041 DEBUG [InputInitializer [Map 1] #0] exec.Utilities: Found plan in cache for name: map.xml\n2015-05-20 16:15:12,055 INFO [InputInitializer [Map 1] #0] exec.Utilities: Processing alias gss_rsn2\n2015-05-20 16:15:12,055 INFO [InputInitializer [Map 1] #0] exec.Utilities: Adding input file hdfs://xhadnnm1p.example.com:8020/apps/hive/warehouse/hue_debug.db/gss_rsn2\n2015-05-20 16:15:12,057 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: hive.io.file.readcolumn.ids=\n2015-05-20 16:15:12,058 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: hive.io.file.readcolumn.names=,arsn_cd,appl_user_id\n2015-05-20 16:15:12,058 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: Generating splits\n2015-05-20 16:15:12,087 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-20 16:15:12,087 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-20 16:15:12,087 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-20 16:15:12,087 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_socket\n2015-05-20 16:15:12,088 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-20 16:15:12,088 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@6c93595a\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_socket\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-20 16:15:12,092 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@6c93595a\n2015-05-20 16:15:12,216 DEBUG [InputInitializer [Map 1] #0] mapred.FileInputFormat: Time taken to get FileStatuses: 112\n2015-05-20 16:15:12,216 INFO [InputInitializer [Map 1] #0] mapred.FileInputFormat: Total input paths to process : 1\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_socket\n2015-05-20 16:15:12,220 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-20 16:15:12,220 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@6c93595a\n2015-05-20 16:15:12,222 DEBUG [InputInitializer [Map 1] #0] mapred.FileInputFormat: Total # of splits generated by getSplits: 1, TimeTaken: 132\n2015-05-20 16:15:12,222 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: number of splits 1\n2015-05-20 16:15:12,222 INFO [InputInitializer [Map 1] #0] log.PerfLogger: </PERFLOG method=getSplits start=1432152912040 end=1432152912222 duration=182 from=org.apache.hadoop.hive.ql.io.HiveInputFormat>\n2015-05-20 16:15:12,222 INFO [InputInitializer [Map 1] #0] tez.HiveSplitGenerator: Number of input splits: 1. 23542 available slots, 1.7 waves. Input format is: org.apache.hadoop.hive.ql.io.HiveInputFormat\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: PLAN PATH = hdfs://xhadnnm1p.example.com:8020/tmp/hive/gss2002/646469af-0a87-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-4805-90a5-84b8c38fe1f4/map.xml\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: ***************non-local mode***************\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: local path = hdfs://xhadnnm1p.example.com:8020/tmp/hive/gss2002/646469af-0a87-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-4805-90a5-84b8c38fe1f4/map.xml\n2015-05-20 16:15:12,223 DEBUG [InputInitializer [Map 1] #0] exec.Utilities: Loading plan from string: /tmp/hive/gss2002/646469af-0a87-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-4805-90a5-84b8c38fe1f4/map.xml\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: Deserializing MapWork via kryo\n2015-05-20 16:15:12,239 INFO [InputInitializer [Map 1] #0] log.PerfLogger: </PERFLOG method=deserializePlan start=1432152912223 end=1432152912239 duration=16 from=org.apache.hadoop.hive.ql.exec.Utilities>\n2015-05-20 16:15:12,240 DEBUG [InputInitializer [Map 1] #0] tez.SplitGrouper: Adding split hdfs://xhadnnm1p.example.com:8020/apps/hive/warehouse/hue_debug.db/gss_rsn2/000000_0.snappy to src new group? true\n2015-05-20 16:15:12,240 INFO [InputInitializer [Map 1] #0] tez.SplitGrouper: # Src groups for split generation: 2\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_\nsocket\n2015-05-20 16:15:12,091 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-20 16:15:12,092 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@6c\n93595a\n2015-05-20 16:15:12,216 DEBUG [InputInitializer [Map 1] #0] mapred.FileInputFormat: Time taken to get FileStatuses: 112\n2015-05-20 16:15:12,216 INFO [InputInitializer [Map 1] #0] mapred.FileInputFormat: Total input paths to process : 1\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-20 16:15:12,219 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_\nsocket\n2015-05-20 16:15:12,220 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-20 16:15:12,220 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@6c\n93595a\n2015-05-20 16:15:12,222 DEBUG [InputInitializer [Map 1] #0] mapred.FileInputFormat: Total # of splits generated by getSplits: 1, Tim\neTaken: 132\n2015-05-20 16:15:12,222 INFO [InputInitializer [Map 1] #0] io.HiveInputFormat: number of splits 1\n2015-05-20 16:15:12,222 INFO [InputInitializer [Map 1] #0] log.PerfLogger: </PERFLOG method=getSplits start=1432152912040 end=143215\n2912222 duration=182 from=org.apache.hadoop.hive.ql.io.HiveInputFormat>\n2015-05-20 16:15:12,222 INFO [InputInitializer [Map 1] #0] tez.HiveSplitGenerator: Number of input splits: 1. 23542 available slots,\n 1.7 waves. Input format is: org.apache.hadoop.hive.ql.io.HiveInputFormat\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: PLAN PATH = hdfs://xhadnnm1p.example.com:8020/tmp/hive/a760\n104/646469af-0a87-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-4\n805-90a5-84b8c38fe1f4/map.xml\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: ***************non-local mode***************\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: local path = hdfs://xhadnnm1p.example.com:8020/tmp/hive/a76\n0104/646469af-0a87-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-\n4805-90a5-84b8c38fe1f4/map.xml\n2015-05-20 16:15:12,223 DEBUG [InputInitializer [Map 1] #0] exec.Utilities: Loading plan from string: /tmp/hive/gss2002/646469af-0a8\n7-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-4805-90a5-84b8c38\nfe1f4/map.xml\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hi\nve.ql.exec.Utilities>\n2015-05-20 16:15:12,223 INFO [InputInitializer [Map 1] #0] exec.Utilities: Deserializing MapWork via kryo\n2015-05-20 16:15:12,239 INFO [InputInitializer [Map 1] #0] log.PerfLogger: </PERFLOG method=deserializePlan start=1432152912223 end=\n1432152912239 duration=16 from=org.apache.hadoop.hive.ql.exec.Utilities>\n2015-05-20 16:15:12,240 DEBUG [InputInitializer [Map 1] #0] tez.SplitGrouper: Adding split hdfs://xhadnnm1p.example.com:8020/apps/hive\n/warehouse/hue_debug.db/gss_rsn2/000000_0.snappy to src new group? true\n2015-05-20 16:15:12,240 INFO [InputInitializer [Map 1] #0] tez.SplitGrouper: # Src groups for split generation: 2\n2015-05-20 16:15:12,241 INFO [InputInitializer [Map 1] #0] tez.SplitGrouper: Estimated number of tasks: 40021 for bucket 1\n2015-05-20 16:15:12,241 INFO [InputInitializer [Map 1] #0] split.TezMapredSplitsGrouper: Grouping splits in Tez\n2015-05-20 16:15:12,241 INFO [InputInitializer [Map 1] #0] split.TezMapredSplitsGrouper: Desired splits: 40021 too large.  Desired splitLength: 20 Min splitLength: 16777216 New desired splits: 1 Total length: 807489 Original splits: 1\n2015-05-20 16:15:12,242 INFO [InputInitializer [Map 1] #0] split.TezMapredSplitsGrouper: Using original number of splits: 1 desired splits: 1\n2015-05-20 16:15:12,242 INFO [InputInitializer [Map 1] #0] tez.SplitGrouper: Original split size is 1 grouped split size is 1, for bucket: 1\n2015-05-20 16:15:12,244 INFO [InputInitializer [Map 1] #0] tez.HiveSplitGenerator: Number of grouped splits: 1\n2015-05-20 16:15:12,251 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false\n2015-05-20 16:15:12,251 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = true\n2015-05-20 16:15:12,251 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false\n2015-05-20 16:15:12,251 DEBUG [InputInitializer [Map 1] #0] hdfs.BlockReaderLocal: dfs.domain.socket.path = /var/lib/hadoop-hdfs/dn_socket\n2015-05-20 16:15:12,251 DEBUG [InputInitializer [Map 1] #0] retry.RetryUtils: multipleLinearRandomRetry = null\n2015-05-20 16:15:12,251 DEBUG [InputInitializer [Map 1] #0] ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@6c93595a\n2015-05-20 16:15:12,252 TRACE [InputInitializer [Map 1] #0] ipc.ProtobufRpcEngine: 85: Call -> xhadnnm1p.example.com/167.69.200.200:8020: getFileInfo {src: \"/tmp/hive/gss2002/646469af-0a87-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-4805-90a5-84b8c38fe1f4/map.xml\"}\n2015-05-20 16:15:12,253 DEBUG [InputInitializer [Map 1] #0] ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms\n2015-05-20 16:15:12,253 TRACE [InputInitializer [Map 1] #0] ipc.ProtobufRpcEngine: 85: Response <- xhadnnm1p.example.com/167.69.200.200:8020: getFileInfo {}\n2015-05-20 16:15:12,254 TRACE [InputInitializer [Map 1] #0] ipc.ProtobufRpcEngine: 85: Call -> xhadnnm1p.example.com/167.69.200.200:8020: getFileInfo {src: \"/tmp/hive/gss2002/646469af-0a87-4080-9d2b-e40af4a34c0e/hive_2015-05-20_16-15-06_565_5281905327000741927-1/gss2002/_tez_scratch_dir/049d6a0d-aea4-4805-90a5-84b8c38fe1f4/reduce.xml\"}\n2015-05-20 16:15:12,255 DEBUG [InputInitializer [Map 1] #0] ipc.ProtobufRpcEngine: Call: getFileInfo took 1ms\n2015-05-20 16:15:12,255 TRACE [InputInitializer [Map 1] #0] ipc.ProtobufRpcEngine: 85: Response <- xhadnnm1p.example.com/167.69.200.200:8020: getFileInfo {}\n2015-05-20 16:15:12,255 INFO [InputInitializer [Map 1] #0] dag.RootInputInitializerManager: Succeeded InputInitializer for Input: gss_rsn2 on vertex vertex_1426958683478_173564_1_00 [Map 1]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-20T20:36:39.214+0000","updated":"2015-05-20T20:36:39.214+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14555456","id":"14555456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"body":"After having offline discussion with Gopal V he determined the cause of this problem is that starting in Hive 0.14 org.apache.hadoop.mapred.TextInputFormat  uses whatever is defined in property: mapreduce.input.fileinputformat.split.minsize; In my case this was defined to \"1\"... Unfortunately that is 1 byte so it created 40040 splits creating 40400 reads of the single 3MB file...\n\nHope this helps someone else out.\n\nShould be around half of the HDFS block size in my case 64MB since my block size is 128MB..\nmapreduce.input.fileinputformat.split.minsize=67108864\n\n\nGopal V if no fix is coming should we resolve/close this JIRA?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gss2002","name":"gss2002","key":"gss2002","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Greg Senia","active":true,"timeZone":"America/New_York"},"created":"2015-05-22T02:10:53.065+0000","updated":"2015-05-22T02:10:53.065+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14585306","id":"14585306","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"[~gss2002]: Talking to the MRv2 folks to change the defaults to be saner than 1 byte.\n\nUntil that issue is resolved, I'll keep this open as a critical issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-06-14T23:06:34.541+0000","updated":"2015-06-14T23:06:34.541+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14590903","id":"14590903","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"Fixing legacy {{Mapred.TextInputFormat}} is fraught with issues.\n\nAllow Tez split generation to set a sane default if the min-size is misconfigured during execution.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-06-18T00:15:49.825+0000","updated":"2015-06-18T00:15:49.825+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14590912","id":"14590912","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"body":"+1. (Nit: ws issue, the closing brace for the if statement is not correctly aligned).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-18T00:21:32.508+0000","updated":"2015-06-18T00:21:32.508+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14591479","id":"14591479","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12740251/HIVE-10746.1.patch\n\n{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9009 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_corr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join28\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4299/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4299/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4299/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 2 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12740251 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-06-18T08:37:25.172+0000","updated":"2015-06-18T08:37:25.172+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14592102","id":"14592102","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"Test failures look unrelated.\n\nReformat before commit.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-06-18T17:00:37.183+0000","updated":"2015-06-18T17:00:37.183+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14592471","id":"14592471","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to 1.2.1, branch-1 and master.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-18T20:39:08.701+0000","updated":"2015-06-18T20:39:08.701+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12830899/comment/14592604","id":"14592604","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Please add to the release wiki ( https://cwiki.apache.org/confluence/display/Hive/Hive+1.2+Release+Status ) when you commit any patch to branch-1.2. I'll go ahead and add this one in.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-18T21:54:09.148+0000","updated":"2015-06-18T21:54:09.148+0000"}],"maxResults":21,"total":21,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10746/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2ewon:"}}