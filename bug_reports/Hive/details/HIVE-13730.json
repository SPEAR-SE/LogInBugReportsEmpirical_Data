{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12967179","self":"https://issues.apache.org/jira/rest/api/2/issue/12967179","key":"HIVE-13730","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334255","id":"12334255","name":"2.1.0","archived":false,"released":true,"releaseDate":"2016-06-20"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-05-10T21:30:14.025+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed May 18 21:13:53 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_41477045_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_638921304","customfield_12312321":null,"resolutiondate":"2016-05-18T16:52:36.463+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-13730/watchers","watchCount":3,"isWatching":false},"created":"2016-05-10T19:52:38.176+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334255","id":"12334255","name":"2.1.0","archived":false,"released":true,"releaseDate":"2016-06-20"}],"issuelinks":[{"id":"12466438","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12466438","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12969473","key":"HIVE-13755","self":"https://issues.apache.org/jira/rest/api/2/issue/12969473","fields":{"summary":"Hybrid mapjoin allocates memory the same for multi broadcast","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12466222","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12466222","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12929253","key":"HIVE-12837","self":"https://issues.apache.org/jira/rest/api/2/issue/12929253","fields":{"summary":"Better memory estimation/allocation for hybrid grace hash join during hash table loading","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-06-21T15:08:22.069+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320810","id":"12320810","name":"Tez","description":"Hive utilizing Tez framework"}],"timeoriginalestimate":null,"description":"I am seeing hybridgrace_hashjoin_1.q getting stuck on master.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334255","id":"12334255","name":"2.1.0","archived":false,"released":true,"releaseDate":"2016-06-20"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803377","id":"12803377","filename":"HIVE-13730.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-11T07:23:44.584+0000","size":1634,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12803377/HIVE-13730.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803806","id":"12803806","filename":"HIVE-13730.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-13T06:23:32.173+0000","size":2330,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12803806/HIVE-13730.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803966","id":"12803966","filename":"HIVE-13730.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-13T22:04:39.209+0000","size":2307,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12803966/HIVE-13730.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12804208","id":"12804208","filename":"HIVE-13730.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-16T17:13:08.874+0000","size":2307,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12804208/HIVE-13730.4.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Avoid double spilling the same partition when memory threshold is set very low","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15278987","id":"15278987","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Looking into it..","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-10T21:30:14.025+0000","updated":"2016-05-10T21:30:14.025+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15279098","id":"15279098","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"It's stuck in an infinite while loop in BytesBytesMultiHashMap.findKeySlotToWrite().\n{code}\n$ jps\n90673 TezChild\n90976 TezChild\n90855 TezChild\n91225 Jps\n82923 RemoteMavenServer\n90205 surefirebooter3625226115924096543.jar\n90191 Launcher\n90542 DAGAppMaster\n$ jstack 90673\n2016-05-10 15:13:47\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.74-b02 mixed mode):\n\n\"Attach Listener\" #138 daemon prio=9 os_prio=31 tid=0x00007feea4800000 nid=0x3d3b waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"TezTaskEventRouter{attempt_1462916018098_0001_32_01_000000_0}\" #134 daemon prio=5 os_prio=31 tid=0x00007feea684f000 nid=0x692f waiting on condition [0x0000700001be7000]\n   java.lang.Thread.State: WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007bc9d6490> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask$1.runInternal(LogicalIOProcessorRuntimeTask.java:773)\n\tat org.apache.tez.common.RunnableWithNdc.run(RunnableWithNdc.java:35)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"org.apache.hadoop.hdfs.PeerCache@35f41fc9\" #22 daemon prio=5 os_prio=31 tid=0x00007feea686d800 nid=0x6a03 waiting on condition [0x0000700001cea000]\n   java.lang.Thread.State: TIMED_WAITING (sleeping)\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:244)\n\tat org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:41)\n\tat org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:119)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"TaskHeartbeatThread\" #15 daemon prio=5 os_prio=31 tid=0x00007feea310c000 nid=0x6403 waiting on condition [0x00007000019e1000]\n   java.lang.Thread.State: TIMED_WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007bcb6aa40> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)\n\tat org.apache.tez.runtime.task.TaskReporter$HeartbeatCallable.call(TaskReporter.java:200)\n\tat org.apache.tez.runtime.task.TaskReporter$HeartbeatCallable.call(TaskReporter.java:128)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"IPC Parameter Sending Thread #0\" #14 daemon prio=5 os_prio=31 tid=0x00007feea0979000 nid=0x6203 waiting on condition [0x00007000018de000]\n   java.lang.Thread.State: TIMED_WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x000000078df78428> (a java.util.concurrent.SynchronousQueue$TransferStack)\n\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n\tat java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)\n\tat java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)\n\tat java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)\n\tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1066)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"IPC Client (1617838096) connection to /10.22.27.129:64289 from application_1462916018098_0001\" #13 daemon prio=5 os_prio=31 tid=0x00007feea11f6800 nid=0x6003 in Object.wait() [0x00007000017db000]\n   java.lang.Thread.State: TIMED_WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\tat org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:920)\n\t- locked <0x000000078df52318> (a org.apache.hadoop.ipc.Client$Connection)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:965)\n\n\"TezChild\" #12 daemon prio=5 os_prio=31 tid=0x00007feea0a65000 nid=0x5e07 runnable [0x00007000016d7000]\n   java.lang.Thread.State: RUNNABLE\n\tat org.apache.hadoop.hive.ql.exec.persistence.BytesBytesMultiHashMap.findKeySlotToWrite(BytesBytesMultiHashMap.java:602)\n\tat org.apache.hadoop.hive.ql.exec.persistence.BytesBytesMultiHashMap.put(BytesBytesMultiHashMap.java:454)\n\tat org.apache.hadoop.hive.ql.exec.MapJoinOperator.reloadHashTable(MapJoinOperator.java:646)\n\tat org.apache.hadoop.hive.ql.exec.MapJoinOperator.continueProcess(MapJoinOperator.java:591)\n\tat org.apache.hadoop.hive.ql.exec.MapJoinOperator.closeOp(MapJoinOperator.java:528)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:641)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:655)\n\tat org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.close(MapRecordProcessor.java:413)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:186)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:160)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:355)\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:72)\n\tat org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:60)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:60)\n\tat org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:36)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"AsyncLogger-1\" #11 daemon prio=5 os_prio=31 tid=0x00007feea1235000 nid=0x5a0f waiting on condition [0x00007000015d5000]\n   java.lang.Thread.State: WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x000000078e0657c8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\n\tat com.lmax.disruptor.BlockingWaitStrategy.waitFor(BlockingWaitStrategy.java:45)\n\tat com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:55)\n\tat com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:123)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"Service Thread\" #9 daemon prio=9 os_prio=31 tid=0x00007feea4801000 nid=0x5203 runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C1 CompilerThread3\" #8 daemon prio=9 os_prio=31 tid=0x00007feea3004800 nid=0x5003 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread2\" #7 daemon prio=9 os_prio=31 tid=0x00007feea102c800 nid=0x4e03 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread1\" #6 daemon prio=9 os_prio=31 tid=0x00007feea1803800 nid=0x4c03 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"C2 CompilerThread0\" #5 daemon prio=9 os_prio=31 tid=0x00007feea1801000 nid=0x4a03 waiting on condition [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Signal Dispatcher\" #4 daemon prio=9 os_prio=31 tid=0x00007feea081c800 nid=0x3e0f runnable [0x0000000000000000]\n   java.lang.Thread.State: RUNNABLE\n\n\"Finalizer\" #3 daemon prio=8 os_prio=31 tid=0x00007feea080f800 nid=0x3803 in Object.wait() [0x0000700000d3a000]\n   java.lang.Thread.State: WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)\n\t- locked <0x000000078e1a8a90> (a java.lang.ref.ReferenceQueue$Lock)\n\tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)\n\tat java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)\n\n\"Reference Handler\" #2 daemon prio=10 os_prio=31 tid=0x00007feea3845000 nid=0x3603 in Object.wait() [0x0000700000c37000]\n   java.lang.Thread.State: WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Object.wait(Object.java:502)\n\tat java.lang.ref.Reference.tryHandlePending(Reference.java:191)\n\t- locked <0x000000078e1a8b28> (a java.lang.ref.Reference$Lock)\n\tat java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)\n\n\"main\" #1 prio=5 os_prio=31 tid=0x00007feea2802000 nid=0x1703 waiting on condition [0x0000700000219000]\n   java.lang.Thread.State: WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007bcb6b0d8> (a com.google.common.util.concurrent.ListenableFutureTask)\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n\tat java.util.concurrent.FutureTask.awaitDone(FutureTask.java:429)\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:191)\n\tat org.apache.tez.runtime.task.TezTaskRunner2.run(TezTaskRunner2.java:158)\n\tat org.apache.tez.runtime.task.TezChild.run(TezChild.java:264)\n\tat org.apache.tez.runtime.task.TezChild.main(TezChild.java:508)\n\n\"VM Thread\" os_prio=31 tid=0x00007feea102c000 nid=0x3403 runnable\n\n\"GC task thread#0 (ParallelGC)\" os_prio=31 tid=0x00007feea101d000 nid=0x2403 runnable\n\n\"GC task thread#1 (ParallelGC)\" os_prio=31 tid=0x00007feea080a800 nid=0x2603 runnable\n\n\"GC task thread#2 (ParallelGC)\" os_prio=31 tid=0x00007feea3000000 nid=0x2803 runnable\n\n\"GC task thread#3 (ParallelGC)\" os_prio=31 tid=0x00007feea0804000 nid=0x2a03 runnable\n\n\"GC task thread#4 (ParallelGC)\" os_prio=31 tid=0x00007feea080d000 nid=0x2c03 runnable\n\n\"GC task thread#5 (ParallelGC)\" os_prio=31 tid=0x00007feea080d800 nid=0x2e03 runnable\n\n\"GC task thread#6 (ParallelGC)\" os_prio=31 tid=0x00007feea080e800 nid=0x3003 runnable\n\n\"GC task thread#7 (ParallelGC)\" os_prio=31 tid=0x00007feea080f000 nid=0x3203 runnable\n\n\"VM Periodic Task Thread\" os_prio=31 tid=0x00007feea481c800 nid=0x5403 waiting on condition\n\nJNI global references: 273\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-10T22:15:46.568+0000","updated":"2016-05-10T22:15:46.568+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15279701","id":"15279701","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"The root cause is that in some cases (e.g. when hive.auto.convert.join.noconditionaltask.size is set very small), a hash partition can be empty when it's being spilled (the memory estimation logic is conservative and strict, so even without loading any row into a hash partition, it can still assume the memory is about to get full, thus choose a partition to spill).\n\nStill, spilling an empty hash partition is OK. The problem happens during deserialization of the spilled hash partition (BytesBytesMultiHashMap). If the hash partition is empty, it will result in the refs array in the hashmap to have a length of only 1. This causes problem of putRow as the backtrace above shows, because it couldn't find a proper slot for inserting.\n\nThe solution is to instantiate a new BytesBytesMultiHashMap manually if we figure out the deserialized hashmap is empty. This way we can have a properly constructed refs array for it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-11T07:22:56.330+0000","updated":"2016-05-11T07:22:56.330+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15279703","id":"15279703","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"patch 1 for test. [~vikram.dixit] Can you review please? Now the test can finish :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-11T07:23:44.591+0000","updated":"2016-05-11T07:23:44.591+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15279707","id":"15279707","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"This issue is caused/exposed by HIVE-12837.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-11T07:25:15.259+0000","updated":"2016-05-11T07:25:15.259+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15282431","id":"15282431","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Here's an todo item after HIVE-13755 is fixed.\nRight now memory manager doesn't guarantee to allocate enough memory for each table in n-way join case. After fixing that issue, this assert below can be put into HybridHashTableContainer's cstr after the variables have been determined.\n{code}\n    assert writeBufferSize * (numPartitions - numPartitionsSpilledOnCreation) <= memoryThreshold :\n        \"hive.auto.convert.join.noconditionaltask.size is set too low. It's not enough to \" +\n        \"allocate \" + (numPartitions - numPartitionsSpilledOnCreation) + \" partitions (each \" +\n        \" of size \" + writeBufferSize;\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-13T05:54:27.912+0000","updated":"2016-05-13T05:54:27.912+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15282456","id":"15282456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Upload patch 2. [~vikram.dixit] Can you take a look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-13T06:23:32.177+0000","updated":"2016-05-13T06:23:32.177+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15282770","id":"15282770","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12803806/HIVE-13730.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 63 failed/errored test(s), 10003 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_grouping_sets.q-update_all_partitioned.q-cte_5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_interval_2.q-schema_evol_text_nonvec_mapwork_part_all_primitive.q-tez_fsstat.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vectorization_16.q-vector_decimal_round.q-orc_merge6.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vectorized_parquet.q-insert_values_non_partitioned.q-schema_evol_orc_nonvec_mapwork_part.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-skewjoinopt15.q-join39.q-avro_joins_native.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkClient - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_tez_join_result_complex\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket5\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket6\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_disable_merge_for_bucketing\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_map_operators\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_num_buckets\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_list_bucket_dml_10\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge9\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge_diff_fs\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_reduce_deduplicate\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join5\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.org.apache.hadoop.hive.cli.TestMiniTezCliDriver\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapreduce1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_19\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_8\norg.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService.testPreemptionQueueComparator\norg.apache.hadoop.hive.llap.tez.TestConverters.testFragmentSpecToTaskSpec\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote\norg.apache.hadoop.hive.metastore.TestFilterHooks.org.apache.hadoop.hive.metastore.TestFilterHooks\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreStatsMerge.testStatsMerge\norg.apache.hadoop.hive.metastore.TestMetaStoreEventListenerOnlyOnCommit.testEventStatus\norg.apache.hadoop.hive.metastore.TestMetaStoreInitListener.testMetaStoreInitListener\norg.apache.hadoop.hive.metastore.TestMetaStoreMetrics.org.apache.hadoop.hive.metastore.TestMetaStoreMetrics\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAddPartitionWithValidPartVal\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAppendPartitionWithCommas\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAppendPartitionWithUnicode\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAppendPartitionWithValidCharacters\norg.apache.hadoop.hive.metastore.TestRetryingHMSHandler.testRetryingHMSHandler\norg.apache.hadoop.hive.metastore.hbase.TestHBaseSchemaTool.oneMondoTest\norg.apache.hadoop.hive.ql.TestTxnCommands2.testInitiatorWithMultipleFailedCompactions\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testShowLocksFilterOptions\norg.apache.hadoop.hive.ql.security.TestExtendedAcls.org.apache.hadoop.hive.ql.security.TestExtendedAcls\norg.apache.hadoop.hive.ql.security.TestMetastoreAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener.org.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener\norg.apache.hadoop.hive.ql.security.TestStorageBasedClientSideAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testDelegationTokenSharedStore\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testMetastoreProxyUser\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testSaslWithHiveMetaStore\norg.apache.hive.service.cli.session.TestHiveSessionImpl.testLeakOperationHandle\n{noformat}\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/256/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/256/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-256/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 63 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12803806 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-13T15:07:51.359+0000","updated":"2016-05-13T15:07:51.359+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15283217","id":"15283217","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"As I dig deeper, it turns out that the issue is actually due to spilling the same hash partition twice.\n\nIn HybridHashTableContainer.internalPutRow, once isMemoryFull() returns true, we will pick the biggest partition in memory so far by calling biggestPartition(). This method is problematic.\n{code}\n  private int biggestPartition() {\n    int res = 0;\n    int maxSize = 0;\n\n    // If a partition has been spilled to disk, its size will be 0, i.e. it won't be picked\n    for (int i = 0; i < hashPartitions.length; i++) {\n      int size;\n      if (isOnDisk(i)) {\n        continue;\n      } else {\n        size = hashPartitions[i].hashMap.getNumValues();\n      }\n      if (size > maxSize) {\n        maxSize = size;\n        res = i;\n      }\n    }\n    return res;\n  }\n{code}\n\nIf all in-memory partitions have size 0, then the default initial value 0 will be returned. But what if partition 0 has already been spilled previously? This will spill partition 0 again, which is not expected.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-13T22:04:14.870+0000","updated":"2016-05-13T22:04:14.870+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15283760","id":"15283760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12803966/HIVE-13730.3.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/287/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/287/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-287/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] Excluding org.apache.spark:spark-core_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding com.twitter:chill_2.10:jar:0.5.0 from the shaded jar.\n[INFO] Excluding com.twitter:chill-java:jar:0.5.0 from the shaded jar.\n[INFO] Excluding org.apache.xbean:xbean-asm5-shaded:jar:4.4 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-client:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-mapreduce-client-app:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-mapreduce-client-shuffle:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-mapreduce-client-jobclient:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-launcher_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-network-common_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-network-shuffle_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-unsafe_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.slf4j:jul-to-slf4j:jar:1.7.10 from the shaded jar.\n[INFO] Excluding org.slf4j:jcl-over-slf4j:jar:1.7.10 from the shaded jar.\n[INFO] Excluding com.ning:compress-lzf:jar:1.0.3 from the shaded jar.\n[INFO] Excluding net.jpountz.lz4:lz4:jar:1.3.0 from the shaded jar.\n[INFO] Excluding com.typesafe.akka:akka-remote_2.10:jar:2.3.11 from the shaded jar.\n[INFO] Excluding com.typesafe.akka:akka-actor_2.10:jar:2.3.11 from the shaded jar.\n[INFO] Excluding com.typesafe:config:jar:1.2.1 from the shaded jar.\n[INFO] Excluding org.uncommons.maths:uncommons-maths:jar:1.2.2a from the shaded jar.\n[INFO] Excluding com.typesafe.akka:akka-slf4j_2.10:jar:2.3.11 from the shaded jar.\n[INFO] Excluding org.scala-lang:scala-library:jar:2.10.4 from the shaded jar.\n[INFO] Excluding org.json4s:json4s-jackson_2.10:jar:3.2.10 from the shaded jar.\n[INFO] Excluding org.json4s:json4s-core_2.10:jar:3.2.10 from the shaded jar.\n[INFO] Excluding org.json4s:json4s-ast_2.10:jar:3.2.10 from the shaded jar.\n[INFO] Excluding org.scala-lang:scalap:jar:2.10.0 from the shaded jar.\n[INFO] Excluding org.scala-lang:scala-compiler:jar:2.10.0 from the shaded jar.\n[INFO] Excluding org.apache.mesos:mesos:jar:shaded-protobuf:0.21.1 from the shaded jar.\n[INFO] Excluding com.clearspring.analytics:stream:jar:2.7.0 from the shaded jar.\n[INFO] Excluding io.dropwizard.metrics:metrics-graphite:jar:3.1.2 from the shaded jar.\n[INFO] Excluding com.fasterxml.jackson.module:jackson-module-scala_2.10:jar:2.4.4 from the shaded jar.\n[INFO] Excluding org.scala-lang:scala-reflect:jar:2.10.4 from the shaded jar.\n[INFO] Excluding oro:oro:jar:2.0.8 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-client:jar:0.8.2 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-underfs-hdfs:jar:0.8.2 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-underfs-s3:jar:0.8.2 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-underfs-local:jar:0.8.2 from the shaded jar.\n[INFO] Excluding net.razorvine:pyrolite:jar:4.9 from the shaded jar.\n[INFO] Excluding net.sf.py4j:py4j:jar:0.9 from the shaded jar.\n[INFO] Excluding org.spark-project.spark:unused:jar:1.0.0 from the shaded jar.\n[INFO] Excluding org.slf4j:slf4j-api:jar:1.7.10 from the shaded jar.\n[INFO] Replacing original artifact with shaded artifact.\n[INFO] Replacing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT.jar with /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT-shaded.jar\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-exec ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT-tests.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT-tests.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT-core.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT-core.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Llap Server 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-llap-server ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/llap-server/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/llap-server (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-llap-server ---\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-llap-server ---\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/llap-server/src/gen/protobuf/gen-java added.\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/llap-server/src/gen/thrift/gen-javabean added.\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-llap-server ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-llap-server ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 19 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-llap-server ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-llap-server ---\n[INFO] Compiling 87 source files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[29,16] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[29,16] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[29,16] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[74,9] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/io/metadata/OrcFileMetadata.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/io/metadata/OrcFileMetadata.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/DirWatcher.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/DirWatcher.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-llap-server ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-llap-server ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp/conf\n     [copy] Copying 15 files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-llap-server ---\n[INFO] Compiling 13 source files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/test-classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-llap-server ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-llap-server ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-llap-server ---\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-llap-server ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT-tests.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-llap-server ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-llap-server/2.1.0-SNAPSHOT/hive-llap-server-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-server/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-llap-server/2.1.0-SNAPSHOT/hive-llap-server-2.1.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT-tests.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-llap-server/2.1.0-SNAPSHOT/hive-llap-server-2.1.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Service 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\nDownloading: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/maven-metadata.xml\n\n[WARNING] Could not transfer metadata org.apache.directory.client.ldap:ldap-client-api:0.1-SNAPSHOT/maven-metadata.xml from/to apache.snapshots (http://repository.apache.org/snapshots): Failed to transfer file: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/maven-metadata.xml. Return code is: 503 , ReasonPhrase:Service Unavailable.\n[WARNING] Failure to transfer org.apache.directory.client.ldap:ldap-client-api:0.1-SNAPSHOT/maven-metadata.xml from http://repository.apache.org/snapshots was cached in the local repository, resolution will not be reattempted until the update interval of apache.snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.apache.directory.client.ldap:ldap-client-api:0.1-SNAPSHOT/maven-metadata.xml from/to apache.snapshots (http://repository.apache.org/snapshots): Failed to transfer file: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/maven-metadata.xml. Return code is: 503 , ReasonPhrase:Service Unavailable.\nDownloading: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/ldap-client-api-0.1-SNAPSHOT.pom\n\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.646s]\n[INFO] Hive Shims Common ................................. SUCCESS [4.513s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [3.249s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [0.971s]\n[INFO] Hive Shims ........................................ SUCCESS [0.771s]\n[INFO] Hive Storage API .................................. SUCCESS [1.659s]\n[INFO] Hive ORC .......................................... SUCCESS [2.989s]\n[INFO] Hive Common ....................................... SUCCESS [4.517s]\n[INFO] Hive Service RPC .................................. SUCCESS [2.804s]\n[INFO] Hive Serde ........................................ SUCCESS [4.672s]\n[INFO] Hive Metastore .................................... SUCCESS [17.852s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.357s]\n[INFO] Hive Llap Common .................................. SUCCESS [5.764s]\n[INFO] Hive Llap Client .................................. SUCCESS [3.266s]\n[INFO] Hive Llap Tez ..................................... SUCCESS [1.681s]\n[INFO] Spark Remote Client ............................... SUCCESS [2.774s]\n[INFO] Hive Query Language ............................... SUCCESS [49.958s]\n[INFO] Hive Llap Server .................................. SUCCESS [2.887s]\n[INFO] Hive Service ...................................... FAILURE [1:09.384s]\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive Llap External Client ......................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:03.670s\n[INFO] Finished at: Sun May 15 01:55:19 GMT 2016\n[INFO] Final Memory: 155M/1341M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-1\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal on project hive-service: Could not resolve dependencies for project org.apache.hive:hive-service:jar:2.1.0-SNAPSHOT: Failed to collect dependencies for [org.apache.hive:hive-exec:jar:2.1.0-SNAPSHOT (compile), org.apache.hive:hive-metastore:jar:2.1.0-SNAPSHOT (compile), org.apache.hive:hive-service-rpc:jar:2.1.0-SNAPSHOT (compile), org.apache.hive:hive-llap-server:jar:2.1.0-SNAPSHOT (compile), commons-codec:commons-codec:jar:1.4 (compile), commons-cli:commons-cli:jar:1.2 (compile), net.sf.jpam:jpam:jar:1.1 (compile), commons-lang:commons-lang:jar:2.6 (compile), org.eclipse.jetty.aggregate:jetty-all:jar:7.6.0.v20120127 (compile), tomcat:jasper-compiler:jar:5.5.23 (compile), tomcat:jasper-runtime:jar:5.5.23 (compile), org.apache.thrift:libfb303:jar:0.9.3 (compile), org.apache.thrift:libthrift:jar:0.9.3 (compile), org.apache.curator:curator-framework:jar:2.6.0 (compile), org.apache.curator:curator-recipes:jar:2.6.0 (compile), org.apache.hadoop:hadoop-common:jar:2.6.0 (compile?), org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.6.0 (compile?), org.jamon:jamon-runtime:jar:2.3.1 (compile), org.apache.hive:hive-exec:jar:tests:2.1.0-SNAPSHOT (test), org.apache.hive:hive-common:jar:tests:2.1.0-SNAPSHOT (test), junit:junit:jar:4.11 (test), org.apache.directory.client.ldap:ldap-client-api:jar:0.1 (test), org.apache.directory.server:apacheds-server-integ:jar:1.5.6 (test), org.apache.directory.server:apacheds-test-framework:jar:1.5.6 (test), org.slf4j:slf4j-api:jar:1.7.10 (compile)]: Failed to read artifact descriptor for org.apache.directory.client.ldap:ldap-client-api:jar:0.1-SNAPSHOT: Could not transfer artifact org.apache.directory.client.ldap:ldap-client-api:pom:0.1-SNAPSHOT from/to apache.snapshots (http://repository.apache.org/snapshots): Failed to transfer file: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/ldap-client-api-0.1-SNAPSHOT.pom. Return code is: 503 , ReasonPhrase:Service Unavailable. -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-service\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12803966 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-15T01:54:31.982+0000","updated":"2016-05-15T01:54:31.982+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15284844","id":"15284844","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Last build had issue with repository.apache.org.\n\nUpload patch 4 (same as patch 3).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-16T17:13:08.880+0000","updated":"2016-05-16T17:13:08.880+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15286393","id":"15286393","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12804208/HIVE-13730.4.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 82 failed/errored test(s), 10042 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-enforce_order.q-vector_partition_diff_num_cols.q-unionDistinct_1.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-groupby2.q-tez_dynpart_hashjoin_1.q-custom_input_output_format.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vectorization_16.q-vector_decimal_round.q-orc_merge6.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_tez_join_result_complex\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket5\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket6\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_disable_merge_for_bucketing\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_map_operators\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_num_buckets\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_list_bucket_dml_10\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge9\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge_diff_fs\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_reduce_deduplicate\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join0\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby5_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_map_ppr_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_innerjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input1_limit\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_alt_syntax\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_vc\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_mixed\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union33\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_16\norg.apache.hadoop.hive.llap.daemon.impl.TestLlapDaemonProtocolServerImpl.test\norg.apache.hadoop.hive.llap.daemon.impl.comparator.TestShortestJobFirstComparator.testWaitQueueComparatorWithinDagPriority\norg.apache.hadoop.hive.llap.tez.TestConverters.testFragmentSpecToTaskSpec\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote\norg.apache.hadoop.hive.metastore.TestFilterHooks.org.apache.hadoop.hive.metastore.TestFilterHooks\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreStatsMerge.testStatsMerge\norg.apache.hadoop.hive.metastore.TestMetaStoreEndFunctionListener.testEndFunctionListener\norg.apache.hadoop.hive.metastore.TestMetaStoreEventListenerOnlyOnCommit.testEventStatus\norg.apache.hadoop.hive.metastore.TestMetaStoreInitListener.testMetaStoreInitListener\norg.apache.hadoop.hive.metastore.TestMetaStoreMetrics.org.apache.hadoop.hive.metastore.TestMetaStoreMetrics\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAddPartitionWithValidPartVal\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAppendPartitionWithCommas\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAppendPartitionWithUnicode\norg.apache.hadoop.hive.metastore.TestPartitionNameWhitelistValidation.testAppendPartitionWithValidCharacters\norg.apache.hadoop.hive.metastore.TestRetryingHMSHandler.testRetryingHMSHandler\norg.apache.hadoop.hive.ql.security.TestClientSideAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestExtendedAcls.org.apache.hadoop.hive.ql.security.TestExtendedAcls\norg.apache.hadoop.hive.ql.security.TestFolderPermissions.org.apache.hadoop.hive.ql.security.TestFolderPermissions\norg.apache.hadoop.hive.ql.security.TestMetastoreAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener.org.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener\norg.apache.hadoop.hive.ql.security.TestStorageBasedClientSideAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.testDropPartition\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadDbFailure\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadDbSuccess\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadTableFailure\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testDelegationTokenSharedStore\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testMetastoreProxyUser\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testSaslWithHiveMetaStore\norg.apache.hive.hcatalog.listener.TestDbNotificationListener.cleanupNotifs\norg.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc.org.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc\norg.apache.hive.minikdc.TestJdbcWithDBTokenStore.org.apache.hive.minikdc.TestJdbcWithDBTokenStore\norg.apache.hive.service.TestHS2ImpersonationWithRemoteMS.org.apache.hive.service.TestHS2ImpersonationWithRemoteMS\norg.apache.hive.service.cli.session.TestHiveSessionImpl.testLeakOperationHandle\n{noformat}\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/305/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/305/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-305/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 82 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12804208 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-17T10:54:02.661+0000","updated":"2016-05-17T10:54:02.661+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15286958","id":"15286958","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Test failures are not related. [~vikram.dixit] Can you review please?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-17T16:31:42.955+0000","updated":"2016-05-17T16:31:42.955+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15289201","id":"15289201","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"We don't have a good run for TestMiniLlapCliDriver & for few batches of TestMiniTezCliDriver for few weeks now. Shall we disable this test, if this gonna take more time to review and commit? cc: [~vikram.dixit]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T16:03:39.150+0000","updated":"2016-05-18T16:03:39.150+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15289258","id":"15289258","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"I ran the three sets of tests that failed to produce TEST-*.xml files, as commented above by Hive QA. All of them passed locally. So Should have nothing to do with patch 4.\n{code}\nenforce_order.q,vector_partition_diff_num_cols.q,unionDistinct_1.q,tez_smb_empty.q,vectorized_timestamp.q,vectorized_rcfile_columnar.q,tez_dml.q,vector_join_nulls.q,delete_tmp_table.q,schema_evol_orc_nonvec_fetchwork_part.q,vectorization_part_varchar.q,load_dyn_part1.q,auto_sortmerge_join_3.q,vector_reduce_groupby_decimal.q,union_type_chk.q\n\ngroupby2.q,tez_dynpart_hashjoin_1.q,custom_input_output_format.q,schema_evol_orc_nonvec_fetchwork_table.q,schema_evol_orc_nonvec_mapwork_part_all_complex.q,tez_multi_union.q,vector_between_in.q,vector_char_4.q,dynamic_partition_pruning_2.q,vector_decimal_math_funcs.q,union7.q,vector_char_simple.q,auto_sortmerge_join_8.q,schema_evol_orc_nonvec_mapwork_table.q,merge2.q\n\nvectorization_16.q,vector_decimal_round.q,orc_merge6.q,vector_multi_insert.q,tez_union.q,vector_decimal_precision.q,alter_merge_2_orc.q,auto_sortmerge_join_14.q,vector_aggregate_9.q,vector_reduce1.q,vector_count_distinct.q,auto_join0.q,cross_join.q,vector_coalesce_2.q,vector_varchar_simple.q\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T16:32:42.136+0000","updated":"2016-05-18T16:32:42.136+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15289292","id":"15289292","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T16:46:17.745+0000","updated":"2016-05-18T16:46:17.745+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15289303","id":"15289303","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to master. Thanks Vikram for the review!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T16:52:36.503+0000","updated":"2016-05-18T16:52:36.503+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12967179/comment/15289834","id":"15289834","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"I just observed the Hive QA run difference before and after this patch was committed. It can be seen that this patch got rid of three sets of xml error mesages.\n\nBefore (HIVE-6131: \nhttps://issues.apache.org/jira/browse/HIVE-6131?focusedCommentId=15289556&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15289556)\n{code}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniLlapCliDriver - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-auto_sortmerge_join_7.q-orc_merge9.q-tez_union_dynamic_partition.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-join1.q-mapjoin_decimal.q-union5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-load_dyn_part2.q-selectDistinctStar.q-vector_decimal_5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-mapjoin_mapjoin.q-insert_into1.q-vector_decimal_2.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_distinct_2.q-tez_joins_explain.q-cte_mat_1.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_interval_2.q-schema_evol_text_nonvec_mapwork_part_all_primitive.q-tez_fsstat.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vectorized_parquet.q-insert_values_non_partitioned.q-schema_evol_orc_nonvec_mapwork_part.q-and-12-more - did not produce a TEST-*.xml file\n{code}\nAfter (HIVE-13750: https://issues.apache.org/jira/browse/HIVE-13750?focusedCommentId=15289795&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15289795)\n{code}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniLlapCliDriver - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-constprog_dpp.q-dynamic_partition_pruning.q-vectorization_10.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-order_null.q-vector_acid3.q-orc_merge10.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-tez_union_group_by.q-vector_auto_smb_mapjoin_14.q-union_fast_stats.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_coalesce.q-cbo_windowing.q-tez_join.q-and-12-more - did not produce a TEST-*.xml file\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T21:13:53.485+0000","updated":"2016-05-18T21:13:53.485+0000"}],"maxResults":18,"total":18,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-13730/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2xj7z:"}}