{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13042454","self":"https://issues.apache.org/jira/rest/api/2/issue/13042454","key":"HIVE-15887","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-02-13T03:19:38.555+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Feb 15 03:30:39 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15887/watchers","watchCount":3,"isWatching":false},"created":"2017-02-13T02:38:48.941+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-02-15T03:30:39.702+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12325007","id":"12325007","name":"Hive"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"when I run Hive queries on Spark, got below error in the console, after check the container's log, found it failed to connected to spark driver. I have set  hive.spark.job.monitor.timeout=3600s, so the log said 'Job hasn't been submitted after 3601s', actually during this long-time period it's impossible no available resource, and also did not see any issue related to the network, so the cause is not clear from the message \"Possible reasons include network issues, errors in remote driver or the cluster has no available resources, etc.\".\nFrom Hive's log, failed to get APP ID, so this might be the cause why the driver did not start up.\n\nconsole log:\nStarting Spark Job = e9ce42c8-ff20-4ac8-803f-7668678c2a00\nJob hasn't been submitted after 3601s. Aborting it.\nPossible reasons include network issues, errors in remote driver or the cluster has no available resources, etc.\nPlease check YARN or Spark driver's logs for further information.\nStatus: SENT\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.spark.SparkTask\n\ncontainer's log:\n\n17/02/13 05:05:54 INFO yarn.ApplicationMaster: Preparing Local resources\n17/02/13 05:05:54 INFO yarn.ApplicationMaster: Prepared Local resources Map(__spark_libs__ -> resource { scheme: \"hdfs\" host: \"hsx-node1\" port: 8020 file: \"/user/root/.sparkStaging/application_1486905599813_0046/__spark_libs__6842484649003444330.zip\" } size: 153484072 timestamp: 1486926551130 type: ARCHIVE visibility: PRIVATE, __spark_conf__ -> resource { scheme: \"hdfs\" host: \"hsx-node1\" port: 8020 file: \"/user/root/.sparkStaging/application_1486905599813_0046/__spark_conf__.zip\" } size: 116245 timestamp: 1486926551318 type: ARCHIVE visibility: PRIVATE)\n17/02/13 05:05:54 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1486905599813_0046_000002\n17/02/13 05:05:54 INFO spark.SecurityManager: Changing view acls to: root\n17/02/13 05:05:54 INFO spark.SecurityManager: Changing modify acls to: root\n17/02/13 05:05:54 INFO spark.SecurityManager: Changing view acls groups to: \n17/02/13 05:05:54 INFO spark.SecurityManager: Changing modify acls groups to: \n17/02/13 05:05:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n17/02/13 05:05:54 INFO yarn.ApplicationMaster: Waiting for Spark driver to be reachable.\n17/02/13 05:05:54 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:54 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:54 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:55 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:56 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:57 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:05:57 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n\n17/02/13 05:07:34 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:07:34 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:07:34 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:07:34 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.1.1:43656, retrying ...\n17/02/13 05:07:34 ERROR yarn.ApplicationMaster: Uncaught exception: \norg.apache.spark.SparkException: Failed to connect to driver!\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.waitForSparkDriver(ApplicationMaster.scala:569)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.runExecutorLauncher(ApplicationMaster.scala:405)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:247)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$main$1.apply$mcV$sp(ApplicationMaster.scala:749)\n\tat org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:71)\n\tat org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:70)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:70)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:747)\n\tat org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:774)\n\tat org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)\n17/02/13 05:07:34 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.SparkException: Failed to connect to driver!)\n17/02/13 05:07:34 INFO yarn.ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: org.apache.spark.SparkException: Failed to connect to driver!)\n17/02/13 05:07:34 INFO yarn.ApplicationMaster: Deleting staging directory hdfs://hsx-node1:8020/user/root/.sparkStaging/application_1486905599813_0046\n17/02/13 05:07:34 INFO util.ShutdownHookManager: Shutdown hook called\n\nhive's log:\n\n2017-02-13T03:10:01,639  INFO [stderr-redir-1] client.SparkClientImpl: 17/02/13 03:10:01 INFO yarn.Client: Application report for application_1486905599813_0046 (state: ACCEPTED)\n2017-02-13T03:10:06,640  INFO [stderr-redir-1] client.SparkClientImpl: 17/02/13 03:10:06 INFO yarn.Client: Application report for application_1486905599813_0046 (state: ACCEPTED)\n2017-02-13T03:10:08,176  WARN [c807cf48-301a-47b4-96df-495b2827d6ba main] impl.RemoteSparkJobStatus: Failed to get APP ID.\njava.util.concurrent.TimeoutException\n        at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:49) ~[netty-all-4.0.29.Final.jar:4.0.29.Final]\n        at org.apache.hadoop.hive.ql.exec.spark.status.impl.RemoteSparkJobStatus.getAppID(RemoteSparkJobStatus.java:65) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.exec.spark.SparkTask.execute(SparkTask.java:114) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2168) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1824) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1511) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1222) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1212) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:400) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:336) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:430) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:446) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:749) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:715) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:642) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_60]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_60]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_60]\n        at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_60]\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221) ~[hadoop-common-2.7.1.jar:?]\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136) ~[hadoop-common-2.7.1.jar:?]\n2017-02-13T03:10:11,641  INFO [stderr-redir-1] client.SparkClientImpl: 17/02/13 03:10:11 INFO yarn.Client: Application report for application_1486905599813_0046 (state: ACCEPTED)\n2017-02-13T03:10:16,643  INFO [stderr-redir-1] client.SparkClientImpl: 17/02/13 03:10:16 INFO yarn.Client: Application report for application_1486905599813_0046 (state: ACCEPTED)\n\n\n2017-02-13T04:11:07,354  INFO [stderr-redir-1] client.SparkClientImpl: 17/02/13 04:11:07 INFO yarn.Client: Application report for application_1486905599813_0046 (state: ACCEPTED)\n2017-02-13T04:11:09,706  WARN [c807cf48-301a-47b4-96df-495b2827d6ba main] impl.RemoteSparkJobStatus: Failed to get APP ID.\njava.util.concurrent.TimeoutException\n        at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:49) ~[netty-all-4.0.29.Final.jar:4.0.29.Final]\n        at org.apache.hadoop.hive.ql.exec.spark.status.impl.RemoteSparkJobStatus.getAppID(RemoteSparkJobStatus.java:65) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.exec.spark.SparkTask.execute(SparkTask.java:132) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2168) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1824) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1511) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1222) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1212) ~[hive-exec-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:400) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:336) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:430) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:446) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:749) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:715) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:642) ~[hive-cli-2.2.0-SNAPSHOT.jar:2.2.0-SNAPSHOT]\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_60]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_60]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_60]\n        at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_60]\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221) ~[hadoop-common-2.7.1.jar:?]\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136) ~[hadoop-common-2.7.1.jar:?]\n2017-02-13T04:11:09,719 ERROR [c807cf48-301a-47b4-96df-495b2827d6ba main] ql.Driver: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.spark.SparkTask\n2017-02-13T04:11:09,720  INFO [c807cf48-301a-47b4-96df-495b2827d6ba main] ql.Driver: Completed executing command(queryId=root_20170213030905_947e7eca-a134-4652-883c-10bded3c6218); Time taken: 3723.688 seconds\n2017-02-13T04:11:09,800  INFO [c807cf48-301a-47b4-96df-495b2827d6ba main] conf.HiveConf: Using the default value passed in for log id: c807cf48-301a-47b4-96df-495b2827d6ba\n2017-02-13T04:11:09,800  INFO [c807cf48-301a-47b4-96df-495b2827d6ba main] session.SessionState: Resetting thread name to  main\n2017-02-13T04:11:09,800  INFO [main] conf.HiveConf: Using the default value passed in for log id: c807cf48-301a-47b4-96df-495b2827d6ba\n2017-02-13T04:11:12,355  INFO [stderr-redir-1] client.SparkClientImpl: 17/02/13 04:11:12 INFO yarn.Client: Application report for application_1486905599813_0046 (state: ACCEPTED)\n2017-02-13T04:11:17,356  INFO [stderr-redir-1] client.SparkClientImpl: 17/02/13 04:11:17 INFO yarn.Client: Application report for application_1486905599813_0046 (state: ACCEPTED)\n2017-02-13T04:11:19,811  WARN [c807cf48-301a-47b4-96df-495b2827d6ba main] client.SparkClientImpl: Timed out shutting down remote driver, interrupting...\n2017-02-13T04:11:19,811  WARN [Driver] client.SparkClientImpl: Waiting thread interrupted, killing child process.\n2017-02-13T04:11:19,839  INFO [main] session.SessionState: Deleted directory: /tmp/hive/root/c807cf48-301a-47b4-96df-495b2827d6ba on fs with scheme hdfs\n2017-02-13T04:11:19,839  INFO [main] session.SessionState: Deleted directory: /tmp/root/c807cf48-301a-47b4-96df-495b2827d6ba on fs with scheme file","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"could not get APP ID and cause failed to connect to spark driver on yarn-client mode","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Hive2.2\nSpark2.0.2\nhadoop2.7.1","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15863160","id":"15863160","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~KaiXu], the failure is just a warning and it shouldn't make the query fail:\n{code}\n  @Override\n  public String getAppID() {\n    Future<String> getAppID = sparkClient.run(new GetAppIDJob());\n    try {\n      return getAppID.get(sparkClientTimeoutInSeconds, TimeUnit.SECONDS);\n    } catch (Exception e) {\n      LOG.warn(\"Failed to get APP ID.\", e);\n      return null;\n    }\n  }\n{code}\nPlease check your log again to find the real cause of the failure. Btw this has nothing to do with Spark and you don't need to log a Spark JIRA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-13T03:19:38.555+0000","updated":"2017-02-13T03:19:38.555+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15863605","id":"15863605","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks Rui Li for the information, the JIRA was first loged on Spark by mistake I have changed it to Hive.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-13T12:41:41.301+0000","updated":"2017-02-13T12:41:41.301+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15863645","id":"15863645","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Seems the application is ACCEPTED but didn't reach RUNNING. YARN log may be helpful to find out why the app hasn't launched.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-13T13:17:01.889+0000","updated":"2017-02-13T13:17:01.889+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15864837","id":"15864837","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~lirui], above container log is the yarn application log, the middle has been cut off for they're repeated \"Failed to connect to driver at 192.168.1.1:43656, retrying\".","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-14T01:27:34.484+0000","updated":"2017-02-14T01:27:34.484+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15864877","id":"15864877","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"From nodemanager log, can only see container transitioned from LOCALIZED to RUNNING, then failed with exitCode=10.\n\n2017-02-13 05:04:00,536 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://hsx-node1:8020/user/root/.sparkStaging/application_1486905599813_0046/__spark_libs__6842484649003444330.zip(->/mnt/disk6/yarn/nm/usercache/root/filecache/94/__spark_libs__6842484649003444330.zip) transitioned from DOWNLOADING to LOCALIZED\n2017-02-13 05:04:00,641 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://hsx-node1:8020/user/root/.sparkStaging/application_1486905599813_0046/__spark_conf__.zip(->/mnt/disk7/yarn/nm/usercache/root/filecache/95/__spark_conf__.zip) transitioned from DOWNLOADING to LOCALIZED\n2017-02-13 05:04:00,641 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1486905599813_0046_01_000001 transitioned from LOCALIZING to LOCALIZED\n2017-02-13 05:04:00,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1486905599813_0046_01_000001 transitioned from LOCALIZED to RUNNING\n2017-02-13 05:04:00,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Neither virutal-memory nor physical-memory monitoring is needed. Not running the monitor-thread\n2017-02-13 05:04:00,717 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /mnt/disk2/yarn/nm/usercache/root/appcache/application_1486905599813_0046/container_1486905599813_0046_01_000001/default_container_executor.sh]\n2017-02-13 05:04:03,304 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1486905599813_0047_000001 (auth:SIMPLE)\n\n2017-02-13 05:05:42,694 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1486905599813_0046_01_000001 is : 10\n2017-02-13 05:05:42,695 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exception from container-launch with container ID: container_1486905599813_0046_01_000001 and exit code: 10\nExitCodeException exitCode=10:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:545)\n        at org.apache.hadoop.util.Shell.run(Shell.java:456)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n2017-02-13 05:05:42,699 INFO org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor: Exception from container-launch.\n2017-02-13 05:05:42,699 INFO org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor: Container id: container_1486905599813_0046_01_000001\n2017-02-13 05:05:42,699 INFO org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor: Exit code: 10","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-14T02:01:47.154+0000","updated":"2017-02-14T02:01:47.154+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15864894","id":"15864894","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"this issue occurred again yesterday, to be notable, this issue occurred when dynamic allocation is as default(disabled).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-14T02:20:21.258+0000","updated":"2017-02-14T02:20:21.258+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15865384","id":"15865384","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"In the AM log, the \"failure to connect to driver\" happened around 5:05. According to Hive log, the query failed around 4:11 and the remote diver was killed. Does this mean the app runs after the job has failed on Hive side?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-14T08:55:11.359+0000","updated":"2017-02-14T08:55:11.359+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15865627","id":"15865627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"it seems like that, Hive side timeout after hive.spark.job.monitor.timeout, after that time yarn still tried to run the query but failed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-14T11:41:02.279+0000","updated":"2017-02-14T11:41:02.279+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042454/comment/15867150","id":"15867150","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"The symptom is quite similar to that of HIVE-12650. Is this a busy cluster?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-15T03:30:39.702+0000","updated":"2017-02-15T03:30:39.702+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15887/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i39z4v:"}}