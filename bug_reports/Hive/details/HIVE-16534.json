{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13066879","self":"https://issues.apache.org/jira/rest/api/2/issue/13066879","key":"HIVE-16534","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-04-26T00:24:39.285+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 22 23:58:14 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_512998088_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_84622117","customfield_12312321":null,"resolutiondate":"2017-05-02T20:54:23.834+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16534/watchers","watchCount":2,"isWatching":false},"created":"2017-04-25T22:54:03.737+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"7.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12502291","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12502291","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13068247","key":"HIVE-16565","self":"https://issues.apache.org/jira/rest/api/2/issue/13068247","fields":{"summary":"Improve how the open transactions and aborted transactions are deserialized in ValidReadTxnList.readFromString","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12504391","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12504391","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13074335","key":"HIVE-16743","self":"https://issues.apache.org/jira/rest/api/2/issue/13074335","fields":{"summary":"BitSet set() is incorrectly used in TxnUtils.createValidCompactTxnList()","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12501974","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12501974","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"13009340","key":"HIVE-14881","self":"https://issues.apache.org/jira/rest/api/2/issue/13009340","fields":{"summary":"integrate MM tables into ACID: merge cleaner into ACID threads ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-22T23:58:14.104+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12322671","id":"12322671","name":"Transactions","description":"Transaction management and ACID"}],"timeoriginalestimate":null,"description":"Currently in ValidReadTxnList, open transactions and aborted transactions are stored together in one array. That makes it impossible to extract just aborted transactions or open transactions.\n\nFor ValidCompactorTxnList this is fine, since we only store aborted transactions but no open transactions.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12865024","id":"12865024","filename":"HIVE-16534.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-25T23:10:11.204+0000","size":460794,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12865024/HIVE-16534.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12865429","id":"12865429","filename":"HIVE-16534.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-27T21:47:51.580+0000","size":471995,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12865429/HIVE-16534.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12865821","id":"12865821","filename":"HIVE-16534.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-01T21:24:39.474+0000","size":471502,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12865821/HIVE-16534.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12865830","id":"12865830","filename":"HIVE-16534.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-01T22:16:09.525+0000","size":471822,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12865830/HIVE-16534.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12865844","id":"12865844","filename":"HIVE-16534.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-01T23:46:56.931+0000","size":475927,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12865883","id":"12865883","filename":"HIVE-16534.6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-02T06:33:30.717+0000","size":475928,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12866005","id":"12866005","filename":"HIVE-16534.7.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-02T16:43:58.452+0000","size":477874,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12866005/HIVE-16534.7.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Add capability to tell aborted transactions apart from open transactions in ValidTxnList","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15983794","id":"15983794","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"[~ekoifman] Can you take a look at WIP patch 1?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-25T23:10:11.213+0000","updated":"2017-04-25T23:10:11.213+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15983882","id":"15983882","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"I think this needs some tests.  For example, \n_int index = Arrays.binarySearch(exceptions, txn);_should return -1 if txn is not found.\nwhich means _if (abortedBits.get(index)) {_ will fail with some ArrayIndexOutOfBounds or something\n\n\nValidReadTxnList.isTxnRangeAborted() is doing (maxTxnId-minTxnId) binary searches.  Why not just do 1 for minTxnId and then use nextSetBit(int fromIndex) to find next aborted txn and see if it equals minTxnId + 1, etc.\n\n\nAlso, you don't need to override isTxnRangeAborted() ValidCompactorTxnList.\n\nsome javadoc on new methods would be useful\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-26T00:24:39.285+0000","updated":"2017-04-26T00:24:39.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15985262","id":"15985262","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"For ValidReadTxnList.isTxnRangeAborted, I think I shouldn't have performed check for every txn in exceptions. Instead I should just scan every txn from min to max in the specified range, and for each of them, check if it's aborted by searching exceptions and the bitset. I corrected that. \n\nI think the override of isTxnRangeAborted in ValidCompactorTxnList is necessary. The reason is for ValidCompactorTxnList, \"exceptions\" includes aborted txns only (see TxnUtils.createValidCompactTxnList). So we don't maintain a bitset for it as it's not necessary. So in the implementation of that method we have a slight difference which is we omit the check against the bitset.\n\nI will add JavaDoc and tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-26T17:54:44.407+0000","updated":"2017-04-26T17:54:44.407+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15985284","id":"15985284","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"using nextSetBig() is also linear but faster for cases where not all txn are aborted; you'd still want to do Binary Search to find the minTxn in the exceptions list\nif there are no aborted txns, the BitSet is empty and \"abortedBits.get(index)\" is always false - that is why it's the same for both.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-26T18:07:18.376+0000","updated":"2017-04-26T18:07:18.376+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15985600","id":"15985600","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"OK, I agree the override for isTxnRangeAborted is not necessary. I also adopted the approach you suggested which is to use nextSetBit to check if an aborted transaction falls into the range between min and max.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-26T21:30:07.310+0000","updated":"2017-04-26T21:30:07.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15987768","id":"15987768","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"[~ekoifman] Can you take a look at patch 2?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-27T21:48:23.076+0000","updated":"2017-04-27T21:48:23.076+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15989172","id":"15989172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"you refactored ValidReadTxnList() c'tor and removed the sorting of exceptions - why?\nwriteToString() always creates 3 ':' - why does the deserializer need cases like _if (values.length < 3) {_\n\nwouldn't be simpler to just serialize the BitSet as \"0010110....\" - it's very compact and the deserializer wouldn't have to sort and do multiple binary searches.... \n\nwhy does _isTxnAborted()_ need a binary search?  why not just look up the in the bitset?\n\n_bitSet.set(0, bitSet.length()); // for ValidCompactorTxnList, everything in exceptio_ - shouldn't this turn all the bits ON?\nNit: seems like ValidCompactorTxnList() c'tor could do this  since it's always the case for compactor\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-28T17:15:18.513+0000","updated":"2017-04-28T17:16:23.795+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15989239","id":"15989239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"The sorting of exceptions in ValidReadTxnList is troublesome for the accompanying BitSet, as we have to sort the BitSet in the same manner. So I removed the sorting logic in the ctor and added \"oder by txn_id\" to TxnHandler.getOpenTxns so we don't need to worry about sorting later on.\n\nIt's true that we always have 3 ':'. But if some fields are missing, e.g. \"1:2::\", then String.split() will only return an array of size 2.\n\nI do serialize the BitSet into a byte array before sending it over Thrift interface. After receiving it I convert it back to BitSet since the bit manipulation is convenient.\n\nI need to binary search in isTxnAborted() to get the index for the txnid, then look up in the bitset using that index.\n\nbitSet.set(0, bitSet.length()) does turn all the bits on, right?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-28T18:00:03.705+0000","updated":"2017-04-28T18:00:03.705+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15989271","id":"15989271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"\nbq. I do serialize the BitSet into a byte array before sending it over Thrift interface. After receiving it I convert it back to BitSet since the bit manipulation is convenient.\n\nI meant in writeToString() - seems like that would make reading from string much simper/efficient\n\nYou are right about the other points","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-28T18:22:06.756+0000","updated":"2017-04-28T18:22:06.756+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15989294","id":"15989294","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"another thought: I think implementation of isTxnRangeAborted() is problematic\nsuppose we do an insert in Table1/part1 with txnid=5.  Then there is no activity on this table for a month.\nThen there is another insert into Table1/part1 with txnid=1000000.\nAfter compaction we get a delta_5_1000000.\n\nso now this method is going to do 1M binary searches....\n\nIf (isAborted(minTxnId) && isAborted(maxTxnId) && (the number of on bits in BitSet between index of minTxnId and maxTxnId is max - min + 1) - then all txns in range in question are aborted - this gives ALL\n\nI'm not sure how to do NONE/SOME efficiently","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-28T18:51:12.617+0000","updated":"2017-04-28T18:51:12.617+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15989305","id":"15989305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"We can drop this:\n{code}\n    while (txnId <= maxTxnId) {\n      firstAbortedTxnIndex = Arrays.binarySearch(exceptions, txnId);\n      if (firstAbortedTxnIndex >= 0) {\n        break;\n      }\n      txnId++;\n    }\n{code}\nThe main usage of above code is to locate the index for first aborted txn in the range so that we can save some unnecessary iterations when scanning the BitSet. But in your example which is very likely to be a common situation, this is not acceptable.\n\nConsidering the BitSet is not big (comparing to the gap between 5 and 1000000), we can just start from index 0 and scan thru the BitSet. I think this should be ok.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-28T19:04:19.670+0000","updated":"2017-04-28T19:04:19.670+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15991589","id":"15991589","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"patch 3 removes the binary search logic in isTxnRangeAborted as commented above.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-01T21:29:25.760+0000","updated":"2017-05-01T21:29:25.760+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15991638","id":"15991638","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 patch 3 pending tests\nCould you add a comment that the exception list is excepted the sorted when passed in ValidReadTxnList\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-01T21:58:55.971+0000","updated":"2017-05-01T21:58:55.971+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15991657","id":"15991657","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Added the comment for ValidTxnList.readFromString","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-01T22:16:09.533+0000","updated":"2017-05-01T22:16:09.533+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15991764","id":"15991764","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12865830/HIVE-16534.4.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4970/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4970/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4970/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-05-01 23:20:05.963\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4970/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-01 23:20:05.966\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 2f79bd6 HIVE-16520: Cache hive metadata in metastore (Daniel Dai, Vaibhav Gumashta, reviewed by Thejas Nair)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 2f79bd6 HIVE-16520: Cache hive metadata in metastore (Daniel Dai, Vaibhav Gumashta, reviewed by Thejas Nair)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-01 23:20:11.973\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: patch failed: metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp:6055\nerror: metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp: patch does not apply\nerror: patch failed: metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php:15489\nerror: metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php: patch does not apply\nerror: patch failed: metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java:51\nerror: metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java: patch does not apply\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12865830 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-01T23:20:13.337+0000","updated":"2017-05-01T23:20:13.337+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15991989","id":"15991989","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4974/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4974/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4974/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-05-02 02:03:35.278\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4974/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-02 02:03:35.280\n+ cd apache-github-source-source\n+ git fetch origin\nFrom https://github.com/apache/hive\n   62fbdd8..5ab03cb  master     -> origin/master\n+ git reset --hard HEAD\nHEAD is now at 62fbdd8 Add license and notice file for storage-api\n+ git clean -f -d\nRemoving metastore/scripts/upgrade/derby/040-HIVE-16399.derby.sql\nRemoving metastore/scripts/upgrade/mssql/025-HIVE-16399.mssql.sql\nRemoving metastore/scripts/upgrade/mysql/040-HIVE-16399.mysql.sql\nRemoving metastore/scripts/upgrade/oracle/040-HIVE-16399.oracle.sql\nRemoving metastore/scripts/upgrade/postgres/039-HIVE-16399.postgres.sql\n+ git checkout master\nAlready on 'master'\nYour branch is behind 'origin/master' by 2 commits, and can be fast-forwarded.\n  (use \"git pull\" to update your local branch)\n+ git reset --hard origin/master\nHEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-02 02:03:40.406\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file common/src/java/org/apache/hadoop/hive/common/ValidCompactorTxnList.java\npatching file common/src/java/org/apache/hadoop/hive/common/ValidReadTxnList.java\npatching file common/src/java/org/apache/hadoop/hive/common/ValidTxnList.java\npatching file common/src/test/org/apache/hadoop/hive/common/TestValidReadTxnList.java\npatching file itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java\npatching file metastore/if/hive_metastore.thrift\npatching file metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp\npatching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp\npatching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h\npatching file metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetOpenTxnsResponse.java\npatching file metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php\npatching file metastore/src/gen/thrift/gen-php/metastore/Types.php\npatching file metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py\npatching file metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb\npatching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\npatching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java\npatching file metastore/src/test/org/apache/hadoop/hive/metastore/txn/TestValidCompactorTxnList.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-common: Compilation failure\n[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-common\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12865844 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-02T02:04:03.928+0000","updated":"2017-05-02T02:04:03.928+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15991995","id":"15991995","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4977/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4977/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4977/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-05-02 02:07:19.555\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4977/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-02 02:07:19.557\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)\n+ git clean -f -d\nRemoving metastore/scripts/upgrade/hive/\nRemoving ql/src/test/queries/clientpositive/sysdb.q\nRemoving ql/src/test/results/clientpositive/llap/sysdb.q.out\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-02 02:07:20.082\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file common/src/java/org/apache/hadoop/hive/common/ValidCompactorTxnList.java\npatching file common/src/java/org/apache/hadoop/hive/common/ValidReadTxnList.java\npatching file common/src/java/org/apache/hadoop/hive/common/ValidTxnList.java\npatching file common/src/test/org/apache/hadoop/hive/common/TestValidReadTxnList.java\npatching file itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java\npatching file metastore/if/hive_metastore.thrift\npatching file metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp\npatching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp\npatching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h\npatching file metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetOpenTxnsResponse.java\npatching file metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php\npatching file metastore/src/gen/thrift/gen-php/metastore/Types.php\npatching file metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py\npatching file metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb\npatching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\npatching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java\npatching file metastore/src/test/org/apache/hadoop/hive/metastore/txn/TestValidCompactorTxnList.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-common: Compilation failure\n[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-common\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12865844 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-02T02:07:36.945+0000","updated":"2017-05-02T02:07:36.945+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15992283","id":"15992283","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch\n\n{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 257 failed/errored test(s), 10634 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_join] (batchId=15)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_mapjoin] (batchId=10)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_partition] (batchId=68)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_project] (batchId=18)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_delete] (batchId=77)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_delete_own_table] (batchId=62)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_update] (batchId=8)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_update_own_table] (batchId=73)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=48)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_no_match] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_acid_dynamic_partition] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_nonacid_from_acid] (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_orig_table] (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=71)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table] (batchId=54)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=59)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_partitioned] (batchId=71)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_tmp_table] (batchId=4)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_reader] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_exception] (batchId=32)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=73)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[transform_acid] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=64)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=68)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_no_match] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_acid3] (batchId=26)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_join_part_col_char] (batchId=22)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_dynamic] (batchId=163)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_static] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=137)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_globallimit] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_vectorization_missing_cols] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_no_match] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_orig_table] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_partitioned] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_tmp_table] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_no_match] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_acid3] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=96)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=96)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=96)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=96)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join_part_col_char] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[acid_overwrite] (batchId=88)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testOpenTxnNotExcluded (batchId=209)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxns (batchId=209)\norg.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testMarkCleanedCleansTxnsAndTxnComponents (batchId=244)\norg.apache.hadoop.hive.metastore.txn.TestTxnHandler.testAbortTxn (batchId=244)\norg.apache.hadoop.hive.metastore.txn.TestTxnHandler.testOpenTxn (batchId=244)\norg.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsEmpty (batchId=244)\norg.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsNoneOpen (batchId=244)\norg.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsSomeOpen (batchId=244)\norg.apache.hadoop.hive.metastore.txn.TestTxnHandlerNoConnectionPool.testOpenTxn (batchId=244)\norg.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnMR (batchId=210)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnTez (batchId=210)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnMR (batchId=210)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnTez (batchId=210)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnMR (batchId=213)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnTez (batchId=213)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnMR (batchId=213)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnTez (batchId=213)\norg.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testErrors (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeCardinalityViolation (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeCase (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testQuotedIdentifier (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testQuotedIdentifier2 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testTimeOutReaper (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testAlterTable (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testFailHeartbeater (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testFileSystemUnCaching (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testInitiatorWithMultipleFailedCompactions (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsertStatement (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNoHistory (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1 (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testSimpleRead (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=265)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAcidWithSchemaEvolution (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAlterTable (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testBucketizedInputFormat (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testETLSplitStrategyForACID (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFailHeartbeater (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFileSystemUnCaching (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testInitiatorWithMultipleFailedCompactions (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsertStatement (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNoHistory (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion1 (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testSimpleRead (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=275)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAcidWithSchemaEvolution (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAlterTable (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testBucketizedInputFormat (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testETLSplitStrategyForACID (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFailHeartbeater (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFileSystemUnCaching (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testInitiatorWithMultipleFailedCompactions (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertStatement (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNoHistory (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion1 (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testSimpleRead (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=272)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=272)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.checkExpectedLocks2 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testCompletedTxnComponents (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testDynamicPartitionInsert (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way01 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way02 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned01 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned02 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned01 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned02 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMetastoreTablesCleanup (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMultiInsert (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking10 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking11 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking5 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking7 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking8 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking9 (batchId=276)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.updateSelectUpdate (batchId=276)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningInsert (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithOnlyInserts (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testTableProperties (batchId=211)\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.cleanEmptyAbortedTxns (batchId=253)\norg.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=187)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=187)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=187)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=187)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=187)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=187)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=187)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4982/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4982/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4982/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 257 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12865844 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-02T03:32:51.950+0000","updated":"2017-05-02T03:32:51.950+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15992486","id":"15992486","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch\n\n{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10635 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)\norg.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4987/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4987/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4987/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 5 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12865883 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-02T07:30:41.659+0000","updated":"2017-05-02T07:30:41.659+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15993311","id":"15993311","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch\n\n{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10637 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)\norg.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4998/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4998/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4998/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 5 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12865883 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-02T17:22:15.815+0000","updated":"2017-05-02T17:22:15.815+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15993538","id":"15993538","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12866005/HIVE-16534.7.patch\n\n{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10637 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_windowing2] (batchId=10)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5000/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5000/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5000/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 3 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12866005 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-02T19:12:53.656+0000","updated":"2017-05-02T19:12:53.656+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/15993724","id":"15993724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed patch 7 to master. Thanks Eugene for the review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wzheng","name":"wzheng","key":"wzheng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Zheng","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-02T20:54:23.929+0000","updated":"2017-05-02T20:54:23.929+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13066879/comment/16485913","id":"16485913","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"body":"Hive 3.0.0 has been released so closing this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-22T23:58:14.100+0000","updated":"2018-05-22T23:58:14.100+0000"}],"maxResults":23,"total":23,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16534/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3e3nj:"}}