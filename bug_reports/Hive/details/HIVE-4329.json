{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12641836","self":"https://issues.apache.org/jira/rest/api/2/issue/12641836","key":"HIVE-4329","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-10-16T21:25:31.565+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Nov 03 04:05:04 UTC 2014","customfield_12310420":"322251","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-4329/watchers","watchCount":22,"isWatching":false},"created":"2013-04-10T13:25:59.119+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326450","id":"12326450","description":"released","name":"0.14.0","archived":false,"released":true,"releaseDate":"2014-11-12"}],"issuelinks":[{"id":"12400250","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12400250","type":{"id":"10020","name":"Cloners","inward":"is cloned by","outward":"is a clone of","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10020"},"inwardIssue":{"id":"12752081","key":"HIVE-8687","self":"https://issues.apache.org/jira/rest/api/2/issue/12752081","fields":{"summary":"Support Avro through HCatalog","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12392895","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12392895","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12729500","key":"HIVE-7502","self":"https://issues.apache.org/jira/rest/api/2/issue/12729500","fields":{"summary":"Writes to parquet tables via HCatalog fail with \"java.lang.RuntimeException: Should never be used\".","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12394912","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12394912","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12736158","key":"HIVE-7855","self":"https://issues.apache.org/jira/rest/api/2/issue/12736158","fields":{"summary":"Invalid partition values specified when writing to static partitioned tables via HCatalog","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12401184","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12401184","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12754821","key":"HIVE-8838","self":"https://issues.apache.org/jira/rest/api/2/issue/12754821","fields":{"summary":"Support Parquet through HCatalog","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12398359","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12398359","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12741673","key":"HIVE-8120","self":"https://issues.apache.org/jira/rest/api/2/issue/12741673","fields":{"summary":"Umbrella JIRA tracking Parquet improvements","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12391933","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12391933","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12723510","key":"HIVE-7286","self":"https://issues.apache.org/jira/rest/api/2/issue/12723510","fields":{"summary":"Parameterize HCatMapReduceTest for testing against all Hive storage formats","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-11-12T18:03:28.218+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320409","id":"12320409","name":"HCatalog","description":"Tracks issues related to the HCatalog"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312585","id":"12312585","name":"Serializers/Deserializers","description":"Tracks issues dealing with serdes"}],"timeoriginalestimate":null,"description":"Attempting to write to a HCatalog defined table backed by the AvroSerde fails with the following stacktrace:\n\n{code}\njava.lang.ClassCastException: org.apache.hadoop.io.NullWritable cannot be cast to org.apache.hadoop.io.LongWritable\n\tat org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat$1.write(AvroContainerOutputFormat.java:84)\n\tat org.apache.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:253)\n\tat org.apache.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:53)\n\tat org.apache.hcatalog.pig.HCatBaseStorer.putNext(HCatBaseStorer.java:242)\n\tat org.apache.hcatalog.pig.HCatStorer.putNext(HCatStorer.java:52)\n\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:139)\n\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:98)\n\tat org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:559)\n\tat org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:85)\n{code}\n\nThe proximal cause of this failure is that the AvroContainerOutputFormat's signature mandates a LongWritable key and HCat's FileRecordWriterContainer forces a NullWritable. I'm not sure of a general fix, other than redefining HiveOutputFormat to mandate a WritableComparable.\n\nIt looks like accepting WritableComparable is what's done in the other Hive OutputFormats, and there's no reason AvroContainerOutputFormat couldn't also be changed, since it's ignoring the key. That way fixing things so FileRecordWriterContainer can always use NullWritable could get spun into a different issue?\n\nThe underlying cause for failure to write to AvroSerde tables is that AvroContainerOutputFormat doesn't meaningfully implement getRecordWriter, so fixing the above will just push the failure into the placeholder RecordWriter.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12658803","id":"12658803","filename":"HIVE-4329.0.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T00:54:07.252+0000","size":67545,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12658803/HIVE-4329.0.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12665095","id":"12665095","filename":"HIVE-4329.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-28T21:52:34.942+0000","size":94249,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12665095/HIVE-4329.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12665097","id":"12665097","filename":"HIVE-4329.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-28T21:56:08.310+0000","size":92721,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12665097/HIVE-4329.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12665137","id":"12665137","filename":"HIVE-4329.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-28T22:51:29.808+0000","size":92636,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12665137/HIVE-4329.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12673066","id":"12673066","filename":"HIVE-4329.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-06T08:03:56.419+0000","size":118551,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12673066/HIVE-4329.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12678086","id":"12678086","filename":"HIVE-4329.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-30T01:10:25.287+0000","size":115552,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12678086/HIVE-4329.5.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"322596","customfield_12312823":null,"summary":"HCatalog should use getHiveRecordWriter rather than getRecordWriter","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=busbey","name":"busbey","key":"busbey","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=busbey&avatarId=13233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=busbey&avatarId=13233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=busbey&avatarId=13233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=busbey&avatarId=13233"},"displayName":"Sean Busbey","active":true,"timeZone":"America/Chicago"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=busbey","name":"busbey","key":"busbey","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=busbey&avatarId=13233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=busbey&avatarId=13233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=busbey&avatarId=13233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=busbey&avatarId=13233"},"displayName":"Sean Busbey","active":true,"timeZone":"America/Chicago"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"discovered in Pig, but it looks like the root cause impacts all non-Hive users","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/13797271","id":"13797271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=akrylov","name":"akrylov","key":"akrylov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexey Krylov","active":true,"timeZone":"America/New_York"},"body":"I can confirm that this applies to a MapReduce job writing HCat records to an Avro-backed table using HCatalog. \n{code}\njava.lang.ClassCastException: org.apache.hadoop.io.NullWritable cannot be cast to org.apache.hadoop.io.LongWritable\n        at org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat$1.write(AvroContainerOutputFormat.java:84)\n        at org.apache.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:257)\n        at org.apache.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:53)\n        at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:639)\n        at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=akrylov","name":"akrylov","key":"akrylov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexey Krylov","active":true,"timeZone":"America/New_York"},"created":"2013-10-16T21:25:31.565+0000","updated":"2013-10-16T21:25:31.565+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/13955594","id":"13955594","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"I am running into this issue as well. If no one is currently working on this ticket, I would like to pick it up.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-31T19:54:14.752+0000","updated":"2014-03-31T19:54:14.752+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/13955736","id":"13955736","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=busbey","name":"busbey","key":"busbey","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=busbey&avatarId=13233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=busbey&avatarId=13233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=busbey&avatarId=13233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=busbey&avatarId=13233"},"displayName":"Sean Busbey","active":true,"timeZone":"America/Chicago"},"body":"I don't think anyone's working on it. I'd be happy to review once you post a patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=busbey","name":"busbey","key":"busbey","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=busbey&avatarId=13233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=busbey&avatarId=13233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=busbey&avatarId=13233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=busbey&avatarId=13233"},"displayName":"Sean Busbey","active":true,"timeZone":"America/Chicago"},"created":"2014-03-31T21:24:54.787+0000","updated":"2014-03-31T21:24:54.787+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/13957201","id":"13957201","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the correct fix for this is that HCatalog should be calling the {{OutputFormat}}s' {{getHiveRecordWriter}} rather than {{getRecordWriter}}. Since the purpose of HCatalog is to provide read and write interfaces and the Hive Metastore's services to non-Hive clients, existing SerDes should work out of the box.\n\nFixing it this way will also allow other SerDes, such as Parquet, to work with HCatalog as well since the ParquetSerDe currently has the same problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-02T00:53:41.715+0000","updated":"2014-04-02T00:53:41.715+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/13999308","id":"13999308","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"If I understand correctly, it seems that this change will end up being quite extensive. HCatalog is currently using {{org.apache.hadoop.mapred.OutputFormat}} everywhere. It seems that in order to have HCatalog properly use Hive's write facilities, we would have to change HCatalog to use HiveOutputFormat rathjer than the Hadoop OutputFormat.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-05-15T22:05:16.247+0000","updated":"2014-05-15T22:05:16.247+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14068160","id":"14068160","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"The test coverage for this patch will be covered by running the HCatMapReduce tests against AvroSerDe and ParquetHiveSerDe. As a result, this ticket depends on HIVE-7286.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-21T03:40:12.607+0000","updated":"2014-07-21T03:40:12.607+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14078537","id":"14078537","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"I think I am close to getting this to work. Writing to Parquet seems to now be working for everything except for external tables. I am fairly certain that the reason why Avro is still not working is due to a table property for the Avro schema being missing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-29T22:48:57.936+0000","updated":"2014-07-29T22:48:57.936+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14078586","id":"14078586","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Correction: Parquet is working for everything except tables with static partitioning. I am pretty sure the root cause has to do with missing table properties.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-29T23:19:34.919+0000","updated":"2014-07-29T23:19:34.919+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14078723","id":"14078723","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"After fixing a {{NullPointerException}} in {{AvroSerDe.initialize}}, HCatalog is now calling {{AvroContainerOutputFormat.getHiveRecordWriter}}. However, {{AvroContainerOutputFormat}} is complaining that: {{Neither avro.schema.literal nor avro.schema.url specified, can't determine table schema}}.\n\nI will check whether this should have been covered by HIVE-6806, but in any case, this should not be a difficult fix.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-30T00:57:56.082+0000","updated":"2014-07-30T00:57:56.082+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14080323","id":"14080323","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Writing via HCatalog is now working for both Avro and Parquet Serdes for everything except static partitioning. For static partitioning, there is a mismatch between the expected schema and the schema set in the table properties due the partition column not being present; I am looking into this problem right now.\n\nI am uploading a patch for initial review and to run through pre-commit tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T00:54:07.256+0000","updated":"2014-07-31T00:54:07.256+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14080326","id":"14080326","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"RB: https://reviews.apache.org/r/24136","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T00:55:17.050+0000","updated":"2014-07-31T00:55:17.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14080338","id":"14080338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Some notes about this patch:\n\n * {{\\*OutputFormatContainer}} classes now wrap a {{HiveOutputFormat}} rather than a mapred {{OutputFormat}}.\n * {{\\*RecordWriterContainer}} classes now wrap a {{FileSinkOperator.RecordWriter}} rather than a mapred {{RecordWriter}}.\n * {{InternalUtil.initializeOutputSerDe}} and {{InternalUtil.initializeDeserializer}} now take the properties from the {{TableDesc}} created from the table contained in {{HCatTableInfo}} rather than creating the properties manually. As a result, {{InternalUtil.setSerDeProperties}} has been removed.\n * Fixed a {{NullPointerException}} in {{AvroSerDe.initialize}} that occurrs if {{columnCommentProperty}} is null.\n\nTest coverage:\n\n * Remove disabled Serde list from {{HCatMapReduceTest}} so that all {{HCatMapReduceTest}} suites are also run against {{AvroSerDe}} and {{ParquetHiveSerDe}}\n\nTo do:\n\n * Fix case where static partitioning is used.\n * Clean up if necessary\n * Remove diagnostic print statements.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T01:05:46.372+0000","updated":"2014-07-31T01:05:46.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14080666","id":"14080666","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12658803/HIVE-4329.0.patch\n\n{color:red}ERROR:{color} -1 due to 21 failed/errored test(s), 5868 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[0]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[1]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[2]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[5]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[6]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[0]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[1]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[2]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[5]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[6]\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[0]\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[1]\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[2]\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[5]\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[6]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/117/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/117/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-117/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 21 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12658803","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-07-31T09:01:57.459+0000","updated":"2014-07-31T09:01:57.459+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14099257","id":"14099257","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi,\n\nI'm against the goal of this patch requirement altogether, and this patch effectively breaks one of the core reasons for the existence of HCatalog, to be a generic wrapper for underlying mapreduce IF/OFs, for consumers that expect mapreduce IF/OFs. I apologize for not having spotted this jira earlier, since it seems a lot of work has gone into this, and I understand that there is an impedance mismatch here between HiveOutputFormat and OutputFormat, and one we want to fix, but this fix is in the opposite direction of the desired way of solving that impedance mismatch.\n\nOne of the longer term goals, for us, has been to try to evolve Hive's usage of StorageHandlers to a point where Hive stops using HiveRecordWriter/HiveOutputFormat altogether, so that there is no notion of an \"internal\" and \"external\" OutputFormat definition, so that third party mapreduce IF/OFs can directly be integrated into Hive, instead of having to change them to HiveOutputFormat/etc.\n\nThe primary issue discussed in this problem, that of FileRecordWriterContainer writing out a NullComparable is something that's solvable, since FileRecordWritableContainer's key format is a WritableComparable, and if AvroContainerOutputFormat does not already care about the key anyway, we should be ignoring it. If it's simpler, I would also be in favour of a hack like the FileRecordWriterContainer emiting a LongWritable in that case if it detects it's wrapping an AvroContainerOutputFormat instead of rewiring HCatalog to make it based on HiveOutputFormat.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-15T22:13:31.873+0000","updated":"2014-08-15T22:13:31.873+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14099343","id":"14099343","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Sushanth,\n\nThank you for taking a look at this ticket.\n\nI agree that it would be ideal to get Hive to a point where a unified StorageHandler interface can replace the current use of HiveOutputFormat and FileSinkOperator.RecordWriter (which should really be named HiveRecordWriter). However, that is a larger, more long-term undertaking whereas this ticket is to fix the fact that it is currently not possible to write using HCatalog for storage formats whose (Hive)OutputFormats that only implement getHiveRecordWriter and not getRecordWriter.\n\nThe new tests I added as part of HIVE-7286 have demonstrated that only solving the type compatibility issue mentioned earlier in this ticket is not sufficient. The type error for AvroContainerOutputFormat masks the real issue which is that AvroContainerOutputFormat's getRecordWriter (as with ParquetHiveOutputFormat's) does nothing but throws an exception, which says that \"this method should not be called.\"\n\nThis is why my fix for this issue is taking this approach, which is based on the approach taken by core Hive. To my understanding, Hive accepts both MR OutputFormats as well as HiveOutputFormats but ends up calling getHiveRecordWriter in both cases. For the case of MR OutputFormats, Hive detects that it is not a HiveOutputFormat and wraps it using HivePassThroughOutputFormat.\n\nMy understanding is that your main concern is that this patch may be turning HCatOutputFormat into a HiveOutputFormat. However, this is not the case. This patch does not change the HCatalog interface; it changes the way that HCatOutputFormat wraps the underlying OutputFormat so that it can properly handle HiveOutputFormats, which is required to make it possible to write using HCatalog for Avro and Parquet.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-15T23:33:46.011+0000","updated":"2014-08-15T23:33:46.011+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14099374","id":"14099374","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi David,\n\nYour patch uses HiveFileFormatUtils.getOutputFormatSubstitute to determine the underlying HiveOutputFormat substitute for the underlying OutputFormat, which is the route taken by core hive to take both MR OutputFormats and HiveOutputFormats. Unfortunately, this will not work, because that simply fetches a substitute HiveOutputFormat from a map of substitutes, which contain substitutes for only IgnoreKeyTextOutputFormat and SequenceFileOutputFormat. \n\nAlthough Hive's interface seems to allow any OF, it in reality accepts only these 2 apart from those that are specifically HiveOutputFormats. Thus, your call to that function will simply return null for mapreduce OutputFormats that are not HiveOutputFormats and are not the above two formats, and effectively does break runtime backward compatibility, even if not breaking compiletime backward compatibility.\n\nIf your patch were so that it fetches an underlying HiveOutputFormat, and if it were a HiveOutputFormat, using getHiveRecordWriter, and if it were not, using getRecordWriter, that solution would not break runtime backward compatibility, and would be acceptable - I tried something on that line over at https://issues.apache.org/jira/browse/HIVE-4524 (which wasn't eventually committed, because that problem was solved from the HBaseStorageHandler end rather than solving it from HCat's end) if you'd like to look at that. I think that might be a better way of solving the base issue of HiveOutputFormats not working from within HCatalog.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-16T00:07:44.767+0000","updated":"2014-08-16T00:07:44.767+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14114530","id":"14114530","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Sushanth,\n\nI really appreciate you taking your time to look at this patch and for your tips. However, I am still a bit unclear about some of the concerns you mentioned.\n\nbq. Unfortunately, this will not work, because that simply fetches a substitute HiveOutputFormat from a map of substitutes, which contain substitutes for only IgnoreKeyTextOutputFormat and SequenceFileOutputFormat.\n\nFrom my understanding, {{HivePassThroughOutputFormat}} was introduced in order to support generic OutputFormats and not just {{HiveOutputFormat}}. According to {{[HiveFileFormatUtils. getOutputFormatSubstitute|https://github.com/apache/hive/blob/b8250ac2f30539f6b23ce80a20a9e338d3d31458/ql/src/java/org/apache/hadoop/hive/ql/io/HiveFileFormatUtils.java]}}, {{HivePassThroughOutputFormat}} is returned if the {{OutputFormat}} does not exist in the map but only if it is called with {{storageHandlerFlag = true}}. From [searching the codebase|https://github.com/apache/hive/search?utf8=%E2%9C%93&q=getOutputFormatSubstitute&type=Code], the only place where {{getOutputFormatSubstitute}} could be called with {{storageHandlerFlag}} set to true is in {{Table.getOutputFormatClass}} and if the {{storage_handler}} property is set.\n\nAs a result, I changed my patch to retrieve the {{OutputFormat}} class using {{Table.getOutputFormatClass}} so that HCatalog would follow the same codepath as Hive proper for getting the {{OutputFormat}}. Does this address your concern?\n\nbq. If your patch were so that it fetches an underlying HiveOutputFormat, and if it were a HiveOutputFormat, using getHiveRecordWriter, and if it were not, using getRecordWriter, that solution would not break runtime backward compatibility, and would be acceptable\n\nI tried this approach, but I think that it is cleaner to change {{OutputFormatContainer}} and {{RecordWriterContainer}} to wrap the Hive implementations ({{HiveOutputFormat}} and {{FileSinkOperator.RecordWriter}}) rather than introduce yet another set of wrappers. After all, Hive already has a mechanism for supporting both Hive OFs and MR OFs by wrapping MR OFs with {{HivePassThroughOutputFormat}}, and I think that HCatalog should evolve to share more common infrastructure with Hive.\n\nI have attached a new revision of my patch that now fixes the original reason why this ticket is opened; writing to an Avro table via HCatalog now works. There are still a few remaining issues though:\n\n * The way that tables with static partitioning is handled is not completely correct. I have opened HIVE-7855 to address that issue.\n * Writing to a Parquet table does not work but more investigation is needed to determine whether this is caused by a bug in HCatalog or in the Parquet SerDe.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-28T22:50:26.078+0000","updated":"2014-08-28T22:50:26.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14114837","id":"14114837","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12665137/HIVE-4329.3.patch\n\n{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 6153 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_8\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization\norg.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation\norg.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.testHCatDynamicPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatExternalDynamicCustomLocation[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned.testHCatNonPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.testHCatDynamicPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned.testHCatNonPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.testHCatPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned.testHCatNonPartitionedTable[4]\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable[4]\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/550/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/550/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-550/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 17 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12665137","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-08-29T04:30:12.008+0000","updated":"2014-08-29T04:30:12.008+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14118836","id":"14118836","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi David, making a change to PassThroughOutputFormat so that that gets used does theoretically solve my concern on why the previous patch wouldn't work. At this point, I'll retract my objections, and I'll tag [~ashutoshc], [~alangates] or [~mithun] to see if any of them want to review your patch to get it in, since it is useful and does introduce some much needed functionality. (One note, we should add a simple test case, maybe by making another DummyIF/DummyOF that composes a TextIF/TextOF, and add tests to see if that works clearly with your change.)\n\nI will personally recuse myself from this, however, because while I'm completely agreed that Hive and HCatalog should use the same code to do I/O, I do still disagree with the direction of the change. HivePassThroughOutputFormat itself was intended to be a stopgap till we could fix Hive I/O to work off a generic M/R IF/OF and get rid of HIF/HOF.\n\n[~ashutoshc], [~alangates], [~mithun] : Could any of you please have a look at this jira and take on reviewing this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-02T22:19:26.837+0000","updated":"2014-09-02T22:19:26.837+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14119055","id":"14119055","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you for your feedback, Sushanth.\n\nbq. One note, we should add a simple test case, maybe by making another DummyIF/DummyOF that composes a TextIF/TextOF, and add tests to see if that works clearly with your change.\n\nAgreed. That should not be difficult to add given the test fixture I added with HIVE-7286. I will add that test.\n\nbq. HivePassThroughOutputFormat itself was intended to be a stopgap till we could fix Hive I/O to work off a generic M/R IF/OF and get rid of HIF/HOF\n\nI also agree that {{HivePassThroughOutputFormat}} seems like a stopgap. Is there a JIRA ticket opened to discuss whether HIF/HOF should be deprecated in favor of MR IF/OF?\n\n----\n\nBefore this patch is committed, I would like to make a few more changes to the tests, including adding Sushanth's suggestion above. I would like to make use of some code I added as part of HIVE-7420 for disabling specific test methods for storage formats. Thus, HIVE-7457 and HIVE-7420 should be committed before this patch. Can someone please take a look at those patches as well?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-03T00:31:44.652+0000","updated":"2014-09-03T00:31:44.652+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14160088","id":"14160088","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Attaching a new patch rebased on master, incorporating the test utils from HIVE-7286 to disable specific test methods for given storage formats.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=davidzchen","name":"davidzchen","key":"davidzchen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-06T08:03:56.441+0000","updated":"2014-10-06T08:03:56.441+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14160352","id":"14160352","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12673066/HIVE-4329.4.patch\n\n{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 6563 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1131/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1131/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1131/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 1 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12673066","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-10-06T14:42:58.409+0000","updated":"2014-10-06T14:42:58.409+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14164575","id":"14164575","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"Could you open a follow-on ticket for the parquet static partitioning issue and link it to HIVE-8120?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-09T01:56:24.964+0000","updated":"2014-10-09T01:56:24.964+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14186212","id":"14186212","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for 0.14","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-28T01:52:09.697+0000","updated":"2014-10-28T01:52:09.697+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14189372","id":"14189372","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"This patch needs a small rebase. I have it done and will upload. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-30T00:23:58.687+0000","updated":"2014-10-30T00:23:58.687+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14189764","id":"14189764","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12678086/HIVE-4329.5.patch\n\n{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 6614 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation\norg.apache.hive.minikdc.TestJdbcWithMiniKdc.testNegativeTokenAuth\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1548/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1548/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1548/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 2 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12678086 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-10-30T07:56:18.610+0000","updated":"2014-10-30T07:56:18.610+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14189838","id":"14189838","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Despite my initial reservations on approach, I've been trying to extend and make this patch work and get it in 0.14 because the functionality it introduces is important.  Last week, I'd pinged Vikram to get it okayed for 0.14. However, as of this time, on reviewing and debugging, this patch is still incomplete. \n\nThe test failure from org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation reported above is because this does not call FileSinkOperator.checkOutputSpecs, which thus, does not wind up populating the \"actualOutputFormat\", and thus, PassthroughOutputFormat thinks its underlying OutputFormat is null. Also, it's not a simple matter of simply calling that function, since that function depends on the FileSinkOperator having been instantiated, and having a TableDesc in its context. That, at least, is fixable, since HCatalog does have access to a TableDesc, in which case, HCatalog will then need to do some detection to see if the underlying OF is a PassthroughOutputFormat, and if so, then will need to instantiate PassthroughOutputFormat appropriately by calling a refactored FileSinkOperator.checkOutputSpecs that does not require the Operator itself.\n\nThis currently still breaks the traditional M/R OutputFormat usage under HCatalog usecase. At this point, I think it's easier to try and fix the underlying issue of making Avro work with HCatalog than to try rushing this patch into a 0.14 timeframe.\n\n( Having said that, PassthroughOutputFormat is itself pretty broken, since it stores the realoutputFormat as a static string in HiveFileFormatUtils, which currently breaks current usecases like calling HBase through HS2, and then attempting to use any other M/R O/F like Accumulo (since HS2 winds up being a persistent process that retains the older versions of that static variable). It doesn't break in cases of hive commandline itself, if you write to only one M/R-OF based output in one query. That is a separate bug that is not this patch's fault, but this patch makes HCatalog depend on PassthroughOutputFormat, and HCat does get used in a multiple use per process scenario which affects it. (I'll file another jira on that issue soon - I've been debugging that issue) We may rely on PassthroughOutputFormat in the short term, but we really need to move off that and support M/R OFs natively(with native MR OutputCommitter semantics) in hive )\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-30T09:22:26.441+0000","updated":"2014-10-30T09:22:26.441+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14189841","id":"14189841","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"(Unsetting patch-available for the time being - this patch still has issues and should not be committed in its current state)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-30T09:24:18.730+0000","updated":"2014-10-30T09:24:18.730+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14192565","id":"14192565","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Created HIVE-8687 for Avro support for HCatalog by plumbing HCat and AvroContainerOutputFormat so that solves the underlying need for this. In the meanwhile, I still think this is worth doing eventually to combine how HCatalog and Hive do IO together.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-31T21:51:38.064+0000","updated":"2014-10-31T21:51:38.064+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14193398","id":"14193398","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"body":"Setting \"Major\" because with HIVE-8687 it's not critical for hive .14 anymore.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-11-01T19:39:49.372+0000","updated":"2014-11-01T19:39:49.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12641836/comment/14194226","id":"14194226","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"(FYI, the issue with PassthroughOutputFormat that I mentioned above is addressed by HIVE-8704 . Note that there is still a further issue with PTOF in that it still will not support having more than one OutputFormat proxied for writing by PTOF in the same thread, which is a HCat usecase (using HCatMultiOutputFormat) but not something which is a usecase for hive commandline or even HS2 (since even in multiwrite cases, since a separate process in the DAG will be the one using PTOF for writing))","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-11-03T04:05:04.049+0000","updated":"2014-11-03T04:05:04.049+0000"}],"maxResults":31,"total":31,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-4329/votes","votes":3,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1jllz:"}}