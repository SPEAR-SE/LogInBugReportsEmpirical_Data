{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13082436","self":"https://issues.apache.org/jira/rest/api/2/issue/13082436","key":"HIVE-16958","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-06-26T11:33:58.510+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 22 23:59:25 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_171661749_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_408805102","customfield_12312321":null,"resolutiondate":"2017-07-03T01:39:14.075+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16958/watchers","watchCount":6,"isWatching":false},"created":"2017-06-26T08:24:47.299+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"7.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12340269","id":"12340269","name":"2.3.0","archived":false,"released":true,"releaseDate":"2017-07-18"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-22T23:59:25.415+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"The process will return \nJob failed with java.lang.NullPointerException\nFAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.spark.SparkTask. java.util.concurrent.ExecutionException: Exception thrown by job\n\tat org.apache.spark.JavaFutureActionWrapper.getImpl(FutureAction.scala:272)\n\tat org.apache.spark.JavaFutureActionWrapper.get(FutureAction.scala:277)\n\tat org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:362)\n\tat org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:323)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 31, bdpe822n1): java.io.IOException: java.lang.reflect.InvocationTargetException\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:271)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.<init>(HadoopShimsSecure.java:217)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getRecordReader(HadoopShimsSecure.java:345)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getRecordReader(CombineHiveInputFormat.java:695)\n\tat org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:246)\n\tat org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:209)\n\tat org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:102)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:85)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.GeneratedConstructorAccessor26.newInstance(Unknown Source)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:257)\n\t... 17 more\nCaused by: java.lang.NullPointerException\n\tat java.util.AbstractCollection.addAll(AbstractCollection.java:343)\n\tat org.apache.hadoop.hive.ql.io.parquet.ProjectionPusher.pushProjectionsAndFilters(ProjectionPusher.java:118)\n\tat org.apache.hadoop.hive.ql.io.parquet.ProjectionPusher.pushProjectionsAndFilters(ProjectionPusher.java:189)\n\tat org.apache.hadoop.hive.ql.io.parquet.ParquetRecordReaderBase.getSplit(ParquetRecordReaderBase.java:84)\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:74)\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:59)\n\tat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat.getRecordReader(MapredParquetInputFormat.java:75)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:99)\n\t... 21 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\nCaused by: java.io.IOException: java.lang.reflect.InvocationTargetException\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:271)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.<init>(HadoopShimsSecure.java:217)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getRecordReader(HadoopShimsSecure.java:345)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getRecordReader(CombineHiveInputFormat.java:695)\n\tat org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:246)\n\tat org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:209)\n\tat org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:102)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:85)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.GeneratedConstructorAccessor26.newInstance(Unknown Source)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:257)\n\t... 17 more\nCaused by: java.lang.NullPointerException\n\tat java.util.AbstractCollection.addAll(AbstractCollection.java:343)\n\tat org.apache.hadoop.hive.ql.io.parquet.ProjectionPusher.pushProjectionsAndFilters(ProjectionPusher.java:118)\n\tat org.apache.hadoop.hive.ql.io.parquet.ProjectionPusher.pushProjectionsAndFilters(ProjectionPusher.java:189)\n\tat org.apache.hadoop.hive.ql.io.parquet.ParquetRecordReaderBase.getSplit(ParquetRecordReaderBase.java:84)\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:74)\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.<init>(ParquetRecordReaderWrapper.java:59)\n\tat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat.getRecordReader(MapredParquetInputFormat.java:75)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:99)\n\t... 21 more\n\nwhen generating data for a database stored as parquet by setting hive.merge.sparkfiles=true. The detailed log and error messages can be seen at attach files.\nThe enviroment I use was hadoop2.7.3 hive release-2.3.0-rc0 spark2.0.0.\nSQL file is showed below:\nCREATE DATABASE IF NOT EXISTS sale;\nuse sale;\n\nCREATE EXTERNAL TABLE IF NOT EXISTS sale_record_temporary\n        ( record_id DECIMAL(23,0)\n        , product_name STRING\n        , amount        DECIMAL(6,0)\n        , prize         DECIMAL(11,0)\n        , customer_name STRING\n        , doc_date      TIMESTAMP\n        , due_date      TIMESTAMP\n        )\nROW FORMAT DELIMITED FIELDS TERMINATED BY '|'\nSTORED AS TEXTFILE LOCATION '/user/hive/warehouse/sale.db/sale_record_temporary'\n;\n\nDROP TABLE IF EXISTS sale_record;\nCREATE TABLE sale_record\n( record_id DECIMAL(23,0), product_name STRING, amount DECIMAL(6,0), prize DECIMAL(11,0), customer_name STRING, due_date TIMESTAMP) partitioned by (doc_date TIMESTAMP)\nSTORED AS parquet;\ninsert overwrite table sale_record PARTITION(doc_date) select record_id,product_name,amount,prize,customer_name,due_date,doc_date from sale_record_temporary;\nExternal data has aleady been put in hdfs path: '/user/hive/warehouse/sale.db/sale_record_temporary'","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12340269","id":"12340269","name":"2.3.0","archived":false,"released":true,"releaseDate":"2017-07-18"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874823","id":"12874823","filename":"HIVE-16958.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-28T08:05:30.520+0000","size":812,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874823/HIVE-16958.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874634","id":"12874634","filename":"hive-site.xml","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-27T07:41:16.336+0000","size":2546,"mimeType":"text/xml","content":"https://issues.apache.org/jira/secure/attachment/12874634/hive-site.xml"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874633","id":"12874633","filename":"Main.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-27T07:37:54.855+0000","size":1078,"mimeType":"text/x-java-source","content":"https://issues.apache.org/jira/secure/attachment/12874633/Main.java"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874449","id":"12874449","filename":"parquet-hivemergesparkfiles.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-26T08:27:06.369+0000","size":8475,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874449/parquet-hivemergesparkfiles.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874631","id":"12874631","filename":"pom.xml","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-27T07:38:10.884+0000","size":835,"mimeType":"text/xml","content":"https://issues.apache.org/jira/secure/attachment/12874631/pom.xml"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874632","id":"12874632","filename":"RowGenerator.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-27T07:38:04.442+0000","size":1851,"mimeType":"text/x-java-source","content":"https://issues.apache.org/jira/secure/attachment/12874632/RowGenerator.java"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874448","id":"12874448","filename":"sale.sql","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-26T08:28:23.049+0000","size":910,"mimeType":"application/x-sql","content":"https://issues.apache.org/jira/secure/attachment/12874448/sale.sql"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Setting hive.merge.sparkfiles=true will retrun an error when generating parquet databases ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"centos7 hadoop2.7.3 spark2.0.0","customfield_12313520":null,"customfield_12311020":null,"duedate":"2017-06-26","customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16062960","id":"16062960","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~Liu765940375], does the issue happen for MR too? I.e. when hive.merge.mapfiles=true and hive.merge.mapredfiles=true.\nAnd could you share your data to reproduce it?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-26T11:33:58.510+0000","updated":"2017-06-26T11:33:58.510+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16064070","id":"16064070","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: this also happened in MR.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-27T01:13:06.760+0000","updated":"2017-06-27T01:13:06.760+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16064419","id":"16064419","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~lirui], I have added the DataGen mvn project file(Main.java, RowGenerator.java, pom.xml) and hive-site.xml in attach files. It is easy to generate data on hdfs by the code(Default textfile is 500M. Parquet file is about 200M, and it generates 10 partitions dynamically. One file in partition is about 10M, so you need at least 2 files in one partition to merge them).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Liu765940375","name":"Liu765940375","key":"liu765940375","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liu Chunxiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-27T07:51:35.027+0000","updated":"2017-06-27T07:55:21.037+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16064513","id":"16064513","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"I think the cause is we need to set neededNestedColumnPaths in {{GenMapRedUtils::createTemporaryTableScanOperator}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-27T09:11:35.060+0000","updated":"2017-06-27T09:11:35.060+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16066104","id":"16066104","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: nestedColumnPaths is to solve the problem of HIVE-13873 which relates the struct type. In current case, there is no struct type and I can not set neededNestedColumnPaths in GenMapRedUtils::createTemporaryTableScanOperator.\n{code}\nCREATE EXTERNAL TABLE IF NOT EXISTS sale_record_temporary\n( record_id DECIMAL(23,0)\n, product_name STRING\n, amount DECIMAL(6,0)\n, prize DECIMAL(11,0)\n, customer_name STRING\n, doc_date TIMESTAMP\n, due_date TIMESTAMP\n)\nROW FORMAT DELIMITED FIELDS TERMINATED BY '|'\nSTORED AS TEXTFILE LOCATION '/user/hive/warehouse/sale.db/sale_record_temporary'\n{code}\n\nI directly add a not null judgement before the code.\n{code}\n-          neededNestedColumnPaths.addAll(ts.getNeededNestedColumnPaths());\n+          if (ts.getNeededNestedColumnPaths() != null) {\n+            neededNestedColumnPaths.addAll(ts.getNeededNestedColumnPaths());\n+          }\n         }\n\n{code}\n\n\n[~Liu765940375]: can you verify whether HIVE-16958.patch can solve your problem?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-28T08:05:05.383+0000","updated":"2017-06-28T08:05:05.383+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16066170","id":"16066170","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-28T09:03:35.279+0000","updated":"2017-06-28T09:03:35.279+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16066497","id":"16066497","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874823/HIVE-16958.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 10850 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5807/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5807/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5807/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 13 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874823 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-28T13:44:20.552+0000","updated":"2017-06-28T13:44:20.552+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16067696","id":"16067696","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~ferd]: as [~lirui] finished review, can you help commit it to upstream?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-29T04:01:44.177+0000","updated":"2017-06-29T04:01:44.177+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16071840","id":"16071840","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Ferd","name":"Ferd","key":"ferd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ferd&avatarId=21543","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ferd&avatarId=21543","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ferd&avatarId=21543","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ferd&avatarId=21543"},"displayName":"Ferdinand Xu","active":true,"timeZone":"Asia/Hong_Kong"},"body":"Committed to the upstream. Thanks [~kellyzly] for the patch and [~lirui] for the review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Ferd","name":"Ferd","key":"ferd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ferd&avatarId=21543","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ferd&avatarId=21543","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ferd&avatarId=21543","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ferd&avatarId=21543"},"displayName":"Ferdinand Xu","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2017-07-03T01:39:14.125+0000","updated":"2017-07-03T01:39:14.125+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082436/comment/16486167","id":"16486167","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"body":"Hive 3.0.0 has been released so closing this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-22T23:59:25.409+0000","updated":"2018-05-22T23:59:25.409+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16958/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3gpxj:"}}