{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12665674","self":"https://issues.apache.org/jira/rest/api/2/issue/12665674","key":"HIVE-5156","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2013-09-17T21:34:12.941+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Oct 15 23:31:38 UTC 2013","customfield_12310420":"345614","customfield_12312320":null,"customfield_12310222":"3_*:*_4_*:*_1704982387_*|*_10002_*:*_2_*:*_187039463_*|*_1_*:*_4_*:*_154144075_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-09-20T01:41:57.965+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5156/watchers","watchCount":3,"isWatching":false},"created":"2013-08-27T09:19:12.062+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-10-15T23:31:38.432+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320408","id":"12320408","name":"HiveServer2","description":"Tracks issues related to HiveServer2"}],"timeoriginalestimate":null,"description":"ResultSet.close does not free up any resources (tmp files etc) on hive server.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12603651","id":"12603651","filename":"HIVE-5156.D12837.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-17T20:10:10.722+0000","size":14589,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12603651/HIVE-5156.D12837.3.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"345915","customfield_12312823":null,"summary":"HiveServer2 jdbc ResultSet.close should free up resources on server side","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13762838","id":"13762838","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"body":"WIP patch for review here: https://reviews.facebook.net/D12837 ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-10T08:09:42.468+0000","updated":"2013-09-10T08:09:42.468+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13770011","id":"13770011","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 \nCan you please open a new jira to address the issue that HiveStatement is not calling ResultSet.close when it should ?\nhttp://docs.oracle.com/javase/7/docs/api/java/sql/ResultSet.html - A ResultSet object is automatically closed when the Statement object that generated it is closed, re-executed, or used to retrieve the next result from a sequence of multiple results.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-17T21:34:12.941+0000","updated":"2013-09-17T21:34:12.941+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13770023","id":"13770023","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Thejas, created the new JIRA here: https://issues.apache.org/jira/browse/HIVE-5305","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-17T21:44:02.387+0000","updated":"2013-09-17T21:44:02.387+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13770231","id":"13770231","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12603651/HIVE-5156.D12837.3.patch\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/789/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/789/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests failed with: NonZeroExitCodeException: Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n '' ]]\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ cd /data/hive-ptest/working/\n+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-789/source-prep.txt\n+ mkdir -p maven ivy\n+ [[ svn = \\s\\v\\n ]]\n+ [[ -n '' ]]\n+ [[ -d apache-svn-trunk-source ]]\n+ [[ ! -d apache-svn-trunk-source/.svn ]]\n+ [[ ! -d apache-svn-trunk-source ]]\n+ cd apache-svn-trunk-source\n+ svn revert -R .\nReverted 'common/src/java/org/apache/hadoop/hive/conf/HiveConf.java'\nReverted 'ql/src/test/results/clientnegative/alter_table_add_partition.q.out'\nReverted 'ql/src/test/results/clientnegative/alter_view_failure5.q.out'\nReverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java'\nReverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g'\nReverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java'\nReverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java'\nReverted 'ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java'\nReverted 'ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java'\n++ egrep -v '^X|^Performing status on external'\n++ awk '{print $2}'\n++ svn status --no-ignore\n+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen ql/src/test/results/clientnegative/illegal_partition_type.q.out ql/src/test/results/clientnegative/illegal_partition_type2.q.out ql/src/test/results/clientpositive/parititon_type_check.q.out ql/src/test/results/clientpositive/partition_type_check.q.out ql/src/test/queries/clientnegative/illegal_partition_type.q ql/src/test/queries/clientnegative/illegal_partition_type2.q ql/src/test/queries/clientpositive/partition_type_check.q\n+ svn update\nU    ql/src/test/queries/clientpositive/udaf_collect_set.q\nU    ql/src/test/results/clientpositive/show_functions.q.out\nU    ql/src/test/results/clientpositive/udaf_collect_set.q.out\nU    ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\nU    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java\nU    hcatalog/webhcat/svr/src/main/bin/webhcat_config.sh\nU    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java\nU    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java\nU    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Main.java\nA    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JobItemBean.java\nU    hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf\n\nFetching external item into 'hcatalog/src/test/e2e/harness'\nUpdated external to revision 1524262.\n\nUpdated to revision 1524262.\n+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hive-ptest/working/scratch/build.patch\n+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]\n+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java\npatching file jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java\npatching file jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java\nHunk #13 succeeded at 848 (offset 7 lines).\nHunk #14 succeeded at 892 (offset 7 lines).\nHunk #15 succeeded at 919 (offset 7 lines).\nHunk #16 succeeded at 980 (offset 19 lines).\nHunk #17 succeeded at 1000 (offset 19 lines).\nHunk #18 succeeded at 1023 (offset 19 lines).\nHunk #19 succeeded at 1076 (offset 19 lines).\nHunk #20 succeeded at 1119 (offset 19 lines).\nHunk #21 succeeded at 1343 (offset 19 lines).\n+ [[ true == \\t\\r\\u\\e ]]\n+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven\n+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven\n+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing\nBuildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml\n\nclean:\n     [echo] Project: hive\n\nclean:\n     [echo] Project: anttasks\n\nclean:\n     [echo] Project: shims\n\nclean:\n     [echo] Project: common\n\nclean:\n     [echo] Project: serde\n\nclean:\n     [echo] Project: metastore\n\nclean:\n     [echo] Project: ql\n\nclean:\n     [echo] Project: contrib\n\nclean:\n     [echo] Project: service\n\nclean:\n     [echo] Project: cli\n\nclean:\n     [echo] Project: jdbc\n\nclean:\n     [echo] Project: beeline\n\nclean:\n     [echo] Project: hwi\n\nclean:\n     [echo] Project: hbase-handler\n\nclean:\n     [echo] Project: testutils\n\nclean:\n     [echo] hcatalog\n\nclean:\n     [echo] hcatalog-core\n\nclean:\n     [echo] hcatalog-pig-adapter\n\nclean:\n     [echo] hcatalog-server-extensions\n\nclean:\n     [echo] webhcat\n\nclean:\n     [echo] webhcat-java-client\n\nclean:\n\nclean:\n     [echo] Project: odbc\n     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs\n\nclean-online:\n     [echo] Project: hive\n\nclean-offline:\n\nivy-init-dirs:\n     [echo] Project: hive\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven\n\nivy-download:\n     [echo] Project: hive\n      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar\n      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar\n\nivy-probe-antlib:\n     [echo] Project: hive\n\nivy-init-antlib:\n     [echo] Project: hive\n\ncompile-ant-tasks:\n     [echo] Project: hive\n\ncreate-dirs:\n     [echo] Project: anttasks\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.\n\ninit:\n     [echo] Project: anttasks\n\nivy-init-settings:\n     [echo] Project: anttasks\n\nivy-resolve:\n     [echo] Project: anttasks\n[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound velocity#velocity;1.5 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...\n[ivy:resolve] ..... (255kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (30ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...\n[ivy:resolve] ....... (382kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (24ms)\n[ivy:resolve] :: resolution report :: resolve 5625ms :: artifacts dl 75ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html\n\nivy-retrieve:\n     [echo] Project: anttasks\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t2 artifacts copied, 0 already retrieved (638kB/11ms)\n\ncompile:\n     [echo] anttasks\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds\n    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n\ndeploy-ant-tasks:\n     [echo] Project: hive\n\ncreate-dirs:\n     [echo] Project: anttasks\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.\n\ninit:\n     [echo] Project: anttasks\n\nivy-init-settings:\n     [echo] Project: anttasks\n\nivy-resolve:\n     [echo] Project: anttasks\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound velocity#velocity;1.5 in maven2\n[ivy:resolve] :: resolution report :: resolve 451ms :: artifacts dl 2ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html\n\nivy-retrieve:\n     [echo] Project: anttasks\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t0 artifacts copied, 2 already retrieved (0kB/8ms)\n\ncompile:\n     [echo] anttasks\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds\n\njar:\n     [echo] anttasks\n     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar\n\ninit:\n     [echo] Project: hive\n\ncreate-dirs:\n     [echo] Project: anttasks\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.\n\ninit:\n     [echo] Project: anttasks\n\ncreate-dirs:\n     [echo] Project: shims\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.\n\ninit:\n     [echo] Project: shims\n\ncreate-dirs:\n     [echo] Project: common\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources\n\ninit:\n     [echo] Project: common\n\ncreate-dirs:\n     [echo] Project: serde\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.\n\ninit:\n     [echo] Project: serde\n\ncreate-dirs:\n     [echo] Project: metastore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.\n\ninit:\n     [echo] Project: metastore\n\ncreate-dirs:\n     [echo] Project: ql\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources\n\ninit:\n     [echo] Project: ql\n\ncreate-dirs:\n     [echo] Project: contrib\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.\n\ninit:\n     [echo] Project: contrib\n\ncreate-dirs:\n     [echo] Project: service\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.\n\ninit:\n     [echo] Project: service\n\ncreate-dirs:\n     [echo] Project: cli\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.\n\ninit:\n     [echo] Project: cli\n\ncreate-dirs:\n     [echo] Project: jdbc\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.\n\ninit:\n     [echo] Project: jdbc\n\ncreate-dirs:\n     [echo] Project: beeline\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.\n\ninit:\n     [echo] Project: beeline\n\ncreate-dirs:\n     [echo] Project: hwi\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.\n\ninit:\n     [echo] Project: hwi\n\ncreate-dirs:\n     [echo] Project: hbase-handler\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.\n\ninit:\n     [echo] Project: hbase-handler\n\ncreate-dirs:\n     [echo] Project: testutils\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.\n\ninit:\n     [echo] Project: testutils\n\ninit:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.13.0-SNAPSHOT\n\njar:\n     [echo] Project: hive\n\nivy-init-settings:\n     [echo] Project: shims\n\ncheck-ivy:\n     [echo] Project: shims\n\nivy-resolve:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.zookeeper#zookeeper;3.4.3 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libthrift;0.9.0 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.0.4 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging-api;1.0.4 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound commons-io#commons-io;2.4 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...\n[ivy:resolve] .............. (749kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (50ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...\n[ivy:resolve] ....... (339kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (12ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar ...\n[ivy:resolve] .. (37kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-logging#commons-logging;1.0.4!commons-logging.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...\n[ivy:resolve] .. (25kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...\n[ivy:resolve] ..... (222kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (46ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...\n[ivy:resolve] ............. (652kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (18ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...\n[ivy:resolve] ......... (470kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...\n[ivy:resolve] ........................... (1609kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (34ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...\n[ivy:resolve] .... (180kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (9ms)\n[ivy:resolve] :: resolution report :: resolve 9037ms :: artifacts dl 227ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html\n\nmake-pom:\n     [echo] Project: shims\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: shims\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.\n\ninit:\n     [echo] Project: shims\n\nivy-retrieve:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t9 artifacts copied, 0 already retrieved (4287kB/38ms)\n\ncompile:\n     [echo] Project: shims\n     [echo] Building shims 0.20\n\nbuild-shims:\n     [echo] Project: shims\n     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)\n\nivy-init-settings:\n     [echo] Project: shims\n\nivy-resolve-hadoop-shim:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [hadoop0.20.shim]\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-core;0.20.2 in maven2\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound xmlenc#xmlenc;0.52 in maven2\n[ivy:resolve] \tfound commons-httpclient#commons-httpclient;3.0.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.0.3 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.3 in maven2\n[ivy:resolve] \tfound commons-net#commons-net;1.4.1 in maven2\n[ivy:resolve] \tfound oro#oro;2.0.8 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty-util;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2\n[ivy:resolve] \tfound tomcat#jasper-runtime;5.5.12 in maven2\n[ivy:resolve] \tfound tomcat#jasper-compiler;5.5.12 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.eclipse.jdt#core;3.1.1 in maven2\n[ivy:resolve] \tfound ant#ant;1.6.5 in maven2\n[ivy:resolve] \tfound commons-el#commons-el;1.0 in maven2\n[ivy:resolve] \tfound net.java.dev.jets3t#jets3t;0.7.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.1.1 in maven2\n[ivy:resolve] \tfound net.sf.kosmosfs#kfs;0.3 in maven2\n[ivy:resolve] \tfound junit#junit;4.5 in maven2\n[ivy:resolve] \tfound hsqldb#hsqldb;1.8.0.10 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-tools;0.20.2 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-test;0.20.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftplet-api;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.mina#mina-core;2.0.0-M5 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.5.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-core;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...\n[ivy:resolve] ............................................ (2624kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (55ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...\n[ivy:resolve] ... (68kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (16ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...\n[ivy:resolve] .......................... (1527kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (32ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...\n[ivy:resolve] .. (40kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...\n[ivy:resolve] .. (14kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...\n[ivy:resolve] ...... (273kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.3/commons-codec-1.3.jar ...\n[ivy:resolve] .. (45kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-codec#commons-codec;1.3!commons-codec.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...\n[ivy:resolve] .... (176kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...\n[ivy:resolve] ......... (504kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (14ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...\n[ivy:resolve] .... (159kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (24ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...\n[ivy:resolve] ... (74kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...\n[ivy:resolve] ........ (395kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...\n[ivy:resolve] .... (131kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...\n[ivy:resolve] ................. (1000kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...\n[ivy:resolve] ... (109kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...\n[ivy:resolve] ....... (368kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (42ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...\n[ivy:resolve] .... (129kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...\n[ivy:resolve] .. (11kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (36ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...\n[ivy:resolve] ..... (194kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] junit#junit;4.5!junit.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...\n[ivy:resolve] ............ (690kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (22ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...\n[ivy:resolve] .. (63kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...\n[ivy:resolve] .......................................................................................... (3483kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (75ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...\n[ivy:resolve] ................. (1009kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (33ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...\n[ivy:resolve] .. (59kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...\n[ivy:resolve] .. (22kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...\n[ivy:resolve] ........... (622kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (16ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...\n[ivy:resolve] ...... (264kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...\n[ivy:resolve] .. (31kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...\n[ivy:resolve] .. (16kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (36ms)\n[ivy:resolve] :: resolution report :: resolve 32966ms :: artifacts dl 658ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tjunit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]\n[ivy:resolve] \tcommons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]\n[ivy:resolve] \tcommons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.3] in [hadoop0.20.shim]\n[ivy:resolve] \tcommons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|  hadoop0.20.shim |   37  |   30  |   30  |   8   ||   29  |   29  |\n\t---------------------------------------------------------------------\n\nivy-retrieve-hadoop-shim:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [hadoop0.20.shim]\n[ivy:retrieve] \t29 artifacts copied, 0 already retrieved (14115kB/57ms)\n    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n     [echo] Building shims 0.20S\n\nbuild-shims:\n     [echo] Project: shims\n     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)\n\nivy-init-settings:\n     [echo] Project: shims\n\nivy-resolve-hadoop-shim:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [hadoop0.20S.shim]\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-core;1.1.2 in maven2\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound xmlenc#xmlenc;0.52 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-core;1.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-json;1.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jettison#jettison;1.1 in maven2\n[ivy:resolve] \tfound stax#stax-api;1.0.1 in maven2\n[ivy:resolve] \tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2\n[ivy:resolve] \tfound javax.xml.bind#jaxb-api;2.2.2 in maven2\n[ivy:resolve] \tfound javax.xml.stream#stax-api;1.0-2 in maven2\n[ivy:resolve] \tfound javax.activation#activation;1.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-xc;1.7.1 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-server;1.8 in maven2\n[ivy:resolve] \tfound asm#asm;3.1 in maven2\n[ivy:resolve] \tfound commons-io#commons-io;2.1 in maven2\n[ivy:resolve] \tfound commons-httpclient#commons-httpclient;3.0.1 in maven2\n[ivy:resolve] \tfound junit#junit;3.8.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.0.3 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-math;2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.1.1 in maven2\n[ivy:resolve] \tfound commons-digester#commons-digester;1.8 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils;1.7.0 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils-core;1.8.0 in maven2\n[ivy:resolve] \tfound commons-net#commons-net;1.4.1 in maven2\n[ivy:resolve] \tfound oro#oro;2.0.8 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty-util;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#servlet-api;2.5-20081211 in maven2\n[ivy:resolve] \tfound tomcat#jasper-runtime;5.5.12 in maven2\n[ivy:resolve] \tfound tomcat#jasper-compiler;5.5.12 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.eclipse.jdt#core;3.1.1 in maven2\n[ivy:resolve] \tfound ant#ant;1.6.5 in maven2\n[ivy:resolve] \tfound commons-el#commons-el;1.0 in maven2\n[ivy:resolve] \tfound net.java.dev.jets3t#jets3t;0.6.1 in maven2\n[ivy:resolve] \tfound hsqldb#hsqldb;1.8.0.10 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-tools;1.1.2 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-test;1.1.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftplet-api;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.mina#mina-core;2.0.0-M5 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.5.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-core;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...\n[ivy:resolve] ............................................................................................... (3941kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (82ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...\n[ivy:resolve] ...... (299kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...\n[ivy:resolve] .............................................. (2712kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (53ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...\n[ivy:resolve] ........ (447kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (14ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...\n[ivy:resolve] .... (144kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...\n[ivy:resolve] ............. (678kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (17ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...\n[ivy:resolve] .... (159kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...\n[ivy:resolve] .. (56kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...\n[ivy:resolve] ............... (812kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (20ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...\n[ivy:resolve] ...... (291kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...\n[ivy:resolve] .......... (527kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...\n[ivy:resolve] .... (172kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...\n[ivy:resolve] ...... (314kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (25ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...\n[ivy:resolve] ... (66kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...\n[ivy:resolve] ............... (869kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (37ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...\n[ivy:resolve] .. (17kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...\n[ivy:resolve] .. (30kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...\n[ivy:resolve] .. (25kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (12ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...\n[ivy:resolve] ... (102kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (21ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...\n[ivy:resolve] .. (22kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (17ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...\n[ivy:resolve] .. (61kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...\n[ivy:resolve] .. (42kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] asm#asm;3.1!asm.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...\n[ivy:resolve] ... (118kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (21ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...\n[ivy:resolve] .......... (561kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (35ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...\n[ivy:resolve] .... (140kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (12ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...\n[ivy:resolve] ..... (201kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...\n[ivy:resolve] .... (184kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (21ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...\n[ivy:resolve] .... (130kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (9ms)\n[ivy:resolve] :: resolution report :: resolve 32216ms :: artifacts dl 713ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \torg.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t| hadoop0.20S.shim |   62  |   30  |   30  |   11  ||   51  |   28  |\n\t---------------------------------------------------------------------\n\nivy-retrieve-hadoop-shim:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [hadoop0.20S.shim]\n[ivy:retrieve] \t51 artifacts copied, 0 already retrieved (22876kB/86ms)\n    [javac] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n     [echo] Building shims 0.23\n\nbuild-shims:\n     [echo] Project: shims\n     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.1.0-beta (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.1.0-beta)\n\nivy-init-settings:\n     [echo] Project: shims\n\nivy-resolve-hadoop-shim:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [hadoop0.23.shim]\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-common;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-annotations;2.1.0-beta in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-math;2.1 in maven2\n[ivy:resolve] \tfound xmlenc#xmlenc;0.52 in maven2\n[ivy:resolve] \tfound commons-httpclient#commons-httpclient;3.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.1.1 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound commons-io#commons-io;2.1 in maven2\n[ivy:resolve] \tfound commons-net#commons-net;3.1 in maven2\n[ivy:resolve] \tfound javax.servlet#servlet-api;2.5 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty-util;6.1.26 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-core;1.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-json;1.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jettison#jettison;1.1 in maven2\n[ivy:resolve] \tfound stax#stax-api;1.0.1 in maven2\n[ivy:resolve] \tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2\n[ivy:resolve] \tfound javax.xml.bind#jaxb-api;2.2.2 in maven2\n[ivy:resolve] \tfound javax.activation#activation;1.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-xc;1.8.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-server;1.8 in maven2\n[ivy:resolve] \tfound asm#asm;3.2 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.17 in maven2\n[ivy:resolve] \tfound net.java.dev.jets3t#jets3t;0.6.1 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.5 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-digester#commons-digester;1.8 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils;1.7.0 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils-core;1.8.0 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.5.3 in maven2\n[ivy:resolve] \tfound com.thoughtworks.paranamer#paranamer;2.3 in maven2\n[ivy:resolve] \tfound org.xerial.snappy#snappy-java;1.0.3.2 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.5.0 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-auth;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound com.jcraft#jsch;0.1.42 in maven2\n[ivy:resolve] \tfound org.apache.zookeeper#zookeeper;3.4.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound tomcat#jasper-compiler;5.5.23 in maven2\n[ivy:resolve] \tfound tomcat#jasper-runtime;5.5.23 in maven2\n[ivy:resolve] \tfound commons-el#commons-el;1.0 in maven2\n[ivy:resolve] \tfound javax.servlet.jsp#jsp-api;2.1 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-core;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-common;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-api;2.1.0-beta in maven2\n[ivy:resolve] \tfound com.google.inject.extensions#guice-servlet;3.0 in maven2\n[ivy:resolve] \tfound com.google.inject#guice;3.0 in maven2\n[ivy:resolve] \tfound javax.inject#javax.inject;1 in maven2\n[ivy:resolve] \tfound aopalliance#aopalliance;1.0 in maven2\n[ivy:resolve] \tfound org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2\n[ivy:resolve] \tfound io.netty#netty;3.5.11.Final in maven2\n[ivy:resolve] \tfound com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey.contribs#jersey-guice;1.8 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-archives;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-hdfs;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-common;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-client;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-common;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-tests;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-nodemanager;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-web-proxy;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-app;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.1.0-beta in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-hs;2.1.0-beta in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.1.0-beta/hadoop-common-2.1.0-beta.jar ...\n[ivy:resolve] ................................................. (2656kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.1.0-beta!hadoop-common.jar (91ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.1.0-beta/hadoop-common-2.1.0-beta-tests.jar ...\n[ivy:resolve] ....................... (1321kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.1.0-beta!hadoop-common.jar(tests) (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.1.0-beta/hadoop-mapreduce-client-core-2.1.0-beta.jar ...\n[ivy:resolve] ....................... (1340kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.1.0-beta!hadoop-mapreduce-client-core.jar (47ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.1.0-beta/hadoop-archives-2.1.0-beta.jar ...\n[ivy:resolve] .. (20kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.1.0-beta!hadoop-archives.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.1.0-beta/hadoop-hdfs-2.1.0-beta.jar ...\n[ivy:resolve] ................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. (5092kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.1.0-beta!hadoop-hdfs.jar (404ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.1.0-beta/hadoop-hdfs-2.1.0-beta-tests.jar ...\n[ivy:resolve] ................................ (1897kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.1.0-beta!hadoop-hdfs.jar(tests) (50ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.1.0-beta/hadoop-mapreduce-client-jobclient-2.1.0-beta.jar ...\n[ivy:resolve] .. (33kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta!hadoop-mapreduce-client-jobclient.jar (25ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.1.0-beta/hadoop-mapreduce-client-jobclient-2.1.0-beta-tests.jar ...\n[ivy:resolve] ....................... (1395kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta!hadoop-mapreduce-client-jobclient.jar(tests) (47ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.1.0-beta/hadoop-mapreduce-client-common-2.1.0-beta.jar ...\n[ivy:resolve] ............ (638kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.1.0-beta!hadoop-mapreduce-client-common.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.1.0-beta/hadoop-yarn-server-tests-2.1.0-beta-tests.jar ...\n[ivy:resolve] .. (33kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.1.0-beta!hadoop-yarn-server-tests.jar(tests) (14ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.1.0-beta/hadoop-mapreduce-client-app-2.1.0-beta.jar ...\n[ivy:resolve] ......... (461kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.1.0-beta!hadoop-mapreduce-client-app.jar (30ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.1.0-beta/hadoop-mapreduce-client-hs-2.1.0-beta.jar ...\n[ivy:resolve] ... (113kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.1.0-beta!hadoop-mapreduce-client-hs.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.1.0-beta/hadoop-annotations-2.1.0-beta.jar ...\n[ivy:resolve] .. (16kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.1.0-beta!hadoop-annotations.jar (44ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...\n[ivy:resolve] ...... (297kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...\n[ivy:resolve] ...... (266kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...\n[ivy:resolve] ... (102kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...\n[ivy:resolve] ......... (478kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...\n[ivy:resolve] ...... (272kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...\n[ivy:resolve] .. (24kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...\n[ivy:resolve] ...... (257kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar ...\n[ivy:resolve] .......... (520kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.5.0!protobuf-java.jar(bundle) (33ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.1.0-beta/hadoop-auth-2.1.0-beta.jar ...\n[ivy:resolve] .. (46kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.1.0-beta!hadoop-auth.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...\n[ivy:resolve] .... (181kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...\n[ivy:resolve] ............. (746kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (25ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4/commons-compress-1.4.jar ...\n[ivy:resolve] ..... (233kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.commons#commons-compress;1.4!commons-compress.jar (29ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...\n[ivy:resolve] .. (32kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...\n[ivy:resolve] .. (17kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...\n[ivy:resolve] .. (31kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (59ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...\n[ivy:resolve] .. (42kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] asm#asm;3.2!asm.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...\n[ivy:resolve] .. (28kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...\n[ivy:resolve] ................. (972kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...\n[ivy:resolve] .. (9kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...\n[ivy:resolve] ... (92kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...\n[ivy:resolve] ........ (398kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...\n[ivy:resolve] ... (75kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...\n[ivy:resolve] ... (98kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.1.0-beta/hadoop-yarn-common-2.1.0-beta.jar ...\n[ivy:resolve] ...................... (1263kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.1.0-beta!hadoop-yarn-common.jar (69ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...\n[ivy:resolve] .. (63kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...\n[ivy:resolve] ................... (1106kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (27ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.1.0-beta/hadoop-yarn-api-2.1.0-beta.jar ...\n[ivy:resolve] .................... (1125kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.1.0-beta!hadoop-yarn-api.jar (30ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...\n[ivy:resolve] ............. (693kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (18ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...\n[ivy:resolve] .. (12kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...\n[ivy:resolve] .. (14kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...\n[ivy:resolve] .. (2kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...\n[ivy:resolve] .. (4kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (27ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...\n[ivy:resolve] ...... (272kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (17ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.1.0-beta/hadoop-yarn-client-2.1.0-beta.jar ...\n[ivy:resolve] ... (84kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.1.0-beta!hadoop-yarn-client.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.1.0-beta/hadoop-yarn-server-common-2.1.0-beta.jar ...\n[ivy:resolve] .... (171kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.1.0-beta!hadoop-yarn-server-common.jar (27ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.1.0-beta/hadoop-yarn-server-nodemanager-2.1.0-beta.jar ...\n[ivy:resolve] ......... (451kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.1.0-beta!hadoop-yarn-server-nodemanager.jar (20ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.1.0-beta/hadoop-yarn-server-resourcemanager-2.1.0-beta.jar ...\n[ivy:resolve] ............ (585kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.1.0-beta!hadoop-yarn-server-resourcemanager.jar (24ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.1.0-beta/hadoop-yarn-server-web-proxy-2.1.0-beta.jar ...\n[ivy:resolve] .. (24kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.1.0-beta!hadoop-yarn-server-web-proxy.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.1.0-beta/hadoop-mapreduce-client-shuffle-2.1.0-beta.jar ...\n[ivy:resolve] .. (21kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.1.0-beta!hadoop-mapreduce-client-shuffle.jar (34ms)\n[ivy:resolve] :: resolution report :: resolve 52812ms :: artifacts dl 1614ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|  hadoop0.23.shim |   75  |   49  |   49  |   0   ||   78  |   52  |\n\t---------------------------------------------------------------------\n\nivy-retrieve-hadoop-shim:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [hadoop0.23.shim]\n[ivy:retrieve] \t78 artifacts copied, 0 already retrieved (34675kB/154ms)\n    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n\njar:\n     [echo] Project: shims\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:36:02 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-shims\n[ivy:publish] \tpublished hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: common\n\ncheck-ivy:\n     [echo] Project: common\n\nivy-resolve:\n     [echo] Project: common\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar ...\n[ivy:resolve] .... (145kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-shims;0.13.0-SNAPSHOT!hive-shims.jar (4ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...\n[ivy:resolve] ..... (235kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (10ms)\n[ivy:resolve] :: resolution report :: resolve 1402ms :: artifacts dl 19ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   6   |   2   |   2   |   0   ||   6   |   2   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html\n\nmake-pom:\n     [echo] Project: common\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: common\n\ninit:\n     [echo] Project: common\n\nsetup:\n     [echo] Project: common\n\nivy-retrieve:\n     [echo] Project: common\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t4 artifacts copied, 2 already retrieved (513kB/9ms)\n\ncompile:\n     [echo] Project: common\n    [javac] Compiling 27 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n\njar:\n     [echo] Project: common\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:36:07 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-common\n[ivy:publish] \tpublished hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: serde\n\ncheck-ivy:\n     [echo] Project: serde\n\nivy-resolve:\n     [echo] Project: serde\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar ...\n[ivy:resolve] ... (97kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-common;0.13.0-SNAPSHOT!hive-common.jar (4ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...\n[ivy:resolve] ...................... (1315kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (35ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...\n[ivy:resolve] ...... (268kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...\n[ivy:resolve] ...... (290kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (14ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...\n[ivy:resolve] .... (164kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (10ms)\n[ivy:resolve] :: resolution report :: resolve 6362ms :: artifacts dl 84ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html\n\nmake-pom:\n     [echo] Project: serde\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: serde\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.\n\ninit:\n     [echo] Project: serde\n\nivy-retrieve:\n     [echo] Project: serde\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t8 artifacts copied, 6 already retrieved (2229kB/33ms)\n\ndynamic-serde:\n\ncompile:\n     [echo] Project: serde\n    [javac] Compiling 338 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes/org/apache/hadoop/hive/serde2/typeinfo/package-info.class\n\njar:\n     [echo] Project: serde\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:36:25 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-serde\n[ivy:publish] \tpublished hive-serde to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: metastore\n\ncheck-ivy:\n     [echo] Project: metastore\n\nivy-resolve:\n     [echo] Project: metastore\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar ...\n[ivy:resolve] ............ (693kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-serde;0.13.0-SNAPSHOT!hive-serde.jar (12ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr/3.4/antlr-3.4.jar ...\n[ivy:resolve] .................. (1086kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.antlr#antlr;3.4!antlr.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar ...\n[ivy:resolve] .... (160kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.antlr#antlr-runtime;3.4!antlr-runtime.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/ST4/4.0.4/ST4-4.0.4.jar ...\n[ivy:resolve] ..... (231kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.antlr#ST4;4.0.4!ST4.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar ...\n[ivy:resolve] ... (112kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.jolbox#bonecp;0.7.1.RELEASE!bonecp.jar(bundle) (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar ...\n[ivy:resolve] ... (93kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-pool#commons-pool;1.5.4!commons-pool.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar ...\n[ivy:resolve] ....... (329kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.datanucleus#datanucleus-api-jdo;3.2.1!datanucleus-api-jdo.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar ...\n[ivy:resolve] .............................. (1759kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.datanucleus#datanucleus-core;3.2.2!datanucleus-core.jar (34ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar ...\n[ivy:resolve] .............................. (1728kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.datanucleus#datanucleus-rdbms;3.2.1!datanucleus-rdbms.jar (42ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar ...\n[ivy:resolve] ..... (196kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.jdo#jdo-api;3.0.1!jdo-api.jar (30ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar ...\n[ivy:resolve] ......................................... (2389kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.derby#derby;10.4.2.0!derby.jar (51ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/r08/guava-r08.jar ...\n[ivy:resolve] ................... (1088kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.guava#guava;r08!guava.jar (28ms)\n[ivy:resolve] :: resolution report :: resolve 10147ms :: artifacts dl 286ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   27  |   12  |   12  |   1   ||   26  |   12  |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-metastore-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-metastore-default.html\n\nmake-pom:\n     [echo] Project: metastore\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: metastore\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.\n\ninit:\n     [echo] Project: metastore\n\nmetastore-init:\n     [echo] Project: metastore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser\n\nivy-retrieve:\n     [echo] Project: metastore\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-metastore\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t12 artifacts copied, 14 already retrieved (9868kB/32ms)\n\nbuild-grammar:\n     [echo] Project: metastore\n     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....\n\nmodel-compile:\n     [echo] Project: metastore\n    [javac] Compiling 24 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n\ncore-compile:\n     [echo] Project: metastore\n    [javac] Compiling 103 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes/org/apache/hadoop/hive/metastore/parser/package-info.class\n\nmodel-enhance:\n     [echo] Project: metastore\n[datanucleusenhancer] log4j:WARN No appenders could be found for logger (DataNucleus.General).\n[datanucleusenhancer] log4j:WARN Please initialize the log4j system properly.\n[datanucleusenhancer] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n[datanucleusenhancer] DataNucleus Enhancer (version 3.2.2) for API \"JDO\" using JRE \"1.6\"\n[datanucleusenhancer] DataNucleus Enhancer : Classpath\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/activation-1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ant-1.6.5.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/asm-3.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-1.7.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-core-1.8.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-cli-1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-codec-1.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-collections-3.2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-configuration-1.6.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-digester-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-el-1.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-httpclient-3.0.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-io-2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-lang-2.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-logging-1.1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-math-2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-net-1.4.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/core-3.1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftplet-api-1.0.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-core-1.0.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-deprecated-1.0.0-M2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-core-1.1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-test-1.1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-tools-1.1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hsqldb-1.8.0.10.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-core-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-jaxrs-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-mapper-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-xc-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-compiler-5.5.12.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-runtime-5.5.12.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-api-2.2.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-impl-2.2.3-1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-core-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-json-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-server-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jets3t-0.6.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jettison-1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-6.1.26.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-util-6.1.26.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-2.1-6.1.14.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-api-2.1-6.1.14.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/junit-3.8.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/mina-core-2.0.0-M5.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/oro-2.0.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-20081211.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-6.1.14.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/slf4j-api-1.5.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0-2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/xmlenc-0.52.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/ST4-4.0.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-3.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-runtime-3.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/bonecp-0.7.1.RELEASE.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-cli-1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-codec-1.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-compress-1.4.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-io-2.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-1.0.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-api-1.0.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-pool-1.5.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-api-jdo-3.2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-core-3.2.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-rdbms-3.2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/derby-10.4.2.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-r08.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-common-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-serde-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-shims-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jdo-api-3.0.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libfb303-0.9.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/log4j-1.2.16.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/mockito-all-1.8.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-api-1.6.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-log4j12-1.6.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/velocity-1.5.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/xz-1.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/zookeeper-3.4.3.jar\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\n[datanucleusenhancer] DataNucleus Enhancer completed with success for 24 classes. Timings : input=738 ms, enhance=1164 ms, total=1902 ms. Consult the log for full details\n\ncompile:\n     [echo] Project: metastore\n\njar:\n     [echo] Project: metastore\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:37:05 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-metastore\n[ivy:publish] \tpublished hive-metastore to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: ql\n\ncheck-ivy:\n     [echo] Project: ql\n\nivy-resolve:\n     [echo] Project: ql\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-exec;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.5.0 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot\n[ivy:resolve] \tfound com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2\n[ivy:resolve] \tfound org.ow2.asm#asm;4.0 in maven2\n[ivy:resolve] \tfound com.esotericsoftware.minlog#minlog;1.2 in maven2\n[ivy:resolve] \tfound org.objenesis#objenesis;1.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar ...\n[ivy:resolve] .................................................... (3257kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-metastore;0.13.0-SNAPSHOT!hive-metastore.jar (51ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/iq80/snappy/snappy/0.2/snappy-0.2.jar ...\n[ivy:resolve] .. (47kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.iq80.snappy#snappy;0.2!snappy.jar (12ms)\n[ivy:resolve] downloading https://oss.sonatype.org/content/repositories/snapshots/com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/kryo-2.22-20130903.084724-39.jar ...\n[ivy:resolve] ............................................................................................ (420kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT!kryo.jar(bundle) (676ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/json/json/20090211/json-20090211.jar ...\n[ivy:resolve] .. (44kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.json#json;20090211!json.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar ...\n[ivy:resolve] .. (16kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.googlecode.javaewah#JavaEWAH;0.3.2!JavaEWAH.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javolution/javolution/5.5.1/javolution-5.5.1.jar ...\n[ivy:resolve] ........ (385kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javolution#javolution;5.5.1!javolution.jar(bundle) (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...\n[ivy:resolve] ... (85kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar ...\n[ivy:resolve] ... (64kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.esotericsoftware.reflectasm#reflectasm;1.07!reflectasm.jar (40ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar ...\n[ivy:resolve] .. (4kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.esotericsoftware.minlog#minlog;1.2!minlog.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/objenesis/objenesis/1.2/objenesis-1.2.jar ...\n[ivy:resolve] .. (35kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.objenesis#objenesis;1.2!objenesis.jar (22ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/ow2/asm/asm/4.0/asm-4.0.jar ...\n[ivy:resolve] .. (44kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.ow2.asm#asm;4.0!asm.jar (26ms)\n[ivy:resolve] :: resolution report :: resolve 17137ms :: artifacts dl 922ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   43  |   11  |   11  |   2   ||   41  |   11  |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-exec-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-exec-default.html\n\nmake-pom:\n     [echo] Project: ql\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: ql\n\ninit:\n     [echo] Project: ql\n\nql-init:\n     [echo] Project: ql\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse\n\nivy-retrieve:\n     [echo] Project: ql\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-exec\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t15 artifacts copied, 26 already retrieved (5813kB/29ms)\n\nbuild-grammar:\n     [echo] Project: ql\n     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g  ....\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:867:5: \n     [java] Decision can match input such as \"Identifier KW_RENAME KW_TO\" using multiple alternatives: 1, 10\n     [java] \n     [java] As a result, alternative(s) 10 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: \n     [java] Decision can match input such as \"KW_TEXTFILE\" using multiple alternatives: 2, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: \n     [java] Decision can match input such as \"KW_SEQUENCEFILE\" using multiple alternatives: 1, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: \n     [java] Decision can match input such as \"KW_ORCFILE\" using multiple alternatives: 4, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: \n     [java] Decision can match input such as \"KW_RCFILE\" using multiple alternatives: 3, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:23: \n     [java] Decision can match input such as \"KW_KEY_TYPE\" using multiple alternatives: 2, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:23: \n     [java] Decision can match input such as \"KW_ELEM_TYPE\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:23: \n     [java] Decision can match input such as \"KW_VALUE_TYPE\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:23: \n     [java] Decision can match input such as \"KW_VALUE_TYPE\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:23: \n     [java] Decision can match input such as \"KW_ELEM_TYPE\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:23: \n     [java] Decision can match input such as \"KW_KEY_TYPE\" using multiple alternatives: 2, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: \n     [java] Decision can match input such as \"KW_PRETTY KW_PARTITION\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: \n     [java] Decision can match input such as \"KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: \n     [java] Decision can match input such as \"KW_PRETTY Identifier\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: \n     [java] Decision can match input such as \"KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: \n     [java] Decision can match input such as \"KW_FORMATTED KW_PARTITION\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: \n     [java] Decision can match input such as \"KW_FORMATTED Identifier\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:116: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_DIRECTORIES\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_SEQUENCEFILE\" using multiple alternatives: 1, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_TEXTFILE\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_INPUTFORMAT\" using multiple alternatives: 5, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_RCFILE\" using multiple alternatives: 3, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_ORCFILE\" using multiple alternatives: 4, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): SelectClauseParser.g:149:5: \n     [java] Decision can match input such as \"KW_NULL DOT Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): SelectClauseParser.g:149:5: \n     [java] Decision can match input such as \"KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:127:2: \n     [java] Decision can match input such as \"KW_LATERAL KW_VIEW KW_OUTER\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:25: \n     [java] Decision can match input such as \"LPAREN StringLiteral EQUAL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:25: \n     [java] Decision can match input such as \"LPAREN StringLiteral COMMA\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:25: \n     [java] Decision can match input such as \"LPAREN StringLiteral RPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL GREATERTHAN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL GREATERTHANOREQUALTO\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LESSTHAN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LESSTHANOREQUALTO\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL DOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL NOTEQUAL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL EQUAL_NS\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL BITWISEXOR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL EQUAL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL RPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_AND\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CAST LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL BITWISEOR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_BETWEEN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_IN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL AMPERSAND\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LSQUARE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL {MINUS, PLUS}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN CharSetName CharSetLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_WHEN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_IS\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN StringLiteral StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_DATE StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_OR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:108:5: \n     [java] Decision can match input such as \"KW_ORDER KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:121:5: \n     [java] Decision can match input such as \"KW_CLUSTER KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:133:5: \n     [java] Decision can match input such as \"KW_PARTITION KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:144:5: \n     [java] Decision can match input such as \"KW_DISTRIBUTE KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:155:5: \n     [java] Decision can match input such as \"KW_SORT KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:172:7: \n     [java] Decision can match input such as \"STAR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:185:5: \n     [java] Decision can match input such as \"KW_STRUCT\" using multiple alternatives: 4, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:185:5: \n     [java] Decision can match input such as \"KW_UNIONTYPE\" using multiple alternatives: 5, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:185:5: \n     [java] Decision can match input such as \"KW_ARRAY\" using multiple alternatives: 2, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_NULL\" using multiple alternatives: 1, 8\n     [java] \n     [java] As a result, alternative(s) 8 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_DATE StringLiteral\" using multiple alternatives: 2, 3\n     [java] \n     [java] As a result, alternative(s) 3 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_FALSE\" using multiple alternatives: 3, 8\n     [java] \n     [java] As a result, alternative(s) 8 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_TRUE\" using multiple alternatives: 3, 8\n     [java] \n     [java] As a result, alternative(s) 8 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"KW_BETWEEN KW_MAP LPAREN\" using multiple alternatives: 6, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:514:5: \n     [java] Decision can match input such as \"{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}\" using multiple alternatives: 1, 3\n     [java] \n     [java] As a result, alternative(s) 3 were disabled for that input\n\ncompile:\n     [echo] Project: ql\n    [javac] Compiling 922 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java:25: package org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMkCollectionEvaluator does not exist\n    [javac] import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMkCollectionEvaluator.BufferType;\n    [javac]                                                                              ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java:386: cannot find symbol\n    [javac] symbol  : class GenericUDAFCollectList\n    [javac] location: class org.apache.hadoop.hive.ql.exec.FunctionRegistry\n    [javac]     registerGenericUDAF(\"collect_list\", new GenericUDAFCollectList());\n    [javac]                                             ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java:52: cannot find symbol\n    [javac] symbol  : class GenericUDAFMkCollectionEvaluator\n    [javac] location: class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet\n    [javac]     return new GenericUDAFMkCollectionEvaluator(BufferType.SET);\n    [javac]                ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java:52: cannot find symbol\n    [javac] symbol  : variable BufferType\n    [javac] location: class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet\n    [javac]     return new GenericUDAFMkCollectionEvaluator(BufferType.SET);\n    [javac]                                                 ^\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] 4 errors\n\nBUILD FAILED\n/data/hive-ptest/working/apache-svn-trunk-source/build.xml:327: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/ql/build.xml:198: Compile failed; see the compiler error output for details.\n\nTotal time: 4 minutes 32 seconds\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2013-09-18T00:37:59.482+0000","updated":"2013-09-18T00:37:59.482+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13772560","id":"13772560","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"I ran the jdbc tests as this is a jdbc only change. Patch committed to trunk and 0.12 branch.\nThanks Vaibhav for the contribution!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-20T01:41:57.983+0000","updated":"2013-09-20T01:41:57.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13773014","id":"13773014","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hive-trunk-hadoop2-ptest #107 (See [https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/107/])\nHIVE-5156: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524880)\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java\n* /hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-20T13:54:04.418+0000","updated":"2013-09-20T13:54:04.418+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13773073","id":"13773073","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hive-trunk-hadoop1-ptest #174 (See [https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/174/])\nHIVE-5156: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524880)\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java\n* /hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-20T15:25:22.028+0000","updated":"2013-09-20T15:25:22.028+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13773082","id":"13773082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hive-trunk-hadoop2 #444 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/444/])\nHIVE-5156: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524880)\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java\n* /hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-20T15:32:52.966+0000","updated":"2013-09-20T15:32:52.966+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13773083","id":"13773083","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hive-trunk-h0.21 #2345 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2345/])\nHIVE-5156: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524880)\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java\n* /hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java\n* /hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-20T15:32:52.970+0000","updated":"2013-09-20T15:32:52.970+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12665674/comment/13796183","id":"13796183","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-10-15T23:31:38.427+0000","updated":"2013-10-15T23:31:38.427+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5156/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1nll3:"}}