{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13021016","self":"https://issues.apache.org/jira/rest/api/2/issue/13021016","key":"HIVE-15218","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2016-11-16T02:37:21.575+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Mar 09 17:38:37 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_437984_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_41371132817","customfield_12312321":null,"resolutiondate":"2018-03-09T22:36:45.433+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15218/watchers","watchCount":5,"isWatching":false},"created":"2016-11-16T02:30:34.667+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"}],"issuelinks":[{"id":"12502956","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12502956","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13070226","key":"HIVE-16611","self":"https://issues.apache.org/jira/rest/api/2/issue/13070226","fields":{"summary":"Kryo remove field is not working","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-03-09T22:36:45.462+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Following exception is observed when running TPCDS query19 during concurrency test\n{code}\nVertex failed, vertexName=Map 3, vertexId=vertex_1477340478603_0610_9_05, diagnostics=[Task failed, taskId=task_1477340478603_0610_9_05_000006, diagnostics=[TaskAttempt 0 killed, TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1477340478603_0610_9_05_000006_1:java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\n  at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at javax.security.auth.Subject.doAs(Subject.java:422)\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\n  at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n  at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\n  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n  at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:57)\n  at org.apache.hadoop.hive.ql.exec.ObjectCacheWrapper.retrieve(ObjectCacheWrapper.java:40)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:129)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n  ... 15 more\nCaused by: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:469)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getMapWork(Utilities.java:305)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor$1.call(MapRecordProcessor.java:132)\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:55)\n  ... 18 more\nCaused by: org.apache.hive.com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 63\nSerialization trace:\nstatistics (org.apache.hadoop.hive.ql.plan.TableScanDesc)\nconf (org.apache.hadoop.hive.ql.exec.TableScanOperator)\naliasToWork (org.apache.hadoop.hive.ql.plan.MapWork)\n  at org.apache.hive.com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:137)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:670)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClass(SerializationUtilities.java:182)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:118)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClassAndObject(SerializationUtilities.java:177)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:161)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:686)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:207)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializeObjectByKryo(SerializationUtilities.java:608)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:495)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:472)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:428)\n  ... 21 more\n], TaskAttempt 2 failed, info=[Error: Error while running task ( failure ) : attempt_1477340478603_0610_9_05_000006_2:java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\n  at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at javax.security.auth.Subject.doAs(Subject.java:422)\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\n  at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n  at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\n  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n  at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:57)\n  at org.apache.hadoop.hive.ql.exec.ObjectCacheWrapper.retrieve(ObjectCacheWrapper.java:40)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:129)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n  ... 15 more\nCaused by: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:469)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getMapWork(Utilities.java:305)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor$1.call(MapRecordProcessor.java:132)\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:55)\n  ... 18 more\nCaused by: org.apache.hive.com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 63\nSerialization trace:\nstatistics (org.apache.hadoop.hive.ql.plan.TableScanDesc)\nconf (org.apache.hadoop.hive.ql.exec.TableScanOperator)\naliasToWork (org.apache.hadoop.hive.ql.plan.MapWork)\n  at org.apache.hive.com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:137)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:670)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClass(SerializationUtilities.java:182)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:118)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClassAndObject(SerializationUtilities.java:177)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:161)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:686)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:207)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializeObjectByKryo(SerializationUtilities.java:608)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:495)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:472)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:428)\n  ... 21 more\n], TaskAttempt 3 failed, info=[Error: Error while running task ( failure ) : attempt_1477340478603_0610_9_05_000006_3:java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\n  at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at javax.security.auth.Subject.doAs(Subject.java:422)\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\n  at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n  at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\n  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n  at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:57)\n  at org.apache.hadoop.hive.ql.exec.ObjectCacheWrapper.retrieve(ObjectCacheWrapper.java:40)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:129)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n  ... 15 more\nCaused by: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:469)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getMapWork(Utilities.java:305)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor$1.call(MapRecordProcessor.java:132)\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:55)\n  ... 18 more\nCaused by: org.apache.hive.com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 63\nSerialization trace:\nstatistics (org.apache.hadoop.hive.ql.plan.TableScanDesc)\nconf (org.apache.hadoop.hive.ql.exec.TableScanOperator)\naliasToWork (org.apache.hadoop.hive.ql.plan.MapWork)\n  at org.apache.hive.com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:137)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:670)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClass(SerializationUtilities.java:182)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:118)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClassAndObject(SerializationUtilities.java:177)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:161)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:686)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:207)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializeObjectByKryo(SerializationUtilities.java:608)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:495)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:472)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:428)\n  ... 21 more\n], TaskAttempt 4 failed, info=[Error: Error while running task ( failure ) : attempt_1477340478603_0610_9_05_000006_4:java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\n  at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at javax.security.auth.Subject.doAs(Subject.java:422)\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\n  at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n  at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\n  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n  at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:57)\n  at org.apache.hadoop.hive.ql.exec.ObjectCacheWrapper.retrieve(ObjectCacheWrapper.java:40)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:129)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n  ... 15 more\nCaused by: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:469)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getMapWork(Utilities.java:305)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor$1.call(MapRecordProcessor.java:132)\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:55)\n  ... 18 more\nCaused by: org.apache.hive.com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 63\nSerialization trace:\nstatistics (org.apache.hadoop.hive.ql.plan.TableScanDesc)\nconf (org.apache.hadoop.hive.ql.exec.TableScanOperator)\naliasToWork (org.apache.hadoop.hive.ql.plan.MapWork)\n  at org.apache.hive.com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:137)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:670)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClass(SerializationUtilities.java:182)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:118)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClassAndObject(SerializationUtilities.java:177)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:161)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:686)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:207)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializeObjectByKryo(SerializationUtilities.java:608)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:495)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:472)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:428)\n  ... 21 more\n]], Task failed, taskId=task_1477340478603_0610_9_05_000004, diagnostics=[TaskAttempt 0 killed, TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1477340478603_0610_9_05_000004_1:java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\n  at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\n  at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at javax.security.auth.Subject.doAs(Subject.java:422)\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\n  at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\n  at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n  at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)\n  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n  at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:57)\n  at org.apache.hadoop.hive.ql.exec.ObjectCacheWrapper.retrieve(ObjectCacheWrapper.java:40)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:129)\n  at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n  ... 15 more\nCaused by: java.lang.RuntimeException: Failed to load plan: hdfs://cn105-10.l42scl.hortonworks.com:8020/tmp/hive/ndembla/0559ce24-663e-482a-a0ea-106d220b53be/hi...\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:469)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getMapWork(Utilities.java:305)\n  at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor$1.call(MapRecordProcessor.java:132)\n  at org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:55)\n  ... 18 more\nCaused by: org.apache.hive.com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 63\nSerialization trace:\nstatistics (org.apache.hadoop.hive.ql.plan.TableScanDesc)\nconf (org.apache.hadoop.hive.ql.exec.TableScanOperator)\naliasToWork (org.apache.hadoop.hive.ql.plan.MapWork)\n  at org.apache.hive.com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:137)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:670)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClass(SerializationUtilities.java:182)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:118)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readClassAndObject(SerializationUtilities.java:177)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:161)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:215)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)\n  at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n  at org.apache.hive.com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:686)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities$KryoWithHooks.readObject(SerializationUtilities.java:207)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializeObjectByKryo(SerializationUtilities.java:608)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:495)\n  at org.apache.hadoop.hive.ql.exec.SerializationUtilities.deserializePlan(SerializationUtilities.java:472)\n  at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:428)\n  ... 21 more\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12839101","id":"12839101","filename":"HIVE-15218.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-16T02:37:46.798+0000","size":664,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12839101/HIVE-15218.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12839474","id":"12839474","filename":"HIVE-15218.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-18T00:31:17.798+0000","size":4798,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12839474/HIVE-15218.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12839478","id":"12839478","filename":"HIVE-15218.branch-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-18T00:58:40.414+0000","size":2892,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Kyro Exception on subsequent run of a query in LLAP mode","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndembla","name":"ndembla","key":"ndembla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nita Dembla","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15669145","id":"15669145","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"body":"[~gopalv] found that HIVE-8769 changed statistics object from being transient to non-transient. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-16T02:37:21.575+0000","updated":"2016-11-16T02:37:21.575+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15669147","id":"15669147","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"body":"[~gopalv] can you please review this change?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-16T02:37:46.816+0000","updated":"2016-11-16T02:37:46.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15669260","id":"15669260","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"LGTM +1 - tests pending.\n\nThe Statistics object doesn't seem to be referred on the execution side at all.\n\nThe question remains about why the {{removeField(kryo, AbstractOperatorDesc.class, \"statistics\");}} doesn't remove this field when serializing in the first place.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-11-16T03:36:16.687+0000","updated":"2016-11-16T03:36:16.687+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15669501","id":"15669501","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12839101/HIVE-15218.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 189 failed/errored test(s), 10694 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_9] (batchId=33)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join0] (batchId=78)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join31] (batchId=40)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join_stats] (batchId=43)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_join_without_localtask] (batchId=1)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_14] (batchId=11)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_15] (batchId=11)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_1] (batchId=41)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=43)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_3] (batchId=1)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_4] (batchId=56)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_5] (batchId=78)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_7] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[bucketsortoptimize_insert_4] (batchId=22)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[bucketsortoptimize_insert_5] (batchId=52)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_cross_product_check_2] (batchId=18)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[correlationoptimizer5] (batchId=63)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cross_product_check_2] (batchId=79)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[identity_project_remove_skip] (batchId=44)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join29] (batchId=39)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[runtime_skewjoin_mapjoin_spark] (batchId=49)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[skewjoin] (batchId=21)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[skewjoin_onesideskew] (batchId=64)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[smb_mapjoin_25] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subq_where_serialization] (batchId=77)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_in_having] (batchId=52)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_multiinsert] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[tez_join_hash] (batchId=47)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union22] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_mapjoin_reduce] (batchId=70)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[dynamic_partition_pruning_2] (batchId=133)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[except_distinct] (batchId=134)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[explainuser_2] (batchId=134)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[intersect_all] (batchId=133)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[intersect_distinct] (batchId=134)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[intersect_merge] (batchId=133)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_nullscan] (batchId=131)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=133)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_union_dynamic_partition] (batchId=133)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=133)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[auto_sortmerge_join_10] (batchId=148)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cluster] (batchId=141)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[column_access_stats] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[constprog_dpp] (batchId=138)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_partition_pruning] (batchId=141)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[hybridgrace_hashjoin_2] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mergejoin] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multi_insert] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ppd_union_view] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[selectDistinctStar] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[temp_table] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_join_hash] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union2] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union_group_by] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_union_multiinsert] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union2] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union3] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union4] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union5] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union6] (batchId=141)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union7] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union8] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union9] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_remove_26] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_stats] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_top_level] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_null_projection] (batchId=137)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_dynamic_partition_pruning] (batchId=141)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_1] (batchId=90)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=91)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=90)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[hybridgrace_hashjoin_2] (batchId=90)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query54] (batchId=219)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query66] (batchId=219)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query71] (batchId=219)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query75] (batchId=219)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query76] (batchId=219)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query80] (batchId=219)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_join27] (batchId=130)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_10] (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[column_access_stats] (batchId=116)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[dynamic_rdd_cache] (batchId=114)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_sort_1_23] (batchId=126)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_sort_skew_1_23] (batchId=96)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join34] (batchId=122)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join35] (batchId=119)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[load_dyn_part13] (batchId=121)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[load_dyn_part14] (batchId=130)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[multi_insert] (batchId=106)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[multi_insert_move_tasks_share_dependencies] (batchId=115)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[multi_join_union] (batchId=92)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[optimize_nullscan] (batchId=126)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[runtime_skewjoin_mapjoin_spark] (batchId=115)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin] (batchId=102)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin_union_remove_1] (batchId=128)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin_union_remove_2] (batchId=104)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt10] (batchId=101)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt11] (batchId=122)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt12] (batchId=96)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt14] (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt15] (batchId=97)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt16] (batchId=98)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt17] (batchId=128)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt19] (batchId=101)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt1] (batchId=126)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt20] (batchId=124)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt2] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt3] (batchId=102)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt4] (batchId=103)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt5] (batchId=103)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt6] (batchId=101)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt7] (batchId=114)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt8] (batchId=104)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoinopt9] (batchId=102)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[stats1] (batchId=98)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[temp_table] (batchId=129)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union10] (batchId=97)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union11] (batchId=120)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union12] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union13] (batchId=114)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union14] (batchId=96)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union15] (batchId=130)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union16] (batchId=129)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union17] (batchId=122)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union18] (batchId=99)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union19] (batchId=117)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union20] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union21] (batchId=92)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union22] (batchId=98)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union23] (batchId=93)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=117)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union25] (batchId=121)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union26] (batchId=120)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union27] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union28] (batchId=111)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union29] (batchId=115)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union2] (batchId=113)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union30] (batchId=125)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union31] (batchId=93)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union32] (batchId=104)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union33] (batchId=103)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union34] (batchId=97)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union3] (batchId=118)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union4] (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union5] (batchId=101)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union6] (batchId=105)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union7] (batchId=119)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union8] (batchId=115)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union9] (batchId=109)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union] (batchId=93)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_lateralview] (batchId=103)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_ppr] (batchId=100)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_10] (batchId=102)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_11] (batchId=100)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_12] (batchId=110)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_13] (batchId=129)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_14] (batchId=97)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_15] (batchId=128)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_16] (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_17] (batchId=121)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_18] (batchId=95)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_19] (batchId=100)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_1] (batchId=106)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_20] (batchId=128)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_21] (batchId=118)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_22] (batchId=125)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_23] (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_24] (batchId=98)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_25] (batchId=129)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_2] (batchId=109)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_3] (batchId=114)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_4] (batchId=96)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_5] (batchId=117)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_6] (batchId=111)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_6_subq] (batchId=108)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_7] (batchId=93)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_8] (batchId=113)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_9] (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_top_level] (batchId=118)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_view] (batchId=98)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/2145/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/2145/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2145/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 189 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12839101 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-11-16T05:35:09.192+0000","updated":"2016-11-16T05:35:09.192+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15675278","id":"15675278","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"body":"This patch adds kryo tracing via hive config.\nAlso for cloning operator tree statistics and colExprMap fields get retained whereas for serializing/deserializing plan these fields gets removed. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-18T00:31:17.803+0000","updated":"2016-11-18T00:31:17.803+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15675334","id":"15675334","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"body":"[~gopalv] can you please review the new changes?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-18T00:58:40.424+0000","updated":"2016-11-18T00:58:40.424+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15675363","id":"15675363","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"Does the removeFields persist when you return the Kryo object to the pool?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-11-18T01:11:00.798+0000","updated":"2016-11-18T01:11:00.798+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15675733","id":"15675733","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"body":"Good catch. It persists so a clone op tree after serialize plan will still lose statistics. \n\nI was trying to fix but even remove field is not working. Looks like we are hitting this issue https://github.com/EsotericSoftware/kryo/issues/285\n\nI will see if there are any workarounds.. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-18T04:32:59.345+0000","updated":"2016-11-18T04:32:59.345+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15675953","id":"15675953","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/2182/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/2182/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2182/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2016-11-18 06:39:57.945\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-2182/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2016-11-18 06:39:57.947\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2016-11-18 06:39:58.939\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12839478 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-11-18T06:39:59.337+0000","updated":"2016-11-18T06:39:59.337+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15675955","id":"15675955","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/2183/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/2183/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2183/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2016-11-18 06:40:46.623\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-2183/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2016-11-18 06:40:46.625\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 67c022f HIVE-10901: Optimize multi column distinct queries (Pengcheng Xiong, reviewed by Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2016-11-18 06:40:47.509\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12839478 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-11-18T06:40:48.967+0000","updated":"2016-11-18T06:40:48.967+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15689503","id":"15689503","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"Review of configuration parameter:  Please change \"kryo\" to \"Kryo\" in the description.\n\n{code}\n+    HIVE_KRYO_TRACE_ENABLE(\"hive.kryo.trace.enable\", false, \"Enable kryo serialization trace. Trace log messages will\" +\n+      \" go to System.out by default.\"),\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2016-11-23T09:27:49.308+0000","updated":"2016-11-23T09:27:49.308+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/15942112","id":"15942112","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4382/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4382/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4382/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-03-26 03:10:37.312\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4382/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-03-26 03:10:37.314\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at b4a8af9 HIVE-16274: Support tuning of NDV of columns using lower/upper bounds (Pengcheng Xiong, reviewed by Jason Dere)\n+ git clean -f -d\nRemoving ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java.orig\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at b4a8af9 HIVE-16274: Support tuning of NDV of columns using lower/upper bounds (Pengcheng Xiong, reviewed by Jason Dere)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-03-26 03:10:38.391\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12839478 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-03-26T03:10:38.924+0000","updated":"2017-03-26T03:10:38.924+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/16392297","id":"16392297","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"Is there a reason this was never committed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-03-09T02:34:54.070+0000","updated":"2018-03-09T02:34:54.070+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/16392677","id":"16392677","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"body":"Initially thought this was the issue but later figured out that this only happened when there was a stranded llap daemon which was not killed by yarn. After proper cleanup of all llap daemons this issue never occured.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasanth_j","name":"prasanth_j","key":"prasanth_j","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasanth Jayachandran","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-03-09T10:24:17.378+0000","updated":"2018-03-09T10:24:17.378+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13021016/comment/16393249","id":"16393249","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12839478/HIVE-15218.branch-1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/9574/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/9574/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-9574/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2018-03-09 17:36:59.309\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-9574/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2018-03-09 17:36:59.312\n+ cd apache-github-source-source\n+ git fetch origin\nFrom https://github.com/apache/hive\n   73ccc44..34eb9ed  master     -> origin/master\n+ git reset --hard HEAD\nHEAD is now at 73ccc44 HIVE-18889 : update all parts of Hive to use the same Guava version (Sergey Shelukhin, reviewed by Ashutosh Chauhan)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is behind 'origin/master' by 1 commit, and can be fast-forwarded.\n  (use \"git pull\" to update your local branch)\n+ git reset --hard origin/master\nHEAD is now at 34eb9ed HIVE-18918 - Bad error message in CompactorMR.lanuchCompactionJob() (Eugene Koifman, reviewed by Jason Dere)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2018-03-09 17:37:00.900\n+ rm -rf ../yetus_PreCommit-HIVE-Build-9574\n+ mkdir ../yetus_PreCommit-HIVE-Build-9574\n+ git gc\n+ cp -R . ../yetus_PreCommit-HIVE-Build-9574\n+ mkdir /data/hiveptest/logs/PreCommit-HIVE-Build-9574/yetus\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: does not exist in index\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java: does not exist in index\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java: does not exist in index\nerror: patch failed: common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:1167\nFalling back to three-way merge...\nApplied patch to 'common/src/java/org/apache/hadoop/hive/conf/HiveConf.java' with conflicts.\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/Driver.java:291\nFalling back to three-way merge...\nApplied patch to 'ql/src/java/org/apache/hadoop/hive/ql/Driver.java' with conflicts.\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java:1266\nFalling back to three-way merge...\nApplied patch to 'ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java' with conflicts.\nGoing to apply patch with: git apply -p1\nerror: patch failed: common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:1167\nFalling back to three-way merge...\nApplied patch to 'common/src/java/org/apache/hadoop/hive/conf/HiveConf.java' with conflicts.\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/Driver.java:291\nFalling back to three-way merge...\nApplied patch to 'ql/src/java/org/apache/hadoop/hive/ql/Driver.java' with conflicts.\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java:1266\nFalling back to three-way merge...\nApplied patch to 'ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java' with conflicts.\nU common/src/java/org/apache/hadoop/hive/conf/HiveConf.java\nU ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nU ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12839478 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2018-03-09T17:38:37.363+0000","updated":"2018-03-09T17:38:37.363+0000"}],"maxResults":15,"total":15,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15218/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i36dmn:"}}