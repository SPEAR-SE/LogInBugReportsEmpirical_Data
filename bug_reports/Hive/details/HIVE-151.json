{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12410364","self":"https://issues.apache.org/jira/rest/api/2/issue/12410364","key":"HIVE-151","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313637","id":"12313637","description":"released","name":"0.3.0","archived":false,"released":true,"releaseDate":"2009-04-30"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-12-27T00:24:44.047+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Dec 31 21:13:07 UTC 2008","customfield_12310420":"73749","customfield_12312320":null,"customfield_12310222":"10002_*:*_2_*:*_76621056_*|*_1_*:*_2_*:*_1763882256_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2008-12-31T21:13:07.312+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-151/watchers","watchCount":3,"isWatching":false},"created":"2008-12-10T13:58:04.735+0000","customfield_12310192":"HIVE-151. Tasks depending on other tasks cannot be a root task. (Namit Jain via zshao)","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-12-17T00:08:48.273+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312586","id":"12312586","name":"Query Processor","description":"Tracks issues dealing with query processing."}],"timeoriginalestimate":null,"description":"Executing a query \n------------------------------------- query start ----------------------------------------------------\nSELECT t11.subject, t22.object , t33.subject , t55.object, t66.object \nFROM \n( \n\tSELECT t1.subject \n\tFROM triples t1  \n\tWHERE \n\t\tt1.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL'  \n\tAND  \n\t\tt1.object='http://ontos/OntosMiner/Common.English/ontology#Citation' \n) t11  \nJOIN  \n( \n\tSELECT t2.subject , t2.object \n\tFROM triples t2  \n\tWHERE  \n\t\t\tt2.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL' \n) t22 \nON (t11.subject=t22.subject)  \t\t\nJOIN  \n( \n\tSELECT t3.subject , t3.object  \n\tFROM triples t3  \n\tWHERE  \n\t\t\tt3.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_from'  \n\t\t\t\t\n) t33\nON (t11.subject=t33.object) \nJOIN  \n( \n\tSELECT t4.subject  \n\tFROM triples t4  \n\tWHERE  \n\t\tt4.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL'  \n\tAND  \n\t\tt4.object='http://ontos/OntosMiner/Common.English/ontology#Author' \n\t\t\t\t\n) t44\nON (t44.subject=t33.subject) \nJOIN  \n( \n\tSELECT t5.subject, t5.object\n\tFROM triples t5  \n\tWHERE  \n\t\tt5.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_to'  \n) t55\nON (t55.subject=t44.subject) \nJOIN  \n( \n\tSELECT t6.subject, t6.object\n\tFROM triples t6  \n\tWHERE  \n\t\tt6.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL'  \n) t66\nON (t66.subject=t55.object)\n------------------------------------- query end ----------------------------------------------------\non table \n------------------------------------- table start ----------------------------------------------------\nCREATE TABLE triples (foo string,subject string, predicate string, object string, foo2 string)\n------------------------------------- table end -----------------------------------------------------\n\ngives the foolowing output \n------------------------------------ console output ----------------------------------------------\n INFO [main] (Driver.java:156) - Starting command: SELECT t11.subject, t22.object , t33.subject , t66.object  FROM  (  \tSELECT t1.subject  \tFROM triples t1   \tWHERE  \t\tt1.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL'   \tAND   \t\tt1.object='http://ontos/OntosMiner/Common.English/ontology#Citation'  ) t11   JOIN   (  \tSELECT t2.subject , t2.object  \tFROM triples t2   \tWHERE   \t\t\tt2.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL'  ) t22  ON (t11.subject=t22.subject)  \t\t JOIN   (  \tSELECT t3.subject , t3.object   \tFROM triples t3   \tWHERE   \t\t\tt3.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_from'   \t\t\t\t ) t33 ON (t11.subject=t33.object)  JOIN   (  \tSELECT t4.subject   \tFROM triples t4   \tWHERE   \t\tt4.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL'   \tAND   \t\tt4.object='http://ontos/OntosMiner/Common.English/ontology#Author'  \t\t\t\t ) t44 ON (t44.subject=t33.subject)  JOIN   (  \tSELECT t5.subject, t5.object as obh \tFROM triples t5   \tWHERE   \t\tt5.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_to'   ) t55 ON (t55.subject=t44.subject)  JOIN   (  \tSELECT t6.subject, t6.object \tFROM triples t6   \tWHERE   \t\tt6.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL'   ) t66 ON (t66.subject=t55.obh)\n INFO [main] (ParseDriver.java:249) - Parsing command: SELECT t11.subject, t22.object , t33.subject , t66.object  FROM  (  \tSELECT t1.subject  \tFROM triples t1   \tWHERE  \t\tt1.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL'   \tAND   \t\tt1.object='http://ontos/OntosMiner/Common.English/ontology#Citation'  ) t11   JOIN   (  \tSELECT t2.subject , t2.object  \tFROM triples t2   \tWHERE   \t\t\tt2.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL'  ) t22  ON (t11.subject=t22.subject)  \t\t JOIN   (  \tSELECT t3.subject , t3.object   \tFROM triples t3   \tWHERE   \t\t\tt3.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_from'   \t\t\t\t ) t33 ON (t11.subject=t33.object)  JOIN   (  \tSELECT t4.subject   \tFROM triples t4   \tWHERE   \t\tt4.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL'   \tAND   \t\tt4.object='http://ontos/OntosMiner/Common.English/ontology#Author'  \t\t\t\t ) t44 ON (t44.subject=t33.subject)  JOIN   (  \tSELECT t5.subject, t5.object as obh \tFROM triples t5   \tWHERE   \t\tt5.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_to'   ) t55 ON (t55.subject=t44.subject)  JOIN   (  \tSELECT t6.subject, t6.object \tFROM triples t6   \tWHERE   \t\tt6.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL'   ) t66 ON (t66.subject=t55.obh)\n INFO [main] (ParseDriver.java:263) - Parse Completed\n INFO [main] (HiveMetaStore.java:126) - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore\n INFO [main] (ObjectStore.java:124) - ObjectStore, initialize called\n INFO [main] (ObjectStore.java:146) - found resource jpox.properties at file:/home/vseledkin/workspace/HiveDrv/bin/jpox.properties\n WARN [main] (Log4JLogger.java:98) - Bundle \"org.jpox\" has an optional dependency to \"org.eclipse.equinox.registry\" but it cannot be resolved\n WARN [main] (Log4JLogger.java:98) - Bundle \"org.jpox\" has an optional dependency to \"org.eclipse.core.runtime\" but it cannot be resolved\n INFO [main] (Log4JLogger.java:79) - ================= Persistence Configuration ===============\n INFO [main] (Log4JLogger.java:79) - JPOX Persistence Factory - Vendor: \"JPOX\"  Version: \"1.2.2\"\n INFO [main] (Log4JLogger.java:79) - JPOX Persistence Factory initialised for datastore URL=\"jdbc:derby:;databaseName=metastore_db;create=true\" driver=\"org.apache.derby.jdbc.EmbeddedDriver\" userName=\"APP\"\n INFO [main] (Log4JLogger.java:79) - ===========================================================\n INFO [main] (Log4JLogger.java:79) - Initialising Catalog \"\", Schema \"APP\" using \"SchemaTable\" auto-start option\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of org.apache.hadoop.hive.metastore.model.MDatabase since it was managed previously\n INFO [main] (Log4JLogger.java:79) - No manager for annotations was found in the CLASSPATH so all annotations are ignored.\n WARN [main] (Log4JLogger.java:98) - MetaData Parser encountered an error in file \"jar:file:/home/vseledkin/workspace/hive/build/hive_metastore.jar!/package.jdo\" at line 282, column 13 : The content of element type \"class\" must match \"(extension*,implements*,datastore-identity?,primary-key?,inheritance?,version?,join*,foreign-key*,index*,unique*,column*,field*,property*,query*,fetch-group*,extension*)\". - Please check your specification of DTD and the validity of the MetaData XML that you have specified.\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of org.apache.hadoop.hive.metastore.model.MStorageDescriptor since it was managed previously\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of org.apache.hadoop.hive.metastore.model.MSerDeInfo since it was managed previously\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of org.apache.hadoop.hive.metastore.model.MTable since it was managed previously\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of org.apache.hadoop.hive.metastore.model.MPartition since it was managed previously\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Class : org.apache.hadoop.hive.metastore.model.MDatabase [Table : DBS, InheritanceStrategy : new-table]\n INFO [main] (Log4JLogger.java:79) - The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Class : org.apache.hadoop.hive.metastore.model.MSerDeInfo [Table : SERDES, InheritanceStrategy : new-table]\n INFO [main] (Log4JLogger.java:79) - The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Class : org.apache.hadoop.hive.metastore.model.MStorageDescriptor [Table : SDS, InheritanceStrategy : new-table]\n INFO [main] (Log4JLogger.java:79) - The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n INFO [main] (Log4JLogger.java:79) - The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Class : org.apache.hadoop.hive.metastore.model.MTable [Table : TBLS, InheritanceStrategy : new-table]\n INFO [main] (Log4JLogger.java:79) - The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n INFO [main] (Log4JLogger.java:79) - The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Class : org.apache.hadoop.hive.metastore.model.MPartition [Table : PARTITIONS, InheritanceStrategy : new-table]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MSerDeInfo.parameters [Table : SERDE_PARAMS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MPartition.parameters [Table : PARTITION_PARAMS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MPartition.values [Table : PARTITION_KEY_VALS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MTable.parameters [Table : TABLE_PARAMS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MTable.partitionKeys [Table : PARTITION_KEYS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MStorageDescriptor.bucketCols [Table : BUCKETING_COLS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MStorageDescriptor.cols [Table : COLUMNS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MStorageDescriptor.parameters [Table : SD_PARAMS]\n INFO [main] (Log4JLogger.java:79) - Managing Persistence of Field : org.apache.hadoop.hive.metastore.model.MStorageDescriptor.sortCols [Table : SORT_COLS]\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table SERDES\n INFO [main] (Log4JLogger.java:79) - Validating 0 foreign key(s) for table SERDES\n INFO [main] (Log4JLogger.java:79) - Validating 1 index(es) for table SERDES\n INFO [main] (Log4JLogger.java:79) - Validating 2 unique key(s) for table PARTITIONS\n INFO [main] (Log4JLogger.java:79) - Validating 2 foreign key(s) for table PARTITIONS\n INFO [main] (Log4JLogger.java:79) - Validating 4 index(es) for table PARTITIONS\n INFO [main] (Log4JLogger.java:79) - Validating 2 unique key(s) for table TBLS\n INFO [main] (Log4JLogger.java:79) - Validating 2 foreign key(s) for table TBLS\n INFO [main] (Log4JLogger.java:79) - Validating 4 index(es) for table TBLS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table SDS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table SDS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table SDS\n INFO [main] (Log4JLogger.java:79) - Validating 2 unique key(s) for table DBS\n INFO [main] (Log4JLogger.java:79) - Validating 0 foreign key(s) for table DBS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table DBS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table SORT_COLS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table SORT_COLS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table SORT_COLS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table TABLE_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table TABLE_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table TABLE_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table COLUMNS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table COLUMNS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table COLUMNS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table PARTITION_KEYS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table PARTITION_KEYS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table PARTITION_KEYS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table SD_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table SD_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table SD_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table PARTITION_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table PARTITION_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table PARTITION_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table PARTITION_KEY_VALS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table PARTITION_KEY_VALS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table PARTITION_KEY_VALS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table SERDE_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table SERDE_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table SERDE_PARAMS\n INFO [main] (Log4JLogger.java:79) - Validating 1 unique key(s) for table BUCKETING_COLS\n INFO [main] (Log4JLogger.java:79) - Validating 1 foreign key(s) for table BUCKETING_COLS\n INFO [main] (Log4JLogger.java:79) - Validating 2 index(es) for table BUCKETING_COLS\n INFO [main] (Log4JLogger.java:79) - Catalog \"\", Schema \"APP\" initialised - managing 14 classes\n INFO [main] (Log4JLogger.java:79) - >> Found StoreManager org.jpox.store.rdbms.RDBMSManager\n INFO [main] (ObjectStore.java:110) - Initialized ObjectStore\n INFO [main] (SemanticAnalyzer.java:3086) - Starting Semantic Analysis\n INFO [main] (SemanticAnalyzer.java:3088) - Completed phase 1 of Semantic Analysis\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:3091) - Completed getting MetaData in Semantic Analysis\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1, string reducesinkvalue2, string reducesinkvalue3, string reducesinkvalue4}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1, string reducesinkvalue2, string reducesinkvalue3, string reducesinkvalue4, string reducesinkvalue5, string reducesinkvalue6, string reducesinkvalue7}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:579) - Get metadata for source tables\n INFO [main] (HiveMetaStore.java:164) - 0: get_table : db=default tbl=triples\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct triples { string tid, string subject, string predicate, string object, string type}\n INFO [main] (SemanticAnalyzer.java:595) - Get metadata for subqueries\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (SemanticAnalyzer.java:602) - Get metadata for destination tables\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1, string reducesinkvalue2, string reducesinkvalue3, string reducesinkvalue4}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1, string reducesinkvalue2, string reducesinkvalue3, string reducesinkvalue4, string reducesinkvalue5, string reducesinkvalue6, string reducesinkvalue7}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string reducesinkkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string reducesinkvalue0, string reducesinkvalue1}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_sortable_table { string joinkey0}\n INFO [main] (SemanticAnalyzer.java:3107) - Completed partition pruning\n INFO [main] (SemanticAnalyzer.java:3111) - Completed sample pruning\n INFO [main] (MetaStoreUtils.java:461) - DDL: struct binary_table { string temporarycol0, string temporarycol1, string temporarycol2, string temporarycol3, string temporarycol4}\n INFO [main] (SemanticAnalyzer.java:3120) - Completed plan generation\n INFO [main] (Driver.java:173) - Semantic Analysis Completed\nTotal MapReduce jobs = 3\n INFO [main] (SessionState.java:254) - Total MapReduce jobs = 3\nNumber of reducers = 1\n INFO [main] (SessionState.java:254) - Number of reducers = 1\nIn order to change numer of reducers use:\n INFO [main] (SessionState.java:254) - In order to change numer of reducers use:\n  set mapred.reduce.tasks = <number>\n INFO [main] (SessionState.java:254) -   set mapred.reduce.tasks = <number>\n WARN [main] (ExecDriver.java:109) - Number of reduce tasks not specified. Defaulting to jobconf value of: 1\n INFO [main] (ExecDriver.java:238) - Adding input file /user/hive/warehouse/triples\n WARN [main] (JobClient.java:547) - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.\n INFO [main] (FileInputFormat.java:181) - Total input paths to process : 1\nStarting Job = job_200812091129_0144, Tracking URL = http://ubunder.avicomp.com:50030/jobdetails.jsp?jobid=job_200812091129_0144\n INFO [main] (SessionState.java:254) - Starting Job = job_200812091129_0144, Tracking URL = http://ubunder.avicomp.com:50030/jobdetails.jsp?jobid=job_200812091129_0144\nKill Command = /home/vseledkin/workspace/HiveDrv/programs/hadoop-0.19.0 job  -Dmapred.job.tracker=ubunder.avicomp.com:9001 -kill job_200812091129_0144\n INFO [main] (SessionState.java:254) - Kill Command = /home/vseledkin/workspace/HiveDrv/programs/hadoop-0.19.0 job  -Dmapred.job.tracker=ubunder.avicomp.com:9001 -kill job_200812091129_0144\n map = 0%,  reduce =0%\n INFO [main] (SessionState.java:254) -  map = 0%,  reduce =0%\n map = 50%,  reduce =0%\n INFO [main] (SessionState.java:254) -  map = 50%,  reduce =0%\n map = 100%,  reduce =0%\n INFO [main] (SessionState.java:254) -  map = 100%,  reduce =0%\n map = 100%,  reduce =100%\n INFO [main] (SessionState.java:254) -  map = 100%,  reduce =100%\nERROR [main] (SessionState.java:263) - Ended Job = job_200812091129_0144 with errors\nEnded Job = job_200812091129_0144 with errors\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.ExecDriver\nERROR [main] (SessionState.java:263) - FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.ExecDriver\n------------------------------------ console output end ----------------------------------------\nand the stack trace in hadoop logs \n------------------------------------ stack trace ---------------------------------------------------\njava.lang.NullPointerException\n\tat org.apache.hadoop.hive.ql.exec.ExecReducer.configure(ExecReducer.java:81)\n\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:58)\n\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:83)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:337)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:155)\n\n------------------------------------ stack trace end ---------------------------------------------\nattached file contains table data to test problematic query","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12396066","id":"12396066","filename":"_user_hive_warehouse_triples_part-00000.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vseledkin","name":"vseledkin","key":"vseledkin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Seledkin","active":true,"timeZone":"Etc/UTC"},"created":"2008-12-15T09:21:40.440+0000","size":90851,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12396066/_user_hive_warehouse_triples_part-00000.tar.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12396940","id":"12396940","filename":"patch-151.1.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-12-30T23:55:27.492+0000","size":17530,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12396940/patch-151.1.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12396942","id":"12396942","filename":"patch-151.2.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-12-31T00:25:10.275+0000","size":18956,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12396942/patch-151.2.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"121976","customfield_12312823":null,"summary":"HiveQL Query execution bug: java.lang.NullPointerException","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vseledkin","name":"vseledkin","key":"vseledkin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Seledkin","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vseledkin","name":"vseledkin","key":"vseledkin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Seledkin","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Ubuntu Linux 386, Hadoop 0.19.0 Hive trunk","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12656581","id":"12656581","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vseledkin","name":"vseledkin","key":"vseledkin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Seledkin","active":true,"timeZone":"Etc/UTC"},"body":"At 25.12.2008 trunk 729399 version behaviour is changed. But Hive stil unable to execute query above. Simptoms: \n\nJob Submission failed with exception 'Input path does not exist: hdfs://ubunder.avicomp.com:9000/tmp/hive-vseledkin/93734513/662604171.10003'\nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.ExecDriver\n\nIt looks like if number of JOINS in query is more than 5 planner generates inconsistent execution process. Queries with 4 JOINS are executing without any problems. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vseledkin","name":"vseledkin","key":"vseledkin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Seledkin","active":true,"timeZone":"Etc/UTC"},"created":"2008-12-15T09:21:40.539+0000","updated":"2008-12-25T07:48:01.021+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12659291","id":"12659291","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"explain <query>;\n\nshows that the fetch task (Stage-0) which should be dependent on Stage-3 is actually a root task. So I think what is happening is that task is trying to read from the output of Stage-3 which has not even started yet!! This looks like a bad bug...\n\nThe output of the explain is as follows:\n\nhive> explain SELECT t11.subject, t22.object , t33.subject , t66.object FROM ( SELECT t1.subject FROM triples t1 WHERE t1.pre\ndicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL' AND t1.object='http://ontos/OntosMiner/Common.English/\nontology#Citation' ) t11 JOIN ( SELECT t2.subject , t2.object FROM triples t2 WHERE t2.predicate='http://sofa.semanticweb.org\n/sofa/v1.0/system#__LABEL_REL' ) t22 ON (t11.subject=t22.subject) JOIN ( SELECT t3.subject , t3.object FROM triples t3 WHERE \nt3.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_from' ) t33 ON (t11.subject=t33.object) JOIN ( SELECT t4.subject\n FROM triples t4 WHERE t4.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL' AND t4.object='http://ont\nos/OntosMiner/Common.English/ontology#Author' ) t44 ON (t44.subject=t33.subject) JOIN ( SELECT t5.subject, t5.object as obh F\nROM triples t5 WHERE t5.predicate='http://www.ontosearch.com/2007/12/ontosofa-ns#_to' ) t55 ON (t55.subject=t44.subject) JOIN\n ( SELECT t6.subject, t6.object FROM triples t6 WHERE t6.predicate='http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL'\n ) t66 ON (t66.subject=t55.obh);\nOK\nABSTRACT SYNTAX TREE:\n  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_JOIN (TOK_JOIN (TOK_JOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF tripl\nes t1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_COLREF t1 subject))) (TOK_WHERE (A\nND (= (TOK_COLREF t1 predicate) 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') (= (TOK_COLREF t1 object) 'h\nttp://ontos/OntosMiner/Common.English/ontology#Citation'))))) t11) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF triples t2)\n) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_COLREF t2 subject)) (TOK_SELEXPR (TOK_CO\nLREF t2 object))) (TOK_WHERE (= (TOK_COLREF t2 predicate) 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL')))) t22)\n (= (TOK_COLREF t11 subject) (TOK_COLREF t22 subject))) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF triples t3)) (TOK_INSE\nRT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_COLREF t3 subject)) (TOK_SELEXPR (TOK_COLREF t3 obj\nect))) (TOK_WHERE (= (TOK_COLREF t3 predicate) 'http://www.ontosearch.com/2007/12/ontosofa-ns#_from')))) t33) (= (TOK_COLREF \nt11 subject) (TOK_COLREF t33 object))) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF triples t4)) (TOK_INSERT (TOK_DESTINATI\nON (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_COLREF t4 subject))) (TOK_WHERE (AND (= (TOK_COLREF t4 predicate) 'h\nttp://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') (= (TOK_COLREF t4 object) 'http://ontos/OntosMiner/Common.Engl\nish/ontology#Author'))))) t44) (= (TOK_COLREF t44 subject) (TOK_COLREF t33 subject))) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK\n_TABREF triples t5)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_COLREF t5 subject)) (\nTOK_SELEXPR (TOK_COLREF t5 object) obh)) (TOK_WHERE (= (TOK_COLREF t5 predicate) 'http://www.ontosearch.com/2007/12/ontosofa-\nns#_to')))) t55) (= (TOK_COLREF t55 subject) (TOK_COLREF t44 subject))) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF triple\ns t6)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_COLREF t6 subject)) (TOK_SELEXPR (T\nOK_COLREF t6 object))) (TOK_WHERE (= (TOK_COLREF t6 predicate) 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL'))))\n t66) (= (TOK_COLREF t66 subject) (TOK_COLREF t55 obh)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (T\nOK_SELEXPR (TOK_COLREF t11 subject)) (TOK_SELEXPR (TOK_COLREF t22 object)) (TOK_SELEXPR (TOK_COLREF t33 subject)) (TOK_SELEXP\nR (TOK_COLREF t66 object)))))\n\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-2 is a root stage\n  Stage-3 depends on stages: Stage-2\n  Stage-0 is a root stage\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Map Reduce\n      Alias -> Map Operator Tree:\n        t66:t6 \n            Select Operator\n              expressions:\n                    expr: subject\n                    type: string\n                    expr: object\n                    type: string\n                    expr: predicate\n                    type: string\n              Filter Operator\n                predicate:\n                    expr: (2 = 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL')\n                    type: boolean\n                Select Operator\n                  expressions:\n                        expr: 0\n                        type: string\n                        expr: 1\n                        type: string\n                  Reduce Output Operator\n                    key expressions:\n                          expr: 0\n                          type: string\n                    sort order: +\n                    Map-reduce partition columns:\n                          expr: 0\n                          type: string\n                    tag: 1\n                    value expressions:\n                          expr: 0\n                          type: string\n                          expr: 1\n                          type: string\n      Reduce Operator Tree:\n        Join Operator\n          condition map:\n               Inner Join 0 to 1\n          condition expressions:\n            0 {VALUE.0} {VALUE.1} {VALUE.2} {VALUE.3} {VALUE.4} {VALUE.5} {VALUE.6} {VALUE.7}\n            1 {VALUE.0} {VALUE.1}\n          Select Operator\n            expressions:\n                  expr: 3\n                  type: string\n                  expr: 5\n                  type: string\n                  expr: 0\n                  type: string\n                  expr: 9\n                  type: string\n            File Output Operator\n              compressed: true\n              table:\n                  input format: org.apache.hadoop.mapred.TextInputFormat\n                  output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat\n\n  Stage: Stage-2\n    Map Reduce\n      Alias -> Map Operator Tree:\n        t22:t2 \n            Select Operator\n              expressions:\n                    expr: subject\n                    type: string\n                    expr: object\n                    type: string\n                    expr: predicate\n                    type: string\n              Filter Operator\n                predicate:\n                    expr: (2 = 'http://sofa.semanticweb.org/sofa/v1.0/system#__LABEL_REL')\n                    type: boolean\n                Select Operator\n                  expressions:\n                        expr: 0\n                        type: string\n                        expr: 1\n                        type: string\n                  Reduce Output Operator\n                    key expressions:\n                          expr: 0\n                          type: string\n                    sort order: +\n                    Map-reduce partition columns:\n                          expr: 0\n                          type: string\n                    tag: 1\n                    value expressions:\n                          expr: 0\n                          type: string\n                          expr: 1\n                          type: string\n        t33:t3 \n            Select Operator\n              expressions:\n                    expr: subject\n                    type: string\n                    expr: object\n                    type: string\n                    expr: predicate\n                    type: string\n              Filter Operator\n                predicate:\n                    expr: (2 = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_from')\n                    type: boolean\n                Select Operator\n                  expressions:\n                        expr: 0\n                        type: string\n                        expr: 1\n                        type: string\n                  Reduce Output Operator\n                    key expressions:\n                          expr: 1\n                          type: string\n                    sort order: +\n                    Map-reduce partition columns:\n                          expr: 1\n                          type: string\n                    tag: 2\n                    value expressions:\n                          expr: 0\n                          type: string\n                          expr: 1\n                          type: string\n        t11:t1 \n            Select Operator\n              expressions:\n                    expr: subject\n                    type: string\n                    expr: predicate\n                    type: string\n                    expr: object\n                    type: string\n              Filter Operator\n                predicate:\n                    expr: ((1 = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (2 = 'http://ontos/Ontos\nMiner/Common.English/ontology#Citation'))\n                    type: boolean\n                Select Operator\n                  expressions:\n                        expr: 0\n                        type: string\n                  Reduce Output Operator\n                    key expressions:\n                          expr: 0\n                          type: string\n                    sort order: +\n                    Map-reduce partition columns:\n                          expr: 0\n                          type: string\n                    tag: 0\n                    value expressions:\n                          expr: 0\n                          type: string\n      Reduce Operator Tree:\n        Join Operator\n          condition map:\n               Inner Join 0 to 1\n               Inner Join 0 to 1\n          condition expressions:\n            0 {VALUE.0}\n            1 {VALUE.0} {VALUE.1}\n            2 {VALUE.0} {VALUE.1}\n          File Output Operator\n            compressed: true\n            table:\n                input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n                output format: org.apache.hadoop.mapred.SequenceFileOutputFormat\n                name: binary_table\n\n  Stage: Stage-3\n    Map Reduce\n      Alias -> Map Operator Tree:\n        $INTNAME \n          Reduce Output Operator\n            key expressions:\n                  expr: 3\n                  type: string\n            sort order: +\n            Map-reduce partition columns:\n                  expr: 3\n                  type: string\n            tag: 0\n            value expressions:\n                  expr: 3\n                  type: string\n                  expr: 4\n                  type: string\n                  expr: 0\n                  type: string\n                  expr: 1\n                  type: string\n                  expr: 2\n                  type: string\n        t55:t5 \n            Select Operator\n              expressions:\n                    expr: subject\n                    type: string\n                    expr: object\n                    type: string\n                    expr: predicate\n                    type: string\n              Filter Operator\n                predicate:\n                    expr: (2 = 'http://www.ontosearch.com/2007/12/ontosofa-ns#_to')\n                    type: boolean\n                Select Operator\n                  expressions:\n                        expr: 0\n                        type: string\n                        expr: 1\n                        type: string\n                  Reduce Output Operator\n                    key expressions:\n                          expr: 0\n                          type: string\n                    sort order: +\n                    Map-reduce partition columns:\n                          expr: 0\n                          type: string\n                    tag: 2\n                    value expressions:\n                          expr: 0\n                          type: string\n                          expr: 1\n                          type: string\n        t44:t4 \n            Select Operator\n              expressions:\n                    expr: subject\n                    type: string\n                    expr: predicate\n                    type: string\n                    expr: object\n                    type: string\n              Filter Operator\n                predicate:\n                    expr: ((1 = 'http://sofa.semanticweb.org/sofa/v1.0/system#__INSTANCEOF_REL') and (2 = 'http://ontos/Ontos\nMiner/Common.English/ontology#Author'))\n                    type: boolean\n                Select Operator\n                  expressions:\n                        expr: 0\n                        type: string\n                  Reduce Output Operator\n                    key expressions:\n                          expr: 0\n                          type: string\n                    sort order: +\n                    Map-reduce partition columns:\n                          expr: 0\n                          type: string\n                    tag: 1\n                    value expressions:\n                          expr: 0\n                          type: string\n      Reduce Operator Tree:\n        Join Operator\n          condition map:\n               Inner Join 0 to 1\n               Inner Join 1 to 1\n          condition expressions:\n            0 {VALUE.0} {VALUE.1} {VALUE.2} {VALUE.3} {VALUE.4}\n            1 {VALUE.0}\n            2 {VALUE.0} {VALUE.1}\n          Reduce Output Operator\n            key expressions:\n                  expr: 7\n                  type: string\n            sort order: +\n            Map-reduce partition columns:\n                  expr: 7\n                  type: string\n            tag: 0\n            value expressions:\n                  expr: 0\n                  type: string\n                  expr: 1\n                  type: string\n                  expr: 5\n                  type: string\n                  expr: 2\n                  type: string\n                  expr: 3\n                  type: string\n                  expr: 4\n                  type: string\n                  expr: 6\n                  type: string\n                  expr: 7\n                  type: string\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: -1\n\n\nTime taken: 0.69 seconds\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2008-12-27T00:24:44.047+0000","updated":"2008-12-27T00:24:44.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12659296","id":"12659296","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"categorizing as blocker.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2008-12-27T00:29:53.823+0000","updated":"2008-12-27T00:29:53.823+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12659414","id":"12659414","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vseledkin","name":"vseledkin","key":"vseledkin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Seledkin","active":true,"timeZone":"Etc/UTC"},"body":"Yes, blocking","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vseledkin","name":"vseledkin","key":"vseledkin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Seledkin","active":true,"timeZone":"Etc/UTC"},"created":"2008-12-28T08:19:05.047+0000","updated":"2008-12-28T08:19:05.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12659898","id":"12659898","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"body":"fetch task does not depend on any other task in the explain plan - that is a problem, but does not explain this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-12-30T19:14:08.788+0000","updated":"2008-12-30T19:14:08.788+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12659985","id":"12659985","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"body":"The task which depends on other tasks cannot be a root task - that was the basic problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-12-30T23:59:07.146+0000","updated":"2008-12-30T23:59:07.146+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12659989","id":"12659989","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"body":"will add more comments","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-12-31T00:24:56.983+0000","updated":"2008-12-31T00:24:56.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12659993","id":"12659993","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rsm","name":"rsm","key":"rsm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghotham Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 looks good.\n\nCan you add a comment about this fix?\nAlso, the variable names seem a little wonky. Change oldTask to parentTask and task to childTask. Also, currTask is an unnecessary variable, use childTask instead.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rsm","name":"rsm","key":"rsm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghotham Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-12-31T00:36:19.614+0000","updated":"2008-12-31T00:36:19.614+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12410364/comment/12660149","id":"12660149","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed revision 730302. Thanks Namit!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-12-31T21:13:07.306+0000","updated":"2008-12-31T21:13:07.306+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-151/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0l86n:"}}