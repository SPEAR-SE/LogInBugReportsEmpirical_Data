{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12701560","self":"https://issues.apache.org/jira/rest/api/2/issue/12701560","key":"HIVE-6671","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324986","id":"12324986","description":"released","name":"0.13.0","archived":false,"released":true,"releaseDate":"2014-04-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-03-15T10:24:02.056+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Mar 26 19:10:30 UTC 2014","customfield_12310420":"379906","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_957394497_*|*_1_*:*_1_*:*_2307865_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-03-25T21:48:22.571+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6671/watchers","watchCount":3,"isWatching":false},"created":"2014-03-14T19:13:20.238+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[{"id":"12385449","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12385449","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12646899","key":"HIVE-4531","self":"https://issues.apache.org/jira/rest/api/2/issue/12646899","fields":{"summary":"[WebHCat] Collecting task logs to hdfs","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-03-26T19:10:30.547+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320912","id":"12320912","name":"WebHCat","description":"Provides rest interface for HCatalog "}],"timeoriginalestimate":null,"description":"We should throw a consistent exception if enablelog=true and WebHCat is talking to H2","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12634811","id":"12634811","filename":"HIVE-6671.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-14T19:51:44.507+0000","size":1296,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12634811/HIVE-6671.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"380191","customfield_12312823":null,"summary":"WebHCat Job Submission API 'enablelog' parameter is only supported with Hadoop 1","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701560/comment/13935536","id":"13935536","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"no pre commit tests","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-14T19:51:44.511+0000","updated":"2014-03-14T19:51:44.511+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701560/comment/13936118","id":"13936118","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12634811/HIVE-6671.patch\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1813/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1813/console\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hwi ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hwi ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hwi ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive ODBC 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-odbc ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/odbc (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-odbc ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/odbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-odbc/0.14.0-SNAPSHOT/hive-odbc-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Aggregator 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-aggregator ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-aggregator ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims-aggregator/0.14.0-SNAPSHOT/hive-shims-aggregator-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive TestUtils 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-testutils ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/testutils (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/classes\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-testutils ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-testutils ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Packaging 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/maven-metadata.xml\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.pom\n[WARNING] The POM for org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT is missing, no dependency information available\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.jar\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [9.824s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [12.808s]\n[INFO] Hive Shims Common ................................. SUCCESS [4.310s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [3.196s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [4.255s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [2.648s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [10.116s]\n[INFO] Hive Shims ........................................ SUCCESS [0.783s]\n[INFO] Hive Common ....................................... SUCCESS [11.327s]\n[INFO] Hive Serde ........................................ SUCCESS [9.990s]\n[INFO] Hive Metastore .................................... SUCCESS [32.520s]\n[INFO] Hive Query Language ............................... SUCCESS [1:28.884s]\n[INFO] Hive Service ...................................... SUCCESS [8.738s]\n[INFO] Hive JDBC ......................................... SUCCESS [3.005s]\n[INFO] Hive Beeline ...................................... SUCCESS [3.161s]\n[INFO] Hive CLI .......................................... SUCCESS [2.718s]\n[INFO] Hive Contrib ...................................... SUCCESS [2.806s]\n[INFO] Hive HBase Handler ................................ SUCCESS [4.920s]\n[INFO] Hive HCatalog ..................................... SUCCESS [0.412s]\n[INFO] Hive HCatalog Core ................................ SUCCESS [2.213s]\n[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [2.549s]\n[INFO] Hive HCatalog Server Extensions ................... SUCCESS [1.579s]\n[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [1.356s]\n[INFO] Hive HCatalog Webhcat ............................. SUCCESS [12.001s]\n[INFO] Hive HWI .......................................... SUCCESS [1.256s]\n[INFO] Hive ODBC ......................................... SUCCESS [0.681s]\n[INFO] Hive Shims Aggregator ............................. SUCCESS [0.208s]\n[INFO] Hive TestUtils .................................... SUCCESS [0.377s]\n[INFO] Hive Packaging .................................... FAILURE [0.735s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 4:04.168s\n[INFO] Finished at: Sat Mar 15 06:24:00 EDT 2014\n[INFO] Final Memory: 74M/515M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal on project hive-packaging: Could not resolve dependencies for project org.apache.hive:hive-packaging:pom:0.14.0-SNAPSHOT: Could not find artifact org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT in apache.snapshots (http://repository.apache.org/snapshots) -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-packaging\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12634811","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-03-15T10:24:02.056+0000","updated":"2014-03-15T10:24:02.056+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701560/comment/13947206","id":"13947206","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alangates","name":"alangates","key":"alangates","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alan Gates","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch checked into trunk and 0.13","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alangates","name":"alangates","key":"alangates","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alan Gates","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-25T21:48:22.595+0000","updated":"2014-03-25T21:48:22.595+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701560/comment/13947579","id":"13947579","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"This could be documented in the wiki here:\n\n* [MapReduce Job Parameters |https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference+MapReduceJar#WebHCatReferenceMapReduceJar-Parameters]\n* [MapReduce Streaming Job Parameters |https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference+MapReduceStream#WebHCatReferenceMapReduceStream-Parameters]\n* [Hive Job Parameters  |https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference+Hive#WebHCatReferenceHive-Parameters]\n* [Pig Job Parameters |https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference+Pig#WebHCatReferencePig-Parameters]\n\nAnd perhaps here too:\n\n* [Using WebHCat:  Log Files |https://cwiki.apache.org/confluence/display/Hive/WebHCat+UsingWebHCat#WebHCatUsingWebHCat-LogFiles]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2014-03-26T05:55:55.125+0000","updated":"2014-03-26T05:55:55.125+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701560/comment/13948176","id":"13948176","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"this probably does not need be documented at all.  Long term this should be supported on hadoop 2.  Short term the error produced will make it clear to the user it's not supported.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-26T17:26:47.431+0000","updated":"2014-03-26T17:26:47.431+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701560/comment/13948338","id":"13948338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"Yay, less work to do.  :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2014-03-26T19:10:30.547+0000","updated":"2014-03-26T19:10:30.547+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6671/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1tgj3:"}}