{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13016935","self":"https://issues.apache.org/jira/rest/api/2/issue/13016935","key":"HIVE-15104","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-11-01T17:32:02.016+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 22 23:58:02 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_16561066997_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_14323518667","customfield_12312321":null,"resolutiondate":"2017-10-25T03:11:47.767+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15104/watchers","watchCount":12,"isWatching":false},"created":"2016-11-01T16:08:42.179+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"11.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-22T23:58:02.312+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"the same sql,  running on spark  and mr engine, will generate different size of shuffle data.\n\ni think it is because of hive on mr just serialize part of HiveKey, but hive on spark which using kryo will serialize full of Hivekey object.  \n\nwhat is your opionion?","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12867727","id":"12867727","filename":"HIVE-15104.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-12T08:26:13.557+0000","size":7779,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12867727/HIVE-15104.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893666","id":"12893666","filename":"HIVE-15104.10.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-24T04:14:57.910+0000","size":20208,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893666/HIVE-15104.10.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12868055","id":"12868055","filename":"HIVE-15104.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-15T11:29:43.566+0000","size":8456,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12868055/HIVE-15104.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12868935","id":"12868935","filename":"HIVE-15104.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-19T12:37:37.885+0000","size":23631,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12868935/HIVE-15104.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12877028","id":"12877028","filename":"HIVE-15104.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-13T06:42:31.454+0000","size":21416,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12877028/HIVE-15104.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883637","id":"12883637","filename":"HIVE-15104.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-25T01:24:54.366+0000","size":21425,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12883637/HIVE-15104.5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12892380","id":"12892380","filename":"HIVE-15104.6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-16T12:54:12.661+0000","size":20488,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12892380/HIVE-15104.6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12892511","id":"12892511","filename":"HIVE-15104.7.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-17T02:28:51.617+0000","size":20027,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12892511/HIVE-15104.7.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12892544","id":"12892544","filename":"HIVE-15104.8.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-17T06:59:22.854+0000","size":20187,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12892544/HIVE-15104.8.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12892549","id":"12892549","filename":"HIVE-15104.9.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-17T07:41:03.414+0000","size":20248,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12892549/HIVE-15104.9.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12869112","id":"12869112","filename":"TPC-H 100G.xlsx","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-20T15:12:05.464+0000","size":30724,"mimeType":"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet","content":"https://issues.apache.org/jira/secure/attachment/12869112/TPC-H+100G.xlsx"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Hive on Spark generate more shuffle data than hive on mr","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15626085","id":"15626085","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~wenli] Can you give an example that I can run and compare? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-01T17:32:02.016+0000","updated":"2016-11-01T17:32:02.016+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15627812","id":"15627812","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"body":"try select count(distinct col1), count (distinct col2) from table,   and see the statistic for shuffle data size.\n\nif you cann't reproduce, let me know.    i will find one table in tpch, and reproduce , then tell the details step.  \n\nthank you~","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-11-02T05:34:40.333+0000","updated":"2016-11-02T05:34:40.333+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15628605","id":"15628605","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Seems MR can just serialize the key as BytesWritable instead of HiveKey. We once hit some problem when only serializing the BytesWritable part. But I think it's worth investigating whether we can improve.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-11-02T11:02:02.241+0000","updated":"2016-11-02T11:02:02.241+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15630435","id":"15630435","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"This is changed by HIVE-8017. [~lirui] Do you recall what kind of issues it caused?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-02T20:48:21.869+0000","updated":"2016-11-02T20:48:21.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15631053","id":"15631053","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"We need to use HiveKey because it holds the proper hash code to be used for partitioning. MR also uses HiveKey, but in OutputCollector, seems it only serializes the BytesWritable part. [~wenli], is this what you mean?\nI suspect we'll need help from Spark if we want to do something similar.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-11-03T00:42:47.718+0000","updated":"2016-11-03T00:42:47.718+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15631376","id":"15631376","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"This is rather interesting. I know I originally reviewed HIVE-8017, but I didn't really know why ByteWritable works for MR while we need HiveKey for Spark. Since Spark is stable now, it would be interesting to find out at least why, whether we can optimize or not.\n\n[~ruili], since you originally discovered the problem, could you revisit the issue? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-03T03:14:14.816+0000","updated":"2016-11-03T03:14:14.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15632244","id":"15632244","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz], here's what I find so far.\nFirstly, MR uses HiveKey as the [key type|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java#L253]. So we're inline with MR. HiveKey extends BytesWritable. I think the main reason we need HiveKey is we don't want the hash code simply computed from the internal bytes. Instead, we somehow compute the hash code elsewhere and set it into HiveKey.\n\nDuring shuffle, MR passes the HiveKey to OutputCollector. OutputCollector computes the proper partition for HiveKey (using the hash code), and uses [WritableSerialization|https://github.com/apache/hadoop/blob/release-2.7.2-RC2/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/serializer/WritableSerialization.java#L97] to serialize it. At this point, it's OK to just serialize the BytesWritable part since the partition has already been figured out.\n\nOn reduce side, WritableSerialization is used again to deserialize input key as HiveKey, then feed it to ExecReducer. Of course at this point, the HiveKey's hash code is just 0. But it doesn't matter because it's not needed any more. And ExecReducer just cast the input key as BytesWritable.\n\nTherefore, I think whether we can achieve the same depends on how Spark deals with the HiveKey we pass to it. If that's possible, we can register a custom Serializer for HiveKey and only ser/de the BytesWritable part. Here're some docs regarding how to do that:\n[spark.kryo.registrator|http://spark.apache.org/docs/latest/configuration.html#compression-and-serialization]\n[kryo registration|https://github.com/EsotericSoftware/kryo#registration]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-11-03T09:52:48.640+0000","updated":"2016-11-03T09:52:48.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15632623","id":"15632623","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui] So what you are saying is, it depends on how spark shuffles the data and whether spark relies on such hashCode to shuffle the data? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-03T12:44:13.560+0000","updated":"2016-11-03T12:44:13.560+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15633820","id":"15633820","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], thanks for sharing your findings. Can you confirm that Spark also uses BytesWritable.hashcode() to partition the RS output rows? If this is true, then there is no difference for Spark because the actual object Hive passed to Spark by RS is HiveKey, whose hashcode will be used for partitioning. \n\nIf this is the case, then we should be able to define the output of our map function and reduce function just as <BytesWritable, BytesWritable>, for which we don't need a custom serializer because we don't need to declare the type as <HiveKey, BytesWritable>. It seems that there is still a gap in our understanding.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-03T18:52:25.462+0000","updated":"2016-11-03T18:52:25.462+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15634112","id":"15634112","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I checked the source code and it seems that both Spark (Partitioner.scala) and MapReduce (HashPartitioner.java) calls key.hashCode() to get the partition number.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-03T20:18:48.394+0000","updated":"2016-11-03T20:18:48.394+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15634914","id":"15634914","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz], [~aihuaxu], both MR and Spark need HiveKey.hashCode to compute the partition number. HiveKey's [hashCode|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java#L58] is not computed on demand. Instead it's a field we set to the HiveKey.\nI think what we need to investigate is, whether the hash code is still needed after the HiveKey is serialized, e.g. Spark somehow deserialize the HiveKey and access the hash code again. If not, we can just ser/de the BytesWritable part of HiveKey because the hash code is not needed any more.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-11-04T01:48:15.919+0000","updated":"2016-11-04T01:48:15.919+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15644296","id":"15644296","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"I will take a look at Spark to see if it's needed after it's serialized.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-07T14:20:15.029+0000","updated":"2016-11-07T14:20:15.029+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15960146","id":"15960146","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~aihuaxu], are you still working on this? If not, do you mind if I take over?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-04-07T01:45:55.288+0000","updated":"2017-04-07T01:45:55.288+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15960801","id":"15960801","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui] I didn't have time to work on that . Feel free to take it over. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-07T13:34:58.273+0000","updated":"2017-04-07T13:34:58.273+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15998177","id":"15998177","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"I looked at the shuffle writers of Spark and none of them seem to need the hashCode/partitionId after the HiveKey is serialized. But I got a problem during implementation. The plan is to implement this Spark trait:\n{code}\ntrait KryoRegistrator {\n  def registerClasses(kryo: Kryo): Unit\n}\n{code}\nThen we set this implementing class to {{spark.kryo.registrator}}. At runtime, Spark will use reflection to instantiate our class and call its registerClasses to register the optimized SerDe for HiveKey.\nHowever, Kryo is relocated in Hive. After build, the method signature of our class will actually be:\n{{public void registerClasses(org.apache.hive.com.esotericsoftware.kryo.Kryo kryo)}}.\nWhen Spark calls the method, we get an {{AbstractMethodError}}. I suppose this is because the {{public void registerClasses(com.esotericsoftware.kryo.Kryo kryo)}} method is not really implemented.\nDoes anybody know how this can be resolved?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-05T11:18:29.439+0000","updated":"2017-05-05T11:18:29.439+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/15998437","id":"15998437","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Tried disabling relocation locally. It does solve the AbstractMethodError. However, seems Spark still needs the hashCode on reducer side. Will dig more ...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-05T14:56:28.093+0000","updated":"2017-05-05T14:56:28.093+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16007788","id":"16007788","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Spark needs the hash code on reducer side for the groupBy shuffling. Since groupBy does no ordering, reducer needs to put the shuffled data into a map to combine values by key, thus needing the hash code. We just need to keep the hash code during SerDe if groupBy shuffle is used.\n\nUpload a PoC patch to demonstrate the idea. It disables kryo relocation which should not be acceptable.\n\nAlso did simple test to see the improvement. The test is to run a query: {{select key, count ( * ) from A group by key order by key;}}, where A contains 40000000 records with 20 distinct keys. The measurement is the number of bytes written during shuffle. I tested optimize HiveKey alone, as well as optimize HiveKey and BytesWritable. We can see even for simple classes like BytesWritable, the custom SerDe does better than a generic one.\n|| ||Opt(N)||Opt(Y, Key)||Opt(Y, Key + Value)||\n||GBY(Y)|2269|1953|1699|\n||GBY(N)|2269|1713|1460|","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-12T08:26:13.563+0000","updated":"2017-05-12T08:26:13.563+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16008107","id":"16008107","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], great progress! Thanks for keeping up the effort.\n\nAs to Kryo class relocation, I think Hive did that to avoid version difference between Spark and Hive. (git history might confirm this.) I'm concerned that class conflicts might come back if we stop relocating Kryo. Any thoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-12T13:16:56.550+0000","updated":"2017-05-12T13:16:56.550+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16008502","id":"16008502","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12867727/HIVE-15104.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 10688 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_3] (batchId=97)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=97)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.org.apache.hadoop.hive.cli.TestNegativeCliDriver (batchId=89)\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testSparkQuery (batchId=225)\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testTempTable (batchId=225)\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=225)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5226/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5226/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5226/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 7 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12867727 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-12T18:10:54.104+0000","updated":"2017-05-12T18:10:54.104+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16009026","id":"16009026","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz], kryo was relocated in HIVE-5915. So it's not intended for Spark. Actually, we're on the same version as Spark-2.0.0: kryo-shaded-3.0.3.\nbq. I'm concerned that class conflicts might come back if we stop relocating Kryo\nYou're right. I'm not sure whether it's a conflict or loading issue, but when I tried to run some TPC-H benchmark, I got a ClassNotFoundException, although the class is there in hive-exec.jar. I'll see how to workaround this.\n\nBTW, the test in my last comment shuffles very little data. That's why optimizing the overhead can have a significant improvement. I guess this won't be the case in real world query. That's why I want to run some more serious benchmark.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-13T01:34:26.491+0000","updated":"2017-05-13T01:34:26.491+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16010348","id":"16010348","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"The CNF is due to how kryo is loaded in {{KryoMessageCodec}}. W/ relocation, kryo is in package {{org.apache.hive.com.esotericsoftware}}. So it's loaded from hive-exec.jar. Spark adds hive-exec.jar at runtime with some URL class loader. W/o relocation, we're using same kryo as Spark. Kryo's class loader is by default the one that loads it - therefore the AppClassLoader. However, AppClassLoader cannot load classes from hive-exec.jar and thus the CNF.\nTo solve it, we can make {{KryoMessageCodec}} use the current context loader.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-15T11:29:43.571+0000","updated":"2017-05-15T11:29:43.571+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16010433","id":"16010433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12868055/HIVE-15104.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10698 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_ppd_decimal] (batchId=9)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=144)\norg.apache.hive.jdbc.TestJdbcWithMiniHS2.testConcurrentStatements (batchId=225)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5260/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5260/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5260/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 3 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12868055 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-15T12:49:08.452+0000","updated":"2017-05-15T12:49:08.452+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16017527","id":"16017527","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12868935/HIVE-15104.3.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10738 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_3] (batchId=97)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=97)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query24] (batchId=231)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5349/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5349/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5349/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 3 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12868935 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-19T15:17:58.388+0000","updated":"2017-05-19T15:17:58.388+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16017621","id":"16017621","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Patch v3 compiles the registrators at runtime, so that we don't have to disable kryo relocation. I've also put it on RB. Will upload a benchmark result later.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-19T16:27:10.621+0000","updated":"2017-05-19T16:27:10.621+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16018496","id":"16018496","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Attaching TPC-H benchmark result. It shows the improvement is more obvious for long queries when we need to shuffle a lot of data. And it's better to use with groupBy shuffle disabled.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-20T15:12:05.471+0000","updated":"2017-05-20T15:12:05.471+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16018507","id":"16018507","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12869112/TPC-H%20100G.xlsx\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5367/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5367/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5367/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-05-20 15:31:32.562\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-5367/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-20 15:31:32.564\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 7429f5f HIVE-16717: Extend shared scan optimizer to handle partitions (Jesus Camacho Rodriguez, reviewed by Ashutosh Chauhan)\n+ git clean -f -d\nRemoving ql/src/gen/vectorization/UDAFTemplates/VectorUDAFAvgDecimal.txt\nRemoving ql/src/gen/vectorization/UDAFTemplates/VectorUDAFAvgDecimalMerge.txt\nRemoving ql/src/gen/vectorization/UDAFTemplates/VectorUDAFAvgMerge.txt\nRemoving ql/src/gen/vectorization/UDAFTemplates/VectorUDAFAvgTimestamp.txt\nRemoving ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/VectorUDAFSumTimestamp.java\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 7429f5f HIVE-16717: Extend shared scan optimizer to handle partitions (Jesus Camacho Rodriguez, reviewed by Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-05-20 15:31:33.510\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\npatch: **** Only garbage was found in the patch input.\npatch: **** Only garbage was found in the patch input.\npatch: **** Only garbage was found in the patch input.\nfatal: unrecognized input\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12869112 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-05-20T15:31:34.014+0000","updated":"2017-05-20T15:31:34.014+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16052006","id":"16052006","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"The approach here can cause problem when we cache RDDs, e.g. combining equivalent works. The cached RDDs will be serialized when stored to disk or transferred via network, then we need the hash code after the data is deserialized. I think we have to ser/de the hash code anyway to be safe.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-16T14:59:55.725+0000","updated":"2017-06-16T14:59:55.725+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16085271","id":"16085271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Update patch v4:\n1. Moved the registrator code to a resource file. Hopefully the patch is more readable.\n2. To be safe, we still have to store the hash code. But that's still better than the generic serializer.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-13T06:44:46.351+0000","updated":"2017-07-13T06:44:46.351+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16085276","id":"16085276","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"I also run another round of TPC-DS. The overall shuffle data is reduced by 12%. The query time improvement is however negligible - about 1.5%.\n[~xuefuz] do you think it's worth the effort?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-13T06:51:11.187+0000","updated":"2017-07-13T06:51:11.187+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16085324","id":"16085324","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], I'm wondering if there is anything new (other than moving code around). Last time we benchmarked and found there was actual performance degradation. We can do that again, and if the perf degradation still exists, we may not want this at lest not by default. I wasn't able to figure out why this degradation might happen.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-13T07:53:47.954+0000","updated":"2017-07-13T07:53:47.954+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16085384","id":"16085384","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~xuefuz], I can't reproduce the perf degradation on my side. Some case runs slower with the patch which I think is just variations. The overall perf (total time taken to run the benchmark) is still slightly improved. I don't have physical nodes to run the benchmark so it's done on VMs. It'd be great if you could rerun your benchmark, and we can take a closer look at the degradation. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-13T08:41:42.416+0000","updated":"2017-07-13T08:41:42.416+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16085465","id":"16085465","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12877028/HIVE-15104.4.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10889 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[create_merge_compressed] (batchId=237)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6004/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6004/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6004/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 6 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12877028 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-13T09:46:24.708+0000","updated":"2017-07-13T09:46:24.708+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16129871","id":"16129871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~xuefuz], with HIVE-17114 and HIVE-17321 the benchmark results become more stable and the improvement is a little higher. Here's the latest [100GB TPC-DS result|https://docs.google.com/spreadsheets/d/1ba-AbUpJOHNb0_5PZyWQHzrH4wfRljMxQP9vA9JACHg/edit?usp=sharing].\nWould you mind share your benchmark tool so that I can look into the perf degradation? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-17T04:13:59.585+0000","updated":"2017-08-17T04:13:59.585+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16129895","id":"16129895","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~lirui], thanks for continuing the work here. The improvement is impressive and not much perf degradation is observed. Let me get back my old benchmarks and see if those patches help.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-17T04:26:12.809+0000","updated":"2017-08-17T04:26:12.809+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16133290","id":"16133290","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], I found it difficulty to backport HIVE-17114 to our code base, so I had to give up. However, since you have a configuration to turn this on/off, I think it's find to have this and postpone the verification on my side later until we upgrade our Hive.\n\nI need some time to review your latest patch as it's different from the previous has some low-level class/jar manipulations.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-18T17:10:25.215+0000","updated":"2017-08-18T17:10:25.215+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16134639","id":"16134639","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~xuefuz] and take your time. I guess we can also run a round of QA test with the switch turned on.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-21T02:28:06.757+0000","updated":"2017-08-21T02:28:06.757+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16134983","id":"16134983","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Run tests with the switch on.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-21T10:01:26.948+0000","updated":"2017-08-21T10:01:26.948+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16141431","id":"16141431","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12883637/HIVE-15104.5.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 11001 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=61)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)\norg.apache.hive.jdbc.TestJdbcWithMiniHS2.testHttpRetryOnServerIdleTimeout (batchId=228)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6535/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6535/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6535/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 3 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12883637 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-08-25T09:47:29.322+0000","updated":"2017-08-25T09:47:29.322+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16148174","id":"16148174","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"The patch looks good to me. My only concern is about the reliability of the runtime compilation and jar creating. I'd think it's best if we can avoid that.\n\nI'm not 100% sure of the class loading problem we faced. If we define class HiveKryoRegistrator in Hive, with relocation, Spark's unrelocated kryo isn't able to find it?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-30T22:47:59.067+0000","updated":"2017-08-30T22:47:59.067+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16148340","id":"16148340","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz], my previous [comment|https://issues.apache.org/jira/browse/HIVE-15104?focusedCommentId=15998177&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15998177] has some explanations about the relocation problem. Basically, the problem is we need to implement some method defined by Spark, and the method accepts a kryo parameter. With relocation, Hive's kryo and Spark's kryo are in different packages. If we compile the class in Hive and runs it in Spark, Spark will find the method not implemented because it has a different signature.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-31T02:03:11.195+0000","updated":"2017-08-31T02:03:11.195+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16148351","id":"16148351","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I see. It might be possible to put this class in a new package (jar), for which we don't relocate kryo? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-31T02:17:34.460+0000","updated":"2017-08-31T02:17:34.460+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16148485","id":"16148485","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz], I'll try if that's feasible. Do you think it's OK to create a package just for one single class?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-31T05:46:30.504+0000","updated":"2017-08-31T05:46:30.504+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16149777","id":"16149777","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~lirui], I think creating a trivial package is still better than the runtime compilation/packaging. Plus, non-hos developers doesn't need to bother with that package. I don't foresee any problem with a separate project.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-31T23:27:59.301+0000","updated":"2017-08-31T23:27:59.301+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16201405","id":"16201405","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~xuefuz], sorry for taking so long to update. I tried out your proposal. The idea is to build the trivial package and add it with the {{--jars}} config when we launch the Spark app. So we need to locate the jar at runtime. To locate the jar, we can use reflection to get the class and call {{SparkContext.jarOfClass}} to get the URI. But since kryo is shaded, we don't have {{com.esotericsoftware.kryo.Kryo}} in our class path on Hive side. When I try to get the registrator class, I get a {{NoClassDefFoundError}} for {{com.esotericsoftware.kryo.Kryo}}.\r\nI guess one workaround is to let user specify the path to the jar, but that seems not very friendly. Any suggestions?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-12T03:57:57.971+0000","updated":"2017-10-12T03:57:57.971+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16201695","id":"16201695","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"One correction: the {{NoClassDefFoundError}} is for {{com.esotericsoftware.kryo.Serializer}}. That's because our HiveKey and BytesWritable serializer extend kryo's Serializer. When loading our classes, the super class also needs to be loaded and thus the error.\r\n\r\nSince the serializers are static nested classes of HiveKryoRegistrator, I tried loading the class w/o linking it, i.e. by calling {{ClassLoader.loadClass()}}. And that can avoid the NoClassDefFoundError. But not sure whether this is reliable and independent from JVM implementations.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-12T09:32:00.684+0000","updated":"2017-10-12T09:32:00.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16202897","id":"16202897","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~lirui], to locate the jar, can we assume that the jar is located somewhere in Hive's installation path? I'm not sure where (Hive, spark-submit, or remote driver) we need to find the location of the jar.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-13T01:01:03.894+0000","updated":"2017-10-13T01:01:03.894+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16203332","id":"16203332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz], we need to locate the jar on Hive side, before we call spark-submit. I made Hive include it in the {{HIVE_HOME/lib}} directory. I guess we can find the path to hive-exec.jar (which is also under lib) and search for the registrator jar under the same path (or relative ones). But that will totally depend on how Hive is installed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-13T09:59:20.164+0000","updated":"2017-10-13T09:59:20.164+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16203867","id":"16203867","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I think it's fairly safe to assume that hive-exec.jar and the new jar are in the same location. We can error out if the jar cannot be found in that location.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-13T17:07:30.664+0000","updated":"2017-10-13T17:07:30.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16205846","id":"16205846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Update patch v6 based on Xuefu's suggestions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-16T12:54:28.991+0000","updated":"2017-10-16T12:54:28.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16205863","id":"16205863","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12892380/HIVE-15104.6.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7323/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7323/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7323/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-10-16 13:13:35.520\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-7323/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-10-16 13:13:35.522\n+ cd apache-github-source-source\n+ git fetch origin\nFrom https://github.com/apache/hive\n   6339936..da304ef  master     -> origin/master\n+ git reset --hard HEAD\nHEAD is now at 6339936 HIVE-17749: Multiple class have missed the ASF header (Saijin Huang via Rui)\n+ git clean -f -d\nRemoving standalone-metastore/src/gen/org/\n+ git checkout master\nAlready on 'master'\nYour branch is behind 'origin/master' by 2 commits, and can be fast-forwarded.\n  (use \"git pull\" to update your local branch)\n+ git reset --hard origin/master\nHEAD is now at da304ef HIVE-17798: When replacing the src table names in BeeLine testing, the table names shouldn't be changed to lower case (Marta Kuczora, via Peter Vary)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-10-16 13:13:39.565\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java: No such file or directory\nerror: a/itests/src/test/resources/testconfiguration.properties: No such file or directory\nerror: a/packaging/pom.xml: No such file or directory\nerror: a/pom.xml: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/LocalHiveSparkClient.java: No such file or directory\nerror: a/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java: No such file or directory\nerror: a/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12892380 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-10-16T13:13:40.156+0000","updated":"2017-10-16T13:13:40.156+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16207028","id":"16207028","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12892511/HIVE-15104.7.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7341/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7341/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7341/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-7341/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-10-17 05:22:03.427\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 8c3f0e4 HIVE-17815: prevent OOM with Atlas Hive hook (Anishek Agarwal reviewed by Thejas Nair)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 8c3f0e4 HIVE-17815: prevent OOM with Atlas Hive hook (Anishek Agarwal reviewed by Thejas Nair)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-10-17 05:22:03.911\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java\npatching file hive-kryo-registrator/pom.xml\npatching file hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java\npatching file itests/src/test/resources/testconfiguration.properties\npatching file packaging/pom.xml\npatching file pom.xml\npatching file ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveSparkClientFactory.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/exec/spark/LocalHiveSparkClient.java\npatching file ql/src/test/queries/clientpositive/spark_opt_shuffle_serde.q\npatching file ql/src/test/results/clientpositive/spark/spark_opt_shuffle_serde.q.out\npatching file spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java\npatching file spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nprotoc-jar: protoc version: 250, detected platform: linux/amd64\nprotoc-jar: executing: [/tmp/protoc9130095883787762036.exe, -I/data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/protobuf/org/apache/hadoop/hive/metastore, --java_out=/data/hiveptest/working/apache-github-source-source/standalone-metastore/target/generated-sources, /data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/protobuf/org/apache/hadoop/hive/metastore/metastore.proto]\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/standalone-metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nDataNucleus Enhancer (version 4.1.17) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMetastoreDBProperties\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMResourcePlan\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMPool\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMTrigger\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMMapping\nDataNucleus Enhancer completed with success for 35 classes. Timings : input=193 ms, enhance=178 ms, total=371 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g\norg/apache/hadoop/hive/ql/parse/HintParser.g\nGenerating vector expression code\nGenerating vector expression test code\nERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[20,33] package com.esotericsoftware.kryo does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[21,33] package com.esotericsoftware.kryo does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[22,36] package com.esotericsoftware.kryo.io does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[23,36] package com.esotericsoftware.kryo.io does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[26,35] package org.apache.spark.serializer does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[34,45] cannot find symbol\n  symbol: class KryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[36,31] cannot find symbol\n  symbol:   class Kryo\n  location: class org.apache.hive.spark.HiveKryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[41,50] cannot find symbol\n  symbol:   class Serializer\n  location: class org.apache.hive.spark.HiveKryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[43,23] cannot find symbol\n  symbol:   class Kryo\n  location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[43,34] cannot find symbol\n  symbol:   class Output\n  location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[49,25] cannot find symbol\n  symbol:   class Kryo\n  location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[49,36] cannot find symbol\n  symbol:   class Input\n  location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[57,56] cannot find symbol\n  symbol:   class Serializer\n  location: class org.apache.hive.spark.HiveKryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[59,23] cannot find symbol\n  symbol:   class Kryo\n  location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[59,34] cannot find symbol\n  symbol:   class Output\n  location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[64,31] cannot find symbol\n  symbol:   class Kryo\n  location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[64,42] cannot find symbol\n  symbol:   class Input\n  location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-kryo-registrator: Compilation failure: Compilation failure:\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[20,33] package com.esotericsoftware.kryo does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[21,33] package com.esotericsoftware.kryo does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[22,36] package com.esotericsoftware.kryo.io does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[23,36] package com.esotericsoftware.kryo.io does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[26,35] package org.apache.spark.serializer does not exist\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[34,45] cannot find symbol\n[ERROR] symbol: class KryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[36,31] cannot find symbol\n[ERROR] symbol:   class Kryo\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[41,50] cannot find symbol\n[ERROR] symbol:   class Serializer\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[43,23] cannot find symbol\n[ERROR] symbol:   class Kryo\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[43,34] cannot find symbol\n[ERROR] symbol:   class Output\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[49,25] cannot find symbol\n[ERROR] symbol:   class Kryo\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[49,36] cannot find symbol\n[ERROR] symbol:   class Input\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.HiveKeySerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[57,56] cannot find symbol\n[ERROR] symbol:   class Serializer\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[59,23] cannot find symbol\n[ERROR] symbol:   class Kryo\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[59,34] cannot find symbol\n[ERROR] symbol:   class Output\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[64,31] cannot find symbol\n[ERROR] symbol:   class Kryo\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] /data/hiveptest/working/apache-github-source-source/hive-kryo-registrator/src/main/java/org/apache/hive/spark/HiveKryoRegistrator.java:[64,42] cannot find symbol\n[ERROR] symbol:   class Input\n[ERROR] location: class org.apache.hive.spark.HiveKryoRegistrator.BytesWritableSerializer\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-kryo-registrator\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12892511 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-10-17T05:23:56.648+0000","updated":"2017-10-17T05:23:56.648+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16207094","id":"16207094","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Fix dependencies","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-17T06:59:33.709+0000","updated":"2017-10-17T06:59:33.709+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16207563","id":"16207563","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12892549/HIVE-15104.9.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 11276 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=163)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multi] (batchId=110)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_notin] (batchId=133)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_scalar] (batchId=119)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_select] (batchId=119)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_views] (batchId=108)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query16] (batchId=243)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query94] (batchId=243)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query16] (batchId=241)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query94] (batchId=241)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=204)\norg.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerHighShuffleBytes (batchId=229)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7348/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7348/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7348/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 13 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12892549 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-10-17T12:26:06.117+0000","updated":"2017-10-17T12:26:06.117+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16208904","id":"16208904","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"The sub-query failures are tracked by HIVE-17823. Others are not related.\r\nI've put the 9th patch on RB. [~xuefuz], could you take another look? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-18T07:05:23.805+0000","updated":"2017-10-18T07:05:23.805+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16216271","id":"16216271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Update to address review comments. Also changed the default switch back to false.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-24T04:16:04.588+0000","updated":"2017-10-24T04:16:04.588+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16217431","id":"16217431","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-24T18:42:51.164+0000","updated":"2017-10-24T18:42:51.164+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16217849","id":"16217849","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12893666/HIVE-15104.10.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 11319 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multi] (batchId=110)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=205)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=222)\norg.apache.hadoop.hive.ql.parse.authorization.plugin.sqlstd.TestOperation2Privilege.checkHiveOperationTypeMatch (batchId=270)\norg.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerHighShuffleBytes (batchId=229)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7456/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7456/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7456/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 5 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12893666 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-10-24T23:01:03.646+0000","updated":"2017-10-24T23:01:03.646+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16218038","id":"16218038","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Pushed to master. Thanks Xuefu for the review!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-25T03:11:47.822+0000","updated":"2017-10-25T03:11:47.822+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16219861","id":"16219861","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"Doc note:  This adds *hive.spark.optimize.shuffle.serde* to HiveConf.java, so it needs to be documented in the wiki.\r\n\r\n* [Configuration Properties -- Spark | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-Spark]\r\n\r\nAdded a TODOC3.0 label.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2017-10-26T02:22:39.561+0000","updated":"2017-10-26T02:22:39.561+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16224326","id":"16224326","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~leftylev] for the reminder. I've updated the wiki.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-30T02:36:19.276+0000","updated":"2017-10-30T02:36:19.276+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16233602","id":"16233602","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"Good doc, thanks [~lirui].  I removed the TODOC3.0 label.\r\n\r\nHere's a direct link to the doc:\r\n\r\n* [hive.spark.optimize.shuffle.serde | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.spark.optimize.shuffle.serde]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2017-11-01T03:15:07.510+0000","updated":"2017-11-01T03:15:07.510+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16388551","id":"16388551","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"Hey [~lirui] I found some time to do some internal testing of this patch. I ran a 1 TB Parquet TPC-DS benchmark (subset of 49 queries, run three times each) on a physical cluster and found similar results to your TPC-DS benchmark.\r\n||||Baseline Run (default configuration)||Optimized Serde||Optimized Serde + No GroupBy||\r\n||Shuffle Bytes Read|699.5 GB|530.7 GB|531.6 GB|\r\n||Shuffle Bytes Written|690 GB|529.5 GB|530.3 GB|\r\n||Total Latency (min)|202|191|190|\r\n\r\nSo about a 25% improvement on shuffle data and 5% performance improvement. I think the improvement for the shuffle data is significant and is a goodimprovement.\r\n\r\nA few questions on the implementation.\r\n * The {{HiveKryoRegistrator}} still seems to be serializing the {{hashCode}} so where are the actual savings coming from?\r\n * I'm not sure I understand why the performance should improve when {{hive.spark.use.groupby.shuffle}} is set to {{false}}. It's still using the same registrator right?\r\n * You said that we need to serialize the {{hashCode}} because \"{{The cached RDDs will be serialized when stored to disk or transferred via network, then we need the hash code after the data is deserialized\"}} - why do we need the {{hashCode}} after deserializing the data?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2018-03-06T21:23:10.024+0000","updated":"2018-03-06T21:23:10.024+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16388915","id":"16388915","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~stakiar], thanks for trying this out.\r\nbq. The HiveKryoRegistrator still seems to be serializing the hashCode so where are the actual savings coming from?\r\nI didn't look deeply into kryo, but I think the reason is generic kryo SerDe has some overhead to store class meta info, while \r\n in {{HiveKryoRegistrator}} we just store the data. My earlier [comment|https://issues.apache.org/jira/browse/HIVE-15104?focusedCommentId=16007788&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16007788] shows custom SerDe can bring improvements for BytesWritable too.\r\n\r\nbq. I'm not sure I understand why the performance should improve when hive.spark.use.groupby.shuffle is set to false.\r\nI guess the difference is due to the different shuffle we used -- if {{hive.spark.use.groupby.shuffle}} is false, group-by-key shuffle is replaced with repartition-and-sort-within-partition shuffle. And yes, the registrator is same for the two cases.\r\n\r\nbq. why do we need the hashCode after deserializing the data?\r\nFor MR, the hash code is not needed for deserialized HiveKey (see HiveKey::hashCode), because when HiveKey is deserialized, it's already been distributed to the proper reducer. For Spark, RDDs may get cached during the execution. So if we deserialize a cached RDD and try to partition it to a downstream reducer, we'll need the hash code available after deserialization.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-03-07T02:37:55.873+0000","updated":"2018-03-07T02:37:55.873+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13016935/comment/16485871","id":"16485871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"body":"Hive 3.0.0 has been released so closing this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-22T23:58:02.304+0000","updated":"2018-05-22T23:58:02.304+0000"}],"maxResults":64,"total":64,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15104/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i35ogf:"}}