{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12950750","self":"https://issues.apache.org/jira/rest/api/2/issue/12950750","key":"HIVE-13293","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334255","id":"12334255","name":"2.1.0","archived":false,"released":true,"releaseDate":"2016-06-20"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-03-16T13:51:23.308+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 17 08:17:23 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_2242736849_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_3121242906","customfield_12312321":null,"resolutiondate":"2016-05-17T08:17:23.838+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-13293/watchers","watchCount":5,"isWatching":false},"created":"2016-03-16T06:17:44.172+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"5.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-12-16T08:09:53.579+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"I use TPCx-BB to do some performance test on Hive on Spark engine. And found query 10 has performance degradation when enabling parallel order by.\nIt seems that sampling cost much time before running the real query.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803166","id":"12803166","filename":"HIVE-13293.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-10T05:53:17.288+0000","size":2296,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12803166/HIVE-13293.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803816","id":"12803816","filename":"HIVE-13293.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-13T08:27:04.184+0000","size":2399,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12803816/HIVE-13293.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12804096","id":"12804096","filename":"HIVE-13293.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-16T02:22:44.259+0000","size":2396,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12804096/HIVE-13293.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12804059","id":"12804059","filename":"HIVE-13293.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-15T12:59:50.916+0000","size":2396,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12804059/HIVE-13293.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803817","id":"12803817","filename":"HIVE-13293.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-13T08:34:44.232+0000","size":2396,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12803817/HIVE-13293.3.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Cache RDD to improve parallel order by performance for HoS","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Lifeng+Wang","name":"Lifeng Wang","key":"lifeng wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lifeng Wang","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Lifeng+Wang","name":"Lifeng Wang","key":"lifeng wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lifeng Wang","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15197341","id":"15197341","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, the result can vary from query to query due to the cost of a separate sampling spark job.  I'd image that the benefit diminishes  as the data to be processed get smaller.\n\nWhile we are here, [~Lifeng Wang], could you check if SamplingOptimizer, which does the similar thing for MR, also has the same effect for MapReduce engine? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-16T13:51:23.308+0000","updated":"2016-03-16T13:51:23.308+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15198571","id":"15198571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"My understanding is that to do the sampling, we need to compute the RDD, which can be a big overhead for complicated queries. Therefore the optimization only works for queries where order by is dominant. The best use case should be just ordering a big table. For complicated queries, the re-computation of RDD may eventually hurt the performance.\nMR doesn't have this problem because MR launches a separate job to do the ordering, and the data to be sampled is already on HDFS.\n\nI think one possible solution is that we can break the spark work at parallel order by, i.e. just as MR, we compute everything to be sorted, and then launch a separate spark job to just do the ordering. I can do a PoC to see how this works.\n[~xuefuz] what do you think?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-17T01:41:31.388+0000","updated":"2016-03-17T01:41:31.388+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15198647","id":"15198647","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], that sounds like a viable optimization. Yes, please do some research around that. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-17T02:38:32.954+0000","updated":"2016-03-17T02:38:32.954+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15211748","id":"15211748","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Just did some research about this. Actually the overhead is not so big as I thought. If a query is complicated, we'll have multiple stages. For spark, intermediate stages are called {{ShuffleMapStage}} and the last stage is called {{ResultStage}}. Suppose we have the following stage graph:\n{noformat}\nShuffleMapStage1\n      | (join)\nShuflleMapStage2\n      | (groupBy)\nShuffleMapStage3\n      | (sortByKey)\n   ResultStage4\n{noformat}\nWhen calling sortByKey, spark launches the sampling job. The job triggers computation of ShuffleMapStage1, ShuflleMapStage2 and a ResultStage that shares most of ShuffleMapStage3. When we launch the real job, we'll submit the above stage graph. But at this point, spark will consider ShuffleMapStage1 and ShuflleMapStage2 as already computed because the shuffle outputs are still in local disk. Therefore what's re-computed is just ShuffleMapStage3. I have done some tests to verify this.\nThat being said, when ShuffleMapStage3 is complicated enough, we'll still have some considerable overhead. And I think that's the case for Q10 in TPCx-BB.\nRather than splitting the task, I think a better and easier way is to cache the RDD before calling sortByKey. We can use DISK_ONLY storage level if memory is a concern. I'll come up with a patch for review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-25T12:18:13.240+0000","updated":"2016-03-25T12:18:13.240+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15234502","id":"15234502","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"I have tried both splitting the task and caching the RDD and chose the latter here. Because it's simpler and works with queries that have only one ShuffleMapStage. Regarding performance, these two solutions provide roughly same performance in my local tests. I used DISK_ONLY as storage level which I think is good enough for performance and avoids more memory overhead.\nLifeng, could you help test the patch with your data set? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-11T05:16:27.826+0000","updated":"2016-04-11T05:16:27.826+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15237434","id":"15237434","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], thanks for the investigation and the patch, which seems simple and straightforward. One question: what do you mean by \"only works queries that have only one ShuffleMapStage\"? In your previous example, there are actually a few such stages. Isn't your patch supposed to help that as well?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-12T15:55:46.130+0000","updated":"2016-04-12T15:55:46.130+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15238556","id":"15238556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~xuefuz] for the review.\nI mean it can work with queries that have only one ShuffleMapStage. It will definitely work with queries that have multiple ShuffleMapStage too. But as I said in previous comment, what we care about here is just the last ShuffleMapStage because that's what gets re-computed in parallel order by.\nOn the other hand, splitting task that has only one ShuffleMapStage seems weird and may be bad for performance. That's why I chose to cache the RDD.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-13T03:49:09.699+0000","updated":"2016-04-13T03:49:09.699+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15242888","id":"15242888","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12797965/HIVE-13293.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 9964 tests executed\n*Failed tests:*\n{noformat}\nTestJdbcWithMiniHS2 - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_llap_partitioned\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_non_ascii_literal2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_grouping_sets\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_interval_mapjoin\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_join_filters\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_noskew_multi_single_reducer\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7597/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7597/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7597/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 9 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12797965 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-04-15T12:31:34.268+0000","updated":"2016-04-15T12:31:34.268+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15277662","id":"15277662","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Upload same patch to trigger tests again. Our benchmark results show that the patch can improve performance for certain queries in TPC-BB by over 30%.\n\nOne shortcoming of parallel order by is that we will end up with more files, which can bring some overhead. We should minimize such overhead, e.g. HIVE-13572.\n\nAlso pinging [~xuefuz] for review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-10T05:53:17.292+0000","updated":"2016-05-10T05:53:17.292+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15280312","id":"15280312","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], thanks for working on this. The patch looks good, but one thing I'm not very sure of is the persistence level. Order by is almost always at the end of stages. Thus, does it make sense to have a mixed of memory and disk?\n\nAs a side, out of scope question, do we need to explicitly call rdd.unpersist() for those cached rdds once a query is completed? Right now, rdds are never reused across queries.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-11T15:48:28.663+0000","updated":"2016-05-11T15:48:28.663+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15280347","id":"15280347","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~xuefuz], yeah order by is mostly at the end of stages. But that doesn't mean the amount of data is small - that's why we need parallel order by. During our benchmark, we hit OOM for several cases, which is due to some bug in Spark 1.6.0. So I thought using memory level cache may make it even worse.\n\nTo your second question, we unpersist cached RDDs at the end of each job. You can refer to {{RemoteDriver#JobWrapper}} for that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-11T16:12:01.420+0000","updated":"2016-05-11T16:12:01.420+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15280380","id":"15280380","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Okay. Sounds good. +1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-11T16:29:50.356+0000","updated":"2016-05-11T16:29:50.356+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15281488","id":"15281488","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12803166/HIVE-13293.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 68 failed/errored test(s), 9194 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniLlapCliDriver - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-bucket_map_join_tez1.q-auto_sortmerge_join_16.q-skewjoin.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-join1.q-schema_evol_orc_nonvec_mapwork_part.q-mapjoin_decimal.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-load_dyn_part2.q-selectDistinctStar.q-vector_decimal_5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-mapjoin_mapjoin.q-insert_into1.q-vector_decimal_2.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-order_null.q-vector_acid3.q-orc_merge10.q-and-12-more - did not produce a TEST-*.xml file\nTestNegativeCliDriver-udf_invalid.q-nopart_insert.q-insert_into_with_schema.q-and-734-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-ppd_transform.q-union_remove_7.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket5\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket6\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_disable_merge_for_bucketing\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_map_operators\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_num_buckets\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_list_bucket_dml_10\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge9\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_orc_merge_diff_fs\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_reduce_deduplicate\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_stats\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby2_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_noskew_multi_single_reducer\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join34\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join35\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_3\norg.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService.testPreemptionQueueComparator\norg.apache.hadoop.hive.llap.daemon.impl.comparator.TestShortestJobFirstComparator.testWaitQueueComparatorWithinDagPriority\norg.apache.hadoop.hive.llap.tez.TestConverters.testFragmentSpecToTaskSpec\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote\norg.apache.hadoop.hive.metastore.TestFilterHooks.org.apache.hadoop.hive.metastore.TestFilterHooks\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreGetMetaConf.org.apache.hadoop.hive.metastore.TestHiveMetaStoreGetMetaConf\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs\norg.apache.hadoop.hive.metastore.TestMetaStoreEndFunctionListener.testEndFunctionListener\norg.apache.hadoop.hive.metastore.TestMetaStoreInitListener.testMetaStoreInitListener\norg.apache.hadoop.hive.metastore.TestMetaStoreMetrics.org.apache.hadoop.hive.metastore.TestMetaStoreMetrics\norg.apache.hadoop.hive.metastore.TestRetryingHMSHandler.testRetryingHMSHandler\norg.apache.hadoop.hive.metastore.hbase.TestHBaseSchemaTool.oneMondoTest\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testShowLocksFilterOptions\norg.apache.hadoop.hive.ql.security.TestExtendedAcls.org.apache.hadoop.hive.ql.security.TestExtendedAcls\norg.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener.org.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener\norg.apache.hadoop.hive.ql.security.TestStorageBasedClientSideAuthorizationProvider.testSimplePrivileges\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler\norg.apache.hive.jdbc.TestSSL.testSSLFetchHttp\norg.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc.org.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc\norg.apache.hive.service.cli.session.TestHiveSessionImpl.testLeakOperationHandle\norg.apache.hive.spark.client.TestSparkClient.testJobSubmission\norg.apache.hive.spark.client.TestSparkClient.testSyncRpc\n{noformat}\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/243/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/243/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-243/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 68 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12803166 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-12T12:54:08.895+0000","updated":"2016-05-12T12:54:08.895+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15282526","id":"15282526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Update patch to fix test: we only cache the RDD when numPartitions > 1 and the RDD hasn't be cached yet.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-13T08:27:04.188+0000","updated":"2016-05-13T08:27:04.188+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15282528","id":"15282528","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Just thought of a better way to check whether an RDD has been cached.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-13T08:34:44.237+0000","updated":"2016-05-13T08:34:44.237+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15282841","id":"15282841","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~lirui], Is checking num of partitions necessary because sampling job is triggered only if more than one partition?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-13T16:08:49.768+0000","updated":"2016-05-13T16:08:49.768+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15283746","id":"15283746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12803817/HIVE-13293.3.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/278/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/278/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-278/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] Excluding org.apache.spark:spark-core_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding com.twitter:chill_2.10:jar:0.5.0 from the shaded jar.\n[INFO] Excluding com.twitter:chill-java:jar:0.5.0 from the shaded jar.\n[INFO] Excluding org.apache.xbean:xbean-asm5-shaded:jar:4.4 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-client:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-mapreduce-client-app:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-mapreduce-client-shuffle:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.hadoop:hadoop-mapreduce-client-jobclient:jar:2.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-launcher_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-network-common_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-network-shuffle_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.apache.spark:spark-unsafe_2.10:jar:1.6.0 from the shaded jar.\n[INFO] Excluding org.slf4j:jul-to-slf4j:jar:1.7.10 from the shaded jar.\n[INFO] Excluding org.slf4j:jcl-over-slf4j:jar:1.7.10 from the shaded jar.\n[INFO] Excluding com.ning:compress-lzf:jar:1.0.3 from the shaded jar.\n[INFO] Excluding net.jpountz.lz4:lz4:jar:1.3.0 from the shaded jar.\n[INFO] Excluding com.typesafe.akka:akka-remote_2.10:jar:2.3.11 from the shaded jar.\n[INFO] Excluding com.typesafe.akka:akka-actor_2.10:jar:2.3.11 from the shaded jar.\n[INFO] Excluding com.typesafe:config:jar:1.2.1 from the shaded jar.\n[INFO] Excluding org.uncommons.maths:uncommons-maths:jar:1.2.2a from the shaded jar.\n[INFO] Excluding com.typesafe.akka:akka-slf4j_2.10:jar:2.3.11 from the shaded jar.\n[INFO] Excluding org.scala-lang:scala-library:jar:2.10.4 from the shaded jar.\n[INFO] Excluding org.json4s:json4s-jackson_2.10:jar:3.2.10 from the shaded jar.\n[INFO] Excluding org.json4s:json4s-core_2.10:jar:3.2.10 from the shaded jar.\n[INFO] Excluding org.json4s:json4s-ast_2.10:jar:3.2.10 from the shaded jar.\n[INFO] Excluding org.scala-lang:scalap:jar:2.10.0 from the shaded jar.\n[INFO] Excluding org.scala-lang:scala-compiler:jar:2.10.0 from the shaded jar.\n[INFO] Excluding org.apache.mesos:mesos:jar:shaded-protobuf:0.21.1 from the shaded jar.\n[INFO] Excluding com.clearspring.analytics:stream:jar:2.7.0 from the shaded jar.\n[INFO] Excluding io.dropwizard.metrics:metrics-graphite:jar:3.1.2 from the shaded jar.\n[INFO] Excluding com.fasterxml.jackson.module:jackson-module-scala_2.10:jar:2.4.4 from the shaded jar.\n[INFO] Excluding org.scala-lang:scala-reflect:jar:2.10.4 from the shaded jar.\n[INFO] Excluding oro:oro:jar:2.0.8 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-client:jar:0.8.2 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-underfs-hdfs:jar:0.8.2 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-underfs-s3:jar:0.8.2 from the shaded jar.\n[INFO] Excluding org.tachyonproject:tachyon-underfs-local:jar:0.8.2 from the shaded jar.\n[INFO] Excluding net.razorvine:pyrolite:jar:4.9 from the shaded jar.\n[INFO] Excluding net.sf.py4j:py4j:jar:0.9 from the shaded jar.\n[INFO] Excluding org.spark-project.spark:unused:jar:1.0.0 from the shaded jar.\n[INFO] Excluding org.slf4j:slf4j-api:jar:1.7.10 from the shaded jar.\n[INFO] Replacing original artifact with shaded artifact.\n[INFO] Replacing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT.jar with /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT-shaded.jar\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-exec ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/dependency-reduced-pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT-tests.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT-tests.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/ql/target/hive-exec-2.1.0-SNAPSHOT-core.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT-core.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Llap Server 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-llap-server ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/llap-server/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/llap-server (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-llap-server ---\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-llap-server ---\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/llap-server/src/gen/protobuf/gen-java added.\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/llap-server/src/gen/thrift/gen-javabean added.\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-llap-server ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-llap-server ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 19 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-llap-server ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-llap-server ---\n[INFO] Compiling 87 source files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[29,16] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[29,16] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[29,16] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java:[74,9] sun.misc.Cleaner is internal proprietary API and may be removed in a future release\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/io/metadata/OrcFileMetadata.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/io/metadata/OrcFileMetadata.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/DirWatcher.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/DirWatcher.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-llap-server ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-llap-server ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp/conf\n     [copy] Copying 15 files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-llap-server ---\n[INFO] Compiling 13 source files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/test-classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/comparator/TestFirstInFirstOutComparator.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-llap-server ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-llap-server ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-llap-server ---\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-llap-server ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT-tests.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-llap-server ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-llap-server/2.1.0-SNAPSHOT/hive-llap-server-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-server/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-llap-server/2.1.0-SNAPSHOT/hive-llap-server-2.1.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/llap-server/target/hive-llap-server-2.1.0-SNAPSHOT-tests.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-llap-server/2.1.0-SNAPSHOT/hive-llap-server-2.1.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Service 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\nDownloading: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/maven-metadata.xml\n\n[WARNING] Could not transfer metadata org.apache.directory.client.ldap:ldap-client-api:0.1-SNAPSHOT/maven-metadata.xml from/to apache.snapshots (http://repository.apache.org/snapshots): Failed to transfer file: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/maven-metadata.xml. Return code is: 503 , ReasonPhrase:Service Unavailable.\n[WARNING] Failure to transfer org.apache.directory.client.ldap:ldap-client-api:0.1-SNAPSHOT/maven-metadata.xml from http://repository.apache.org/snapshots was cached in the local repository, resolution will not be reattempted until the update interval of apache.snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.apache.directory.client.ldap:ldap-client-api:0.1-SNAPSHOT/maven-metadata.xml from/to apache.snapshots (http://repository.apache.org/snapshots): Failed to transfer file: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/maven-metadata.xml. Return code is: 503 , ReasonPhrase:Service Unavailable.\nDownloading: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/ldap-client-api-0.1-SNAPSHOT.pom\n\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.933s]\n[INFO] Hive Shims Common ................................. SUCCESS [4.417s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [3.355s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [0.987s]\n[INFO] Hive Shims ........................................ SUCCESS [0.768s]\n[INFO] Hive Storage API .................................. SUCCESS [1.688s]\n[INFO] Hive ORC .......................................... SUCCESS [2.970s]\n[INFO] Hive Common ....................................... SUCCESS [4.645s]\n[INFO] Hive Service RPC .................................. SUCCESS [2.837s]\n[INFO] Hive Serde ........................................ SUCCESS [4.276s]\n[INFO] Hive Metastore .................................... SUCCESS [17.357s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.504s]\n[INFO] Hive Llap Common .................................. SUCCESS [3.893s]\n[INFO] Hive Llap Client .................................. SUCCESS [1.760s]\n[INFO] Hive Llap Tez ..................................... SUCCESS [2.071s]\n[INFO] Spark Remote Client ............................... SUCCESS [2.857s]\n[INFO] Hive Query Language ............................... SUCCESS [50.791s]\n[INFO] Hive Llap Server .................................. SUCCESS [2.852s]\n[INFO] Hive Service ...................................... FAILURE [1:02.187s]\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive Llap External Client ......................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 2:54.255s\n[INFO] Finished at: Sun May 15 01:09:30 GMT 2016\n[INFO] Final Memory: 152M/855M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-1\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal on project hive-service: Could not resolve dependencies for project org.apache.hive:hive-service:jar:2.1.0-SNAPSHOT: Failed to collect dependencies for [org.apache.hive:hive-exec:jar:2.1.0-SNAPSHOT (compile), org.apache.hive:hive-metastore:jar:2.1.0-SNAPSHOT (compile), org.apache.hive:hive-service-rpc:jar:2.1.0-SNAPSHOT (compile), org.apache.hive:hive-llap-server:jar:2.1.0-SNAPSHOT (compile), commons-codec:commons-codec:jar:1.4 (compile), commons-cli:commons-cli:jar:1.2 (compile), net.sf.jpam:jpam:jar:1.1 (compile), commons-lang:commons-lang:jar:2.6 (compile), org.eclipse.jetty.aggregate:jetty-all:jar:7.6.0.v20120127 (compile), tomcat:jasper-compiler:jar:5.5.23 (compile), tomcat:jasper-runtime:jar:5.5.23 (compile), org.apache.thrift:libfb303:jar:0.9.3 (compile), org.apache.thrift:libthrift:jar:0.9.3 (compile), org.apache.curator:curator-framework:jar:2.6.0 (compile), org.apache.curator:curator-recipes:jar:2.6.0 (compile), org.apache.hadoop:hadoop-common:jar:2.6.0 (compile?), org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.6.0 (compile?), org.jamon:jamon-runtime:jar:2.3.1 (compile), org.apache.hive:hive-exec:jar:tests:2.1.0-SNAPSHOT (test), org.apache.hive:hive-common:jar:tests:2.1.0-SNAPSHOT (test), junit:junit:jar:4.11 (test), org.apache.directory.client.ldap:ldap-client-api:jar:0.1 (test), org.apache.directory.server:apacheds-server-integ:jar:1.5.6 (test), org.apache.directory.server:apacheds-test-framework:jar:1.5.6 (test), org.slf4j:slf4j-api:jar:1.7.10 (compile)]: Failed to read artifact descriptor for org.apache.directory.client.ldap:ldap-client-api:jar:0.1-SNAPSHOT: Could not transfer artifact org.apache.directory.client.ldap:ldap-client-api:pom:0.1-SNAPSHOT from/to apache.snapshots (http://repository.apache.org/snapshots): Failed to transfer file: http://repository.apache.org/snapshots/org/apache/directory/client/ldap/ldap-client-api/0.1-SNAPSHOT/ldap-client-api-0.1-SNAPSHOT.pom. Return code is: 503 , ReasonPhrase:Service Unavailable. -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-service\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12803817 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-15T01:08:42.708+0000","updated":"2016-05-15T01:08:42.708+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15283836","id":"15283836","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz] - yeah sampling is needed only if we have more than 1 partitions. So we don't need cache in case of single reducer order by.\nNot sure why the build failed. Upload same patch to try again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-15T12:59:50.921+0000","updated":"2016-05-15T12:59:50.921+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15284226","id":"15284226","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12804096/HIVE-13293.3.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 48 failed/errored test(s), 9941 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniLlapCliDriver - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-auto_join1.q-schema_evol_text_vec_mapwork_part_all_complex.q-vector_complex_join.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-constprog_dpp.q-dynamic_partition_pruning.q-vectorization_10.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-enforce_order.q-vector_partition_diff_num_cols.q-unionDistinct_1.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-explainuser_4.q-update_after_multiple_inserts.q-mapreduce2.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-join1.q-mapjoin_decimal.q-union5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-load_dyn_part2.q-selectDistinctStar.q-vector_decimal_5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_coalesce.q-cbo_windowing.q-tez_join.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_distinct_2.q-tez_joins_explain.q-cte_mat_1.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_interval_2.q-schema_evol_text_nonvec_mapwork_part_all_primitive.q-tez_fsstat.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vectorized_parquet.q-insert_values_non_partitioned.q-schema_evol_orc_nonvec_mapwork_part.q-and-12-more - did not produce a TEST-*.xml file\nTestMinimrCliDriver-join1.q-infer_bucket_sort_bucketed_table.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_reordering_values\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_udf_udaf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_dynamic_rdd_cache\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby3_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_having\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_identity_project_remove_skip\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_insert_into1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join22\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_merge_multi_expressions\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_test_outer\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_pcr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_seqfile\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_in\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_temp_table\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_udf_max\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_uniquejoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_short_regress\norg.apache.hadoop.hive.llap.tez.TestConverters.testFragmentSpecToTaskSpec\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure\norg.apache.hive.service.cli.session.TestHiveSessionImpl.testLeakOperationHandle\n{noformat}\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/295/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/295/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-295/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 48 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12804096 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-16T07:20:56.003+0000","updated":"2016-05-16T07:20:56.003+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15284369","id":"15284369","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"None of the failures can be reproduced locally. Seems the test framework has become quite unstable though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-16T10:44:24.032+0000","updated":"2016-05-16T10:44:24.032+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15285944","id":"15285944","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~xuefuz], any further comments on this one?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-17T03:18:55.648+0000","updated":"2016-05-17T03:18:55.648+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15286005","id":"15286005","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Please commit. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-17T04:19:06.640+0000","updated":"2016-05-17T04:19:06.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12950750/comment/15286209","id":"15286209","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Committed to master. Thanks to Xuefu for the review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-17T08:17:23.891+0000","updated":"2016-05-17T08:17:23.891+0000"}],"maxResults":23,"total":23,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-13293/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2uqzz:"}}