{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12701182","self":"https://issues.apache.org/jira/rest/api/2/issue/12701182","key":"HIVE-6649","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324986","id":"12324986","description":"released","name":"0.13.0","archived":false,"released":true,"releaseDate":"2014-04-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-03-13T16:37:51.852+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Mar 17 19:05:22 UTC 2014","customfield_12310420":"379528","customfield_12312320":null,"customfield_12310222":"10002_*:*_5_*:*_393171269_*|*_1_*:*_5_*:*_3428839_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-03-17T22:11:52.311+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6649/watchers","watchCount":2,"isWatching":false},"created":"2014-03-13T08:01:52.244+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-03-17T22:11:52.342+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Query ran with hive.vectorized.execution.enabled=true:\n{code}\nselect dt, to_date(date_add(dt, 2)), to_date(date_sub(dt, 2)),\n       datediff(dt, date_add(dt, 2)), datediff(dt, date_sub(dt, 2)),\n       datediff(date_add(dt, 2), date_sub(dt, 2))\nfrom vectortab10korc limit 1;\n{code}\nfails with the following error:\n{noformat}\nError: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:195)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:45)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:177)\n\t... 8 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating datediff(date_add(dt, 2), date_sub(dt, 2))\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.processOp(VectorSelectOperator.java:117)\n\tat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:791)\n\tat org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)\n\tat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:791)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:43)\n\t... 9 more\nCaused by: java.lang.NullPointerException\n\tat java.lang.String.checkBounds(String.java:400)\n\tat java.lang.String.<init>(String.java:569)\n\tat org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFDateDiffColCol.setDays(VectorUDFDateDiffColCol.java:254)\n\tat org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFDateDiffColCol.copySelected(VectorUDFDateDiffColCol.java:231)\n\tat org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFDateDiffColCol.toDateArray(VectorUDFDateDiffColCol.java:190)\n\tat org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFDateDiffColCol.evaluate(VectorUDFDateDiffColCol.java:72)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.processOp(VectorSelectOperator.java:115)\n\t... 13 more\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12634396","id":"12634396","filename":"HIVE-6649.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-13T08:38:01.073+0000","size":10553,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12634396/HIVE-6649.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12634937","id":"12634937","filename":"HIVE-6649.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-15T21:40:52.743+0000","size":17909,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12634937/HIVE-6649.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12634921","id":"12634921","filename":"HIVE-6649.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-15T16:56:46.466+0000","size":17909,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12634921/HIVE-6649.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12634677","id":"12634677","filename":"HIVE-6649.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-14T09:07:39.309+0000","size":17909,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12634677/HIVE-6649.2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"379819","customfield_12312823":null,"summary":"Vectorization: some date expressions throw exception.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13933506","id":"13933506","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you put this up on ReviewBoard if you're ready for a review?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-13T16:37:51.852+0000","updated":"2014-03-13T16:37:51.852+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13934797","id":"13934797","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"Review board: https://reviews.apache.org/r/19218/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-14T09:07:39.314+0000","updated":"2014-03-14T09:07:39.314+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13934824","id":"13934824","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:green}Overall{color}: +1 all checks pass\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12634396/HIVE-6649.1.patch\n\n{color:green}SUCCESS:{color} +1 5394 tests passed\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1770/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1770/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12634396","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-03-14T09:49:23.372+0000","updated":"2014-03-14T09:49:23.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13935621","id":"13935621","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"body":"+1\n\nPlease see my minor comments on ReviewBoard","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-14T20:49:01.314+0000","updated":"2014-03-14T20:49:01.314+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13936079","id":"13936079","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12634677/HIVE-6649.2.patch\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1806/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1806/console\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hwi ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hwi ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hwi ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive ODBC 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-odbc ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/odbc (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-odbc ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/odbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-odbc/0.14.0-SNAPSHOT/hive-odbc-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Aggregator 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-aggregator ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-aggregator ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims-aggregator/0.14.0-SNAPSHOT/hive-shims-aggregator-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive TestUtils 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-testutils ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/testutils (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/classes\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-testutils ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-testutils ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Packaging 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/maven-metadata.xml\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.pom\n[WARNING] The POM for org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT is missing, no dependency information available\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.jar\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [8.411s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [5.908s]\n[INFO] Hive Shims Common ................................. SUCCESS [3.685s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [2.434s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [4.213s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [3.024s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [8.086s]\n[INFO] Hive Shims ........................................ SUCCESS [1.024s]\n[INFO] Hive Common ....................................... SUCCESS [6.569s]\n[INFO] Hive Serde ........................................ SUCCESS [10.029s]\n[INFO] Hive Metastore .................................... SUCCESS [31.428s]\n[INFO] Hive Query Language ............................... SUCCESS [1:20.187s]\n[INFO] Hive Service ...................................... SUCCESS [8.150s]\n[INFO] Hive JDBC ......................................... SUCCESS [3.087s]\n[INFO] Hive Beeline ...................................... SUCCESS [2.844s]\n[INFO] Hive CLI .......................................... SUCCESS [1.971s]\n[INFO] Hive Contrib ...................................... SUCCESS [2.519s]\n[INFO] Hive HBase Handler ................................ SUCCESS [2.764s]\n[INFO] Hive HCatalog ..................................... SUCCESS [0.589s]\n[INFO] Hive HCatalog Core ................................ SUCCESS [2.525s]\n[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [2.388s]\n[INFO] Hive HCatalog Server Extensions ................... SUCCESS [1.297s]\n[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [2.058s]\n[INFO] Hive HCatalog Webhcat ............................. SUCCESS [9.982s]\n[INFO] Hive HWI .......................................... SUCCESS [1.091s]\n[INFO] Hive ODBC ......................................... SUCCESS [0.819s]\n[INFO] Hive Shims Aggregator ............................. SUCCESS [0.265s]\n[INFO] Hive TestUtils .................................... SUCCESS [0.678s]\n[INFO] Hive Packaging .................................... FAILURE [1.375s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:33.939s\n[INFO] Finished at: Sat Mar 15 04:01:03 EDT 2014\n[INFO] Final Memory: 74M/553M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal on project hive-packaging: Could not resolve dependencies for project org.apache.hive:hive-packaging:pom:0.14.0-SNAPSHOT: Could not find artifact org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT in apache.snapshots (http://repository.apache.org/snapshots) -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-packaging\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12634677","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-03-15T08:01:05.001+0000","updated":"2014-03-15T08:01:05.001+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13936246","id":"13936246","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"Uploading same patch to trigger pre-commit build.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-15T16:56:46.472+0000","updated":"2014-03-15T16:56:46.472+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13936255","id":"13936255","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12634921/HIVE-6649.2.patch\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1834/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1834/console\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hwi ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hwi ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hwi ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive ODBC 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-odbc ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/odbc (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-odbc ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/odbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-odbc/0.14.0-SNAPSHOT/hive-odbc-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Aggregator 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-aggregator ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-aggregator ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims-aggregator/0.14.0-SNAPSHOT/hive-shims-aggregator-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive TestUtils 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-testutils ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/testutils (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/classes\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-testutils ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-testutils ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Packaging 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/maven-metadata.xml\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.pom\n[WARNING] The POM for org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT is missing, no dependency information available\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.jar\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [8.750s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [5.916s]\n[INFO] Hive Shims Common ................................. SUCCESS [3.781s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [2.504s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [4.415s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [2.806s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [7.882s]\n[INFO] Hive Shims ........................................ SUCCESS [1.003s]\n[INFO] Hive Common ....................................... SUCCESS [11.949s]\n[INFO] Hive Serde ........................................ SUCCESS [9.976s]\n[INFO] Hive Metastore .................................... SUCCESS [33.143s]\n[INFO] Hive Query Language ............................... SUCCESS [1:18.256s]\n[INFO] Hive Service ...................................... SUCCESS [6.850s]\n[INFO] Hive JDBC ......................................... SUCCESS [2.696s]\n[INFO] Hive Beeline ...................................... SUCCESS [2.719s]\n[INFO] Hive CLI .......................................... SUCCESS [1.934s]\n[INFO] Hive Contrib ...................................... SUCCESS [1.753s]\n[INFO] Hive HBase Handler ................................ SUCCESS [3.610s]\n[INFO] Hive HCatalog ..................................... SUCCESS [0.533s]\n[INFO] Hive HCatalog Core ................................ SUCCESS [3.306s]\n[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [1.769s]\n[INFO] Hive HCatalog Server Extensions ................... SUCCESS [1.824s]\n[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [1.836s]\n[INFO] Hive HCatalog Webhcat ............................. SUCCESS [10.207s]\n[INFO] Hive HWI .......................................... SUCCESS [1.268s]\n[INFO] Hive ODBC ......................................... SUCCESS [0.864s]\n[INFO] Hive Shims Aggregator ............................. SUCCESS [0.331s]\n[INFO] Hive TestUtils .................................... SUCCESS [0.585s]\n[INFO] Hive Packaging .................................... FAILURE [2.367s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:38.124s\n[INFO] Finished at: Sat Mar 15 13:27:28 EDT 2014\n[INFO] Final Memory: 74M/419M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal on project hive-packaging: Could not resolve dependencies for project org.apache.hive:hive-packaging:pom:0.14.0-SNAPSHOT: Could not find artifact org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT in apache.snapshots (http://repository.apache.org/snapshots) -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-packaging\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12634921","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-03-15T17:27:31.497+0000","updated":"2014-03-15T17:27:31.497+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13936319","id":"13936319","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12634937/HIVE-6649.2.patch\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1842/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1842/console\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hwi ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hwi ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hwi ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.14.0-SNAPSHOT/hive-hwi-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive ODBC 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-odbc ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/odbc (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-odbc ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-odbc ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/odbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-odbc/0.14.0-SNAPSHOT/hive-odbc-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Aggregator 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-aggregator ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-shims-aggregator ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-aggregator ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims-aggregator/0.14.0-SNAPSHOT/hive-shims-aggregator-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive TestUtils 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-testutils ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/testutils (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/classes\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-testutils ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-testutils ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-testutils ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-testutils ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.14.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.14.0-SNAPSHOT/hive-testutils-0.14.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Packaging 0.14.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/maven-metadata.xml\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.pom\n[WARNING] The POM for org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT is missing, no dependency information available\nDownloading: http://repository.apache.org/snapshots/org/apache/hive/hcatalog/hive-hcatalog-hbase-storage-handler/0.14.0-SNAPSHOT/hive-hcatalog-hbase-storage-handler-0.14.0-SNAPSHOT.jar\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [8.663s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [5.475s]\n[INFO] Hive Shims Common ................................. SUCCESS [3.741s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [2.610s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [4.402s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [2.589s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [8.047s]\n[INFO] Hive Shims ........................................ SUCCESS [1.270s]\n[INFO] Hive Common ....................................... SUCCESS [7.163s]\n[INFO] Hive Serde ........................................ SUCCESS [10.347s]\n[INFO] Hive Metastore .................................... SUCCESS [33.518s]\n[INFO] Hive Query Language ............................... SUCCESS [1:19.821s]\n[INFO] Hive Service ...................................... SUCCESS [7.875s]\n[INFO] Hive JDBC ......................................... SUCCESS [3.121s]\n[INFO] Hive Beeline ...................................... SUCCESS [2.820s]\n[INFO] Hive CLI .......................................... SUCCESS [1.737s]\n[INFO] Hive Contrib ...................................... SUCCESS [2.468s]\n[INFO] Hive HBase Handler ................................ SUCCESS [2.813s]\n[INFO] Hive HCatalog ..................................... SUCCESS [0.521s]\n[INFO] Hive HCatalog Core ................................ SUCCESS [2.476s]\n[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [2.471s]\n[INFO] Hive HCatalog Server Extensions ................... SUCCESS [1.221s]\n[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [2.116s]\n[INFO] Hive HCatalog Webhcat ............................. SUCCESS [9.947s]\n[INFO] Hive HWI .......................................... SUCCESS [1.004s]\n[INFO] Hive ODBC ......................................... SUCCESS [0.915s]\n[INFO] Hive Shims Aggregator ............................. SUCCESS [0.165s]\n[INFO] Hive TestUtils .................................... SUCCESS [0.676s]\n[INFO] Hive Packaging .................................... FAILURE [1.754s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:36.505s\n[INFO] Finished at: Sat Mar 15 17:55:19 EDT 2014\n[INFO] Final Memory: 74M/467M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal on project hive-packaging: Could not resolve dependencies for project org.apache.hive:hive-packaging:pom:0.14.0-SNAPSHOT: Could not find artifact org.apache.hive.hcatalog:hive-hcatalog-hbase-storage-handler:jar:0.14.0-SNAPSHOT in apache.snapshots (http://repository.apache.org/snapshots) -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-packaging\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12634937","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-03-15T21:55:21.545+0000","updated":"2014-03-15T21:55:21.545+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13938193","id":"13938193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"Ran tests locally. Only failures were show_create_table_serde.q and metadata_only_queries_with_filters.q which are unrelated to this patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-17T18:48:06.963+0000","updated":"2014-03-17T18:48:06.963+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12701182/comment/13938218","id":"13938218","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"I have committed this to trunk.\n\n[~rhbutani] This bug affects hive-0.13 and fails several vectorized queries on DATE. This should be fixed in branch-0.13 as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-17T19:05:22.891+0000","updated":"2014-03-17T19:05:22.891+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6649/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1te8f:"}}