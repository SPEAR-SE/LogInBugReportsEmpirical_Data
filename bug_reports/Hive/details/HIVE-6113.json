{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12686504","self":"https://issues.apache.org/jira/rest/api/2/issue/12686504","key":"HIVE-6113","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-04-08T14:54:29.784+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Mar 17 20:33:50 UTC 2017","customfield_12310420":"365495","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_59549169844_*|*_3_*:*_7_*:*_229628872_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_8_*:*_4034206360","customfield_12312321":null,"resolutiondate":"2016-01-04T20:57:05.148+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6113/watchers","watchCount":14,"isWatching":false},"created":"2013-12-27T07:07:00.165+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":["HiveMetaStoreClient","TODOC2.0","metastore","unable_instantiate"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"11.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12324986","id":"12324986","description":"released","name":"0.13.0","archived":false,"released":true,"releaseDate":"2014-04-21"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12326450","id":"12326450","description":"released","name":"0.14.0","archived":false,"released":true,"releaseDate":"2014-11-12"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12329278","id":"12329278","description":"Branch 1.0 release","name":"1.0.0","archived":false,"released":true,"releaseDate":"2015-02-04"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"}],"issuelinks":[{"id":"12475961","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12475961","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"outwardIssue":{"id":"12975304","key":"HIVE-13931","self":"https://issues.apache.org/jira/rest/api/2/issue/12975304","fields":{"summary":"Add support for HikariCP  connection pooling","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12448829","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12448829","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12838580","key":"HIVE-11036","self":"https://issues.apache.org/jira/rest/api/2/issue/12838580","fields":{"summary":"Race condition in DataNucleus makes Metastore to hang","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12450032","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12450032","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12771671","key":"HIVE-9543","self":"https://issues.apache.org/jira/rest/api/2/issue/12771671","fields":{"summary":"MetaException(message:Metastore contains multiple versions)","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12474347","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12474347","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12986353","key":"HIVE-14152","self":"https://issues.apache.org/jira/rest/api/2/issue/12986353","fields":{"summary":"datanucleus.autoStartMechanismMode should set to 'Ignored' to allow rolling downgrade ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12475841","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12475841","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12992074","key":"HIVE-14322","self":"https://issues.apache.org/jira/rest/api/2/issue/12992074","fields":{"summary":"Postgres db issues after Datanucleus 4.x upgrade","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12454047","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12454047","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12618540","key":"HIVE-3764","self":"https://issues.apache.org/jira/rest/api/2/issue/12618540","fields":{"summary":"Support metastore version consistency check","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12453821","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12453821","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12492754","key":"HIVE-1841","self":"https://issues.apache.org/jira/rest/api/2/issue/12492754","fields":{"summary":" datanucleus.fixedDatastore should be true in hive-default.xml","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12454035","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12454035","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12913783","key":"HIVE-12436","self":"https://issues.apache.org/jira/rest/api/2/issue/12913783","fields":{"summary":"Default hive.metastore.schema.verification to true","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/3","id":"3","description":"A task that needs to be done.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype","name":"Task","subtask":false,"avatarId":21148}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-03-17T20:33:50.069+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12317906","id":"12317906","name":"Database/Schema","description":"Issues related to support for multiple Datasbases/Schemas"}],"timeoriginalestimate":null,"description":"CLEAR LIBRARY CACHE\n\nWhen I exccute SQL \"use fdm; desc formatted fdm.tableName;\"  in python, throw Error as followed.\nbut when I tryit again , It will success.\n\n2013-12-25 03:01:32,290 ERROR exec.DDLTask (DDLTask.java:execute(435)) - org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1143)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1128)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.switchDatabase(DDLTask.java:3479)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:237)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)\n\tat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1414)\n\tat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1192)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1020)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:260)\n\tat org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:217)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:507)\n\tat org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:875)\n\tat org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:769)\n\tat org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:708)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:197)\nCaused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1217)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:62)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2372)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2383)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1139)\n\t... 20 more\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1210)\n\t... 25 more\nCaused by: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore\nNestedThrowables:\njava.sql.BatchUpdateException: Duplicate entry 'default' for key 'UNIQUE_DATABASE'\n\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:451)\n\tat org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:165)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:358)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.createDatabase(ObjectStore.java:404)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:124)\n\tat $Proxy9.createDatabase(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB_core(HiveMetaStore.java:422)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:441)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:326)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.<init>(HiveMetaStore.java:286)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:54)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:59)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newHMSHandler(HiveMetaStore.java:4060)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:121)\n\t... 30 more\nCaused by: java.sql.BatchUpdateException: Duplicate entry 'default' for key 'UNIQUE_DATABASE'\n\tat com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:2028)\n\tat com.mysql.jdbc.PreparedStatement.executeBatch(PreparedStatement.java:1451)\n\tat com.jolbox.bonecp.StatementHandle.executeBatch(StatementHandle.java:469)\n\tat org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:372)\n\tat org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:628)\n\tat org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:596)\n\tat org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:683)\n\tat org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:86)\n\tat org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:454)\n\tat org.datanucleus.TransactionImpl.flush(TransactionImpl.java:199)\n\tat org.datanucleus.TransactionImpl.commit(TransactionImpl.java:263)\n\tat org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:98)\n\t... 46 more\nCaused by: com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry 'default' for key 'UNIQUE_DATABASE'\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n\tat com.mysql.jdbc.Util.handleNewInstance(Util.java:411)\n\tat com.mysql.jdbc.Util.getInstance(Util.java:386)\n\tat com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1039)\n\tat com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3609)\n\tat com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3541)\n\tat com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2002)\n\tat com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2163)\n\tat com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2624)\n\tat com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2127)\n\tat com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:2427)\n\tat com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:1980)\n\t... 57 more\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332154","id":"12332154","description":"","name":"1.3.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12779112","id":"12779112","filename":"HIVE-6113.10.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-22T19:43:22.323+0000","size":18268,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12779112/HIVE-6113.10.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12773550","id":"12773550","filename":"HIVE-6113.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-20T17:36:34.035+0000","size":12290,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12773550/HIVE-6113.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12773890","id":"12773890","filename":"HIVE-6113.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-23T20:05:11.383+0000","size":14641,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12773890/HIVE-6113.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12774318","id":"12774318","filename":"HIVE-6113.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-25T10:35:44.298+0000","size":16968,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12774318/HIVE-6113.5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12774888","id":"12774888","filename":"HIVE-6113.6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-30T21:09:04.950+0000","size":17916,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12774888/HIVE-6113.6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12775944","id":"12775944","filename":"HIVE-6113.7.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-05T18:57:20.305+0000","size":18788,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12775944/HIVE-6113.7.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12775977","id":"12775977","filename":"HIVE-6113.8.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-06T08:31:12.624+0000","size":19083,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12775977/HIVE-6113.8.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12778935","id":"12778935","filename":"HIVE-6113.9.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-21T23:52:40.981+0000","size":17738,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12778935/HIVE-6113.9.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12772479","id":"12772479","filename":"HIVE-6113.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-16T12:31:56.241+0000","size":2358,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12772479/HIVE-6113.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12775440","id":"12775440","filename":"HIVE-6113.with.reflection.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-03T00:30:53.928+0000","size":17266,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12775440/HIVE-6113.with.reflection.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12772722","id":"12772722","filename":"HIVE-6113-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-17T11:24:14.130+0000","size":12643,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12772722/HIVE-6113-2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"365796","customfield_12312823":null,"summary":"Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shiw019","name":"shiw019","key":"shiw019","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"William Stone","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shiw019","name":"shiw019","key":"shiw019","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"William Stone","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"hadoop-0.20.2-cdh3u3,hive-0.12.0","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/13963055","id":"13963055","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliac","name":"eliac","key":"eliac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Acherkan","active":true,"timeZone":"Asia/Jerusalem"},"body":"The exact same issue reproduces here. Hive 0.12 on MapR 3.1.0 with MySQL metastore. The exception appears when there are several processes working with Hive concurrently.\n\nFrom our analysis the problem seems related to the one described here: http://mail-archives.apache.org/mod_mbox/hive-user/201107.mbox/%3C4F6B25AFFFCAFE44B6259A412D5F9B1033183876@ExchMBX104.netflix.com%3E\n\nh5. Analysis:\nAt certain times, Hive's DataNucleus decides to create and then drop tables called \"DELETEME\"+timestamp in the metastore schema on MySQL (see [ProbleTable|http://sourceforge.net/p/datanucleus/code/HEAD/tree/platform/store.rdbms/tags/datanucleus-rdbms-3.2.2/src/java/org/datanucleus/store/rdbms/table/ProbeTable.java]).\n\nDuring other flows, DataNucleus queries MySQL for the list of all the columns of all the tables (see [RDBMSSchemaHandler.refreshTableData|http://sourceforge.net/p/datanucleus/code/HEAD/tree/platform/store.rdbms/tags/datanucleus-rdbms-3.2.2/src/java/org/datanucleus/store/rdbms/schema/RDBMSSchemaHandler.java#l872]). MySQL's JDBC driver implements the DatabaseMetaData.getColumns method by querying the DB for a list of all the tables, and then iterating over that list and querying for each table's columns (see [com.mysql.jdbc.DatabaseMetaData|http://bazaar.launchpad.net/~mysql/connectorj/5.1/view/head:/src/com/mysql/jdbc/DatabaseMetaData.java#L2581]). If a table is deleted from the DB during this operation, DatabaseMetaData.getColumns will throw an exception.\n\nThis exception is interpreted by Hive to mean that the \"default\" Hive database doesn't exist. Hive tries to create it, inserting a row into the metastore.DBS table in MySQL, which triggers the \"Duplicate entry 'default' for key 'UNIQUE_DATABASE'\" exception.\n\nI'm not completely clear about the conditions for a) DataNucleus creating and dropping a \"DELETEME\" table, and b) DataNucleus calling DatabaseMetaData.getColumns, so unfortunately I can't yet provide a clear test case. But in our lab environment under load we were able to reproduce the exception once every few minutes.\n\nh5. Workaround:\nAs suggested by the link above, setting the *datanucleus.fixedDatastore* property to *true* (e.g. in hive-site.xml or elsewhere) seems to solve the problem. However, it means that the metastore schema is no longer automatically created on-demand, and requires using Hive's schematool command to manually create the metastore schema.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliac","name":"eliac","key":"eliac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Acherkan","active":true,"timeZone":"Asia/Jerusalem"},"created":"2014-04-08T14:54:29.784+0000","updated":"2014-04-08T14:54:29.784+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15006600","id":"15006600","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"ROOT-CAUSE:\n\nBug http://www.datanucleus.org/servlet/jira/browse/NUCRDBMS-755 in DataNucleus Store RDBMS of version 3.2.9\n\nSOLUTION:\n\nUse DataNucleus Store RDBMS of higher version where fix of NUCRDBMS-755 is provided. Version change summary:\n\ndatanucleus-api-jdo 3.2.6  ---> 4.2.1\ndatanucleus-core    3.2.10 ---> 4.1.6\ndatanucleus-rdbms 3.2.9  ---> 4.1.7","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-16T12:31:19.449+0000","updated":"2015-11-16T12:31:19.449+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15006620","id":"15006620","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"For review https://reviews.apache.org/r/40344/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-16T12:45:39.979+0000","updated":"2015-11-16T12:45:39.979+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15006993","id":"15006993","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"@[~osayankin] : I know [~sershe] will be pleased with this proposal, he's been suggesting the same for other reasons. :)  That said, whenever we do a major version bump of DN, we should do a verification to ensure that we continue to work correctly. Have you verified the elements in http://www.datanucleus.org/products/accessplatform_4_2/migration.html to see if we won't be affected adversely?\n\n@[~eliac] : Very interesting analysis. Could you point me to where you see the following:\n\n> If a table is deleted from the DB during this operation, DatabaseMetaData.getColumns will throw an exception.\n>This exception is interpreted by Hive to mean that the \"default\" Hive database doesn't exist. \n\nBecause I do recollect similar sounding issues where DN would report a null return when we tried to do a getDatabase, which reads equivalently to a case of a NoSuchObjectException from us, rather than throwing a JDOException when there was an underlying db issue. If this is the same issue and we have a trace of where that happens, this solves a lot more for us, hopefully.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-16T17:50:28.834+0000","updated":"2015-11-16T17:50:28.834+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15006999","id":"15006999","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"A couple of other gardening notes:\n\n+cc [~ashutoshc]/[~sershe] as they would also be interested in this issue.\n\nAlso, I removed the fix-version of 1.2.1 from this bug, fix version is marked by a committer to denote what versions a patch has already been patched into. Target version is the field used to request what version the requestor wants the patch to go into, and for that, it must be unreleased versions. Thus, since 1.2.1 has already been released, I've updated Target version to 1.2.2.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-16T17:53:59.125+0000","updated":"2015-11-16T17:53:59.125+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15007081","id":"15007081","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"DN version should be upgraded in 2.0 and 1.3 too if upgrading in 1.2.2. Also the release note is needed. \nOtherwise this makes sense to me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-16T18:37:04.229+0000","updated":"2015-11-16T18:37:04.229+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15007158","id":"15007158","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12772479/HIVE-6113.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 898 failed/errored test(s), 5641 tests executed\n*Failed tests:*\n{noformat}\nTestFilterHooks - did not produce a TEST-*.xml file\nTestHS2ImpersonationWithRemoteMS - did not produce a TEST-*.xml file\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMetastoreAuthorizationProvider - did not produce a TEST-*.xml file\nTestPartitionNameWhitelistValidation - did not produce a TEST-*.xml file\nTestRemoteHiveMetaStore - did not produce a TEST-*.xml file\nTestSetUGIOnBothClientServer - did not produce a TEST-*.xml file\nTestSetUGIOnOnlyClient - did not produce a TEST-*.xml file\nTestSetUGIOnOnlyServer - did not produce a TEST-*.xml file\nTestStorageBasedMetastoreAuthorizationDrops - did not produce a TEST-*.xml file\nTestStorageBasedMetastoreAuthorizationReads - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestCliDriverMethods.testProcessSelectDatabase\norg.apache.hadoop.hive.cli.TestCliDriverMethods.testQuit\norg.apache.hadoop.hive.cli.TestCliDriverMethods.testRun\norg.apache.hadoop.hive.cli.TestCliDriverMethods.testprocessInitFiles\norg.apache.hadoop.hive.cli.TestCliSessionState.testgetDbName\norg.apache.hadoop.hive.cli.TestCompareCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestContribCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestContribNegativeCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_external_table_queries\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries_prefix\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_storage_queries\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key2\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key3\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_handler_bulk\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_handler_snapshot\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_joins\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_null_first_col\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_join\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_scan_params\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_single_sourced_multi_insert\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_stats3\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_timestamp\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_timestamp_format\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges\norg.apache.hadoop.hive.cli.TestHBaseMinimrCliDriver.testCliDriver_hbase_bulk\norg.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_cascade_dbdrop\norg.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_cascade_dbdrop_hadoop20\norg.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_generatehfiles_require_family_path\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestSparkCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.initializationError\norg.apache.hadoop.hive.hooks.TestHs2Hooks.org.apache.hadoop.hive.hooks.TestHs2Hooks\norg.apache.hadoop.hive.metastore.TestAdminUser.testCreateAdminNAddUser\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInEmbed.org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInEmbed\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testCreateRole\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testDropRole\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testGetPrivSet\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testGrantPriv\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testGrantRole\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testListPriv\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testListRoles\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testRevokePriv\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testRevokeRole\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testAlterPartition\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testAlterTable\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testAlterViewParititon\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testColumnStatistics\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testComplexTable\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testComplexTypeApi\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testConcurrentMetastores\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDBOwner\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDBOwnerChange\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabase\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabaseLocation\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabaseLocationWithPermissionProblems\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDropTable\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testFilterLastPartition\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testFilterSinglePartition\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testFunctionWithResources\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testGetConfigValue\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testGetTableObjects\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testListPartitionNames\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testListPartitions\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testNameMethods\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testPartition\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testPartitionFilter\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testRenamePartition\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testRetriableClientWithConnLifetime\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSimpleFunction\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSimpleTable\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSimpleTypeApi\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testStatsFastTrivial\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSynchronized\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testTableDatabase\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testTableFilter\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testValidateTableCols\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTimeout.org.apache.hadoop.hive.metastore.TestHiveMetaStoreTimeout\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testLocks\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testLocksWithTxn\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testOpenTxnNotExcluded\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxns\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreWithEnvironmentContext.testEnvironmentContext\norg.apache.hadoop.hive.metastore.TestHiveMetaTool.testExecuteJDOQL\norg.apache.hadoop.hive.metastore.TestHiveMetaTool.testListFSRoot\norg.apache.hadoop.hive.metastore.TestHiveMetaTool.testUpdateFSRootLocation\norg.apache.hadoop.hive.metastore.TestMarkPartition.testMarkingPartitionSet\norg.apache.hadoop.hive.metastore.TestMarkPartitionRemote.testMarkingPartitionSet\norg.apache.hadoop.hive.metastore.TestMetaStoreAuthorization.testMetaStoreAuthorization\norg.apache.hadoop.hive.metastore.TestMetaStoreEndFunctionListener.testEndFunctionListener\norg.apache.hadoop.hive.metastore.TestMetaStoreEventListener.testListener\norg.apache.hadoop.hive.metastore.TestMetaStoreEventListenerOnlyOnCommit.testEventStatus\norg.apache.hadoop.hive.metastore.TestMetaStoreListenersError.testEventListenerException\norg.apache.hadoop.hive.metastore.TestMetaStoreMetrics.testConnections\norg.apache.hadoop.hive.metastore.TestMetaStoreMetrics.testMetricsFile\norg.apache.hadoop.hive.metastore.TestMetastoreExpr.testPartitionExpr\norg.apache.hadoop.hive.metastore.TestMetastoreVersion.testMetastoreVersion\norg.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionMatching\norg.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionMisMatch\norg.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionRestriction\norg.apache.hadoop.hive.metastore.TestObjectStore.testDatabaseOps\norg.apache.hadoop.hive.metastore.TestObjectStore.testMasterKeyOps\norg.apache.hadoop.hive.metastore.TestObjectStore.testPartitionOps\norg.apache.hadoop.hive.metastore.TestObjectStore.testRoleOps\norg.apache.hadoop.hive.metastore.TestObjectStore.testTableOps\norg.apache.hadoop.hive.metastore.TestRemoteHiveMetaStoreIpAddress.testIpAddress\norg.apache.hadoop.hive.metastore.TestRemoteUGIHiveMetaStoreIpAddress.testIpAddress\norg.apache.hadoop.hive.metastore.TestRetryingHMSHandler.testRetryingHMSHandler\norg.apache.hadoop.hive.metastore.hbase.TestHBaseImport.org.apache.hadoop.hive.metastore.hbase.TestHBaseImport\norg.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testRevokeTimedOutWorkers\norg.apache.hadoop.hive.ql.TestCreateUdfEntities.testUdfWithDfsResource\norg.apache.hadoop.hive.ql.TestCreateUdfEntities.testUdfWithLocalResource\norg.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateDatabaseWithTableNonDefaultNameNode\norg.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode\norg.apache.hadoop.hive.ql.TestLocationQueries.testAlterTablePartitionLocation_alter5\norg.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1\norg.apache.hadoop.hive.ql.TestTxnCommands.exchangePartition\norg.apache.hadoop.hive.ql.TestTxnCommands.testDelete\norg.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn\norg.apache.hadoop.hive.ql.TestTxnCommands.testErrors\norg.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback\norg.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback\norg.apache.hadoop.hive.ql.TestTxnCommands.testInsertOverwrite\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts\norg.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert\norg.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert\norg.apache.hadoop.hive.ql.TestTxnCommands.testTimeOutReaper\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts\norg.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn\norg.apache.hadoop.hive.ql.TestTxnCommands2.testInsertOverwriteWithSelfJoin\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD\norg.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase\norg.apache.hadoop.hive.ql.exec.TestExecDriver.initializationError\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testCommonClass\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testCommonClassComparison\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testCommonClassUnionAll\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testGetMethodInternal\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testGetTypeInfoForPrimitiveCategory\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testImplicitConversion\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testImpliesOrder\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testIsRankingFunction\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testPrintTypeCompatibility\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testTypeAffinity\norg.apache.hadoop.hive.ql.exec.TestOperators.testFetchOperatorContext\norg.apache.hadoop.hive.ql.exec.TestOperators.testScriptOperator\norg.apache.hadoop.hive.ql.exec.TestUtilities.testgetDbTableName\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testBuildDag\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testClose\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testEmptyWork\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testExistingSessionGetsStorageHandlerResources\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testExtraResourcesAddedToDag\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testGetExtraLocalResources\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testSubmit\norg.apache.hadoop.hive.ql.history.TestHiveHistory.testHiveHistoryConfigDisabled\norg.apache.hadoop.hive.ql.history.TestHiveHistory.testHiveHistoryConfigEnabled\norg.apache.hadoop.hive.ql.history.TestHiveHistory.testQueryloglocParentDirNotExist\norg.apache.hadoop.hive.ql.history.TestHiveHistory.testSimpleQuery\norg.apache.hadoop.hive.ql.hooks.TestHooks.org.apache.hadoop.hive.ql.hooks.TestHooks\norg.apache.hadoop.hive.ql.io.TestSymlinkTextInputFormat.testCombine\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.concurrencyFalse\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLExclusive\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLNoLock\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLShared\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDelete\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testExceptions\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testJoin\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testReadWrite\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testRollback\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadMultiPartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadPartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleWritePartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleWriteTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testUpdate\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testWriteDynamicPartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.basicBlocking\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.createTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.insertOverwriteCreate\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.insertOverwritePartitionedCreate\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.lockConflictDbTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.updateSelectUpdate\norg.apache.hadoop.hive.ql.lockmgr.TestDummyTxnManager.testDedupLockObjects\norg.apache.hadoop.hive.ql.lockmgr.TestDummyTxnManager.testSingleReadTable\norg.apache.hadoop.hive.ql.metadata.TestHive.testAutoPurgeTablesAndPartitions\norg.apache.hadoop.hive.ql.metadata.TestHive.testDropPartitionsWithPurge\norg.apache.hadoop.hive.ql.metadata.TestHive.testDropTableTrash\norg.apache.hadoop.hive.ql.metadata.TestHive.testGetAndDropTables\norg.apache.hadoop.hive.ql.metadata.TestHive.testHiveCloseCurrent\norg.apache.hadoop.hive.ql.metadata.TestHive.testHiveRefreshOnConfChange\norg.apache.hadoop.hive.ql.metadata.TestHive.testIndex\norg.apache.hadoop.hive.ql.metadata.TestHive.testMetaStoreApiTiming\norg.apache.hadoop.hive.ql.metadata.TestHive.testPartition\norg.apache.hadoop.hive.ql.metadata.TestHive.testTable\norg.apache.hadoop.hive.ql.metadata.TestHive.testThriftTable\norg.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testDataDeletion\norg.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testPartitionsCheck\norg.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testTableCheck\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testAutoPurgeTablesAndPartitions\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testDropPartitionsWithPurge\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testDropTableTrash\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testGetAndDropTables\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testHiveCloseCurrent\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testHiveRefreshOnConfChange\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testIndex\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testMetaStoreApiTiming\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testPartition\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testTable\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testThriftTable\norg.apache.hadoop.hive.ql.metadata.TestSemanticAnalyzerHookLoading.testHookLoading\norg.apache.hadoop.hive.ql.parse.TestColumnAccess.org.apache.hadoop.hive.ql.parse.TestColumnAccess\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType1\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType2\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType3\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType4\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType5\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType6\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType7\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType8\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType9\norg.apache.hadoop.hive.ql.parse.TestIUD.org.apache.hadoop.hive.ql.parse.TestIUD\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testCannotUseReservedWordAsName\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacro\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroDoesNotExist\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroExistsDoNotIgnoreErrors\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistent\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistentWithIfExists\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistentWithIfExistsDoNotIgnoreNonExistent\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testNoBody\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testOneInputParamters\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testOneUnusedParameterName\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testThreeDuplicateParameters\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testThreeInputParamters\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testTwoDuplicateParameterNames\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testTwoInputParamters\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testTwoUnusedParameterNames\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testUnknownInputParameter\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testZeroInputParamters\norg.apache.hadoop.hive.ql.parse.TestParseNegative.initializationError\norg.apache.hadoop.hive.ql.parse.TestQBCompact.org.apache.hadoop.hive.ql.parse.TestQBCompact\norg.apache.hadoop.hive.ql.parse.TestQBJoinTreeApplyPredicate.org.apache.hadoop.hive.ql.parse.TestQBJoinTreeApplyPredicate\norg.apache.hadoop.hive.ql.parse.TestQBSubQuery.org.apache.hadoop.hive.ql.parse.TestQBSubQuery\norg.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsNegative.org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsNegative\norg.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsPositive.org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsPositive\norg.apache.hadoop.hive.ql.parse.TestUnpermittedCharsInColumnNameCreateTableNegative.org.apache.hadoop.hive.ql.parse.TestUnpermittedCharsInColumnNameCreateTableNegative\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllNonPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllWherePartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteOnePartition\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteOnePartitionWhere\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteWhereNoPartition\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertSelect\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertValues\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertValuesPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllNonPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllNonPartitionedWhere\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllPartitionedWhere\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateOnePartition\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateOnePartitionWhere\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testCreateRole\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testDropRole\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantGroupTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleGroup\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleRole\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleUser\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantServer\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantUri\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantUserTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeGroupTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleGroup\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleRole\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleUser\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeUserTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowGrantGroupOnTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowGrantRoleOnTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowGrantUserOnTable\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowRoleGrantGroup\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowRoleGrantRole\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowRoleGrantUser\norg.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV1.testPrivInGrant\norg.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV1.testPrivInGrantNotAccepted\norg.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV2.testPrivInGrant\norg.apache.hadoop.hive.ql.parse.positive.TestTransactionStatement.org.apache.hadoop.hive.ql.parse.positive.TestTransactionStatement\norg.apache.hadoop.hive.ql.plan.TestReadEntityDirect.org.apache.hadoop.hive.ql.plan.TestReadEntityDirect\norg.apache.hadoop.hive.ql.plan.TestViewEntity.org.apache.hadoop.hive.ql.plan.TestViewEntity\norg.apache.hadoop.hive.ql.processors.TestCommandProcessorFactory.testAvailableCommands\norg.apache.hadoop.hive.ql.processors.TestSetProcessor.testHiddenConfig\norg.apache.hadoop.hive.ql.security.TestAuthorizationPreEventListener.testListener\norg.apache.hadoop.hive.ql.security.TestClientSideAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestExtendedAcls.org.apache.hadoop.hive.ql.security.TestExtendedAcls\norg.apache.hadoop.hive.ql.security.TestFolderPermissions.org.apache.hadoop.hive.ql.security.TestFolderPermissions\norg.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener.testMultipleAuthorizationListners\norg.apache.hadoop.hive.ql.security.TestStorageBasedClientSideAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerCheckInvocation.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerCheckInvocation\norg.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters\norg.apache.hadoop.hive.ql.session.TestAddResource.testDeleteJar\norg.apache.hadoop.hive.ql.session.TestAddResource.testDeleteJarMultiple\norg.apache.hadoop.hive.ql.session.TestAddResource.testDuplicateAdds\norg.apache.hadoop.hive.ql.session.TestAddResource.testSanity\norg.apache.hadoop.hive.ql.session.TestAddResource.testUnion\norg.apache.hadoop.hive.ql.session.TestSessionState.testClassLoaderEquality[0]\norg.apache.hadoop.hive.ql.session.TestSessionState.testClassLoaderEquality[1]\norg.apache.hadoop.hive.ql.session.TestSessionState.testClose[0]\norg.apache.hadoop.hive.ql.session.TestSessionState.testClose[1]\norg.apache.hadoop.hive.ql.session.TestSessionState.testReloadAuxJars2[0]\norg.apache.hadoop.hive.ql.session.TestSessionState.testReloadAuxJars2[1]\norg.apache.hadoop.hive.ql.session.TestSessionState.testReloadExistingAuxJars2[0]\norg.apache.hadoop.hive.ql.session.TestSessionState.testReloadExistingAuxJars2[1]\norg.apache.hadoop.hive.ql.session.TestSessionState.testgetDbName[0]\norg.apache.hadoop.hive.ql.session.TestSessionState.testgetDbName[1]\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.blockedByLockPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.blockedByLockTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorPartitionCompactionNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMinorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMinorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.notBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.nothing\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.partitionNotBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.blockedByLockPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.blockedByLockTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorPartitionCompactionNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMinorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMinorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.notBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.nothing\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.partitionNotBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.chooseMajorOverMinorWhenBothValid\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.cleanEmptyAbortedTxns\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactPartitionHighDeltaPct\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactPartitionTooManyDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactTableHighDeltaPct\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactTableTooManyDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.dropPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.dropTable\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.enoughDeltasNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.majorCompactOnPartitionTooManyAborts\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.majorCompactOnTableTooManyAborts\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactOnManyDifferentPartitionAborts\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableDeltaPctNotHighEnough\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableDynamicPartitioning\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableNotEnoughDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenCompactAlreadyScheduled\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenNoCompactSet\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenNoCompactSetLowerCase\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.nothing\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.recoverFailedLocalWorkers\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.recoverFailedRemoteWorkers\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.twoTxnsOnSamePartitionGenerateOneCompactionRequest\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.inputSplit\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.inputSplitNullBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorNoBaseLotsOfDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorNoBaseLotsOfDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.nothing\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.sortedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.sortedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.stringableList\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.stringableMap\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.inputSplit\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.inputSplitNullBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorNoBaseLotsOfDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorPartitionWithBaseMissingBuckets\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorNoBaseLotsOfDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.nothing\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.sortedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.sortedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.stringableList\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.stringableMap\norg.apache.hadoop.hive.thrift.TestDBTokenStore.testDBTokenStore\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testMetastoreProxyUser\norg.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testSaslWithHiveMetaStore\norg.apache.hive.beeline.TestBeeLineWithArgs.org.apache.hive.beeline.TestBeeLineWithArgs\norg.apache.hive.beeline.cli.TestHiveCli.testCmd\norg.apache.hive.beeline.cli.TestHiveCli.testDatabaseOptions\norg.apache.hive.beeline.cli.TestHiveCli.testErrOutput\norg.apache.hive.beeline.cli.TestHiveCli.testHelp\norg.apache.hive.beeline.cli.TestHiveCli.testInValidCmd\norg.apache.hive.beeline.cli.TestHiveCli.testInvalidDatabaseOptions\norg.apache.hive.beeline.cli.TestHiveCli.testInvalidOptions\norg.apache.hive.beeline.cli.TestHiveCli.testInvalidOptions2\norg.apache.hive.beeline.cli.TestHiveCli.testNoErrorDB\norg.apache.hive.beeline.cli.TestHiveCli.testSetHeaderValue\norg.apache.hive.beeline.cli.TestHiveCli.testSetPromptValue\norg.apache.hive.beeline.cli.TestHiveCli.testSourceCmd\norg.apache.hive.beeline.cli.TestHiveCli.testSourceCmd2\norg.apache.hive.beeline.cli.TestHiveCli.testSourceCmd3\norg.apache.hive.beeline.cli.TestHiveCli.testSqlFromCmd\norg.apache.hive.beeline.cli.TestHiveCli.testSqlFromCmdWithDBName\norg.apache.hive.beeline.cli.TestHiveCli.testUseCurrentDB1\norg.apache.hive.beeline.cli.TestHiveCli.testUseCurrentDB2\norg.apache.hive.beeline.cli.TestHiveCli.testUseCurrentDB3\norg.apache.hive.beeline.cli.TestHiveCli.testUseInvalidDB\norg.apache.hive.beeline.cli.TestHiveCli.testVariables\norg.apache.hive.beeline.cli.TestHiveCli.testVariablesForSource\norg.apache.hive.hcatalog.api.TestHCatClient.testBasicDDLCommands\norg.apache.hive.hcatalog.api.TestHCatClient.testCreateTableLike\norg.apache.hive.hcatalog.api.TestHCatClient.testDatabaseLocation\norg.apache.hive.hcatalog.api.TestHCatClient.testDropPartitionsWithPartialSpec\norg.apache.hive.hcatalog.api.TestHCatClient.testDropTableException\norg.apache.hive.hcatalog.api.TestHCatClient.testEmptyTableInstantiation\norg.apache.hive.hcatalog.api.TestHCatClient.testGetMessageBusTopicName\norg.apache.hive.hcatalog.api.TestHCatClient.testGetPartitionsWithPartialSpec\norg.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException\norg.apache.hive.hcatalog.api.TestHCatClient.testOtherFailure\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSchema\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionsHCatClientImpl\norg.apache.hive.hcatalog.api.TestHCatClient.testRenameTable\norg.apache.hive.hcatalog.api.TestHCatClient.testReplicationTaskIter\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation\norg.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure\norg.apache.hive.hcatalog.api.TestHCatClient.testUpdateTableSchema\norg.apache.hive.hcatalog.api.TestHCatClientNotification.org.apache.hive.hcatalog.api.TestHCatClientNotification\norg.apache.hive.hcatalog.api.repl.TestReplicationTask.testCreate\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testBasicReplEximCommands\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropDatabaseCommand\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropPartitionCommand\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropTableCommand\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropTableCommand2\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testMetadataReplEximCommands\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testNoopReplEximCommands\norg.apache.hive.hcatalog.api.repl.exim.TestEximReplicationTasks.org.apache.hive.hcatalog.api.repl.exim.TestEximReplicationTasks\norg.apache.hive.hcatalog.cli.SemanticAnalysis.TestHCatAuthUtil.authDisabled\norg.apache.hive.hcatalog.cli.SemanticAnalysis.TestHCatAuthUtil.authEnabledV1Auth\norg.apache.hive.hcatalog.cli.SemanticAnalysis.TestHCatAuthUtil.authEnabledV2Auth\norg.apache.hive.hcatalog.cli.TestPermsGrp.testCustomPerms\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddDriverInfo\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddPartFail\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddPartPass\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddReplaceCols\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTableSetFF\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTblClusteredBy\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTblFFpart\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTblTouch\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCTAS\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCTLFail\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCTLPass\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testChangeColumns\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCreateTableIfNotExists\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCreateTblWithLowerCasePartNames\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testDatabaseOperations\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testDescDB\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateClusteredBy\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateNonStringPartition\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateSeqFileStoredAs\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateTextFileStoredAs\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testStoredAs\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testUsNonExistentDB\norg.apache.hive.hcatalog.cli.TestUseDatabase.testAlterTablePass\norg.apache.hive.hcatalog.common.TestHiveClientCache.testCacheExpiry\norg.apache.hive.hcatalog.common.TestHiveClientCache.testCacheHit\norg.apache.hive.hcatalog.common.TestHiveClientCache.testCacheMiss\norg.apache.hive.hcatalog.common.TestHiveClientCache.testCloseAllClients\norg.apache.hive.hcatalog.common.TestHiveClientCache.testMultipleThreadAccess\norg.apache.hive.hcatalog.data.TestReaderWriter.test\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler\norg.apache.hive.hcatalog.listener.TestDbNotificationListener.org.apache.hive.hcatalog.listener.TestDbNotificationListener\norg.apache.hive.hcatalog.listener.TestMsgBusConnection.testConnection\norg.apache.hive.hcatalog.listener.TestNotificationListener.testAMQListener\norg.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatHiveCompatibility.testPartedRead\norg.apache.hive.hcatalog.mapreduce.TestHCatHiveCompatibility.testUnpartedReadWrite\norg.apache.hive.hcatalog.mapreduce.TestHCatHiveThriftCompatibility.testDynamicCols\norg.apache.hive.hcatalog.mapreduce.TestHCatInputFormat.testBadRecordHandlingFails\norg.apache.hive.hcatalog.mapreduce.TestHCatInputFormat.testBadRecordHandlingPasses\norg.apache.hive.hcatalog.mapreduce.TestHCatInputFormatMethods.testGetPartitionAndDataColumns\norg.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat.org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat\norg.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned\norg.apache.hive.hcatalog.mapreduce.TestHCatOutputFormat.testSetOutput\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish.testPartitionPublish\norg.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned\norg.apache.hive.hcatalog.mapreduce.TestInputJobInfo.test4ArgCreate\norg.apache.hive.hcatalog.mapreduce.TestPassProperties.testSequenceTableWriteReadMR\norg.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteRead\norg.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteReadMR\norg.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteRead\norg.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteReadMR\norg.apache.hive.hcatalog.pig.TestE2EScenarios.testReadOrcAndRCFromPig\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[5]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[0]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[1]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[2]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[3]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[4]\norg.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[5]\norg.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[0]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[1]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[2]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[3]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[4]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[5]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[0]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[1]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[2]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[3]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[4]\norg.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[5]\norg.apache.hive.hcatalog.pig.TestHCatLoaderStorer.testReadWrite\norg.apache.hive.hcatalog.pig.TestHCatLoaderStorer.testSmallTinyInt\norg.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[5]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[0]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[1]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[2]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[3]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[4]\norg.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[5]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[0]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[1]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[2]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[3]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[5]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[0]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[1]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[2]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[3]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[5]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[0]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[1]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[2]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[3]\norg.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[5]\norg.apache.hive.hcatalog.pig.TestHCatStorerWrapper.testStoreExternalTableWithExternalDir\norg.apache.hive.hcatalog.streaming.TestStreaming.testAddPartition\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketing\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol\norg.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits\norg.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection\norg.apache.hive.hcatalog.streaming.TestStreaming.testHearbeat\norg.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits\norg.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits\norg.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions\norg.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing\norg.apache.hive.hcatalog.streaming.TestStreaming.testTableValidation\norg.apache.hive.hcatalog.streaming.TestStreaming.testTimeOutReaper\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyAbort\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyAbortPartitioned\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyAbortUnartitioned\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyCommitPartitioned\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyCommitUnpartitioned\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes\norg.apache.hive.jdbc.TestJdbcDriver2.org.apache.hive.jdbc.TestJdbcDriver2\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark\norg.apache.hive.jdbc.TestJdbcWithMiniHS2.org.apache.hive.jdbc.TestJdbcWithMiniHS2\norg.apache.hive.jdbc.TestJdbcWithMiniMr.org.apache.hive.jdbc.TestJdbcWithMiniMr\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark\norg.apache.hive.jdbc.TestNoSaslAuth.org.apache.hive.jdbc.TestNoSaslAuth\norg.apache.hive.jdbc.TestSSL.testConnectionMismatch\norg.apache.hive.jdbc.TestSSL.testInvalidConfig\norg.apache.hive.jdbc.TestSSL.testSSLConnectionWithProperty\norg.apache.hive.jdbc.TestSSL.testSSLConnectionWithURL\norg.apache.hive.jdbc.TestSSL.testSSLFetch\norg.apache.hive.jdbc.TestSSL.testSSLFetchHttp\norg.apache.hive.jdbc.TestSSL.testSSLVersion\norg.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerPrimaryQueueMapping\norg.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerQueueMapping\norg.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerSecondaryQueueMapping\norg.apache.hive.jdbc.TestSchedulerQueue.testQueueMappingCheckDisabled\norg.apache.hive.jdbc.authorization.TestCLIAuthzSessionContext.org.apache.hive.jdbc.authorization.TestCLIAuthzSessionContext\norg.apache.hive.jdbc.authorization.TestHS2AuthzContext.org.apache.hive.jdbc.authorization.TestHS2AuthzContext\norg.apache.hive.jdbc.authorization.TestHS2AuthzSessionContext.org.apache.hive.jdbc.authorization.TestHS2AuthzSessionContext\norg.apache.hive.jdbc.authorization.TestJdbcMetadataApiAuth.org.apache.hive.jdbc.authorization.TestJdbcMetadataApiAuth\norg.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthUDFBlacklist.testBlackListedUdfUsage\norg.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization.org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization\norg.apache.hive.jdbc.miniHS2.TestHiveServer2.org.apache.hive.jdbc.miniHS2.TestHiveServer2\norg.apache.hive.jdbc.miniHS2.TestHiveServer2SessionTimeout.testConnection\norg.apache.hive.jdbc.miniHS2.TestMiniHS2.testConfInSession\norg.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForDBTokenStore\norg.apache.hive.minikdc.TestHs2HooksWithMiniKdc.org.apache.hive.minikdc.TestHs2HooksWithMiniKdc\norg.apache.hive.minikdc.TestJdbcWithMiniKdc.org.apache.hive.minikdc.TestJdbcWithMiniKdc\norg.apache.hive.minikdc.TestJdbcWithMiniKdcCookie.org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie\norg.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthBinary.org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthBinary\norg.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthHttp.org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthHttp\norg.apache.hive.service.auth.TestCustomAuthentication.org.apache.hive.service.auth.TestCustomAuthentication\norg.apache.hive.service.auth.TestPlainSaslHelper.testDoAsSetting\norg.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService\norg.apache.hive.service.cli.TestRetryingThriftCLIServiceClient.testRetryBehaviour\norg.apache.hive.service.cli.operation.TestOperationLoggingAPIWithMr.org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithMr\norg.apache.hive.service.cli.operation.TestOperationLoggingAPIWithTez.org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithTez\norg.apache.hive.service.cli.operation.TestOperationLoggingLayout.org.apache.hive.service.cli.operation.TestOperationLoggingLayout\norg.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitDir\norg.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFile\norg.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFileAndConfOverlay\norg.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFileWithUser\norg.apache.hive.service.cli.session.TestSessionHooks.testProxyUser\norg.apache.hive.service.cli.session.TestSessionHooks.testSessionHook\norg.apache.hive.service.cli.thrift.TestThriftBinaryCLIService.org.apache.hive.service.cli.thrift.TestThriftBinaryCLIService\norg.apache.hive.service.cli.thrift.TestThriftHttpCLIService.org.apache.hive.service.cli.thrift.TestThriftHttpCLIService\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6049/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6049/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6049/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 898 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12772479 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-11-16T19:21:34.561+0000","updated":"2015-11-16T19:21:34.561+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15007204","id":"15007204","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"2.0 is a good time to do this. Lets try to get it in. Web page pointed out by Sushanth does list few items we need to be wary of.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-16T19:48:37.310+0000","updated":"2015-11-16T19:48:37.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15008513","id":"15008513","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":">  Have you verified the elements in http://www.datanucleus.org/products/accessplatform_4_2/migration.html to see if we won't be affected adversely?\n\nYes. Added HIVE-6113-2.patch where applied all changes regarding DN version migration from 3.X.X to 4.X.X. See https://reviews.apache.org/r/40344/\n\nCode change summary. \nRenamed:\ndatanucleus.validateTables ---> datanucleus.schema.validateTables\ndatanucleus.validateColumns ---> datanucleus.schema.validateColumns\ndatanucleus.validateConstraints ---> datanucleus.schema.validateConstraints\ndatanucleus.autoCreateSchema ---> datanucleus.schema.autoCreateAll\n\nDeleted:\ndatanucleus.fixedDatastore","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-17T11:27:57.285+0000","updated":"2015-11-17T11:27:57.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15008558","id":"15008558","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliac","name":"eliac","key":"eliac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Acherkan","active":true,"timeZone":"Asia/Jerusalem"},"body":"> @Eli Acherkan : Very interesting analysis. Could you point me to where you see the following:\n>> If a table is deleted from the DB during this operation, DatabaseMetaData.getColumns will throw an exception.\n>> This exception is interpreted by Hive to mean that the \"default\" Hive database doesn't exist.\n\nSure, let me try to explain.\n\n#When DatabaseMetaData.getColumns throws an SQLException, it's caught by RDBMSSchemaHandler.refreshTableData and rethrown as a NucleusDataStoreException.\n#This one is then caught by JDOQLQuery.compileQueryFull, which doesn't rethrow an exception - it simply returns an empty result.\n#ObjectStore.getMDatabase then receives the empty result and throws a NoSuchObjectException.\n#This exception is caught by HiveMetaStore.createDefaultDB_core, and taken to mean that the default DB doesn't exist.\n#The createDefaultDB_core method then proceeds to try to create a DB, which fails because the DB actually _does_exist already.\n\nPlease let me know if the above is unclear.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliac","name":"eliac","key":"eliac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Acherkan","active":true,"timeZone":"Asia/Jerusalem"},"created":"2015-11-17T12:09:54.853+0000","updated":"2015-11-17T12:09:54.853+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15010696","id":"15010696","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"Hi team!\nAny updates regarding HIVE-6113-2.patch ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-18T10:24:28.452+0000","updated":"2015-11-18T10:24:28.452+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15011610","id":"15011610","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"va/org/apache/hadoop/hive/conf/HiveConf.java\n\n     if (getBoolVar(ConfVars.METASTORE_SCHEMA_VERIFICATION)) {\n-      setBoolVar(ConfVars.METASTORE_AUTO_CREATE_SCHEMA, false);\n-      setBoolVar(ConfVars.METASTORE_FIXED_DATASTORE, true);\n+      setBoolVar(ConfVars.METASTORE_AUTO_CREATE_ALL, false);\n     }\n\nI'm not sure about this change. Do we really need to set  setBoolVar(ConfVars.METASTORE_AUTO_CREATE_ALL, false);? What about 'true' value? Please advice.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-18T18:33:03.766+0000","updated":"2015-11-18T18:33:03.766+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15014691","id":"15014691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"Wrt the patch, it looks like all the tests have failed above.\nAlso given the code changes, I assume there's no way to downgrade to old DN jars on a running Hive build if some issue is discovered? I love it when people change public APIs to beautify some package name or whatever. Maybe we can try to find the classes by string name to be able to use both jars?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-19T23:08:34.140+0000","updated":"2015-11-19T23:08:34.140+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15020277","id":"15020277","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12773550/HIVE-6113.3.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6089/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6089/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6089/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]\n+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera\n+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera\n+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin\n+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ cd /data/hive-ptest/working/\n+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-6089/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 8e9bae2 HIVE-12472: Add test case for HIVE-10592 (Prasanth Jayachandran reviewed by  Ashutosh Chauhan)\n+ git clean -f -d\nRemoving data/files/TJOIN1\nRemoving data/files/TJOIN2\nRemoving data/files/TJOIN3\nRemoving data/files/TJOIN4\nRemoving ql/src/test/queries/clientpositive/vector_outer_join6.q\nRemoving ql/src/test/results/clientpositive/tez/vector_outer_join6.q.out\nRemoving ql/src/test/results/clientpositive/vector_outer_join6.q.out\n+ git checkout master\nAlready on 'master'\n+ git reset --hard origin/master\nHEAD is now at 8e9bae2 HIVE-12472: Add test case for HIVE-10592 (Prasanth Jayachandran reviewed by  Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ git gc\n+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hive-ptest/working/scratch/build.patch\n+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]\n+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12773550 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-11-21T06:41:06.176+0000","updated":"2015-11-21T06:41:06.176+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15026135","id":"15026135","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12773890/HIVE-6113.4.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6120/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6120/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6120/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---\n[INFO] Compiling 51 source files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-util ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-util ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf\n     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-util ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-util ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-util ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.0.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-util ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-util ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.0.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.0.0-SNAPSHOT/hive-it-util-2.0.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.0.0-SNAPSHOT/hive-it-util-2.0.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Integration - Unit Tests 2.0.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-unit ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n     [exec] + /bin/pwd\n     [exec] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit\n     [exec] + BASE_DIR=./target\n     [exec] + HIVE_ROOT=./target/../../../\n     [exec] + DOWNLOAD_DIR=./../thirdparty\n     [exec] + mkdir -p ./../thirdparty\n     [exec] + download http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz spark\n     [exec] + url=http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz\n     [exec] + finalName=spark\n     [exec] ++ basename http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz\n     [exec] + tarName=spark-1.5.0-bin-hadoop2-without-hive.tgz\n     [exec] + rm -rf ./target/spark\n     [exec] + [[ ! -f ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz ]]\n     [exec] + tar -zxf ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz -C ./target\n     [exec] + mv ./target/spark-1.5.0-bin-hadoop2-without-hive ./target/spark\n     [exec] + cp -f ./target/../../..//data/conf/spark/log4j2.xml ./target/spark/conf/\n     [exec] + sed '/package /d' /data/hive-ptest/working/apache-github-source-source/itests/../contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java\n     [exec] + javac -cp /data/hive-ptest/working/maven/org/apache/hive/hive-exec/2.0.0-SNAPSHOT/hive-exec-2.0.0-SNAPSHOT.jar /tmp/UDFExampleAdd.java -d /tmp\n     [exec] + jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/classes\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf\n     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore\n     [copy] Copying 235 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit ---\n[INFO] Compiling 98 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/test-classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[54,41] cannot find symbol\n  symbol:   variable METASTORE_AUTO_CREATE_SCHEMA\n  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[55,41] cannot find symbol\n  symbol:   variable METASTORE_FIXED_DATASTORE\n  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[84,53] cannot find symbol\n  symbol:   variable METASTORE_AUTO_CREATE_SCHEMA\n  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[85,54] cannot find symbol\n  symbol:   variable METASTORE_FIXED_DATASTORE\n  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[96,54] cannot find symbol\n  symbol:   variable METASTORE_AUTO_CREATE_SCHEMA\n  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[97,53] cannot find symbol\n  symbol:   variable METASTORE_FIXED_DATASTORE\n  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[INFO] 6 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive Integration - Parent ......................... SUCCESS [7.774s]\n[INFO] Hive Integration - Custom Serde ................... SUCCESS [14.734s]\n[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [24.616s]\n[INFO] Hive Integration - Testing Utilities .............. SUCCESS [18.257s]\n[INFO] Hive Integration - Unit Tests ..................... FAILURE [28.255s]\n[INFO] Hive Integration - Test Serde ..................... SKIPPED\n[INFO] Hive Integration - QFile Tests .................... SKIPPED\n[INFO] Hive Integration - QFile Accumulo Tests ........... SKIPPED\n[INFO] JMH benchmark: Hive ............................... SKIPPED\n[INFO] Hive Integration - Unit Tests - Hadoop 2 .......... SKIPPED\n[INFO] Hive Integration - Unit Tests with miniKdc ........ SKIPPED\n[INFO] Hive Integration - QFile Spark Tests .............. SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:39.450s\n[INFO] Finished at: Tue Nov 24 23:04:48 EST 2015\n[INFO] Final Memory: 84M/327M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-2\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[54,41] cannot find symbol\n[ERROR] symbol:   variable METASTORE_AUTO_CREATE_SCHEMA\n[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[55,41] cannot find symbol\n[ERROR] symbol:   variable METASTORE_FIXED_DATASTORE\n[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[84,53] cannot find symbol\n[ERROR] symbol:   variable METASTORE_AUTO_CREATE_SCHEMA\n[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[85,54] cannot find symbol\n[ERROR] symbol:   variable METASTORE_FIXED_DATASTORE\n[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[96,54] cannot find symbol\n[ERROR] symbol:   variable METASTORE_AUTO_CREATE_SCHEMA\n[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[97,53] cannot find symbol\n[ERROR] symbol:   variable METASTORE_FIXED_DATASTORE\n[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-it-unit\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12773890 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-11-25T04:04:50.464+0000","updated":"2015-11-25T04:04:50.464+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15026579","id":"15026579","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"Fixed compilation error in TestMetastoreVersion.java","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-25T10:35:44.302+0000","updated":"2015-11-25T10:35:44.302+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15030421","id":"15030421","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12774318/HIVE-6113.5.patch\n\n{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 9865 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping\norg.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching\norg.apache.hive.jdbc.TestSSL.testSSLVersion\norg.apache.hive.jdbc.miniHS2.TestHs2Metrics.testMetrics\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6152/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6152/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6152/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 8 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12774318 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-11-28T08:08:35.255+0000","updated":"2015-11-28T08:08:35.255+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15032465","id":"15032465","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"Fixed org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-30T21:10:00.507+0000","updated":"2015-11-30T21:10:00.507+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15032542","id":"15032542","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Since DN property names are changing, it will be good to have this one before 2.0 for backward compat reasons. Apart from the issue discussed on this jira, it will also help HIVE-11036 \n[~thejas] [~sushanth]  I think you guys are best equipped to review this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-30T21:47:53.678+0000","updated":"2015-11-30T21:47:53.678+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15036950","id":"15036950","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"Suggested patch with reflection to be able to downgrade the JAR just in case...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-03T00:30:53.934+0000","updated":"2015-12-03T00:30:53.934+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15037907","id":"15037907","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"Hi Sergey,\n\n{code:title=Utilities.java|borderStyle=solid}\n    if (DN_MAP_CLASS != null) {\n      e.setPersistenceDelegate(DN_MAP_CLASS, new MapDelegate());\n    }\n    if (DN_LIST_CLASS != null) {\n      e.setPersistenceDelegate(DN_LIST_CLASS, new ListDelegate());\n    }\n    if (DN_MAP_CLASS == null || DN_LIST_CLASS == null) {\n      LOG.info(\"DN map and/or list classes were not found; not adding persistence delegate\");\n    }\n{code}\n\n1. Why not to throw Exception here or at least LOG.error() ?\n2. Why not no move not null verification before class usage and thus skip double verification. I mean smth like this:\n\n{code:title=Utilities.java|borderStyle=solid}\n    if (DN_MAP_CLASS == null || DN_LIST_CLASS == null) {\n      throw new ClassNotFoundException(\"DN map and/or list classes were not found; not adding persistence delegate\");\n    }\n      e.setPersistenceDelegate(DN_MAP_CLASS, new MapDelegate());\n      e.setPersistenceDelegate(DN_LIST_CLASS, new ListDelegate());\n{code}\n\nThanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-03T15:12:56.269+0000","updated":"2015-12-03T15:12:56.269+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15043447","id":"15043447","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"Added Sergey's reflection code that makes Hive to be able to downgrade the DN JAR.\n\nReflection code is available in HIVE-6113.7.patch ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-05T18:57:20.310+0000","updated":"2015-12-05T18:57:20.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15043734","id":"15043734","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12775944/HIVE-6113.7.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6263/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6263/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6263/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/2.1.0-SNAPSHOT/hive-hcatalog-it-unit-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/2.1.0-SNAPSHOT/hive-hcatalog-it-unit-2.1.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.1.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/2.1.0-SNAPSHOT/hive-hcatalog-it-unit-2.1.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Integration - Testing Utilities 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-util ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/util/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/util (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-util ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-util ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-util ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-util ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-util ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---\n[INFO] Compiling 51 source files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-util ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-util ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf\n     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-util ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-util ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-util ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-util ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-util ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.1.0-SNAPSHOT/hive-it-util-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.1.0-SNAPSHOT/hive-it-util-2.1.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Integration - Unit Tests 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-unit ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n     [exec] + /bin/pwd\n     [exec] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit\n     [exec] + BASE_DIR=./target\n     [exec] + HIVE_ROOT=./target/../../../\n     [exec] + DOWNLOAD_DIR=./../thirdparty\n     [exec] + mkdir -p ./../thirdparty\n     [exec] + download http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz spark\n     [exec] + url=http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz\n     [exec] + finalName=spark\n     [exec] ++ basename http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz\n     [exec] + tarName=spark-1.5.0-bin-hadoop2-without-hive.tgz\n     [exec] + rm -rf ./target/spark\n     [exec] + [[ ! -f ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz ]]\n     [exec] + tar -zxf ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz -C ./target\n     [exec] + mv ./target/spark-1.5.0-bin-hadoop2-without-hive ./target/spark\n     [exec] + cp -f ./target/../../..//data/conf/spark/log4j2.properties ./target/spark/conf/\n     [exec] + sed '/package /d' /data/hive-ptest/working/apache-github-source-source/itests/../contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java\n     [exec] + javac -cp /data/hive-ptest/working/maven/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT.jar /tmp/UDFExampleAdd.java -d /tmp\n     [exec] + jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/classes\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf\n     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore\n     [copy] Copying 245 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit ---\n[INFO] Compiling 98 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/test-classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java:[798,34] cannot find symbol\n  symbol:   class AbstractNucleusContext\n  location: class org.apache.hive.jdbc.TestJdbcWithMiniHS2\n[INFO] 1 error\n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive Integration - Parent ......................... SUCCESS [7.133s]\n[INFO] Hive Integration - Custom Serde ................... SUCCESS [16.180s]\n[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [23.874s]\n[INFO] Hive Integration - Testing Utilities .............. SUCCESS [16.164s]\n[INFO] Hive Integration - Unit Tests ..................... FAILURE [28.503s]\n[INFO] Hive Integration - Test Serde ..................... SKIPPED\n[INFO] Hive Integration - QFile Tests .................... SKIPPED\n[INFO] Hive Integration - QFile Accumulo Tests ........... SKIPPED\n[INFO] JMH benchmark: Hive ............................... SKIPPED\n[INFO] Hive Integration - Unit Tests - Hadoop 2 .......... SKIPPED\n[INFO] Hive Integration - Unit Tests with miniKdc ........ SKIPPED\n[INFO] Hive Integration - QFile Spark Tests .............. SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:36.347s\n[INFO] Finished at: Sun Dec 06 01:43:22 EST 2015\n[INFO] Final Memory: 85M/244M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-2\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit: Compilation failure\n[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java:[798,34] cannot find symbol\n[ERROR] symbol:   class AbstractNucleusContext\n[ERROR] location: class org.apache.hive.jdbc.TestJdbcWithMiniHS2\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-it-unit\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12775944 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-12-06T06:43:23.698+0000","updated":"2015-12-06T06:43:23.698+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15043764","id":"15043764","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"Added import of AbstractNucleusContext;","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-06T08:31:12.629+0000","updated":"2015-12-06T08:31:12.629+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15043934","id":"15043934","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12775977/HIVE-6113.8.patch\n\n{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 9897 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_udf_max\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorized_dynamic_partition_pruning\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping\norg.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching\norg.apache.hive.jdbc.TestSSL.testSSLVersion\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6268/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6268/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6268/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 9 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12775977 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-12-06T15:58:05.969+0000","updated":"2015-12-06T15:58:05.969+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15046839","id":"15046839","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"body":"I have applied HIVE-6113.with.reflection.patch, installed patched hive, replaced \n\n{noformat}\ndatanucleus-api-jdo-4.2.1.jar\ndatanucleus-core-4.1.6.jar\ndatanucleus-rdbms-4.1.7.jar\n{noformat}\n\nwith\n\n{noformat}\ndatanucleus-api-jdo-3.2.6.jar'\ndatanucleus-core-3.2.10.jar'\ndatanucleus-rdbms-3.2.9.jar'\n{noformat}\n\nin hive/lib folder, and restarted hive-metsatore. Then I got an exception (see below). If I replace back datanucleus-*3.X*jar with datanucleus-*4.X*jar, then hive-metsatore starts fine.\n\n{noformat}\norg.datanucleus.api.jdo.exceptions.ClassNotPersistenceCapableException: The class \"org.apache.hadoop.hive.metastore.model.MVersionTable\" is not persistable. This means that it either hasnt been enhanced, or that the enhanced version of the file is not in the CLASSPATH (or is hidden by an unenhanced version), or the Meta-Data/annotations for the class are not found.\n\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:380)\n\tat org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:732)\n\tat org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6776)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6673)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6648)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)\n\tat com.sun.proxy.$Proxy4.verifySchema(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:572)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5756)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5751)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:5984)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:5909)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nNestedThrowablesStackTrace:\nThe class \"org.apache.hadoop.hive.metastore.model.MVersionTable\" is not persistable. This means that it either hasnt been enhanced, or that the enhanced version of the file is not in the CLASSPATH (or is hidden by an unenhanced version), or the Meta-Data/annotations for the class are not found.\norg.datanucleus.exceptions.ClassNotPersistableException: The class \"org.apache.hadoop.hive.metastore.model.MVersionTable\" is not persistable. This means that it either hasnt been enhanced, or that the enhanced version of the file is not in the CLASSPATH (or is hidden by an unenhanced version), or the Meta-Data/annotations for the class are not found.\n\tat org.datanucleus.ExecutionContextImpl.assertClassPersistable(ExecutionContextImpl.java:5698)\n\tat org.datanucleus.ExecutionContextImpl.persistObjectInternal(ExecutionContextImpl.java:2123)\n\tat org.datanucleus.ExecutionContextImpl.persistObjectWork(ExecutionContextImpl.java:2065)\n\tat org.datanucleus.ExecutionContextImpl.persistObject(ExecutionContextImpl.java:1913)\n\tat org.datanucleus.ExecutionContextThreadedImpl.persistObject(ExecutionContextThreadedImpl.java:217)\n\tat org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:727)\n\tat org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6776)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6673)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6648)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)\n\tat com.sun.proxy.$Proxy4.verifySchema(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:572)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5756)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5751)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:5984)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:5909)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n{noformat}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=osayankin","name":"osayankin","key":"osayankin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=osayankin&avatarId=34533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=osayankin&avatarId=34533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=osayankin&avatarId=34533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=osayankin&avatarId=34533"},"displayName":"Oleksiy Sayankin","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-08T13:12:01.968+0000","updated":"2015-12-08T13:12:01.968+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15047608","id":"15047608","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"+0.99, TestJdbcWithMiniHS2 appears to be related","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-08T22:37:51.415+0000","updated":"2015-12-08T22:37:51.415+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15067277","id":"15067277","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"Rebased the patch (the code to add custom handlers was removed in some other JIRA); fixed the classloader map cleanup that broke the test.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-21T23:52:40.986+0000","updated":"2015-12-21T23:52:40.986+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15068497","id":"15068497","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12778935/HIVE-6113.9.patch\n\n{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 19 failed/errored test(s), 9899 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestSparkCliDriver-timestamp_lazy.q-bucketsortoptimize_insert_4.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_stats2\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_multiple_part_clause\norg.apache.hadoop.hive.cli.TestPerfCliDriver.initializationError\norg.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse\norg.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse\norg.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.checkHiveOperationTypeMatch\norg.apache.hive.jdbc.TestSSL.testSSLVersion\norg.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles\norg.apache.hive.spark.client.TestSparkClient.testCounters\norg.apache.hive.spark.client.TestSparkClient.testErrorJob\norg.apache.hive.spark.client.TestSparkClient.testJobSubmission\norg.apache.hive.spark.client.TestSparkClient.testMetricsCollection\norg.apache.hive.spark.client.TestSparkClient.testRemoteClient\norg.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob\norg.apache.hive.spark.client.TestSparkClient.testSyncRpc\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6444/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6444/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6444/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 19 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12778935 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-12-22T18:07:26.753+0000","updated":"2015-12-22T18:07:26.753+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15068629","id":"15068629","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"Hmm. The test that failed works for me locally. Added the property just in case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-22T19:43:22.327+0000","updated":"2015-12-22T19:43:22.327+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15069683","id":"15069683","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12779112/HIVE-6113.10.patch\n\n{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 18 failed/errored test(s), 9961 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestSparkCliDriver-timestamp_lazy.q-bucketsortoptimize_insert_4.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_stats2\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_multiple_part_clause\norg.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse\norg.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse\norg.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.checkHiveOperationTypeMatch\norg.apache.hive.jdbc.TestSSL.testSSLVersion\norg.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles\norg.apache.hive.spark.client.TestSparkClient.testCounters\norg.apache.hive.spark.client.TestSparkClient.testErrorJob\norg.apache.hive.spark.client.TestSparkClient.testJobSubmission\norg.apache.hive.spark.client.TestSparkClient.testMetricsCollection\norg.apache.hive.spark.client.TestSparkClient.testRemoteClient\norg.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob\norg.apache.hive.spark.client.TestSparkClient.testSyncRpc\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6457/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6457/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6457/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 18 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12779112 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-12-23T14:43:20.190+0000","updated":"2015-12-23T14:43:20.190+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15070171","id":"15070171","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"None of the tests have age 1. +1. Will commit later today unless there are objections","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-23T20:43:33.116+0000","updated":"2015-12-23T20:43:33.116+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15081793","id":"15081793","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to master and branch-2.0","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-04T20:57:05.188+0000","updated":"2016-01-04T20:57:05.188+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15093058","id":"15093058","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sladymon","name":"sladymon","key":"sladymon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shannon Ladymon","active":true,"timeZone":"America/Vancouver"},"body":"Doc note: This changes the name of four configuration parameters in HiveConf.java in 2.0.0. The new names are documented in the wiki in the Configuration Properties section here:\n* [datanucleus.schema.validateTables | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.validateTables]\n* [datanucleus.schema.validateColumns | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.validateColumns]\n* [datanucleus.schema.validateConstraints | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.validateConstraints]\n* [datanucleus.schema.autoCreateAll | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.autoCreateAll]\n\nAdditionally, *datanucleus.fixedDatastore* was updated to show that it was removed and *hive.metastore.schema.verification* was updated to note that it affects *datanucleus.schema.autoCreateAll*:\n* [datanucleus.fixedDatastore | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.fixedDatastore]\n* [hive.metastore.schema.verification | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.metastore.schema.verification]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sladymon","name":"sladymon","key":"sladymon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shannon Ladymon","active":true,"timeZone":"America/Vancouver"},"created":"2016-01-12T01:15:28.261+0000","updated":"2016-01-12T01:15:28.261+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15093141","id":"15093141","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"[~sershe] and [~osayankin], are these two sentences from \"Metastore Schema Consistency and Upgrades\" and \"Metastore Schema Verification\" still valid?\n\n{quote}\nTo suppress the schema check and allow the metastore to implicitly modify the schema, you need to set a configuration property hive.metastore.schema.verification to false in hive-site.xml.\n{quote}\n\n{quote}\nBy default the configuration property hive.metastore.schema.verification is false and metastore to implicitly write the schema version if it's not matching. To enable the strict schema verification, you need to set this property to true in hive-site.xml.\n{quote}\n\nI don't understand why *hive.metastore.schema.verification* would need to be set to false in hive-site.xml since it is already false by default in HiveConf.java.  I also don't know which hive-site.xml file(s) should be set, or whether the parameter could be set in HiveConf.java instead.  HIVE-12841 asks for better documentation of hive-site.xml.\n\nAlso, in the second sentence quoted above should \"... and metastore to implicitly write\" be changed to \"... will implicitly write\" (or \"... implicitly writes\")?\n\nFinally, I don't understand what is meant by implicitly modifying the schema or implicitly writing the schema version -- are they the same thing, that is, \"modify the schema\" means \"modify the schema version\"?  If you're not the right people to ask, perhaps you could suggest someone else.  Thanks.\n\nHere are the quoted sections:\n\n* [Admin Manual -- Metastore Admin -- Metastore Schema Consistency and Upgrades | https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin#AdminManualMetastoreAdmin-MetastoreSchemaConsistencyandUpgrades]\n* [Hive Schema Tool -- Metastore Schema Verification | https://cwiki.apache.org/confluence/display/Hive/Hive+Schema+Tool#HiveSchemaTool-MetastoreSchemaVerification]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2016-01-12T02:06:48.050+0000","updated":"2016-01-12T02:06:48.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12686504/comment/15930671","id":"15930671","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"body":"Removing target 1.2.2 as it's a minor upgrade and this change touches lots of parts.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgumashta","name":"vgumashta","key":"vgumashta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vaibhav Gumashta","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-03-17T20:33:50.069+0000","updated":"2017-03-17T20:33:50.069+0000"}],"maxResults":36,"total":36,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6113/votes","votes":5,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1qzxr:"}}