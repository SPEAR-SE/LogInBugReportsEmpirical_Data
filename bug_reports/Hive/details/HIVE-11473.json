{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12852388","self":"https://issues.apache.org/jira/rest/api/2/issue/12852388","key":"HIVE-11473","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327352","id":"12327352","description":"Dev branch for Hive on Spark","name":"spark-branch","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332154","id":"12332154","description":"","name":"1.3.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-08-05T22:10:39.384+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Oct 22 06:18:23 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_4044796_*|*_4_*:*_1_*:*_193225942_*|*_5_*:*_2_*:*_4156730329_*|*_10002_*:*_1_*:*_2330131940","customfield_12312321":null,"resolutiondate":"2015-10-22T06:18:23.305+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11473/watchers","watchCount":4,"isWatching":false},"created":"2015-08-05T21:36:10.345+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12448092","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12448092","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12910969","key":"BIGTOP-2114","self":"https://issues.apache.org/jira/rest/api/2/issue/12910969","fields":{"summary":"hive is broken after BIGTOP-2104","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-02-16T23:51:07.166+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"In Spark 1.5, SparkListener interface is changed. So HoS may fail to create the spark client if the un-implemented event callback method is invoked.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12762349","id":"12762349","filename":"HIVE-11473.1-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T07:39:01.336+0000","size":2883,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12762349/HIVE-11473.1-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12762435","id":"12762435","filename":"HIVE-11473.2-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-25T18:47:01.027+0000","size":3384,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12762435/HIVE-11473.2-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12764153","id":"12764153","filename":"HIVE-11473.3-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-29T01:38:01.099+0000","size":8713,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12764153/HIVE-11473.3-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12762632","id":"12762632","filename":"HIVE-11473.3-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-28T03:17:48.955+0000","size":8713,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12762632/HIVE-11473.3-spark.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Upgrade Spark dependency to 1.5 [Spark Branch]","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14659060","id":"14659060","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I believe that Hive is currently at Spark. Thus, this seems more applicable when Spark dependency is upgraded.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-05T22:10:39.384+0000","updated":"2015-08-05T22:10:39.384+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14659111","id":"14659111","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"body":"Ok. Closed it for now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-05T22:43:24.033+0000","updated":"2015-08-05T22:43:24.033+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14902267","id":"14902267","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Shall we reopen this one as Spark 1.5.0 has been released?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-22T09:09:12.583+0000","updated":"2015-09-22T09:09:12.583+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14902632","id":"14902632","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Makes sense. However, Hive still depends on 1.4 at the moment. Maybe we change the JIRA to upgrade the dependency?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-22T13:41:26.873+0000","updated":"2015-09-22T13:41:26.873+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14903769","id":"14903769","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Changed the JIRA as Xuefu suggested.\n[~jxiang], please let me know if you still want to work on this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-23T01:22:25.451+0000","updated":"2015-09-23T01:22:25.451+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14904661","id":"14904661","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui], feel free to take it. I have something else to take care currently. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jxiang","name":"jxiang","key":"jxiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jimmy Xiang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-23T15:28:06.808+0000","updated":"2015-09-23T15:28:06.808+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907357","id":"14907357","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"I tried the patch locally with Spark 1.5.0 and passed some simple queries.\n[~xuefuz], to run the tests, would you mind package a new Spark tar and upload to our repo? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T01:34:24.135+0000","updated":"2015-09-25T01:34:24.135+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907539","id":"14907539","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks, Rui. I'm building it. However, publishing it might take a little bit longer as I don't have the credentials. I will update once done.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-25T04:12:25.454+0000","updated":"2015-09-25T04:12:25.454+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907590","id":"14907590","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"The tarball is published here: http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-25T05:08:13.766+0000","updated":"2015-09-25T05:08:13.766+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907720","id":"14907720","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks Xuefu. Let the tests run.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T07:02:51.400+0000","updated":"2015-09-25T07:02:51.400+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907741","id":"14907741","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12762295/HIVE-11473.1-spark.patch\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/950/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/950/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-950/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] ------------------------------------------------------------------------\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.pom (20 KB at 189.7 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-parent_2.10/1.5.0/spark-parent_2.10-1.5.0.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-parent_2.10/1.5.0/spark-parent_2.10-1.5.0.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-parent_2.10/1.5.0/spark-parent_2.10-1.5.0.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-parent_2.10/1.5.0/spark-parent_2.10-1.5.0.pom (85 KB at 1153.1 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.pom (5 KB at 191.7 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.pom (4 KB at 136.1 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.pom (4 KB at 142.4 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom\nDownloading: https://repository.apache.org/content/repositories/releases/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom\nDownloaded: https://repository.apache.org/content/repositories/releases/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom (5 KB at 4.1 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.pom\nDownloading: http://repo.maven.apache.org/maven2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.pom\nDownloaded: http://repo.maven.apache.org/maven2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.pom (2 KB at 52.3 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.pom\nDownloading: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.pom\nDownloaded: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.pom (4 KB at 133.1 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.pom\nDownloading: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.pom\nDownloaded: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.pom (2 KB at 72.3 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.pom\nDownloading: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.pom\nDownloaded: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.pom (3 KB at 95.3 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.pom\nDownloaded: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.pom (846 B at 31.8 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/io/dropwizard/metrics/metrics-parent/3.1.2/metrics-parent-3.1.2.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/io/dropwizard/metrics/metrics-parent/3.1.2/metrics-parent-3.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-parent/3.1.2/metrics-parent-3.1.2.pom\nDownloaded: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-parent/3.1.2/metrics-parent-3.1.2.pom (12 KB at 434.1 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.pom\nDownloaded: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.pom (967 B at 36.3 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.pom\nDownloaded: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.pom (2 KB at 51.9 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.pom\nDownloaded: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.pom (2 KB at 36.2 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.pom\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.pom (8 KB at 267.2 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-clients/0.7.1/tachyon-clients-0.7.1.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-clients/0.7.1/tachyon-clients-0.7.1.pom\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-clients/0.7.1/tachyon-clients-0.7.1.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-clients/0.7.1/tachyon-clients-0.7.1.pom (918 B at 34.5 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-parent/0.7.1/tachyon-parent-0.7.1.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-parent/0.7.1/tachyon-parent-0.7.1.pom\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-parent/0.7.1/tachyon-parent-0.7.1.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-parent/0.7.1/tachyon-parent-0.7.1.pom (17 KB at 461.3 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.pom\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.pom (2 KB at 63.6 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-underfs/0.7.1/tachyon-underfs-0.7.1.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-underfs/0.7.1/tachyon-underfs-0.7.1.pom\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs/0.7.1/tachyon-underfs-0.7.1.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs/0.7.1/tachyon-underfs-0.7.1.pom (2 KB at 39.2 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.pom\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.pom\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.pom\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.pom (2 KB at 66.7 KB/sec)\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.jar\nDownloading: http://www.datanucleus.org/downloads/maven2/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.jar\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.jar\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.jar\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.jar\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.jar\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.jar\nDownloading: http://repo.maven.apache.org/maven2/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.jar\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-shuffle_2.10/1.5.0/spark-network-shuffle_2.10-1.5.0.jar (49 KB at 859.1 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-launcher_2.10/1.5.0/spark-launcher_2.10-1.5.0.jar (43 KB at 611.4 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.jar (43 KB at 496.3 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar\nDownloaded: http://repo.maven.apache.org/maven2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar (232 KB at 3401.9 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar\nDownloaded: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar (16 KB at 606.4 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar\nDownloaded: http://repo.maven.apache.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar (21 KB at 783.2 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.jar\nDownloaded: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar (1321 KB at 8304.6 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.jar\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-network-common_2.10/1.5.0/spark-network-common_2.10-1.5.0.jar (2276 KB at 9065.4 KB/sec)\nDownloading: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.jar\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-hdfs/0.7.1/tachyon-underfs-hdfs-0.7.1.jar (12 KB at 427.8 KB/sec)\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-underfs-local/0.7.1/tachyon-underfs-local-0.7.1.jar (8 KB at 223.3 KB/sec)\nDownloaded: http://repo.maven.apache.org/maven2/org/tachyonproject/tachyon-client/0.7.1/tachyon-client-0.7.1.jar (1926 KB at 15164.2 KB/sec)\nDownloaded: http://repo.maven.apache.org/maven2/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar (2596 KB at 11640.6 KB/sec)\nDownloaded: http://repo.maven.apache.org/maven2/org/apache/spark/spark-core_2.10/1.5.0/spark-core_2.10-1.5.0.jar (10822 KB at 31186.8 KB/sec)\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-client ---\n[INFO] Deleting /data/hive-ptest/working/apache-git-source-source/spark-client/target\n[INFO] Deleting /data/hive-ptest/working/apache-git-source-source/spark-client (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ spark-client ---\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-client ---\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [3.818s]\n[INFO] Hive Shims Common ................................. SUCCESS [4.453s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [1.055s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [3.130s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [0.990s]\n[INFO] Hive Shims ........................................ SUCCESS [0.689s]\n[INFO] Hive Storage API .................................. SUCCESS [0.790s]\n[INFO] Hive Common ....................................... SUCCESS [6.993s]\n[INFO] Hive Serde ........................................ SUCCESS [5.060s]\n[INFO] Hive Metastore .................................... SUCCESS [14.117s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.621s]\n[INFO] Spark Remote Client ............................... FAILURE [15.362s]\n[INFO] Hive Query Language ............................... SKIPPED\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 58.124s\n[INFO] Finished at: Fri Sep 25 03:38:17 EDT 2015\n[INFO] Final Memory: 78M/927M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.5:process (default) on project spark-client: Error resolving project artifact: Failure to transfer org.apache.spark:spark-unsafe_2.10:pom:1.5.0 from https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/ was cached in the local repository, resolution will not be reattempted until the update interval of spark-1.3 has elapsed or updates are forced. Original error: Could not transfer artifact org.apache.spark:spark-unsafe_2.10:pom:1.5.0 from/to spark-1.3 (https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/): Access denied to: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom , ReasonPhrase:Forbidden. for project org.apache.spark:spark-unsafe_2.10:jar:1.5.0 -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :spark-client\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12762295 - PreCommit-HIVE-SPARK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-09-25T07:24:56.847+0000","updated":"2015-09-25T07:24:56.847+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907756","id":"14907756","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Try again. The spark dependencies can be resolved on my side.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T07:39:01.339+0000","updated":"2015-09-25T07:39:01.339+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907767","id":"14907767","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"BTW, I think we can get rid of the {{spark-1.3}} repo?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T07:50:05.684+0000","updated":"2015-09-25T07:50:05.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907770","id":"14907770","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12762349/HIVE-11473.1-spark.patch\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/951/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/951/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-951/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO]   CP: /data/hive-ptest/working/maven/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar\n[INFO]   CP: /data/hive-ptest/working/maven/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar\n[INFO]   CP: /data/hive-ptest/working/maven/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar\n[INFO]   CP: /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar\nDataNucleus Enhancer (version 3.2.10) for API \"JDO\" using JRE \"1.7\"\nDataNucleus Enhancer : Classpath\n>>  /usr/local/apache-maven-3.0.5/boot/plexus-classworlds-2.4.jar\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nDataNucleus Enhancer completed with success for 29 classes. Timings : input=182 ms, enhance=313 ms, total=495 ms. Consult the log for full details\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-metastore ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-git-source-source/metastore/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-git-source-source/metastore/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-git-source-source/metastore/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-git-source-source/metastore/target/tmp/conf\n     [copy] Copying 10 files to /data/hive-ptest/working/apache-git-source-source/metastore/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---\n[INFO] Compiling 22 source files to /data/hive-ptest/working/apache-git-source-source/metastore/target/test-classes\n[WARNING] /data/hive-ptest/working/apache-git-source-source/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-git-source-source/metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---\n[INFO] Building jar: /data/hive-ptest/working/apache-git-source-source/metastore/target/hive-metastore-2.0.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-metastore ---\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---\n[INFO] Building jar: /data/hive-ptest/working/apache-git-source-source/metastore/target/hive-metastore-2.0.0-SNAPSHOT-tests.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---\n[INFO] Installing /data/hive-ptest/working/apache-git-source-source/metastore/target/hive-metastore-2.0.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/2.0.0-SNAPSHOT/hive-metastore-2.0.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-git-source-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/2.0.0-SNAPSHOT/hive-metastore-2.0.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-git-source-source/metastore/target/hive-metastore-2.0.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/2.0.0-SNAPSHOT/hive-metastore-2.0.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Ant Utilities 2.0.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---\n[INFO] Deleting /data/hive-ptest/working/apache-git-source-source/ant/target\n[INFO] Deleting /data/hive-ptest/working/apache-git-source-source/ant (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-ant ---\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-ant ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-ant ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-git-source-source/ant/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---\n[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-git-source-source/ant/target/classes\n[WARNING] /data/hive-ptest/working/apache-git-source-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java: /data/hive-ptest/working/apache-git-source-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-git-source-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-git-source-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java: /data/hive-ptest/working/apache-git-source-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-git-source-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-ant ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-git-source-source/ant/src/test/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-git-source-source/ant/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-git-source-source/ant/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-git-source-source/ant/target/tmp/conf\n     [copy] Copying 10 files to /data/hive-ptest/working/apache-git-source-source/ant/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---\n[INFO] Building jar: /data/hive-ptest/working/apache-git-source-source/ant/target/hive-ant-2.0.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-ant ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---\n[INFO] Installing /data/hive-ptest/working/apache-git-source-source/ant/target/hive-ant-2.0.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/2.0.0-SNAPSHOT/hive-ant-2.0.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-git-source-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/2.0.0-SNAPSHOT/hive-ant-2.0.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Spark Remote Client 2.0.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-client ---\n[INFO] Deleting /data/hive-ptest/working/apache-git-source-source/spark-client (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ spark-client ---\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-client ---\nDownloading: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.799s]\n[INFO] Hive Shims Common ................................. SUCCESS [3.308s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [0.967s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [2.596s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [0.999s]\n[INFO] Hive Shims ........................................ SUCCESS [0.685s]\n[INFO] Hive Storage API .................................. SUCCESS [0.701s]\n[INFO] Hive Common ....................................... SUCCESS [3.834s]\n[INFO] Hive Serde ........................................ SUCCESS [5.555s]\n[INFO] Hive Metastore .................................... SUCCESS [13.834s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.611s]\n[INFO] Spark Remote Client ............................... FAILURE [6.050s]\n[INFO] Hive Query Language ............................... SKIPPED\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 42.885s\n[INFO] Finished at: Fri Sep 25 04:04:17 EDT 2015\n[INFO] Final Memory: 80M/798M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.5:process (default) on project spark-client: Error resolving project artifact: Could not transfer artifact org.apache.spark:spark-unsafe_2.10:pom:1.5.0 from/to spark-1.3 (https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/): Access denied to: https://s3-us-west-1.amazonaws.com/hive-spark/maven2/spark_2.10-1.3-rc1/org/apache/spark/spark-unsafe_2.10/1.5.0/spark-unsafe_2.10-1.5.0.pom, ReasonPhrase: Forbidden. for project org.apache.spark:spark-unsafe_2.10:jar:1.5.0 -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :spark-client\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12762349 - PreCommit-HIVE-SPARK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-09-25T07:50:57.156+0000","updated":"2015-09-25T07:50:57.156+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907810","id":"14907810","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Remove the repo since we no longer need snapshots.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T08:46:39.421+0000","updated":"2015-09-25T08:46:39.421+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14907896","id":"14907896","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12762354/HIVE-11473.2-spark.patch\n\n{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 7483 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_inner_join\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join2\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation\norg.apache.hive.hcatalog.streaming.TestStreaming.testTimeOutReaper\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/952/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/952/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-952/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 7 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12762354 - PreCommit-HIVE-SPARK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-09-25T10:20:10.362+0000","updated":"2015-09-25T10:20:10.362+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14908031","id":"14908031","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"{{parquet_join}} failed because hive and spark depend on different parquet versions (hive on 1.8.1 while spark on 1.7.0). To work around this, we can build spark with {{parquet-provided}} profile. I built such a spark package and passed the test locally.\n[~xuefuz] do you have any other suggestions?\n\nOther failures are not related.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T13:29:45.419+0000","updated":"2015-09-25T13:29:45.419+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14908352","id":"14908352","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks, Rui. Yes. we can build Spark w/o parquet.  I will do that and publish a new tarball.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-25T17:24:06.684+0000","updated":"2015-09-25T17:24:06.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14908491","id":"14908491","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lirui] I updated the tarball and reloaded your patch to another test run.\n\nLooking at your patch, I'm wondering if we should just let our ClientListener extend JavaSparkListener that's provided by Spark, instead of implementing the unimplemented methods?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-25T18:47:01.033+0000","updated":"2015-09-25T18:47:01.033+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14908616","id":"14908616","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12762435/HIVE-11473.2-spark.patch\n\n{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 7554 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_inner_join\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/953/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/953/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-953/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 5 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12762435 - PreCommit-HIVE-SPARK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-09-25T20:20:08.545+0000","updated":"2015-09-25T20:20:08.545+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14909994","id":"14909994","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xuefuz] the latest patch extends JavaSparkListener instead. Good idea.\n\nAs to the failure, the test still passes on my side. Do we need to do some cleanup to make sure the new tar is used?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-28T03:17:48.960+0000","updated":"2015-09-28T03:17:48.960+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14910031","id":"14910031","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12762632/HIVE-11473.3-spark.patch\n\n{color:red}ERROR:{color} -1 due to 856 failed/errored test(s), 7261 tests executed\n*Failed tests:*\n{noformat}\nTestCliDriver-groupby8_map.q-exim_14_managed_location_over_existing.q-insert_values_tmp_table.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestCliDriverMethods.testRun\norg.apache.hadoop.hive.cli.TestHBaseMinimrCliDriver.testCliDriver_hbase_bulk\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_auto_sortmerge_join_16\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket5\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucket6\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucketizedhiveinputformat\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucketmapjoin6\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucketmapjoin7\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_constprog_partitioner\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_disable_merge_for_bucketing\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_empty_dir_in_table\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_external_table_with_space_in_location_path\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_file_with_header_footer\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_import_exported_table\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap_auto\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_bucketed_table\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_map_operators\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_merge\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_num_buckets\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_input16_cc\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_leftsemijoin_mr\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_list_bucket_dml_10\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_load_fs2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_load_hdfs_file_with_space_in_the_name\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_parallel_orderby\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_ql_rewrite_gbtoidx\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_quotedid_smb\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_reduce_deduplicate\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_remote_script\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_root_dir_external_table\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_schemeAuthority\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_schemeAuthority2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_scriptfile1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_smb_mapjoin_8\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_stats_counter\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_stats_counter_partitioned\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_temp_table_external\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_truncate_column_buckets\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_uber_reduce\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_inner_join\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join0\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join1\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join2\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join3\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join4\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join5\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_groupby_reduce\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.initializationError\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_add_part_multiple\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_alter_merge_orc\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_alter_merge_stats_orc\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_annotate_stats_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join0\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join18_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join19\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join20\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join21\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join22\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join23\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join24\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join26\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join27\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join28\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join29\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join30\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join31\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join32\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_filters\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_nulls\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_reordering_values\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_stats\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_stats2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_without_localtask\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_smb_mapjoin_14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_avro_compression_enabled_native\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_avro_decimal_native\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_avro_joins\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_avro_joins_native\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_spark1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_spark2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_spark3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_spark4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketsortoptimize_insert_8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_gby\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_gby_empty\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_limit\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_semijoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_simple_select\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_stats\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_subq_in\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_subq_not_in\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_udf_udaf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_union\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_column_access_stats\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_count\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_create_merge_compressed\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cross_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cross_product_check_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cross_product_check_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ctas\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_date_join1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_date_udf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_decimal_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_disable_merge_for_bucketing\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_dynamic_rdd_cache\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_enforce_order\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_escape_clusterby1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_escape_distributeby1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_escape_orderby1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_escape_sortby1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_filter_join_breaktask\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_filter_join_breaktask2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby1_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby1_map_nomap\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby1_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby1_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby2_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby2_map_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby2_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby2_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby2_noskew_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby3_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby3_map_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby3_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby3_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby3_noskew_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby4_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby4_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby4_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby5_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby5_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby5_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby6_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby6_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby6_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_map_multi_single_reducer\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_noskew_multi_single_reducer\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8_map\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8_map_skew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby8_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_bigdata\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types_multi_single_reducer\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_cube1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_grouping_id2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_map_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_map_ppr_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_insert_common_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_single_reducer\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_single_reducer2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_single_reducer3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_position\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_ppr_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_resolution\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_rollup1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_sort_1_23\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_sort_skew_1_23\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_having\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_identity_project_remove_skip\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_index_auto_self_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_innerjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input1_limit\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input_part2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_insert1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_insert_into1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_insert_into2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_insert_into3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join0\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join18_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join19\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join20\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join21\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join22\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join23\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join24\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join25\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join26\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join27\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join28\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join29\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join30\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join31\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32_lessSize\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join33\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join34\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join35\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join36\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join37\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join38\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join39\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join40\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join41\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_1to1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_alt_syntax\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_array\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_casesensitive\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_empty\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_filters_overlap\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_hive_626\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_literals\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_map_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_merge_multi_expressions\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_merging\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_nullsafe\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_rc\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_star\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_thrift\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_vc\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_view\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_lateral_view_explode2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_leftsemijoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_leftsemijoin_mr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_limit_partition_metadataonly\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_limit_pushdown\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_list_bucket_dml_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_louter_join_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_addjar\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_decimal\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_filter_on_outerjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_mapjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_memcheck\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_test_outer\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapreduce1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapreduce2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_merge1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_merge2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mergejoins\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mergejoins_mixed\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_metadata_only_queries\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_metadata_only_queries_with_filters\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_lateral_view\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_mixed\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_move_tasks_share_dependencies\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_join_union\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multigroupby_singlemr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_nullgroup\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_nullgroup2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_nullgroup4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_nullgroup4_multi_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_order\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_order2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_outer_join_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parallel\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parallel_join0\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parallel_join1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_pcr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_gby_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join_filter\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_multi_insert\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_transform\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_decimal\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_general_queries\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_matchpath\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_rcfile\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_register_tblfn\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_seqfile\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_streaming\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_rcfile_bigdata\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_reduce_deduplicate_exclude_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_router_join_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_runtime_skewjoin_mapjoin_spark\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_script_env_var1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_script_env_var2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_script_pipe\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_scriptfile1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_semijoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin_noskew\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin_union_remove_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin_union_remove_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt19\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt20\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_19\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_20\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_21\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_22\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_25\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats0\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats20\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_counter\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_counter_partitioned\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_noscan_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_noscan_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_only_null\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_partscan_1_23\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_statsfs\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_exists\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_in\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_multiinsert\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_table_access_keys_stats\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_temp_table\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_temp_table_gb1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_temp_table_join1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_tez_join_tests\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_tez_joins_explain\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_timestamp_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_timestamp_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_timestamp_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_timestamp_comparison\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_timestamp_lazy\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_timestamp_null\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_timestamp_udf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_transform1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_transform2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_transform_ppr1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_transform_ppr2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_udaf_collect_set\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_udf_example_add\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_udf_in_file\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_udf_max\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_udf_min\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_udf_percentile\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union19\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union20\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union21\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union22\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union23\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union24\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union25\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union26\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union27\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union28\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union29\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union30\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union31\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union32\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union33\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union34\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_date\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_date_trim\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_lateralview\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_null\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_ppr\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_19\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_20\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_21\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_22\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_23\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_24\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_25\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_6_subq\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_script\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_top_level\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_view\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_uniquejoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_varchar_join1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_between_in\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_char_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_count_distinct\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_data_types\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_aggregate\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_mapjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_distinct_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_elt\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_groupby_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_left_outer_join\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_mapjoin_reduce\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_orderby_5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_string_concat\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_varchar_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_0\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_13\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_14\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_15\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_16\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_17\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_6\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_decimal_date\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_div0\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_nested_udf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_not\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_part\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_part_project\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_pushdown\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_short_regress\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_case\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_mapjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_math_funcs\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_nested_mapjoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_ptf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_rcfile_columnar\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_shufflejoin\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_string_funcs\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_timestamp_funcs\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_windowing\norg.apache.hadoop.hive.metastore.TestAdminUser.testCreateAdminNAddUser\norg.apache.hadoop.hive.metastore.TestMetastoreExpr.testPartitionExpr\norg.apache.hadoop.hive.ql.TestTxnCommands.exchangePartition\norg.apache.hadoop.hive.ql.TestTxnCommands.testDelete\norg.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn\norg.apache.hadoop.hive.ql.TestTxnCommands.testErrors\norg.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback\norg.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback\norg.apache.hadoop.hive.ql.TestTxnCommands.testInsertOverwrite\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts\norg.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert\norg.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert\norg.apache.hadoop.hive.ql.TestTxnCommands.testTimeOutReaper\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts\norg.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn\norg.apache.hadoop.hive.ql.TestTxnCommands2.testInsertOverwriteWithSelfJoin\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD\norg.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase\norg.apache.hadoop.hive.ql.exec.TestExecDriver.initializationError\norg.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testImplicitConversion\norg.apache.hadoop.hive.ql.exec.TestOperators.testFetchOperatorContext\norg.apache.hadoop.hive.ql.exec.TestOperators.testScriptOperator\norg.apache.hadoop.hive.ql.exec.TestUtilities.testgetDbTableName\norg.apache.hadoop.hive.ql.exec.tez.TestTezTask.testGetExtraLocalResources\norg.apache.hadoop.hive.ql.hooks.TestHooks.org.apache.hadoop.hive.ql.hooks.TestHooks\norg.apache.hadoop.hive.ql.io.TestSymlinkTextInputFormat.testCombine\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.concurrencyFalse\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLExclusive\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLNoLock\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLShared\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDelete\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testExceptions\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testJoin\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testReadWrite\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testRollback\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadMultiPartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadPartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleWritePartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleWriteTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testUpdate\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testWriteDynamicPartition\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.basicBlocking\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.createTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.insertOverwriteCreate\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.insertOverwritePartitionedCreate\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.lockConflictDbTable\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.updateSelectUpdate\norg.apache.hadoop.hive.ql.lockmgr.TestDummyTxnManager.testDedupLockObjects\norg.apache.hadoop.hive.ql.metadata.TestHive.testAutoPurgeTablesAndPartitions\norg.apache.hadoop.hive.ql.metadata.TestHive.testDropPartitionsWithPurge\norg.apache.hadoop.hive.ql.metadata.TestHive.testDropTableTrash\norg.apache.hadoop.hive.ql.metadata.TestHive.testGetAndDropTables\norg.apache.hadoop.hive.ql.metadata.TestHive.testHiveCloseCurrent\norg.apache.hadoop.hive.ql.metadata.TestHive.testHiveRefreshOnConfChange\norg.apache.hadoop.hive.ql.metadata.TestHive.testIndex\norg.apache.hadoop.hive.ql.metadata.TestHive.testMetaStoreApiTiming\norg.apache.hadoop.hive.ql.metadata.TestHive.testPartition\norg.apache.hadoop.hive.ql.metadata.TestHive.testTable\norg.apache.hadoop.hive.ql.metadata.TestHive.testThriftTable\norg.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testDataDeletion\norg.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testPartitionsCheck\norg.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testTableCheck\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testAutoPurgeTablesAndPartitions\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testDropPartitionsWithPurge\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testDropTableTrash\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testGetAndDropTables\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testHiveCloseCurrent\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testHiveRefreshOnConfChange\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testIndex\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testMetaStoreApiTiming\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testPartition\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testTable\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testThriftTable\norg.apache.hadoop.hive.ql.parse.TestColumnAccess.org.apache.hadoop.hive.ql.parse.TestColumnAccess\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType1\norg.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType2\norg.apache.hadoop.hive.ql.parse.TestIUD.org.apache.hadoop.hive.ql.parse.TestIUD\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacro\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroDoesNotExist\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroExistsDoNotIgnoreErrors\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistent\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistentWithIfExists\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistentWithIfExistsDoNotIgnoreNonExistent\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testOneInputParamters\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testThreeInputParamters\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testTwoInputParamters\norg.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testZeroInputParamters\norg.apache.hadoop.hive.ql.parse.TestQBCompact.org.apache.hadoop.hive.ql.parse.TestQBCompact\norg.apache.hadoop.hive.ql.parse.TestQBJoinTreeApplyPredicate.org.apache.hadoop.hive.ql.parse.TestQBJoinTreeApplyPredicate\norg.apache.hadoop.hive.ql.parse.TestQBSubQuery.org.apache.hadoop.hive.ql.parse.TestQBSubQuery\norg.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsNegative.org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsNegative\norg.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsPositive.org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsPositive\norg.apache.hadoop.hive.ql.parse.TestSemanticAnalyzerFactory.testDrop\norg.apache.hadoop.hive.ql.parse.TestUnpermittedCharsInColumnNameCreateTableNegative.org.apache.hadoop.hive.ql.parse.TestUnpermittedCharsInColumnNameCreateTableNegative\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllNonPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllWherePartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteOnePartition\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteOnePartitionWhere\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteWhereNoPartition\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertSelect\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertValues\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertValuesPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllNonPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllNonPartitionedWhere\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllPartitioned\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllPartitionedWhere\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateOnePartition\norg.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateOnePartitionWhere\norg.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleGroup\norg.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV1.testPrivInGrantNotAccepted\norg.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV2.testPrivInGrant\norg.apache.hadoop.hive.ql.parse.positive.TestTransactionStatement.org.apache.hadoop.hive.ql.parse.positive.TestTransactionStatement\norg.apache.hadoop.hive.ql.plan.TestReadEntityDirect.org.apache.hadoop.hive.ql.plan.TestReadEntityDirect\norg.apache.hadoop.hive.ql.plan.TestViewEntity.org.apache.hadoop.hive.ql.plan.TestViewEntity\norg.apache.hadoop.hive.ql.processors.TestCommandProcessorFactory.testAvailableCommands\norg.apache.hadoop.hive.ql.session.TestAddResource.testUnion\norg.apache.hadoop.hive.ql.session.TestSessionState.testClose[0]\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.blockedByLockPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.blockedByLockTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorPartitionCompactionNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMinorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMinorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.notBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner.partitionNotBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.blockedByLockPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.blockedByLockTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorPartitionCompactionNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMinorPartitionCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMinorTableCompaction\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.notBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.partitionNotBlockedBySubsequentLock\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.chooseMajorOverMinorWhenBothValid\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.cleanEmptyAbortedTxns\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactPartitionHighDeltaPct\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactPartitionTooManyDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactTableHighDeltaPct\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactTableTooManyDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.dropPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.dropTable\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.enoughDeltasNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.majorCompactOnPartitionTooManyAborts\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.majorCompactOnTableTooManyAborts\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactOnManyDifferentPartitionAborts\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableDeltaPctNotHighEnough\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableDynamicPartitioning\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableNotEnoughDeltas\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenCompactAlreadyScheduled\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenNoCompactSet\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenNoCompactSetLowerCase\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.recoverFailedLocalWorkers\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.recoverFailedRemoteWorkers\norg.apache.hadoop.hive.ql.txn.compactor.TestInitiator.twoTxnsOnSamePartitionGenerateOneCompactionRequest\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.sortedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.sortedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.droppedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.droppedTable\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorPartitionWithBaseMissingBuckets\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorPartitionWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableLegacy\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableNoBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableWithBase\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorWithAborted\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorWithOpenInMiddle\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.sortedPartition\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker2.sortedTable\norg.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateNonStringPartition\norg.apache.hive.hcatalog.cli.TestSemanticAnalysis.testUsNonExistentDB\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigFilterProjection\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigHBaseSchema\norg.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testSparkQuery\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testTempTable\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/954/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/954/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-954/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 856 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12762632 - PreCommit-HIVE-SPARK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2015-09-28T04:45:24.920+0000","updated":"2015-09-28T04:45:24.920+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14934467","id":"14934467","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Try again","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-29T01:38:01.103+0000","updated":"2015-09-29T01:38:01.103+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14940637","id":"14940637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~xuefuz], the latest test result is [here|http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/view/All/job/PreCommit-HIVE-SPARK-Build/lastBuild/].\n{{parquet_join}} still fails. But it passes on my machine (using your updated tarball). Do we need to do some cleanup for the pre-commit test? Or would you mind try that test on your side? Thanks.\n\nI also noticed snapshots of hive jars are uploaded [here|http://repository.apache.org/snapshots/org/apache/hive/]. We need to make sure to run {{mvn clean install -DskipTests -Phadoop-2}} under hive-home before the test, so that the test won't pick up a snapshot from external repo.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-10-02T00:30:19.525+0000","updated":"2015-10-02T00:30:19.525+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14944018","id":"14944018","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~lirui], precommit-test has been suffering some env related issues and we are looking into it. I will take a look at the parquet test problem. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-10-05T20:56:49.472+0000","updated":"2015-10-05T20:56:49.472+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14968406","id":"14968406","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi Xuefu, any progress on this one?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-10-22T02:42:12.625+0000","updated":"2015-10-22T02:42:12.625+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14968430","id":"14968430","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Unfortunately no. However, I think we can commit the patch as it is. It's just that we need to verify locally the test failures.\n\n[~spena], have you made any progress in recreating precommit instance for Spark branch? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-10-22T03:06:52.887+0000","updated":"2015-10-22T03:06:52.887+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14968443","id":"14968443","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Would you mind verify the failure {{parquet_join}} locally? It passes on my side. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-10-22T03:27:28.881+0000","updated":"2015-10-22T03:27:28.881+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14968452","id":"14968452","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, it passed on my side.\n\nPlease also feel free to work on master directly for any Spark related JIRAs, as the job queue isn't long these days.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-10-22T03:35:51.606+0000","updated":"2015-10-22T03:35:51.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14968464","id":"14968464","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks Xuefu. I'll commit this shortly.\n\nShall we get rid of the spark branch and work on master afterwards? It'll be tedious to switch branches as they're not synchronized.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-10-22T03:48:17.053+0000","updated":"2015-10-22T03:48:17.053+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14968493","id":"14968493","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, I think that's a viable way. However, currently the two branches are out of synch, so we have to wait until all patches from Spark branch are committed to master. For that, we need to have the branch test work first.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-10-22T04:06:05.834+0000","updated":"2015-10-22T04:06:05.834+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12852388/comment/14968626","id":"14968626","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Committed to spark branch and updated the getting started wiki.\nThanks Xuefu for the review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-10-22T06:18:23.338+0000","updated":"2015-10-22T06:18:23.338+0000"}],"maxResults":32,"total":32,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11473/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2idzz:"}}