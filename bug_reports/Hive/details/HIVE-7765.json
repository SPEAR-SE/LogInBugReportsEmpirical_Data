{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12734769","self":"https://issues.apache.org/jira/rest/api/2/issue/12734769","key":"HIVE-7765","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-06-29T14:31:25.458+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 10 08:53:26 UTC 2016","customfield_12310420":"412709","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7765/watchers","watchCount":7,"isWatching":false},"created":"2014-08-18T14:23:41.989+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326450","id":"12326450","description":"released","name":"0.14.0","archived":false,"released":true,"releaseDate":"2014-11-12"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12326829","id":"12326829","description":"0.13 maintenance release 1","name":"0.13.1","archived":false,"released":true,"releaseDate":"2014-06-06"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-10T08:53:26.139+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"When executing a UNION ALL query in Tez over partitioned tables where at least one table is empty, Hive fails to execute the query, returning the message \"FAILED: NullPointerException null\".  No stack trace accompanies this message.  Removing partitioning solves this problem, as does switching to MapReduce as the execution engine.\n\nThis can be reproduced using a variant of the example tables from the \"Getting Started\" documentation on the Hive wiki.  To create the schema, use\n\nCREATE TABLE invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);\nCREATE TABLE empty_invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);\n\nThen, load invites with data (e.g., using the instructions [here|https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-DMLOperations]) and execute the following:\n\nSELECT * FROM invites\nUNION ALL\nSELECT * FROM empty_invites;","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"412695","customfield_12312823":null,"summary":"Null pointer error with UNION ALL on partitioned tables using Tez","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cdragga","name":"cdragga","key":"cdragga","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Dragga","active":true,"timeZone":"America/Havana"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cdragga","name":"cdragga","key":"cdragga","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Dragga","active":true,"timeZone":"America/Havana"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Tez 0.4.1, Ubuntu 12.04, Hadoop 2.4.1;\nHadoop 2.2.6, Tez 0.5.2, Hive 0.14.0, CentOS 6.6","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12734769/comment/14605693","id":"14605693","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bush0a","name":"bush0a","key":"bush0a","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alex Bush","active":true,"timeZone":"Etc/UTC"},"body":"Stack trace from error:\nSELECT * FROM test5_a\nUNION ALL\nSELECT * FROM test5_b\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO parse.ParseDriver: Parsing command:\n\nSELECT * FROM test5_a\nUNION ALL\nSELECT * FROM test5_b\n15/06/29 15:11:35 [main]: INFO parse.ParseDriver: Parse Completed\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=parse start=1435587095311 end=1435587095313 duration=2 from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Starting Semantic Analysis\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Completed phase 1 of Semantic Analysis\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for source tables\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for subqueries\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for source tables\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for subqueries\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for destination tables\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for source tables\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for subqueries\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for destination tables\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Get metadata for destination tables\n15/06/29 15:11:35 [main]: INFO ql.Context: New scratch dir is hdfs://upgtst226/tmp/hive/hdp_batch/57614a3b-aa9a-4bf8-82ca-4451f72b9d28/hive_2015-06-29_15-11-35_310_293431230946478382-1\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Completed getting MetaData in Semantic Analysis\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Not invoking CBO because the statement has too few joins\n15/06/29 15:11:35 [main]: INFO parse.SemanticAnalyzer: Set stats collection dir : hdfs://upgtst226/tmp/hive/hdp_batch/57614a3b-aa9a-4bf8-82ca-4451f72b9d28/hive_2015-06-29_15-11-35_310_293431230946478382-1/-ext-10002\n15/06/29 15:11:35 [main]: INFO ppd.OpProcFactory: Processing for FS(6)\n15/06/29 15:11:35 [main]: INFO ppd.OpProcFactory: Processing for SEL(5)\n15/06/29 15:11:35 [main]: INFO ppd.OpProcFactory: Processing for UNION(4)\n15/06/29 15:11:35 [main]: INFO ppd.OpProcFactory: Processing for SEL(1)\n15/06/29 15:11:35 [main]: INFO ppd.OpProcFactory: Processing for TS(0)\n15/06/29 15:11:35 [main]: INFO ppd.OpProcFactory: Processing for SEL(3)\n15/06/29 15:11:35 [main]: INFO ppd.OpProcFactory: Processing for TS(2)\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=partition-retrieving start=1435587095494 end=1435587095606 duration=112 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=partition-retrieving start=1435587095606 end=1435587095735 duration=129 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>\n15/06/29 15:11:35 [main]: INFO parse.TezCompiler: Cycle free: true\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO exec.Utilities: Serializing ArrayList via kryo\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=serializePlan start=1435587095740 end=1435587095743 duration=3 from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO exec.Utilities: Deserializing ArrayList via kryo\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=deserializePlan start=1435587095743 end=1435587095746 duration=3 from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO exec.Utilities: Serializing ArrayList via kryo\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=serializePlan start=1435587095747 end=1435587095747 duration=0 from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO exec.Utilities: Deserializing ArrayList via kryo\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=deserializePlan start=1435587095747 end=1435587095747 duration=0 from=org.apache.hadoop.hive.ql.exec.Utilities>\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Found 0 null table scans\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Found 0 null table scans\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Found 0 null table scans\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Found 0 null table scans\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Found 0 null table scans\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable\n15/06/29 15:11:35 [main]: INFO physical.NullScanTaskDispatcher: Found 0 null table scans\n15/06/29 15:11:35 [main]: INFO physical.Vectorizer: Validating MapWork...\nFAILED: NullPointerException null\n15/06/29 15:11:35 [main]: ERROR ql.Driver: FAILED: NullPointerException null\njava.lang.NullPointerException\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:128)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:109)\n        at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$VectorizationDispatcher.validateMapWork(Vectorizer.java:357)\n        at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$VectorizationDispatcher.convertMapWork(Vectorizer.java:321)\n        at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$VectorizationDispatcher.dispatch(Vectorizer.java:307)\n        at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.dispatch(TaskGraphWalker.java:111)\n        at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.walk(TaskGraphWalker.java:194)\n        at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.startWalking(TaskGraphWalker.java:139)\n        at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.resolve(Vectorizer.java:847)\n        at org.apache.hadoop.hive.ql.parse.TezCompiler.optimizeTaskPlan(TezCompiler.java:468)\n        at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:223)\n        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10170)\n        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:417)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:305)\n        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1069)\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1131)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1006)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:996)\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:247)\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:199)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:410)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:345)\n        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:733)\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:677)\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:616)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=compile start=1435587095308 end=1435587095766 duration=458 from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>\n15/06/29 15:11:35 [main]: INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1435587095766 end=1435587095766 duration=0 from=org.apache.hadoop.hive.ql.Driver>\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bush0a","name":"bush0a","key":"bush0a","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alex Bush","active":true,"timeZone":"Etc/UTC"},"created":"2015-06-29T14:31:25.458+0000","updated":"2015-06-29T14:31:25.458+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12734769/comment/14605700","id":"14605700","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bush0a","name":"bush0a","key":"bush0a","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alex Bush","active":true,"timeZone":"Etc/UTC"},"body":"Workaround is to create an empty partition by creating the directory in HDFS and doing an MSCK repair table.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bush0a","name":"bush0a","key":"bush0a","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alex Bush","active":true,"timeZone":"Etc/UTC"},"created":"2015-06-29T14:35:48.529+0000","updated":"2015-06-29T14:35:48.529+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12734769/comment/14605728","id":"14605728","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bush0a","name":"bush0a","key":"bush0a","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alex Bush","active":true,"timeZone":"Etc/UTC"},"body":"Here is how to recreate this bug and use the workaround:\n#!/bin/bash\n\necho \"col1,col2\" > /tmp/unionall_txt\n\nHIVECONF=\"--hiveconf hive.root.logger=INFO,console --hiveconf hive.cli.errors.ignore=true\"\n\nhive -v $HIVECONF -e \"\ndrop database if exists unionall_test cascade;\n\ncreate database unionall_test;\n\nuse unionall_test;\n\nCREATE TABLE test_a (f1 STRING, f2 STRING) PARTITIONED BY (ds STRING);\nCREATE TABLE test_b (f1 STRING, f2 STRING) PARTITIONED BY (ds STRING);\n\nLOAD DATA LOCAL INPATH '/tmp/unionall_txt' OVERWRITE INTO TABLE test_a PARTITION ( ds='a' );\n\nSELECT * FROM test_a\nUNION ALL\nSELECT * FROM test_b;\n\nalter table test_b add partition ( ds='b' );\n\nSELECT * FROM test_a\nUNION ALL\nSELECT * FROM test_b;\n\"","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bush0a","name":"bush0a","key":"bush0a","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alex Bush","active":true,"timeZone":"Etc/UTC"},"created":"2015-06-29T14:57:53.289+0000","updated":"2015-06-29T14:57:53.289+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12734769/comment/14611324","id":"14611324","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"Looks like this was fixed somewhere in the 1.x branch.\n\nIn the old build, it removes the entire TableScan for some reason. So mostly you need a more recent build & test again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-07-02T01:59:24.155+0000","updated":"2015-07-02T01:59:24.155+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12734769/comment/15414941","id":"15414941","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashu_bhumca","name":"ashu_bhumca","key":"ashu_bhumca","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Kumar","active":true,"timeZone":"Asia/Kolkata"},"body":"What's the fix version for this issue?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashu_bhumca","name":"ashu_bhumca","key":"ashu_bhumca","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Kumar","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-08-10T08:53:26.139+0000","updated":"2016-08-10T08:53:26.139+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7765/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1yzxj:"}}