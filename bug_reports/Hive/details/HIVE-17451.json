{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13099722","self":"https://issues.apache.org/jira/rest/api/2/issue/13099722","key":"HIVE-17451","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-09-17T22:00:29.149+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Sep 22 13:58:19 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-17451/watchers","watchCount":4,"isWatching":false},"created":"2017-09-05T06:03:55.364+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329363","id":"12329363","name":"1.1.0","archived":false,"released":true,"releaseDate":"2015-03-07"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gatripat","name":"gatripat","key":"gatripat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432"},"displayName":"Ganesh Tripathi","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-09-22T13:58:19.035+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12325007","id":"12325007","name":"Hive"}],"timeoriginalestimate":null,"description":"Hi,\n\nWhen we export decimal data from a hive managed table to a hive avro external table (as bytes with decimal logicalType) the value from avro file cannot be read with any other tools (ex: avro-tools, spark, datastage..)\n\n_+Scenario:+_\n\n*create hive managed table an insert a decimal record:*\n\n{code:java}\ncreate table test_decimal (col1 decimal(20,2));\ninsert into table test_decimal values (3.12);\n{code}\n\n\n*create avro schema /tmp/test_decimal.avsc with below content:*\n\n{code:java}\n{\n  \"type\" : \"record\",\n  \"name\" : \"decimal_test_avro\",\n  \"fields\" : [ {\n    \"name\" : \"col1\",\n    \"type\" : [ \"null\", {\n      \"type\" : \"bytes\",\n      \"logicalType\" : \"decimal\",\n      \"precision\" : 20,\n      \"scale\" : 2\n    } ],\n    \"default\" : null,\n    \"columnName\" : \"col1\",\n    \"sqlType\" : \"2\"\n  }],\n  \"tableName\" : \"decimal_test_avro\"\n}\n{code}\n\n\n*create an hive external table stored as avro:*\n\n{code:java}\ncreate external table test_decimal_avro\nSTORED AS AVRO\nLOCATION '/tmp/test_decimal'\nTBLPROPERTIES (\n  'avro.schema.url'='/tmp/test_decimal.avsc',\n  'orc.compress'='SNAPPY');\n{code}\n\n\n*insert data in avro external table from hive managed table:*\n\n{code:java}\nset hive.exec.compress.output=true;\nset hive.exec.compress.intermediate=true;\nset avro.output.codec=snappy; \ninsert overwrite table test_decimal_avro select * from test_decimal;\n{code}\n\n\n*successfully reading data from hive avro table through hive cli:*\n\n{code:java}\nselect * from test_decimal_avro;\nOK\n3.12\n{code}\n\n\n*avro schema from avro created file is ok:*\n\n{code:java}\nhadoop jar /avro-tools.jar getschema /tmp/test_decimal/000000_0\n{\n  \"type\" : \"record\",\n  \"name\" : \"decimal_test_avro\",\n  \"fields\" : [ {\n    \"name\" : \"col1\",\n    \"type\" : [ \"null\", {\n      \"type\" : \"bytes\",\n      \"logicalType\" : \"decimal\",\n      \"precision\" : 20,\n      \"scale\" : 2\n    } ],\n    \"default\" : null,\n    \"columnName\" : \"col1\",\n    \"sqlType\" : \"2\"\n  } ],\n  \"tableName\" : \"decimal_test_avro\"\n}\n{code}\n\n\n*read data from avro file with avro-tools {color:#d04437}error{color}, got {color:#d04437}\"\\u00018\"{color} value instead of the correct one:*\n\n{code:java}\nhadoop jar avro-tools.jar tojson /tmp/test_decimal/000000_0\n{\"col1\":{\"bytes\":\"\\u00018\"}}\n{code}\n\n\n*Read data in a spark dataframe error, got {color:#d04437}[01 38]{color} and{color:#d04437} 8{color} when converted to string instead of correct \"3.12\" value :*\n\n{code:java}\n\nval df = sql.read.avro(\"/tmp/test_decimal\")\ndf: org.apache.spark.sql.DataFrame = [col1: binary]\n\nscala> df.show()\n+-------+\n|   col1|\n+-------+\n|[01 38]|\n+-------+\n\n\nscala> df.withColumn(\"col2\", 'col1.cast(\"String\")).select(\"col2\").show()\n+----+\n|col2|\n+----+\n|  8|\n+----+\n\n{code}\n\n\nIs this a Hive bug or there is anything else I can do in order to get correct values in the avro file created by Hive?\n\nThanks,","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Cannot read decimal from avro file created with HIVE","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliviu","name":"eliviu","key":"eliviu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liviu","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliviu","name":"eliviu","key":"eliviu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liviu","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13099722/comment/16169433","id":"16169433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"Hexidecimal 0x138 = Decimal 312 (unscaled)\nand, hexidecimal bytes 01 and 38 are a non-visible control character \\001 and ASCII \"8\"","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2017-09-17T22:00:29.149+0000","updated":"2017-09-17T23:38:05.063+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13099722/comment/16169472","id":"16169472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"I believe Avro stores the decimal as the serialization of a Java BigInteger.  That is, we call BigInteger's toByteArray function that returns a byte array with two's compliment reprentation.  Why do we use BigInteger?  Because decimal's max precion of 38 digits cannot be stored in a Java 64 bit signed long.  128 bits are needed.  I believe Spark represents decimal with precision > 18 as Java BigDecimal.  BigDecimal.unscaledValue() returns a BigInteger.\n\nSo logicalType decimal and stored as bytes makes sense.\n\nDoes specifying [col1:decimal(20,2)] in the data frame detail not work?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2017-09-17T23:57:08.181+0000","updated":"2017-09-17T23:57:08.181+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13099722/comment/16169474","id":"16169474","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"Seems like avro-tools.jar tojson isn't converting the binary (physical type) to decimal (logical type).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2017-09-18T00:03:42.833+0000","updated":"2017-09-18T00:03:42.833+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13099722/comment/16173140","id":"16173140","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gatripat","name":"gatripat","key":"gatripat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432"},"displayName":"Ganesh Tripathi","active":true,"timeZone":"Etc/UTC"},"body":"even in toText option : binary is displayed.\n\n while (fileReader.hasNext()) {\n          ByteBuffer outBuff = (ByteBuffer) fileReader.next();\n          outStream.write(outBuff.array());\n         outStream.write(LINE_SEPARATOR); \n    }\n     fileReader.close();","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gatripat","name":"gatripat","key":"gatripat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432"},"displayName":"Ganesh Tripathi","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-20T13:06:10.333+0000","updated":"2017-09-20T13:06:25.122+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13099722/comment/16176460","id":"16176460","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliviu","name":"eliviu","key":"eliviu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liviu","active":true,"timeZone":"Etc/UTC"},"body":"bq. Does specifying [col1:decimal(20,2)] in the data frame detail not work?\n\ncannot convert from Bytes to Decimal in DF:\n\nscala> df.withColumn(\"col2\", 'col1.cast(\"decimal(20,2)\")).select(\"col2\").show()\norg.apache.spark.sql.AnalysisException: cannot resolve 'cast(col1 as decimal(20,2))' due to data type mismatch: cannot cast BinaryType to DecimalType(20,2);\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliviu","name":"eliviu","key":"eliviu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liviu","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-22T13:58:19.035+0000","updated":"2017-09-22T13:58:19.035+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-17451/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3jmxb:"}}