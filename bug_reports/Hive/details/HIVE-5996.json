{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12683761","self":"https://issues.apache.org/jira/rest/api/2/issue/12683761","key":"HIVE-5996","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2013-12-10T19:07:30.664+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Dec 13 19:23:59 UTC 2013","customfield_12310420":"362833","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_209911117_*|*_1_*:*_2_*:*_91958765_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-12-13T15:37:21.771+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5996/watchers","watchCount":5,"isWatching":false},"created":"2013-12-10T03:46:11.922+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10342","value":"Incompatible change","id":"10342"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[{"id":"12379953","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12379953","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12680881","key":"HIVE-5878","self":"https://issues.apache.org/jira/rest/api/2/issue/12680881","fields":{"summary":"Hive standard avg UDAF returns double as the return type for some exact input types","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12379954","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12379954","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12670413","key":"HIVE-5356","self":"https://issues.apache.org/jira/rest/api/2/issue/12670413","fields":{"summary":"Move arithmatic UDFs to generic UDF implementations","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/3","id":"3","description":"A task that needs to be done.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype","name":"Task","subtask":false,"avatarId":21148}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-12-13T19:40:43.363+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12313585","id":"12313585","name":"UDF","description":"This includes the UDFs and UDAFs"}],"timeoriginalestimate":null,"description":"{code}\nhive> desc test2;\nOK\nl                   \tbigint              \tNone                \nhive> select * from test2;                                 \nOK\n6666666666666666666\n5555555555555555555\nhive> select sum(l) from test2;\nOK\n-6224521851487329395\n{code}\nIt's believed that a wrap-around error occurred. It's surprising that it happens only with two rows. Same query in MySQL returns:\n{code}\nmysql> select sum(l) from test;\n+----------------------+\n| sum(l)               |\n+----------------------+\n| 12222222222222222221 |\n+----------------------+\n1 row in set (0.00 sec)\n{code}\nHive should accommodate large number of rows. Overflowing with only two rows is very unusable.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12618065","id":"12618065","filename":"HIVE-5996.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-10T17:58:13.131+0000","size":824,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12618065/HIVE-5996.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"363139","customfield_12312823":null,"summary":"Query for sum of a long column of a table with only two rows produces wrong result","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13843972","id":"13843972","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"For information, the follow is the text from SQL-92[1] standard w.r.t SUM function:\n{quote}\n            b) If SUM is specified and DT is exact numeric with scale\n              S, then the data type of the result is exact numeric with\n              implementation-defined precision and scale S.\n{quote}\nFor DT as long, currently Hive returns long, which doesn't violate the standard. However, such implementation is problematic as demonstrated in this JIRA. Plus, for decimal, Hive sum function accommodates at least 10 billion rows of data. Letting sum(long) return long is not able to uphold that assurance. Thus, we need to change the return type to make the function more useful.\n\n[1] http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-10T05:34:21.570+0000","updated":"2013-12-10T05:34:21.570+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13844473","id":"13844473","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Initial patch to kick off test.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-10T17:58:13.136+0000","updated":"2013-12-10T17:58:13.136+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13844551","id":"13844551","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12618065/HIVE-5996.patch\n\n{color:red}ERROR:{color} -1 due to 36 failed/errored test(s), 4761 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join0\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join10\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join11\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join13\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join15\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join16\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join18\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join18_multi_distinct\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join20\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join22\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join24\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join30\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join31\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer4\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer6\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_count\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_cube1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_distinct_samekey\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_rollup1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_skew_1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_predicate_pushdown\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ql_rewrite_gbtoidx\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoin\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf3\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorization_12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorization_4\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorization_5\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorization_nested_udf\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorization_short_regress\n{noformat}\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/597/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/597/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 36 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12618065","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2013-12-10T19:07:30.664+0000","updated":"2013-12-10T19:07:30.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13845634","id":"13845634","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"body":"-1\n\nWe should not be changing the output data types of expression results that are arguably reasonable. It causes code churn and can break existing apps. \n\nHaving sum(bigint) return bigint is long standing behavior in Hive and is reasonable.\n\nAs a side note, SQL Server returns bigint for sum(bigint).\n\nIf users need more digits, they can cast the input to sum to a decimal.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-11T18:59:33.941+0000","updated":"2013-12-11T18:59:33.941+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13845650","id":"13845650","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"[~xuefuz] Can you please mark any jiras that make/propose such non backward compatible changes with the 'Incompatible change' flag ?\nThat would ensure that the community reviews such changes more carefully.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-11T19:19:00.072+0000","updated":"2013-12-11T19:19:00.072+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13845664","id":"13845664","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Okay. Will do.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-11T19:33:45.342+0000","updated":"2013-12-11T19:33:45.342+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13845760","id":"13845760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nHaving sum(bigint) return bigint is long standing behavior in Hive and is reasonable.\n\nAs a side note, SQL Server returns bigint for sum(bigint).\n\nIf users need more digits, they can cast the input to sum to a decimal.\n{quote}\n\nMy concern is not about the number of digits that long can hold. Hive processes large number of rows that traditional DBs are shy of, and the chance of getting overflow error is bigger. With the proposed change, Hive can guarantee 10b (or certain number of) rows without worry about this problem. Without it, Hive has such guaranty, and two valid rows can overflow, as demonstrated in this JIRA.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-11T22:00:56.148+0000","updated":"2013-12-11T22:00:56.148+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13846033","id":"13846033","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"I am curious what the datatype for \"sum(l)\" is in mysql, where l is a bigint. Is it also using decimal ?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-12T03:24:41.528+0000","updated":"2013-12-12T03:24:41.528+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13846067","id":"13846067","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"{code}\nmysql> create table test74 as select sum(l) from test;\nERROR 2006 (HY000): MySQL server has gone away\nNo connection. Trying to reconnect...\nConnection id:    44\nCurrent database: metastore\n\nQuery OK, 1 row affected (0.17 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> desc test74;\n+--------+---------------+------+-----+---------+-------+\n| Field  | Type          | Null | Key | Default | Extra |\n+--------+---------------+------+-----+---------+-------+\n| sum(l) | decimal(41,0) | YES  |     | NULL    |       |\n+--------+---------------+------+-----+---------+-------+\n1 row in set (0.00 sec)\n{code}\nIt seems that MySQL is using the 22 + p as the output precision, where p is the precision of the input. This is true for other types other than long also.\n{code}\nmysql> desc test1;\n+-------+---------+------+-----+---------+-------+\n| Field | Type    | Null | Key | Default | Extra |\n+-------+---------+------+-----+---------+-------+\n| i     | int(11) | YES  |     | NULL    |       |\n+-------+---------+------+-----+---------+-------+\nmysql> create table test75 as select sum(i) from test1;\nQuery OK, 1 row affected (0.19 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> desc test75;\n+--------+---------------+------+-----+---------+-------+\n| Field  | Type          | Null | Key | Default | Extra |\n+--------+---------------+------+-----+---------+-------+\n| sum(i) | decimal(32,0) | YES  |     | NULL    |       |\n+--------+---------------+------+-----+---------+-------+\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-12T04:52:06.345+0000","updated":"2013-12-12T04:52:06.345+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13846553","id":"13846553","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"body":"Xuefu,\n\nI'm all for new, useful functionality and better performance for Hive. And I'm all for getting correct results. I appreciate your contributions and your passion.\n\nBut I strongly believe changing behavior from one reasonable alternative to another in a way that breaks backward compatibility is not the way to go. I have a lot of experience with evolving a database (SQL Server) over a decade, and have talked to a many people who've been evolving the product longer than that. From this experience, I can say that changing backward compatibility (for either functionality or performance, but especially functionality) even in subtle ways can anger customers/users. \n\nAny changes to semantics like this should first of all be avoided, and if they can't be avoided, they need to be rolled out carefully, with a switch to enable backward compatibility. SQL Server has compatibility levels and \"SET options\" as switches, and a defined deprecation schedule. This is kind of process-heavy in the engineering effort, and also causes explosion of the test matrix. So I am not recommending necessarily that Hive go there, though maybe we need to have that discussion. I think we're better off being strict about not breaking backward compatibility unless really needed.\n\nSo, I ask that you please close this JIRA without making a patch.\n\nThere are a couple of other areas where there is an issue of ANSI SQL compatibility (result type of int/int and avg(int)). We could have a further discussion on those, though you know my preference would be to leave the semantics as-is on those since I think backward compatibility trumps ANSI SQL compatibility for those. If there is no issue of ANSI compatibility, and the current Hive behavior is reasonable, I'd like us to leave things as they are. I don't think there is a need to be across-the-board compatible with another system (MySQL or anything else).\n\nBest regards,\nEric\n\nP.S. Your specific argument that you can overflow a bigint sum, while technically accurate, I think is not a significant user issue. I've never heard a complaint about it with SQL Server, or PDW, our scale-out data warehouse appliance. Really big numbers, like the national debt in pennies, fit in a bigint, just to put it in perspective. Users can cast the input to decimal or double if they need more magnitude.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-12T18:25:11.490+0000","updated":"2013-12-12T18:25:11.490+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13846635","id":"13846635","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"body":"Xuefu,\n\nI see you want to make changes to have Hive be more in line with MySQL semantics. Can you explain why you're making these changes or considering them?\n\nThanks,\nEric","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-12T19:29:04.961+0000","updated":"2013-12-12T19:29:04.961+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13846705","id":"13846705","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~ehans] Thanks for sharing your thoughts and your inquiry. For your information, I'm not trying to make MySQL as the model. My first line of consideration is SQL standard. For a functionality if there is no SQL standard, Hive doesn't have to invent everything, thus, I do reference MySQL for ideas, mostly because MySQL and its technical documentation are readily available. However, this doesn't precludeme following other DB's practice. For instance, precision/scale determination for arithmetic operations in hive is following SQL server's formula. I'm not either anti- or pro- MySQL. Nor am I to SQL server, but I strongly believe that following well-established practices benefits Hive than doing something in a unique, unfortunate way. An example would be int/int in Hive.\n\nHowever, a  lot of existing functionality in Hive was put into place when Hive is positioned as a tool rather than DB, and before all necessary data types were introduced. Take int/int again as an example, early developer probably didn't even think about SQL-compliance, and even if he/she did, there wasn't decimal data type as a consideration. As Hive is shift to a DB on bigdata positioning, I believe that we should start thinking in a perspective other than performance or backward compatibility. If we restrict ourselves based on  unconscious decisions made in the past, we may lose a lot of opportunities of doing the right things.\n\nAs I worked on decimal precision/scale support, I found a lot of problems in Hive about data types and their conversions and promotions. In many cases, Hive is not consistent itself. Let me ask you a question to see if you know the answer: what's the return type of 35 + '3.14', where 35 is from int column and '3.14' from a string column? Before I made the changes, you probably would say: wait, let me read the code first. And your answer might be different if my question were 35/'3.14'. Now, to answer the same questions, I can give right way, and I have a theory to tell why. In summary, it's a lot of effort to clean up the mess and inconsistency in Hive from the beginning of my work on decimal.\n\nNow if we use either performance or backward compatibility to shut down what we have achieved, I don't see how Hive is shifting from a tool to a DB, and how Hive can become adopted as enterprise grade product.\n\nHive is still evolving, and that's why I think we have certain luxury of breaking backward compatibility for doing the right thing. As Ashutosh once mentioned, we don't want to be backward compatible to a bug. Once Hive is stabilized, it becomes much harder to make backward incompatible changes, as you know with your experience with SQL server.\n\nI understand your concern about backward compatibility, especially your possible frustration over vectorization breaking or redoing. On the other hand, I think we are here to help hive become more useful. A blunt rejection without much consideration and communication doesn't seem as helpful and constructive as it should be.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-12T20:30:41.898+0000","updated":"2013-12-12T20:30:41.898+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13846718","id":"13846718","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Now, to answer the same questions, I can give right way, and I have a theory to tell why.\nIt would be great if you can document the theory, otherwise I still would need to look at code to understand the theory !  :)\n\nI really appreciate the code cleanup you have been doing. But we have to be careful about backward compatibility. I also agree that we should not burden new users with historic problems.\nRegarding \"Once Hive is stabilized\", how do we define that ? Maybe, once we create a list of non backward compatible changes that are important to make, we can make a major release version (1.x) , we can break the backward compatibility of certain things, and document it very well. Hopefully, that list of non-backward compatible changes can be kept small.\n\nI discuss this in context of config defaults in HIVE-5875 .\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-12T20:44:47.143+0000","updated":"2013-12-12T20:44:47.143+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13846721","id":"13846721","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"Regarding the specific change in this jira, I am not convinced that is an important  non-backward compatible change to make. You can have an overflow even with decimal type, if they are large enough, with just two rows.\nOn the other hand, the int division returning double is arguably a change to consider for a 1.0 candidate, as that is a SQL compliance issue.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-12T20:47:24.808+0000","updated":"2013-12-12T20:47:24.808+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13847150","id":"13847150","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nIt would be great if you can document the theory, otherwise I still would need to look at code to understand the theory\n{quote}\n\nI will put it somewhere on the wiki.\n\n{quote}\nYou can have an overflow even with decimal type, if they are large enough, with just two rows.\n{quote}\n\nIt's impossible to overflow output decimal type with just two rows because the precision of the output decimal type is 10 + the precision of the input type. In case of long input, the output decimal type is (29,0).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-13T04:28:52.965+0000","updated":"2013-12-13T04:28:52.965+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13847381","id":"13847381","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry, I meant even if the input row type is decimal , two rows can overflow","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-13T10:48:34.597+0000","updated":"2013-12-13T10:48:34.597+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13847579","id":"13847579","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, in theory, but unlikely. Current precision formula, 10 + p as the output precision, gives some room. Of course, if the input precision is already at  maximum, then output type precision will the same as the input precision. In that case, for really big numbers, it can overflow. Anyway, I'm going to close the JIRA, so the discussion.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-13T15:37:09.706+0000","updated":"2013-12-13T15:37:09.706+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12683761/comment/13847809","id":"13847809","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Xuefu for closing this one. You make some good points above about Hive's evolution & ANSI compliance. I think we still have to come to a conclusion on the other issues regarding int/int and avg(int) output type. We can take that up on the other JIRA(s). I'll cross-link.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ehans","name":"ehans","key":"ehans","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ehans&avatarId=16468","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ehans&avatarId=16468","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ehans&avatarId=16468","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ehans&avatarId=16468"},"displayName":"Eric Hanson","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-13T19:23:59.864+0000","updated":"2013-12-13T19:23:59.864+0000"}],"maxResults":18,"total":18,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5996/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1qjlj:"}}