{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12972313","self":"https://issues.apache.org/jira/rest/api/2/issue/12972313","key":"HIVE-13830","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-10-24T10:01:04.109+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jan 17 06:06:23 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-13830/watchers","watchCount":6,"isWatching":false},"created":"2016-05-24T08:02:43.999+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334255","id":"12334255","name":"2.1.0","archived":false,"released":true,"releaseDate":"2016-06-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-01-17T06:06:23.008+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12324504","id":"12324504","name":"spark-branch"}],"timeoriginalestimate":null,"description":"With Hive 1.2.1 I was able to use Hive on  successfully with the use of the -assembly \"-assembly-1.4.1-hadoop2.7.1.jar\". \nToday with Hive 2.0.0, I'm unable to use Hive on  whether it be with the -assembly \"-assembly-1.4.1-hadoop2.7.1.jar\" or the -assembly \"-assembly-1.6.1-hadoop2.7.2.jar\".\n\nMy configuration is the following:\n  * -. available in HIVE_DIR/\n  *  assembly available in HIVE_DIR/lib\n\nI gathered several logs below:\n- HQL commands\n{noformat}\n$ hive -v --database shfs3453\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/opt/application/Hive/apache-hive-2.0.0-bin/lib/hive-jdbc-2.0.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/opt/application/Hive/apache-hive-2.0.0-bin/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/opt/application//-1.6.1/assembly/target/scala-2.10/-assembly-1.6.1-hadoop2.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/opt/application/Hadoop/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n\nLogging initialized using configuration in file:/opt/application/Hive/apache-hive-2.0.0-bin/conf/hive-log4j2.properties\nuse shfs3453\nOK\nTime taken: 1.425 seconds\nHive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, ) or using Hive 1.X releases.\nhive (shfs3453)> set hive.execution.engine=;\nset hive.execution.engine=\nhive (shfs3453)> set .master=yarn-client;\nset .master=yarn-client\nhive (shfs3453)> CREATE TABLE chicagoCrimes2 (ID BIGINT, CaseNumber STRING, Day STRING, Block STRING, IUCR INT, PrimaryType STRING, Description STRING, LocationDescription STRING, Arrest BOOLEAN, Domestic BOOLEAN, Beat INT, District INT, Ward INT, CommunityArea INT, FBICode INT, XCoordinate BIGINT, YCoordinate BIGINT, Year INT, UpdatedOn STRING, Latitude FLOAT, Longitude FLOAT, Location STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;\nCREATE TABLE chicagoCrimes2 (ID BIGINT, CaseNumber STRING, Day STRING, Block STRING, IUCR INT, PrimaryType STRING, Description STRING, LocationDescription STRING, Arrest BOOLEAN, Domestic BOOLEAN, Beat INT, District INT, Ward INT, CommunityArea INT, FBICode INT, XCoordinate BIGINT, YCoordinate BIGINT, Year INT, UpdatedOn STRING, Latitude FLOAT, Longitude FLOAT, Location STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE\nOK\nTime taken: 0.408 seconds\nhive (shfs3453)> INSERT OVERWRITE TABLE chicagocrimes2 SELECT * FROM chicagocrimes WHERE Description = 'FIRST DEGREE MURDER';\nINSERT OVERWRITE TABLE chicagocrimes2 SELECT * FROM chicagocrimes WHERE Description = 'FIRST DEGREE MURDER'\nQuery ID = shfs3453_20160524092714_41c89aec-2c6f-49e9-98c7-d227ca144f73\nTotal jobs = 1\nLaunching Job 1 out of 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nStarting  Job = 79484279-8e75-4b13-8e71-7de463f4d51e\nStatus: SENT\nFailed to execute  task, with exception 'java.lang.IllegalStateException(RPC channel is closed.)'\nFAILED: Execution , return code 1 from org.apache.hadoop.hive.ql.exec..SparkTask\n{noformat}\n\n- Client logs\n{noformat}\nMay 24 09:32:19 hive-cli  - org.apache.hive..client.rpc.RpcDispatcherReceived  message:io.netty.handler.codec.DecoderException: java.lang.NoClassDefFoundError: org/apache/hive//client/Job\n        at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:358)\n        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:230)\n        at io.netty.handler.codec.ByteToMessageCodec.channelRead(ByteToMessageCodec.java:103)\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)\n        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.NoClassDefFoundError: org/apache/hive//client/Job\n        at java.lang.ClassLoader.defineClass1(Native Method)\n        at java.lang.ClassLoader.defineClass(ClassLoader.java:800)\n        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n        at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)\n        at java.net.URLClassLoader.access$100(URLClassLoader.java:71)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:361)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)\n        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:412)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n        at java.lang.Class.forName0(Native Method)\n        at java.lang.Class.forName(Class.java:278)\n        at org.apache.hive.com.esotericsoftware.kryo.util.DefaultClassResolver.readName(DefaultClassResolver.java:154)\n        at org.apache.hive.com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:133)\n        at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:670)\n        at org.apache.hive.com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:118)\n        at org.apache.hive.com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)\n        at org.apache.hive.com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)\n        at org.apache.hive..client.rpc.KryoMessageCodec.decode(KryoMessageCodec.java:97)\n        at io.netty.handler.codec.ByteToMessageCodec$1.decode(ByteToMessageCodec.java:42)\n        at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:327)\n        ... 15 more\nCaused by: java.lang.ClassNotFoundException: org.apache.hive..client.Job\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)\n        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n        ... 39 more\n.\nMay 24 09:32:19 hive-cli  - org.apache.hive..client.SparkClientImplClient RPC channel closed unexpectedly.\nMay 24 09:32:48 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.status.SparkJobMonitorJob hasn't been submitted after 61s. Aborting it.\nMay 24 09:32:48 hive-cli  - org.apache.hadoop.hive.ql.exec..status.SparkJobMonitorStatus: SENT\nMay 24 09:32:48 hive-cli  - org.apache.hadoop.hive.ql.exec..SparkTaskFailed to execute spark task, with exception 'java.lang.IllegalStateException(RPC channel is closed.)'\njava.lang.IllegalStateException: RPC channel is closed.\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:149)\n        at org.apache.hive.spark.client.rpc.Rpc.call(Rpc.java:276)\n        at org.apache.hive.spark.client.rpc.Rpc.call(Rpc.java:259)\n        at org.apache.hive.spark.client.SparkClientImpl$ClientProtocol.cancel(SparkClientImpl.java:523)\n        at org.apache.hive.spark.client.SparkClientImpl.cancel(SparkClientImpl.java:187)\n        at org.apache.hive.spark.client.JobHandleImpl.cancel(JobHandleImpl.java:62)\n        at org.apache.hadoop.hive.ql.exec.spark.status.impl.RemoteSparkJobRef.cancelJob(RemoteSparkJobRef.java:54)\n        at org.apache.hadoop.hive.ql.exec.spark.SparkTask.execute(SparkTask.java:128)\n        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:158)\n        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:101)\n        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1840)\n        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1584)\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1361)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1184)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1172)\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:400)\n        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:778)\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:717)\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:645)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n\nMay 24 09:32:48 hive-cli  - org.apache.hadoop.hive.ql.exec..SparkTaskFailed to execute spark task, with exception 'java.lang.IllegalStateException(RPC channel is closed.)'\njava.lang.IllegalStateException: RPC channel is closed.\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:149) ~[guava-14.0.1.jar:?]\n        at org.apache.hive.spark.client.rpc.Rpc.call(Rpc.java:276) ~[hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hive.spark.client.rpc.Rpc.call(Rpc.java:259) ~[hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hive.spark.client.SparkClientImpl$ClientProtocol.cancel(SparkClientImpl.java:523) ~[hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hive.spark.client.SparkClientImpl.cancel(SparkClientImpl.java:187) ~[hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hive.spark.client.JobHandleImpl.cancel(JobHandleImpl.java:62) ~[hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.exec.spark.status.impl.RemoteSparkJobRef.cancelJob(RemoteSparkJobRef.java:54) ~[hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.exec.spark.SparkTask.execute(SparkTask.java:128) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:158) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:101) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1840) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1584) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1361) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1184) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1172) [hive-exec-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233) [hive-cli-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184) [hive-cli-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:400) [hive-cli-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:778) [hive-cli-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:717) [hive-cli-2.0.0.jar:2.0.0]\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:645) [hive-cli-2.0.0.jar:2.0.0]\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.7.0_85]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[?:1.7.0_85]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.7.0_85]\n        at java.lang.reflect.Method.invoke(Method.java:606) ~[?:1.7.0_85]\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221) [spark-assembly-1.6.1-hadoop2.7.2.jar:1.6.1]\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136) [spark-assembly-1.6.1-hadoop2.7.2.jar:1.6.1]\nMay 24 09:32:48 hive-cli  - org.apache.hadoop.hive.ql.DriverFAILED: Execution , return code 1 from org.apache.hadoop.hive.ql.exec..SparkTask\nMay 24 09:32:48 hive-cli INFO - org.apache.hadoop.hive.ql.DriverCompleted executing command(queryId=shfs3453_20160524092714_41c89aec-2c6f-49e9-98c7-d227ca144f73); Time taken: 65.543 seconds\n{noformat}\n\n- Yarn logs (executor)\n{noformat}\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/mnt/hd4/hadoop/yarn/local/usercache/shfs3453/filecache/18/spark-assembly-1.6.1-hadoop2.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/opt/application/Hadoop/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n16/05/24 09:32:14 INFO executor.CoarseGrainedExecutorBackend: Registered signal handlers for [TERM, HUP, INT]\n16/05/24 09:32:15 INFO spark.SecurityManager: Changing view acls to: shfs3453\n16/05/24 09:32:15 INFO spark.SecurityManager: Changing modify acls to: shfs3453\n16/05/24 09:32:15 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(shfs3453); users with modify permissions: Set(shfs3453)\n16/05/24 09:32:15 INFO spark.SecurityManager: Changing view acls to: shfs3453\n16/05/24 09:32:15 INFO spark.SecurityManager: Changing modify acls to: shfs3453\n16/05/24 09:32:15 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(shfs3453); users with modify permissions: Set(shfs3453)\n16/05/24 09:32:16 INFO slf4j.Slf4jLogger: Slf4jLogger started\n16/05/24 09:32:16 INFO Remoting: Starting remoting\n16/05/24 09:32:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@datanode05.bigdata.fr:37444]\n16/05/24 09:32:16 INFO util.Utils: Successfully started service 'sparkExecutorActorSystem' on port 37444.\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd8/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-8206d302-c8c7-4c79-974f-e349586c64f3\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd3/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-c3f44368-0b14-4bbf-b216-9fb332fd5174\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd2/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-008678f2-f592-4026-8342-9f03432539bc\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd1/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-44aad90f-755c-4294-b294-355b929b43e7\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd9/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-0862fb2d-aa29-48eb-abde-e4b8fa6943af\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd10/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-10811a27-1cb0-44cb-a842-db98638d67b5\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd4/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-b6f7eb6f-bb1e-4f18-80a8-d0e0de4c0c5e\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd5/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-c0949d83-1c03-457d-8c09-b61ae02c9567\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd6/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-c33365d4-9ff0-41a9-9684-19fbd3a8c8ec\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd0/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-94c7ebea-3df2-4004-911d-03e46f02909d\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd11/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-316bc7e1-1cb6-4a68-bf64-f4169d433e4e\n16/05/24 09:32:17 INFO storage.DiskBlockManager: Created local directory at /mnt/hd7/hadoop/yarn/local/usercache/shfs3453/appcache/application_1463151644662_0023/blockmgr-d4b6e343-2f03-4558-acc6-027b896491ee\n16/05/24 09:32:17 INFO storage.MemoryStore: MemoryStore started with capacity 2.7 GB\n16/05/24 09:32:17 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.200.208:55898\n16/05/24 09:32:17 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver\n16/05/24 09:32:17 INFO executor.Executor: Starting executor ID 4 on host datanode05.bigdata.fr\n16/05/24 09:32:17 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49034.\n16/05/24 09:32:17 INFO netty.NettyBlockTransferService: Server created on 49034\n16/05/24 09:32:17 INFO storage.BlockManagerMaster: Trying to register BlockManager\n16/05/24 09:32:17 INFO storage.BlockManagerMaster: Registered BlockManager\n16/05/24 09:32:19 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown\n16/05/24 09:32:20 INFO storage.MemoryStore: MemoryStore cleared\n16/05/24 09:32:20 INFO storage.BlockManager: BlockManager stopped\n16/05/24 09:32:20  executor.CoarseGrainedExecutorBackend: An unknown (hiveclient.bigdata.fr:55898) driver disconnected.\n16/05/24 09:32:20  executor.CoarseGrainedExecutorBackend: Driver 192.168.200.208:55898 disassociated! Shutting down.\n16/05/24 09:32:20 INFO util.ShutdownHookManager: Shutdown hook called\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Hive on spark driver crash with Spark 1.6.1","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Hadoop 2.7.2, Hive 2.1.0, Spark 1.6.1, Kerberos","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972313/comment/15352653","id":"15352653","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"body":"Hi,\nI upgraded Hive to Hive 2.1.0. Now I have the following errors:\n- HQL commands\n{noformat}\nhive (shfs3453)> SELECT COUNT(year) FROM chicagocrimes GROUP BY year;\nSELECT COUNT(year) FROM chicagocrimes GROUP BY year\nFAILED: SemanticException Failed to get a spark session: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create spark client.\n{noformat}\n- Client logs\n{noformat}\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.conf.HiveConfUsing the default value passed in for log id: c10f51a3-a72d-40c7-9ff6-26e5fb3732da\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.session.SessionStateUpdating thread name to c10f51a3-a72d-40c7-9ff6-26e5fb3732da main\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.DriverCompiling command(queryId=shfs3453_20160628110208_f0b51237-d391-472d-abe8-f2dd2457a9ed): SELECT COUNT(year) FROM chicagocrimes GROUP BY year\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerStarting Semantic Analysis\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerCompleted phase 1 of Semantic Analysis\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerGet metadata for source tables\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerGet metadata for subqueries\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerGet metadata for destination tables\nJun 28 11:02:08 hive-cli INFO - hive.ql.ContextNew scratch dir is hdfs://sandbox/tmp/hive/shfs3453/c10f51a3-a72d-40c7-9ff6-26e5fb3732da/hive_2016-06-28_11-02-08_399_7245611464735028300-1\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerCompleted getting MetaData in Semantic Analysis\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerGet metadata for source tables\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerGet metadata for subqueries\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerGet metadata for destination tables\nJun 28 11:02:08 hive-cli INFO - hive.ql.ContextNew scratch dir is hdfs://sandbox/tmp/hive/shfs3453/c10f51a3-a72d-40c7-9ff6-26e5fb3732da/hive_2016-06-28_11-02-08_399_7245611464735028300-1\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.common.FileUtilsCreating directory if it doesn't exist: hdfs://sandbox/tmp/hive/shfs3453/c10f51a3-a72d-40c7-9ff6-26e5fb3732da/hive_2016-06-28_11-02-08_399_7245611464735028300-1/-mr-10001/.hive-staging_hive_2016-06-28_11-02-08_399_7245611464735028300-1\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.parse.CalcitePlannerCBO Succeeded; optimized logical plan.\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.ppd.OpProcFactoryProcessing for FS(6)\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.ppd.OpProcFactoryProcessing for SEL(5)\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.ppd.OpProcFactoryProcessing for GBY(4)\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.ppd.OpProcFactoryProcessing for RS(3)\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.ppd.OpProcFactoryProcessing for GBY(2)\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.ppd.OpProcFactoryProcessing for SEL(1)\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.ppd.OpProcFactoryProcessing for TS(0)\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactoryRS 3 oldColExprMap: {KEY._col0=Column[_col0], VALUE._col0=Column[_col1]}\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactoryRS 3 newColExprMap: {KEY._col0=Column[_col0], VALUE._col0=Column[_col1]}\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryloading spark properties from:spark-defaults.conf\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.default.parallelism -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.kryoserializer.buffer -> 100m).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.executor.memory -> 4g).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.driver.memory -> 2g).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.kryo.classesToRegister -> org.apache.hadoop.hive.ql.io.HiveKey,org.apache.hadoop.io.BytesWritable,org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.eventLog.compress -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.akka.frameSize -> 100).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.kryoserializer.buffer.max -> 1500m).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.sql.hive.metastore.jars -> builtin).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.yarn.scheduler.heartbeat.interval-ms -> 3000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.broadcast.compress -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.eventLog.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.executor.extraClassPath -> /opt/application/Spark-Cassandra/current/jar/spark-cassandra-connector.jar).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.broadcast.blockSize -> 4096).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.master -> yarn-client).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.io.compression.snappy.blockSize -> 32k).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.executor.cores -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.io.compression.codec -> org.apache.spark.io.SnappyCompressionCodec).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.kryo.referenceTracking -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.serializer -> org.apache.spark.serializer.KryoSerializer).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.executor.instances -> 4).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.executor.extraJavaOptions -> -Djava.library.path=/opt/application/Hadoop/current/lib/native/).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.driver.maxResultSize -> 1200m).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.sql.hive.metastore.version -> 1.2.1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from spark-defaults.conf (spark.eventLog.dir -> hdfs:///Products/SPARK/logs/).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.leaderport -> 3888).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.localizer.client.thread-count -> 5).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.storefile.refresh.period -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload RPC property from hive configuration (hive.spark.client.connect.timeout -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.admin.address -> 0.0.0.0:8047).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.property.clientPort -> 2181).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.dfs.client.read.shortcircuit.buffer.size -> 131072).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.failover-retries-on-socket-timeouts -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.thrift.framed.max_frame_size_in_mb -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.address -> 0.0.0.0:0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.ha.automatic-failover.embedded -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-state-store.parent-path -> /yarn/rmstore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.metrics.exposeOperationTimes -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.local.dir -> /tmp/hbase-shfs3453/local/).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern -> ^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.client-am.ipc.max-retries -> 3).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.keytab.file -> /opt/application/Hbase/current/keytabs/hbase.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.info.port -> 16030).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.fs.state-store.retry-interval-ms -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (zookeeper.znode.parent -> /hbase).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.coprocessor.regionserver.classes -> org.apache.hadoop.hbase.security.access.AccessController).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.client.best-effort -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.disk-health-checker.interval-ms -> 120000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-timeout-ms -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.aux-services.mapreduce_shuffle.class -> org.apache.hadoop.mapred.ShuffleHandler).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.health-checker.script.timeout-ms -> 1200000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.client.retry-interval-ms -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.coprocessor.abortonerror -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.bytes.per.checksum -> 16384).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.ha.automatic-failover.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.logroll.errors.tolerated -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.data.umask.enable -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.windows-container.memory-limit.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.root-dir -> /sharedcache).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.resource-tracker.address.rm1 -> resourcemanager01.bigdata.fr:8031).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.resource-tracker.address.rm2 -> resourcemanager02.bigdata.fr:8031).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.webapp.address -> resourcemanager01.bigdata.fr:8188).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.status.publisher.class -> org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.balancer.period -> 300000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.readonly -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.cluster.distributed -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.staging-dir -> /Products/MR/staging).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.env-whitelist -> JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.max.filesize -> 10737418240).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.sleep-delay-before-sigkill.ms -> 250).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.address -> resourcemanager01.bigdata.fr:10200).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.recovery.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.dns.interface -> default).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.work-preserving-recovery.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-num-retries -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.ttl-ms -> 604800000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.generic-application-history.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.am.liveness-monitor.expiry-interval-ms -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.ipc.client.fallback-to-simple-auth-allowed -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.table.lock.enable -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.property.initLimit -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb -> 1024).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.compactionThreshold -> 3).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.webapp.address -> 0.0.0.0:8042).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.webapp.https.address -> resourcemanager01.bigdata.fr:8190).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.keytab.file -> /opt/application/Hbase/current/keytabs/hbase.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.admin.address -> resourcemanager01.bigdata.fr:8033).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.http.filter.initializers -> org.apache.hadoop.hbase.http.lib.StaticUserWebFilter).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.resource-tracker.address -> resourcemanager01.bigdata.fr:8031).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.kerberos.principal -> hbase/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.log-aggregation.retain-seconds -> 43200).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.coprocessor.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.metrics.showTableName -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.nodemanager-client-async.thread-pool-max-size -> 500).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.resource.cpu-vcores -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.status.multicast.address.port -> 16100).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.nested-level -> 3).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.property.maxClientCnxns -> 300).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.thrift.http -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.aux-services -> mapreduce_shuffle).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.client.job.max-retries -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs -> 86400).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.fail-fast -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.info.port -> 16010).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.nodemanager-connect.retry-interval-ms -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.container-metrics.unregister-delay-ms -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.write.buffer -> 2097152).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.info.port.auto -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.application-client-protocol.poll-interval-ms -> 200).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.http.max.threads -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.security.qop -> auth).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.command-opts -> -Xmx3800m -Xss512k -XX:+UseParallelGC -XX:ParallelGCThreads=4 -verbose:gc -XX:+PrintTenuringDistribution -XX:+PrintGCDetails -Xloggc:GC.log).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.fail-fast -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.generic-application-history.fs-history-store.uri -> /Products/YARN/timeline/).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.pmem-check-enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.scheduler.minimum-allocation-mb -> 1024).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.http-authentication.type -> kerberos).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.useMulti -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.shuffle.log.backups -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.memstore.block.multiplier -> 4).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.max-completed-applications -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload RPC property from hive configuration (hive.spark.client.rpc.threads -> 8).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.acl.enable -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nm.liveness-monitor.expiry-interval-ms -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.state-store.max-completed-applications -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.log-aggregation-enable -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.ipc.client.tcpnodelay -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.principal -> rm/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.storescanner.parallel.seek.enable -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.htablepool.size.max -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.snapshot.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.store.in-memory.staleness-period-mins -> 10080).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.info.bindAddress -> 0.0.0.0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.scheduler.monitor.policies -> org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.http-authentication.simple.anonymous.allowed -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.local-cache.max-files-per-directory -> 8192).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.admin.acl -> rm,yarn,hdfs).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.cluster-id -> sandbox-RMS).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.coprocessor.user.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.job.task.listener.thread-count -> 30).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.security.visibility.mutations.checkauth -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.scheduler.client.thread-count -> 50).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.ha.rm-ids -> rm1,rm2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.resourcemanager.minimum.version -> NONE).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.cgroups.mount -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.process-kill-wait.ms -> 2000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rootdir -> hdfs://sandbox/Products/HBASE/warehouse/).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-auth -> @/opt/application/Hadoop/current/etc/hadoop/rmhazk-auth.txt).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.server.versionfile.writeattempts -> 3).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.server.compactchecker.interval.multiplier -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.ipc.server.callqueue.scan.ratio -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.address.rm2 -> resourcemanager02.bigdata.fr:8032).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.address.rm1 -> resourcemanager01.bigdata.fr:8032).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload RPC property from hive configuration (hive.spark.client.rpc.max.size -> 52428800).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.job.committer.cancel-timeout -> 60000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.scheduler.address -> resourcemanager01.bigdata.fr:8030).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.principal -> nm/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.server.scanner.max.result.size -> 104857600).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.logcleaner.plugins -> org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.shuffle.log.separate -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds -> -1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.http.policy -> HTTP_ONLY).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.retries.number -> 35).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.authentication.kerberos.principal -> HTTP/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.catalog.timeout -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.majorcompaction -> 604800000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.localizer.fetch.thread-count -> 4).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.kerberos.principal -> HTTP/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.generic-application-history.max-applications -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.keytab -> /opt/application/Hadoop/current/keytabs/yarn.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.thrift.compact -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.online.schema.update.enable -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload spark property from hive configuration (spark.master -> yarn-client).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.proxy-user-privileges.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.checksum.verify -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.docker-container-executor.exec-name -> /usr/bin/docker).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.lease.recovery.dfs.timeout -> 64000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.fs.tmp.dir -> /user/shfs3453/hbase-staging).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.minWorkerThreads -> 16).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.delayed.delegation-token.removal-interval-ms -> 30000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.catalog.timeout -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.store-class -> org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.log.level -> INFO).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.coprocessor.master.classes -> org.apache.hadoop.hbase.security.access.AccessController,org.apache.hadoop.hbase.security.visibility.VisibilityController).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.delete.thread-count -> 4).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.scheduler.maximum-allocation-vcores -> 24).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.data.umask -> 000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.resource.mb -> 4096).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user -> nobody).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.uploader.server.address -> 0.0.0.0:8046).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.infoserver.redirect -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.bin.path -> /opt/application/Hadoop/current/bin/yarn).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.coordinated.state.manager.class -> org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.preclose.flush.size -> 5242880).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.kerberos.principal -> hbase/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.localityCheck.threadPoolSize -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.localizer.cache.target-size-mb -> 10240).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.port -> 16020).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.status.multicast.address.ip -> 226.1.1.3).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.defaults.for.version -> 1.1.2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.remote-app-log-dir -> /Products/YARN/logs).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.bulkload.retries.number -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.hard-kill-timeout-ms -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.scheduler.maximum-allocation-mb -> 65536).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.hostname -> resourcemanager01.bigdata.fr).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms -> 300000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.region.replica.replication.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.container.liveness-monitor.interval-ms -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.vmem-pmem-ratio -> 2.1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rpc.shortoperation.timeout -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.hostname -> 0.0.0.0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.cleaner.resource-sleep-ms -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.status.listener.class -> org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.keyvalue.maxsize -> 10485760).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.pause -> 100).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload RPC property from hive configuration (hive.spark.client.server.connect.timeout -> 90000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.column.max.version -> 1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.nodes.include-path -> /opt/application/Hadoop/current/etc/hadoop/slaves).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.status.published -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.webapp.cross-origin.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.nodemanager.minimum.version -> NONE).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.port -> 8080).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rpc.timeout -> 60000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.resources-handler.class -> org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.ttl-enable -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.checksum.algo.impl -> org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.hfilecleaner.plugins -> org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.cleaner.initial-delay-mins -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.webapp.address -> 0.0.0.0:8788).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.keytab -> /opt/application/Hadoop/current/keytabs/yarn.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-acl -> @/opt/application/Hadoop/current/etc/hadoop/rmhazk-acl.txt).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.hlog.reader.impl -> org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.generic-application-history.store-class -> org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage -> 100).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.hlog.writer.impl -> org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.client.job.retry-interval -> 2000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.ha.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.replication.rpc.codec -> org.apache.hadoop.hbase.codec.KeyValueCodecWithTags).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.admin.address.rm1 -> resourcemanager01.bigdata.fr:8033).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.admin.address.rm2 -> resourcemanager02.bigdata.fr:8033).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.memstore.flush.size -> 134217728).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.dns.interface -> default).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.log-aggregation.retain-check-interval-seconds -> -1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.msginterval -> 3000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.majorcompaction.jitter -> 0.50).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (zookeeper.znode.rootserver -> root-region-server).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.disk-health-checker.min-healthy-disks -> 0.25).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.max-cached-nodemanagers-proxies -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.threads.min -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.resource-tracker.client.thread-count -> 50).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.store.class -> org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.client.thread-count -> 50).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.group -> hadoop).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.resource.memory-mb -> -33088).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.dns.nameserver -> default).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.scheduler.address.rm1 -> resourcemanager01.bigdata.fr:8030).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.scheduler.address.rm2 -> resourcemanager02.bigdata.fr:8030).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.flusher.count -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.max.total.tasks -> 100).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.kerberos.principal -> stargate/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.handler.count -> 30).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.security.authorization -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.admin.client.thread-count -> 1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.logroll.period -> 3600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.log.retain-seconds -> 10800).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.cgroups.hierarchy -> /hadoop-yarn).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.security.exec.permission.checks -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.container.log.limit.kb -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.admin.thread-count -> 1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regions.slop -> 0.2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.threads.max -> 100).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.shuffle.log.limit.kb -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.snapshot.restore.take.failsafe.snapshot -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.blockingStoreFiles -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts -> 3).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.maxQueuedRequests -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.keytab.file -> /etc/krb5/spnego.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.nm.uploader.thread-count -> 20).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.webapp.address -> resourcemanager01.bigdata.fr:8088).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.memstore.mslab.enabled -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.remote-app-log-dir-suffix -> logs).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.dns.nameserver -> default).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.security.authentication -> kerberos).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-state-store.root-node.acl -> setindatabag).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.recovery.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.admin-env -> MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.handler-thread-count -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.hostname -> 0.0.0.0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rootdir.perms -> 700).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.container-monitor.interval-ms -> 3000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.support.proxyuser -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.store.class -> org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rs.cacheblocksonwrite -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.client.max-retries -> 30).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.log-dirs -> file:///mnt/hd0/hadoop/yarn/log/).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.fs.state-store.uri -> /tmp/hadoop-shfs3453/yarn/system/rmstore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.keytab -> /opt/application/Hadoop/current/keytabs/yarn.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.security.visibility.mutations.checkauths -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.http-authentication.kerberos.principal -> HTTP/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.leveldb-timeline-store.read-cache-size -> 104857600).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.ipc.server.callqueue.read.ratio -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.authentication.kerberos.keytab -> /etc/krb5/spnego.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.job.committer.commit-window -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.cells.scanned.per.heartbeat.check -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.connect.max-wait.ms -> 900000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.auth.key.update.interval -> 86400000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.config.read.zookeeper.config -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.client.max-retries -> 3).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.defaults.for.version.skip -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.webapp.https.address -> 0.0.0.0:8090).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.ipc.rpc.class -> org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.localizer.cache.cleanup.interval-ms -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.amlauncher.thread-count -> 50).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.connect.retry-interval.ms -> 30000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.scheduler.minimum-allocation-vcores -> 1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.dynamic.jars.dir -> hdfs://sandbox/Products/HBASE/warehouse//lib).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline_service.webapp.address -> resourcemanager01.bigdata.fr:8188).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.nodemanager-connect-retries -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.region.split.policy -> org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-address -> namenode01.bigdata.fr:2181,namenode02.bigdata.fr:2181,datanode01.bigdata.fr:2181,).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.store.in-memory.initial-delay-mins -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.resource.percentage-physical-cpu-limit -> 100).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.webapp.cross-origin.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.handler.abort.on.error.percent -> 0.5).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload RPC property from hive configuration (hive.spark.client.secret.bits -> 256).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.system-metrics-publisher.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.auth.token.max.lifetime -> 604800000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.scanner.timeout.period -> 60000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.port -> 16000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.task.container.log.backups -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.uploader.server.thread-count -> 50).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.scheduler.class -> org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.keytab.file -> /opt/application/Hbase/current/keytabs/hbase.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.nodemanager-connect.max-wait-ms -> 180000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.nodes.exclude-path -> /opt/application/Hadoop/current/etc/hadoop/exclude).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.fs.state-store.retry-policy-spec -> 2000, 500).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.nodemanagers.heartbeat-interval-ms -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.fs.state-store.num-retries -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.compaction.kv.max -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.failover-proxy-provider -> org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.quorum -> namenode01.bigdata.fr:2181,namenode02.bigdata.fr:2181,datanode01.bigdata.fr:2181,).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.snapshot.restore.failsafe.name -> hbase-failsafe-{snapshot.name}-{restore.timestamp}).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.container-executor.class -> org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.recovery.dir -> /tmp/hadoop-shfs3453/yarn-nm-recovery).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.scanner.caching -> 2147483647).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.coprocessor.region.classes -> org.apache.hadoop.hbase.security.access.AccessController,org.apache.hadoop.hbase.security.visibility.VisibilityController,org.apache.hadoop.hbase.security.token.TokenProvider,org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.scanner.max.result.size -> 2097152).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.nm.uploader.replication.factor -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.table.max.rowsize -> 1073741824).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.bulkload.staging.dir -> /tmp/hbase-staging).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.lease.recovery.timeout -> 900000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.compaction.max -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.server.thread.wakefrequency -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.thrift.framed -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.recovery.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.webapp.address.rm2 -> resourcemanager02.bigdata.fr:8088).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.webapp.address.rm1 -> resourcemanager01.bigdata.fr:8088).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.thrift.maxWorkerThreads -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.dispatcher.drain-events.timeout -> 300000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.superuser -> hdfs).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.time.to.purge.deletes -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs -> 86400).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.client.failover-retries -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.client-server.address -> 0.0.0.0:8045).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.container-manager.thread-count -> 20).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.http.staticuser.user -> dr.stack).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.tmp.dir -> /tmp/hbase-shfs3453).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.app-checker.class -> org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.container.log.backups -> 0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.property.syncLimit -> 5).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.leveldb-timeline-store.path -> /mnt/hd0/hadoop/yarn/timeline).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms -> 10000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.distributed.log.replay -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.support.proxyuser -> true).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.address -> resourcemanager01.bigdata.fr:8032).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.windows-container.cpu-limit.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.localizer.address -> 0.0.0.0:8040).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.logcleaner.ttl -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.regionSplitLimit -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.client-server.thread-count -> 50).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.health-checker.interval-ms -> 600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.master.loadbalancer.class -> org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.info.bindAddress -> 0.0.0.0).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.scheduler.monitor.enable -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.zk-retry-interval-ms -> 1000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (zookeeper.znode.acl.parent -> acl).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.configuration.provider-class -> org.apache.hadoop.yarn.LocalConfigurationProvider).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.local-dirs -> file:///mnt/hd0/hadoop/yarn/local/).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.leveldb-state-store.path -> /tmp/hadoop-shfs3453/yarn/system/rmstore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.max.perregion.tasks -> 1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.http-authentication.kerberos.keytab -> /opt/application/Hadoop/current/keytabs/hadoop.keytab).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.state-store-class -> org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.peerport -> 2888).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.regionserver.optionalcacheflushinterval -> 3600000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.client.max.perserver.tasks -> 5).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.leveldb-state-store.path -> /tmp/hadoop-shfs3453/yarn/timeline).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.filter.classes -> org.apache.hadoop.hbase.rest.filter.GzipFilter).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.delete.debug-delay-sec -> 60000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rest.authentication.type -> kerberos).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.rpc.protection -> auth-conf).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.log-aggregation.compression-type -> none).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.vmem-check-enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.enabled -> false).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.zookeeper.property.dataDir -> /tmp/hbase-shfs3453/zookeeper).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.checksum.algorithm -> CRC32).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.cleaner.period-mins -> 1440).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.timeline-service.principal -> tl/_HOST@REALM.FR).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hstore.blockingWaitTime -> 90000).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.hregion.percolumnfamilyflush.size.lower.bound -> 16777216).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.ha.automatic-failover.zk-base-path -> /yarn/leader-election).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.ipc.server.callqueue.handler.factor -> 0.1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.sharedcache.store.in-memory.check-period-mins -> 720).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload HBase configuration (hbase.storescanner.parallel.seek.threads -> 10).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.nodemanager.aux-services.mapreduce.shuffle.class -> org.apache.hadoop.mapred.ShuffleHandler).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.resourcemanager.am.max-attempts -> 2).\nJun 28 11:02:08 hive-cli INFO - org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactoryload yarn property from hive configuration in yarn-client mode (yarn.app.mapreduce.am.resource.cpu-vcores -> 1).\nJun 28 11:02:08 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplLoading spark defaults: file:/opt/application/Hive/apache-hive-2.1.0-bin/conf/spark-defaults.conf\nJun 28 11:02:08 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplRunning client driver with argv: kinit hiveserver2/sparkclient01.bigdata.fr@REALM.FR -k -t /opt/application/Hive/current/keytabs/hiveserver2.keytab; /opt/application/Spark/current/bin/spark-submit --properties-file /tmp/spark-submit.1914700103794483224.properties --class org.apache.hive.spark.client.RemoteDriver /opt/application/Hive/apache-hive-2.1.0-bin/lib/hive-exec-2.1.0.jar --remote-host sparkclient01.bigdata.fr --remote-port 64022 --conf hive.spark.client.connect.timeout=1000 --conf hive.spark.client.server.connect.timeout=90000 --conf hive.spark.client.channel.log.level=null --conf hive.spark.client.rpc.max.size=52428800 --conf hive.spark.client.rpc.threads=8 --conf hive.spark.client.secret.bits=256 --conf hive.spark.client.rpc.server.address=null\nJun 28 11:02:08 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplkinit: Client 'hiveserver2/sparkclient01.bigdata.fr@REALM.FR' not found in Kerberos database while getting initial credentials\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplWarning: Ignoring non-spark config property: hive.spark.client.server.connect.timeout=90000\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplWarning: Ignoring non-spark config property: hive.spark.client.rpc.threads=8\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplWarning: Ignoring non-spark config property: hive.spark.client.connect.timeout=1000\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplWarning: Ignoring non-spark config property: hive.spark.client.secret.bits=256\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplWarning: Ignoring non-spark config property: hive.spark.client.rpc.max.size=52428800\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImplException in thread \"main\" java.lang.NoSuchFieldError: SPARK_RPC_SERVER_ADDRESS\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.hive.spark.client.rpc.RpcConfiguration.<clinit>(RpcConfiguration.java:45)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.hive.spark.client.RemoteDriver.<init>(RemoteDriver.java:134)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.hive.spark.client.RemoteDriver.main(RemoteDriver.java:516)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at java.lang.reflect.Method.invoke(Method.java:606)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\nJun 28 11:02:10 hive-cli INFO - org.apache.hive.spark.client.SparkClientImpl    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nJun 28 11:02:10 hive-cli ERROR - org.apache.hive.spark.client.SparkClientImplError while waiting for client to connect.\njava.util.concurrent.ExecutionException: java.lang.RuntimeException: Cancel client '9f709de7-d5c2-4a16-9346-40568e651542'. Error: Child process exited before connecting back with error log kinit: Client 'hiveserver2/sparkclient01.bigdata.fr@REALM.FR' not found in Kerberos database while getting initial credentials\nWarning: Ignoring non-spark config property: hive.spark.client.server.connect.timeout=90000\nWarning: Ignoring non-spark config property: hive.spark.client.rpc.threads=8\nWarning: Ignoring non-spark config property: hive.spark.client.connect.timeout=1000\nWarning: Ignoring non-spark config property: hive.spark.client.secret.bits=256\nWarning: Ignoring non-spark config property: hive.spark.client.rpc.max.size=52428800\nException in thread \"main\" java.lang.NoSuchFieldError: SPARK_RPC_SERVER_ADDRESS\n        at org.apache.hive.spark.client.rpc.RpcConfiguration.<clinit>(RpcConfiguration.java:45)\n        at org.apache.hive.spark.client.RemoteDriver.<init>(RemoteDriver.java:134)\n        at org.apache.hive.spark.client.RemoteDriver.main(RemoteDriver.java:516)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\n        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)\n        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n        at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:37)\n        at org.apache.hive.spark.client.SparkClientImpl.<init>(SparkClientImpl.java:104)\n        at org.apache.hive.spark.client.SparkClientFactory.createClient(SparkClientFactory.java:80)\n        at org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient.createRemoteClient(RemoteHiveSparkClient.java:99)\n        at org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient.<init>(RemoteHiveSparkClient.java:95)\n        at org.apache.hadoop.hive.ql.exec.spark.HiveSparkClientFactory.createHiveSparkClient(HiveSparkClientFactory.java:67)\n        at org.apache.hadoop.hive.ql.exec.spark.session.SparkSessionImpl.open(SparkSessionImpl.java:62)\n        at org.apache.hadoop.hive.ql.exec.spark.session.SparkSessionManagerImpl.getSession(SparkSessionManagerImpl.java:114)\n        at org.apache.hadoop.hive.ql.exec.spark.SparkUtilities.getSparkSession(SparkUtilities.java:136)\n        at org.apache.hadoop.hive.ql.optimizer.spark.SetSparkReducerParallelism.process(SetSparkReducerParallelism.java:117)\n        at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:158)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120)\n        at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.runJoinOptimizations(SparkCompiler.java:178)\n        at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.optimizeOperatorPlan(SparkCompiler.java:116)\n        at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:134)\n        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10857)\n        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:239)\n        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:250)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:437)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:329)\n        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1158)\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1253)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1084)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1072)\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:232)\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:183)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:399)\n        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:776)\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:714)\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: java.lang.RuntimeException: Cancel client '9f709de7-d5c2-4a16-9346-40568e651542'. Error: Child process exited before connecting back with error log kinit: Client 'hiveserver2/sparkclient01.bigdata.fr@REALM.FR' not found in Kerberos database while getting initial credentials\nWarning: Ignoring non-spark config property: hive.spark.client.server.connect.timeout=90000\nWarning: Ignoring non-spark config property: hive.spark.client.rpc.threads=8\nWarning: Ignoring non-spark config property: hive.spark.client.connect.timeout=1000\nWarning: Ignoring non-spark config property: hive.spark.client.secret.bits=256\nWarning: Ignoring non-spark config property: hive.spark.client.rpc.max.size=52428800\nException in thread \"main\" java.lang.NoSuchFieldError: SPARK_RPC_SERVER_ADDRESS\n        at org.apache.hive.spark.client.rpc.RpcConfiguration.<clinit>(RpcConfiguration.java:45)\n        at org.apache.hive.spark.client.RemoteDriver.<init>(RemoteDriver.java:134)\n        at org.apache.hive.spark.client.RemoteDriver.main(RemoteDriver.java:516)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\n        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)\n        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\n        at org.apache.hive.spark.client.rpc.RpcServer.cancelClient(RpcServer.java:179)\n        at org.apache.hive.spark.client.SparkClientImpl$3.run(SparkClientImpl.java:465)\n        at java.lang.Thread.run(Thread.java:745)\nJun 28 11:02:10 hive-cli WARN - org.apache.hive.spark.client.SparkClientImplChild process exited with code 1\nJun 28 11:02:10 hive-cli ERROR - org.apache.hadoop.hive.ql.DriverFAILED: SemanticException Failed to get a spark session: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create spark client.\norg.apache.hadoop.hive.ql.parse.SemanticException: Failed to get a spark session: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create spark client.\n        at org.apache.hadoop.hive.ql.optimizer.spark.SetSparkReducerParallelism.process(SetSparkReducerParallelism.java:121)\n        at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:158)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120)\n        at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.runJoinOptimizations(SparkCompiler.java:178)\n        at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.optimizeOperatorPlan(SparkCompiler.java:116)\n        at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:134)\n        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10857)\n        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:239)\n        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:250)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:437)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:329)\n        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1158)\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1253)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1084)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1072)\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:232)\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:183)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:399)\n        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:776)\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:714)\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n\nJun 28 11:02:10 hive-cli INFO - org.apache.hadoop.hive.ql.DriverCompleted compiling command(queryId=shfs3453_20160628110208_f0b51237-d391-472d-abe8-f2dd2457a9ed); Time taken: 2.496 seconds\nJun 28 11:02:10 hive-cli INFO - org.apache.hadoop.hive.conf.HiveConfUsing the default value passed in for log id: c10f51a3-a72d-40c7-9ff6-26e5fb3732da\nJun 28 11:02:10 hive-cli INFO - org.apache.hadoop.hive.ql.session.SessionStateResetting thread name to  main\n{noformat}\nIt's very strange that Hive tries to do a kinit on the machine, with a wrong principal.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"created":"2016-06-28T09:19:29.951+0000","updated":"2016-06-28T09:19:29.951+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972313/comment/15547919","id":"15547919","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"body":"Nothing new here?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"created":"2016-10-05T07:16:54.182+0000","updated":"2016-10-05T07:16:54.182+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972313/comment/15601515","id":"15601515","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"I used spark1.6.2 release version, spark1.6.4 and Hive 1.2.1, it has the same error.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-10-24T10:01:04.109+0000","updated":"2016-10-24T10:01:04.109+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972313/comment/15625642","id":"15625642","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"Did you get HoS to work? {{java.lang.NoSuchFieldError: SPARK_RPC_SERVER_ADDRESS}} looks like mismatched jars in the hive installation.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aihuaxu","name":"aihuaxu","key":"aihuaxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aihua Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-01T15:01:38.966+0000","updated":"2016-11-01T15:01:38.966+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972313/comment/15628158","id":"15628158","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"body":"I'm still using Spark 1.6.1, Hive 2.1.0 and Hadoop 2.7.2, the error remains valid.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=BigDataOrange","name":"BigDataOrange","key":"bigdataorange","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexandre Linte","active":true,"timeZone":"Europe/Paris"},"created":"2016-11-02T08:11:38.152+0000","updated":"2016-11-02T08:11:38.152+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972313/comment/15825512","id":"15825512","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"how do you build your spark? did you add the -Phive profile?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-01-17T06:06:23.008+0000","updated":"2017-01-17T06:06:23.008+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-13830/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2yetz:"}}