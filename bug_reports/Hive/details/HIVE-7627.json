{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12732211","self":"https://issues.apache.org/jira/rest/api/2/issue/12732211","key":"HIVE-7627","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329363","id":"12329363","name":"1.1.0","archived":false,"released":true,"releaseDate":"2015-03-07"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-09-10T10:57:40.759+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Sep 29 18:06:24 UTC 2014","customfield_12310420":"410240","customfield_12312320":null,"customfield_12310222":"10002_*:*_2_*:*_136228489_*|*_1_*:*_2_*:*_4583638746_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-09-29T18:06:24.197+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7627/watchers","watchCount":3,"isWatching":false},"created":"2014-08-06T03:01:57.023+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["spark-m1"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"7.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12393856","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12393856","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12732454","key":"SPARK-2895","self":"https://issues.apache.org/jira/rest/api/2/issue/12732454","fields":{"summary":"Support mapPartitionsWithContext in Spark Java API","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12393537","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12393537","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"inwardIssue":{"id":"12723734","key":"HIVE-7292","self":"https://issues.apache.org/jira/rest/api/2/issue/12723734","fields":{"summary":"Hive on Spark","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12393608","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12393608","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12732454","key":"SPARK-2895","self":"https://issues.apache.org/jira/rest/api/2/issue/12732454","fields":{"summary":"Support mapPartitionsWithContext in Spark Java API","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12393538","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12393538","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12731635","key":"HIVE-7597","self":"https://issues.apache.org/jira/rest/api/2/issue/12731635","fields":{"summary":"Support analyze table [Spark Branch]","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-05-29T02:30:16.421+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"Hive table statistic failed on FSStatsPublisher mode, with the following exception in Spark executor side:\n{noformat}\n14/08/05 16:46:24 WARN hdfs.DFSClient: DataStreamer Exception\njava.io.FileNotFoundException: ID mismatch. Request id and saved id: 20277 , 20278 for file /tmp/hive-root/8833d172-1edd-4508-86db-fdd7a1b0af17/hive_2014-08-05_16-46-03_013_6279446857294757772-1/-ext-10000/tmpstats-0\n        at org.apache.hadoop.hdfs.server.namenode.INodeId.checkId(INodeId.java:53)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2952)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2754)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2662)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:584)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)\n\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:525)\n        at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)\n       at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1442)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1261)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:525)\nCaused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): ID mismatch. Request id and saved id: 20277 , 20278 for file /tmp/hive-root/8833d172-1edd-4508-86db-fdd7a1b0af17/hive_2014-08-05_16-46-03_013_6279446857294757772-1/-ext-10000/tmpstats-0\n        at org.apache.hadoop.hdfs.server.namenode.INodeId.checkId(INodeId.java:53)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2952)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2754)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2662)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:584)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:440)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1410)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1363)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n        at com.sun.proxy.$Proxy19.addBlock(Unknown Source)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:601)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:190)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy19.addBlock(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:361)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1439)\n        ... 2 more\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12665291","id":"12665291","filename":"HIVE-7627.1-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-29T07:54:29.861+0000","size":5595,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12665291/HIVE-7627.1-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12667637","id":"12667637","filename":"HIVE-7627.2-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-10T09:22:48.067+0000","size":1096,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12667637/HIVE-7627.2-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12671696","id":"12671696","filename":"HIVE-7627.3-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-28T07:54:40.719+0000","size":1020,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12671696/HIVE-7627.3-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12671721","id":"12671721","filename":"HIVE-7627.4-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-28T23:06:16.497+0000","size":2102,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12671721/HIVE-7627.4-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12671699","id":"12671699","filename":"HIVE-7627.4-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-28T09:48:31.823+0000","size":2102,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12671699/HIVE-7627.4-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12671815","id":"12671815","filename":"HIVE-7627.5-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-29T16:12:53.047+0000","size":2102,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12671815/HIVE-7627.5-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12671735","id":"12671735","filename":"HIVE-7627.5-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-29T03:02:47.861+0000","size":2102,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12671735/HIVE-7627.5-spark.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"410230","customfield_12312823":null,"summary":"FSStatsPublisher does fit into Spark multi-thread task mode[Spark Branch]","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14088744","id":"14088744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"Root  cause:\n\nFSStatsPublisher collect table data info through TableScanOperator in each task, and write collect data into a file each, the file name for each task is set by prefix + conf.getInt(“mapred.task.partition”). During Hive on Spark, \"mapred.task.partition\" is not set, so it's all the same for all tasks, which means all tasks write to the same file. In HDFS, multi-thread write to  same file with overwrite is true would lead to the previous exception.\n\nSolution:\n\nWe need to set \"mapred.task.partition\" in Spark transformation closure, so current problem is that Spark transformation closure can't get task context information through Spark Java API, it's only available in Spark Scala API, I've created SPARK-2895 to track this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-07T03:12:47.489+0000","updated":"2014-08-07T03:12:47.489+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14115000","id":"14115000","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"Use {{mapPartitionToPairWithContext()}} instead of {{mapPartitionToPair()}} to get access of TaskContext in HiveMapFuction/HiveReduceFunction. \n\n*NOTICE*, this patch depends on SPARK-2895, we need to update Spark dependency to latest spark master build after SPARK-2895 is merged.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-29T07:54:29.865+0000","updated":"2014-08-29T07:54:29.865+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14128247","id":"14128247","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"make taskId field variable of FSStatPublisher would resolve this issue either, since SPARK-2895 is still under review, we could enable random generated taskId first.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-10T09:22:48.087+0000","updated":"2014-09-10T09:22:48.087+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14128338","id":"14128338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12667637/HIVE-7627.2-spark.patch\n\n{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 6343 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan\norg.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/123/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/123/console\nTest logs: http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-123/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 4 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12667637","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-09-10T10:57:40.759+0000","updated":"2014-09-10T10:57:40.759+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151020","id":"14151020","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12671696/HIVE-7627.3-spark.patch\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/167/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/167/console\nTest logs: http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-167/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN KW_CASE KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN LPAREN KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:115:5: \nDecision can match input such as \"KW_CLUSTER KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:127:5: \nDecision can match input such as \"KW_PARTITION KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:138:5: \nDecision can match input such as \"KW_DISTRIBUTE KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:149:5: \nDecision can match input such as \"KW_SORT KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:166:7: \nDecision can match input such as \"STAR\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_STRUCT\" using multiple alternatives: 4, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_ARRAY\" using multiple alternatives: 2, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_UNIONTYPE\" using multiple alternatives: 5, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_NULL\" using multiple alternatives: 1, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_TRUE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_FALSE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_DATE StringLiteral\" using multiple alternatives: 2, 3\n\nAs a result, alternative(s) 3 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"KW_BETWEEN KW_MAP LPAREN\" using multiple alternatives: 8, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:518:5: \nDecision can match input such as \"{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}\" using multiple alternatives: 1, 3\n\nAs a result, alternative(s) 3 were disabled for that input\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/hadoop/hadoop-client/2.3.0-cdh5.1.2/hadoop-client-2.3.0-cdh5.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-client/2.3.0-cdh5.1.2/hadoop-client-2.3.0-cdh5.1.2.pom\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.3.0-cdh5.1.2/hadoop-mapreduce-client-app-2.3.0-cdh5.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.3.0-cdh5.1.2/hadoop-mapreduce-client-app-2.3.0-cdh5.1.2.pom\nDownloading: http://www.datanucleus.org/downloads/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.3.0-cdh5.1.2/hadoop-mapreduce-client-shuffle-2.3.0-cdh5.1.2.pom\nDownloading: http://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.3.0-cdh5.1.2/hadoop-mapreduce-client-shuffle-2.3.0-cdh5.1.2.pom\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 2 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n  symbol:   method get()\n  location: class org.apache.spark.TaskContext\n[INFO] 1 error\n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.892s]\n[INFO] Hive Shims Common ................................. SUCCESS [2.532s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [1.010s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [1.468s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [0.865s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [1.862s]\n[INFO] Hive Shims ........................................ SUCCESS [0.243s]\n[INFO] Hive Common ....................................... SUCCESS [4.505s]\n[INFO] Hive Serde ........................................ SUCCESS [3.837s]\n[INFO] Hive Metastore .................................... SUCCESS [11.725s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.560s]\n[INFO] Hive Query Language ............................... FAILURE [18.143s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 50.539s\n[INFO] Finished at: Sun Sep 28 04:24:21 EDT 2014\n[INFO] Final Memory: 84M/827M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n[ERROR] symbol:   method get()\n[ERROR] location: class org.apache.spark.TaskContext\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12671696","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-09-28T08:23:08.923+0000","updated":"2014-09-28T08:23:08.923+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151065","id":"14151065","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12671699/HIVE-7627.4-spark.patch\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/168/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/168/console\nTest logs: http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-168/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN KW_CASE KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN LPAREN KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:115:5: \nDecision can match input such as \"KW_CLUSTER KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:127:5: \nDecision can match input such as \"KW_PARTITION KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:138:5: \nDecision can match input such as \"KW_DISTRIBUTE KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:149:5: \nDecision can match input such as \"KW_SORT KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:166:7: \nDecision can match input such as \"STAR\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_STRUCT\" using multiple alternatives: 4, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_ARRAY\" using multiple alternatives: 2, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_UNIONTYPE\" using multiple alternatives: 5, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_NULL\" using multiple alternatives: 1, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_TRUE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_FALSE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_DATE StringLiteral\" using multiple alternatives: 2, 3\n\nAs a result, alternative(s) 3 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"KW_BETWEEN KW_MAP LPAREN\" using multiple alternatives: 8, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:518:5: \nDecision can match input such as \"{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}\" using multiple alternatives: 1, 3\n\nAs a result, alternative(s) 3 were disabled for that input\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 2 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n  symbol:   method get()\n  location: class org.apache.spark.TaskContext\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol\n  symbol:   method get()\n  location: class org.apache.spark.TaskContext\n[INFO] 2 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.923s]\n[INFO] Hive Shims Common ................................. SUCCESS [2.534s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [0.731s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [1.442s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [0.684s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [1.729s]\n[INFO] Hive Shims ........................................ SUCCESS [0.264s]\n[INFO] Hive Common ....................................... SUCCESS [3.298s]\n[INFO] Hive Serde ........................................ SUCCESS [3.676s]\n[INFO] Hive Metastore .................................... SUCCESS [12.425s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.546s]\n[INFO] Hive Query Language ............................... FAILURE [16.338s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 47.489s\n[INFO] Finished at: Sun Sep 28 06:04:28 EDT 2014\n[INFO] Final Memory: 86M/945M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n[ERROR] symbol:   method get()\n[ERROR] location: class org.apache.spark.TaskContext\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol\n[ERROR] symbol:   method get()\n[ERROR] location: class org.apache.spark.TaskContext\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12671699","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-09-28T10:03:15.767+0000","updated":"2014-09-28T10:03:15.767+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151115","id":"14151115","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"The failure may be caused by the snapshot spark library, which may need to be updated to include the fix for SPARK-2895. Will do that shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-28T14:20:51.338+0000","updated":"2014-09-28T14:20:51.338+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151252","id":"14151252","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Reload the same patch to trigger the test.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-28T23:06:16.507+0000","updated":"2014-09-28T23:06:16.507+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151259","id":"14151259","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12671721/HIVE-7627.4-spark.patch\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/169/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/169/console\nTest logs: http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-169/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN KW_CASE KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN LPAREN KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:115:5: \nDecision can match input such as \"KW_CLUSTER KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:127:5: \nDecision can match input such as \"KW_PARTITION KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:138:5: \nDecision can match input such as \"KW_DISTRIBUTE KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:149:5: \nDecision can match input such as \"KW_SORT KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:166:7: \nDecision can match input such as \"STAR\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_STRUCT\" using multiple alternatives: 4, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_ARRAY\" using multiple alternatives: 2, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_UNIONTYPE\" using multiple alternatives: 5, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_NULL\" using multiple alternatives: 1, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_TRUE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_FALSE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_DATE StringLiteral\" using multiple alternatives: 2, 3\n\nAs a result, alternative(s) 3 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"KW_BETWEEN KW_MAP LPAREN\" using multiple alternatives: 8, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:518:5: \nDecision can match input such as \"{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}\" using multiple alternatives: 1, 3\n\nAs a result, alternative(s) 3 were disabled for that input\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 2 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n  symbol:   method get()\n  location: class org.apache.spark.TaskContext\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol\n  symbol:   method get()\n  location: class org.apache.spark.TaskContext\n[INFO] 2 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.892s]\n[INFO] Hive Shims Common ................................. SUCCESS [2.371s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [0.975s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [1.330s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [0.646s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [1.616s]\n[INFO] Hive Shims ........................................ SUCCESS [0.247s]\n[INFO] Hive Common ....................................... SUCCESS [3.192s]\n[INFO] Hive Serde ........................................ SUCCESS [3.826s]\n[INFO] Hive Metastore .................................... SUCCESS [11.761s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.564s]\n[INFO] Hive Query Language ............................... FAILURE [18.403s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 48.984s\n[INFO] Finished at: Sun Sep 28 19:23:58 EDT 2014\n[INFO] Final Memory: 84M/842M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n[ERROR] symbol:   method get()\n[ERROR] location: class org.apache.spark.TaskContext\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol\n[ERROR] symbol:   method get()\n[ERROR] location: class org.apache.spark.TaskContext\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12671721","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-09-28T23:22:45.741+0000","updated":"2014-09-28T23:22:45.741+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151326","id":"14151326","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12671735/HIVE-7627.5-spark.patch\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/170/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/170/console\nTest logs: http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-170/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN KW_CASE KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:68:4: \nDecision can match input such as \"LPAREN LPAREN KW_IF\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:115:5: \nDecision can match input such as \"KW_CLUSTER KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:127:5: \nDecision can match input such as \"KW_PARTITION KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:138:5: \nDecision can match input such as \"KW_DISTRIBUTE KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:149:5: \nDecision can match input such as \"KW_SORT KW_BY LPAREN\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:166:7: \nDecision can match input such as \"STAR\" using multiple alternatives: 1, 2\n\nAs a result, alternative(s) 2 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_STRUCT\" using multiple alternatives: 4, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_ARRAY\" using multiple alternatives: 2, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:179:5: \nDecision can match input such as \"KW_UNIONTYPE\" using multiple alternatives: 5, 6\n\nAs a result, alternative(s) 6 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_NULL\" using multiple alternatives: 1, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_TRUE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_FALSE\" using multiple alternatives: 3, 8\n\nAs a result, alternative(s) 8 were disabled for that input\nwarning(200): IdentifiersParser.g:261:5: \nDecision can match input such as \"KW_DATE StringLiteral\" using multiple alternatives: 2, 3\n\nAs a result, alternative(s) 3 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"KW_BETWEEN KW_MAP LPAREN\" using multiple alternatives: 8, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:393:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:518:5: \nDecision can match input such as \"{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}\" using multiple alternatives: 1, 3\n\nAs a result, alternative(s) 3 were disabled for that input\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 2 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 1909 source files to /data/hive-ptest/working/apache-svn-spark-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n  symbol:   method get()\n  location: class org.apache.spark.TaskContext\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol\n  symbol:   method get()\n  location: class org.apache.spark.TaskContext\n[INFO] 2 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [3.104s]\n[INFO] Hive Shims Common ................................. SUCCESS [2.346s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [0.861s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [1.210s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [0.606s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [1.826s]\n[INFO] Hive Shims ........................................ SUCCESS [0.271s]\n[INFO] Hive Common ....................................... SUCCESS [3.376s]\n[INFO] Hive Serde ........................................ SUCCESS [3.801s]\n[INFO] Hive Metastore .................................... SUCCESS [12.085s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.564s]\n[INFO] Hive Query Language ............................... FAILURE [16.142s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 47.034s\n[INFO] Finished at: Sun Sep 28 23:24:13 EDT 2014\n[INFO] Final Memory: 86M/942M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveMapFunction.java:[52,58] cannot find symbol\n[ERROR] symbol:   method get()\n[ERROR] location: class org.apache.spark.TaskContext\n[ERROR] /data/hive-ptest/working/apache-svn-spark-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HiveReduceFunction.java:[51,58] cannot find symbol\n[ERROR] symbol:   method get()\n[ERROR] location: class org.apache.spark.TaskContext\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12671735","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-09-29T03:23:00.302+0000","updated":"2014-09-29T03:23:00.302+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151852","id":"14151852","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"Re-uploading the same patch to test the precommit infra.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-29T16:12:53.055+0000","updated":"2014-09-29T16:12:53.055+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151918","id":"14151918","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12671815/HIVE-7627.5-spark.patch\n\n{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 6509 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/173/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/173/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-173/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 2 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12671815","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-09-29T17:21:09.471+0000","updated":"2014-09-29T17:21:09.471+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151963","id":"14151963","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-29T18:03:03.748+0000","updated":"2014-09-29T18:03:03.748+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12732211/comment/14151968","id":"14151968","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch committed to Spark branch. Thanks to Chengxiang for the contribution.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-29T18:06:24.238+0000","updated":"2014-09-29T18:06:24.238+0000"}],"maxResults":14,"total":14,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7627/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1ykxr:"}}