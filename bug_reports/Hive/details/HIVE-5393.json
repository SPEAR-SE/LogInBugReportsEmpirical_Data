{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12671049","self":"https://issues.apache.org/jira/rest/api/2/issue/12671049","key":"HIVE-5393","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-11-14T01:12:33.921+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Nov 14 01:12:33 UTC 2013","customfield_12310420":"350878","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5393/watchers","watchCount":4,"isWatching":false},"created":"2013-09-27T23:42:41.457+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12317742","id":"12317742","description":"released","name":"0.9.0","archived":false,"released":true,"releaseDate":"2012-04-30"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-11-14T01:12:33.921+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12314270","id":"12314270","name":"Diagnosability","description":"Error messages, logging, diagnostics, etc."}],"timeoriginalestimate":null,"description":"When I am running multi insert statment in Hive to copy data from a single source table to a target table but into two different partitions, The log is not showing how many rows got loaded into two different partitions by the separate insert statements. It is only showing how many rows loaded for only insert statement not both of them.\n\n\nBelow is the query:\n\n=============================================================\nfrom WBUSINESS_STR\ninsert OVERWRITE table WBUSINESS_intraday_30mins PARTITION (data_year='2013',data_month='09',data_day='23',data_hourmin='0000',data_run_id='201309230001') \nselect\nyear(DB_COMMIT_TIMESTAMP ) as year,\nmonth(DB_COMMIT_TIMESTAMP) as month,\nday(DB_COMMIT_TIMESTAMP) as day,\nconcat(hour(DB_COMMIT_TIMESTAMP),minute(DB_COMMIT_TIMESTAMP)) as hourmin,\n'201309230001' as RUN_ID,\ncast(DB_COMMIT_TIMESTAMP as timestamp),\nDB_ACTION_TYPE,\ncast( RBA as bigint),\ncast( ID as bigint ),\ncast( ACCOUNT_NUMBER as bigint ),\ncast( TIME_CREATED as bigint ),\ncast( FLAGS as bigint ),\nNAME ,\nNAME_UPPER ,\ncast( ADDRESS_ID as bigint ),\ncast( EIN as bigint ),\nDUNS_NUMBER ,\ncast( SIC as bigint ),\ncast( TYPE as bigint ),\nSTATE_INC ,\ncast( AVERAGE_TICKET as bigint ),\nSERVICE_EMAIL ,\nSERVICE_PHONE ,\ncast(concat(substr(TIME_ROW_UPDATED,1,10),' ',substr(TIME_ROW_UPDATED,12)) as timestamp),\nDISPUTE_EMAIL ,\nDOING_BUSINESS_AS \nwhere \ncast(DB_COMMIT_TIMESTAMP as timestamp) >= cast('2013-09-23 00:00:00'  as timestamp)\nand cast(DB_COMMIT_TIMESTAMP as timestamp) < cast('2013-09-23 00:30:00' as timestamp)\ninsert OVERWRITE table WBUSINESS_intraday_30mins PARTITION (data_year='2013',data_month='09',data_day='22',data_hourmin='2330',data_run_id='201309230001') \nselect\nyear(DB_COMMIT_TIMESTAMP ) as year,\nmonth(DB_COMMIT_TIMESTAMP) as month,\nday(DB_COMMIT_TIMESTAMP) as day,\nconcat(hour(DB_COMMIT_TIMESTAMP),minute(DB_COMMIT_TIMESTAMP)) as hourmin,\n'201309230001' as RUN_ID,\ncast(DB_COMMIT_TIMESTAMP as timestamp),\nDB_ACTION_TYPE,\ncast( RBA as bigint),\ncast( ID as bigint ),\ncast( ACCOUNT_NUMBER as bigint ),\ncast( TIME_CREATED as bigint ),\ncast( FLAGS as bigint ),\nNAME ,\nNAME_UPPER ,\ncast( ADDRESS_ID as bigint ),\ncast( EIN as bigint ),\nDUNS_NUMBER ,\ncast( SIC as bigint ),\ncast( TYPE as bigint ),\nSTATE_INC ,\ncast( AVERAGE_TICKET as bigint ),\nSERVICE_EMAIL ,\nSERVICE_PHONE ,\ncast(concat(substr(TIME_ROW_UPDATED,1,10),' ',substr(TIME_ROW_UPDATED,12)) as timestamp),\nDISPUTE_EMAIL ,\nDOING_BUSINESS_AS \nwhere \ncast(DB_COMMIT_TIMESTAMP as timestamp) >= cast('2013-09-22 23:30:00'  as timestamp)\nand cast(DB_COMMIT_TIMESTAMP as timestamp) < cast('2013-09-23 00:00:00' as timestamp)\n============================================\n\nThe Hive log says:\n\nTotal MapReduce jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks is set to 0 since there's no reduce operator\nStarting Job = job_201309261542_0042, Tracking URL = http://dmdevetllvs01:50030/jobdetails.jsp?jobid=job_201309261542_0042\nKill Command = /dmdev/data01/paypal/HADOOP/node1/hadoop-0.20.2-cdh3u4/bin/hadoop job  -Dmapred.job.tracker=dmdevetllvs01:9010 -kill job_201309261542_0042\nHadoop job information for Stage-2: number of mappers: 1; number of reducers: 0\n2013-09-27 16:24:26,542 Stage-2 map = 0%,  reduce = 0%\n2013-09-27 16:24:28,565 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.52 sec\n2013-09-27 16:24:29,574 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.52 sec\nMapReduce Total cumulative CPU time: 2 seconds 520 msec\nEnded Job = job_201309261542_0042\nEnded Job = 730112486, job is filtered out (removed at runtime).\nEnded Job = -507348248, job is filtered out (removed at runtime).\nMoving data to: hdfs://dmdevetllvs01.qa.paypal.com/tmp/hive-sanddas/hive_2013-09-27_16-24-19_784_1282210997007172719/-ext-10000\nMoving data to: hdfs://dmdevetllvs01.qa.paypal.com/tmp/hive-sanddas/hive_2013-09-27_16-24-19_784_1282210997007172719/-ext-10002\nLoading data to table default.wbusiness_intraday_30mins partition (data_year=2013, data_month=09, data_day=22, data_hourmin=2330, data_run_id=201309230001)\nDeleted hdfs://dmdevetllvs01.qa.paypal.com/sys/pp_dm/sanddas/import/site/CONF/WBUSINESS/RCFILE/incremental/data_year=2013/data_month=09/data_day=22/data_hourmin=2330/data_run_id=201309230001\nPartition default.wbusiness_intraday_30mins{data_year=2013, data_month=09, data_day=22, data_hourmin=2330, data_run_id=201309230001} stats: [num_files: 1, num_rows: 0, total_size: 12283, raw_data_size: 0]\nTable default.wbusiness_intraday_30mins stats: [num_partitions: 7, num_files: 7, num_rows: 0, total_size: 62018, raw_data_size: 0]\nLoading data to table default.wbusiness_intraday_30mins partition (data_year=2013, data_month=09, data_day=23, data_hourmin=0000, data_run_id=201309230001)\nDeleted hdfs://dmdevetllvs01.qa.paypal.com/sys/pp_dm/sanddas/import/site/CONF/WBUSINESS/RCFILE/incremental/data_year=2013/data_month=09/data_day=23/data_hourmin=0000/data_run_id=201309230001\nPartition default.wbusiness_intraday_30mins{data_year=2013, data_month=09, data_day=23, data_hourmin=0000, data_run_id=201309230001} stats: [num_files: 1, num_rows: 0, total_size: 1870, raw_data_size: 0]\nTable default.wbusiness_intraday_30mins stats: [num_partitions: 7, num_files: 7, num_rows: 0, total_size: 62018, raw_data_size: 0]\n141 Rows loaded to wbusiness_intraday_30mins\nMapReduce Jobs Launched: \nJob 0: Map: 1   Cumulative CPU: 2.52 sec   HDFS Read: 4191 HDFS Write: 14153 SUCCESS\nTotal MapReduce CPU Time Spent: 2 seconds 520 msec\nOK\nTime taken: 10.771 seconds\n====================================================================\n\nIt is only showing 141 rows loaded for a partition.\nIt is not showing another 21 rows loaded in another partition.\n\nThe source table has 161 rows.\n\nPlease let us know if this is normal.\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"351169","customfield_12312823":null,"summary":"Hive Multi insert statement  is not logging how many rows loaded for individual insert statements","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sanddas154","name":"sanddas154","key":"sanddas154","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sandip Das","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sanddas154","name":"sanddas154","key":"sanddas154","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sandip Das","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Hive 0.9.0\nCloudera CDH3U4","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12671049/comment/13822056","id":"13822056","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=teddy.choi","name":"teddy.choi","key":"teddy.choi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=teddy.choi&avatarId=17686","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=teddy.choi&avatarId=17686","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=teddy.choi&avatarId=17686","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=teddy.choi&avatarId=17686"},"displayName":"Teddy Choi","active":true,"timeZone":"Asia/Seoul"},"body":"I just clicked somewhere of this page once and closed, then it became updated. It is my mistake. Sorry.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=teddy.choi","name":"teddy.choi","key":"teddy.choi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=teddy.choi&avatarId=17686","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=teddy.choi&avatarId=17686","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=teddy.choi&avatarId=17686","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=teddy.choi&avatarId=17686"},"displayName":"Teddy Choi","active":true,"timeZone":"Asia/Seoul"},"created":"2013-11-14T01:12:33.921+0000","updated":"2013-11-14T01:12:33.921+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5393/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1ohy7:"}}