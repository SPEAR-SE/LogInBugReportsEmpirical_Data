{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12987289","self":"https://issues.apache.org/jira/rest/api/2/issue/12987289","key":"HIVE-14171","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-01-10T19:07:48.164+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Feb 09 04:39:05 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14171/watchers","watchCount":6,"isWatching":false},"created":"2016-07-06T21:14:34.991+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["Parquet"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-02-09T04:39:05.654+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320633","id":"12320633","name":"File Formats","description":"File Formats"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12321300","id":"12321300","name":"Vectorization","description":"Vectorized query execution"}],"timeoriginalestimate":null,"description":"{code}\n create temporary table cd_parquet stored as parquet as select * from customer_demographics;\n\nselect count(1) from cd_parquet where cd_gender = 'F';\n{code}\n\n{code}\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.next(ParquetRecordReaderWrapper.java:206)\n\tat org.apache.hadoop.hive.ql.io.parquet.VectorizedParquetInputFormat$VectorizedParquetRecordReader.next(VectorizedParquetInputFormat.java:118)\n\tat org.apache.hadoop.hive.ql.io.parquet.VectorizedParquetInputFormat$VectorizedParquetRecordReader.next(VectorizedParquetInputFormat.java:51)\n\tat org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:350)\n\t... 17 more\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Parquet: Simple vectorization throws NPEs","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16320872","id":"16320872","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vihangk1","name":"vihangk1","key":"vihangk1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vihang Karajgaonkar","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~gopalv] Do you know if this is still a problem? I haven't hit this issue recently. Thanks for reporting!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vihangk1","name":"vihangk1","key":"vihangk1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vihang Karajgaonkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-01-10T19:07:48.164+0000","updated":"2018-01-10T19:07:48.164+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16356325","id":"16356325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"Found similar issue with hive.vectorized.use.row.serde.deserialize=true on TPC-DS query12, parquet file format.\r\nenvironment:\r\nHive2.2.0 with patch HIVE-14029\r\nSpark2.0.2\r\nHadoop2.7.3\r\n \r\nstack trace:\r\nJob aborted due to stage failure: Task 76 in stage 1.0 failed 4 times, most recent failure: Lost task 76.3 in stage 1.0 (TID 35, skl-slave2): java.io.IOException: java.io.IOException: java.lang.NullPointerException\r\n         at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderNextException(HiveIOExceptionHandlerChain.java:121)\r\n         at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderNextException(HiveIOExceptionHandlerUtil.java:77)\r\n         at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.doNextWithExceptionHandler(HadoopShimsSecure.java:231)\r\n         at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.next(HadoopShimsSecure.java:141)\r\n         at org.apache.spark.rdd.HadoopRDD$$anon$1.getNext(HadoopRDD.scala:254)\r\n         at org.apache.spark.rdd.HadoopRDD$$anon$1.getNext(HadoopRDD.scala:208)\r\n         at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\r\n         at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)\r\n         at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30)\r\n         at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList.hasNext(HiveBaseFunctionResultList.java:83)\r\n         at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42)\r\n         at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:200)\r\n         at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\r\n         at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\r\n         at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\r\n         at org.apache.spark.scheduler.Task.run(Task.scala:86)\r\n         at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\r\n         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n         at java.lang.Thread.run(Thread.java:748)\r\n Caused by: java.io.IOException: java.lang.NullPointerException\r\n         at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderNextException(HiveIOExceptionHandlerChain.java:121)\r\n         at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderNextException(HiveIOExceptionHandlerUtil.java:77)\r\n         at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:355)\r\n         at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:157)\r\n         at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:51)\r\n         at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.next(HiveContextAwareRecordReader.java:116)\r\n         at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.doNextWithExceptionHandler(HadoopShimsSecure.java:228)\r\n         ... 17 more\r\n Caused by: java.lang.NullPointerException\r\n         at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.next(ParquetRecordReaderWrapper.java:206)\r\n         at org.apache.hadoop.hive.ql.io.parquet.VectorizedParquetInputFormat$VectorizedParquetRecordReader.next(VectorizedParquetInputFormat.java:118)\r\n         at org.apache.hadoop.hive.ql.io.parquet.VectorizedParquetInputFormat$VectorizedParquetRecordReader.next(VectorizedParquetInputFormat.java:51)\r\n         at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:350)\r\n         ... 21 more","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-08T01:13:50.857+0000","updated":"2018-02-08T01:17:06.061+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16356392","id":"16356392","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vihangk1","name":"vihangk1","key":"vihangk1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vihang Karajgaonkar","active":true,"timeZone":"America/Los_Angeles"},"body":"AFAIK {{hive.vectorized.use.row.serde.deserialize}} is not supported for Parquet. Does it fail if you set to false as well? Many fixes for Parquet vectorized reader went in 2.3.0. So it would be good to check using 2.3.0 if its possible.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vihangk1","name":"vihangk1","key":"vihangk1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vihang Karajgaonkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-08T02:32:46.576+0000","updated":"2018-02-08T02:32:46.576+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16356394","id":"16356394","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vihangk1","name":"vihangk1","key":"vihangk1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vihang Karajgaonkar","active":true,"timeZone":"America/Los_Angeles"},"body":"cc [~Ferd]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vihangk1","name":"vihangk1","key":"vihangk1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vihang Karajgaonkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-08T02:33:19.554+0000","updated":"2018-02-08T02:33:19.554+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16356612","id":"16356612","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=colinma","name":"colinma","key":"colinma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Colin Ma","active":true,"timeZone":"Etc/UTC"},"body":"[~vihangk1], [~KaiXu], I think this NPE problem is fixed in HIVE-15718 and HIVE-16465. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=colinma","name":"colinma","key":"colinma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Colin Ma","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-08T07:53:20.483+0000","updated":"2018-02-08T07:53:20.483+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16356734","id":"16356734","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~colinma] for the information. \r\nTo [~vihangk1], several queries(e.g. q22, q64, q75, q80, q85) of TPC-DS hits java.lang.OutOfMemoryError: Java heap space, when set to false. It's OK with TXT file, the configuration is the same.\r\n\r\njava.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.hadoop.hive.serde2.WriteBuffers.nextBufferToWrite(WriteBuffers.java:246)\r\n\tat org.apache.hadoop.hive.serde2.WriteBuffers.write(WriteBuffers.java:222)\r\n\tat org.apache.hadoop.hive.serde2.WriteBuffers.write(WriteBuffers.java:207)\r\n\tat org.apache.hadoop.hive.ql.exec.persistence.BytesBytesMultiHashMap.put(BytesBytesMultiHashMap.java:422)\r\n\tat org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.putRow(MapJoinBytesTableContainer.java:395)\r\n\tat org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.loadOptimized(MapJoinTableContainerSerDe.java:200)\r\n\tat org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.load(MapJoinTableContainerSerDe.java:152)\r\n\tat org.apache.hadoop.hive.ql.exec.spark.HashTableLoader.load(HashTableLoader.java:169)\r\n\tat org.apache.hadoop.hive.ql.exec.spark.HashTableLoader.load(HashTableLoader.java:148)\r\n\tat org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:315)\r\n\tat org.apache.hadoop.hive.ql.exec.MapJoinOperator$1.call(MapJoinOperator.java:187)\r\n\tat org.apache.hadoop.hive.ql.exec.MapJoinOperator$1.call(MapJoinOperator.java:183)\r\n\tat org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieve(ObjectCache.java:60)\r\n\tat org.apache.hadoop.hive.ql.exec.mr.ObjectCache.retrieveAsync(ObjectCache.java:68)\r\n\tat org.apache.hadoop.hive.ql.exec.ObjectCacheWrapper.retrieveAsync(ObjectCacheWrapper.java:51)\r\n\tat org.apache.hadoop.hive.ql.exec.MapJoinOperator.initializeOp(MapJoinOperator.java:181)\r\n\tat org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:366)\r\n\tat org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:556)\r\n\tat org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:508)\r\n\tat org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:376)\r\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.init(SparkReduceRecordHandler.java:200)\r\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.call(HiveReduceFunction.java:46)\r\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.call(HiveReduceFunction.java:28)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:185)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:185)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\r\n\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:105)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-08T09:44:36.343+0000","updated":"2018-02-08T09:44:36.343+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16357801","id":"16357801","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=colinma","name":"colinma","key":"colinma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Colin Ma","active":true,"timeZone":"Etc/UTC"},"body":"[~KaiXu], for the OOM problem, I think the fix in HIVE-16004 is related, you can verify it with that patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=colinma","name":"colinma","key":"colinma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Colin Ma","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-09T01:27:24.797+0000","updated":"2018-02-09T01:27:24.797+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12987289/comment/16357911","id":"16357911","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks, [~colinma]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=KaiXu","name":"KaiXu","key":"kaixu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"KaiXu","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T04:39:05.654+0000","updated":"2018-02-09T04:39:05.654+0000"}],"maxResults":8,"total":8,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14171/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i30mav:"}}