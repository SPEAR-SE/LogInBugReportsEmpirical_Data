{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12895251","self":"https://issues.apache.org/jira/rest/api/2/issue/12895251","key":"HIVE-11906","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-11-11T10:33:18.286+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Aug 02 07:10:15 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11906/watchers","watchCount":5,"isWatching":false},"created":"2015-09-21T21:01:51.148+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329278","id":"12329278","description":"Branch 1.0 release","name":"1.0.0","archived":false,"released":true,"releaseDate":"2015-02-04"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srinathsmn","name":"srinathsmn","key":"srinathsmn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Varadharajan","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-02T10:09:48.782+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320409","id":"12320409","name":"HCatalog","description":"Tracks issues related to the HCatalog"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12322671","id":"12322671","name":"Transactions","description":"Transaction management and ACID"}],"timeoriginalestimate":null,"description":"{noformat}\njava.lang.IllegalStateException: Attempting to flush a RecordUpdater on hdfs://127.0.0.1:9000/user/hive/warehouse/store_sales/dt=2015/delta_0003405_0003405/bucket_00000 with a single transaction.\n\tat org.apache.hadoop.hive.ql.io.orc.OrcRecordUpdater.flush(OrcRecordUpdater.java:341)\n\tat org.apache.hive.hcatalog.streaming.AbstractRecordWriter.flush(AbstractRecordWriter.java:124)\n\tat org.apache.hive.hcatalog.streaming.DelimitedInputWriter.flush(DelimitedInputWriter.java:49)\n\tat org.apache.hive.hcatalog.streaming.HiveEndPoint$TransactionBatchImpl.commitImpl(HiveEndPoint.java:723)\n\tat org.apache.hive.hcatalog.streaming.HiveEndPoint$TransactionBatchImpl.commit(HiveEndPoint.java:701)\n\tat org.apache.hive.acid.RueLaLaTest.test(RueLaLaTest.java:89)\n{noformat}\n\n{noformat}\npackage org.apache.hive.acid;\n\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.apache.hadoop.hive.common.JavaUtils;\nimport org.apache.hadoop.hive.conf.HiveConf;\nimport org.apache.hadoop.hive.ql.Driver;\nimport org.apache.hadoop.hive.ql.session.SessionState;\nimport org.apache.hive.hcatalog.streaming.DelimitedInputWriter;\nimport org.apache.hive.hcatalog.streaming.HiveEndPoint;\nimport org.apache.hive.hcatalog.streaming.StreamingConnection;\nimport org.apache.hive.hcatalog.streaming.TransactionBatch;\nimport org.junit.Test;\n\nimport java.net.URL;\nimport java.util.ArrayList;\nimport java.util.List;\n\n/**\n */\npublic class RueLaLaTest {\n  static final private Log LOG = LogFactory.getLog(RueLaLaTest.class);\n  @Test\n  public void test() throws Exception {\n    HiveConf.setHiveSiteLocation(new URL(\"file:///Users/ekoifman/dev/hwxhive/packaging/target/apache-hive-0.14.0-bin/apache-hive-0.14.0-bin/conf/hive-site.xml\"));\n    HiveConf hiveConf = new HiveConf(this.getClass());\n    final String workerName = \"test_0\";\n    SessionState.start(new SessionState(hiveConf));\n    Driver d = new Driver(hiveConf);\n    d.setMaxRows(200002);//make sure Driver returns all results\n    runStatementOnDriver(d, \"drop table if exists store_sales\");\n    runStatementOnDriver(d, \"create table store_sales\\n\" +\n      \"(\\n\" +\n      \"    ss_sold_date_sk           int,\\n\" +\n      \"    ss_sold_time_sk           int,\\n\" +\n      \"    ss_item_sk                int,\\n\" +\n      \"    ss_customer_sk            int,\\n\" +\n      \"    ss_cdemo_sk               int,\\n\" +\n      \"    ss_hdemo_sk               int,\\n\" +\n      \"    ss_addr_sk                int,\\n\" +\n      \"    ss_store_sk               int,\\n\" +\n      \"    ss_promo_sk               int,\\n\" +\n      \"    ss_ticket_number          int,\\n\" +\n      \"    ss_quantity               int,\\n\" +\n      \"    ss_wholesale_cost         decimal(7,2),\\n\" +\n      \"    ss_list_price             decimal(7,2),\\n\" +\n      \"    ss_sales_price            decimal(7,2),\\n\" +\n      \"    ss_ext_discount_amt       decimal(7,2),\\n\" +\n      \"    ss_ext_sales_price        decimal(7,2),\\n\" +\n      \"    ss_ext_wholesale_cost     decimal(7,2),\\n\" +\n      \"    ss_ext_list_price         decimal(7,2),\\n\" +\n      \"    ss_ext_tax                decimal(7,2),\\n\" +\n      \"    ss_coupon_amt             decimal(7,2),\\n\" +\n      \"    ss_net_paid               decimal(7,2),\\n\" +\n      \"    ss_net_paid_inc_tax       decimal(7,2),\\n\" +\n      \"    ss_net_profit             decimal(7,2)\\n\" +\n      \")\\n\" +\n      \" partitioned by (dt string)\\n\" +\n      \"clustered by (ss_store_sk, ss_promo_sk)\\n\" +\n      \"INTO 2 BUCKETS stored as orc TBLPROPERTIES ('orc.compress'='NONE', 'transactional'='true')\");\n\n    runStatementOnDriver(d, \"alter table store_sales add partition(dt='2015')\");\n    LOG.info(workerName + \" starting...\");\n    List<String> partitionVals = new ArrayList<String>();\n    partitionVals.add(\"2015\");\n    HiveEndPoint endPt = new HiveEndPoint(HiveConf.getVar(hiveConf, HiveConf.ConfVars.METASTOREURIS, \"thrift://localhost:9933\"), \"default\", \"store_sales\", partitionVals);\n    DelimitedInputWriter writer = new DelimitedInputWriter(new String[] {\"ss_sold_date_sk\",\"ss_sold_time_sk\", \"ss_item_sk\", \n      \"ss_customer_sk\", \"ss_cdemo_sk\", \"ss_hdemo_sk\", \"ss_addr_sk\", \"ss_store_sk\", \"ss_promo_sk\", \"ss_ticket_number\", \"ss_quantity\", \n      \"ss_wholesale_cost\", \"ss_list_price\", \"ss_sales_price\", \"ss_ext_discount_amt\", \"ss_ext_sales_price\", \"ss_ext_wholesale_cost\", \n      \"ss_ext_list_price\", \"ss_ext_tax\", \"ss_coupon_amt\", \"ss_net_paid\", \"ss_net_paid_inc_tax\", \"ss_net_profit\"},\",\", endPt);\n    StreamingConnection connection = endPt.newConnection(false, null);//should this really be null?\n\n    TransactionBatch txnBatch =  connection.fetchTransactionBatch(1, writer);\n    LOG.info(workerName + \" started txn batch\");\n    txnBatch.beginNextTransaction();\n    LOG.info(workerName + \" started commit txn \" + JavaUtils.txnIdToString(txnBatch.getCurrentTxnId()));\n\n    StringBuilder row = new StringBuilder();\n    for(int i = 0; i < 1; i++) {\n      for(int ints = 0; ints < 11; ints++) {\n        row.append(ints).append(',');\n      }\n      for(int decs = 0; decs < 12; decs++) {\n        row.append(i + 0.1).append(',');\n      }\n      row.setLength(row.length() - 1);\n      txnBatch.write(row.toString().getBytes());\n    }\n    txnBatch.commit();\n    txnBatch.close();\n    connection.close();\n  }\n  private List<String> runStatementOnDriver(Driver d, String stmt) throws Exception {\n    return AcidSystemTest.runStatementOnDriver(d, stmt);\n  }\n}\n{noformat}\n\nkey part being that TransactionBatch has size 1.  > 1 works OK.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"IllegalStateException: Attempting to flush a RecordUpdater on....bucket_00000 with a single transaction.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895251/comment/15000202","id":"15000202","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srinathsmn","name":"srinathsmn","key":"srinathsmn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Varadharajan","active":true,"timeZone":"Etc/UTC"},"body":"Any updates on this? I'm facing the same issue. \n\nPS: As of now, i using more than 1 transaction and hence fine.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srinathsmn","name":"srinathsmn","key":"srinathsmn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Varadharajan","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-11T10:33:18.286+0000","updated":"2015-11-11T10:33:18.286+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895251/comment/15096079","id":"15096079","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mikeskali","name":"mikeskali","key":"mikeskali","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"michael sklyar","active":true,"timeZone":"Etc/UTC"},"body":"Hmm, \nyou are currently assigned to this issue => do you plan to fix it?\n\nAnd yes, it is an annoying bug. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mikeskali","name":"mikeskali","key":"mikeskali","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"michael sklyar","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-13T11:59:55.590+0000","updated":"2016-01-13T11:59:55.590+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895251/comment/15096791","id":"15096791","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"this Exception is thrown for a reason.  In Streaming API use cases each TransactionBatch is expected to include > 1 transaction.\nCreating batches of size 1 is usually a mistake which causes a perf hit - this is what the exception is preventing.\n\nThe fix would be in TransactionBatchImpl to special case batches of size 1 to not call flush(), but like I said most likely this exception means you are not using API as it was meant to.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-13T18:56:31.233+0000","updated":"2016-01-13T18:56:31.233+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895251/comment/15403511","id":"15403511","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vmaroli","name":"vmaroli","key":"vmaroli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinuraj M","active":true,"timeZone":"Asia/Kolkata"},"body":"I am using Streaming ingest API to load files coming in at regular intervals from another system. The way I thought of implementing the file loading into Hive is to get one TransactionBatch instance and write the contents of one file using the single TransactionBatch instance obtained in single transaction. Basically trying to write one file contents in single transaction and commit it so that in case of an error I can always attempt to re-process the whole the file. \n\nCurrently I am working around the API by getting more than one transaction batches but using only one of those.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vmaroli","name":"vmaroli","key":"vmaroli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinuraj M","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-08-02T07:10:15.469+0000","updated":"2016-08-02T10:09:48.732+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11906/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2ld8v:"}}