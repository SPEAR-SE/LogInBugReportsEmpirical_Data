{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13039001","self":"https://issues.apache.org/jira/rest/api/2/issue/13039001","key":"HIVE-15756","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/10004","id":"10004","description":"Not A Bug","name":"Not A Bug"},"customfield_12312322":null,"customfield_12310220":"2017-02-21T18:12:29.516+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Aug 18 11:03:07 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_1890742395_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2017-02-21T18:14:09.429+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15756/watchers","watchCount":3,"isWatching":false},"created":"2017-01-30T21:01:47.069+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"}],"issuelinks":[{"id":"12494997","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12494997","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13041231","key":"HIVE-15844","self":"https://issues.apache.org/jira/rest/api/2/issue/13041231","fields":{"summary":"Make ReduceSinkOperator independent of Acid","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-08-18T11:03:07.524+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12322671","id":"12322671","name":"Transactions","description":"Transaction management and ACID"}],"timeoriginalestimate":null,"description":"Update and delete queries on ACID tables fail throwing ArrayIndexOutOfBoundsException.\n{noformat}\nhive> update customer_acid set c_comment = 'foo bar' where c_custkey % 100 = 1;\nQuery ID = cstm-hdfs_20170128005823_efa1cdb7-2ad2-4371-ac80-0e35868ad17c\nTotal jobs = 1\nLaunching Job 1 out of 1\nTez session was closed. Reopening...\nSession re-established.\n\n\nStatus: Running (Executing on YARN cluster with App id application_1485331877667_0036)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nMap 1 ..........   SUCCEEDED     14         14        0        0       0       0\nReducer 2             FAILED      1          0        0        1       1       0\n--------------------------------------------------------------------------------\nVERTICES: 01/02  [========================>>--] 93%   ELAPSED TIME: 23.68 s    \n--------------------------------------------------------------------------------\nStatus: Failed\nVertex failed, vertexName=Reducer 2, vertexId=vertex_1485331877667_0036_1_01, diagnostics=[Task failed, taskId=task_1485331877667_0036_1_01_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":72,\"bucketid\":1,\"rowid\":0}},\"value\":{\"_col0\":103601,\"_col1\":\"Customer#000103601\",\"_col2\":\"3cYSrJtAA36vth35 emuIk\",\"_col3\":20,\"_col4\":\"30-526-248-3190\",\"_col5\":8047.21,\"_col6\":\"MACHINERY \"}}\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:173)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:139)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:347)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:194)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:185)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:185)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:181)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":72,\"bucketid\":1,\"rowid\":0}},\"value\":{\"_col0\":103601,\"_col1\":\"Customer#000103601\",\"_col2\":\"3cYSrJtAA36vth35 emuIk\",\"_col3\":20,\"_col4\":\"30-526-248-3190\",\"_col5\":8047.21,\"_col6\":\"MACHINERY \"}}\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:284)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:252)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:150)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":72,\"bucketid\":1,\"rowid\":0}},\"value\":{\"_col0\":103601,\"_col1\":\"Customer#000103601\",\"_col2\":\"3cYSrJtAA36vth35 emuIk\",\"_col3\":20,\"_col4\":\"30-526-248-3190\",\"_col5\":8047.21,\"_col6\":\"MACHINERY \"}}\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:352)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:274)\n\t... 16 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 1\n\tat org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:780)\n\tat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:838)\n\tat org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:343)\n\t... 17 more\n]], Vertex did not succeed due to OWN_TASK_FAILURE, failedTasks:1 killedTasks:0, Vertex vertex_1485331877667_0036_1_01 [Reducer 2] killed/failed due to:OWN_TASK_FAILURE]\nDAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:0\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Reducer 2, vertexId=vertex_1485331877667_0036_1_01, diagnostics=[Task failed, taskId=task_1485331877667_0036_1_01_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":72,\"bucketid\":1,\"rowid\":0}},\"value\":{\"_col0\":103601,\"_col1\":\"Customer#000103601\",\"_col2\":\"3cYSrJtAA36vth35 emuIk\",\"_col3\":20,\"_col4\":\"30-526-248-3190\",\"_col5\":8047.21,\"_col6\":\"MACHINERY \"}}\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:173)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:139)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:347)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:194)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:185)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:185)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:181)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":72,\"bucketid\":1,\"rowid\":0}},\"value\":{\"_col0\":103601,\"_col1\":\"Customer#000103601\",\"_col2\":\"3cYSrJtAA36vth35 emuIk\",\"_col3\":20,\"_col4\":\"30-526-248-3190\",\"_col5\":8047.21,\"_col6\":\"MACHINERY \"}}\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:284)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:252)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:150)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":72,\"bucketid\":1,\"rowid\":0}},\"value\":{\"_col0\":103601,\"_col1\":\"Customer#000103601\",\"_col2\":\"3cYSrJtAA36vth35 emuIk\",\"_col3\":20,\"_col4\":\"30-526-248-3190\",\"_col5\":8047.21,\"_col6\":\"MACHINERY \"}}\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:352)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:274)\n\t... 16 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 1\n\tat org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:780)\n\tat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:838)\n\tat org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:343)\n\t... 17 more\n]], Vertex did not succeed due to OWN_TASK_FAILURE, failedTasks:1 killedTasks:0, Vertex vertex_1485331877667_0036_1_01 [Reducer 2] killed/failed due to:OWN_TASK_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:0\n{noformat}\n\n{noformat}\nhive> explain extended update customer_acid set c_comment = 'foo bar' where c_custkey % 100 = 1;\nOK\nABSTRACT SYNTAX TREE:\n  \nTOK_UPDATE_TABLE\n   TOK_TABNAME\n      customer_acid\n   TOK_SET_COLUMNS_CLAUSE\n      =\n         TOK_TABLE_OR_COL\n            c_comment\n         'foo bar'\n   TOK_WHERE\n      =\n         %\n            TOK_TABLE_OR_COL\n               c_custkey\n            100\n         1\n\n\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-2 depends on stages: Stage-1\n  Stage-0 depends on stages: Stage-2\n  Stage-3 depends on stages: Stage-0\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Tez\n      DagId: cstm-hdfs_20170128012834_4d41e184-1e40-443c-9990-147cfdc6ea15:5\n      Edges:\n        Reducer 2 <- Map 1 (SIMPLE_EDGE)\n      DagName: \n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: customer_acid\n                  filterExpr: ((c_custkey % 100) = 1) (type: boolean)\n                  Statistics: Num rows: 25219 Data size: 8700894 Basic stats: COMPLETE Column stats: NONE\n                  GatherStats: false\n                  Filter Operator\n                    isSamplingPred: false\n                    predicate: ((c_custkey % 100) = 1) (type: boolean)\n                    Statistics: Num rows: 12609 Data size: 4350274 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ROW__ID (type: struct<transactionid:bigint,bucketid:int,rowid:bigint>), c_custkey (type: int), c_name (type: string), c_address (type: string), c_nationkey (type: int), c_phone (type: char(15)), c_acctbal (type: decimal(15,2)), c_mktsegment (type: char(10))\n                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7\n                      Statistics: Num rows: 12609 Data size: 4350274 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: struct<transactionid:bigint,bucketid:int,rowid:bigint>)\n                        sort order: +\n                        Statistics: Num rows: 12609 Data size: 4350274 Basic stats: COMPLETE Column stats: NONE\n                        tag: -1\n                        value expressions: _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: char(15)), _col6 (type: decimal(15,2)), _col7 (type: char(10))\n                        auto parallelism: true\n            Path -> Alias:\n              hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid [customer_acid]\n            Path -> Partition:\n              hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid \n                Partition\n                  base file name: customer_acid\n                  input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n                  output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n                  properties:\n                    bucket_count 8\n                    bucket_field_name c_custkey\n                    columns c_custkey,c_name,c_address,c_nationkey,c_phone,c_acctbal,c_mktsegment,c_comment\n                    columns.comments \n                    columns.types int:string:string:int:char(15):decimal(15,2):char(10):string\n                    file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n                    file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n                    location hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid\n                    name tpch.customer_acid\n                    numFiles 12\n                    numRows 0\n                    rawDataSize 0\n                    serialization.ddl struct customer_acid { i32 c_custkey, string c_name, string c_address, i32 c_nationkey, char(15) c_phone, decimal(15,2) c_acctbal, char(10) c_mktsegment, string c_comment}\n                    serialization.format 1\n                    serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde\n                    totalSize 8700894\n                    transactional true\n                    transient_lastDdlTime 1485548417\n                  serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde\n                \n                    input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n                    output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n                    properties:\n                      bucket_count 8\n                      bucket_field_name c_custkey\n                      columns c_custkey,c_name,c_address,c_nationkey,c_phone,c_acctbal,c_mktsegment,c_comment\n                      columns.comments \n                      columns.types int:string:string:int:char(15):decimal(15,2):char(10):string\n                      file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n                      file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n                      location hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid\n                      name tpch.customer_acid\n                      numFiles 12\n                      numRows 0\n                      rawDataSize 0\n                      serialization.ddl struct customer_acid { i32 c_custkey, string c_name, string c_address, i32 c_nationkey, char(15) c_phone, decimal(15,2) c_acctbal, char(10) c_mktsegment, string c_comment}\n                      serialization.format 1\n                      serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde\n                      totalSize 8700894\n                      transactional true\n                      transient_lastDdlTime 1485548417\n                    serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde\n                    name: tpch.customer_acid\n                  name: tpch.customer_acid\n            Truncated Path -> Alias:\n              /tpch.db/customer_acid [customer_acid]\n        Reducer 2 \n            Needs Tagging: false\n            Reduce Operator Tree:\n              Select Operator\n                expressions: KEY.reducesinkkey0 (type: struct<transactionid:bigint,bucketid:int,rowid:bigint>), VALUE._col0 (type: int), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: int), VALUE._col4 (type: char(15)), VALUE._col5 (type: decimal(15,2)), VALUE._col6 (type: char(10)), 'foo bar' (type: string)\n                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8\n                Statistics: Num rows: 12609 Data size: 4350274 Basic stats: COMPLETE Column stats: NONE\n                File Output Operator\n                  compressed: false\n                  GlobalTableId: 1\n                  directory: hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid/.hive-staging_hive_2017-01-28_01-28-34_547_5091220054599015088-1/-ext-10000\n                  NumFilesPerFileSink: 1\n                  Statistics: Num rows: 12609 Data size: 4350274 Basic stats: COMPLETE Column stats: NONE\n                  Stats Publishing Key Prefix: hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid/.hive-staging_hive_2017-01-28_01-28-34_547_5091220054599015088-1/-ext-10000/\n                  table:\n                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n                      properties:\n                        bucket_count 8\n                        bucket_field_name c_custkey\n                        columns c_custkey,c_name,c_address,c_nationkey,c_phone,c_acctbal,c_mktsegment,c_comment\n                        columns.comments \n                        columns.types int:string:string:int:char(15):decimal(15,2):char(10):string\n                        file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n                        file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n                        location hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid\n                        name tpch.customer_acid\n                        numFiles 12\n                        numRows 0\n                        rawDataSize 0\n                        serialization.ddl struct customer_acid { i32 c_custkey, string c_name, string c_address, i32 c_nationkey, char(15) c_phone, decimal(15,2) c_acctbal, char(10) c_mktsegment, string c_comment}\n                        serialization.format 1\n                        serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde\n                        totalSize 8700894\n                        transactional true\n                        transient_lastDdlTime 1485548417\n                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde\n                      name: tpch.customer_acid\n                  TotalFiles: 1\n                  GatherStats: true\n                  MultiFileSpray: false\n\n  Stage: Stage-2\n    Dependency Collection\n\n  Stage: Stage-0\n    Move Operator\n      tables:\n          replace: false\n          source: hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid/.hive-staging_hive_2017-01-28_01-28-34_547_5091220054599015088-1/-ext-10000\n          table:\n              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n              properties:\n                bucket_count 8\n                bucket_field_name c_custkey\n                columns c_custkey,c_name,c_address,c_nationkey,c_phone,c_acctbal,c_mktsegment,c_comment\n                columns.comments \n                columns.types int:string:string:int:char(15):decimal(15,2):char(10):string\n                file.inputformat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\n                file.outputformat org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\n                location hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid\n                name tpch.customer_acid\n                numFiles 12\n                numRows 0\n                rawDataSize 0\n                serialization.ddl struct customer_acid { i32 c_custkey, string c_name, string c_address, i32 c_nationkey, char(15) c_phone, decimal(15,2) c_acctbal, char(10) c_mktsegment, string c_comment}\n                serialization.format 1\n                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde\n                totalSize 8700894\n                transactional true\n                transient_lastDdlTime 1485548417\n              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde\n              name: tpch.customer_acid\n\n  Stage: Stage-3\n    Stats-Aggr Operator\n      Stats Aggregation Key Prefix: hdfs://hive-acid-upgrade-issue-5.openstacklocal:8020/apps/hive/warehouse/tpch.db/customer_acid/.hive-staging_hive_2017-01-28_01-28-34_547_5091220054599015088-1/-ext-10000/\n\nTime taken: 0.422 seconds, Fetched: 189 row(s)\n\n{noformat}\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Update/deletes on ACID table throws ArrayIndexOutOfBoundsException","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kavansuresh%40gmail.com","name":"kavansuresh@gmail.com","key":"kavansuresh@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kavan Suresh","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kavansuresh%40gmail.com","name":"kavansuresh@gmail.com","key":"kavansuresh@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kavan Suresh","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13039001/comment/15845918","id":"15845918","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kavansuresh%40gmail.com","name":"kavansuresh@gmail.com","key":"kavansuresh@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kavan Suresh","active":true,"timeZone":"Etc/UTC"},"body":"Another occurrence of the issue:\n{code:java}\n0: jdbc:hive2://tesths2-merge-ks-1.openstackl> merge into lineitem using (select * from lineitem_stage WHERE L_ORDERKEY%2=1) sub on sub.L_ORDERKEY = lineitem.L_ORDERKEY when matched then delete;\nINFO  : Session is already open\nINFO  : Dag name: merge into lineitem using (select *...delete(Stage-1)\nINFO  : Setting tez.task.scale.memory.reserve-fraction to 0.30000001192092896\nINFO  : \n\nINFO  : Status: Running (Executing on YARN cluster with App id application_1485398058799_0109)\n\nINFO  : Map 1: -/-\tMap 3: 0/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+1)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+2)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+3)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+4)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+6)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+7)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+9)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 0(+10)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0/5\tMap 3: 1(+9)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+1)/5\tMap 3: 1(+9)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+1)/5\tMap 3: 1(+9)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+1)/5\tMap 3: 2(+8)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+2)/5\tMap 3: 2(+8)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+2)/5\tMap 3: 2(+8)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+2)/5\tMap 3: 2(+8)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+2)/5\tMap 3: 2(+8)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+2)/5\tMap 3: 2(+8)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+2)/5\tMap 3: 4(+6)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+4)/5\tMap 3: 4(+6)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+4)/5\tMap 3: 6(+4)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+5)/5\tMap 3: 6(+4)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+5)/5\tMap 3: 7(+3)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+5)/5\tMap 3: 8(+2)/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+5)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+5)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 0(+5)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 1(+4)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 2(+3)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 2(+2)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 3(+2)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 3(+2)/5\tMap 3: 10/10\tReducer 2: 0/2\t\nINFO  : Map 1: 4(+1)/5\tMap 3: 10/10\tReducer 2: 0/1\t\nINFO  : Map 1: 4(+1)/5\tMap 3: 10/10\tReducer 2: 0(+1)/1\t\nINFO  : Map 1: 5/5\tMap 3: 10/10\tReducer 2: 0(+1)/1\t\nINFO  : Map 1: 5/5\tMap 3: 10/10\tReducer 2: 0(+1,-1)/1\t\nINFO  : Map 1: 5/5\tMap 3: 10/10\tReducer 2: 0(+1,-2)/1\t\nINFO  : Map 1: 5/5\tMap 3: 10/10\tReducer 2: 0(+1,-3)/1\t\nERROR : Status: Failed\nERROR : Vertex failed, vertexName=Reducer 2, vertexId=vertex_1485398058799_0109_3_02, diagnostics=[Task failed, taskId=task_1485398058799_0109_3_02_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":38,\"bucketid\":1,\"rowid\":0}},\"value\":null}\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:173)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:139)\n\tat org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:347)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:194)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:185)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:185)\n\tat org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:181)\n\tat org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":38,\"bucketid\":1,\"rowid\":0}},\"value\":null}\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:284)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:266)\n\tat org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:150)\n\t... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":38,\"bucketid\":1,\"rowid\":0}},\"value\":null}\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:352)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:274)\n\t... 16 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 1\n\tat org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:780)\n\tat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:841)\n\tat org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)\n\tat org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:343)\n\t... 17 more\n{code}\nHs2 logs:\n{code:java}\n2017-01-26 22:13:20,924 INFO  [HiveServer2-Background-Pool: Thread-648]: log.PerfLogger (PerfLogger.java:PerfLogEnd(177)) - </PERFLOG method=TezRunVertex.Map 1 start=1485468754798 end=1485468800924 duration=46126 from=org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor>\n2017-01-26 22:13:20,925 INFO  [HiveServer2-Background-Pool: Thread-648]: SessionState (SessionState.java:printInfo(971)) - Map 1: 5/5   Map 3: 10/10    Reducer 2: 0(+1)/1\n2017-01-26 22:13:22,744 INFO  [HiveServer2-Background-Pool: Thread-648]: SessionState (SessionState.java:printInfo(971)) - Map 1: 5/5   Map 3: 10/10    Reducer 2: 0(+1,-1)/1\n2017-01-26 22:13:24,369 INFO  [HiveServer2-Background-Pool: Thread-648]: SessionState (SessionState.java:printInfo(971)) - Map 1: 5/5   Map 3: 10/10    Reducer 2: 0(+1,-2)/1\n2017-01-26 22:13:26,194 INFO  [HiveServer2-Background-Pool: Thread-648]: SessionState (SessionState.java:printInfo(971)) - Map 1: 5/5   Map 3: 10/10    Reducer 2: 0(+1,-3)/1\n2017-01-26 22:13:28,221 ERROR [HiveServer2-Background-Pool: Thread-648]: SessionState (SessionState.java:printError(980)) - Status: Failed\n2017-01-26 22:13:28,222 ERROR [HiveServer2-Background-Pool: Thread-648]: SessionState (SessionState.java:printError(980)) - Vertex failed, vertexName=Reducer 2, vertexId=vertex_1485398058799_0108_2_02, diagnostics=[Task failed, taskId=task_1485398058799_0108_2_02_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":38,\"bucketid\":1,\"rowid\":0}},\"value\":null}\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:173)\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:139)\n        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:347)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:194)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:185)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:185)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:181)\n        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":38,\"bucketid\":1,\"rowid\":0}},\"value\":null}\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:284)\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:266)\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:150)\n        ... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":38,\"bucketid\":1,\"rowid\":0}},\"value\":null}\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:352)\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:274)\n        ... 16 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 1\n        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:780)\n        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:841)\n        at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:343)\n        ... 17 more\n\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kavansuresh%40gmail.com","name":"kavansuresh@gmail.com","key":"kavansuresh@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kavan Suresh","active":true,"timeZone":"Etc/UTC"},"created":"2017-01-30T21:05:22.149+0000","updated":"2017-01-30T21:06:41.468+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13039001/comment/15876413","id":"15876413","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"this is caused by hive.enforce.bucketing=false, which is not supported (i.e. misconfiguration).  In fact, this property doesn't even exist in Hive 2.2","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-21T18:12:29.516+0000","updated":"2017-02-21T18:12:49.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13039001/comment/16132063","id":"16132063","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ankur555varshney%40gmail.com","name":"ankur555varshney@gmail.com","key":"ankur555varshney@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ankur varshney","active":true,"timeZone":"Etc/UTC"},"body":"Hi Team,\n\nPlease let us the work around for this issue.\n\nHive Vesion:-hive-2.1\nI can see error in logs ,But in yarn it is showing Succeeded. Please let us\nknow why it is showing succeeded if it has error in yarn logs.\n\nError Details:-\n\n2017-08-18 01:43:23,877 [ERROR] [TezChild] |tez.ReduceRecordSource|:\norg.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while\nprocessing row (tag=0)\n{\"key\":{\"reducesinkkey0\":{\"transactionid\":0,\"bucketid\":-1,\"rowid\":0}},\"value\":null}\n        at\norg.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:357)\n        at\norg.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:279)\n        at\norg.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:279)\n        at\norg.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:185)\n        at\norg.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)\n        at\norg.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)\n        at\norg.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)\n        at\norg.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at\norg.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1595)\n        at\norg.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)\n        at\norg.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)\n        at\norg.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:744)\nCaused by: java.lang.ArrayIndexOutOfBoundsException: -1\n        at\norg.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:779)\n        at\norg.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:879)\n        at\norg.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:95)\n        at\norg.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:348)\n        ... 17 more\n\nThanks\nAnkur\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ankur555varshney%40gmail.com","name":"ankur555varshney@gmail.com","key":"ankur555varshney@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ankur varshney","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-18T11:03:07.396+0000","updated":"2017-08-18T11:03:07.396+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15756/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i39dxj:"}}