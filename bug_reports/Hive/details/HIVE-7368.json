{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12726199","self":"https://issues.apache.org/jira/rest/api/2/issue/12726199","key":"HIVE-7368","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-09-10T01:57:24.355+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Nov 03 09:37:42 UTC 2014","customfield_12310420":"404306","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7368/watchers","watchCount":4,"isWatching":false},"created":"2014-07-08T22:12:26.612+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-11-03T09:37:42.145+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312584","id":"12312584","name":"Metastore","description":"Tracks issue dealing with metastore."}],"timeoriginalestimate":null,"description":"I investigated a scenario wherein a user needed to use a large number of concurrent hive clients doing simple DDL tasks, while not using a standalone metastore server. Say, for eg., each of them doing \"drop table if exists tmp_blah_${i};\"\n\nThis would consistently fail stating that it could not create a db, which is a funny error to have when trying to drop a db \"if exists\". On digging in, it turned out that the error was a mistaken report, coming instead from an attempt by the embedded metastore attempting to create a \"default\" db when it did not exist. The funny thing being that the default db did exist, and the getDatabase call would return empty, rather than returning an error or returning a result. We could disable hive.metastore.checkForDefaultDb and the number of these reports would drastically fall, but that only moved the problem, and we'd get phantom reports from time to time of various other databases that existed that were being reported as non-existent.\n\nOn digging further, parallelism seemed to be an important factor in whether or not hive was able to perform getDatabases without error. With about 20 simultaneous processes, there seemed to be no errors whatsoever. At about 40 simultaneous processes, at least 1 would consistently fail. At about 200, about 15-20 would consistently fail, in addition to taking a long time to run.\n\nI wrote a sample JDBC ping (actually a get_database mimic) utility to see whether the issue was with connecting from that machine to the database server, and this had no errors whatsoever up to 400 simultaneous processes. The mysql server in question was configured to serve up to 650 connections, and it seemed to be serving responses quickly and did not seem overloaded. We also disabled connection pooling in case that was exacerbating a connection availability issue with that many concurrent processes, each with an embedded metastore. That, especially in conjunction with disabling schema checking, and specifying a \"datanucleus.connectionPool.testSQL=SELECT 1\" did a fair amount for performance in this scenarios, but the errors (or rather, the null-result-successes when there shouldn't have been one) continued.\n\nOn checking through hive again, if we modified hive to have datanucleus simply return a connection, with which we did a direct sql get database, there would not be any error, but if we tried to use jdo on datanucleus to construct a db object, we would get an empty result, so the issue seems to crop up in the jdo mapping.\n\nOne of the biggest issues with this investigation, for me, was the difficulty of reproducibility. When trying to reproduce in a lab, we were unable to create a similar enough environment that caused the issue. Even in the client's environment, moving from RHEL5 to RHEL6 made the issue go away.\n\nThus, we still have work to do on determining the underlying issue, I'm logging this issue to collect information on similar issues we discover so we can work towards nailing down the issue and then fixing it(in DN if need be)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"404346","customfield_12312823":null,"summary":"datanucleus sometimes returns an empty result instead of an error or data","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12726199/comment/14127931","id":"14127931","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=selinazh","name":"selinazh","key":"selinazh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=selinazh&avatarId=19244","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=selinazh&avatarId=19244","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=selinazh&avatarId=19244","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=selinazh&avatarId=19244"},"displayName":"Selina Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Sush,\n\nMy feeling for the root cause probably is not as same as yours. Just want to provide another possibility. Please correct me if I am wrong. \n\nExist databases(tables) were reported as non-exist: This is due to the connection to db (mysql/oracle) was bounced back due to the connection pool is small and the thread waiting time is too short. Currently this \"internal error\" exception was mistakenly casted to NoSuchObjectException. We have to fix the misleading error message. ( \n\nParallelism execution: This is due to meta store usually hold connections for a very long time because lots of drop/add/alter operations have HDFS operations involved. Sometimes the table stats also are collected during the window. And connections to db is not shared by the meta store clients. So the best practice for parallelism is increasing the size of connection pools(DBCP for example). The db load is not heavy at all, we can utilize the concurrency of existing RDBMS. DirectSQL get_database definitely will hold connection for much less time than ORM get_database, so the connection shortage problem may not be obvious. \n\nI think \"datanucleus.connectionPool.testSQL=SELECT 1\" is the validation query for DBCP to validate the underneath connection to RDBMS. Have it set DBCP will guarantee the connection each time we borrow from the connection pool is valid. \n\nThanks,\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=selinazh","name":"selinazh","key":"selinazh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=selinazh&avatarId=19244","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=selinazh&avatarId=19244","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=selinazh&avatarId=19244","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=selinazh&avatarId=19244"},"displayName":"Selina Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T01:57:24.355+0000","updated":"2014-09-10T01:57:24.355+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12726199/comment/14170041","id":"14170041","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Selina,\n\nYes, I would agree that the connection pool (or jdbc driver, since I've since been able to see this happening a couple of times with DBCP as well) is probably raising some sort of internal error that is being incorrectly read as normal operation by DN, which results in a NSOE by the hive ObjectStore. I definitely agree that this is the underlying error that we need to reproduce and track down to fix.\n\nIn the case of a persistent remote metastore, I would agree that increasing the size of the connection pools makes sense, and should be the way to go. I generally do advise a larger pool, and always going through the metastore. \n\nBut in the case of parallel hive fatclients, the embedded metastore is effectively single-threaded w.r.t to connections to the database, so I'm afraid I don't yet understand how having a larger pool would help in this case. Could you please expand on this bit?\n\n(And yes, \"datanucleus.connectionPool.testSQL=SELECT 1\" is so that the overhead of DN testing connectivity to the db is minimized - without that, DN creates a bunch of deleteme* tables and drops them to test connectivity.)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-13T21:39:05.957+0000","updated":"2014-10-13T21:39:05.957+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12726199/comment/14194386","id":"14194386","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andy","name":"andy","key":"andy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andy Jefferson","active":true,"timeZone":"Etc/UTC"},"body":"\"DN creates a bunch of deleteme* tables ...\"\nIt creates a _single_ DELETEME* table _when_ the RDBMS doesn't provide another mechanism for checking the catalog/schema in use _per PMF_ (and it isn't 'testing connectivity'). The only way there will be \"a bunch\" is if the application is using multiple PMFs (why would it need multiple), and even then the cost of a create/drop of a DELETEME table is so insignificant compared to the overall PMF startup cost.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andy","name":"andy","key":"andy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andy Jefferson","active":true,"timeZone":"Etc/UTC"},"created":"2014-11-03T09:37:42.145+0000","updated":"2014-11-03T09:37:42.145+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7368/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1xkzb:"}}