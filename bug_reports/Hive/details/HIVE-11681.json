{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12859921","self":"https://issues.apache.org/jira/rest/api/2/issue/12859921","key":"HIVE-11681","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-12-21T10:30:01.449+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jul 27 17:05:39 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11681/watchers","watchCount":18,"isWatching":false},"created":"2015-08-28T13:37:05.946+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"}],"issuelinks":[{"id":"12436863","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12436863","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12630265","key":"HIVE-3969","self":"https://issues.apache.org/jira/rest/api/2/issue/12630265","fields":{"summary":"Session state for hive server should be cleaned-up","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/5","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/trivial.svg","name":"Trivial","id":"5"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-07-27T17:05:39.086+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320408","id":"12320408","name":"HiveServer2","description":"Tracks issues related to HiveServer2"}],"timeoriginalestimate":null,"description":"sometimes the hiveserver will throw below exception , \n\n2015-08-28 05:05:44,107 | FATAL | Thread-82995 | error parsing conf mapred-default.xml | org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2404)\njava.io.IOException: Stream closed\n\tat java.util.zip.InflaterInputStream.ensureOpen(InflaterInputStream.java:84)\n\tat java.util.zip.InflaterInputStream.read(InflaterInputStream.java:160)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat com.sun.org.apache.xerces.internal.impl.XMLEntityManager$RewindableInputStream.read(XMLEntityManager.java:2902)\n\tat com.sun.org.apache.xerces.internal.impl.io.UTF8Reader.read(UTF8Reader.java:302)\n\tat com.sun.org.apache.xerces.internal.impl.XMLEntityScanner.load(XMLEntityScanner.java:1753)\n\tat com.sun.org.apache.xerces.internal.impl.XMLEntityScanner.skipChar(XMLEntityScanner.java:1426)\n\tat com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2807)\n\tat com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)\n\tat com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)\n\tat com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)\n\tat com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)\n\tat com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)\n\tat com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)\n\tat com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)\n\tat com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)\n\tat javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)\n\tat org.apache.hadoop.conf.Configuration.parse(Configuration.java:2246)\n\tat org.apache.hadoop.conf.Configuration.parse(Configuration.java:2234)\n\tat org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2305)\n\tat org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2258)\n\tat org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2175)\n\tat org.apache.hadoop.conf.Configuration.get(Configuration.java:854)\n\tat org.apache.hadoop.mapred.JobConf.checkAndWarnDeprecation(JobConf.java:2069)\n\tat org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:477)\n\tat org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:467)\n\tat org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:187)\n\tat org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:580)\n\tat org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:578)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1612)\n\tat org.apache.hadoop.mapred.JobClient.getJobUsingCluster(JobClient.java:578)\n\tat org.apache.hadoop.mapred.JobClient.getJob(JobClient.java:596)\n\tat org.apache.hadoop.hive.ql.exec.mr.HadoopJobExecHelper.progress(HadoopJobExecHelper.java:289)\n\tat org.apache.hadoop.hive.ql.exec.mr.HadoopJobExecHelper.progress(HadoopJobExecHelper.java:548)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:435)\n\tat org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:159)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:72)\n\n\nafter analysis, we found the root cause, below is step to reproduce the issue\n1.  open one beeline window, add jar\n2.  execute one sql like create table abc as select * from t1;\n3.  execute !quit, before this add a breakpoint at java.net.URLClassLoader.close(), so it will stop here\n\n4. open another beeline window\n5. execute one sql like select count(*) from t1, before this add one condition breakpoint at org.apache.hadoop.conf.Configuration.parse, the condition is url.toString().indexOf(\"hadoop-mapreduce-client-core-V100R001C00.jar!/mapred-default.xml\")>0\n6. when proceed to the above step, just get the stream\n7. let the 3th step go ahead, which will close the stream\n8. now, let sixth step go ahead, then the above exception coming\n\nsuggest solution:\nthe issue is hadppend when client use add jar + short connection ,  the client app should try best to use long connection, means reuse hive connetion\n\nmeanwhile, here ,experts can suggest good solution for this issue\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"sometimes when query mr job progress, stream closed exception will happen","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12859921/comment/14736752","id":"14736752","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"body":"below is the stacktrace  that stream be cached in the URLClassloader when load TaskCounter.properties in hadoop-mapreduce-client-core.jar\n\nThread [Thread-31585] (Suspended (breakpoint at line 239 in URLClassLoader))\t\n\towns: WeakHashMap<K,V>  (id=2282)\t\n\towns: Class<T> (org.apache.hadoop.mapreduce.util.ResourceBundles) (id=1456)\t\n\towns: Counters  (id=2283)\t\n\tURLClassLoader.getResourceAsStream(String) line: 239\t\n\tResourceBundle$Control$1.run() line: 2601 [local variables unavailable]\t\n\tResourceBundle$Control$1.run() line: 2586\t\n\tAccessController.doPrivileged(PrivilegedExceptionAction<T>) line: not available [native method]\t\n\tResourceBundle$Control.newBundle(String, Locale, String, ClassLoader, boolean) line: 2585\t\n\tResourceBundle.loadBundle(CacheKey, List<String>, Control, boolean) line: 1436\t\n\tResourceBundle.findBundle(CacheKey, List<Locale>, List<String>, int, Control, ResourceBundle) line: 1400\t\n\tResourceBundle.findBundle(CacheKey, List<Locale>, List<String>, int, Control, ResourceBundle) line: 1354\t\n\tResourceBundle.findBundle(CacheKey, List<Locale>, List<String>, int, Control, ResourceBundle) line: 1354\t\n\tResourceBundle.getBundleImpl(String, Locale, ClassLoader, ResourceBundle$Control) line: 1296\t\n\tResourceBundle.getBundle(String, Locale, ClassLoader) line: 1028\t\n\tResourceBundles.getBundle(String) line: 37\t\n\tResourceBundles.getValue(String, String, String, T) line: 56\t\n\tResourceBundles.getCounterGroupName(String, String) line: 77\t\n\tCounters$GroupFactory(CounterGroupFactory<C,G>).newGroup(String, Limits) line: 94\t\n\tCounters(AbstractCounters<C,G>).getGroup(String) line: 226\t\n\tCounters.getGroup(String) line: 113\t\n\tCounters.findCounter(String, String) line: 479\t\n\tHadoopJobExecHelper.progress(HadoopJobExecHelper$ExecDriverTaskHandle) line: 347\t\n\tHadoopJobExecHelper.progress(RunningJob, JobClient, HiveTxnManager) line: 548\t\n\tMapRedTask(ExecDriver).execute(DriverContext) line: 435\t\n\tMapRedTask.execute(DriverContext) line: 159\t\n\tMapRedTask(Task<T>).executeTask() line: 153\t\n\tTaskRunner.runSequential() line: 85\t\n\tTaskRunner.run() line: 72\n\n\nbelow is the stacktrace that steam is closed:\njava.util.zip.InflaterInputStream.getStack(InflaterInputStream.java:309)\njava.util.zip.InflaterInputStream.close(InflaterInputStream.java:247)\njava.util.zip.ZipFile$ZipFileInflaterInputStream.close(ZipFile.java:398)\njava.util.zip.ZipFile.close(ZipFile.java:585)\nsun.net.www.protocol.jar.URLJarFile.close(URLJarFile.java:167)\njava.net.URLClassLoader.close(URLClassLoader.java:294)\norg.apache.hadoop.hive.common.JavaUtils.closeClassLoader(JavaUtils.java:101)\norg.apache.hadoop.hive.common.JavaUtils.closeClassLoadersTo(JavaUtils.java:79)\norg.apache.hadoop.hive.ql.session.SessionState.close(SessionState.java:942)\norg.apache.hive.service.cli.session.HiveSessionImpl.close(HiveSessionImpl.java:562)\n\n\nso here the root cause is that:  add jar will lead to new classloader created, and it will cache the JarFile ,  but JarFile in jvm only has one instance(see JarURLConnection.setUseCache), so when other thread is read from the same JarFile, once hive session closed will lead to classloader close the stream.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenli","name":"wenli","key":"wenli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangwenli","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-09T12:18:48.037+0000","updated":"2015-09-09T12:18:48.037+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12859921/comment/15766706","id":"15766706","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ssubhas","name":"ssubhas","key":"ssubhas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sindhu Subhas","active":true,"timeZone":"Asia/Kolkata"},"body":"The issue is related to Java Bugs:\nhttp://bugs.java.com/view_bug.do?bug_id=7087947\nhttp://bugs.java.com/bugdatabase/view_bug.do?bug_id=7194301","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ssubhas","name":"ssubhas","key":"ssubhas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sindhu Subhas","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-12-21T10:30:01.449+0000","updated":"2016-12-21T10:30:01.449+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12859921/comment/15809285","id":"15809285","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gdosi%40zaloni.com","name":"gdosi@zaloni.com","key":"gdosi@zaloni.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Garima Dosi","active":true,"timeZone":"Asia/Kolkata"},"body":"I thought this was more of a multi-threading concurrency related issue where one hive job is trying to access a JAR which has been closed by another hive job which completed execution and was using the same session level jar. And hence HS2 directly sends a KILL signal to an MR job which was submitted and is IN PROGRESS. So, \n1. Can we not solve the problem by maintaining ClassLoader counts and checking the counts before closing the loaders in JavaUtils class' closeClassLoader method?\n2. Can we change settings related to JarURLConnection.setUseCache while class loading?\n\nAs a temporary solution for this issue, we stopped using \"add jar\" for concurrent hive jobs. Instead added the auxiliary jars in Hive's classpath at the time of HS2 service start. This ensures that the class is loaded only once and is not closed unless HS2 is shutdown and hence it is available to all sessions and jobs.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gdosi%40zaloni.com","name":"gdosi@zaloni.com","key":"gdosi@zaloni.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Garima Dosi","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-01-08T12:10:49.042+0000","updated":"2017-01-08T12:10:49.042+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12859921/comment/15823819","id":"15823819","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anishek","name":"anishek","key":"anishek","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"anishek","active":true,"timeZone":"Asia/Kolkata"},"body":"Adding another scenario which can lead so similar errors.\n\n* add hive config to hive-site.xml -- > hive.downloaded.resources.dir = /tmp/download \n* start hiverserver2\n* put a jar with a hive udf class on hdfs location /tmp/someudf.jar . Assume hive udf class is 'org.someorg.hive.udf.TextUDF'\n* on beeline start a session as user 1 ==>   add jar hdfs://tmp/someudf.jar; create temporary function userOneFun as 'org.someorg.hive.udf.TextUDF';\n* on beeline start another session as user 2 ==> add jar hdfs://tmp/someudf.jar;\n* close session of user 1\n* on session of user 2 ==>  create temporary function userTwoFun as 'org.someorg.hive.udf.TextUDF';  ==> throws error with ClassNotFound.\n\nIt doesnt throw any error relating to the stream closed but seems to be because of same JarUrlConnection for different class loaders and then one of them is closed. Since the underlying location is same due to setting hive.download.resources.dir . The default value for this config sets is correctly by additionally doing {code}File.separator + \"${hive.session.id}_resources\" {code}. It would be great to do this programmatically in SessionState Constructor to create the correct resourceDownloader. \n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anishek","name":"anishek","key":"anishek","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"anishek","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-01-16T11:43:24.685+0000","updated":"2017-01-16T11:43:24.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12859921/comment/15853425","id":"15853425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=muxin","name":"muxin","key":"muxin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"muxin","active":true,"timeZone":"Asia/Chongqing"},"body":"https://issues.apache.org/jira/browse/HADOOP-12404\nthis post might be a decent solution","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=muxin","name":"muxin","key":"muxin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"muxin","active":true,"timeZone":"Asia/Chongqing"},"created":"2017-02-06T01:23:10.077+0000","updated":"2017-02-06T05:26:29.174+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12859921/comment/15853552","id":"15853552","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gdosi%40zaloni.com","name":"gdosi@zaloni.com","key":"gdosi@zaloni.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Garima Dosi","active":true,"timeZone":"Asia/Kolkata"},"body":"Yes disabling jar cache seems to be a viable option.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gdosi%40zaloni.com","name":"gdosi@zaloni.com","key":"gdosi@zaloni.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Garima Dosi","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-02-06T05:41:09.179+0000","updated":"2017-02-06T05:41:09.179+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12859921/comment/16103506","id":"16103506","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=franluo","name":"franluo","key":"franluo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"frank luo","active":true,"timeZone":"America/Chicago"},"body":"https://issues.apache.org/jira/browse/HADOOP-13809 is a similar case.\n\nI believe they are all related to https://bugs.openjdk.java.net/browse/JDK-6947916, which hasn't been released.\n\nI am able to recreate it with oracle jdk 1.8.0_131.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=franluo","name":"franluo","key":"franluo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"frank luo","active":true,"timeZone":"America/Chicago"},"created":"2017-07-27T17:05:39.086+0000","updated":"2017-07-27T17:05:39.086+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11681/votes","votes":8,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2ji13:"}}