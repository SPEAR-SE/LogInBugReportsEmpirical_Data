{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12466184","self":"https://issues.apache.org/jira/rest/api/2/issue/12466184","key":"HIVE-1391","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2010-12-25T16:14:17.574+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Mar 24 17:12:19 UTC 2011","customfield_12310420":"72928","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_17633779764_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2010-12-25T16:14:17.653+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-1391/watchers","watchCount":5,"isWatching":false},"created":"2010-06-04T13:57:57.889+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314156","id":"12314156","description":"released","name":"0.5.0","archived":false,"released":true,"releaseDate":"2010-02-23"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-03-24T17:12:19.098+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312584","id":"12312584","name":"Metastore","description":"Tracks issue dealing with metastore."}],"timeoriginalestimate":null,"description":"When I have tried to use MS-SQL2005 as the hive metastore I have encountered numerous issues.\n\nMy configuration:\n\nproperty>\n  <name>javax.jdo.option.ConnectionURL</name>\n <value>jdbc:sqlserver://cwdbint05:1445;DatabaseName=HiveMetastore;</value>\n  <description>JDBC connect string for a JDBC metastore</description>\n</property>\n\n<property>\n  <name>javax.jdo.option.ConnectionDriverName</name>\n  <value>com.microsoft.sqlserver.jdbc.SQLServerDriver</value>\n  <description>Driver class name for a JDBC metastore</description>\n</property>\n\n<property>\n  <name>javax.jdo.option.ConnectionUserName</name>\n  <value>HiveUser</value>\n  <description>username to use against metastore database</description>\n</property>\n\n<property>\n  <name>javax.jdo.option.ConnectionPassword</name>\n  <value>XXXXXXXXXXXXXX</value>\n  <description>password to use against metastore database</description>\n</property>\n\n<property>\n  <name>datanucleus.autoCreateSchema</name>\n  <value>true</value>\n  <description>creates necessary schema on a startup if one doesn't exist. set this to false, after creating it once</description>\n</property>\n\n\nHive user has full rights to the HiveMetastore DB.\n---------------------------------------------------------------------\n\nWhen launching hive on command line and executing \"show tables;\" i got the following:\n\nFAILED: Error in metadata: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\nNestedThrowables:\njava.lang.reflect.InvocationTargetException\nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask\n\n\nWhen launching hive through the Java API (org.apache.commons.cli.CommandLine) the auto create kicked in but failed with the following (Full stack trace attached to ticket):\n\n[2010-06-04 09:22:11,817] ERROR (Log4JLogger.java:115) - Error thrown executing ALTER TABLE COLUMNS ADD TYPE_NAME varchar(128) NOT NULL : Cannot find the object \"COLUMNS\" because it does not exist or you do not have permissions.\ncom.microsoft.sqlserver.jdbc.SQLServerException: Cannot find the object \"COLUMNS\" because it does not exist or you do not have permissions.\n\tat com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:196)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement.getNextResult(SQLServerStatement.java:1454)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement.doExecuteStatement(SQLServerStatement.java:786)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement$StmtExecCmd.doExecute(SQLServerStatement.java:685)\n\tat com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:4026)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:1416)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement.executeCommand(SQLServerStatement.java:185)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement.executeStatement(SQLServerStatement.java:160)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement.execute(SQLServerStatement.java:658)\n\tat org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatement(AbstractTable.java:730)\n\tat org.datanucleus.store.rdbms.table.AbstractTable.executeDdlStatementList(AbstractTable.java:681)\n\tat org.datanucleus.store.rdbms.table.TableImpl.validateColumns(TableImpl.java:261)\n\tat org.datanucleus.store.rdbms.RDBMSManager$ClassAdder.performTablesValidation(RDBMSManager.java:2794)\n\tat org.datanucleus.store.rdbms.RDBMSManager$ClassAdder.addClassTablesAndValidate(RDBMSManager.java:2595)\n\tat org.datanucleus.store.rdbms.RDBMSManager$ClassAdder.run(RDBMSManager.java:2241)\n\tat org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:113)\n\tat org.datanucleus.store.rdbms.RDBMSManager.addClasses(RDBMSManager.java:994)\n\tat org.datanucleus.store.rdbms.RDBMSManager.addClasses(RDBMSManager.java:960)\n\tat org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:691)\n\tat org.datanucleus.store.mapped.MappedStoreManager.getDatastoreClass(MappedStoreManager.java:358)\n\tat org.datanucleus.store.rdbms.RDBMSManager.getExtent(RDBMSManager.java:1344)\n\tat org.datanucleus.ObjectManagerImpl.getExtent(ObjectManagerImpl.java:3736)\n\tat org.datanucleus.store.rdbms.query.JDOQLQueryCompiler.compileCandidates(JDOQLQueryCompiler.java:411)\n\tat org.datanucleus.store.rdbms.query.QueryCompiler.executionCompile(QueryCompiler.java:312)\n\tat org.datanucleus.store.rdbms.query.JDOQLQueryCompiler.compile(JDOQLQueryCompiler.java:225)\n\tat org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:174)\n\tat org.datanucleus.store.query.Query.executeQuery(Query.java:1443)\n\tat org.datanucleus.store.rdbms.query.JDOQLQuery.executeQuery(JDOQLQuery.java:244)\n\tat org.datanucleus.store.query.Query.executeWithArray(Query.java:1357)\n\tat org.datanucleus.jdo.JDOQuery.execute(JDOQuery.java:265)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:551)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:494)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:397)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table(HiveMetaStore.java:353)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:340)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:308)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:293)\n\tat com.contextweb.hive.lookup.LookupDumper.createTable(LookupDumper.java:179)\n\tat com.contextweb.hive.lookup.LookupDumper.execute(LookupDumper.java:122)\n\tat com.contextweb.hive.cli.QueryCommand.runImpl(QueryCommand.java:142)\n\tat com.contextweb.hive.cli.HiveSessionAwareCommand.run(HiveSessionAwareCommand.java:48)\n\tat com.contextweb.hive.cli.Launcher.exec(Launcher.java:78)\n\tat com.contextweb.hive.cli.Launcher.main(Launcher.java:46)\n\n\nAt this point in time I have looked at what hive done to my DB and I saw that it created the following tables:\nDBS\nNUCLEUS_TABLES\nSEQUENCE_TABLE\n\nThe table COLUMS does not exist and the alter statement is failing (Makes sense)\n\nSo I went ahead and created the table with the needed column:\nCREATE TABLE COLUMNS (TYPE_NAME varchar(128) NOT NULL)\n\nWhen I ran hive again with the CLI the auto create managed to complete creation this time but during the run failed with the following:\n\n[2010-06-04 09:54:38,787] INFO  (SemanticAnalyzer.java:5399) - Creating tablelookup_CampaignId positin=22\nFAILED: Error in metadata: javax.jdo.JDODataStoreException: Add request failed : INSERT INTO COLUMNS (SD_ID,COMMENT,\"COLUMN_NAME\",TYPE_NAME,INTEGER_IDX) VALUES (?,?,?,?,?) \nNestedThrowables:\njava.sql.BatchUpdateException: Invalid column name 'COLUMN_NAME'.\n[2010-06-04 09:54:39,158] ERROR (SessionState.java:248) - FAILED: Error in metadata: javax.jdo.JDODataStoreException: Add request failed : INSERT INTO COLUMNS (SD_ID,COMMENT,\"COLUMN_NAME\",TYPE_NAME,INTEGER_IDX) VALUES (?,?,?,?,?) \nNestedThrowables:\njava.sql.BatchUpdateException: Invalid column name 'COLUMN_NAME'.\norg.apache.hadoop.hive.ql.metadata.HiveException: javax.jdo.JDODataStoreException: Add request failed : INSERT INTO COLUMNS (SD_ID,COMMENT,\"COLUMN_NAME\",TYPE_NAME,INTEGER_IDX) VALUES (?,?,?,?,?) \nNestedThrowables:\njava.sql.BatchUpdateException: Invalid column name 'COLUMN_NAME'.\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:281)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:1281)\n\tat org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:119)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:99)\n\tat com.contextweb.hive.session.HiveQuery.exec(HiveQuery.java:112)\n\tat com.contextweb.hive.lookup.LookupDumper.createTable(LookupDumper.java:201)\n\tat com.contextweb.hive.lookup.LookupDumper.execute(LookupDumper.java:122)\n\tat com.contextweb.hive.cli.QueryCommand.runImpl(QueryCommand.java:142)\n\tat com.contextweb.hive.cli.HiveSessionAwareCommand.run(HiveSessionAwareCommand.java:48)\n\tat com.contextweb.hive.cli.Launcher.exec(Launcher.java:78)\n\tat com.contextweb.hive.cli.Launcher.main(Launcher.java:46)\nCaused by: javax.jdo.JDODataStoreException: Add request failed : INSERT INTO COLUMNS (SD_ID,COMMENT,\"COLUMN_NAME\",TYPE_NAME,INTEGER_IDX) VALUES (?,?,?,?,?) \nNestedThrowables:\njava.sql.BatchUpdateException: Invalid column name 'COLUMN_NAME'.\n\tat org.datanucleus.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:289)\n\tat org.datanucleus.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:673)\n\tat org.datanucleus.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:693)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.createTable(ObjectStore.java:458)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table(HiveMetaStore.java:321)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:254)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:275)\n\t... 10 more\nCaused by: java.sql.BatchUpdateException: Invalid column name 'COLUMN_NAME'.\n\tat com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.executeBatch(SQLServerPreparedStatement.java:1132)\n\tat org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:573)\n\tat org.datanucleus.store.rdbms.SQLController.executeStatementUpdate(SQLController.java:366)\n\tat org.datanucleus.store.rdbms.scostore.RDBMSJoinListStoreSpecialization.internalAdd(RDBMSJoinListStoreSpecialization.java:425)\n\tat org.datanucleus.store.mapped.scostore.JoinListStore.internalAdd(JoinListStore.java:239)\n\tat org.datanucleus.store.mapped.scostore.AbstractListStore.addAll(AbstractListStore.java:128)\n\tat org.datanucleus.store.mapped.mapping.CollectionMapping.postInsert(CollectionMapping.java:157)\n\tat org.datanucleus.store.rdbms.request.InsertRequest.execute(InsertRequest.java:515)\n\tat org.datanucleus.store.rdbms.RDBMSPersistenceHandler.insertTable(RDBMSPersistenceHandler.java:200)\n\tat org.datanucleus.store.rdbms.RDBMSPersistenceHandler.insertObject(RDBMSPersistenceHandler.java:179)\n\tat org.datanucleus.state.JDOStateManagerImpl.internalMakePersistent(JDOStateManagerImpl.java:3097)\n\tat org.datanucleus.state.JDOStateManagerImpl.makePersistent(JDOStateManagerImpl.java:3073)\n\tat org.datanucleus.ObjectManagerImpl.persistObjectInternal(ObjectManagerImpl.java:1280)\n\tat org.datanucleus.store.mapped.mapping.PersistenceCapableMapping.setObjectAsValue(PersistenceCapableMapping.java:604)\n\tat org.datanucleus.store.mapped.mapping.PersistenceCapableMapping.setObject(PersistenceCapableMapping.java:364)\n\tat org.datanucleus.store.rdbms.fieldmanager.ParameterSetter.storeObjectField(ParameterSetter.java:197)\n\tat org.datanucleus.state.AbstractStateManager.providedObjectField(AbstractStateManager.java:1011)\n\tat org.apache.hadoop.hive.metastore.model.MTable.jdoProvideField(MTable.java)\n\tat org.apache.hadoop.hive.metastore.model.MTable.jdoProvideFields(MTable.java)\n\tat org.datanucleus.state.JDOStateManagerImpl.provideFields(JDOStateManagerImpl.java:2627)\n\tat org.datanucleus.store.rdbms.request.InsertRequest.execute(InsertRequest.java:294)\n\tat org.datanucleus.store.rdbms.RDBMSPersistenceHandler.insertTable(RDBMSPersistenceHandler.java:200)\n\tat org.datanucleus.store.rdbms.RDBMSPersistenceHandler.insertObject(RDBMSPersistenceHandler.java:179)\n\tat org.datanucleus.state.JDOStateManagerImpl.internalMakePersistent(JDOStateManagerImpl.java:3097)\n\tat org.datanucleus.state.JDOStateManagerImpl.makePersistent(JDOStateManagerImpl.java:3073)\n\tat org.datanucleus.ObjectManagerImpl.persistObjectInternal(ObjectManagerImpl.java:1280)\n\tat org.datanucleus.ObjectManagerImpl.persistObject(ObjectManagerImpl.java:1157)\n\tat org.datanucleus.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:668)\n\t... 15 more\n\n\nSeems like the autocreate forgot to create the column \"COLUMN_NAME\" \n\nI have again ran the command manually in my db:\nALTER TABLE COLUMNS ADD COLUMN_NAME varchar(256) NOT NULL\n\nAt this point I was able to run the hive through the CLI successfully but running \"show tables;\" from the command line still give me:\nFAILED: Error in metadata: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory\nNestedThrowables:\njava.lang.reflect.InvocationTargetException\nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask\n\nPlease contact me if you need further information.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12446347","id":"12446347","filename":"hive-trace.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arov","name":"arov","key":"arov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"Alex Rovner","active":true,"timeZone":"America/New_York"},"created":"2010-06-04T13:58:46.106+0000","size":69217,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12446347/hive-trace.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"123058","customfield_12312823":null,"summary":"Various issues when using MS-SQL2005 as the Hive Metastore","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arov","name":"arov","key":"arov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"Alex Rovner","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arov","name":"arov","key":"arov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"Alex Rovner","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466184/comment/12975068","id":"12975068","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"body":"This is not an attempt to pass the buck.\n\nWe do not officially support any particular RDBMS. However we defacto support Derby and MySQL. \nhttp://www.datanucleus.org/products/accessplatform/rdbms/support.html \nDatanucleus claims to support ms-sql2005 so maybe the issue should be taken up there. We have at least proved we are doing something correct by working with two of their other supported databases.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2010-12-25T16:14:17.574+0000","updated":"2010-12-25T16:14:17.574+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466184/comment/13010624","id":"13010624","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andyr","name":"andyr","key":"andyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andy R","active":true,"timeZone":"Etc/UTC"},"body":"Hi, did anyone have much resolving this issue?\n\nI’m also experiencing this issue with SQL server 2005. I’ve enabled DEBUG logging for DataNucleus & JPOX in hive-log4j.properies and can see that the table COLUMNS (and other tables) create statement is never executed. Is this a DataNucleus problem or is this because Hive is not issuing the create table statement? I thought if this was a DataNucleus problem then the logs would show a create table COLUMNS  exception but I can not see the statement even being executed?\n\nAny thoughts much appreciated.\n\nMany thanks,\n\nAndy.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andyr","name":"andyr","key":"andyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andy R","active":true,"timeZone":"Etc/UTC"},"created":"2011-03-24T10:38:41.103+0000","updated":"2011-03-24T10:38:41.103+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466184/comment/13010628","id":"13010628","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andyr","name":"andyr","key":"andyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andy R","active":true,"timeZone":"Etc/UTC"},"body":"One thing i did notice in the logs ....\n\n2011-03-24 10:06:58,561 DEBUG Datastore.Schema (Log4JLogger.java:debug(58)) - Check of existence of COLUMNS returned table type of VIEW\n\n... so hive (or data nucleus?) does not try to create the table. I can confim that SQL server has a default COLUMNS view on our database. Any ideas how to work around this with Hive if this is a DataNucleus issue?\n\nThanks, Andy. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andyr","name":"andyr","key":"andyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andy R","active":true,"timeZone":"Etc/UTC"},"created":"2011-03-24T10:58:54.935+0000","updated":"2011-03-24T10:58:54.935+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466184/comment/13010768","id":"13010768","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cwsteinbach","name":"cwsteinbach","key":"cwsteinbach","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Carl Steinbach","active":true,"timeZone":"America/Los_Angeles"},"body":"From what I understand SQLServer has the notion of a \"default schema\" (usually dbo) which is used to resolve identifiers that are not defined in a user's current schema. I think you need to either undefine the default schema for your metastore user account, or else make it point to the metastore schema.\n\nHere are some relevant links with more information:\n\nhttp://msdn.microsoft.com/en-us/library/ms190387.aspx\nhttp://stackoverflow.com/questions/3806245/sql-server-schema-and-default-schema\nhttp://dba.fyicenter.com/faq/sql_server_2/Default_Schema_of_Your_Login_Session.html\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cwsteinbach","name":"cwsteinbach","key":"cwsteinbach","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Carl Steinbach","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-03-24T17:12:19.057+0000","updated":"2011-03-24T17:12:19.057+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-1391/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0lev3:"}}