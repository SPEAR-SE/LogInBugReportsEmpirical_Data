{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12692598","self":"https://issues.apache.org/jira/rest/api/2/issue/12692598","key":"HIVE-6347","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324744","id":"12324744","description":"Dev branch for Tez","name":"tez-branch","archived":false,"released":false}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-02-01T12:46:01.154+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jan 20 21:03:17 UTC 2016","customfield_12310420":"371193","customfield_12312320":null,"customfield_12310222":"10002_*:*_3_*:*_2174199434_*|*_1_*:*_3_*:*_26415644_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-02-26T08:51:32.939+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6347/watchers","watchCount":8,"isWatching":false},"created":"2014-01-31T21:34:37.906+0000","customfield_12310192":"ZeroCopy readers for the ORC file format","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"5.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324744","id":"12324744","description":"Dev branch for Tez","name":"tez-branch","archived":false,"released":false}],"issuelinks":[{"id":"12382505","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12382505","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"outwardIssue":{"id":"12693495","key":"HIVE-6382","self":"https://issues.apache.org/jira/rest/api/2/issue/12693495","fields":{"summary":"PATCHED_BLOB encoding in ORC will corrupt data in some cases","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12382288","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12382288","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12692595","key":"HIVE-6346","self":"https://issues.apache.org/jira/rest/api/2/issue/12692595","fields":{"summary":"Add Hadoop-2.4.0 shims to hive-tez","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12382287","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12382287","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12673900","key":"HADOOP-10047","self":"https://issues.apache.org/jira/rest/api/2/issue/12673900","fields":{"summary":"Add a directbuffer Decompressor API to hadoop","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12383588","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12383588","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12693000","key":"HIVE-6360","self":"https://issues.apache.org/jira/rest/api/2/issue/12693000","fields":{"summary":"Hadoop 2.3 + Tez 0.3","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12382289","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12382289","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12655836","key":"HDFS-4949","self":"https://issues.apache.org/jira/rest/api/2/issue/12655836","fields":{"summary":"Centralized cache management in HDFS","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12383067","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12383067","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12695381","key":"HDFS-5957","self":"https://issues.apache.org/jira/rest/api/2/issue/12695381","fields":{"summary":"Provide support for different mmap cache retention policies in ShortCircuitCache.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-01-20T21:03:17.722+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320633","id":"12320633","name":"File Formats","description":"File Formats"}],"timeoriginalestimate":null,"description":"ORC can use the new HDFS Caching APIs and the ZeroCopy readers to avoid extra data copies into memory while scanning files.\n\nImplement ORC zcr codepath and a hive.orc.zerocopy flag.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12626451","id":"12626451","filename":"HIVE-6347.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-01T04:42:23.266+0000","size":26117,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12626451/HIVE-6347.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12629191","id":"12629191","filename":"HIVE-6347.2-tez.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-15T03:06:48.125+0000","size":27267,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12629191/HIVE-6347.2-tez.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12629192","id":"12629192","filename":"HIVE-6347.3-tez.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-15T03:12:12.454+0000","size":27186,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12629192/HIVE-6347.3-tez.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12629484","id":"12629484","filename":"HIVE-6347.4-tez.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-18T06:35:40.892+0000","size":27018,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12629484/HIVE-6347.4-tez.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12631167","id":"12631167","filename":"HIVE-6347.5-tez.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-26T07:28:25.073+0000","size":24710,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12631167/HIVE-6347.5-tez.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"371496","customfield_12312823":null,"summary":"ZeroCopy read path for ORC RecordReader","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13888456","id":"13888456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"Patch which applies over HIVE-6346 on hive/tez branch","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-01T04:42:23.271+0000","updated":"2014-02-01T04:42:23.271+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13888559","id":"13888559","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"The patch adds *hive.orc.zerocopy* to HiveConf.java, so it also needs to document the flag in hive-default.xml.template.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2014-02-01T12:46:01.154+0000","updated":"2014-02-01T12:46:01.154+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13888587","id":"13888587","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12626451/HIVE-6347.1.patch\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1151/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1151/console\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:399:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:399:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:399:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:399:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:399:5: \nDecision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW\" using multiple alternatives: 2, 9\n\nAs a result, alternative(s) 9 were disabled for that input\nwarning(200): IdentifiersParser.g:524:5: \nDecision can match input such as \"{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}\" using multiple alternatives: 1, 3\n\nAs a result, alternative(s) 3 were disabled for that input\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 1546 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[21,48] cannot find symbol\nsymbol  : class DirectDecompressorShim\nlocation: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[23,48] cannot find symbol\nsymbol  : class DirectCompressionType\nlocation: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[51,48] cannot find symbol\nsymbol  : class ByteBufferPoolShim\nlocation: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[52,48] cannot find symbol\nsymbol  : class ZeroCopyReaderShim\nlocation: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[100,64] cannot find symbol\nsymbol  : class ByteBufferPoolShim\nlocation: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[96,17] cannot find symbol\nsymbol  : class ZeroCopyReaderShim\nlocation: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[27,48] cannot find symbol\nsymbol  : class DirectCompressionType\nlocation: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[28,48] cannot find symbol\nsymbol  : class DirectDecompressorShim\nlocation: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[82,11] cannot find symbol\nsymbol  : variable DirectCompressionType\nlocation: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[94,5] cannot find symbol\nsymbol  : class DirectDecompressorShim\nlocation: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[95,32] cannot find symbol\nsymbol  : variable DirectCompressionType\nlocation: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[153,5] method does not override or implement a method from a supertype\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[165,5] method does not override or implement a method from a supertype\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[228,45] cannot find symbol\nsymbol  : method getZeroCopyReader(org.apache.hadoop.fs.FSDataInputStream,org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.ByteBufferAllocatorPool)\nlocation: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[95,11] cannot find symbol\nsymbol  : variable DirectCompressionType\nlocation: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[107,5] cannot find symbol\nsymbol  : class DirectDecompressorShim\nlocation: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[108,32] cannot find symbol\nsymbol  : variable DirectCompressionType\nlocation: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec\n[INFO] 17 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [4.645s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [6.787s]\n[INFO] Hive Shims Common ................................. SUCCESS [3.329s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [2.245s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [2.600s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [1.428s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [3.198s]\n[INFO] Hive Shims ........................................ SUCCESS [0.590s]\n[INFO] Hive Common ....................................... SUCCESS [7.734s]\n[INFO] Hive Serde ........................................ SUCCESS [8.743s]\n[INFO] Hive Metastore .................................... SUCCESS [26.982s]\n[INFO] Hive Query Language ............................... FAILURE [40.846s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:52.063s\n[INFO] Finished at: Sat Feb 01 08:39:12 EST 2014\n[INFO] Final Memory: 55M/422M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[21,48] cannot find symbol\n[ERROR] symbol  : class DirectDecompressorShim\n[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[23,48] cannot find symbol\n[ERROR] symbol  : class DirectCompressionType\n[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[51,48] cannot find symbol\n[ERROR] symbol  : class ByteBufferPoolShim\n[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[52,48] cannot find symbol\n[ERROR] symbol  : class ZeroCopyReaderShim\n[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[100,64] cannot find symbol\n[ERROR] symbol  : class ByteBufferPoolShim\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[96,17] cannot find symbol\n[ERROR] symbol  : class ZeroCopyReaderShim\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[27,48] cannot find symbol\n[ERROR] symbol  : class DirectCompressionType\n[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[28,48] cannot find symbol\n[ERROR] symbol  : class DirectDecompressorShim\n[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[82,11] cannot find symbol\n[ERROR] symbol  : variable DirectCompressionType\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[94,5] cannot find symbol\n[ERROR] symbol  : class DirectDecompressorShim\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/SnappyCodec.java:[95,32] cannot find symbol\n[ERROR] symbol  : variable DirectCompressionType\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.SnappyCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[153,5] method does not override or implement a method from a supertype\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[165,5] method does not override or implement a method from a supertype\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java:[228,45] cannot find symbol\n[ERROR] symbol  : method getZeroCopyReader(org.apache.hadoop.fs.FSDataInputStream,org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.ByteBufferAllocatorPool)\n[ERROR] location: interface org.apache.hadoop.hive.shims.HadoopShims\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[95,11] cannot find symbol\n[ERROR] symbol  : variable DirectCompressionType\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[107,5] cannot find symbol\n[ERROR] symbol  : class DirectDecompressorShim\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec\n[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ZlibCodec.java:[108,32] cannot find symbol\n[ERROR] symbol  : variable DirectCompressionType\n[ERROR] location: class org.apache.hadoop.hive.ql.io.orc.ZlibCodec\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12626451","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-02-01T13:39:13.801+0000","updated":"2014-02-01T13:39:13.801+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13888658","id":"13888658","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"There are a number of cases there the if contains a negation\nbut there is an else condition. Thse should be swapped:\n\ne.g\n\nif (!bool) else => if (bool) else\n\n{noformat}\n+      if(zcr != null) {\n+        while(len > 0) {\n+          ByteBuffer partial = zcr.readBuffer(len, false);\n+          result.add(new BufferChunk(partial, off));\n+          int read = partial.remaining();\n+          len -= read;\n+          off += read;\n+        }\n+      } else {\n{noformat}\n\n{noformat}\n+      if (ShimLoader.getHadoopShims().getDirectDecompressor(\n+          DirectCompressionType.SNAPPY) != null) {\n+        direct = Boolean.valueOf(true);\n+      } else {\n+        direct = Boolean.valueOf(false);\n+      }\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-02-01T17:51:05.903+0000","updated":"2014-02-01T17:51:05.903+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13892600","id":"13892600","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"[~leftylev]: I will add the docs into the hive-site.xml in the next rev - was waiting for HIVE-6346 to get pushed to branch.\n\n[~brocknoland]: a != null is actually positive test, because it implies there exists something (i.e it's presence). That is how rest of the ORC code deals with optional feature/args (like SARGs).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-05T21:38:53.798+0000","updated":"2014-02-05T21:38:53.798+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13902298","id":"13902298","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"Address comments on review board (& added docs)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-15T03:06:48.130+0000","updated":"2014-02-15T03:06:48.130+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13902800","id":"13902800","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"munmap() is async and delayed action","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-02-16T19:55:15.366+0000","updated":"2014-02-16T19:55:15.366+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/13912652","id":"13912652","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to branch. Thanks [~gopalv]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hagleitn","name":"hagleitn","key":"hagleitn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hagleitn&avatarId=16035","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hagleitn&avatarId=16035","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hagleitn&avatarId=16035","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hagleitn&avatarId=16035"},"displayName":"Gunther Hagleitner","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-02-26T08:51:32.976+0000","updated":"2014-02-26T08:51:32.976+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/14021861","id":"14021861","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"*hive.exec.orc.zerocopy* is documented in hive-default.xml.template as of Hive 0.13.0 with the description \"Use zerocopy reads with ORC.\" See HIVE-6360.\n\nIn the wiki its description has been expanded to \"Use zerocopy reads with ORC. (This requires Hadoop 2.3 or later.)\"\n\n* [Configuration Properties: hive.exec.orc.zerocopy | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.exec.orc.zerocopy]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2014-06-09T10:21:51.268+0000","updated":"2014-06-09T10:21:51.268+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/15108883","id":"15108883","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sztanko","name":"sztanko","key":"sztanko","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Demeter Sztanko","active":true,"timeZone":"Etc/UTC"},"body":"Hello,\nI am running my cluster on Hadoop 2.7.1 (checksum fc0a1a23fc1868e4d5ee7fa2b28a58a), using Hive 1.2.1 (checksum ab480aca41b24a9c3751b8c023338231) and hive.exec.orc.zerocopy tends to cause failures.\nAll my hive queries run fines, but once I enable zerocopy, it seems to have some problems with native libraries:\n\n{code}\nset hive.exec.orc.zerocopy = true;\n<execute my query>\nHadoop job information for Stage-1: number of mappers: 316; number of reducers: 90\n2016-01-20 16:37:54,479 Stage-1 map = 0%,  reduce = 0%\n2016-01-20 16:38:21,061 Stage-1 map = 100%,  reduce = 100%\n2016-01-20 16:39:21,246 Stage-1 map = 100%,  reduce = 100%\nEnded Job = job_1452780282075_23380 with errors\nError during job, obtaining debugging information...\nDiagnostic Messages for this Task:\nError: java.io.IOException: java.lang.reflect.InvocationTargetException\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)\n\tat org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:266)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.<init>(HadoopShimsSecure.java:213)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getRecordReader(HadoopShimsSecure.java:333)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getRecordReader(CombineHiveInputFormat.java:719)\n\tat org.apache.hadoop.mapred.MapTask$TrackedRecordReader.<init>(MapTask.java:169)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:252)\n\t... 11 more\nCaused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect()I\n\tat org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect(Native Method)\n\tat org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressDirect(SnappyDecompressor.java:305)\n\tat org.apache.hadoop.io.compress.snappy.SnappyDecompressor$SnappyDirectDecompressor.decompress(SnappyDecompressor.java:341)\n\tat org.apache.hadoop.hive.shims.ZeroCopyShims$DirectDecompressorAdapter.decompress(ZeroCopyShims.java:101)\n\tat org.apache.hadoop.hive.ql.io.orc.SnappyCodec.directDecompress(SnappyCodec.java:100)\n\tat org.apache.hadoop.hive.ql.io.orc.SnappyCodec.decompress(SnappyCodec.java:67)\n\tat org.apache.hadoop.hive.ql.io.orc.InStream$CompressedStream.readHeader(InStream.java:214)\n\tat org.apache.hadoop.hive.ql.io.orc.InStream$CompressedStream.read(InStream.java:227)\n\tat org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReaderV2.readValues(RunLengthIntegerReaderV2.java:54)\n\tat org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReaderV2.next(RunLengthIntegerReaderV2.java:302)\n\tat org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StringDictionaryTreeReader.readDictionaryLengthStream(TreeReaderFactory.java:1674)\n\tat org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StringDictionaryTreeReader.startStripe(TreeReaderFactory.java:1654)\n\tat org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StringTreeReader.startStripe(TreeReaderFactory.java:1382)\n\tat org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.startStripe(TreeReaderFactory.java:2040)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.readStripe(RecordReaderImpl.java:795)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.advanceStripe(RecordReaderImpl.java:986)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.advanceToNextRow(RecordReaderImpl.java:1019)\n\tat org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.<init>(RecordReaderImpl.java:205)\n\tat org.apache.hadoop.hive.ql.io.orc.ReaderImpl.rowsOptions(ReaderImpl.java:539)\n\tat org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat$VectorizedOrcRecordReader.<init>(VectorizedOrcInputFormat.java:71)\n\tat org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat.getRecordReader(VectorizedOrcInputFormat.java:156)\n\tat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.createVectorizedReader(OrcInputFormat.java:1088)\n\tat org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:1102)\n\tat org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:67)\n\t... 16 more\n\nContainer killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 143\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sztanko","name":"sztanko","key":"sztanko","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Demeter Sztanko","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-20T16:46:14.842+0000","updated":"2016-01-20T16:46:14.842+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/15109350","id":"15109350","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"{code}\nCaused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.compress.snappy.SnappyDecompressor.decompressBytesDirect()I\n{code}\n\nDoes look like the tasks are not able to locate the libhadoop.so binary (*or* the hadoop build was done without snappy-dev available).\n\nZero copy readers don't work if libhadoop.so is missing anyway.\n\nBut to fill in some later developments, turning on zerocopy=true needs cluster-wide configs to turn on YARN-1775.\n\nThe YARN memory counting counts memory-mapped files as container memory, so without that change you might see containers being killed for using too much memory as you scale past the terabyte levels.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-01-20T20:38:06.900+0000","updated":"2016-01-20T20:38:06.900+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12692598/comment/15109401","id":"15109401","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sztanko","name":"sztanko","key":"sztanko","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Demeter Sztanko","active":true,"timeZone":"Etc/UTC"},"body":"Thanks, [~gopalv],\nSeems like tasks are not able to locate the libhadoop, indeed. However, they were able to do that when zerocopy was disabled (I am using snappy compression in my orc tables) and perform well. libhadoop.so and libsnappy are there and I never had any problem with those. This makes me think that there is a correlation between finding native libraries and zerocopy.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sztanko","name":"sztanko","key":"sztanko","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Demeter Sztanko","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-20T21:03:17.722+0000","updated":"2016-01-20T21:03:17.722+0000"}],"maxResults":12,"total":12,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6347/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1rz1b:"}}