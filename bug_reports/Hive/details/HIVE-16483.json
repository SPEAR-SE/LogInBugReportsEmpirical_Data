{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13065218","self":"https://issues.apache.org/jira/rest/api/2/issue/13065218","key":"HIVE-16483","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-04-19T22:27:32.240+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 22 23:59:48 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_285322_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_416455925","customfield_12312321":null,"resolutiondate":"2017-04-24T16:57:27.082+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16483/watchers","watchCount":3,"isWatching":false},"created":"2017-04-19T21:11:45.886+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-22T23:59:48.194+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"There are several split related configurations, such as {{MAPREDMINSPLITSIZE}}, {{MAPREDMINSPLITSIZEPERNODE}}, {{MAPREDMINSPLITSIZEPERRACK}}, etc., that should be populated to HiveConf. Currently we only do this for {{MAPREDMINSPLITSIZE}}.\nAll the others, if not set, will be using the default value, which is 1.\n\nWithout these, Spark sometimes will not merge small files for file formats such as text.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12864647","id":"12864647","filename":"HIVE-16483.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-22T18:19:21.654+0000","size":2447,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12864647/HIVE-16483.1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"HoS should populate split related configurations to HiveConf","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/15975652","id":"15975652","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 pending on test results.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-19T22:27:32.240+0000","updated":"2017-04-19T22:27:32.240+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/15977016","id":"15977016","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"Re-attach patch to trigger test.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-20T16:27:16.070+0000","updated":"2017-04-20T16:27:16.070+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/15977022","id":"15977022","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12864304/HIVE-16483.1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4794/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4794/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4794/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-04-20 16:28:51.796\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4794/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-04-20 16:28:51.799\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at fa24d4b HIVE-16317 CASE .. NULL in JOIN condition can trigger SemanticException (Remus Rusanu, reviewed by Ashutosh Chauhan)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at fa24d4b HIVE-16317 CASE .. NULL in JOIN condition can trigger SemanticException (Remus Rusanu, reviewed by Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-04-20 16:28:52.850\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nDataNucleus Enhancer (version 4.1.17) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nDataNucleus Enhancer completed with success for 30 classes. Timings : input=177 ms, enhance=217 ms, total=394 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g\norg/apache/hadoop/hive/ql/parse/HintParser.g\nGenerating vector expression code\nGenerating vector expression test code\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java:[323,40] ')' expected\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java:[323,40] ')' expected\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12864304 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-04-20T16:29:56.624+0000","updated":"2017-04-20T16:29:56.624+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/15979419","id":"15979419","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12864555/HIVE-16483.1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4828/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4828/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4828/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-04-21 21:28:51.197\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4828/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-04-21 21:28:51.200\n+ cd apache-github-source-source\n+ git fetch origin\nFrom https://github.com/apache/hive\n   17fcac0..6566065  master     -> origin/master\n   ca29a7c..0ecdfcd  branch-2   -> origin/branch-2\n+ git reset --hard HEAD\nHEAD is now at 17fcac0 HIVE-16419: Exclude hadoop related classes for JDBC stabdalone jar (Tao Li reviewed by Vaibhav Gumashta)\n+ git clean -f -d\nRemoving ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFWidthBucket.java\nRemoving ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFWidthBucket.java\nRemoving ql/src/test/queries/clientpositive/udf_width_bucket.q\nRemoving ql/src/test/results/clientpositive/udf_width_bucket.q.out\n+ git checkout master\nAlready on 'master'\nYour branch is behind 'origin/master' by 2 commits, and can be fast-forwarded.\n  (use \"git pull\" to update your local branch)\n+ git reset --hard origin/master\nHEAD is now at 6566065 HIVE-15982 : Support the width_bucket function (Sahil Takiar via Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-04-21 21:28:53.506\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nDataNucleus Enhancer (version 4.1.17) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nDataNucleus Enhancer completed with success for 30 classes. Timings : input=145 ms, enhance=156 ms, total=301 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g\norg/apache/hadoop/hive/ql/parse/HintParser.g\nGenerating vector expression code\nGenerating vector expression test code\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java:[323,40] ')' expected\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java:[323,40] ')' expected\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12864555 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-04-21T21:29:57.346+0000","updated":"2017-04-21T21:29:57.346+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/15979873","id":"15979873","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12864578/HIVE-16483.1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4839/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4839/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4839/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-04-22 12:05:01.459\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4839/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-04-22 12:05:01.462\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 6566065 HIVE-15982 : Support the width_bucket function (Sahil Takiar via Ashutosh Chauhan)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 6566065 HIVE-15982 : Support the width_bucket function (Sahil Takiar via Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-04-22 12:05:03.339\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nDataNucleus Enhancer (version 4.1.17) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nDataNucleus Enhancer completed with success for 30 classes. Timings : input=165 ms, enhance=205 ms, total=370 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g\norg/apache/hadoop/hive/ql/parse/HintParser.g\nGenerating vector expression code\nGenerating vector expression test code\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java:[323,40] ')' expected\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkPlanGenerator.java:[323,40] ')' expected\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12864578 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-04-22T12:06:11.293+0000","updated":"2017-04-22T12:06:11.293+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/15980199","id":"15980199","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12864647/HIVE-16483.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10626 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat12] (batchId=78)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4849/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4849/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4849/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 3 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12864647 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-04-23T01:12:07.501+0000","updated":"2017-04-23T01:12:07.501+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/15981503","id":"15981503","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"Test failure not related. Committed to master. Thanks Xuefu for the review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-04-24T16:57:27.118+0000","updated":"2017-04-24T16:57:27.118+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13065218/comment/16486249","id":"16486249","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"body":"Hive 3.0.0 has been released so closing this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-22T23:59:48.191+0000","updated":"2018-05-22T23:59:48.191+0000"}],"maxResults":8,"total":8,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16483/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3dtzr:"}}