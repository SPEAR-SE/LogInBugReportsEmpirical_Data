{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12763152","self":"https://issues.apache.org/jira/rest/api/2/issue/12763152","key":"HIVE-9187","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-05-04T13:52:06.211+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu May 21 13:12:26 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-9187/watchers","watchCount":5,"isWatching":false},"created":"2014-12-22T03:10:05.642+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-05-21T13:12:26.047+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"The Operation Systemï¼ŒCentOS 6\nSoftware version, Hadoop 2.4.1, Tez 0.5.3, Hive 0.14.0.\n\nThe hive table structure is \nCREATE EXTERNAL TABLE IF NOT EXISTS inv_info(optDate string, code int, custno int, sku int, euno int, totalamount double, price double, type int, finalamout double) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/user/hadoop/inv';\n\nUse Hive local Cli for query,\n1. Use the default engine \"mr\", execute the Hive QL, it's normal\nhive> select count(*) from inv_info;\nAutomatically selecting local only mode for query\nQuery ID = root_20141221181313_60e150e1-34dd-4bea-8d4f-1a703c5516d6\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks determined at compile time: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/webapp/hadoop-2.4.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/webapp/apache-hive-0.14.0-bin/lib/hive-jdbc-0.14.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n14/12/21 18:13:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n14/12/21 18:13:51 WARN conf.Configuration: file:/tmp/root/2006970b-1b5e-41e7-a604-4ed7405cc7e9/hive_2014-12-21_18-13-41_747_2372484449278617092-3/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.\n14/12/21 18:13:51 WARN conf.Configuration: file:/tmp/root/2006970b-1b5e-41e7-a604-4ed7405cc7e9/hive_2014-12-21_18-13-41_747_2372484449278617092-3/-local-10003/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.\nExecution log at: /tmp/root/root_20141221181313_60e150e1-34dd-4bea-8d4f-1a703c5516d6.log\nJob running in-process (local Hadoop)\nHadoop job information for null: number of mappers: 0; number of reducers: 0\n2014-12-21 18:14:00,666 null map = 0%,  reduce = 0%\n2014-12-21 18:14:05,365 null map = 100%,  reduce = 100%\nEnded Job = job_local886866076_0001\nExecution completed successfully\nMapredLocal task succeeded\nOK\n2146872\nTime taken: 26.281 seconds, Fetched: 1 row(s)\n\n2. when I  set hive.execution.engine=tez; the query is fail, can anyone help me to find the reason? I looked up for many reference materials, can't resolve it.\nhive> select count(*) from inv_info;\nQuery ID = root_20141221181515_cbf8f20b-e105-441e-b044-269266088c48\nTotal jobs = 1\nLaunching Job 1 out of 1\n\n\nStatus: Running (Executing on YARN cluster with App id application_1418953370736_0009)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nMap 1                 FAILED      4          0        0        4       9       3\nReducer 2             KILLED      1          0        0        1       0       1\n--------------------------------------------------------------------------------\nVERTICES: 00/02  [>>--------------------------] 0%    ELAPSED TIME: 29.57 s\n--------------------------------------------------------------------------------\nStatus: Failed\nVertex failed, vertexName=Map 1, vertexId=vertex_1418953370736_0009_1_00, diagnostics=[Task failed, taskId=task_1418953370736_0009_1_00_000000, diagnostics=[TaskAttempt 0 failed, info=[Container container_1418953370736_0009_01_000002 finished with diagnostics set to [Container failed. Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException:\norg.apache.hadoop.util.Shell$ExitCodeException:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:505)\n        at org.apache.hadoop.util.Shell.run(Shell.java:418)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:650)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:300)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:81)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:701)\n\n\nContainer exited with a non-zero exit code 1\n]], TaskAttempt 1 failed, info=[Container container_1418953370736_0009_01_000009 finished with diagnostics set to [Container failed. Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException:\norg.apache.hadoop.util.Shell$ExitCodeException:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:505)\n        at org.apache.hadoop.util.Shell.run(Shell.java:418)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:650)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:300)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:81)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:701)\n\n\nContainer exited with a non-zero exit code 1\n]], TaskAttempt 2 failed, info=[Container container_1418953370736_0009_01_000010 finished with diagnostics set to [Container failed. Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException:\norg.apache.hadoop.util.Shell$ExitCodeException:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:505)\n        at org.apache.hadoop.util.Shell.run(Shell.java:418)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:650)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:300)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:81)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:701)\n\n\nContainer exited with a non-zero exit code 1\n]], TaskAttempt 3 failed, info=[Container container_1418953370736_0009_01_000013 finished with diagnostics set to [Container failed. Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException:\norg.apache.hadoop.util.Shell$ExitCodeException:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:505)\n        at org.apache.hadoop.util.Shell.run(Shell.java:418)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:650)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:300)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:81)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:701)\n\n\nContainer exited with a non-zero exit code 1\n]]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1418953370736_0009_1_00 [Map 1] killed/failed due to:null]\nVertex killed, vertexName=Reducer 2, vertexId=vertex_1418953370736_0009_1_01, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1418953370736_0009_1_01 [Reducer 2] killed/failed due to:null]\nDAG failed due to vertex failure. failedVertices:1 killedVertices:1\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Hive0.14.0 query fail with Tez0.5.3 and Hadoop2.4.1","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hongethan","name":"hongethan","key":"hongethan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ethan Hu","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hongethan","name":"hongethan","key":"hongethan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ethan Hu","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"CentOS 6","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763152/comment/14526645","id":"14526645","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srfnmnk","name":"srfnmnk","key":"srfnmnk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daniel Tomes","active":true,"timeZone":"America/New_York"},"body":"Confirmed. Same issue. The only way to complete the job was with MR engine.\n\ninsert overwrite table target select * from source where <key> is not null;","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srfnmnk","name":"srfnmnk","key":"srfnmnk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daniel Tomes","active":true,"timeZone":"America/New_York"},"created":"2015-05-04T13:52:06.211+0000","updated":"2015-05-04T13:52:06.211+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763152/comment/14554251","id":"14554251","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbahri","name":"bbahri","key":"bbahri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"brahim bahri","active":true,"timeZone":"Etc/UTC"},"body":"i have the same problem, did you please found a solution","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbahri","name":"bbahri","key":"bbahri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"brahim bahri","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-21T13:12:26.047+0000","updated":"2015-05-21T13:12:26.047+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-9187/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i23o8v:"}}