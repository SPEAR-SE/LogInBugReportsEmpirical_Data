{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13035941","self":"https://issues.apache.org/jira/rest/api/2/issue/13035941","key":"HIVE-15659","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2017-01-19T13:21:03.265+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jan 19 16:43:23 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_82060665_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2017-01-19T16:43:41.360+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15659/watchers","watchCount":3,"isWatching":false},"created":"2017-01-18T17:56:00.735+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-01-19T16:43:41.397+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"Sometimes a query needs to process a large number of input files, which could cause the following error:\n{code}\n17/01/15 09:31:52 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, hadoopworker1344-sjc1.prod.uber.internal): java.lang.StackOverflowError\n        at java.util.concurrent.ConcurrentHashMap.putIfAbsent(ConcurrentHashMap.java:1535)\n        at java.lang.ClassLoader.getClassLoadingLock(ClassLoader.java:463)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:404)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:411)\n{code}\n\nThe cause, I think, is that for each input file we may need to load additional jars to the class loader of the current thread. This accumulates with the number of input files. When adding a new class loader, the old class loader will be used as the parent of the new one. \nSee [Utilities#getBaseWork|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java#L388] for more details.\n\nOne possible solution is to detect duplicated jar paths before creating the new class loader.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"StackOverflowError when ClassLoader.loadClass for Spark","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13035941/comment/15829905","id":"15829905","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~csun], do you know whether the SOFE exception happens at the driver or executor? Secondly, I'm not sure if Spark will load additional jars for each input file. To me, it seems to be \"per task\".","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-19T13:21:03.265+0000","updated":"2017-01-19T13:21:03.265+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13035941/comment/15830229","id":"15830229","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"This happens at executor and is per task. However, I reproduced this in CDH Hive 1.1.0 and I think the latest master already fixed it via HIVE-11878, indirectly. I'm going to close this as \"invalid\".\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-19T16:43:23.462+0000","updated":"2017-01-19T16:43:23.462+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15659/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i38vwn:"}}