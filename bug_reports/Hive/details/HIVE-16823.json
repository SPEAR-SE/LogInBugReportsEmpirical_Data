{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13077179","self":"https://issues.apache.org/jira/rest/api/2/issue/13077179","key":"HIVE-16823","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-06-06T09:29:29.681+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 30 22:52:35 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16823/watchers","watchCount":7,"isWatching":false},"created":"2017-06-05T07:16:14.193+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12513053","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12513053","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"13097289","key":"HIVE-17383","self":"https://issues.apache.org/jira/rest/api/2/issue/13097289","fields":{"summary":"ArrayIndexOutOfBoundsException in VectorGroupByOperator","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12509684","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12509684","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13088132","key":"HIVE-17122","self":"https://issues.apache.org/jira/rest/api/2/issue/13088132","fields":{"summary":"spark_vectorized_dynamic_partition_pruning.q is continuously failing","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-08-30T22:52:35.335+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"spark_vectorized_dynamic_partition_pruning.q\n{code}\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.spark.dynamic.partition.pruning=true;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.vectorized.execution.enabled=true;\nset hive.strict.checks.cartesian.product=false;\n\n-- parent is reduce tasks\nselect count(*) from srcpart join (select ds as ds, ds as `date` from srcpart group by ds) s on (srcpart.ds = s.ds) where s.`date` = '2008-04-08';\n{code}\n\nThe exceptions are as follows:\n{code}\n2017-06-05T09:20:31,468 ERROR [Executor task launch worker-0] spark.SparkReduceRecordHandler: Fatal error: org.apache.hadoop.hive.ql.metadata.HiveException: Error while processing vector batch (tag=0) Column vector types: 0:BYTES, 1:BYTES\n[\"2008-04-08\", \"2008-04-08\"]\norg.apache.hadoop.hive.ql.metadata.HiveException: Error while processing vector batch (tag=0) Column vector types: 0:BYTES, 1:BYTES\n[\"2008-04-08\", \"2008-04-08\"]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processVectors(SparkReduceRecordHandler.java:413) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processRow(SparkReduceRecordHandler.java:301) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunctionResultList.processNextRecord(HiveReduceFunctionResultList.java:54) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunctionResultList.processNextRecord(HiveReduceFunctionResultList.java:28) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList.hasNext(HiveBaseFunctionResultList.java:85) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42) ~[scala-library-2.11.8.jar:?]\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893) ~[scala-library-2.11.8.jar:?]\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336) ~[scala-library-2.11.8.jar:?]\n\tat org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$12.apply(AsyncRDDActions.scala:127) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$12.apply(AsyncRDDActions.scala:127) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1974) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1974) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:85) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 1\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:107) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeReduceMergePartial.doProcessBatch(VectorGroupByOperator.java:832) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeBase.processBatch(VectorGroupByOperator.java:179) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:1035) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processVectors(SparkReduceRecordHandler.java:400) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\t... 17 more\n2017-06-05T09:20:31,472 ERROR [Executor task launch worker-0] executor.Executor: Exception in task 2.0 in stage 1.0 (TID 8)\njava.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Error while processing vector batch (tag=0) Column vector types: 0:BYTES, 1:BYTES\n[\"2008-04-08\", \"2008-04-08\"]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processRow(SparkReduceRecordHandler.java:315) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunctionResultList.processNextRecord(HiveReduceFunctionResultList.java:54) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunctionResultList.processNextRecord(HiveReduceFunctionResultList.java:28) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList.hasNext(HiveBaseFunctionResultList.java:85) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42) ~[scala-library-2.11.8.jar:?]\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893) ~[scala-library-2.11.8.jar:?]\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336) ~[scala-library-2.11.8.jar:?]\n\tat org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$12.apply(AsyncRDDActions.scala:127) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$12.apply(AsyncRDDActions.scala:127) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1974) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1974) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:85) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274) ~[spark-core_2.11-2.0.0.jar:2.0.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error while processing vector batch (tag=0) Column vector types: 0:BYTES, 1:BYTES\n[\"2008-04-08\", \"2008-04-08\"]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processVectors(SparkReduceRecordHandler.java:413) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processRow(SparkReduceRecordHandler.java:301) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\t... 16 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 1\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:107) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeReduceMergePartial.doProcessBatch(VectorGroupByOperator.java:832) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeBase.processBatch(VectorGroupByOperator.java:179) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:1035) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processVectors(SparkReduceRecordHandler.java:400) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processRow(SparkReduceRecordHandler.java:301) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n\t... 16 more\n2017-06-05T09:20:31,488 DEBUG [dispatcher-event-loop-2] scheduler.TaskSchedulerImpl: parentName: , name: TaskSet_1, runningTasks: 0\n2017-06-05T09:20:31,493  WARN [task-result-getter-0] scheduler.TaskSetManager: Lost task 2.0 in stage 1.0 (TID 8, localhost): java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Error while processing vector batch (tag=0) Column vector types: 0:BYTES, 1:BYTES\n[\"2008-04-08\", \"2008-04-08\"]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processRow(SparkReduceRecordHandler.java:315)\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunctionResultList.processNextRecord(HiveReduceFunctionResultList.java:54)\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunctionResultList.processNextRecord(HiveReduceFunctionResultList.java:28)\n\tat org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList.hasNext(HiveBaseFunctionResultList.java:85)\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$12.apply(AsyncRDDActions.scala:127)\n\tat org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$12.apply(AsyncRDDActions.scala:127)\n\tat org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1974)\n\tat org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1974)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:85)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error while processing vector batch (tag=0) Column vector types: 0:BYTES, 1:BYTES\n[\"2008-04-08\", \"2008-04-08\"]\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processVectors(SparkReduceRecordHandler.java:413)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processRow(SparkReduceRecordHandler.java:301)\n\t... 16 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 1\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:107)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeReduceMergePartial.doProcessBatch(VectorGroupByOperator.java:832)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeBase.processBatch(VectorGroupByOperator.java:179)\n\tat org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:1035)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.processVectors(SparkReduceRecordHandler.java:400)\n\t... 17 more\n\n2017-06-05T09:20:31,495 ERROR [task-result-getter-0] scheduler.TaskSetManager: Task 2 in stage 1.0 failed 1 times; aborting job\n{code}\nThis exception happens in this line of VectorGroupKeyHelper.java:\n{code}\nBytesColumnVector outputColumnVector = (BytesColumnVector) outputBatch.cols[columnIndex];\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883036","id":"12883036","filename":"explain.spark","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-22T02:13:24.945+0000","size":4501,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12883036/explain.spark"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883035","id":"12883035","filename":"explain.tez","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-22T02:13:24.930+0000","size":4368,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12883035/explain.tez"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883287","id":"12883287","filename":"HIVE-16823.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-23T08:35:55.388+0000","size":413265,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12883287/HIVE-16823.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883056","id":"12883056","filename":"HIVE-16823.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-22T05:46:08.259+0000","size":959,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12883056/HIVE-16823.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"\"ArrayIndexOutOfBoundsException\" in spark_vectorized_dynamic_partition_pruning.q","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=JonnyR","name":"JonnyR","key":"jonnyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jianguo Tian","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=JonnyR","name":"JonnyR","key":"jonnyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jianguo Tian","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16038454","id":"16038454","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"body":"Possibly fixed with HIVE-16273.  What release did this problem occur on?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmccline","name":"mmccline","key":"mmccline","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mmccline&avatarId=36046","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mmccline&avatarId=36046","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mmccline&avatarId=36046","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mmccline&avatarId=36046"},"displayName":"Matt McCline","active":true,"timeZone":"America/Chicago"},"created":"2017-06-06T09:29:29.681+0000","updated":"2017-06-06T09:29:29.681+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16039995","id":"16039995","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=JonnyR","name":"JonnyR","key":"jonnyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jianguo Tian","active":true,"timeZone":"Etc/UTC"},"body":"Hi, [~mmccline]. This exception was indeed triggered by [-HIVE-16273-|https://issues.apache.org/jira/browse/HIVE-16273], if I build Hive with code before this patch, this exception won't occur. Any comments and suggestion will be appreciated. Thx!\nAnd in my opinion, it would be better to add some detailed description for  [-HIVE-16273-|https://issues.apache.org/jira/browse/HIVE-16273].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=JonnyR","name":"JonnyR","key":"jonnyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jianguo Tian","active":true,"timeZone":"Etc/UTC"},"created":"2017-06-07T01:52:21.821+0000","updated":"2017-06-07T01:58:28.374+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16040398","id":"16040398","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~mmccline]: the exception was found after HIVE-16273.\n\nbefore HIVE-16273\nVectorGroupKeyHelper#copyGroupKey\n{code}\n for(int i=0;i<stringIndices.length; ++i) {\n      int keyIndex = stringIndices[i];\n      BytesColumnVector inputColumnVector = (BytesColumnVector) inputBatch.cols[keyIndex];\n      BytesColumnVector outputColumnVector = (BytesColumnVector) outputBatch.cols[keyIndex];\n      if (inputColumnVector.noNulls || !inputColumnVector.isNull[0]) {\n        // Copy bytes into scratch buffer.\n        int start = buffer.getLength();\n        int length = inputColumnVector.length[0];\n        try {\n          buffer.write(inputColumnVector.vector[0], inputColumnVector.start[0], length);\n        } catch (IOException ioe) {\n          throw new IllegalStateException(\"bad write\", ioe);\n        }\n        outputColumnVector.setRef(outputBatch.size, buffer.getData(), start, length);\n      } else {\n        outputColumnVector.noNulls = false;\n        outputColumnVector.isNull[outputBatch.size] = true;\n      }\n{code}\n\nafter HIVE-16273\n{code}\n  for(int i=0;i<stringIndices.length; ++i) {\n      final int columnIndex = outputColumnNums[stringIndices[i]];\n      BytesColumnVector inputColumnVector = (BytesColumnVector) inputBatch.cols[columnIndex];\n      BytesColumnVector outputColumnVector = (BytesColumnVector) outputBatch.cols[columnIndex];\n      if (inputColumnVector.noNulls || !inputColumnVector.isNull[0]) {\n        // Copy bytes into scratch buffer.\n        int start = buffer.getLength();\n        int length = inputColumnVector.length[0];\n        try {\n          buffer.write(inputColumnVector.vector[0], inputColumnVector.start[0], length);\n        } catch (IOException ioe) {\n          throw new IllegalStateException(\"bad write\", ioe);\n        }\n        outputColumnVector.setRef(outputBatch.size, buffer.getData(), start, length);\n      } else {\n        outputColumnVector.noNulls = false;\n        outputColumnVector.isNull[outputBatch.size] = true;\n      }\n    }\n{code}\n\nThe exception occurs  {noformat}outputBatch.cols[columnIndex]{noformat} (here the columnIndex is 1 while the size of outputBatch.cols is 1), so ArrayIndexOutOfBoundsException happened.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-07T07:31:57.031+0000","updated":"2017-06-07T07:31:57.031+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16136156","id":"16136156","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"some updates about the jira.\n The root cause of the problem is because the difference of sub-query {{select ds as ds, ds as `date` from srcpart group by ds}} between tez and spark mode.\nthe spark explain(the full spark explain is attached in [here|https://issues.apache.org/jira/secure/attachment/12883036/explain.spark] )\n{code}\n  Map 3 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  filterExpr: (ds = '2008-04-08') (type: boolean)\n                  Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                    Group By Operator\n                      keys: '2008-04-08' (type: string)\n                      mode: hash\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: '2008-04-08' (type: string)\n                        sort order: +\n                        Map-reduce partition columns: '2008-04-08' (type: string)\n                        Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n Reducer 4 \n            Local Work:\n              Map Reduce Local Work\n            Reduce Operator Tree:\n              Group By Operator\n                keys: '2008-04-08' (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n{code}\n\nthe tez explain(the full tez explain is attached in [here|https://issues.apache.org/jira/secure/attachment/12883035/explain.tez] )\n{code}\n  Map 2 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  filterExpr: (ds = '2008-04-08') (type: boolean)\n                  Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                    Group By Operator\n                      keys: '2008-04-08' (type: string)\n                      mode: hash\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: string)\n                        Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n            Execution mode: vectorized\n        Reducer 3 \n            Execution mode: vectorized\n            Reduce Operator Tree:\n              Group By Operator\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0\n{code}\n\nThe Group By Operator appears in Map and Reducer in tez or spark mode. But the keys of GroupByOperator in Reducer is different. In tez, the key is  {{keys: KEY._col0 (type: string)}} while in spark the key is {{keys: '2008-04-08' (type: string)}}.  This difference causes [VectorizationContext#getVectorExpression|https://github.com/kellyzly/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizationContext.java#L579 ] returns [getColumnVectorExpression|https://github.com/kellyzly/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizationContext.java#L582] in tez mode while  returns [getConstantVectorExpression|https://github.com/kellyzly/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizationContext.java#L660].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-22T02:14:53.280+0000","updated":"2017-08-22T02:16:12.973+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16136339","id":"16136339","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"In HIVE-15269:Dynamic Min-Max/BloomFilter runtime-filtering for Tez, ConstantPropagate is removed in TezCompiler#runDynamicPartitionPruning. Similar code should be removed in SparkCompiler#runDynamicPartitionPruning\n{code}\n  private void runDynamicPartitionPruning(OptimizeTezProcContext procCtx, Set<ReadEntity> inputs,\n      Set<WriteEntity> outputs) throws SemanticException {\n\n    if (!procCtx.conf.getBoolVar(ConfVars.TEZ_DYNAMIC_PARTITION_PRUNING)) {\n      return;\n    }\n\n    // Sequence of TableScan operators to be walked\n    Deque<Operator<?>> deque = new LinkedList<Operator<?>>();\n    deque.addAll(procCtx.parseContext.getTopOps().values());\n\n    Map<Rule, NodeProcessor> opRules = new LinkedHashMap<Rule, NodeProcessor>();\n    opRules.put(\n        new RuleRegExp(new String(\"Dynamic Partition Pruning\"), FilterOperator.getOperatorName()\n            + \"%\"), new DynamicPartitionPruningOptimization());\n\n    // The dispatcher fires the processor corresponding to the closest matching\n    // rule and passes the context along\n    Dispatcher disp = new DefaultRuleDispatcher(null, opRules, procCtx);\n    List<Node> topNodes = new ArrayList<Node>();\n    topNodes.addAll(procCtx.parseContext.getTopOps().values());\n    GraphWalker ogw = new ForwardWalker(disp);\n    ogw.startWalking(topNodes, null);\n\n/** Similar code is removed in TezCompiler in HIVE-15269:Dynamic Min-Max/BloomFilter runtime-filtering for Tez***/\n    // need a new run of the constant folding because we might have created lots\n    // of \"and true and true\" conditions.\n    // Rather than run the full constant folding just need to shortcut AND/OR expressions\n    // involving constant true/false values.\n    if(procCtx.conf.getBoolVar(ConfVars.HIVEOPTCONSTANTPROPAGATION)) {\n      new ConstantPropagate(ConstantPropagateOption.SHORTCUT).transform(procCtx.parseContext);\n    }\n\n  }\n\n{code}\n[~lirui],[~stakiar]: can you help review?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-22T05:50:13.412+0000","updated":"2017-08-22T05:50:13.412+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16136825","id":"16136825","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12883056/HIVE-16823.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 10994 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning] (batchId=169)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_2] (batchId=171)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_3] (batchId=171)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_mapjoin_only] (batchId=170)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=100)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)\norg.apache.hadoop.hive.common.TestFileUtils.testCopyWithDistCpAs (batchId=250)\norg.apache.hadoop.hive.common.TestFileUtils.testCopyWithDistcp (batchId=250)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6484/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6484/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6484/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 13 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12883056 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-08-22T13:59:46.398+0000","updated":"2017-08-22T13:59:46.398+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16137991","id":"16137991","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"update changes in q*out in HIVE-16823.1.patch. Most changes like following. This is because we remove ConstantPropagate in SparkCompiler#runDynamicPartitionPruning.  \n{code}\n            Map Operator Tree:\n                 TableScan\n                   alias: srcpart_date\n-                  filterExpr: ((date = '2008-04-08') and ds is not null) (type: boolean)\n+                  filterExpr: ((date = '2008-04-08') and ds is not null and true) (type: boolean)\n                   Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE\n                   Filter Operator\n-                    predicate: ((date = '2008-04-08') and ds is not null) (type: boolean)\n+                    predicate: ((date = '2008-04-08') and ds is not null and true) (type: boolean)\n                     Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n{code}\nBig changes in spark_vectorized_dynamic_partition_pruning.q.out as this file has not been updated for long time.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-23T07:11:10.660+0000","updated":"2017-08-23T07:11:10.660+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16138071","id":"16138071","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"explain more about the big changes in spark_vectorized_dynamic_partition_pruning.q.out on review board. [~lirui] and [~stakiar]: If have time, please help review, thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-23T08:35:28.689+0000","updated":"2017-08-23T08:35:28.689+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16138093","id":"16138093","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], thanks for working on this. I think the root cause is not in how we implement DPP. I can reproduce the issue with DPP disabled:\n{noformat}\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.spark.dynamic.partition.pruning=false;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.vectorized.execution.enabled=true;\nset hive.strict.checks.cartesian.product=false;\n\nset hive.auto.convert.join=true;\nset hive.auto.convert.join.noconditionaltask = true;\nset hive.auto.convert.join.noconditionaltask.size = 10000000;\n\nset hive.cbo.enable=false;\nset hive.optimize.constant.propagation=true;\n{noformat}\n\nLooking at the code in the vectorizer, I think it's because the vectorized GBY is not properly set when SparkHashTableSinkOperator is present. To verify this, if you change {{hive.auto.convert.join=false}} in the above configs, the query can run successfully. I'm still trying to understand the logic in the vectorizer. Please also update the JIRA if you find anything. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-23T08:53:10.558+0000","updated":"2017-08-23T08:53:10.558+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16138170","id":"16138170","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12883287/HIVE-16823.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 10994 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)\norg.apache.hadoop.hive.common.TestFileUtils.testCopyWithDistCpAs (batchId=250)\norg.apache.hadoop.hive.common.TestFileUtils.testCopyWithDistcp (batchId=250)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6499/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6499/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6499/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 7 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12883287 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-08-23T09:59:41.970+0000","updated":"2017-08-23T09:59:41.970+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16139547","id":"16139547","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Here's what I found so far. When we create vector GBY, the vector expression of the key is {{ConstantVectorExpression(val 2008-04-08) -> 1:string}}, with {{outputColumn == 1}}. The corresponding VectorizationContext is something like this:\n{noformat}\nContext name __Reduce_Shuffle__, level 0, sorted projectionColumnMap {0=KEY._col0}, scratchColumnTypeNames [string]\n{noformat}\nBut in the constructor of the vector GBY, we create another VectorizationContext using the above one: https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupByOperator.java#L870.\nTherefore, the vector GBY's VectorizationContext will be something like:\n{noformat}\nContext name GBY, level 0, sorted projectionColumnMap {0=_col0}, scratchColumnTypeNames []\n{noformat}\nNote that it doesn't have scratch columns. At runtime, the key expression's column index is 1, but we only have 1 column vector in the output batch, and thus getting the exception.\nI don't fully understand the vectorization logics. But it seems the vector GBY relies on following operators to setup its VectorizationContext. If it's followed by SEL or RS, the VectorizationContext may be fixed as we get vector expressions for these operators (different operators' VectorizationContext share the same OutputColumnManager). [~mmccline] do you think it's an issue? Or let me know where else I should look at. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-24T04:45:15.479+0000","updated":"2017-08-24T04:45:15.479+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16139569","id":"16139569","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: I found if enable cbo with your settings, everything works fine\n{code}\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.spark.dynamic.partition.pruning=false;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.vectorized.execution.enabled=true;\nset hive.strict.checks.cartesian.product=false;\nset hive.auto.convert.join=true;\nset hive.auto.convert.join.noconditionaltask = true;\nset hive.auto.convert.join.noconditionaltask.size = 10000000;\nset hive.optimize.constant.propagation=true;\n{code}\n\nwhen enabling cbo, the explain is\n{code}\n Map 3 \n            Map Operator Tree:                TableScan\n                  alias: srcpart                  filterExpr: (ds = '2008-04-08') (type: boolean)\n                  Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                    Group By Operator\n                      keys: '2008-04-08' (type: string)\n                      mode: hash\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: string)\n                        Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n            Execution mode: vectorized\n        Reducer 4 \n            Execution mode: vectorized\n            Local Work:\n              Map Reduce Local Work\n            Reduce Operator Tree:\n              Group By Operator\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0\n\n{code}\n\nwhen disabling cbo, the explain is\n{code}\n Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart                  filterExpr: (true and (ds = '2008-04-08')) (type: boolean)\n                  Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                  Filter Operator                    predicate: true (type: boolean)\n                    Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator                      Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: '2008-04-08' (type: string)                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                        Reduce Output Operator\n                          key expressions: '2008-04-08' (type: string)                          sort order: +\n                          Map-reduce partition columns: '2008-04-08' (type: string)\n                          Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n            Execution mode: vectorized\n        Reducer 2 \n            Execution mode: vectorized\n            Local Work:\n              Map Reduce Local Work\n            Reduce Operator Tree:\n              Group By Operator\n                keys: '2008-04-08' (type: string)\n{code}\n\nthe difference is the key of GroupByOperator in the Reducer. But not know why cbo causes wrong explain. Need to investigate.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-24T05:19:57.464+0000","updated":"2017-08-24T05:19:57.464+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16139582","id":"16139582","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly] I think that's because when CBO is on, ConstantPropagate won't be run.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-24T05:37:36.091+0000","updated":"2017-08-24T05:37:36.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16139655","id":"16139655","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: Although ConstantPropagate influence the logical planhive on tez will not throw the exception.\n\n{code}\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.tez.dynamic.partition.pruning=true;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.vectorized.execution.enabled=true;\nset hive.strict.checks.cartesian.product=false;\nset hive.cbo.enable=false;\nset hive.user.install.directory=file:///tmp;\nset fs.default.name=file:///;\nset fs.defaultFS=file:///;\nset tez.staging-dir=/tmp;\nset tez.ignore.lib.uris=true;\nset tez.runtime.optimize.local.fetch=true;\nset tez.local.mode=true;\nset hive.explain.user=false;\nselect count(*) from srcpart join (select ds as ds, ds as `date` from srcpart group by ds) s on (srcpart.ds = s.ds) where s.`date` = '2008-04-08';\n{code}\n\nthe explain(It seems the key of GroupByOperator is not right)\n{code}\n Reducer 2 \n            Execution mode: vectorized\n            Reduce Operator Tree:\n              Group By Operator\n                keys: '2008-04-08' (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                Select Operator\n                  Statistics: Num rows: 1 Data size: 11624 Basic stats: COMPLETE Column stats: NONE\n                  Map Join Operator\n{code}\n\nNeed more time to investigate why tez is not influenced when cbo is disabled. But i guess this is another problem, any suggestion?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-24T06:55:01.741+0000","updated":"2017-08-24T06:55:01.741+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16139686","id":"16139686","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], the operator tree is different between spark and tez and as I said, the following operators might change the VectorizationContext of the GBY. This is why the query runs if map join is disabled, in which case GBY is followed by SEL/RS instead of SparkHashTableSinkOperator.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-24T07:15:53.500+0000","updated":"2017-08-24T07:15:53.500+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16139902","id":"16139902","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"I have a simpler query to reproduce the issue and it happens to Tez as well:\n{noformat}\nset hive.cbo.enable=false;\nselect count(*) from (select key from src group by key) s where s.key='98';\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-24T11:21:02.092+0000","updated":"2017-08-24T11:21:02.092+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16141446","id":"16141446","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"some update\n{quote}\nThis is why the query runs if map join is disabled, in which case GBY is followed by SEL/RS instead of SparkHashTableSinkOperator.\n{quote}\nmore explain about this.  \n{code}\nset spark.master=local;\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.spark.dynamic.partition.pruning=false;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.vectorized.execution.enabled=true;\nset hive.strict.checks.cartesian.product=false;\nset hive.auto.convert.join=false;\nset hive.cbo.enable=false;\nset hive.optimize.constant.propagation=true;\nselect count(*) from srcpart join (select ds as ds, ds as `date` from srcpart group by ds) s on (srcpart.ds = s.ds) where s.`date` = '2008-04-08';\n{code}\nthe cbo is disabled and the explain is not right, the key of GroupBy in Reducer is {{keys: '2008-04-08' (type: string)}} it should be {{keys: KEY._col0 (type: string)}} but the query finishes successfully. The reason is there is {{RS\\[9\\]}} after {{GBY\\[4\\]}} \n{code}\nGBY[4]-SEL[5]-RS[9]\n{code}\n\n{{RS\\[9\\]}} called following stack, OutputColumnManager#allocateOutputColumn makes OutputColumnManager#getScratchColumnTypeNames returning value.\n{code}\norg.apache.hadoop.hive.ql.exec.vector.VectorizationContext$OutputColumnManager.allocateOutputColumn(VectorizationContext.java:478)\n          at org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.getConstantVectorExpression(VectorizationContext.java:1153)\n          at org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.getVectorExpression(VectorizationContext.java:688)\n          at org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.getVectorExpressions(VectorizationContext.java:590)\n          at org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.getVectorExpressions(VectorizationContext.java:578)\n          at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.canSpecializeReduceSink(Vectorizer.java:3490)\n          at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.vectorizeOperator(Vectorizer.java:4174)\n          at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$VectorizationNodeProcessor.doVectorize(Vectorizer.java:1632)\n          at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$ReduceWorkVectorizationNodeProcessor.process(Vectorizer.java:1772)\n{code}\n\nin the log, we can see after VectorizationNodeProcessor#doVectorizer {{GBY\\[4\\]}} , the vectorization context is \n{code}\n2017-08-25T03:40:21,316 DEBUG [cd30697a-7797-4bbe-ad92-1fcec8a89689 main] physical.Vectorizer: Vectorized ReduceWork reduce shuffle vectorization context Context name __Reduce_Shuffle__, level 0, sorted projectionColumnMap {0=KEY._col0}, scratchColumnTypeNames []\n{code}\nafter  VectorizationNodeProcessor#doVectorizer {{RS\\[9\\]}}, the vectorization context is(here scratchColumnTypeNames  returns value)\n{code}\n2017-08-25T03:48:00,245 DEBUG [cd30697a-7797-4bbe-ad92-1fcec8a89689 main] physical.Vectorizer: vectorizeOperator org.apache.hadoop.hive.ql.plan.ReduceSinkDesc\n2017-08-25T03:48:43,101 DEBUG [cd30697a-7797-4bbe-ad92-1fcec8a89689 main] physical.Vectorizer: Vectorized ReduceWork operator RS added vectorization context Context name SEL, level 1, sorted projectionColumnMap {}, scratchColumnTypeNames [string]\n{code}\n\nThe difference in scratchColumnTypeNames causes different value in outputBatch in [VectorGroupKeyHelper|https://github.com/kellyzly/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorGroupKeyHelper.java#L107].\n\nI guess arrayIndexOutOfBoundsException can be reproduced in following condition whether in spark or tez mode.\n1. cbo is disabled\n2.  there is no RS follows GBY in the reducer\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-25T10:01:05.949+0000","updated":"2017-08-25T10:01:05.949+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16143397","id":"16143397","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: can you help review the patch?\ni have 1 question about {{spark_vectorized_dynamic_partition_pruning.q}}, should we add {{-- SORT_QUERY_RESULTS}} to the file, otherwise \nthe result of \n{code}\nselect distinct ds from srcpart\n{code}\n{code}\n2008-04-09\t\n2008-04-08\n{code}\n\nwhile the result in the q.out is\n{code}\n2008-04-08\t\n2008-04-09\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-28T05:53:39.468+0000","updated":"2017-08-28T06:06:47.821+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16143455","id":"16143455","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], the v1 patch doesn't fix the root cause of the issue so it's not the right way to go. Let's figure out a fix for HIVE-17383 first and come back here. Besides, we do need to get rid of the \"and true and true\" conditions. Seems tez doesn't have such filters in the query plans.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-28T07:05:18.960+0000","updated":"2017-08-28T07:05:18.960+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16147825","id":"16147825","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"So HIVE-15269 doesn't actually remove the call to constant propagate. It just moves it to the end of {{TezCompiler#optimizeOperatorPlan}}. It seems the reason Tez has {{keys: KEY._col0 (type: string)}} in the explain plan, while Spark has {{keys: '2008-04-08' (type: string)}} is because Tez calls {{ConstantPropagate(ConstantPropagateOption.SHORTCUT)}} while Spark has been calling {{ConstantPropagate()}}. I changed this in HIVE-17405 to fix some other issues with the call to {{ConstantPropagate}}, and it looks like that made {{spark_vectorized_dynamic_partition_pruning.q}} work again.\n\nSo looks like HIVE-17405 should fix spark_vectorized_dynamic_partition_pruning.q, although sounds like HIVE-17383 is still a real bug.\n\nMaybe a follow up JIRA would be to see what happens when we run {ConstantPropagate()}} at the end of {{SparkCompiler#optimizeOperatorPlan}}? Theoretically, it should improve performance? But sounds like there are some bugs we need to address before getting to that stage.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-30T18:50:25.942+0000","updated":"2017-08-30T18:50:25.942+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16148105","id":"16148105","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~stakiar]: {quote} \nMaybe a follow up JIRA would be to see what happens when we run {ConstantPropagate()}} at the end of SparkCompiler#optimizeOperatorPlan? Theoretically, it should improve performance? But sounds like there are some bugs we need to address before getting to that stage.\n{quote}\n\nis there any unit test failures if we put following code in the end of SparkCompiler#optimizeOperatorPlan?\n{code}\n  if(procCtx.conf.getBoolVar(ConfVars.HIVEOPTCONSTANTPROPAGATION)) {\n      new ConstantPropagate(ConstantPropagateOption.SHORTCUT).transform(procCtx.parseContext);\n    }\n{code}\n\nI think it is better to put it in the end of SparkCompiler#optimizeOperatorPlan than in the runDynamicPartitionPruning. This is not related dpp just found bug in dpp unit test.  Beside, why it should improve performance? if you know, please tell me, thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-30T21:49:21.859+0000","updated":"2017-08-30T21:49:21.859+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16148125","id":"16148125","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"let's fix spark_vectorized_dynamic_partition_pruning.q  in the HIVE-17405 although the target of HIVE-17405 is not spark_vectorized_dynamic_partition_pruning.q  after HIVE-17383 is resolved.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-30T22:08:26.775+0000","updated":"2017-08-30T22:08:26.775+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077179/comment/16148179","id":"16148179","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"[~kellyzly] sounds good. I attached a new patch to HIVE-17405 with the call to constant propagate moved to the end of {{SparkCompiler#optimizeOperatorPlan}}. Let's see if there are any test failures. I'm not actually sure if an additional call to {{ConstantPropagate}} will improve performance, I would just assume if it changes things in the explain plan, then the execution of that plan should be faster; but thats just a theory.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-30T22:52:35.335+0000","updated":"2017-08-30T22:52:35.335+0000"}],"maxResults":23,"total":23,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16823/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3fv5j:"}}