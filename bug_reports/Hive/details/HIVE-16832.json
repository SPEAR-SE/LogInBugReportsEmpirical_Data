{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13077771","self":"https://issues.apache.org/jira/rest/api/2/issue/13077771","key":"HIVE-16832","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-06-07T04:16:04.614+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed May 23 00:00:11 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_15439027_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_3109639154","customfield_12312321":null,"resolutiondate":"2017-07-12T23:04:30.576+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16832/watchers","watchCount":3,"isWatching":false},"created":"2017-06-06T18:59:52.457+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"19.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"}],"issuelinks":[{"id":"12505877","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12505877","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12979916","key":"HIVE-14035","self":"https://issues.apache.org/jira/rest/api/2/issue/12979916","fields":{"summary":"Enable predicate pushdown to delta files created by ACID Transactions","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12509401","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12509401","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13087695","key":"HIVE-17110","self":"https://issues.apache.org/jira/rest/api/2/issue/13087695","fields":{"summary":"BucketCodec should enforce value ranges","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12520988","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12520988","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13121156","key":"HIVE-18158","self":"https://issues.apache.org/jira/rest/api/2/issue/13121156","fields":{"summary":"Remove OrcRawRecordMerger.ReaderPairAcid.statementId","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12505850","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12505850","type":{"id":"12310040","name":"Required","inward":"is required by","outward":"requires","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310040"},"inwardIssue":{"id":"13012089","key":"HIVE-14947","self":"https://issues.apache.org/jira/rest/api/2/issue/13012089","fields":{"summary":"Add support for Acid 2 in Merge","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-23T00:00:11.211+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12322671","id":"12322671","name":"Transactions","description":"Transaction management and ACID"}],"timeoriginalestimate":null,"description":"{noformat}\n create table AcidTablePart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true');\n create temporary table if not exists data1 (x int);\n insert into data1 values (1);\n from data1\n   insert into AcidTablePart partition(p) select 0, 0, 'p' || x\n   insert into AcidTablePart partition(p='p1') select 0, 1\n{noformat}\n\nEach branch of this multi-insert create a row in partition p1/bucket0 with ROW__ID=(1,0,0).\nThe same can happen when running SQL Merge (HIVE-10924) statement that has both Insert and Update clauses when target table has _'transactional'='true','transactional_properties'='default'_  (see HIVE-14035).  This is so because Merge is internally run as a multi-insert statement.\n\nThe solution relies on statement ID introduced in HIVE-11030.  Each Insert clause of a multi-insert is gets a unique ID.\nThe ROW__ID.bucketId now becomes a bit packed triplet (format version, bucketId, statementId).\n(Since ORC stores field names in the data file we can't rename ROW__ID.bucketId).\nThis ensures that there are no collisions and retains desired sort properties of ROW__ID.\nIn particular _SortedDynPartitionOptimizer_ works w/o any changes even in cases where there fewer reducers than buckets.  \n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12871718","id":"12871718","filename":"HIVE-16832.01.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-06T23:17:02.699+0000","size":32406,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12871718/HIVE-16832.01.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873581","id":"12873581","filename":"HIVE-16832.03.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-20T01:45:01.720+0000","size":79403,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873581/HIVE-16832.03.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873614","id":"12873614","filename":"HIVE-16832.04.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-20T07:03:43.251+0000","size":86154,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873614/HIVE-16832.04.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873702","id":"12873702","filename":"HIVE-16832.05.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-20T15:46:25.148+0000","size":97118,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873702/HIVE-16832.05.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873989","id":"12873989","filename":"HIVE-16832.06.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-22T01:53:47.230+0000","size":97346,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873989/HIVE-16832.06.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874171","id":"12874171","filename":"HIVE-16832.08.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-23T02:19:25.807+0000","size":115263,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874171/HIVE-16832.08.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874192","id":"12874192","filename":"HIVE-16832.09.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-23T04:35:54.882+0000","size":116312,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874192/HIVE-16832.09.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874314","id":"12874314","filename":"HIVE-16832.10.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-23T20:48:23.127+0000","size":131501,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874314/HIVE-16832.10.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874324","id":"12874324","filename":"HIVE-16832.11.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-23T22:20:55.483+0000","size":232296,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874793","id":"12874793","filename":"HIVE-16832.14.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-28T02:02:47.129+0000","size":34909,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874793/HIVE-16832.14.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874999","id":"12874999","filename":"HIVE-16832.15.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-29T02:25:16.600+0000","size":88800,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874999/HIVE-16832.15.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12875110","id":"12875110","filename":"HIVE-16832.16.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-29T20:58:25.347+0000","size":96826,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12875110/HIVE-16832.16.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12875809","id":"12875809","filename":"HIVE-16832.17.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-05T19:52:22.531+0000","size":102131,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12875809/HIVE-16832.17.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12875831","id":"12875831","filename":"HIVE-16832.18.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-05T23:44:44.643+0000","size":107373,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12875831/HIVE-16832.18.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12876158","id":"12876158","filename":"HIVE-16832.19.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-07T23:28:54.737+0000","size":119555,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12876158/HIVE-16832.19.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12876248","id":"12876248","filename":"HIVE-16832.20.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-08T16:27:04.249+0000","size":123945,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12876248/HIVE-16832.20.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12876176","id":"12876176","filename":"HIVE-16832.20.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-08T04:47:46.793+0000","size":123945,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12876176/HIVE-16832.20.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12876708","id":"12876708","filename":"HIVE-16832.21.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-11T22:31:12.037+0000","size":124412,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12876708/HIVE-16832.21.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12876914","id":"12876914","filename":"HIVE-16832.22.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-12T18:24:18.782+0000","size":129972,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12876914/HIVE-16832.22.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"duplicate ROW__ID possible in multi insert into transactional table","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16039852","id":"16039852","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"HIVE-16832.01.patch is an incomplete WIP\nVectorizedOrcAcidRowBatchReader assumes that ROW__ID.bucketId is the same in each split (and each bucket file of a delete_delta) which is no longer the case\n\nSortedDynPartitionOptimizer needs to ensure that data is sorted by \nby (ROW__ID.bucketId%numBuckets) before it's sorted by ROW__ID so that\nFileSinkOperator.process() sees all rows for a given bucket equivalence set before moving on to the next equivalence set.  ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-06T23:17:02.717+0000","updated":"2017-06-06T23:17:02.717+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16040144","id":"16040144","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12871718/HIVE-16832.01.patch\n\n{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 48 failed/errored test(s), 10832 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=157)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query78] (batchId=232)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5559/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5559/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5559/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 48 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12871718 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-07T04:16:04.614+0000","updated":"2017-06-07T04:16:04.614+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16055191","id":"16055191","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12873581/HIVE-16832.03.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5682/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5682/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5682/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[68,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[73,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[74,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[75,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[80,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[81,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[84,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[89,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[90,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[91,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[96,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[97,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[98,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[99,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestSequenceValidator.java:[100,39] no suitable constructor found for RecordIdentifier(long,int,int)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestRecordInspectorImpl.java:[38,41] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java:[150,34] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java:[43,33] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[57,57] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[58,57] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[59,57] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[60,58] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[245,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[302,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[313,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[324,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[326,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[372,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[501,95] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[504,83] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[506,53] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[507,98] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[521,62] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[523,62] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[525,62] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[533,59] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[541,63] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-hcatalog-streaming\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12873581 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-20T06:05:33.640+0000","updated":"2017-06-20T06:05:33.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16055468","id":"16055468","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12873614/HIVE-16832.04.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5687/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5687/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5687/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/token/Token.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Tool.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar(org/apache/thrift/TException.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/conf/Configurable.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Callable.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/InterruptedException.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Boolean.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/ClassNotFoundException.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/ql/target/hive-exec-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/ql/ErrorMsg.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Integer.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/Log.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/LogFactory.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobStatus.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobProfile.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Long.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/JavaUtils.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileNotFoundException.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URISyntaxException.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URI.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/metastore/target/hive-metastore-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/metastore/api/MetaException.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Credentials.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/InetAddress.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/UnknownHostException.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/text/MessageFormat.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Matcher.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Pattern.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/DELETE.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/FormParam.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/GET.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/POST.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PUT.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Path.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PathParam.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Produces.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/QueryParam.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/Context.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/SecurityContext.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/UriInfo.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-lang/commons-lang/2.6/commons-lang-2.6.jar(org/apache/commons/lang/StringUtils.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/fs/FileStatus.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/BufferedReader.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStream.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStreamReader.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/PrintWriter.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Map$Entry.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Semaphore.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/CommandLine.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/DefaultExecutor.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteWatchdog.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/PumpStreamHandler.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Shell.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Thread.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Runnable.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/ExceptionMapper.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/Provider.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/NotFoundException.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobID.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Groups.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/HashSet.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Set.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ConcurrentHashMap.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hive/common/util/HiveVersionInfo.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataInput.class)]]\n[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataOutput.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/InputSplit.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar(org/apache/curator/framework/CuratorFramework.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/CreateMode.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/KeeperException.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs.class)]]\n[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs$Ids.class)]]\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:testCompile (default-testCompile) on project hive-hcatalog-streaming: Compilation failure: Compilation failure:\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestRecordInspectorImpl.java:[38,41] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java:[150,34] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java:[43,33] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[57,57] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[58,57] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[59,57] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorCoordinator.java:[60,58] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[245,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[302,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[313,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[324,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[326,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[372,61] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[501,95] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[504,83] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[506,53] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[507,98] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[521,62] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[523,62] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[525,62] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[533,59] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] /data/hiveptest/working/apache-github-source-source/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java:[541,63] no suitable constructor found for RecordIdentifier(long,int,long)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier() is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] constructor org.apache.hadoop.hive.ql.io.RecordIdentifier.RecordIdentifier(long,int,int,long) is not applicable\n[ERROR] (actual and formal argument lists differ in length)\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-hcatalog-streaming\nDestroying 1 processes\nDestroying process..\nDestroyed 1 processes\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12873614 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-20T09:48:47.272+0000","updated":"2017-06-20T09:48:47.272+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16056077","id":"16056077","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12873702/HIVE-16832.05.patch\n\n{color:green}SUCCESS:{color} +1 due to 15 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 304 failed/errored test(s), 10845 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_join] (batchId=15)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_mapjoin] (batchId=10)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_partition] (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_project] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=48)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_no_match] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_acid_dynamic_partition] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_nonacid_from_acid] (batchId=70)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_orig_table] (batchId=59)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=71)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table] (batchId=54)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_partitioned] (batchId=72)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_tmp_table] (batchId=4)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=76)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_reader] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_exception] (batchId=32)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[transform_acid] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=65)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_no_match] (batchId=19)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=59)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_acid3] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_join_part_col_char] (batchId=22)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_dynamic] (batchId=165)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_static] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_globallimit] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_no_match] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_orig_table] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_partitioned] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_tmp_table] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_no_match] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_acid3] (batchId=148)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=98)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=98)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=98)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join_part_col_char] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[acid_overwrite] (batchId=89)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnMR (batchId=213)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnTez (batchId=213)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnMR (batchId=213)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnTez (batchId=213)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnMR (batchId=217)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnTez (batchId=217)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnMR (batchId=217)\norg.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnTez (batchId=217)\norg.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testErrors (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeCardinalityViolation (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testAlterTable (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testFileSystemUnCaching (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testInitiatorWithMultipleFailedCompactions (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsertStatement (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNoHistory (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testSimpleRead (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAcidWithSchemaEvolution (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAlterTable (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testBucketizedInputFormat (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge2 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testETLSplitStrategyForACID (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFileSystemUnCaching (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testInitiatorWithMultipleFailedCompactions (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMergeWithPredicate (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsert (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsertStatement (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNoHistory (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion1 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testSimpleRead (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAcidWithSchemaEvolution (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAlterTable (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testBucketizedInputFormat (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge2 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testETLSplitStrategyForACID (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFileSystemUnCaching (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testInitiatorWithMultipleFailedCompactions (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMergeWithPredicate (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsert (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertStatement (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertVectorized (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNoHistory (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion1 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testSimpleRead (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=277)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBase (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPair (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPairNoMin (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.checkExpectedLocks2 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testCompletedTxnComponents (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testDynamicPartitionInsert (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way01 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way02 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned01 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned02 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned01 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned02 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMetastoreTablesCleanup (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMultiInsert (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking10 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking11 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking5 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking7 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking8 (batchId=281)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking9 (batchId=281)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningInsert (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithOnlyInserts (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testTableProperties (batchId=214)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5692/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5692/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5692/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 304 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12873702 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-20T16:56:05.299+0000","updated":"2017-06-20T16:56:05.299+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16058842","id":"16058842","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12873989/HIVE-16832.06.patch\n\n{color:green}SUCCESS:{color} +1 due to 15 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 188 failed/errored test(s), 10839 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=49)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=76)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=65)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=59)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=98)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=101)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)\norg.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=268)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDynamicPartitionsMerge2 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMergeWithPredicate (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDynamicPartitionsMerge2 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMergeWithPredicate (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertVectorized (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=277)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=277)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testEmpty (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBase (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPair (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testReaderPairNoMin (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testUpdates (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriterTblProperties (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testCanCreateVectorizedAcidRowBatchReaderOnSplit (batchId=261)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=214)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=214)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=189)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=189)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=189)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5728/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5728/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5728/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 188 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12873989 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-22T06:38:07.582+0000","updated":"2017-06-22T06:38:07.582+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16060379","id":"16060379","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874171/HIVE-16832.08.patch\n\n{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 76 failed/errored test(s), 10858 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort (batchId=215)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming (batchId=215)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreamingForSplitUpdate (batchId=215)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort (batchId=215)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming (batchId=215)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreamingWithSplitUpdate (batchId=215)\norg.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=215)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=190)\norg.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5737/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5737/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5737/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 76 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874171 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-23T03:36:45.568+0000","updated":"2017-06-23T03:36:45.568+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16060707","id":"16060707","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874192/HIVE-16832.09.patch\n\n{color:green}SUCCESS:{color} +1 due to 16 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 51 failed/errored test(s), 10858 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_7] (batchId=42)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_8] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_9] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderOldBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=227)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5744/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5744/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5744/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 51 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874192 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-23T10:35:25.191+0000","updated":"2017-06-23T10:35:25.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16061629","id":"16061629","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch\n\n{color:green}SUCCESS:{color} +1 due to 17 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 33 failed/errored test(s), 10857 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=238)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsert (batchId=269)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5757/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5757/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5757/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 33 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874324 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-23T23:18:52.626+0000","updated":"2017-06-23T23:18:52.626+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16061675","id":"16061675","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874324/HIVE-16832.11.patch\n\n{color:green}SUCCESS:{color} +1 due to 17 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 31 failed/errored test(s), 10857 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_explode2] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[lateral_view_noalias] (batchId=36)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_stack] (batchId=36)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lateral_view] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_in] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_notin] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[invalid_cast_from_binary_1] (batchId=88)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=89)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=89)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[lateral_view_explode2] (batchId=136)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5758/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5758/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5758/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 31 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874324 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-24T00:16:00.862+0000","updated":"2017-06-24T00:16:00.862+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16066380","id":"16066380","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874793/HIVE-16832.14.patch\n\n{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 26 failed/errored test(s), 10862 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[zero_rows_hdfs] (batchId=241)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testNewBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta (batchId=262)\norg.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.testWriter (batchId=263)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=262)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=190)\norg.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=190)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5804/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5804/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5804/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 26 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874793 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-28T11:50:59.168+0000","updated":"2017-06-28T11:50:59.168+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16067753","id":"16067753","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874999/HIVE-16832.15.patch\n\n{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 10841 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=238)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=98)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5824/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5824/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5824/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 17 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874999 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-29T05:19:35.901+0000","updated":"2017-06-29T05:19:35.901+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16069180","id":"16069180","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12875110/HIVE-16832.16.patch\n\n{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 20 failed/errored test(s), 10833 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=141)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=146)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=100)\norg.apache.hadoop.hive.llap.security.TestLlapSignerImpl.testSigning (batchId=290)\norg.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.testVectorizedOrcAcidRowBatchReader (batchId=261)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5835/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5835/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5835/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 20 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12875110 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-29T23:21:20.441+0000","updated":"2017-06-29T23:21:20.441+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16075626","id":"16075626","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12875809/HIVE-16832.17.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5896/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5896/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5896/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-07-05 23:32:57.513\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-5896/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-07-05 23:32:57.516\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at c39b879 HIVE-16893: move replication dump related work in semantic analysis phase to execution phase using a task (Anishek Agarwal, reviewed by Sankar Hariappan, Daniel Dai)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at c39b879 HIVE-16893: move replication dump related work in semantic analysis phase to execution phase using a task (Anishek Agarwal, reviewed by Sankar Hariappan, Daniel Dai)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-07-05 23:33:02.202\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java\npatching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/BucketIdResolverImpl.java\npatching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/MutatorCoordinator.java\npatching file hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/MutatorImpl.java\npatching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/StreamingAssert.java\npatching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/TestMutations.java\npatching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestBucketIdResolverImpl.java\npatching file hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/worker/TestMutatorImpl.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/io/AcidOutputFormat.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/io/RecordIdentifier.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRawRecordMerger.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/parse/UpdateDeleteSemanticAnalyzer.java\npatching file ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2WithSplitUpdate.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2WithSplitUpdateAndVectorization.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/io/TestAcidUtils.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestInputOutputFormat.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcRawRecordMerger.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcRecordUpdater.java\npatching file ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestVectorizedOrcAcidRowBatchReader.java\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nDataNucleus Enhancer (version 4.1.17) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMetastoreDBProperties\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nDataNucleus Enhancer completed with success for 31 classes. Timings : input=153 ms, enhance=224 ms, total=377 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g\norg/apache/hadoop/hive/ql/parse/HintParser.g\nGenerating vector expression code\nGenerating vector expression test code\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[34,36] cannot find symbol\n  symbol:   class BucketCodec\n  location: package org.apache.hadoop.hive.ql.io\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java:[41,36] cannot find symbol\n  symbol:   class BucketCodec\n  location: package org.apache.hadoop.hive.ql.io\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java:[35,36] cannot find symbol\n  symbol:   class BucketCodec\n  location: package org.apache.hadoop.hive.ql.io\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java:[27,36] cannot find symbol\n  symbol:   class BucketCodec\n  location: package org.apache.hadoop.hive.ql.io\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[34,36] cannot find symbol\n[ERROR] symbol:   class BucketCodec\n[ERROR] location: package org.apache.hadoop.hive.ql.io\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java:[41,36] cannot find symbol\n[ERROR] symbol:   class BucketCodec\n[ERROR] location: package org.apache.hadoop.hive.ql.io\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRecordUpdater.java:[35,36] cannot find symbol\n[ERROR] symbol:   class BucketCodec\n[ERROR] location: package org.apache.hadoop.hive.ql.io\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java:[27,36] cannot find symbol\n[ERROR] symbol:   class BucketCodec\n[ERROR] location: package org.apache.hadoop.hive.ql.io\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12875809 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-05T23:34:15.964+0000","updated":"2017-07-05T23:34:15.964+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16075863","id":"16075863","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12875831/HIVE-16832.18.patch\n\n{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 10847 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=74)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5901/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5901/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5901/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 12 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12875831 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-06T03:29:30.652+0000","updated":"2017-07-06T03:29:30.652+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16078875","id":"16078875","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12876158/HIVE-16832.19.patch\n\n{color:green}SUCCESS:{color} +1 due to 11 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10848 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5917/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5917/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5917/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 8 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12876158 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-08T00:51:26.021+0000","updated":"2017-07-08T00:51:26.021+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16078972","id":"16078972","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12876176/HIVE-16832.20.patch\n\n{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10848 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5919/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5919/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5919/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 8 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12876176 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-08T05:58:35.983+0000","updated":"2017-07-08T05:58:35.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16079244","id":"16079244","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12876248/HIVE-16832.20.patch\n\n{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10848 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5920/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5920/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5920/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 6 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12876248 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-08T17:39:44.174+0000","updated":"2017-07-08T17:39:44.174+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16079255","id":"16079255","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"no related failures (for example, https://builds.apache.org/job/PreCommit-HIVE-Build/5916/#showFailuresLink has all the same ones)\n\n[~gopalv], could you review please","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-08T17:56:00.261+0000","updated":"2017-07-08T17:56:00.261+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16081773","id":"16081773","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"LGTM - +1.\n\nMinor comments - the bits used for bucket and statement ids are too big and misaligned (i.e 3:14:15), gets very hard to debug if looking at hex output (instead of raw binary). \n\nWith 4k buckets & 4k statements, (3:1(reserved):12:4(reserved):12), allows the hex output to be much more easily read, with 3 hex digits there - also possibly those 5 bits can come of some use later. \n\nThis patch is good and we can make the inner loops faster in a later iteration as the bucketproperty min-max is actually computed across the whole stripe/file (i.e if min==max, then no more checks needed).\n\nCompressed OTID got a bit bigger with this, perhaps it is better to build lists per statement id instead of storing it - that extra int will eat up 1 long worth of space, but the txn push-down from the main split -> delete deltas should ensure we never read too much data into that structure.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-07-11T07:08:02.621+0000","updated":"2017-07-11T07:08:02.621+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16082294","id":"16082294","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"\nI agree that Compressed OTID is now bigger but I'm not sure how useful it's in the first place.\nSuppose you populate a partition via 100 inserts and 1M rows.  So you have 100 OTIDs.\nNow if you run an update/delete with some WHERE clause it will match rows randomly wrt OTIDs on average.\nSo if this delete generates 500 events, it seems likely that you get a lot of distinct OTIDs among them.  Perhaps simply relying on the \"push down\" to delete deltas is enough and we are better off just keeping 3 arrays.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-11T14:36:17.061+0000","updated":"2017-07-11T14:36:17.061+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16082885","id":"16082885","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. Suppose you populate a partition via 100 inserts and 1M rows. So you have 100 OTIDs.\n\nYeah, this was an optimization for the possibility that you're doing an \"update every row\" merge which would otherwise cause a massive memory jump in deletes (& overflow the 2G limit on arrays).\n\nbq. Perhaps simply relying on the \"push down\" to delete deltas is enough and we are better off just keeping 3 arrays\n\nYes, it might be better - I've yet to really look into the delete distribution for a regular CDC workload. The push-down into deletes is a big win anyway.\n\nNot too worried about the extra size here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gopalv","name":"gopalv","key":"gopalv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gopal V","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-07-11T20:16:09.838+0000","updated":"2017-07-11T20:16:09.838+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16083104","id":"16083104","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"patch 21 addresses Gopal's comments","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-11T22:31:22.182+0000","updated":"2017-07-11T22:31:22.182+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16083333","id":"16083333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12876708/HIVE-16832.21.patch\n\n{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 10853 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=60)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.ql.TestTxnCommands.testNonAcidToAcidConversion01 (batchId=282)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion02 (batchId=269)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion02 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion02 (batchId=277)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5969/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5969/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5969/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 13 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12876708 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-12T02:36:52.299+0000","updated":"2017-07-12T02:36:52.299+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16084858","id":"16084858","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12876914/HIVE-16832.22.patch\n\n{color:green}SUCCESS:{color} +1 due to 12 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 10888 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=237)\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver[hbase_queries] (batchId=94)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5989/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5989/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5989/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 10 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12876914 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-12T22:45:27.069+0000","updated":"2017-07-12T22:45:27.069+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16084878","id":"16084878","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"no related failures (see builds 5985,5984 for same failures)\nHIVE-16832.22.patch committed to master (3.0)\nthanks Gopal for the review","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-12T23:03:50.060+0000","updated":"2017-07-12T23:03:50.060+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16085317","id":"16085317","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"body":"No-doc note:  This adds *hive.test.bucketcodec.version* to HiveConf.java, but it's for testing only so no user documentation is needed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftylev","name":"leftylev","key":"lefty@hortonworks.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lefty%40hortonworks.com&avatarId=15906","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lefty%40hortonworks.com&avatarId=15906","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lefty%40hortonworks.com&avatarId=15906","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lefty%40hortonworks.com&avatarId=15906"},"displayName":"Lefty Leverenz","active":true,"timeZone":"America/New_York"},"created":"2017-07-13T07:49:54.645+0000","updated":"2017-07-13T07:49:54.645+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13077771/comment/16486330","id":"16486330","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"body":"Hive 3.0.0 has been released so closing this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-23T00:00:11.209+0000","updated":"2018-05-23T00:00:11.209+0000"}],"maxResults":28,"total":28,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16832/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3fy0v:"}}