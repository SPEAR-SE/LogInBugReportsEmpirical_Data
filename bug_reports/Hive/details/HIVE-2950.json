{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12550726","self":"https://issues.apache.org/jira/rest/api/2/issue/12550726","key":"HIVE-2950","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2012-04-12T19:19:17.316+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jul 17 17:08:45 UTC 2012","customfield_12310420":"235590","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_8265310356_*|*_1_*:*_1_*:*_21818473_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-07-17T17:08:44.965+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-2950/watchers","watchCount":2,"isWatching":false},"created":"2012-04-12T19:09:56.280+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12350490","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12350490","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12550432","key":"HIVE-2941","self":"https://issues.apache.org/jira/rest/api/2/issue/12550432","fields":{"summary":"Hive should expand nested structs when setting the table schema from thrift structs","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12353659","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12353659","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12560824","key":"HIVE-3144","self":"https://issues.apache.org/jira/rest/api/2/issue/12560824","fields":{"summary":"Custom Deserializers Should be Used for Thrift Table Objects","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12354116","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12354116","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12596524","key":"HCATALOG-443","self":"https://issues.apache.org/jira/rest/api/2/issue/12596524","fields":{"summary":"Serde-reported schema support, enums as strings, misc fixes","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-07-17T17:08:45.104+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Hive tables have a schema, which is copied into the partition storage descriptor when adding a partition. Currently only columns stored in the table storage descriptor are copied - columns that are reported by the serde are not copied. Instead of copying the table storage descriptor columns into the partition columns, the full table schema should be copied.\n\n\nDETAILS\n\nThis is a little long but is necessary to show 3 things: current behavior when explicitly listing columns, behavior with HIVE-2941 patched in and serde reported columns, and finally the behavior with this patch (full table schema copied into the partition storage descriptor).\n\n\nHere's an example of what currently happens. Note the following:\n\n* the two manually-defined fields defined for the table are listed in the table storage descriptor.\n* both fields are present in the partition storage descriptor\n\nThis works great because users who query for a partition can look at its storage descriptor and get the schema.\n\n{code}\nhive> create external table foo_test (name string, age int) partitioned by (part_dt string);\nhive> describe extended foo_test;\nOK\nname\tstring\t\nage\tint\t\npart_dt\tstring\t\n\t \t \nDetailed Table Information\tTable(tableName:foo_test, dbName:travis_test, owner:travis, createTime:1334256062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null), FieldSchema(name:age, type:int, comment:null), FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/warehouse/travis_test.db/foo_test, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), partitionKeys:[FieldSchema(name:part_dt, type:string, comment:null)], parameters:{EXTERNAL=TRUE, transient_lastDdlTime=1334256062}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\t\nTime taken: 0.082 seconds\n\nhive> alter table foo_test add partition (part_dt = '20120331T000000Z') location 'hdfs://foo.com/foo/2012/03/31/00';\nhive> describe extended foo_test partition (part_dt = '20120331T000000Z');\nOK\nname\tstring\t\nage\tint\t\npart_dt\tstring\t\n\t \t \nDetailed Partition Information\tPartition(values:[20120331T000000Z], dbName:travis_test, tableName:foo_test, createTime:1334256131, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null), FieldSchema(name:age, type:int, comment:null), FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/foo/2012/03/31/00, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), parameters:{transient_lastDdlTime=1334256131})\t\n{code}\n\n\n\n\nCURRENT BEHAVIOR WITH HIVE-2941 PATCHED IN\n\nNow let's examine what happens when creating a table when the serde reports the schema. Notice the following:\n\n* The table storage descriptor contains an empty list of columns. However, the table schema is available from the serde reflecting on the serialization class.\n* The partition storage descriptor does contain a single \"part_dt\" column that was copied from the table partition keys. The actual data columns are not present.\n\n{code}\nhive> create external table travis_test.person_test partitioned by (part_dt string) row format serde \"com.twitter.elephantbird.hive.serde.ThriftSerDe\" with serdeproperties (\"serialization.class\"=\"com.twitter.elephantbird.examples.thrift.Person\") stored as inputformat \"com.twitter.elephantbird.mapred.input.HiveMultiInputFormat\" outputformat \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\";\nOK\nTime taken: 0.08 seconds\nhive> describe extended person_test;\nOK\nname\tstruct<first_name:string,last_name:string>\tfrom deserializer\nid\tint\tfrom deserializer\nemail\tstring\tfrom deserializer\nphones\tarray<struct<number:string,type:struct<value:int>>>\tfrom deserializer\npart_dt\tstring\t\n\t \t \nDetailed Table Information\tTable(tableName:person_test, dbName:travis_test, owner:travis, createTime:1334256942, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[], location:hdfs://foo.com/warehouse/travis_test.db/person_test, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), partitionKeys:[FieldSchema(name:part_dt, type:string, comment:null)], parameters:{EXTERNAL=TRUE, transient_lastDdlTime=1334256942}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\t\nTime taken: 0.147 seconds\nhive> alter table person_test add partition (part_dt = '20120331T000000Z') location 'hdfs://foo.com/foo/2012/03/31/00'; \nOK\nTime taken: 0.149 seconds\nhive> describe extended person_test partition (part_dt = '20120331T000000Z');\nOK\npart_dt\tstring\t\n\t \t \nDetailed Partition Information\tPartition(values:[20120331T000000Z], dbName:travis_test, tableName:person_test, createTime:1334257029, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/foo/2012/03/31/00, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), parameters:{transient_lastDdlTime=1334257029})\t\nTime taken: 0.106 seconds\nhive> \n{code}\n\n\nPROPOSED BEHAVIOR\n\n\nI believe the correct thing to do is copy the full table schema (serde-reported columns + partition keys) into the partition storage descriptor. Notice the following:\n\n* Table storage descriptor does not contain any columns, because they are reported by the serde.\n* Partition storage descriptor now contains both the serde-reported schema, and full table schema.\n\n{code}\nhive> create external table travis_test.person_test partitioned by (part_dt string) row format serde \"com.twitter.elephantbird.hive.serde.ThriftSerDe\" with serdeproperties (\"serialization.class\"=\"com.twitter.elephantbird.examples.thrift.Person\") stored as inputformat \"com.twitter.elephantbird.mapred.input.HiveMultiInputFormat\" outputformat \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\";\nOK\nTime taken: 0.076 seconds\nhive> describe extended person_test;                                                                                                                                     OK                                                                                                                                                                       name    struct<first_name:string,last_name:string>      from deserializer\nid\tint\tfrom deserializer\nemail\tstring\tfrom deserializer\nphones\tarray<struct<number:string,type:struct<value:int>>>\tfrom deserializer\npart_dt\tstring\t\n\t \t \nDetailed Table Information\tTable(tableName:person_test, dbName:travis_test, owner:travis, createTime:1334257489, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[], location:hdfs://foo.com/warehouse/travis_test.db/person_test, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), partitionKeys:[FieldSchema(name:part_dt, type:string, comment:null)], parameters:{EXTERNAL=TRUE, transient_lastDdlTime=1334257489}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\t\nTime taken: 0.155 seconds\nhive> alter table person_test add partition (part_dt = '20120331T000000Z') location 'hdfs://foo.com/foo/2012/03/31/00';\nOK                                                                                                                                                                       Time taken: 0.296 seconds                                        \nhive> describe extended person_test partition (part_dt = '20120331T000000Z');                                                                                            OK                                                                                                                                                                       name    struct<first_name:string,last_name:string>      from deserializer\nid\tint\tfrom deserializer\nemail\tstring\tfrom deserializer\nphones\tarray<struct<number:string,type:struct<value:int>>>\tfrom deserializer\npart_dt\tstring\t\n\t \t \nDetailed Partition Information\tPartition(values:[20120331T000000Z], dbName:travis_test, tableName:person_test, createTime:1334257504, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:struct<first_name:string,last_name:string>, comment:from deserializer), FieldSchema(name:id, type:int, comment:from deserializer), FieldSchema(name:email, type:string, comment:from deserializer), FieldSchema(name:phones, type:array<struct<number:string,type:struct<value:int>>>, comment:from deserializer), FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/foo/2012/03/31/00, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), parameters:{transient_lastDdlTime=1334257504})\t\nTime taken: 0.133 seconds\nhive> \n{code}\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12522472","id":"12522472","filename":"ASF.LICENSE.NOT.GRANTED--HIVE-2950.D2769.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phabricator%40reviews.facebook.net","name":"phabricator@reviews.facebook.net","key":"phabricator@reviews.facebook.net","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Phabricator","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-12T19:19:19.696+0000","size":1141,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12522472/ASF.LICENSE.NOT.GRANTED--HIVE-2950.D2769.1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"124246","customfield_12312823":null,"summary":"Hive should store the full table schema in partition storage descriptors","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13252754","id":"13252754","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phabricator%40reviews.facebook.net","name":"phabricator@reviews.facebook.net","key":"phabricator@reviews.facebook.net","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Phabricator","active":true,"timeZone":"Etc/UTC"},"body":"travis requested code review of \"HIVE-2950 [jira] Hive should store the full table schema in partition storage descriptors\".\nReviewers: JIRA\n\n  When adding a partition, copy the full table schema into the partition storage descriptor. The table storage descriptor may not contain the full schema when using a serde that reports its schema. This change makes partitions with serde-reported schema behave the same as partitions without a serde-reported schem.\n\n  Hive tables have a schema, which is copied into the partition storage descriptor when adding a partition. Currently only columns stored in the table storage descriptor are copied - columns that are reported by the serde are not copied. Instead of copying the table storage descriptor columns into the partition columns, the full table schema should be copied.\n\n  DETAILS\n\n  This is a little long but is necessary to show 3 things: current behavior when explicitly listing columns, behavior with HIVE-2941 patched in and serde reported columns, and finally the behavior with this patch (full table schema copied into the partition storage descriptor).\n\n  Here's an example of what currently happens. Note the following:\n\n  \tthe two manually-defined fields defined for the table are listed in the table storage descriptor.\n  \tboth fields are present in the partition storage descriptor\n\n  This works great because users who query for a partition can look at its storage descriptor and get the schema.\n\n  hive> create external table foo_test (name string, age int) partitioned by (part_dt string);\n  hive> describe extended foo_test;\n  OK\n  name\tstring\n  age\tint\n  part_dt\tstring\n\n  Detailed Table Information\tTable(tableName:foo_test, dbName:travis_test, owner:travis, createTime:1334256062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null), FieldSchema(name:age, type:int, comment:null), FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/warehouse/travis_test.db/foo_test, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), partitionKeys:[FieldSchema(name:part_dt, type:string, comment:null)], parameters:{EXTERNAL=TRUE, transient_lastDdlTime=1334256062}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\n  Time taken: 0.082 seconds\n\n  hive> alter table foo_test add partition (part_dt = '20120331T000000Z') location 'hdfs://foo.com/foo/2012/03/31/00';\n  hive> describe extended foo_test partition (part_dt = '20120331T000000Z');\n  OK\n  name\tstring\n  age\tint\n  part_dt\tstring\n\n  Detailed Partition Information\tPartition(values:[20120331T000000Z], dbName:travis_test, tableName:foo_test, createTime:1334256131, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:string, comment:null), FieldSchema(name:age, type:int, comment:null), FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/foo/2012/03/31/00, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), parameters:{transient_lastDdlTime=1334256131})\n\n  CURRENT BEHAVIOR WITH HIVE-2941 PATCHED IN\n\n  Now let's examine what happens when creating a table when the serde reports the schema. Notice the following:\n\n  \tThe table storage descriptor contains an empty list of columns. However, the table schema is available from the serde reflecting on the serialization class.\n  \tThe partition storage descriptor does contain a single \"part_dt\" column that was copied from the table partition keys. The actual data columns are not present.\n\n  hive> create external table travis_test.person_test partitioned by (part_dt string) row format serde \"com.twitter.elephantbird.hive.serde.ThriftSerDe\" with serdeproperties (\"serialization.class\"=\"com.twitter.elephantbird.examples.thrift.Person\") stored as inputformat \"com.twitter.elephantbird.mapred.input.HiveMultiInputFormat\" outputformat \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\";\n  OK\n  Time taken: 0.08 seconds\n  hive> describe extended person_test;\n  OK\n  name\tstruct<first_name:string,last_name:string>\tfrom deserializer\n  id\tint\tfrom deserializer\n  email\tstring\tfrom deserializer\n  phones\tarray<struct<number:string,type:struct<value:int>>>\tfrom deserializer\n  part_dt\tstring\n\n  Detailed Table Information\tTable(tableName:person_test, dbName:travis_test, owner:travis, createTime:1334256942, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[], location:hdfs://foo.com/warehouse/travis_test.db/person_test, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), partitionKeys:[FieldSchema(name:part_dt, type:string, comment:null)], parameters:{EXTERNAL=TRUE, transient_lastDdlTime=1334256942}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\n  Time taken: 0.147 seconds\n  hive> alter table person_test add partition (part_dt = '20120331T000000Z') location 'hdfs://foo.com/foo/2012/03/31/00';\n  OK\n  Time taken: 0.149 seconds\n  hive> describe extended person_test partition (part_dt = '20120331T000000Z');\n  OK\n  part_dt\tstring\n\n  Detailed Partition Information\tPartition(values:[20120331T000000Z], dbName:travis_test, tableName:person_test, createTime:1334257029, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/foo/2012/03/31/00, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), parameters:{transient_lastDdlTime=1334257029})\n  Time taken: 0.106 seconds\n  hive>\n\n  PROPOSED BEHAVIOR\n\n  I believe the correct thing to do is copy the full table schema (serde-reported columns + partition keys) into the partition storage descriptor. Notice the following:\n\n  \tTable storage descriptor does not contain any columns, because they are reported by the serde.\n  \tPartition storage descriptor now contains both the serde-reported schema, and full table schema.\n\n  hive> create external table travis_test.person_test partitioned by (part_dt string) row format serde \"com.twitter.elephantbird.hive.serde.ThriftSerDe\" with serdeproperties (\"serialization.class\"=\"com.twitter.elephantbird.examples.thrift.Person\") stored as inputformat \"com.twitter.elephantbird.mapred.input.HiveMultiInputFormat\" outputformat \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\";\n  OK\n  Time taken: 0.076 seconds\n  hive> describe extended person_test;                                                                                                                                     OK                                                                                                                                                                       name    struct<first_name:string,last_name:string>      from deserializer\n  id\tint\tfrom deserializer\n  email\tstring\tfrom deserializer\n  phones\tarray<struct<number:string,type:struct<value:int>>>\tfrom deserializer\n  part_dt\tstring\n\n  Detailed Table Information\tTable(tableName:person_test, dbName:travis_test, owner:travis, createTime:1334257489, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[], location:hdfs://foo.com/warehouse/travis_test.db/person_test, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), partitionKeys:[FieldSchema(name:part_dt, type:string, comment:null)], parameters:{EXTERNAL=TRUE, transient_lastDdlTime=1334257489}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)\n  Time taken: 0.155 seconds\n  hive> alter table person_test add partition (part_dt = '20120331T000000Z') location 'hdfs://foo.com/foo/2012/03/31/00';\n  OK                                                                                                                                                                       Time taken: 0.296 seconds\n  hive> describe extended person_test partition (part_dt = '20120331T000000Z');                                                                                            OK                                                                                                                                                                       name    struct<first_name:string,last_name:string>      from deserializer\n  id\tint\tfrom deserializer\n  email\tstring\tfrom deserializer\n  phones\tarray<struct<number:string,type:struct<value:int>>>\tfrom deserializer\n  part_dt\tstring\n\n  Detailed Partition Information\tPartition(values:[20120331T000000Z], dbName:travis_test, tableName:person_test, createTime:1334257504, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:name, type:struct<first_name:string,last_name:string>, comment:from deserializer), FieldSchema(name:id, type:int, comment:from deserializer), FieldSchema(name:email, type:string, comment:from deserializer), FieldSchema(name:phones, type:array<struct<number:string,type:struct<value:int>>>, comment:from deserializer), FieldSchema(name:part_dt, type:string, comment:null)], location:hdfs://foo.com/foo/2012/03/31/00, inputFormat:com.twitter.elephantbird.mapred.input.HiveMultiInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:com.twitter.elephantbird.hive.serde.ThriftSerDe, parameters:{serialization.class=com.twitter.elephantbird.examples.thrift.Person, serialization.format\n =1}), bucketCols:[], sortCols:[], parameters:{}, primaryRegionName:, secondaryRegions:[]), parameters:{transient_lastDdlTime=1334257504})\n  Time taken: 0.133 seconds\n  hive>\n\nTEST PLAN\n  empty\n\nREVISION DETAIL\n  https://reviews.facebook.net/D2769\n\nAFFECTED FILES\n  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java\n\nMANAGE HERALD DIFFERENTIAL RULES\n  https://reviews.facebook.net/herald/view/differential/\n\nWHY DID I GET THIS EMAIL?\n  https://reviews.facebook.net/herald/transcript/6297/\n\nTip: use the X-Herald-Rules header to filter Herald messages in your client.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phabricator%40reviews.facebook.net","name":"phabricator@reviews.facebook.net","key":"phabricator@reviews.facebook.net","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Phabricator","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-12T19:19:17.316+0000","updated":"2012-04-12T19:19:17.316+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13260064","id":"13260064","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"body":"Would it be possible for someone to take a look at this patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-23T23:02:43.898+0000","updated":"2012-04-23T23:02:43.898+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13291338","id":"13291338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"body":"Updated the branch against trunk and reran the tests.\n\nhttps://travis.ci.cloudbees.com/job/HIVE-2950_partition_full_schema/1/\n\nThere were some test failures in CI so I ran these locally and they passed:\n\n{code}\nant clean package test -Dtestcase=TestCliDriver -Dqfile=create_view_partitioned.q\nant clean package test -Dtestcase=TestNegativeCliDriver -Dqfile=create_or_replace_view1.q\nant clean package test -Dtestcase=TestNegativeCliDriver -Dqfile=create_or_replace_view2.q\nant clean package test -Dtestcase=TestHiveServerSessions\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-07T21:43:18.843+0000","updated":"2012-06-07T21:43:18.843+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13293218","id":"13293218","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"@Travis,\nCan you upload the latest patch at jira. Unfortunately, Phabricator doesn't let you download a patch file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-12T00:16:39.644+0000","updated":"2012-06-12T00:16:39.644+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13293227","id":"13293227","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"body":"The patch is actually the same - the one attached to Jira is up-to-date.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-12T00:33:54.444+0000","updated":"2012-06-12T00:33:54.444+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13404357","id":"13404357","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"body":"Status update:\n\nLooking into this a bit more, I think we can avoid storing the cols in the metastore if we simply allow partitions to report cols from the serde. Something like this:\n\n{code:title=ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java}\n   public List<FieldSchema> getCols() {\n-    return tPartition.getSd().getCols();\n+    if (SerDeUtils.shouldGetColsFromSerDe(table.getSerializationLib())) {\n+      return table.getCols();\n+    } else {\n+      return tPartition.getSd().getCols();\n+    }\n   }\n{code}\n\nFor thrift/protobuf this would work perfectly, since you want all records to have the newest schema, and let thrift/protobuf deal with figuring out missing values, unknown fields, etc.\n\nThoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-30T01:23:04.826+0000","updated":"2012-06-30T01:23:04.826+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13405317","id":"13405317","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Travis,\nI liked your first patch better then this one. Semantics is that when you add partition, you store *current* table's schema in Partition's storage descriptor (which is what your first patch is doing). Your second approach will return the table schema for Partition at the read time, by which time table's schema might have changed. I will test and commit your first patch. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-02T20:45:45.675+0000","updated":"2012-07-02T20:45:45.675+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13405332","id":"13405332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"body":"In some cases (storing thrift/protobufs) reporting the read-time schema is preferable to the write-time schema. For example, let's say you're storing thrift structs and add a new optional field with default value. In that case all your old records would be automatically upgraded if using the read-time field reporting.\n\nI played around with this over the weekend and think it could look something like this. If the partition storage descriptor has a serde that you should get the cols from, then do that. Otherwise, use the fields stored in the metastore. Since this is per-partition you could have some partitions using serde-reported fields, and other partitions using hard-coded ones.\n\n{code:title=ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java}\n-  public List<FieldSchema> getCols() {\n-    return tPartition.getSd().getCols();\n+  public List<FieldSchema> getCols() throws HiveException {\n+    if (SerDeUtils.shouldGetColsFromSerDe(\n+        tPartition.getSd().getSerdeInfo().getSerializationLib())) {\n+      return Hive.getFieldsFromDeserializer(table.getTableName(), getDeserializer());\n+    } else {\n+      return tPartition.getSd().getCols();\n+    }\n{code}\n\nThoughts? I still think the original patch (copy table columns into partition storage descriptor at write time) is an improvement, but this dynamic approach would be awesome. Some of our schemas are pretty large so this would save a lot of metastore space :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-02T21:25:47.543+0000","updated":"2012-07-02T21:25:47.543+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12550726/comment/13416365","id":"13416365","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"body":"After looking at this further, this change is not actually needed.\n\nThe confusion arises from Hive having two sets of classes to represent the main objects (tables, partitions, ...). If you use metastore.api classes the fields are not available unless stored in the metastore. However, if using the ql.metadata classes, Partition copies the table fields to the partition if they're empty. This works great for thrift-based tables.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=traviscrawford","name":"traviscrawford","key":"traviscrawford","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=traviscrawford&avatarId=26745","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=traviscrawford&avatarId=26745","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=traviscrawford&avatarId=26745","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=traviscrawford&avatarId=26745"},"displayName":"Travis Crawford","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-17T17:08:45.035+0000","updated":"2012-07-17T17:08:45.035+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-2950/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0lm73:"}}