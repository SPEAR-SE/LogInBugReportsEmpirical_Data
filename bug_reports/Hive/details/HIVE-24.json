{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12403646","self":"https://issues.apache.org/jira/rest/api/2/issue/12403646","key":"HIVE-24","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313637","id":"12313637","description":"released","name":"0.3.0","archived":false,"released":true,"releaseDate":"2009-04-30"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-09-04T22:18:02.940+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Nov 17 01:30:47 UTC 2008","customfield_12310420":"73827","customfield_12312320":null,"customfield_12310222":"10002_*:*_2_*:*_4675495269_*|*_1_*:*_2_*:*_1727419817_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2008-11-17T01:30:48.086+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-24/watchers","watchCount":10,"isWatching":false},"created":"2008-09-03T22:55:33.282+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12321589","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12321589","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"outwardIssue":{"id":"12403645","key":"HIVE-20","self":"https://issues.apache.org/jira/rest/api/2/issue/12403645","fields":{"summary":"Hive should be able to create tables over binary flat files","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12321681","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12321681","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12404460","key":"HADOOP-4192","self":"https://issues.apache.org/jira/rest/api/2/issue/12404460","fields":{"summary":"Class <? extends T> Deserializer.getRealClass() method to return the actual class of the objects from a deserializer","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12321716","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12321716","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12400531","key":"MAPREDUCE-376","self":"https://issues.apache.org/jira/rest/api/2/issue/12400531","fields":{"summary":"Add serialization for Thrift","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/5","id":"5","description":"General wishlist item.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Wish","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-12-17T00:09:05.551+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312585","id":"12312585","name":"Serializers/Deserializers","description":"Tracks issues dealing with serdes"}],"timeoriginalestimate":null,"description":"like textinputformat - looking for a concrete implementation to read binary records from a flat file (that may be compressed).\n\nit's assumed that hadoop can't split such a file. so the inputformat can set splittable to false.\n\ntricky aspects are:\n- how to know what class the file contains (has to be in a configuration somewhere).\n- how to determine EOF (would be nice if hadoop can determine EOF and not have the deserializer throw an exception  (which is hard to distinguish from a exception due to corruptions?)). this is easy for non-compressed streams - for compressed streams - DecompressorStream has a useful looking getAvailable() call - except the class is marked package private.\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12390331","id":"12390331","filename":"FlatFileReader.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-18T03:09:37.018+0000","size":10334,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12390331/FlatFileReader.java"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12389715","id":"12389715","filename":"HADOOP-4065.0.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T01:35:34.894+0000","size":13182,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12389715/HADOOP-4065.0.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12390340","id":"12390340","filename":"HADOOP-4065.1.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-18T04:46:22.285+0000","size":18429,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12390340/HADOOP-4065.1.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12390145","id":"12390145","filename":"HADOOP-4065.1.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-15T23:22:36.607+0000","size":16198,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12390145/HADOOP-4065.1.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12390798","id":"12390798","filename":"HADOOP-4065.2.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-23T22:45:03.760+0000","size":34840,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12390798/HADOOP-4065.2.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12389716","id":"12389716","filename":"ThriftFlatFile.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T01:42:37.762+0000","size":2515,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12389716/ThriftFlatFile.java"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"108038","customfield_12312823":null,"summary":"support for reading binary data from flat files","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12628192","id":"12628192","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"see https://issues.apache.org/jira/browse/HADOOP-4065 as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-09-03T22:56:09.183+0000","updated":"2008-09-03T22:56:09.183+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12628484","id":"12628484","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"How are you going to define/find record boundaries? Is it going to be key/value or single blob? How is it different from KeyValueInputFormat?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-04T22:18:02.940+0000","updated":"2008-09-04T22:18:02.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12628526","id":"12628526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"I think what he means is that file format and record boundary finding could be decoupled, and the latter made into some kind of interface that may be related to the deserializer. He's talking about binary data for which only really the deserializer can figure out record boundaries. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-04T23:51:42.771+0000","updated":"2008-09-04T23:51:42.771+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12628530","id":"12628530","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"It would be nice to also take care of the case where the file is self describing like sequence files. If we had a FlatFileRecordReader(conf, split, serializerFactory) where the serializerFactory could be initialized with the conf, split and the input stream, it could optionally read the self describing data from the inputstream. Then regardless, it could be used to implement getKey and getValue which it could do from the self described data or as you said based on the path. Or it could just instantiate the factory from a conf variable.\n\nThen the user is free to implement the serializer lookup however they want much like most of the rest of the system.\n\nThis means the serializer lookup is very low in the stack, but since one must implement next and as Joy points out, you can't do that without the serializer??\n\nThis solves this case, but also the case of self describing thrift TRecordStream since the serializer class info would be in the header itself.\n\nIt would also be nice if the underlying input stream could actually be an interface because sometimes there's a flat file, but other times it may be compressed or some other format, but that format is capable of producing a stream of bytes. \n\nSo, I guess I'm advocating for flexibility in defining the serializer lookup logic as well as how to read from the file.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-05T01:22:02.207+0000","updated":"2008-09-05T01:22:02.207+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12628658","id":"12628658","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"Ok, a dispatching FileInputFormat could make sense. Where it looked at the\nfilenames or header of the files and picked the appropriate reader. At that\npoint, it isn't about binary files, because you'd want it to work for text\nfiles also. What would be the approach? Filenames like we do with the\ncompression of text files? Or sampling the first 80 bytes looking for a\nheader?\n\n-- Owen\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-05T15:50:46.591+0000","updated":"2008-09-05T15:50:46.591+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12628679","id":"12628679","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"I think in Joy's case, it would be the filename and/or with some configuration info in the jobconf.  In the TRecordStream case, we would need to use some code from TFixedFrameTransport to read the frame headers - TFixedFrameTransport is splittable. (TRS is a thin layer on top of TFFT).\n\nJoy or I can post a proposed API.\n\ngood point, we should make it general and not just for binary.\n\npete\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-05T17:29:55.878+0000","updated":"2008-09-05T17:29:55.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12628806","id":"12628806","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"I propose we re-use the code from SequenceFileRecordReader by making it depend on a SplittableTypedFile interace (below) which conveniently is already implemented by SequenceFile.  Then we're basically done. \n\nI am not super-familiar with this code and the devil is probably in the details, but looking at SequenceFileRecordReader, there is basically only about 5 methods it uses from SequenceFile and those are all well defined and seem needed for any implementation of a self describing file that is splittable.\n\nWe could also not touch SequenceFileRecordReader, but it seems we'd just be duplicating all of its code.\n\n\n{code:title=TypedFile Interfaces}\n\n                                                                                                                                                                                      public interface TypedFile  {                                                                                                                                                         \n  public void initialize(Configuration conf, InputStream in);                                                                                                                         \n  public Class getKeyClass();                                                                                                                                                         \n  public Class getValueClass();                                                                                                                                                       \n                                                                                                                                                                                      \n  public boolean next(Writable key);                                                                                                                                                  \n  public boolean next(Writable key, Writable value);                                                                                                                                  \n  public Writable getCurrentValue();                                                                                                                                                  \n}                                                                                                                                                                                     \n                                                                                                                                                                                      \npublic interface SplittableTypedFile implements TypedFile {                                                                                                                           \n  public boolean syncSeen(); // i.e., atEOF()                                                                                                                                         \n  public boolean sync(long); // skip to past last frame boundary                                                                                                                      \n}                                                                                                                                                                                     \n                                                                                                                                                                                      \n{code}\n\n{code:title=TypedSplittableRecordReader }\n\n// This is almost a complete cut-n-paste of existing SequenceFileRecordReader - which would be removed\n\npublic class TypedSplittableRecordReader<K, V> implements RecordReader<K,V> {                                                                                                         \n  SplittableTypedFile in;                                                                                                                                                             \n  public TypedRecordReader(Configuration conf, FileSplit split, SplittableTypedFileFactory<K,V> fileFactory) {                                                                        \n    this.in = fileFactory.getFileReader(fs, path, conf);                                                                                                                              \n  }                                                                                                                                                                                   \n  // the rest is exactly like the current sequence file implementation basically.                                                                                                     \n}                                                                                                                                                                                     \n                                                                                                                                                                                      \n{code}\n\n{code:title=SequenceFile}\n\n-public class SequenceFile {\n+public class SequenceFile implements SplittableTypedFile {                                                                                                                                  \n                                                                                                                                                                                      \n{code}\n\n{code:title=SequenceFileInputFormat}                                                                                                                                                                                      \n\npublic class SequenceFileInputFormat<K, V> extends FileInputFormat<K, V> {                                                                                                            \n  public RecordReader<K,V> getRecordReader() {                                                                                                                                        \n    return TypedSplittableRecordReader<K, V>(job, split, new SequenceFileFactory<K,V>());                                                                                             \n  }                                                                                                                                                                                   \n}                            \n\n{code}\n\n{code:title=SelfDescribingFileExample}\npublic class TFixedFrameTransportInputFormat implements SplittableTypedFile {                                                                                                         \n  // implementing all the above should be straightforward                                                                                                                             \n}                                                                                                                                                                                     \n\npublic class TFixedFrameTransportFileInputFormat<K, V> extends FileInputFormat<K, V> {                                                                                                \n  public RecordReader<K,V> getRecordReader() {                                                                                                                                        \n    return TypedSplittableRecordReader<K, V>(job, split, new TFixedFrameFileFactory<K,V>());                                                                                          \n  }                                                                                                                                                                                   \n}                                                                                                                                                                                     \n\n{code}\n\nOne problem is for non-splittable files, I have to create another record reader with almost the same code. Maybe better to put everything in one interface and add boolean isSplittable and have sync just do a seek(0) and syncSeen just look at EOF.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-06T00:45:43.703+0000","updated":"2008-09-06T00:45:43.703+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629296","id":"12629296","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"I just wanted to post pseudo-code for this design that actually addresses this JIRA :) and not only self describing files like SequenceFile and Thrift's TRecordStream.\n\nIn the case for this JIRA, the file's metadata is stored in some external store or dictionary or something.  The only way to lookup the file would be through the filename/path, so I think it's fair that on job submission, the mapping is put in the JobConf.\n\nGiven this use case, and looking at line 43 of SequenceFileRecordReader (   this.in = new SequenceFile.Reader(fs, path, conf); ), the TypeFile        interface should be changed:\n\n- public void initialize(Configuration conf, InputStream in);                                                                                                                         \n+ public void initialize(FileSystem, Path, Configuration);\n\nObviously it has top open the inputstream anyway ( :) ).  \n\nAnd a typo SequenceFile would not implement SplittableTypedFile, SequenceFile.Reader would.\n                                         \n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-08T21:22:44.479+0000","updated":"2008-09-08T21:22:44.479+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629298","id":"12629298","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"body":"we at yahoo have been working on similar kind of files where data is just stored as binary data and is splittable. \n\nhttp://issues.apache.org/jira/browse/HADOOP-3315\n\nthe  spec is old and needs to be updated. TFile is meant to be a sequence file replacement.\n\n\n  A TFile is a container of key-value pairs. Both keys and values are type-less\n  byte arrays. Keys can be up to 64KB, value length is not restricted. TFile\n  further provides the following features:\n- Block Compression.\n- Named meta data blocks.\n- Sorted or unsorted keys.\n- Seek by key or by file offset.\n\nWe will update the specs on HADOOP-3315 by the end of this week. \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-08T21:32:10.171+0000","updated":"2008-09-08T21:32:10.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629305","id":"12629305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"Nice. Will the TFileRecordReader fit into this paradigm?  How were you going to implement the TFileRecordReader?\n\nTFile is very similar to TRecordStream - but more full featured - sorted and seek by key. But, TRecordStream is meant to be readable/writable in many languages (first cut c++, java, python and perl). It's primary use case is non-hadoop - just a robust way of logging data, but secondarily, there's no reason not to enable directly reading/writing to one from Hadoop as it's a waste to open one, read it and write it out as a TFile or SF if one doesn't need the richer functionality that sequence file and tfile support.\n\n\n\n-- pete\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-08T21:46:41.921+0000","updated":"2008-09-08T21:46:41.921+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629315","id":"12629315","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"body":"the tfilerecordreader would just return raw bytes for keys and values and its up to the application to convert the raw bytes to types. Though as far as our implementation goes right now -- we dont have a map reduce interface for Tfiles. We intend to provide one.\n\nThe TFile is also supposed to be readable/writable in  other languages with the spec being clear enough on how to read and write Tfiles. We intend to provide just java implementation of Tfiles though. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-08T22:22:00.893+0000","updated":"2008-09-08T22:22:00.893+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629339","id":"12629339","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"Actual interface\n\n{code:title=TypedSplittableFile.java}\n\npublic interface TypedSplittableFile {                                                                                                                                                                         \n  public void initialize(FileSystem fileSys, Path path, Configuration conf) throws IOException;                                                                                                                \n                                                                                                                                                                                                               \n  public Class getKeyClass() ;                                                                                                                                                                                 \n  public Class getValueClass();                                                                                                                                                                                \n                                                                                                                                                                                                               \n  public Object next(Object key) throws IOException;                                                                                                                                                           \n  public Object getCurrentValue(Object val) throws IOException ;                                                                                                                                               \n                                                                                                                                                                                                               \n  public boolean syncSeen(); // i.e., atEOF()                                                                                                                                                                  \n  public void sync(long position) throws IOException; // skip to past last frame boundary                                                                                                                      \n  public long getPosition() throws IOException;                                                                                                                                                                \n  public void seek(long position) throws IOException;                                                                                                                                                          \n  public void close() throws IOException;                                                                                                                                                                      \n                                                                                                                                                                                                               \n}    \n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-08T23:56:19.386+0000","updated":"2008-09-08T23:56:19.386+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629342","id":"12629342","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"bq. The TFile is also supposed to be readable/writable in other languages with the spec being clear enough on how to read and write Tfiles. We intend to provide just java implementation of Tfiles though.\n\nFair enough. If we had TFile in a number of languages it could probably be put in as a thrift transport. TRS is much simpler though and thus much easier to write in other languages.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T00:06:42.248+0000","updated":"2008-09-09T00:06:42.248+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629359","id":"12629359","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"This is what the proposal would look like. It:\n\n1. adds the TypedSplittableFile interface\n2. changes SequenceFile.Reader to implement TypedSplittableFile and adds an initialize method and an empty constructor\n3. implements TypedSplittableFileRecordReader - just copied the code from SequenceFileRecordReader and changed the constructor only\n4. change SequenceFileRecordReader to extend TypedSplittableFileRecordReader and have its constructor just construct the parent class.\n\nStill a work in progress, but this kind of shows the API and the changes to SequenceFileRecordReader.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T01:35:34.928+0000","updated":"2008-09-09T01:35:34.928+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629360","id":"12629360","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"psuedo-esque code that implements Thrift in FlatFiles where the filename is used as the key to get the thrift class from the configuration.  Implements <LongWritable, ThriftWritable>;\n\nOf course, it may be that we want to use the serialization classes.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T01:42:37.806+0000","updated":"2008-09-09T01:42:37.806+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629362","id":"12629362","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"@Pete - i am still trying to understand the proposed interface. in my case - the data is not splitable (so maybe there's a different base class - UnsplittableFileInputFormat). The factory approach for getting a record reader sounds interesting - but on second thoughts - since the getRR() already takes in a Configuration object - we don't need a new interface for this i think. (Meaning that we could write a ConfigurableRecordReader that could look at the config and instantiate the right record reader and then redirect all RR api calls to the contained record reader.)\n\nthe main motivation i had for filing this bug was to extract out the common parts for dealing with compressed, non-splitable binary data into a base class (and most of this functionality is in the record reader) and make it easy to handle new kinds of binary data with minimal code. Binary files don't have keys and values - they just have rows of data. So one part is to supply some default key (like record number). The remaining part is to get the class of the row and the deserialization method. Appropriately - it would be nice to have a deserializerFactory that takes in a Configuration object (which is i think one of the key missing parts of hadoop-1986). that way - the deserializer can be configured by application - instead of hadoop maintaining a mapping from class -> Deserializer.\n\nso my proposal would be something like this (admittedly - i am not being very ambitious here - just want to cover the issue mentioned in this jira):\n\n{code}\n/**\n  * forced to make this class since maprunner tries to use same object for all next() calls.\n  * This way we can swap out the actual 'row' object on each call to next()\n  */\npublic class RowContainer {\n   public Object row;\n}\n\n/**\n * Application can return right deserializer based on configuration\n */\npublic interface RowSource {\n   public Deserializer<?> getDeserializer(Configuration conf) throws IOException;\n   public Class<?> getClass();\n}\n\n/**\n * Reads a non-splitable binary flat file.\n */\npublic class RowSourceFileInputFormat extends FileInputFormat<LongWritable, RowContainer> {\n  protected boolean isSplitable(FileSystem fs, Path file) { return false; }\n  public RecordReader<LongWritable, RowContainer> getRecordReader(InputSplit genericSplit, JobConf job,\n                                                                      Reporter reporter)\n    throws IOException {\n    reporter.setStatus(genericSplit.toString());\n    return new RowSourceRecordReader(job, (FileSplit) genericSplit);\n  }\n}\n\n/**\n * Reads one row at a time. The key is the row number and the actual row is returned inside the RowContainer\n */\npublic class RowSourceRecordReader implements RecordReader<LongWritable, RowContainer> {\n    private long rnum;\n    private final DataInput in;\n    private final DecompressorStream dcin;\n    private final FSDataInputStream fsin;\n    private final long end;\n    private final Deserializer deserializer;\n\n    public RowSourceRecordReader(Configuration job,\n                                FileSplit split) throws IOException {\n\n      final Path file = split.getPath();\n      CompressionCodecFactory compressionCodecs = new CompressionCodecFactory(job);\n      final CompressionCodec codec = compressionCodecs.getCodec(file);\n      FileSystem fs = file.getFileSystem(job);\n      fsin = fs.open(split.getPath());\n\n      if(codec != null) {\n        dcin = (DecompressorStream)codec.createInputStream(fsin);\n        in = new DataInputStream(dcin);\n      } else {\n        dcin = null;\n        in = fsin;\n      }\n      rnum = 0;\n      end = split.getLength();\n\n      deserializer=(ReflectionUtils.newInstance(job.getClass(\"mapred.input.rowsource\", null, RowSource.class)).getDeserializer(job);\n      deserializer.open(in);\n    }\n\n    public LongWritable createKey() {\n      return new LongWritable();\n    }\n\n    public RowContainer createValue() {\n       return new RowContainer();\n    }\n\n    public synchronized boolean next(LongWritable key, RowContainer value) throws IOException {\n      if(dcin != null) {\n        if (dcin.available() == 0) {\n          return false;\n        }\n      } else {\n        if(fsin.getPos() >= end) {\n          return false;\n        }\n      }\n      key.set(rnum++);\n      Object row = deserializer.deserialize(value.row);\n      value.row = row;\n      return true;\n    }\n\n    public synchronized float getProgress() throws IOException {\n      // this assumes no splitting                                                                                               \n      if (end == 0) {\n        return 0.0f;\n      } else {\n        // gives progress over uncompressed stream                                                                               \n        return Math.min(1.0f, fsin.getPos()/(float)(end));\n\n\n    public synchronized long getPos() throws IOException {\n      // position over uncompressed stream. not sure what                                                                        \n      // effect this has on stats about job                                                                                      \n      return fsin.getPos();\n    }\n\n    public synchronized void close() throws IOException {\n       // assuming that this closes the underlying streams\n       deserializer.close();\n    }\n}\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-09-09T01:46:08.847+0000","updated":"2008-09-09T01:47:01.526+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629366","id":"12629366","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"oh - and my code does not work without a change to DecompressorStream class to make that a public class (it's marked package private right now). Truthfully - that forced me to file this bug :-)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-09-09T02:05:51.700+0000","updated":"2008-09-09T02:05:51.700+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629398","id":"12629398","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"It looks like we posted complimentary patches :) I think we should keep my RecordReader, but use your implementation of the TypedFileTransport as it's more general since it uses the serialization framework.\n\nThis would address the use case of files whose serializers are set in the config file and self describing files like sequence files and TRecordStream and I would guess, TFile but I haven't looked at it.\n\n-- pete\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T05:44:45.944+0000","updated":"2008-09-09T05:44:45.944+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629652","id":"12629652","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I think this is too complicated. What is the justification for these new interfaces? We already have RecordReader that already \nexpresses these concepts.\n\nOnce the TFile stuff is ready, I think it would make a lot of sense to build an ObjectFile that uses the pluggable serializer\nframework to save any objects. At that point, it becomes a potential replacement for SequenceFile. By using the serializer\nframework, it should work fine with Java serialization, Thrift, or Protocol Buffers. I don't think having a Thrift file format is very\ncompelling at that point.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-09T23:12:56.882+0000","updated":"2008-09-09T23:12:56.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629654","id":"12629654","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"Yes, good point.\n\nI will change it to DeserializerTypedFile.\n\nBut, the SequenceFileRecordReader is re-usable for all these.  From the reader of a file that does its own deserializing of its types, it's all the same.\n\nWith this interface, the SequenceFileRecordReader can read SequenceFiles, DeserializerTypedFiles (thrift, proto buffers, record io whatever) and any other self describing typed files; sequencefile's being one example of these.\n\nOtherwise, I don't see how not to be re-implementing the current SequenceFileRecordReader functionality for all these use cases??\n\n-- pete\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T23:19:16.452+0000","updated":"2008-09-09T23:19:16.452+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629659","id":"12629659","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"I will submit a patch with its own RecordReader so we don't need to change SequenceFileRR. I\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-09T23:42:24.198+0000","updated":"2008-09-09T23:42:24.198+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12629661","id":"12629661","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> With this interface, the SequenceFileRecordReader can read SequenceFiles, DeserializerTypedFiles (thrift, proto buffers, record io whatever) and any other self describing typed files; sequencefile's being one example of these.\n\nI'm all for reducing code duplication.  So if SequenceFileRecordReader can mostly be replaced with code that's shared by other file format's that'd be great.  But we need those file formats to exist before we perform this factoring.  Is there a splittable thrift or protocol-buffer input file format implementation yet that can share code with SequenceFileInputFormat?  Let's not refactor until we have these.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-09T23:50:53.437+0000","updated":"2008-09-09T23:50:53.437+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12631184","id":"12631184","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"This patch implements: FlatFileDeserializerRecordReader (and input format), which reads rows of any kind of data using a Deserializer that is given in the JobConf.\n\nFor the current test case, I created a simple deserializer for \\n separated plain text as a thin wrapper around LineRecordReader.LineReader to show what LineRecordReader would look like using FlatFileDeserializerRecordReader.\n\nOne thing is this is my first foray into Java generics, so I would appreciate an experienced generics person looking at the code.\n\n-- pete\n\nI want to also implement a thrift or record io test case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-15T23:22:36.635+0000","updated":"2008-09-15T23:22:36.635+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12631187","id":"12631187","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"\nShould also mention we could put this in contrib as it is self contained.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-15T23:26:38.303+0000","updated":"2008-09-15T23:26:38.303+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12631544","id":"12631544","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Please don't edit descriptions.  It's very difficult to tell what's changed.  The description should describe the problem.  The discussion below should present solutions.  Editing descriptions and comments makes it very hard to follow an issue.  This is discussed in the \"Jira Guidlines\" section of http://wiki.apache.org/hadoop/HowToContribute.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-16T20:52:58.784+0000","updated":"2008-09-16T20:52:58.784+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12631555","id":"12631555","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"reverting to original description :)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-16T21:18:28.584+0000","updated":"2008-09-16T21:18:28.584+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12631913","id":"12631913","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"proposal (which does not touch any existing code):\n\n1. extend Deserializer with an interface that requires returning the actual type being deserialized\n{code:title=ParameterizedDeserializer.java}\npublic interface ParameterizedDeserializer<T> extends Deserializer<T> {\n  Class<? extends T> getRealClass() ;\n}\n{code}\n2. create a Serialization implementation which gets the Serializer/Deserializer from the JobConf - e.g.,\n{code}\n   public ParameterizedDeserializer<R> getDeserializer(Class<R> c) {                                                                                                                                        \n     // ignore c. doesn't matter, it is coming from the configuration                                                                                                                                        \n      Class<? extends ParameterizedDeserializer> t = conf.getClass(\"mapred.input.io.deserializer\", null, ParameterizedDeserializer.class);                                                                      \n      return ReflectionUtils.newInstance(t, conf);                                                                                                                                                           \n    } \n{code}\n3. Parameterized deserializers will (typically) get the specific class (? extends T - e.g., T= Record) they are implementing from the JobConf. e.g.,\n{code}\n    this.recordClass = conf.getClass(\"mapred.input.io.record_class\", null, Record.class);                                                                                                                   \n{code}\n\n4. RecordReader.getValueClass looks like:\n{code}\n  public R createValue() {                                                                                                                                                                     \n    return (R)ReflectionUtils.newInstance(deserializer.getRealClass(),conf);                                                                                                                                              \n  }                    \n{code}\n\n5. Setting up the JobConf:\n{code}\n      job.setClass(\"mapred.input.io.deserializer\", .serializer.RecordIOSerialization.RecordIODeserializer.class, serializer.ParameterizedDeserializer.class);          \n                                                                                                                                                                                                             \n      // Set this so the RecordIO Deserializer knows the specific Record class in the file                                                                                                                   \n      job.setClass(\"mapred.input.io.recordio_class\", FlatFileDeserializerTestObj.class, record.Record.class);             \n{code}\n\nThese classes could all go into a contrib directory devoted to contributing Serialization implementations.  Or it could be in core and mapred.\n\nIssues - why not get the  deserialization specific class in Serialization.getDeserializer (and implement getRealClass in this Serialization implementation - no need for any new interface) and pass that in to any normal Deserializer?  This would make things more uniform and also mean the Deserializer is any old deserializer.\n{code}\nClass<? extends R> realClass = conf.getClass(\"mapred.input.io.deserializer.class\", null, Class<R>);                                                                                                                   \nreturn ReflectionUtils.newInstance(conf.getClass(\"mapred.input.deserializer\",null,Deserializer.class));\n{code}\nAnd then we can construct an instance of realClass and pass that into any Deserializer.deserialize(T t).\n\nI am just learning generics and it doesn't seem conf.getClass(\"mapred.input.io.deserializer.class\", null, Class<R>);  is possible because it doesn't accept Class<R>. It wants something more like Record.class, forcing us into doing this in the deserizlier.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-17T20:12:16.767+0000","updated":"2008-09-17T20:12:16.767+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12631938","id":"12631938","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I've lost the motivation for this. It complicates the public interfaces a lot and doesn't have any payback.\n\nIn our experience, given a file format, the code is pretty independent, but it is tied to the fragment splitting. \n\nIs the goal of this jira to:\n  1. Make a generic / self-detecting format?\n  2. A generic file format?\n\nIn either case, changes to the serialization framework seems like serious overkill.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-17T20:42:35.485+0000","updated":"2008-09-17T20:42:35.485+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632058","id":"12632058","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi Owen - the motivation was based on different families of binary (or even non binary) data embedded within flat files (by which i mean they are unsplittable and not self-describing (except for compression).\n\n- We should be able to write one concrete implementation that covers no-splits and compression related code\n- One should be able to plug in different deserializers for different binary formats\n\nThe desire was that once this is written out - different deserializers can be plugged in easily. In that sense - this does not follow the general pattern that you observed of having to write custom code to deal with splitting (since there's no splitting here). Existing interfaces should not have to be changed (although things got pretty complicated in the intermediate discussion) - and i don't think they are although i am going to send back feedback on the code separately. The code should be really simple i would think.\n\nDo you think this is a reasonable thing to add?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-09-18T02:11:17.130+0000","updated":"2008-09-18T02:11:17.130+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632067","id":"12632067","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"bq. In either case, changes to the serialization framework seems like serious overkill.\n\nyou are right - I don't know why I went that direction. It should be exactly the oppostite of the way I coded it up.\n\nAll one needs is some way of getting SerializationContext information (to instantiate the right Serialization Object and then the actual subclass we want to deserialize; e.g., Record/MyRecordObj). [this was called RowSource in joy's code example]\n\nAnd then a simple record reader that uses that info to instantiate a deserializer and done.\n\nNo changes to the serialization framework.\n\nI actually have that with unit tests and just need to clean up the documentation and such.\n\n-- pete\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-18T02:50:30.657+0000","updated":"2008-09-18T02:50:30.657+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632072","id":"12632072","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"this is all this is - don't know why i went the other way :(\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-18T03:09:37.055+0000","updated":"2008-09-18T03:09:37.055+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632089","id":"12632089","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"Here's the simple patch and in contrib/serialization/readers. No build file with this yet as will coordinate with Tom White on that.\n\nAlthough the unit test is only for Java now, I did have it with Thrift and RecordIO, but since neither of those are checked in yet, i didn't include those tests.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-18T04:46:22.319+0000","updated":"2008-09-18T04:46:22.319+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632217","id":"12632217","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"A few comments:\n\nCould the types be called FlatFileInputFormat and FlatFileRecordReader?\n\nIs a SerializationContext class needed? The Serialization can be got from the SerializationFactory. It just needs to know the base class (Writable, TBase etc). A second configuration parameter is needed to specify the concrete class, but I don't see why the FlatFileDeserializerRecordReader can't just get these two classes from the Configuration itself.\n\nCan the classes go in the org.apache.hadoop.contrib.serialization.mapred package to echo the main mapred package? When HADOOP-1230 is done an equivalent could then go in the mapreduce package.\n\nI agree it would be good to have tests for Writable, Java Serialization and Thrift to test the abstraction.\n\nShouldn't keys be file offsets, similar to TextInputFormat? The row numbers you have are actually the row number within the split, which might be confusing (and they're not unique per file).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2008-09-18T14:03:19.869+0000","updated":"2008-09-18T14:03:19.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632309","id":"12632309","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"bq. Could the types be called FlatFileInputFormat and FlatFileRecordReader?\nYes, better names.\n\nbq. Is a SerializationContext class needed?\n\nIf the Serialization is in contrib, one would need to use ReflectionUtils to instantiate it and it wouldn't be in any Factory, would it?  So, in this case, it needs to know the name of the Class to instantiate it, no?  \n\nbq. an't just get these two classes from the Configuration itself.\n\nwanted to make it extensible so it could some from the configuration or maybe some place else - the name of the file or some external store or something depending on the application. Of course, in that case, one could argue a higher level is setting that up anyway, so why don't they just do the lookup and store the info in the configuration. \n\nbq. Shouldn't keys be file offsets, similar to TextInputFormat? The row numbers you have are actually the row number within the split, which might be confusing (and they're not unique per file).\n\nAre the file offsets useful anywhere?  Maybe we should just always return the same instance of some dummy Writable for performance if the key isn't used anyway??\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-18T17:43:56.545+0000","updated":"2008-09-18T17:43:56.545+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632451","id":"12632451","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"couple of comments on the code:\n\nSerializationContext<R> sinfo = (SerializationContext<R>)ReflectionUtils.newInstance(sinfoClass, conf);\nsinfo.setConf(conf);\n\nthe setConf call is redundant since SerializationContext is configurable\n\nkey.set(rnum++);\nif (key == null)\n    key = createKey();\n\nswitch order? (or maybe the createKey()/createValue() is not required?)\n\notherwise looks good.\n\nwrt some of Tom's comments:\n\n> The row numbers you have are actually the row number within the split, which might be confusing\nthe inputformat is not splittable - so we are safe here\n\n> Is a SerializationContext class needed? \n\nVery much so. Let me walk through the Hive use case:\n- Hive knows the deserialization class for each file. However - it knows this through metadata about the _file_.  (The file belongs to a table that has some metadata). This metadata is passed to mappers through the configuration.\n- In this case the mapping is not from a class -> deserializer but from a file -> deserializer - and the ability to bootstrap the serialization factory from the configuration is critical (the configuration has both the file name and the metadata about the file name)\n\nThis also seems to be the hadoop style of doing things (all implementations can be configurable) - and i think if it covers the hive case - it would help others as well. In fact - i think we should try to make this (configurable serialization factory pattern) a more fundamental part of the infrastructure. it seems more general than the class->serialization way of bootstrapping (de)serialization.\n\n\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-09-18T23:41:10.466+0000","updated":"2008-09-18T23:41:10.466+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632475","id":"12632475","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"HADOOP-3787 includes the build file changes and such for creating src/contrib/serialization, so will need to wait for its commit.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-19T00:54:25.706+0000","updated":"2008-09-19T00:54:25.706+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632501","id":"12632501","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm still not convinced about the utility of this class outside of Hive. What is the advantage of storing the data this way?\nIf you put it in a sequence file or t-file, a single bug in the serialization code for the application type doesn't destroy\nyour entire file. With this format, that is exactly what will happen. Furthermore, since the types have to be configured,\nyou can't use multiple ones in different contexts.\n\nMaybe we should just put this into Hive?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-19T04:06:56.366+0000","updated":"2008-09-19T04:06:56.366+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632529","id":"12632529","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"yes - given that this has no dependency on core hadoop now - i really don't care - we can put this into Hive. The generic ThriftDeserializer is trivial - we could duplicate the code for now and then remove it once 3787 provides those classes as well.\n\nbtw - we also don't store data in this manner. agree with all your observations. however \n- this requested originated from outside Hive/Facebook. I get the impression (perhaps wrong) that quite a few people just dump thrift logs into a flat file (just like people dump apache logs into a flat file). This is also because Thrift does not have (so far) a good framed file format.\n- the same counter argument can be made for TextFileInputFormat. The general observation is that data originates outside the hadoop ecosystem and the general format it originates in is flat files. We should strive the easiest way to absorb this data and transform it into a better one (like Sequencefile). \n\nThat is the general effort with Hive at least. We expect users to create temporary tables by pointing to flat files. And then quickly do some transformations (using sql and potentially scripts) and load it into tables in sequencefile (like) format (for longer term storage).  Being able to point to thrift flat files(and potentially other binary files)  is part of the data integration story.\n\n> Furthermore, since the types have to be configured, you can't use multiple ones in different contexts. \n\nnot sure what u mean - but this is not true. the deserializer is obtained from a combination of file name and file name->deserializer metadata from an external source. Different files can be read using different deserializers and then operated on in the same map-reduce program (the application logic has logic to deal with different classes based on the file name).  we will only be too happy to demonstrate a join of two different thrift classes (in different files/tables) using Hive and a generic flat file reader like this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-09-19T05:59:33.057+0000","updated":"2008-09-19T05:59:33.057+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632752","id":"12632752","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"bq. I'm still not convinced about the utility of this class outside of Hive. What is the advantage of storing the data this way?\n\n1. You don't need a loader.  \n2. Tools outside of hadoop can use the data - python, perl, c++, ...\n3. There are other file formats that are splittable and self or non self-describing. Hadoop is generally pretty pluggable, but not at the file level. Would be nice to have generic file interfaces that one can implement to get *First Class* hadoop treatment for any file format.\n \nTo be clear, Hive writes and reads binary data to sequence files only now. We load all binary data into sequence files.\n\nbq. i really don't care - we can put this into Hive. \n\n-1\n\nThis is a general FlatFileRecordReader - HADOOP-3566 seems to be a non-general version of this? (with the issue of that being <String, Void>)\n\nAnd note my intention is to put this in contrib/serialization\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-19T17:36:31.254+0000","updated":"2008-09-19T17:36:31.254+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632760","id":"12632760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"bq. And note my intention is to put this in contrib/serialization\n\nSorry, I meant. my intention was (not is) to put this in contrib/serialization, but if there is objection, i can change the patch to contrib/hive.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-19T18:28:48.612+0000","updated":"2008-09-19T18:28:48.612+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12632806","id":"12632806","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"RE: FlatFileRecordReader's signature.\n\nWhat would the implications be of changing the signature to <T, Void> ? Owen points out on HADOOP-3566 there can be benefits to this viz sorting but that JIRA is for Strings, whereas here T could be anything.\n\n(Assuming for a moment that HADOOP-1230 is implemented. Now it would be <RowContainer<T>, Void>)\n\nthanks, pete\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-19T20:26:13.396+0000","updated":"2008-09-19T20:26:13.396+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12633082","id":"12633082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"if there are implications, why not make the signature <Void, T> and when someone wants the sorting, have them use the InverseMapper instead of the IdentityMapper?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-21T17:33:28.116+0000","updated":"2008-09-21T17:33:28.116+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12633566","id":"12633566","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"This is what HADOOP-3566 looks like as an instance of a FlatFileRecordReader (with signature <Void, String>, not <String, Void>).  This assumes there is a StringSerialization implementation (based on LineRecordReader) and that HADOOP-1230 is implemented. But, it should hopefully demonstrate that FlatFileRecordReader can be used for non binary records.  Although,  without this, it can still be be used for anything that implements the Serialization interface.\n\n{code:title=StringInputFormat.java}\npublic class StringInputFormat extends FileInputFormat<Void, String> implements JobConfigurable {                                                     \n  private CompressionCodecFactory compressionCodecs = null;                                                                                           \n                                                                                                                                                      \n  public void configure(JobConf conf) {                                                                                                               \n    compressionCodecs = new CompressionCodecFactory(conf);                                                                                            \n  }                                                                                                                                                   \n                                                                                                                                                      \n  protected boolean isSplittable(FileSystem fs, Path file) {                                                                                          \n    return compressionCodecs.getCodec(file) == null;                                                                     \n  }                                                                                                                                                   \n                                                                                                                                                      \n  public RecordReader<Void, String> getRecordReader(InputSplit split,                                                                                 \n                                                    JobConf job, Reporter reporter)                                                                   \n    throws IOException {                                                                                                                              \n                                                                                                                                                      \n    reporter.setStatus(split.toString());                                                                                                             \n                                                                                                                                                      \n    //                                                                                                                                                \n    // Set this so the SerializerFromConf can lookup our deserializer.                                                                                \n    //                                                                                                                                                \n    job.setClass(FlatFileRecordReader.SerializationContextFromConf.SerializationImplKey,                                                              \n                 org.apache.hadoop.contrib.serialization.string.StringSerialization.class,                                                            \n                 org.apache.hadoop.io.Serialization.class);                                                                                           \n                                                                                                                                                      \n    job.setClass(FlatFileRecordReader.SerializationContextFromConf.SerializationSubclassKey,                                                          \n                 java.lang.String.class, java.lang.String.class);                                                                                     \n                                                                                                                                                      \n    return new FlatFileRecordReader<String>(job, (FileSplit) split);                                                                                  \n  }                                                                                                                                                   \n}                                                                                                                                                     \n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-22T23:46:13.097+0000","updated":"2008-09-22T23:46:13.097+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12633822","id":"12633822","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> my intention was to put this in contrib/serialization, but if there is objection, i can change the patch to contrib/hive.\n\n+1 I'd rather not have contrib/serialization just become a grab-bag of io-related stuff.  If this is needed by Hive only, then it belongs in contrib/hive.  If we decide (subsequently, perhaps) that it has wide utility as a generic API for access to files in a variety of formats for a variety of applications, then perhaps it could be moved to mapred.  But that doesn't yet sound like the consensus, so contrib/hive is probably best for now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-09-23T17:47:15.091+0000","updated":"2008-09-23T17:47:15.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12633949","id":"12633949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"namespaced into hive and also brought back the RowContainer so it will work without HADOOP-1230 being fixed.  \n\nThe testcase uses JavaSerialization, WritableSerialization (Record) and ThriftSerialization.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-23T22:45:03.820+0000","updated":"2008-09-23T22:45:03.820+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12634030","id":"12634030","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12390798/HADOOP-4065.2.txt\n  against trunk revision 698385.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 9 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-24T05:54:01.779+0000","updated":"2008-09-24T05:54:01.779+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12634337","id":"12634337","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"hudson -1 contrib i think this wasn't due to this patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-24T23:03:52.739+0000","updated":"2008-09-24T23:03:52.739+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12634338","id":"12634338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"re-submitting for hudson.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-24T23:04:08.092+0000","updated":"2008-09-24T23:04:08.092+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12634394","id":"12634394","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12390798/HADOOP-4065.2.txt\n  against trunk revision 698721.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 9 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-25T07:20:14.403+0000","updated":"2008-09-25T07:20:14.403+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12642527","id":"12642527","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"+1. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-10-24T19:37:16.134+0000","updated":"2008-10-24T19:37:16.134+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12647312","id":"12647312","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"I think this patch is already commited. Is there anything else needed on this. Can we mark this as resolved?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2008-11-13T15:01:20.294+0000","updated":"2008-11-13T15:01:20.294+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12403646/comment/12648059","id":"12648059","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"body":"yes, already committed.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wyckoff","name":"wyckoff","key":"wyckoff","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pete Wyckoff","active":true,"timeZone":"Etc/UTC"},"created":"2008-11-17T01:30:47.265+0000","updated":"2008-11-17T01:30:47.265+0000"}],"maxResults":52,"total":52,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-24/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0iuin:"}}