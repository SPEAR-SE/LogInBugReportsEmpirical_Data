{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12982733","self":"https://issues.apache.org/jira/rest/api/2/issue/12982733","key":"HIVE-14090","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335838","id":"12335838","description":"Maintenance branch for 2.1 ","name":"2.1.1","archived":false,"released":true,"releaseDate":"2016-12-08"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335837","id":"12335837","name":"2.2.0","archived":false,"released":true,"releaseDate":"2017-07-25"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-06-27T19:42:26.703+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jul 06 21:27:18 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_767826_*|*_3_*:*_1_*:*_258453081_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_796822870","customfield_12312321":null,"resolutiondate":"2016-07-06T21:36:17.959+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14090/watchers","watchCount":2,"isWatching":false},"created":"2016-06-24T16:15:34.367+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329363","id":"12329363","name":"1.1.0","archived":false,"released":true,"releaseDate":"2015-03-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334255","id":"12334255","name":"2.1.0","archived":false,"released":true,"releaseDate":"2016-06-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-12-08T14:38:53.678+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"When user try to create any database or table with a name longer than 128 characters:\n\n{code}\ncreate database test_longname_looooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooongNametableFAIL;\n{code}\n\nIt dumps the full exception stack-trace in a non-user-friendly message. The lends to relatively negative user-experience for Beeline users who hit this exception, they are generally not interested in the full stack-trace.\n\nThe formatted stack-trace is below:\n\n{code}\nError while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:javax.jdo.JDOFatalUserException: Attempt to store value \"test_longname_looooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooongnametablefail2\" in column \"`NAME`\" that has maximum length of 128. Please correct your data!\nat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:528)\nat org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:732)\nat org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752)\nat org.apache.hadoop.hive.metastore.ObjectStore.createDatabase(ObjectStore.java:569)\nat sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:606)\nat org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)\nat com.sun.proxy.$Proxy10.createDatabase(Unknown Source)\nat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:923)\nat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:962)\nat sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:606)\nat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:138)\nat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:99)\nat com.sun.proxy.$Proxy12.create_database(Unknown Source)\nat org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:8863)\nat org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:8847)\nat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\nat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\nat org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:707)\nat org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:702)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:415)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\nat org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:702)\nat org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\nat java.lang.Thread.run(Thread.java:745) NestedThrowablesStackTrace: Attempt to store value \"test_longname_looooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooongnametablefail2\" in column \"`NAME`\" that has maximum length of 128. Please correct your data! org.datanucleus.exceptions.NucleusUserException: Attempt to store value \"test_longname_looooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooongnametablefail2\" in column \"`NAME`\" that has maximum length of 128. Please correct your data!\nat org.datanucleus.store.rdbms.mapping.datastore.CharRDBMSMapping.setString(CharRDBMSMapping.java:263)\nat org.datanucleus.store.rdbms.mapping.java.SingleFieldMapping.setString(SingleFieldMapping.java:201)\nat org.datanucleus.store.rdbms.fieldmanager.ParameterSetter.storeStringField(ParameterSetter.java:159)\nat org.datanucleus.state.JDOStateManager.providedStringField(JDOStateManager.java:1256)\nat org.apache.hadoop.hive.metastore.model.MDatabase.jdoProvideField(MDatabase.java)\nat org.apache.hadoop.hive.metastore.model.MDatabase.jdoProvideFields(MDatabase.java)\nat org.datanucleus.state.JDOStateManager.provideFields(JDOStateManager.java:1346)\nat org.datanucleus.store.rdbms.request.InsertRequest.execute(InsertRequest.java:289)\nat org.datanucleus.store.rdbms.RDBMSPersistenceHandler.insertTable(RDBMSPersistenceHandler.java:167)\nat org.datanucleus.store.rdbms.RDBMSPersistenceHandler.insertObject(RDBMSPersistenceHandler.java:143)\nat org.datanucleus.state.JDOStateManager.internalMakePersistent(JDOStateManager.java:3784)\nat org.datanucleus.state.JDOStateManager.makePersistent(JDOStateManager.java:3760)\nat org.datanucleus.ExecutionContextImpl.persistObjectInternal(ExecutionContextImpl.java:2219)\nat org.datanucleus.ExecutionContextImpl.persistObjectWork(ExecutionContextImpl.java:2065)\nat org.datanucleus.ExecutionContextImpl.persistObject(ExecutionContextImpl.java:1913)\nat org.datanucleus.ExecutionContextThreadedImpl.persistObject(ExecutionContextThreadedImpl.java:217)\nat org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:727)\nat org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752)\nat org.apache.hadoop.hive.metastore.ObjectStore.createDatabase(ObjectStore.java:569)\nat sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:606)\nat org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)\nat com.sun.proxy.$Proxy10.createDatabase(Unknown Source)\nat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:923)\nat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:962)\nat sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:606)\nat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:138)\nat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:99)\nat com.sun.proxy.$Proxy12.create_database(Unknown Source)\nat org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:8863)\nat org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:8847)\nat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\nat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\nat org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:707)\nat org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:702)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:415)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\nat org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:702)\nat org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\nat java.lang.Thread.run(Thread.java:745) )\n{code}\n\nThe ideal situation would be to just return the following message to Beeline users:\n\n{code}\nError while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:javax.jdo.JDOFatalUserException: Attempt to store value \"test_longname_looooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooonglooooooongnametablefail2\" in column \"`NAME`\" that has maximum length of 128. Please correct your data!)\n{code}\n\nAnd have the full stack trace should up in the HiveServer2 logs.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335838","id":"12335838","description":"Maintenance branch for 2.1 ","name":"2.1.1","archived":false,"released":true,"releaseDate":"2016-12-08"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12815279","id":"12815279","filename":"HIVE-14090.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-30T02:14:11.854+0000","size":3437,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12815279/HIVE-14090.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12813112","id":"12813112","filename":"HIVE-14090.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-24T16:27:32.774+0000","size":1013,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12813112/HIVE-14090.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"JDOExceptions thrown by the Metastore have their full stack trace returned to clients","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982733/comment/15348497","id":"15348497","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"The root cause of this issue is in {{RetryingHMSHandler.invokeInternal}} method, specifically the following lines:\n\n{code}\nif (retryCount >= retryLimit) {\n    LOG.error(\"HMSHandler Fatal error: \" + ExceptionUtils.getStackTrace(caughtException));\n    // Since returning exceptions with a nested \"cause\" can be a problem in\n    // Thrift, we are stuffing the stack trace into the message itself.\n    throw new MetaException(ExceptionUtils.getStackTrace(caughtException));\n}\n{code}\n\nSome context: this code is run on the Hive Metastore server (clients communicate with the remote Hive Metastore instance via a Thrift API).\n\nThe {{caughtException}} variable is a {{JDOFatalUserException}}. So the entire stack-trace of {{JDOFatalUserException}} gets stuffed into the message of a {{MetaException}}, which then gets returned to the client (HiveServer2 usually), via the Hive Metastore Thrift API. This only happens for {{JDOException}}s due to some other logic in the class, which is why it is not a very common complaint. So when HiveServer2 sees an exception is thrown by the Metastore, it displays the exception message to the user, which in this case contains the full stack-trace of the exception.\n\nNote that the comments in the code mention that the stack-trace is stuffed into the message due to some problems with Thrift not sending the entire stack-trace back to the client. This comment was added in HIVE-3400 - there is a Phabricator review linked to the Hive JIRA (https://reviews.facebook.net/D4791) which contains a relevant conversation about this choice, I copied it below:\n\n{code}\nActually the RetryingHMSHandler is currently putting the stacktrace into the \"message\" of the MetaException and not its \"cause\". In the Thrift generated MetaException.java, there is no constructor taking the cause so I stuffed it into the message. Now that I think of it, I can call initCause(jdoexception) after constructing the MetaException. Then I can make the change you suggested. Do you want me to do that?\n...\nYes, please do that. Type comparison is much better than regex matching.\n...\nUnfortunately, things break with that change. In direct db mode things are fine. But when we go through Thrift, the MetaException received by Hive client from the Thrift server has null as its cause. Even though the cause is being set properly on the Thrift side. This might be happening because Thrift does not \"know\" about JDOExceptions. Or it may even be a limitation of Thrift exception handling. Not sure. I'm satisfied with the way it was. The two key requirements of letting the client know about the JDOException and shipping the entire stack trace back were being met. What do you think?\n...\nYeah, lets keep it this way then. If, thrift can't transport exception trace correctly. I will suggest to leave a comment there saying why we have to do regex matching of exception message instead of checking type of exception.\n{code}\n\nI modified the code to stop stuffing the stack-trace into the exception message, and I tested the change locally. The change works. The full exception is still shipped to the client (HiveServer2), who prints the full exception stack trace in its log files, and only the exception message is displayed to the user. I was sure to run the Hive Metastore as a Thrift Server in order to check if Thrift had any issues transporting the stack trace of the exception, and I saw no issues.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-24T16:16:54.228+0000","updated":"2016-06-24T16:17:23.077+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982733/comment/15351672","id":"15351672","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12813112/HIVE-14090.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10273 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_13\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_all\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_join\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_create_with_constraints_duplicate_name\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/276/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/276/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-276/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 6 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12813112 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-06-27T19:42:26.703+0000","updated":"2016-06-27T19:42:26.703+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982733/comment/15356300","id":"15356300","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"[~spena] can you review?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-30T01:33:15.267+0000","updated":"2016-06-30T01:33:15.267+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982733/comment/15356305","id":"15356305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"Looks like I made need to re-generate some golden files which expect the full stack trace of the {{JDOException}} to be present in the query response.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-30T01:36:58.610+0000","updated":"2016-06-30T01:36:58.610+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982733/comment/15357979","id":"15357979","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12815279/HIVE-14090.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10287 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_multiinsert\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_all\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_join\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskSchedulerService.testDelayedLocalityNodeCommErrorImmediateAllocation\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/329/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/329/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-329/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 5 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12815279 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-06-30T22:35:39.718+0000","updated":"2016-06-30T22:35:39.718+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982733/comment/15358102","id":"15358102","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"Test failures seem un-related.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-01T00:28:23.640+0000","updated":"2016-07-01T00:28:23.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982733/comment/15365143","id":"15365143","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"body":"Good, the patch looks good. Thanks for the investigation of this issue too. Great work.\n+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=spena","name":"spena","key":"spena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergio Peña","active":true,"timeZone":"America/Chicago"},"created":"2016-07-06T21:27:18.912+0000","updated":"2016-07-06T21:27:18.912+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14090/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i301iv:"}}