{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12536446","self":"https://issues.apache.org/jira/rest/api/2/issue/12536446","key":"HIVE-2683","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2011-12-28T09:58:31.511+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Dec 28 09:58:31 UTC 2011","customfield_12310420":"222129","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-2683/watchers","watchCount":1,"isWatching":false},"created":"2011-12-27T21:59:42.948+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12316336","id":"12316336","description":"released","name":"0.7.1","archived":false,"released":true,"releaseDate":"2011-06-21"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-12-28T09:58:31.624+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12315100","id":"12315100","name":"SQL","description":"Issues related to Hive Query Language and its conformance with ANSI SQL."}],"timeoriginalestimate":null,"description":"I try to load data into a hive table twice from the same hdfs file without overwrite option.\nI would expect second load to append to existing data or at least replace it. \nI get the following error message instead.\n\nNote that, during the operation Hive is renaming the source file to <original_name>_copy_<nbr>, which\nmakes us believe it is trying to avoid erasing the existing file while moving and both files (original and renamed) would be made available to Hive. But this is not the case.\n\nExample of code end error stack : \n\nload data  inpath 'hdfs://0.0.0.0/user/qafiles/SRC_FILE_EMP.dat' \ninto table EMP_DELIMITED_FILE_TRUNC_TBL \n\n------------------- \nQuery returned non-zero code: 9, cause: FAILED: Execution Error, return code \n1 from org.apache.hadoop.hive.ql.exec.MoveTask \n\nriver returned: 9.  Errors: Hive history \nfile=/tmp/hue/hive_job_log_hue_201112132213_439347746.txt \nLoading data to table default.emp_delimited_file_trunc_tbl \nFailed with exception null \nFAILED: Execution Error, return code 1 from \norg.apache.hadoop.hive.ql.exec.MoveTask \n\nFailed with exception null \n11/12/13 22:13:55 ERROR exec.MoveTask: Failed with exception null \njava.lang.NullPointerException \nat org.apache.hadoop.hive.ql.metadata.Hive.copyFiles(Hive.java:1738) \nat org.apache.hadoop.hive.ql.metadata.Table.copyFiles(Table.java:542) \nat org.apache.hadoop.hive.ql.metadata.Hive.loadTable(Hive.java:1189) \nat org.apache.hadoop.hive.ql.exec.MoveTask.execute(MoveTask.java:197) \nat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:130) \nat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57) \nat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1063) \nat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:900) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState.execute(BeeswaxServiceImpl.java:306) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:510) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:499) \nat java.security.AccessController.doPrivileged(Native Method) \nat javax.security.auth.Subject.doAs(Subject.java:337) \nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java :1110) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1.run(BeeswaxService Impl.java:499) \nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) \nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) \nat java.util.concurrent.FutureTask.run(FutureTask.java:138) \nat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java :886) \nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908 ) \nat java.lang.Thread.run(Thread.java:619) \n\nFAILED: Execution Error, return code 1 from \norg.apache.hadoop.hive.ql.exec.MoveTask \n11/12/13 22:13:55 ERROR ql.Driver: FAILED: Execution Error, return code 1 \nfrom org.apache.hadoop.hive.ql.exec.MoveTask \n11/12/13 22:13:55 ERROR beeswax.BeeswaxServiceImpl: Exception while \nprocessing query \nBeeswaxException(message:Driver returned: 9.  Errors: Hive history \nfile=/tmp/hue/hive_job_log_hue_201112132213_439347746.txt \nLoading data to table default.emp_delimited_file_trunc_tbl \nFailed with exception null \nFAILED: Execution Error, return code 1 from \norg.apache.hadoop.hive.ql.exec.MoveTask \n, log_context:8e8ea906-9b5a-4bfe-9946-515249cc523f, \nhandle:QueryHandle(id:8e8ea906-9b5a-4bfe-9946-515249cc523f, \nlog_context:8e8ea906-9b5a-4bfe-9946-515249cc523f)) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState.execute(BeeswaxServiceImpl.java:313) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:510) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:499) \nat java.security.AccessController.doPrivileged(Native Method) \nat javax.security.auth.Subject.doAs(Subject.java:337) \nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java :1110) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1.run(BeeswaxServiceImpl.java:499) \nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) \nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) \nat java.util.concurrent.FutureTask.run(FutureTask.java:138) \nat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java :886) \nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908 ) \nat java.lang.Thread.run(Thread.java:619) \n11/12/13 22:13:58 ERROR beeswax.BeeswaxServiceImpl: Caught BeeswaxException \nBeeswaxException(message:Driver returned: 9.  Errors: Hive history \nfile=/tmp/hue/hive_job_log_hue_201112132213_439347746.txt \nLoading data to table default.emp_delimited_file_trunc_tbl \nFailed with exception null \nFAILED: Execution Error, return code 1 from \norg.apache.hadoop.hive.ql.exec.MoveTask \n, log_context:8e8ea906-9b5a-4bfe-9946-515249cc523f, \nhandle:QueryHandle(id:8e8ea906-9b5a-4bfe-9946-515249cc523f, \nlog_context:8e8ea906-9b5a-4bfe-9946-515249cc523f)) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState.execute(BeeswaxServiceImpl.java:313) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:510) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:499) \nat java.security.AccessController.doPrivileged(Native Method) \nat javax.security.auth.Subject.doAs(Subject.java:337) \nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1110) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1.run(BeeswaxServiceImpl.java:499) \nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) \nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) \nat java.util.concurrent.FutureTask.run(FutureTask.java:138) \nat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) \nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908 ) \nat java.lang.Thread.run(Thread.java:619) \n11/12/13 22:30:51 ERROR beeswax.BeeswaxServiceImpl: Caught BeeswaxException \nBeeswaxException(message:Driver returned: 9.  Errors: Hive history \nfile=/tmp/hue/hive_job_log_hue_201112132213_439347746.txt \nLoading data to table default.emp_delimited_file_trunc_tbl \nFailed with exception null \nFAILED: Execution Error, return code 1 from \norg.apache.hadoop.hive.ql.exec.MoveTask \n, log_context:8e8ea906-9b5a-4bfe-9946-515249cc523f, \nhandle:QueryHandle(id:8e8ea906-9b5a-4bfe-9946-515249cc523f, \nlog_context:8e8ea906-9b5a-4bfe-9946-515249cc523f)) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState.execute(BeeswaxServiceImpl.java:313) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:510) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1$1.run(BeeswaxServiceImpl.java:499) \nat java.security.AccessController.doPrivileged(Native Method) \nat javax.security.auth.Subject.doAs(Subject.java:337) \nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1110) \nat com.cloudera.beeswax.BeeswaxServiceImpl$RunningQueryState$1.run(BeeswaxServiceImpl.java:499) \nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) \nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) \nat java.util.concurrent.FutureTask.run(FutureTask.java:138) \nat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) \nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) \nat java.lang.Thread.run(Thread.java:619) \n ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"74300","customfield_12312823":null,"summary":"load data twice from the same hdfs file without overwrite fails with return code  1 from org.apache.hadoop.hive.ql.exec.MoveTask","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bobovava","name":"bobovava","key":"bobovava","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bobo Vava","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bobovava","name":"bobovava","key":"bobovava","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bobo Vava","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Cloudera VM for Linux Red Hat","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12536446/comment/13176551","id":"13176551","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chinnalalam","name":"chinnalalam","key":"chinnalalam","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chinna Rao Lalam","active":true,"timeZone":"Asia/Kolkata"},"body":"Pls check this issue HIVE-1996 it resolves this issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chinnalalam","name":"chinnalalam","key":"chinnalalam","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chinna Rao Lalam","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-12-28T09:58:31.511+0000","updated":"2011-12-28T09:58:31.511+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-2683/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0d38f:"}}