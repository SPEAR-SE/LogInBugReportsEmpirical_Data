{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13090679","self":"https://issues.apache.org/jira/rest/api/2/issue/13090679","key":"HIVE-17193","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12343343","id":"12343343","name":"4.0.0","archived":false,"released":false}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-08-30T17:28:09.054+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Apr 25 07:51:12 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_9014776092_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_14415388359","customfield_12312321":null,"resolutiondate":"2018-04-25T07:51:12.191+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-17193/watchers","watchCount":6,"isWatching":false},"created":"2017-07-28T03:28:27.790+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"5.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12520367","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12520367","type":{"id":"12310040","name":"Required","inward":"is required by","outward":"requires","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310040"},"outwardIssue":{"id":"13090312","key":"HIVE-17178","self":"https://issues.apache.org/jira/rest/api/2/issue/13090312","fields":{"summary":"Spark Partition Pruning Sink Operator can't target multiple Works","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12518273","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12518273","type":{"id":"12310040","name":"Required","inward":"is required by","outward":"requires","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310040"},"outwardIssue":{"id":"13111439","key":"HIVE-17877","self":"https://issues.apache.org/jira/rest/api/2/issue/13111439","fields":{"summary":"HoS: combine equivalent DPP sink works","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-22T21:17:15.335+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"Suppose {{srcpart}} is partitioned by {{ds}}. The following query can trigger the issue:\r\n{code}\r\nexplain\r\nselect * from\r\n  (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) a\r\njoin\r\n  (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.value) b\r\non a.key=b.key;\r\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12896851","id":"12896851","filename":"HIVE-17193.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-11-09T11:34:24.951+0000","size":14286,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12896851/HIVE-17193.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12897542","id":"12897542","filename":"HIVE-17193.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-11-14T11:19:16.180+0000","size":29899,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12897542/HIVE-17193.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12917528","id":"12917528","filename":"HIVE-17193.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-04-04T10:38:36.726+0000","size":27929,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12917528/HIVE-17193.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12919424","id":"12919424","filename":"HIVE-17193.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-04-17T14:14:34.420+0000","size":35890,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12919424/HIVE-17193.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12920422","id":"12920422","filename":"HIVE-17193.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-04-24T08:51:31.273+0000","size":35894,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12920422/HIVE-17193.5.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"HoS: don't combine map works that are targets of different DPPs","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16147645","id":"16147645","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"[~lirui] is this a bug with {{CombineEquivalentWorkResolver}}?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-30T17:28:09.054+0000","updated":"2017-08-30T17:28:09.054+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16148344","id":"16148344","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Yes I think so. We don't consider DPP when we combine map works in CombineEquivalentWorkResolver. This is wrong because if two map works are to be pruned by different DPP sinks, their outputs are probably different and shouldn't be combined.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-31T02:05:51.658+0000","updated":"2017-08-31T02:05:51.658+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16212502","id":"16212502","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"The main challenge here is how to decide whether two DPP works are different. In {{CombineEquivalentWorkResolver}}, we visit child tasks before its parent. That means when we visit the target map works, we haven't seen the corresponding DPPs yet. The simplest solution is, if the DPP works' IDs (tracked by the target map works) are different, then we consider the target map works are different and don't combine them. The drawback is we'll lose some optimization opportunities - actually I'm not sure whether it's possible that two target map works share the same DPP in current implementation.\r\n\r\nAnother solution is we walk the parent tasks first, and combine equivalent DPP works. Two DPP works can be considered equivalent as long as they output same records. It shouldn't matter how these records are used to prune different tables. As we combine the DPP works, we update the information in the target map works accordingly (DPP works have reference to target map works). Then when we visit the target map works later, we know whether they should be combined. I'm working on a PoC patch to demonstrate the idea.\r\n[~xuefuz], [~csun], [~stakiar], [~kellyzly] do you have any suggestions?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-20T11:30:40.157+0000","updated":"2017-10-20T11:30:40.157+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16214603","id":"16214603","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: I remember this problem when i developed HIVE-16948. But I can not reproduce this problem on hive(commit a51ae9c) now\r\n{code}\r\nset hive.explain.user=false;\r\nset hive.spark.dynamic.partition.pruning=true;\r\nset hive.tez.dynamic.partition.pruning=true;\r\nset hive.auto.convert.join=false;\r\nexplain\r\nselect * from\r\n  (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) a\r\njoin\r\n  (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.value) b\r\non a.key=b.key;\r\n{code}\r\nthe explain \r\n{code}\r\nSTAGE DEPENDENCIES:\r\n  Stage-2 is a root stage\r\n  Stage-1 depends on stages: Stage-2\r\n  Stage-0 depends on stages: Stage-1\r\n\r\nSTAGE PLANS:\r\n  Stage: Stage-2\r\n    Spark\r\n      DagName: root_20171022233200_990c146c-b49f-49b9-9a5b-a0028e34f200:2\r\n      Vertices:\r\n        Map 8 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: key (type: string)\r\n                      outputColumnNames: _col0\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                      Select Operator\r\n                        expressions: _col0 (type: string)\r\n                        outputColumnNames: _col0\r\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                        Group By Operator\r\n                          keys: _col0 (type: string)\r\n                          mode: hash\r\n                          outputColumnNames: _col0\r\n                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                          Spark Partition Pruning Sink Operator\r\n                            Target column: ds (string)\r\n                            partition key expr: ds\r\n                            Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                            target work: Map 1\r\n        Map 9 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: value is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: value (type: string)\r\n                      outputColumnNames: _col0\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                      Select Operator\r\n                        expressions: _col0 (type: string)\r\n                        outputColumnNames: _col0\r\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                        Group By Operator\r\n                          keys: _col0 (type: string)\r\n                          mode: hash\r\n                          outputColumnNames: _col0\r\n                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                          Spark Partition Pruning Sink Operator\r\n                            Target column: ds (string)\r\n                            partition key expr: ds\r\n                            Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                            target work: Map 5\r\n\r\n  Stage: Stage-1\r\n    Spark\r\n      Edges:\r\n        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 1), Map 4 (PARTITION-LEVEL SORT, 1)\r\n        Reducer 3 <- Reducer 2 (PARTITION-LEVEL SORT, 1), Reducer 6 (PARTITION-LEVEL SORT, 1)\r\n        Reducer 6 <- Map 5 (PARTITION-LEVEL SORT, 1), Map 7 (PARTITION-LEVEL SORT, 1)\r\n      DagName: root_20171022233200_990c146c-b49f-49b9-9a5b-a0028e34f200:1\r\n      Vertices:\r\n        Map 1 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: srcpart\r\n                  Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: key (type: string), ds (type: string)\r\n                      outputColumnNames: _col0, _col1\r\n                      Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                      Reduce Output Operator\r\n                        key expressions: _col1 (type: string)\r\n                        sort order: +\r\n                        Map-reduce partition columns: _col1 (type: string)\r\n                        Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                        value expressions: _col0 (type: string)\r\n        Map 4 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: key (type: string)\r\n                      outputColumnNames: _col0\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                      Reduce Output Operator\r\n                        key expressions: _col0 (type: string)\r\n                        sort order: +\r\n                        Map-reduce partition columns: _col0 (type: string)\r\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n        Map 5 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: srcpart\r\n                  Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: key (type: string), ds (type: string)\r\n                      outputColumnNames: _col0, _col1\r\n                      Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                      Reduce Output Operator\r\n                        key expressions: _col1 (type: string)\r\n                        sort order: +\r\n                        Map-reduce partition columns: _col1 (type: string)\r\n                        Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                        value expressions: _col0 (type: string)\r\n        Map 7 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: value is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: value (type: string)\r\n                      outputColumnNames: _col0\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                      Reduce Output Operator\r\n                        key expressions: _col0 (type: string)\r\n                        sort order: +\r\n                        Map-reduce partition columns: _col0 (type: string)\r\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n        Reducer 2 \r\n            Reduce Operator Tree:\r\n              Join Operator\r\n                condition map:\r\n                     Inner Join 0 to 1\r\n                keys:\r\n                  0 _col1 (type: string)\r\n                  1 _col0 (type: string)\r\n                outputColumnNames: _col0, _col1\r\n                Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                Select Operator\r\n                  expressions: _col1 (type: string), _col0 (type: string)\r\n                  outputColumnNames: _col0, _col1\r\n                  Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                  Reduce Output Operator\r\n                    key expressions: _col1 (type: string)\r\n                    sort order: +\r\n                    Map-reduce partition columns: _col1 (type: string)\r\n                    Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                    value expressions: _col0 (type: string)\r\n        Reducer 3 \r\n            Reduce Operator Tree:\r\n              Join Operator\r\n                condition map:\r\n                     Inner Join 0 to 1\r\n                keys:\r\n                  0 _col1 (type: string)\r\n                  1 _col1 (type: string)\r\n                outputColumnNames: _col0, _col1, _col2, _col3\r\n                Statistics: Num rows: 280 Data size: 28129 Basic stats: COMPLETE Column stats: NONE\r\n                File Output Operator\r\n                  compressed: false\r\n                  Statistics: Num rows: 280 Data size: 28129 Basic stats: COMPLETE Column stats: NONE\r\n                  table:\r\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\r\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\r\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\r\n        Reducer 6 \r\n            Reduce Operator Tree:\r\n              Join Operator\r\n                condition map:\r\n                     Inner Join 0 to 1\r\n                keys:\r\n                  0 _col1 (type: string)\r\n                  1 _col0 (type: string)\r\n                outputColumnNames: _col0, _col1\r\n                Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                Select Operator\r\n                  expressions: _col1 (type: string), _col0 (type: string)\r\n                  outputColumnNames: _col0, _col1\r\n                  Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                  Reduce Output Operator\r\n                    key expressions: _col1 (type: string)\r\n                    sort order: +\r\n                    Map-reduce partition columns: _col1 (type: string)\r\n                    Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                    value expressions: _col0 (type: string)\r\n\r\n  Stage: Stage-0\r\n    Fetch Operator\r\n      limit: -1\r\n      Processor Tree:\r\n        ListSink\r\n\r\n{code}\r\n\r\nI guess what you mean in the jira is that map8 and map9 are combined as one map in your env as the operators in these two map are same. The reason why there are not combined in my env is the filter operators in Map8 and Map9 are not same.\r\n{code}\r\nMap8\r\n  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n{code}\r\n\r\n{code}\r\nMap9\r\n\t\t\t\t\t\r\n\t\t\t\t\t    Filter Operator\r\n                    predicate: value is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n{code}\r\n\r\nCan you provide your scripts? thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-23T03:58:55.376+0000","updated":"2017-10-23T03:58:55.376+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16214617","id":"16214617","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], the problem is map works for {{srcpart}} (in your case Map1 and Map5) are combined, while they shouldn't because they're targets of different DPPs and therefore are likely to output different results. I think you can disable CBO to see if the issue can be reproduced. Another way is to change the outer query into a union instead of a join.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-23T04:33:18.956+0000","updated":"2017-10-23T04:33:18.956+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16214644","id":"16214644","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"I can reproduce after disabling cbo\r\n{code}\r\n\r\nset hive.explain.user=false;\r\nset hive.spark.dynamic.partition.pruning=true;\r\nset hive.tez.dynamic.partition.pruning=true;\r\nset hive.auto.convert.join=false;\r\nset hive.cbo.enable=false;\r\nexplain\r\nselect * from\r\n  (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) a\r\njoin\r\n  (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.value) b\r\non a.key=b.key;\r\n{code}\r\n\r\nthe explain\r\n{code}\r\nSTAGE DEPENDENCIES:\r\n  Stage-2 is a root stage\r\n  Stage-1 depends on stages: Stage-2\r\n  Stage-0 depends on stages: Stage-1\r\n\r\nSTAGE PLANS:\r\n  Stage: Stage-2\r\n    Spark\r\n      DagName: root_20171023004308_4b3c304e-3deb-4193-846d-12cf9e6a50ab:2\r\n      Vertices:\r\n        Map 8 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: key (type: string)\r\n                      outputColumnNames: _col0\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                      Group By Operator\r\n                        keys: _col0 (type: string)\r\n                        mode: hash\r\n                        outputColumnNames: _col0\r\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                        Spark Partition Pruning Sink Operator\r\n                          Target column: ds (string)\r\n                          partition key expr: ds\r\n                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                          target work: Map 1\r\n\r\n  Stage: Stage-1\r\n    Spark\r\n      Edges:\r\n        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 1), Map 4 (PARTITION-LEVEL SORT, 1)\r\n        Reducer 3 <- Reducer 2 (PARTITION-LEVEL SORT, 1), Reducer 6 (PARTITION-LEVEL SORT, 1)\r\n        Reducer 6 <- Map 1 (PARTITION-LEVEL SORT, 1), Map 7 (PARTITION-LEVEL SORT, 1)\r\n      DagName: root_20171023004308_4b3c304e-3deb-4193-846d-12cf9e6a50ab:1\r\n      Vertices:\r\n        Map 1 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: srcpart\r\n                  Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                    Reduce Output Operator\r\n                      key expressions: ds (type: string)\r\n                      sort order: +\r\n                      Map-reduce partition columns: ds (type: string)\r\n                      Statistics: Num rows: 232 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\r\n                      value expressions: key (type: string)\r\n        Map 4 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Reduce Output Operator\r\n                      key expressions: key (type: string)\r\n                      sort order: +\r\n                      Map-reduce partition columns: key (type: string)\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n        Map 7 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: value is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Reduce Output Operator\r\n                      key expressions: value (type: string)\r\n                      sort order: +\r\n                      Map-reduce partition columns: value (type: string)\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n        Reducer 2 \r\n            Reduce Operator Tree:\r\n              Join Operator\r\n                condition map:\r\n                     Inner Join 0 to 1\r\n                keys:\r\n                  0 ds (type: string)\r\n                  1 key (type: string)\r\n                outputColumnNames: _col0, _col2\r\n                Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                Select Operator\r\n                  expressions: _col2 (type: string), _col0 (type: string)\r\n                  outputColumnNames: _col0, _col1\r\n                  Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                  Reduce Output Operator\r\n                    key expressions: _col1 (type: string)\r\n                    sort order: +\r\n                    Map-reduce partition columns: _col1 (type: string)\r\n                    Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                    value expressions: _col0 (type: string)\r\n        Reducer 3 \r\n            Reduce Operator Tree:\r\n              Join Operator\r\n                condition map:\r\n                     Inner Join 0 to 1\r\n                keys:\r\n                  0 _col1 (type: string)\r\n                  1 _col1 (type: string)\r\n                outputColumnNames: _col0, _col1, _col2, _col3\r\n                Statistics: Num rows: 280 Data size: 28129 Basic stats: COMPLETE Column stats: NONE\r\n                File Output Operator\r\n                  compressed: false\r\n                  Statistics: Num rows: 280 Data size: 28129 Basic stats: COMPLETE Column stats: NONE\r\n                  table:\r\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\r\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\r\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\r\n        Reducer 6 \r\n            Reduce Operator Tree:\r\n              Join Operator\r\n                condition map:\r\n                     Inner Join 0 to 1\r\n                keys:\r\n                  0 ds (type: string)\r\n                  1 value (type: string)\r\n                outputColumnNames: _col0, _col2\r\n                Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                Select Operator\r\n                  expressions: _col2 (type: string), _col0 (type: string)\r\n                  outputColumnNames: _col0, _col1\r\n                  Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                  Reduce Output Operator\r\n                    key expressions: _col1 (type: string)\r\n                    sort order: +\r\n                    Map-reduce partition columns: _col1 (type: string)\r\n                    Statistics: Num rows: 255 Data size: 25572 Basic stats: COMPLETE Column stats: NONE\r\n                    value expressions: _col0 (type: string)\r\n\r\n  Stage: Stage-0\r\n    Fetch Operator\r\n      limit: -1\r\n      Processor Tree:\r\n        ListSink\r\n\r\n{code}\r\n\r\nThere is only 1 Map about srcpart. The reason why the maps about srcpart can not be merged when enabling cbo is because the RS in Maps are considered different while they are considered same when disabling cbo(see attached [picture|https://issues.apache.org/jira/secure/attachment/12893484/17193_compare_RS_in_Map_5_1.PNG])","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-23T04:56:36.472+0000","updated":"2017-10-23T05:24:56.810+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16214728","id":"16214728","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]:\r\n{quote}\r\n1. The simplest solution is, if the DPP works' IDs (tracked by the target map works) are different, then we consider the target map works are different and don't combine them.\r\n2. Another solution is we walk the parent tasks first, and combine equivalent DPP works. Two DPP works can be considered equivalent as long as they output same records.\r\n{quote}\r\nFor #1, it can be implemented from the current code. For #2, how to compare the result of dpp work in the period of physical plan?  You mean directly comparing the estimated data size(Statistics: Num rows: 58 Data size: 5812)?\r\n\r\n{code}\r\n Map 9 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: value is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: value (type: string)\r\n                      outputColumnNames: _col0\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                      Select Operator\r\n                        expressions: _col0 (type: string)\r\n                        outputColumnNames: _col0\r\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                        Group By Operator\r\n                          keys: _col0 (type: string)\r\n                          mode: hash\r\n                          outputColumnNames: _col0\r\n                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                          Spark Partition Pruning Sink Operator\r\n                            Target column: ds (string)\r\n                            partition key expr: ds\r\n                            Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                            target work: Map 5\r\n{code}\r\n\r\n\r\n{code}\r\n  Map 8 \r\n            Map Operator Tree:\r\n                TableScan\r\n                  alias: src\r\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                  Filter Operator\r\n                    predicate: key is not null (type: boolean)\r\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                    Select Operator\r\n                      expressions: key (type: string)\r\n                      outputColumnNames: _col0\r\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                      Select Operator\r\n                        expressions: _col0 (type: string)\r\n                        outputColumnNames: _col0\r\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                        Group By Operator\r\n                          keys: _col0 (type: string)\r\n                          mode: hash\r\n                          outputColumnNames: _col0\r\n                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                          Spark Partition Pruning Sink Operator\r\n                            Target column: ds (string)\r\n                            partition key expr: ds\r\n                            Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\r\n                            target work: Map 1\r\n\r\n{code}\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-23T06:49:54.078+0000","updated":"2017-10-23T06:49:54.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16214737","id":"16214737","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~kellyzly],\r\nbq. how to compare the result of dpp work in the period of physical plan?\r\nWe can compare the DPP works the same way as we compare other works, i.e. if two works have the same operator tree and each operator has an equivalent counterpart, then the two works can be combined.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-23T06:56:55.385+0000","updated":"2017-10-23T06:57:30.794+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16215590","id":"16215590","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"{quote} The drawback is we'll lose some optimization opportunities - actually I'm not sure whether it's possible that two target map works share the same DPP in current implementation. {quote} As far as I know, this isn't possible. A DPP subtree can only be used to prune a single target {{MapWork}} - although that is something we want to change in HIVE-17178\r\n\r\n{quote} Two DPP works can be considered equivalent as long as they output same records. {quote} I'm not sure how this would work, you don't know what a DPP work will output until the query actually starts to run.\r\n\r\nI think a good fix here would to be just implement HIVE-17178 (I'm not sure, but this may be the same as HIVE-17877). If two DPP sinks are completely equivalent (same source table, filters, operations, etc.), but they only differ by the value of {{Target Work}}, then I think we should be able to combine them into a single DPP tree, with multiple target works. The value of the target work shouldn't change the value of the data that is written by a DPP subtree, so if the subtrees are equivalent, we can combine them. The main work will be to change the DPP code so that there can be multiple Target Works. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-23T18:23:45.555+0000","updated":"2017-10-23T18:23:45.555+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16216227","id":"16216227","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~stakiar], I meant we can compare DPP sink works the same way we compare other works. If two DPP works have the same operator tree, they will have the same output. I'll provide a PoC patch and more details in HIVE-17877.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-24T03:08:52.928+0000","updated":"2017-10-24T03:08:52.928+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16246852","id":"16246852","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12896851/HIVE-17193.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 11371 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=47)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=77)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_text] (batchId=73)\norg.apache.hadoop.hive.cli.TestContribNegativeCliDriver.org.apache.hadoop.hive.cli.TestContribNegativeCliDriver (batchId=240)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[llap_acid_fast] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning] (batchId=173)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=173)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=102)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[ct_noperm_loc] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multi] (batchId=111)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=206)\norg.apache.hadoop.hive.ql.exec.tez.TestWorkloadManager.testApplyPlanQpChanges (batchId=281)\norg.apache.hadoop.hive.ql.exec.tez.TestWorkloadManager.testReopen (batchId=281)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=223)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7742/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7742/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7742/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 17 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12896851 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-11-10T01:00:46.086+0000","updated":"2017-11-10T01:00:46.086+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16251262","id":"16251262","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Update to fix tests.\r\nWith the patch, two map works are considered targets of same DPP if:\r\n# They share the same DPP sink operators.\r\n# The DPP sink operators target the same columns of the map works.\r\n\r\nCurrently we don't combine sub trees within a base work, so this results in some suboptimal plans, and thus the update of the golden files. I think this is acceptable because correctness is more important. And it will be improved once we implement HIVE-17178.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-11-14T11:25:12.449+0000","updated":"2017-11-14T11:25:12.449+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16251738","id":"16251738","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12897542/HIVE-17193.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 11383 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=47)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=77)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ppd_union_view] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=102)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[ct_noperm_loc] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multi] (batchId=111)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=206)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=223)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7804/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7804/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7804/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 11 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12897542 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-11-14T17:04:24.704+0000","updated":"2017-11-14T17:04:24.704+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16254659","id":"16254659","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"The test failures are not related.\r\n[~kellyzly], [~stakiar], [~xuefuz] could you take a look? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-11-16T02:35:20.104+0000","updated":"2017-11-16T02:35:20.104+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16427157","id":"16427157","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 43s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 48s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 19s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  6s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 48s{color} | {color:red} ql: The patch generated 1 new + 25 unchanged - 2 fixed = 26 total (was 27) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 15s{color} | {color:red} The patch generated 50 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 17m  2s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10017/dev-support/hive-personality.sh |\r\n| git revision | master / dc5a943 |\r\n| Default Java | 1.8.0_111 |\r\n| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10017/yetus/diff-checkstyle-ql.txt |\r\n| asflicense | http://104.198.109.242/logs//PreCommit-HIVE-Build-10017/yetus/patch-asflicense-problems.txt |\r\n| modules | C: itests ql U: . |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10017/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2018-04-05T15:58:51.375+0000","updated":"2018-04-05T15:58:51.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16427278","id":"16427278","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12917528/HIVE-17193.3.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 141 failed/errored test(s), 13580 tests executed\n*Failed tests:*\n{noformat}\nTestBeeLineDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)\nTestCopyUtils - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestDbNotificationListener - did not produce a TEST-*.xml file (likely timed out) (batchId=246)\nTestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=252)\nTestExportImport - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestHCatHiveCompatibility - did not produce a TEST-*.xml file (likely timed out) (batchId=246)\nTestMiniDruidCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)\nTestMiniDruidKafkaCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)\nTestNegativeCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=95)\n\t[nopart_insert.q,insert_into_with_schema.q,input41.q,having1.q,create_table_failure3.q,default_constraint_invalid_default_value.q,database_drop_not_empty_restrict.q,windowing_after_orderby.q,orderbysortby.q,subquery_select_distinct2.q,authorization_uri_alterpart_loc.q,udf_last_day_error_1.q,constraint_duplicate_name.q,create_table_failure4.q,alter_tableprops_external_with_notnull_constraint.q,semijoin5.q,udf_format_number_wrong4.q,deletejar.q,exim_11_nonpart_noncompat_sorting.q,show_tables_bad_db2.q,drop_func_nonexistent.q,nopart_load.q,alter_table_non_partitioned_table_cascade.q,check_constraint_subquery.q,load_wrong_fileformat.q,check_constraint_udtf.q,lockneg_try_db_lock_conflict.q,udf_field_wrong_args_len.q,create_table_failure2.q,create_with_fk_constraints_enforced.q,groupby2_map_skew_multi_distinct.q,authorization_update_noupdatepriv.q,show_columns2.q,authorization_insert_noselectpriv.q,orc_replace_columns3_acid.q,compare_double_bigint.q,authorization_set_nonexistent_conf.q,alter_rename_partition_failure3.q,split_sample_wrong_format2.q,create_with_fk_pk_same_tab.q,compare_double_bigint_2.q,authorization_show_roles_no_admin.q,materialized_view_authorization_rebuild_no_grant.q,unionLimit.q,authorization_revoke_table_fail2.q,authorization_insert_noinspriv.q,duplicate_insert3.q,authorization_desc_table_nosel.q,stats_noscan_non_native.q,orc_change_serde_acid.q,create_or_replace_view7.q,exim_07_nonpart_noncompat_ifof.q,create_with_unique_constraints_enforced.q,udf_concat_ws_wrong2.q,fileformat_bad_class.q,merge_negative_2.q,exim_15_part_nonpart.q,authorization_not_owner_drop_view.q,external1.q,authorization_uri_insert.q,create_with_fk_wrong_ref.q,columnstats_tbllvl_incorrect_column.q,authorization_show_parts_nosel.q,authorization_not_owner_drop_tab.q,external2.q,authorization_deletejar.q,temp_table_create_like_partitions.q,udf_greatest_error_1.q,ptf_negative_AggrFuncsWithNoGBYNoPartDef.q,alter_view_as_select_not_exist.q,touch1.q,groupby3_map_skew_multi_distinct.q,insert_into_notnull_constraint.q,exchange_partition_neg_partition_missing.q,groupby_cube_multi_gby.q,columnstats_tbllvl.q,drop_invalid_constraint2.q,alter_table_add_partition.q,update_not_acid.q,archive5.q,alter_table_constraint_invalid_pk_col.q,ivyDownload.q,udf_instr_wrong_type.q,bad_sample_clause.q,authorization_not_owner_drop_tab2.q,authorization_alter_db_owner.q,show_columns1.q,orc_type_promotion3.q,create_view_failure8.q,strict_join.q,udf_add_months_error_1.q,groupby_cube2.q,groupby_cube1.q,groupby_rollup1.q,genericFileFormat.q,invalid_cast_from_binary_4.q,drop_invalid_constraint1.q,serde_regex.q,show_partitions1.q,check_constraint_nonboolean_expr.q,invalid_cast_from_binary_6.q,create_with_multi_pk_constraint.q,udf_field_wrong_type.q,groupby_grouping_sets4.q,groupby_grouping_sets3.q,insertsel_fail.q,udf_locate_wrong_type.q,orc_type_promotion1_acid.q,set_table_property.q,create_or_replace_view2.q,groupby_grouping_sets2.q,alter_view_failure.q,distinct_windowing_failure1.q,invalid_t_alter2.q,alter_table_constraint_invalid_fk_col1.q,invalid_varchar_length_2.q,authorization_show_grant_otheruser_alltabs.q,subquery_windowing_corr.q,compact_non_acid_table.q,authorization_view_4.q,authorization_disallow_transform.q,materialized_view_authorization_rebuild_other.q,authorization_fail_4.q,dbtxnmgr_nodblock.q,set_hiveconf_internal_variable1.q,input_part0_neg.q,udf_printf_wrong3.q,load_orc_negative2.q,druid_buckets.q,archive2.q,authorization_addjar.q,invalid_sum_syntax.q,insert_into_with_schema1.q,udf_add_months_error_2.q,dyn_part_max_per_node.q,authorization_revoke_table_fail1.q,udf_printf_wrong2.q,archive_multi3.q,udf_printf_wrong1.q,subquery_subquery_chain.q,authorization_view_disable_cbo_4.q,no_matching_udf.q,create_view_failure7.q,drop_native_udf.q,truncate_column_list_bucketing.q,authorization_uri_add_partition.q,authorization_view_disable_cbo_3.q,bad_exec_hooks.q,authorization_view_disable_cbo_2.q,fetchtask_ioexception.q,char_pad_convert_fail2.q,authorization_set_role_neg1.q,serde_regex3.q,authorization_delete_nodeletepriv.q,materialized_view_delete.q,create_or_replace_view6.q,bucket_mapjoin_wrong_table_metadata_2.q,udf_sort_array_by_wrong2.q,local_mapred_error_cache.q,alter_external_acid.q,mm_concatenate.q,authorization_fail_3.q,set_hiveconf_internal_variable0.q,udf_last_day_error_2.q,alter_table_constraint_invalid_ref.q,create_table_wrong_regex.q,describe_xpath4.q,join32.q,insert_sorted.q,describe_xpath2.q,authorization_role_grant_otheruser.q,masking_acid_merge.q,authorization_ctas.q,authorization_fail_5.q,alter_view_failure9.q,insert_into_acid_notnull.q,illegal_partition_type3.q,alter_table_constraint_invalid_pk_tbl.q,authorization_uri_import.q,database_drop_does_not_exist.q,date_literal3.q,archive_multi4.q,date_literal2.q,gby_star2.q,authorization_table_grant_nosuchrole.q,insert_into_with_schema2.q,join_cond_unqual_ambiguous_vc.q,archive_multi2.q,analyze1.q,invalid_distinct3.q,fs_default_name1.q,subquery_in_on.q,show_columns3.q,column_rename1.q,authorization_view_1.q,ptf_negative_JoinWithAmbigousAlias.q,groupby_rollup3.q,truncate_table_failure6.q,groupby_cube3.q,invalid_create_tbl1.q,illegal_partition_type.q,cachingprintstream.q,create_function_nonudf_class.q,exchange_partition_neg_table_missing2.q,dbtxnmgr_notablelock.q,create_view_failure1.q,create_view_failure2.q,alter_view_failure8.q,check_constraint_window_fun.q,update_notnull_constraint.q,authorization_drop_db_cascade.q,archive_partspec3.q,truncate_partition_column.q,alter_partition_partial_spec_dyndisabled.q,udf_format_number_wrong2.q,column_rename5.q,authorization_import.q,authorization_fail_2.q,script_error.q,archive_partspec5.q,script_broken_pipe2.q,update_no_such_table.q,exim_09_nonpart_noncompat_serdeparam.q,invalid_cast_from_binary_1.q,archive_partspec1.q,unionDistributeBy.q,drop_function_failure.q,authorization_priv_current_role_neg.q,archive_insert1.q,authorization_addpartition.q,archive_multi6.q,exim_05_nonpart_noncompat_coltype.q,druid_case.q,invalid_cast_to_binary_5.q,orderby_invalid_position.q,materialized_view_authorization_create_no_select_perm.q,exchange_partition_neg_with_fullacid_table.q,druid_address.q,delete_not_acid.q,temp_table_partitions.q,constraint_invalide_name.q,authorization_uri_load_data.q,udf_locate_wrong_args_len.q,duplicate_insert1.q,duplicate_insert2.q,udf_sort_array_by_wrong3.q,stats_publisher_error_2.q,show_tableproperties1.q,invalid_cast_to_binary_2.q,authorization_drop_admin_role.q,lockneg1.q,exim_16_part_noncompat_schema.q,database_switch_does_not_exist.q,ctas.q,exim_10_nonpart_noncompat_bucketing.q,unionOrderBy.q,addpart1.q,ptf_negative_NoWindowDefn.q,authorization_set_invalidconf.q,udtf_explode_not_supported3.q,ptf_negative_AmbiguousWindowDefn.q,create_external_with_check_constraint.q,udtf_invalid_place.q,join_cond_unqual_ambiguous.q,udf_format_number_wrong1.q,authorization_view_disable_cbo_6.q,exim_25_import_nonexist_authfail.q,authorization_role_cycles1.q,invalid_char_length_3.q,groupby_struct.q,join_alt_syntax_comma_on.q,exchange_partition_neg_incomplete_partition.q,udf_test_error_reduce.q,load_wrong_noof_part.q,authorization_export_ptn.q,drop_partition_failure.q,subquery_in_implicit_gby.q,udf_map_values_arg_num.q,udf_elt_wrong_args_len.q,alter_table_wrong_location.q,archive_insert4.q,authorization_grant_table_fail_nogrant.q,authorization_create_func1.q,dyn_part3.q,cte_with_in_subquery.q,column_change_skewedcol_type1.q,materialized_view_drop.q,selectDistinctStarNeg_2.q,exchange_partition_neg_with_mm_table.q,invalid_std_syntax.q,unset_view_property.q,authorization_view_3.q,subquery_exists_implicit_gby.q,authorization_set_role_neg2.q,authorization_grant_group.q,invalid_min_syntax.q,semijoin3.q,truncate_nonexistant_column.q,exchange_partition_neg_table_missing.q,gby_star.q,truncate_partition_column2.q,insertover_dynapart_ifnotexists.q,unionClusterBy.q,udf_qualified_name.q,udaf_invalid_place.q,spark_job_max_tasks.q,authorization_cannot_create_default_role.q,nonkey_groupby.q,spark_stage_max_tasks.q,ptf_negative_HavingLeadWithNoGBYNoWindowing.q,alter_view_as_select_with_partition.q,load_exist_part_authfail.q,archive_multi7.q,authorization_create_func2.q,authorization_grant_uri.q,line_terminator.q,load_view_failure.q,groupby_grouping_sets8.q,invalid_cast_from_binary_3.q,exim_21_part_managed_external.q,insert_into4.q,database_create_invalid_name.q,groupby_grouping_sets7.q,subq_insert.q,dyn_part2.q,alter_external_with_notnull_constraint.q,exchange_partition.q,lateral_view_join.q,allow_change_col_type_par_neg.q,create_function_nonexistent_db.q,create_function_nonexistent_class.q,authorization_not_owner_alter_tab_rename.q,strict_pruning.q,subquery_notexists_implicit_gby.q,orc_reorder_columns1.q,columnstats_partlvl_invalid_values.q,orc_reorder_columns2.q,authorization_dfs.q,udf_format_number_wrong7.q,exim_17_part_spec_underspec.q,druid_partitions.q,authorization_drop_role_no_admin.q,windowing_ll_no_over.q,subquery_corr_from.q,desc_failure2.q,load_non_native.q,windowing_ll_no_neg.q,authorization_role_grant2.q,lockneg4.q,lockneg3.q,drop_table_failure2.q,temp_table_authorize_create_tbl.q,dyn_part_max.q,orc_reorder_columns2_acid.q,change_hive_local_session_path.q,insert_into5.q,insert_into1.q,insert_into3.q,udf_in_2.q,udtf_explode_not_supported2.q,sample.q,udtf_explode_not_supported1.q,authorization_droppartition.q,orc_type_promotion2_acid.q,materialized_view_load.q,right_side_join.q,authorization_fail_1.q,authorization_cannot_create_all_role.q,invalid_max_syntax.q,udf_array_contains_wrong1.q,authorization_cannot_create_none_role.q,subquery_in_lhs.q,orc_replace_columns3.q,udf_size_wrong_args_len.q,create_skewed_table_dup_col_name.q,authorization_fail_7.q,authorization_invalid_priv_v1.q,invalidate_view1.q,union22.q,subquery_scalar_multi_columns.q,disallow_incompatible_type_change_on1.q,semijoin1.q,create_skewed_table_failure_invalid_col_name.q,udf_when_type_wrong.q,timestamp_literal.q,create_external_with_default_constraint.q,truncate_table_failure4.q,masking_acid_delete.q,check_constraint_violation.q,uniquejoin2.q,authorization_grant_table_dup.q,invalid_tbl_name.q,authorization_createview.q,alter_external_with_default_constraint.q,truncate_table_failure1.q,alter_partition_coltype_invalidtype.q,show_tablestatus_not_existing_part.q,authorization_msck.q,truncate_table_failure2.q,joinneg.q]\nTestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=216)\nTestReplicationOnHDFSEncryptedZones - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestReplicationScenarios - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestReplicationScenariosAcidTables - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestReplicationScenariosAcrossInstances - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestSequenceFileReadWrite - did not produce a TEST-*.xml file (likely timed out) (batchId=246)\nTestTezPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=54)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[statsoptimizer] (batchId=62)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[bucket_map_join_tez1] (batchId=174)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[groupby_groupingset_bug] (batchId=174)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=169)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mergejoin] (batchId=168)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=160)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_access_time_non_current_db] (batchId=171)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorization_div0] (batchId=170)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_dynamic_semijoin_reduction] (batchId=155)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.org.apache.hadoop.hive.cli.TestNegativeCliDriver (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[alter_notnull_constraint_violation] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_multi_into_notnull] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_overwrite_notnull_constraint] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[smb_bucketmapjoin] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[smb_mapjoin_14] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[sortmerge_mapjoin_mismatch_1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[stats_aggregator_error_1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[stats_aggregator_error_2] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[stats_publisher_error_1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[subquery_corr_in_agg] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[subquery_notin_implicit_gby] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[truncate_bucketed_column] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[truncate_column_seqfile] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_map_values_arg_type] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_max] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_min] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_next_day_error_1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_printf_wrong4] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_reflect_neg] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_sort_array_by_wrong1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_sort_array_wrong1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_sort_array_wrong2] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_sort_array_wrong3] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_test_error] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_trunc_error1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_trunc_error2] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_trunc_error3] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udtf_explode_not_supported4] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udtf_not_supported1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udtf_not_supported3] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[union2] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[unionSortBy] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[uniquejoin3] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[uniquejoin] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[unset_table_property] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[updateBasicStats] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[update_bucket_col] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[update_non_acid_table] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[update_partition_col] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[view_update] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[windowing_invalid_udaf] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[windowing_leadlag_in_udaf] (batchId=96)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_scalar] (batchId=125)\norg.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.org.apache.hadoop.hive.cli.TestSparkPerfCliDriver (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query11] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query15] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query16] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query18] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query19] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query21] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query24] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query25] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query29] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query30] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query32] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query34] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query35] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query37] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query40] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query44] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query45] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query46] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query47] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query48] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query4] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query50] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query53] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query54] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query57] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query58] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query5] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query61] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query63] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query65] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query66] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query67] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query68] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query6] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query72] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query73] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query75] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query76] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query77] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query78] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query79] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query80] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query81] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query82] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query83] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query85] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query88] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query89] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query8] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query90] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query91] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query92] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query94] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query95] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query97] (batchId=254)\norg.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query99] (batchId=254)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=224)\norg.apache.hadoop.hive.metastore.TestMetastoreVersion.testMetastoreVersion (batchId=226)\norg.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionMatching (batchId=226)\norg.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionEmptyPartValues[Embedded] (batchId=210)\norg.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionEmptyPartValues[Remote] (batchId=210)\norg.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionNullPartValues[Embedded] (batchId=210)\norg.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionNullPartValues[Remote] (batchId=210)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testGetSplitsLocks (batchId=227)\norg.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=231)\norg.apache.hive.jdbc.TestJdbcWithMiniLlap.testLlapInputFormatEndToEnd (batchId=237)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/10017/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/10017/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10017/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 141 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12917528 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2018-04-05T17:13:57.362+0000","updated":"2018-04-05T17:13:57.362+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16442946","id":"16442946","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 46s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 41s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 18s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  2s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 41s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 40s{color} | {color:red} ql: The patch generated 1 new + 25 unchanged - 2 fixed = 26 total (was 27) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 15s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 17m  2s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10303/dev-support/hive-personality.sh |\r\n| git revision | master / 760d472 |\r\n| Default Java | 1.8.0_111 |\r\n| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10303/yetus/diff-checkstyle-ql.txt |\r\n| asflicense | http://104.198.109.242/logs//PreCommit-HIVE-Build-10303/yetus/patch-asflicense-problems.txt |\r\n| modules | C: itests ql U: . |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10303/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2018-04-18T17:54:58.836+0000","updated":"2018-04-18T17:54:58.836+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16443033","id":"16443033","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12919424/HIVE-17193.4.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 56 failed/errored test(s), 14288 tests executed\n*Failed tests:*\n{noformat}\nTestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=217)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_smb] (batchId=92)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_vectorization_0] (batchId=17)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[results_cache_invalidation2] (batchId=39)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[tez_join_hash] (batchId=54)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_udaf] (batchId=68)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mergejoin] (batchId=168)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[results_cache_invalidation2] (batchId=163)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_1] (batchId=171)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[alter_notnull_constraint_violation] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[avro_non_nullable_union] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[cachingprintstream] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[check_constraint_violation] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[compute_stats_long] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[default_constraint_invalid_default_value_type] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[dyn_part3] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[dyn_part_max_per_node] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[dynamic_partitions_with_whitelist] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_into_acid_notnull] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_into_notnull_constraint] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_multi_into_notnull] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_overwrite_notnull_constraint] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insertsel_fail] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[merge_constraint_notnull] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[script_broken_pipe2] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[script_broken_pipe3] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[script_error] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[serde_regex2] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[stats_aggregator_error_2] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[stats_publisher_error_1] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[stats_publisher_error_2] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[subquery_corr_in_agg] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[subquery_in_implicit_gby] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[subquery_notin_implicit_gby] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[subquery_scalar_corr_multi_rows] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[subquery_scalar_multi_rows] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true2] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_assert_true] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_reflect_neg] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_test_error] (batchId=96)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[udf_test_error_reduce] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[update_notnull_constraint] (batchId=95)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[cluster_tasklog_retrieval] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[local_mapred_error_cache] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace_turnoff] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[minimr_broken_pipe] (batchId=98)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=225)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testAcidInsertWithRemoveUnion (batchId=228)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=228)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=228)\norg.apache.hadoop.hive.ql.TestAutoPurgeTables.testExternalNoAutoPurge (batchId=233)\norg.apache.hadoop.hive.ql.TestAutoPurgeTables.testTruncateInvalidAutoPurge (batchId=233)\norg.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=232)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/10303/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/10303/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10303/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 56 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12919424 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2018-04-18T18:51:51.267+0000","updated":"2018-04-18T18:51:51.267+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16447064","id":"16447064","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"The failures are not related. [~stakiar], could you take a look at the latest patch? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-04-22T01:49:30.977+0000","updated":"2018-04-22T01:49:30.977+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16449794","id":"16449794","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2018-04-24T13:00:07.323+0000","updated":"2018-04-24T13:00:07.323+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16451652","id":"16451652","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 50s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 34s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 14s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  4s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 42s{color} | {color:red} ql: The patch generated 1 new + 25 unchanged - 2 fixed = 26 total (was 27) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 14s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 16m 40s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10474/dev-support/hive-personality.sh |\r\n| git revision | master / 63923e7 |\r\n| Default Java | 1.8.0_111 |\r\n| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10474/yetus/diff-checkstyle-ql.txt |\r\n| modules | C: itests ql U: . |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10474/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2018-04-25T04:32:58.677+0000","updated":"2018-04-25T04:32:58.677+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16451675","id":"16451675","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12920422/HIVE-17193.5.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 44 failed/errored test(s), 14293 tests executed\n*Failed tests:*\n{noformat}\nTestMinimrCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=93)\n\t[infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,parallel_orderby.q,bucket_num_reducers_acid.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,root_dir_external_table.q,infer_bucket_sort_dyn_part.q,udf_using.q,bucket_num_reducers_acid2.q]\nTestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=217)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_nullscan] (batchId=68)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=54)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=13)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_vectorization_0] (batchId=17)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=80)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_vectorization_original] (batchId=173)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[check_constraint] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[default_constraint] (batchId=163)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=165)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[enforce_constraint_notnull] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=169)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[materialized_view_create_rewrite_4] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[materialized_view_create_rewrite_5] (batchId=154)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_stats] (batchId=168)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=168)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[acid_vectorization_original_tez] (batchId=106)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[cluster_tasklog_retrieval] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace_turnoff] (batchId=98)\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[minimr_broken_pipe] (batchId=98)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testAcidInsertWithRemoveUnion (batchId=228)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=228)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=228)\norg.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=232)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=300)\norg.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgress (batchId=235)\norg.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=235)\norg.apache.hive.jdbc.TestSSL.testSSLFetchHttp (batchId=239)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStore.testTokenAuth (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testCancelRenewTokenFlow (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testConnection (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testIsValid (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testIsValidNeg (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testNegativeProxyAuth (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testNegativeTokenAuth (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testProxyAuth (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testRenewDelegationToken (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testTokenAuth (batchId=254)\norg.apache.hive.minikdc.TestJdbcWithMiniKdcCookie.testCookieNegative (batchId=254)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/10474/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/10474/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10474/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 44 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12920422 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2018-04-25T05:31:18.997+0000","updated":"2018-04-25T05:31:18.997+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090679/comment/16451821","id":"16451821","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Pushed to master. Thanks for the review, [~stakiar].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-04-25T07:51:12.228+0000","updated":"2018-04-25T07:51:12.228+0000"}],"maxResults":23,"total":23,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-17193/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3i48n:"}}