{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13129477","self":"https://issues.apache.org/jira/rest/api/2/issue/13129477","key":"HIVE-18412","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-01-09T17:34:32.367+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jan 09 21:51:26 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-18412/watchers","watchCount":4,"isWatching":false},"created":"2018-01-09T09:39:49.470+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-01-26T05:47:12.018+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12325007","id":"12325007","name":"Hive"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12322671","id":"12322671","name":"Transactions","description":"Transaction management and ACID"}],"timeoriginalestimate":null,"description":"Hi,\r\nwhile executing a query (DELETE with a join) on an ACID table, I get a NullPointerException in reducer.\r\nSee stack trace below.\r\nAccording to FileSinkOperator source code, it seems that buckepMap transient field is Null.\r\nIn my opinion, the only circumstance in which this field may be null is when the involved FileSinkOperator has been serialized and then deserialized. Actually, deserialization lets that transient reference uninitialized.\r\nI checked source code for more recent versions (including Hive 2.x) but everywhere that field may remain uninitialized (if FileSinkOperator is serialized/deserialized). So I think that issue may concern any version of Hive.\r\n{noformat}\r\nERROR : Vertex failed, vertexName=Reducer 3, vertexId=vertex_1513704146031_77754_2_05, diagnostics=[Task failed, taskId=task_1513704146031_77754_2_05_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java\r\n.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":108117,\"bucketid\":0,\"rowid\":1114}},\"value\":{\"\r\n_col0\":\"2017\",\"_col1\":\"10\"}}\r\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:173)\r\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:139)\r\n        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:347)\r\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:194)\r\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:185)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at javax.security.auth.Subject.doAs(Subject.java:422)\r\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)\r\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:185)\r\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:181)\r\n        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":108117,\"bucketid\":0,\"rowid\":1114}},\"value\":{\"_col0\":\"2017\"\r\n,\"_col1\":\"10\"}}\r\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:284)\r\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:266)\r\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:150)\r\n        ... 14 more\r\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":108117,\"bucketid\":0,\"rowid\":1114}},\"value\":{\"_col0\":\"2017\",\"_col1\":\"10\"}}\r\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:352)\r\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:274)\r\n        ... 16 more\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.findWriterOffset(FileSinkOperator.java:830)\r\n        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:758)\r\n        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:841)\r\n        at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)\r\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:343)\r\n        ... 17 more\r\n], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: .... etc.\r\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"FileSinkOperator thows NullPointerException ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"HDP2.6.1, Hive 1.2.1","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13129477/comment/16318784","id":"16318784","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"[~bbonnet] do you have repro query?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-01-09T17:34:32.367+0000","updated":"2018-01-09T17:34:32.367+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13129477/comment/16319248","id":"16319248","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"body":"Hi [~ekoifman], \r\nin our use case, we have 2 tables : a raw table named \"raw_table\" that is partitionned by date, and an ACID table named \"clean_table\" containing the same columns as the ones in \"raw_table\".\r\n\"clean_table\" has 3 buckets.\r\nThen, we have a cleansing query that will delete from \"clean_table\" all rows that exist in a specified partition of \"raw_table\". Comparison is done on a combination of functional keys (key0,key1,key2 and key3).\r\nThat job is made using 3 reducers (enforced by a parameter set before executing the query).\r\nHere is how it looks like :\r\n{code}\r\nset mapred.reduce.tasks=3;\r\nDELETE\r\n    FROM clean_table\r\n    WHERE concat(CASE WHEN key0 IS NULL THEN '' ELSE CAST(key0 AS STRING) END,'#',CASE WHEN key1 IS NULL THEN '' ELSE CAST(key1 AS STRING) END,'#',CASE WHEN key2 IS NULL THEN '' ELSE CAST(key2 AS STRING) END,'#',CASE WHEN key3 IS NULL THEN '' ELSE CAST(key3 AS STRING) END)\r\n        IN (\r\n             SELECT concat(CASE WHEN mt.key0 IS NULL THEN '' ELSE CAST(mt.key0 AS STRING) END,'#',CASE WHEN mt.key1 IS NULL THEN '' ELSE CAST(mt.key1 AS STRING) END,'#',CASE WHEN mt.key2 IS NULL THEN '' ELSE CAST(mt.key2 AS STRING) END,'#',CASE WHEN mt.key3 IS NULL THEN '' ELSE CAST(mt.key3 AS STRING) END)\r\n             FROM clean_table clean\r\n             LEFT SEMI JOIN(\r\n                             SELECT concat(CASE WHEN key0 IS NULL THEN '' ELSE CAST(key0 AS STRING) END,'#',CASE WHEN key1 IS NULL THEN '' ELSE CAST(key1 AS\r\n STRING) END,'#',CASE WHEN key2 IS NULL THEN '' ELSE CAST(key2 AS STRING) END,'#',CASE WHEN key3 IS NULL THEN '' ELSE CAST(key3 AS STRING) END) AS key\r\n                             FROM raw_table\r\n                             WHERE (year='2017' AND month='01' AND day='01' AND INPUT__FILE__NAME like '%20170101%') AND 1=1) raw \r\n             ON concat(CASE WHEN clean.key0 IS NULL THEN '' ELSE CAST(clean.key0 AS STRING) END,'#',CASE WHEN clean.key1 IS NULL THEN '' ELSE CAST(clean.key1 AS STRING) END,'#',CASE WHEN clean.key2 IS NULL THEN '' ELSE CAST(clean.key2 AS STRING) END,'#',CASE WHEN clean.key3 IS NULL THEN '' ELSE CAST(clean.key3 AS STRING) END) = raw.key\r\n            );\r\n {code}\r\nExecution plan confirms a multifile sprayer is used to run that request.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"created":"2018-01-09T21:51:26.669+0000","updated":"2018-01-09T21:51:26.669+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-18412/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3oocn:"}}