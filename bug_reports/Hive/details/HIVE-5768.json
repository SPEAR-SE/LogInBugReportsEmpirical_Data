{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12677938","self":"https://issues.apache.org/jira/rest/api/2/issue/12677938","key":"HIVE-5768","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324986","id":"12324986","description":"released","name":"0.13.0","archived":false,"released":true,"releaseDate":"2014-04-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2013-11-07T16:38:25.836+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Mar 26 18:11:17 UTC 2014","customfield_12310420":"357313","customfield_12312320":null,"customfield_12310222":"10002_*:*_4_*:*_11825859791_*|*_1_*:*_4_*:*_226793337_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-03-26T18:11:17.014+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5768/watchers","watchCount":5,"isWatching":false},"created":"2013-11-07T06:13:43.911+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/5","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/trivial.svg","name":"Trivial","id":"5"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-03-26T18:11:24.903+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12313604","id":"12313604","name":"CLI","description":"Command-line interpreter for Hive.\n"}],"timeoriginalestimate":null,"description":"NO PRECOMMIT TESTS\n{noformat}\n0: jdbc:hive2://localhost:10000/db2> !close\nAmbiguous command: [close, closeall]\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12612542","id":"12612542","filename":"HIVE-5768.1.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2013-11-07T06:22:00.752+0000","size":2975,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12612542/HIVE-5768.1.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12613282","id":"12613282","filename":"HIVE-5768.2.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2013-11-12T00:56:52.933+0000","size":2975,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12613282/HIVE-5768.2.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12617783","id":"12617783","filename":"HIVE-5768.3.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2013-12-09T05:54:51.170+0000","size":2975,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12617783/HIVE-5768.3.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12623064","id":"12623064","filename":"HIVE-5768.4.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2014-01-15T05:58:48.902+0000","size":2975,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12623064/HIVE-5768.4.patch.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"357603","customfield_12312823":null,"summary":"Beeline connection cannot be closed with !close command","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13816104","id":"13816104","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-07T16:38:25.836+0000","updated":"2013-11-07T16:38:25.836+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13816147","id":"13816147","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12612542/HIVE-5768.1.patch.txt\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/177/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/177/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests failed with: NonZeroExitCodeException: Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n '' ]]\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ cd /data/hive-ptest/working/\n+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-177/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ svn = \\s\\v\\n ]]\n+ [[ -n '' ]]\n+ [[ -d apache-svn-trunk-source ]]\n+ [[ ! -d apache-svn-trunk-source/.svn ]]\n+ [[ ! -d apache-svn-trunk-source ]]\n+ cd apache-svn-trunk-source\n+ svn revert -R .\nReverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java'\n++ egrep -v '^X|^Performing status on external'\n++ awk '{print $2}'\n++ svn status --no-ignore\n+ rm -rf target datanucleus.log ant/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target metastore/target common/target common/src/gen serde/target\n+ svn update\n\nFetching external item into 'hcatalog/src/test/e2e/harness'\nExternal at revision 1539724.\n\nAt revision 1539724.\n+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hive-ptest/working/scratch/build.patch\n+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]\n+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file beeline/src/java/org/apache/hive/beeline/BeeLine.java\npatching file beeline/src/java/org/apache/hive/beeline/Commands.java\nHunk #1 succeeded at 801 (offset 4 lines).\npatching file beeline/src/main/resources/BeeLine.properties\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hive-ptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven\n[INFO] Scanning for projects...\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Build Order:\n[INFO] \n[INFO] Hive\n[INFO] Hive Ant Utilities\n[INFO] Hive Shims Common\n[INFO] Hive Shims 0.20\n[INFO] Hive Shims Secure Common\n[INFO] Hive Shims 0.20S\n[INFO] Hive Shims 0.23\n[INFO] Hive Shims\n[INFO] Hive Common\n[INFO] Hive Serde\n[INFO] Hive Metastore\n[INFO] Hive Query Language\n[INFO] Hive Service\n[INFO] Hive JDBC\n[INFO] Hive Beeline\n[INFO] Hive CLI\n[INFO] Hive Contrib\n[INFO] Hive HBase Handler\n[INFO] Hive HCatalog\n[INFO] Hive HCatalog Core\n[INFO] Hive HCatalog Pig Adapter\n[INFO] Hive HCatalog Server Extensions\n[INFO] Hive HCatalog Webhcat Java Client\n[INFO] Hive HCatalog Webhcat\n[INFO] Hive HCatalog HBase Storage Handler\n[INFO] Hive HWI\n[INFO] Hive ODBC\n[INFO] Hive Shims Aggregator\n[INFO] Hive TestUtils\n[INFO] Hive Packaging\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive/0.13.0-SNAPSHOT/hive-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ant (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---\n[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---\n[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20 ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20 (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20 ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20 ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common-secure ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---\n[INFO] Compiling 12 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common-secure ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common-secure ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20S ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---\n[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20S ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20S ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.23 ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23 (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---\n[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.23 ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.23 ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---\n[WARNING] JAR will be empty - no content was marked for inclusion!\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-assembly-plugin:2.3:single (uberjar) @ hive-shims ---\n[INFO] Reading assembly descriptor: src/assemble/uberjar.xml\n[WARNING] Artifact: org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[WARNING] Configuration options: 'appendAssemblyId' is set to false, and 'classifier' is missing.\nInstead of attaching the assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar, it will become the file for main project artifact.\nNOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!\n[WARNING] Replacing pre-existing project main-artifact file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/archive-tmp/hive-shims-0.13.0-SNAPSHOT.jar\nwith assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Common 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/common (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---\n[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---\n[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-common ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-common ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Serde 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-serde ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/serde (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---\n[INFO] Compiling 351 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---\n[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/test-classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-serde ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-serde ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Metastore 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-metastore ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/metastore (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.\n[INFO] \n[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---\n[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java\nANTLR Parser Generator  Version 3.4\norg/apache/hadoop/hive/metastore/parser/Filter.g\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---\n[INFO] Compiling 132 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---\n[INFO] DataNucleus Enhancer (version 3.2.2) for API \"JDO\" using JRE \"1.6\"\nDataNucleus Enhancer : Classpath\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar\n>>  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar\n>>  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar\n>>  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar\n>>  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar\n>>  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar\n>>  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar\n>>  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar\n>>  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes\n>>  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar\n>>  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar\n>>  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar\n>>  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar\n>>  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar\n>>  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar\n>>  /data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar\n>>  /data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar\n>>  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar\n>>  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar\n>>  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar\n>>  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar\n>>  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar\n>>  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar\n>>  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar\n>>  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar\n>>  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar\n>>  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar\n>>  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar\n>>  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar\n>>  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar\n>>  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar\n>>  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar\n>>  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar\n>>  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar\n>>  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar\n>>  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar\n>>  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar\n>>  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar\n>>  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar\n>>  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar\n>>  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar\n>>  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar\n>>  /data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar\n>>  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar\n>>  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar\n>>  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar\n>>  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar\n>>  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar\n>>  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar\n>>  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar\n>>  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar\n>>  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar\n>>  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar\n>>  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar\n>>  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar\n>>  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar\n>>  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar\n>>  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar\n>>  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar\n>>  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar\n>>  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar\n>>  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nDataNucleus Enhancer completed with success for 25 classes. Timings : input=591 ms, enhance=948 ms, total=1539 ms. Consult the log for full details\n\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---\n[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Query Language 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.551s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [6.713s]\n[INFO] Hive Shims Common ................................. SUCCESS [2.802s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [1.755s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [3.183s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [1.328s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [3.162s]\n[INFO] Hive Shims ........................................ SUCCESS [3.627s]\n[INFO] Hive Common ....................................... SUCCESS [5.126s]\n[INFO] Hive Serde ........................................ SUCCESS [11.141s]\n[INFO] Hive Metastore .................................... SUCCESS [23.767s]\n[INFO] Hive Query Language ............................... FAILURE [0.195s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:07.591s\n[INFO] Finished at: Thu Nov 07 12:20:55 EST 2013\n[INFO] Final Memory: 43M/202M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal on project hive-exec: Could not resolve dependencies for project org.apache.hive:hive-exec:jar:0.13.0-SNAPSHOT: Could not find artifact org.apache.hive:hive-shims:jar:uberjar:0.13.0-SNAPSHOT -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12612542","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2013-11-07T17:21:08.107+0000","updated":"2013-11-07T17:21:08.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13819680","id":"13819680","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"body":"Rebased to trunk","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2013-11-12T00:56:52.938+0000","updated":"2013-11-12T00:56:52.938+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13841332","id":"13841332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks like need to re-upload to trigger Hive QA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-12-06T15:06:25.723+0000","updated":"2013-12-06T15:06:25.723+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13871693","id":"13871693","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"body":"just for triggering tests","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2014-01-15T05:59:26.544+0000","updated":"2014-01-15T05:59:26.544+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13938460","id":"13938460","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry for chiming in late, but I think there are two sides of the issue underneath: 1. prefix match is used for autocomplete (when tab is pressed) 2. exact match for execution. Currently #1 is used for both, which caused the problem seen. However, if we switch to #2, then we will lost #1. I tried to the patch, and it seems that autocomplete stops working, and additionally, somehow I got an exception for !command. There might be a bit more work required for this problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-17T22:07:17.677+0000","updated":"2014-03-17T22:07:17.677+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13938664","id":"13938664","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"body":"This patch is not related to auto completion, which is handled by jline and completors. Could you explain the situation in detail? Or you may freely fix this as you wish.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2014-03-18T01:36:57.931+0000","updated":"2014-03-18T01:36:57.931+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13938704","id":"13938704","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I could be wrong, but w/o the patch, if I type \"close\" followed by tab, I'm prompted two choices: close and clossall. With the patch, it asks me if I want to show xxx choices. I guessed it's because closeall isn't considered a match.\n\nAlso, I saw an exception when close is executed, but I'm not sure if that's my setup problem, whatsoever.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-18T02:30:21.132+0000","updated":"2014-03-18T02:30:21.132+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13938779","id":"13938779","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"body":"I cannot understand, in trunk,\n{noformat}\n0: jdbc:hive2://localhost:10000> !c    \n\n!connect     !columns     !close       !closeall    !commit      !call\n0: jdbc:hive2://localhost:10000> !close\n\n!close       !closeall\n0: jdbc:hive2://localhost:10000> !close                                           \nAmbiguous command: [close, closeall]\n{noformat}\n\nHIVE-5768\n{noformat}\n0: jdbc:hive2://localhost:10000> !c                                               \n\n!connect     !columns     !close       !closeall    !commit      !call\n0: jdbc:hive2://localhost:10000> !close\n\n!close       !closeall\n0: jdbc:hive2://localhost:10000> !close\nClosing: 0: jdbc:hive2://localhost:10000\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2014-03-18T04:09:04.466+0000","updated":"2014-03-18T04:09:04.466+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13938794","id":"13938794","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I tried again, and wasn't able to reproduce either the problems either. Sorry for the noise.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-18T04:19:25.246+0000","updated":"2014-03-18T04:19:25.246+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13947573","id":"13947573","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alangates","name":"alangates","key":"alangates","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alan Gates","active":true,"timeZone":"America/Los_Angeles"},"body":"Ran the tests locally, all pass.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alangates","name":"alangates","key":"alangates","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alan Gates","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-26T05:47:02.179+0000","updated":"2014-03-26T05:47:02.179+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12677938/comment/13948244","id":"13948244","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rhbutani","name":"rhbutani","key":"rhbutani","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Harish Butani","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to trunk and 0.13\n[~alangates] thanks for running the tests","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rhbutani","name":"rhbutani","key":"rhbutani","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Harish Butani","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-26T18:11:17.034+0000","updated":"2014-03-26T18:11:17.034+0000"}],"maxResults":12,"total":12,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5768/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1plin:"}}