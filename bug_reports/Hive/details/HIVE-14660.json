{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13000708","self":"https://issues.apache.org/jira/rest/api/2/issue/13000708","key":"HIVE-14660","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-08-27T20:57:30.417+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jan 26 11:36:16 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14660/watchers","watchCount":6,"isWatching":false},"created":"2016-08-27T20:12:14.339+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["pull-request-available"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-01-26T11:36:16.634+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312586","id":"12312586","name":"Query Processor","description":"Tracks issues dealing with query processing."},{"self":"https://issues.apache.org/jira/rest/api/2/component/12322671","id":"12322671","name":"Transactions","description":"Transaction management and ACID"}],"timeoriginalestimate":null,"description":"Hi,\n\nDELETE on an ACID table may fail on an ArrayIndexOutOfBoundsException.\nThat bug occurs at Reduce phase when there are less reducers than the number of the table buckets.\n\nIn order to reproduce, create a simple ACID table :\n\n{code:sql}\nCREATE TABLE test (`cle` bigint,`valeur` string)\n PARTITIONED BY (`annee` string)\n CLUSTERED BY (cle) INTO 5 BUCKETS\n TBLPROPERTIES ('transactional'='true');\n{code}\n\nPopulate it with lines distributed among all buckets, with random values and a few partitions.\nForce the Reducers to be less than the buckets :\n{code:sql}\nset mapred.reduce.tasks=1;\n{code}\nThen execute a delete that will remove many lines from all the buckets.\n{code:sql}\nDELETE FROM test WHERE valeur<'some_value';\n{code}\nThen you will get an ArrayIndexOutOfBoundsException :\n{code}\n2016-08-22 21:21:02,500 [FATAL] [TezChild] |tez.ReduceRecordSource|: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":{\"transactionid\":119,\"bucketid\":0,\"rowid\":0}},\"value\":{\"_col0\":\"4\"}}\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:352)\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:274)\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:252)\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:150)\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:139)\n        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:344)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:181)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:172)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:172)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:168)\n        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 5\n        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:769)\n        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:838)\n        at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)\n        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:343)\n        ... 17 more\n{code}\nAdding logs into FileSinkOperator, one sees the operator deals with buckets 0, 1, 2, 3, 4, then 0 again and it fails at line 769 : actually each time you switch bucket, you move forwards in a 5 (number of buckets) elements array. So when you get bucket 0 for the second time, you get out of the array...\n\n\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12825885","id":"12825885","filename":"HIVE-14660.1-banch-1.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"created":"2016-08-27T20:46:43.685+0000","size":2429,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12825885/HIVE-14660.1-banch-1.2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"ArrayIndexOutOfBoundsException on delete","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15442216","id":"15442216","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"GitHub user bonnetb opened a pull request:\n\n    https://github.com/apache/hive/pull/100\n\n    HIVE-14660 : ArrayIndexOutOfBounds on delete\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bonnetb/hive HIVE-14660\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/hive/pull/100.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #100\n    \n----\ncommit 21f333f0483249949dd97a6960c169b6dd255491\nAuthor: Benjamin BONNET <benjamin.bonnet@m4x.org>\nDate:   2016-08-27T20:20:15Z\n\n    HIVE-14660 : ArrayIndexOutOfBounds on delete\n\n----\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-27T20:57:30.417+0000","updated":"2016-08-27T20:57:30.417+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15443795","id":"15443795","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cartershanklin","name":"cartershanklin","key":"cartershanklin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Carter Shanklin","active":true,"timeZone":"America/Chicago"},"body":"[~ekoifman]  ran across this at random, not sure if you had seen it, does this problem still exist in Hive 2.X?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cartershanklin","name":"cartershanklin","key":"cartershanklin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Carter Shanklin","active":true,"timeZone":"America/Chicago"},"created":"2016-08-28T17:18:55.698+0000","updated":"2016-08-28T17:18:55.698+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15443844","id":"15443844","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"[~cartershanklin] I've not seen this before.  ACID writes require number of reducers (writers) to be equal the number of buckets.  So we should detect \"set mapred.reduce.tasks=1;\" type of config and raise a meaningful error.  I don't think there are any other options.\n\ncc [~alangates]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-28T17:48:25.047+0000","updated":"2016-08-28T17:48:25.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15445617","id":"15445617","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"body":"[~ekoifman] : actually, we encountered that bug without setting mapred.reduce.tasks=1. But I managed to reproduce it on a sandbox only by forcing the FileSinkOperator to deal with more than one bucket, forcing the number of reducers to 1.\n\nOn the platform where we encountered the issue (with default mapred settings), we have a work-around setting mapred.reduce.tasks to number of buckets.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"created":"2016-08-29T11:40:45.711+0000","updated":"2016-08-29T15:23:35.449+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15446510","id":"15446510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"[~bbonnet]\nbq. we have a work-around setting mapred.reduce.tasks to number of buckets.\nthat is the correct solution.  This should happen automatically - it's a serious bug if it does not.  Can you describe more precisely how you are ending up in this situation?  (Your config settings, query to repro this, relevant DDL.)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-29T17:34:25.625+0000","updated":"2016-08-29T17:34:25.625+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15449205","id":"15449205","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"body":"Here are the properties we set before creating the table and before inserting/deleting rows:\n{code}\nset hive.support.concurrency=true;\nset hive.enforce.bucketing=true;\nset hive.exec.dynamic.partition.mode=nonstrict;\nset hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;\nset hive.compactor.initiator.on=true;\nset hive.compactor.worker.threads=1;\n{code}\n\nApart from those properties, settings are \"standard\" (we use a HDP 2.3 cluster). \nmapred.reduce.tasks is not set\n\nWe have (by default): \nmapreduce.job.reduces=-1\nmapreduce.reduce.speculative=true\n\nTable has 36 columns, is clustered into 4 buckets (on a single column), ORC formatted, transactional and partitioned by year/month. It has about half billion rows.\n\nThe genuine query that fails is a kind of :\n{code}DELETE FROM table WHERE string_operations_on_some_columns IN ( select_from_another_table );\n{code}\n\nConcerning the mapred.reduce.tasks setting, I talk about a work-around (not a solution) since reading the FileSinkOperator, one sees it has be designed to operate on multiple buckets. In my opinion, the only mistake was the use of an array instead of a map, or a circular array (if you are guaranteed the way buckets are dealtwith  is circular for the latter, which I could not assume when I wrote the patch).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"created":"2016-08-30T14:44:12.264+0000","updated":"2016-08-30T14:44:12.264+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15468462","id":"15468462","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alangates","name":"alangates","key":"alangates","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alan Gates","active":true,"timeZone":"America/Los_Angeles"},"body":"Not having a writer for every bucket will cause incorrect results.  Any bucket that doesn't get a writer won't get a delta file written that covers that bucket, and thus any records in that bucket that should be deleted will not be.  So changing the FileSinkOperator to not assume there's a writer for each bucket is not the right approach.\n\nWe need to figure out how it is that we're getting to the write phase without the proper number of writers.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alangates","name":"alangates","key":"alangates","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alan Gates","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-09-06T20:32:09.604+0000","updated":"2016-09-06T20:32:09.604+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/15551513","id":"15551513","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"body":"Actually, every bucket gets a writer : even though you have only one reducer, every bucket is covered - by the same writer. And indeed, writers are designed to cover several buckets (see that comment \"// Find the bucket id, and switch buckets if need to\" in FileSeekOperator source code).\nIn my opinion, there is just a small bug in the way the bucket switch is implemented.\nRegards\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbonnet","name":"bbonnet","key":"bbonnet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Benjamin BONNET","active":true,"timeZone":"Europe/Paris"},"created":"2016-10-06T10:01:12.856+0000","updated":"2016-10-06T10:01:12.856+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/16340937","id":"16340937","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user bonnetb closed the pull request at:\n\n    https://github.com/apache/hive/pull/100\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-26T11:24:26.931+0000","updated":"2018-01-26T11:24:26.931+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13000708/comment/16340945","id":"16340945","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"GitHub user bonnetb opened a pull request:\n\n    https://github.com/apache/hive/pull/299\n\n    HIVE-14660 : ArrayIndexOutOfBounds on delete\n\n    See https://issues.apache.org/jira/browse/HIVE-14660\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bonnetb/hive HIVE-14660\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/hive/pull/299.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #299\n    \n----\ncommit 323f4bfa92835921780c057082b440bf54a7f5c8\nAuthor: Benjamin BONNET <benjamin.bonnet@...>\nDate:   2016-08-27T20:20:15Z\n\n    HIVE-14660 : ArrayIndexOutOfBounds on delete\n\n----\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-26T11:36:16.634+0000","updated":"2018-01-26T11:36:16.634+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14660/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i32wkf:"}}