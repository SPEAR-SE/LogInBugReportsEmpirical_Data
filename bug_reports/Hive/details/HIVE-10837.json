{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12833191","self":"https://issues.apache.org/jira/rest/api/2/issue/12833191","key":"HIVE-10837","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-01-13T11:51:16.430+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jan 29 14:33:36 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10837/watchers","watchCount":5,"isWatching":false},"created":"2015-05-27T21:12:19.523+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-01-29T14:33:36.460+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"When running a large insert statement through beeline or pyhs2, a thrift error is returned and hiveserver2 crashes.\n\nI ran into this with large insert statements -- my initial failing query was around 6million characters. After further testing however it seems like the failure threshold is based on number of inserted rows rather than the query's size in characters. My testing shows the failure threshold between 199,000 and 230,000 inserted rows.\n\nThe thrift error is as follows:\n\nError: org.apache.thrift.transport.TTransportException: java.net.SocketException: Broken pipe (state=08S01,code=0)\n\n\nAlso note for anyone that tests this issue - when testing different queries I ran into https://issues.apache.org/jira/browse/HIVE-10836\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Running large queries (inserts) fails and crashes hiveserver2","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pmcanneny","name":"pmcanneny","key":"pmcanneny","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick McAnneny","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pmcanneny","name":"pmcanneny","key":"pmcanneny","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick McAnneny","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Hive 1.1.0 on RHEL with Cloudera (cdh5.4.0)","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12833191/comment/15096061","id":"15096061","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bzamecnik","name":"bzamecnik","key":"bzamecnik","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bohumir Zamecnik","active":true,"timeZone":"Europe/Prague"},"body":"I've came across this issue on HiveServer2 1.1.1 used via Beeline on CDH CDH-5.4.4-1.cdh5.4.4.p0.4. The problem wasn't limited to inserting, a plain select failed as well. I queried a quite a big partitioned tabled backed by SequenceFiles of Protobuf. Each partition has about 6B records and it around 700GB. Query on a single partition was ok, but querying eg. 30 partitions fails (~19TB). Note that the same query executed via Hive CLI 1.1.1 works ok. The resulting number of rows is really small (the number of partitions, eg. <= 31). The HQL query string itself is small.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bzamecnik","name":"bzamecnik","key":"bzamecnik","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bohumir Zamecnik","active":true,"timeZone":"Europe/Prague"},"created":"2016-01-13T11:51:16.430+0000","updated":"2016-01-13T11:51:16.430+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12833191/comment/15096063","id":"15096063","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bzamecnik","name":"bzamecnik","key":"bzamecnik","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bohumir Zamecnik","active":true,"timeZone":"Europe/Prague"},"body":"Also the problem is that this error message does not provide any information what went wrong. Also I was unable to find any HiveServer log files.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bzamecnik","name":"bzamecnik","key":"bzamecnik","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bohumir Zamecnik","active":true,"timeZone":"Europe/Prague"},"created":"2016-01-13T11:53:01.012+0000","updated":"2016-01-13T11:53:01.012+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12833191/comment/15123523","id":"15123523","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dwatzke","name":"dwatzke","key":"dwatzke","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Watzke","active":true,"timeZone":"Europe/Prague"},"body":"Cloudera recommends increasing the HiveServer2's heap size\n\nhttp://www.cloudera.com/documentation/enterprise/latest/topics/admin_hos_troubleshooting.html\n\nso that's what I've done (from 256M to 8G) and it seems that it helped.\n\nBTW: I noticed that Cloudera increased the default heap size for hive roles in CDH 5.5 which is maybe related to this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dwatzke","name":"dwatzke","key":"dwatzke","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Watzke","active":true,"timeZone":"Europe/Prague"},"created":"2016-01-29T14:33:36.460+0000","updated":"2016-01-29T14:33:36.460+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10837/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2fa3z:"}}