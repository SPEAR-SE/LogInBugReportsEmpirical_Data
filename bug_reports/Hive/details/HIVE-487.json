{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12425378","self":"https://issues.apache.org/jira/rest/api/2/issue/12425378","key":"HIVE-487","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313714","id":"12313714","description":"released","name":"0.4.0","archived":false,"released":true,"releaseDate":"2009-10-12"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2009-05-21T19:47:13.458+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 05 17:29:51 UTC 2009","customfield_12310420":"73501","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_6467975433_*|*_1_*:*_1_*:*_711422499_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2009-08-04T23:11:12.469+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-487/watchers","watchCount":13,"isWatching":false},"created":"2009-05-13T20:54:34.537+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"16.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313637","id":"12313637","description":"released","name":"0.3.0","archived":false,"released":true,"releaseDate":"2009-04-30"}],"issuelinks":[{"id":"12326107","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12326107","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12432308","key":"HIVE-726","self":"https://issues.apache.org/jira/rest/api/2/issue/12432308","fields":{"summary":"Make \"ant package -Dhadoop.version=0.17.0\" work","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-12-17T00:07:14.518+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Attempting to compile Hive with Hadoop 0.20.0 fails:\n\naaron@jargon:~/src/ext/svn/hive-0.3.0$ ant -Dhadoop.version=0.20.0 package\n(several lines elided)\ncompile:\n     [echo] Compiling: hive\n    [javac] Compiling 261 source files to /home/aaron/src/ext/svn/hive-0.3.0/build/ql/classes\n    [javac] /home/aaron/src/ext/svn/hive-0.3.0/build/ql/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java:94: cannot find symbol\n    [javac] symbol  : method getCommandLineConfig()\n    [javac] location: class org.apache.hadoop.mapred.JobClient\n    [javac]       Configuration commandConf = JobClient.getCommandLineConfig();\n    [javac]                                            ^\n    [javac] /home/aaron/src/ext/svn/hive-0.3.0/build/ql/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java:241: cannot find symbol\n    [javac] symbol  : method validateInput(org.apache.hadoop.mapred.JobConf)\n    [javac] location: interface org.apache.hadoop.mapred.InputFormat\n    [javac]       inputFormat.validateInput(newjob);\n    [javac]                  ^\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] 2 errors\n\nBUILD FAILED\n/home/aaron/src/ext/svn/hive-0.3.0/build.xml:145: The following error occurred while executing this line:\n/home/aaron/src/ext/svn/hive-0.3.0/ql/build.xml:135: Compile failed; see the compiler error output for details.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12414370","id":"12414370","filename":"dynamic-proxy.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-23T19:41:23.431+0000","size":2104,"mimeType":"application/gzip","content":"https://issues.apache.org/jira/secure/attachment/12414370/dynamic-proxy.tar.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12409779","id":"12409779","filename":"hive-487.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-06-03T15:07:49.329+0000","size":9135,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12409779/hive-487.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12412175","id":"12412175","filename":"hive-487.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-06-30T15:08:14.715+0000","size":9107,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12412175/hive-487.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12408731","id":"12408731","filename":"HIVE-487.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-21T19:47:13.450+0000","size":40623,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12408731/HIVE-487.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12414667","id":"12414667","filename":"hive-487.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-27T21:39:56.732+0000","size":34899,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12414667/hive-487.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12414418","id":"12414418","filename":"hive-487.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-24T08:38:30.098+0000","size":34883,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12414418/hive-487.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12408992","id":"12408992","filename":"HIVE-487-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-26T04:53:21.854+0000","size":5248,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12408992/HIVE-487-2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12414345","id":"12414345","filename":"hive-487-jetty.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-23T15:04:35.729+0000","size":17445,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12414345/hive-487-jetty.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12414180","id":"12414180","filename":"hive-487-jetty-2.diff","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-22T04:01:15.180+0000","size":17723,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12414180/hive-487-jetty-2.diff"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12415460","id":"12415460","filename":"hive-487-runtime.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-08-04T05:49:30.253+0000","size":57211,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12415460/hive-487-runtime.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12415069","id":"12415069","filename":"hive-487-with-cli-changes.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-30T22:59:18.231+0000","size":40828,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12415069/hive-487-with-cli-changes.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12415410","id":"12415410","filename":"hive-487-with-cli-changes.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-08-03T21:17:00.085+0000","size":42478,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12415410/hive-487-with-cli-changes.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12415056","id":"12415056","filename":"hive-487-with-cli-changes.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-30T20:22:40.647+0000","size":38852,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12415056/hive-487-with-cli-changes.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12413932","id":"12413932","filename":"jetty-patch.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-18T19:40:21.790+0000","size":8110,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12413932/jetty-patch.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12408732","id":"12408732","filename":"junit-patch1.html","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-21T19:47:13.455+0000","size":380622,"mimeType":"text/html","content":"https://issues.apache.org/jira/secure/attachment/12408732/junit-patch1.html"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12415026","id":"12415026","filename":"patch-487.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-30T15:02:01.696+0000","size":38040,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12415026/patch-487.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"122278","customfield_12312823":null,"summary":"Hive does not compile with Hadoop 0.20.0","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kimballa","name":"kimballa","key":"kimballa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Kimball","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kimballa","name":"kimballa","key":"kimballa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Kimball","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12711771","id":"12711771","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"body":"This patch (based on trunk) will allow a compile and passes all but two unit tests (see attached junit test report). This is my first time contributing so I'm going to need a bit of help with the SQL result differences.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-21T19:47:13.458+0000","updated":"2009-05-21T19:47:13.458+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12711838","id":"12711838","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"body":"Actually it appears that those test failures are /not/ related to my changes (I checked out vanilla trunk and built and tested it, and those two tests still failed).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-21T21:59:16.540+0000","updated":"2009-05-21T21:59:16.540+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12711930","id":"12711930","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Assigned.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-22T02:30:49.074+0000","updated":"2009-05-22T02:30:49.074+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12711931","id":"12711931","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Thanks for your contribution.\nPlease do a submit patch when you attach a patch so that we get it in the patch submitted queue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-22T02:31:37.017+0000","updated":"2009-05-22T02:31:37.017+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12712332","id":"12712332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Hi Justin, Why have all the @Overrides have been taken out from the code.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-23T01:24:56.205+0000","updated":"2009-05-23T01:24:56.205+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12712621","id":"12712621","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"body":"The @Override annotations were removed because they were causing runtime exceptions to be generated in the latest sun Java VM. This is because those annotations were used on methods that were not correctly overriding anything in the respective superclass.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-25T01:20:06.387+0000","updated":"2009-05-25T01:20:06.387+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12712627","id":"12712627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasadc","name":"prasadc","key":"prasadc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasad Chakka","active":true,"timeZone":"Etc/UTC"},"body":"which version of JAVA VM are you using?\n\nThe below doesn't throw such errors but some configurations of Eclipse does throw such errors.\n\npchakka@dev111 ~ > java -version\njava version \"1.6.0_07\"\nJava(TM) SE Runtime Environment (build 1.6.0_07-b06)\nJava HotSpot(TM) 64-Bit Server VM (build 10.0-b23, mixed mode)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasadc","name":"prasadc","key":"prasadc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasad Chakka","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-25T03:14:18.466+0000","updated":"2009-05-25T03:14:18.466+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12712835","id":"12712835","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"body":"Output of my java -version reads:\njava version \"1.6.0_13\"\nJava(TM) SE Runtime Environment (build 1.6.0_13-b03)\nJava HotSpot(TM) Server VM (build 11.3-b02, mixed mode)\n\nLooking for more differences or reasons why this might happen. Double checking some things.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-26T03:07:51.379+0000","updated":"2009-05-26T03:07:51.379+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12712854","id":"12712854","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"body":"This patch removes all extraneous @override removals (potentially not neccessary, should've been done in another bug). Passes all unit tests on trunk (rev. 778559).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-26T04:53:21.865+0000","updated":"2009-05-26T04:53:21.865+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12712855","id":"12712855","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"body":"This patch does not attempt to re-implement the hadoop version specific functionality that was removed. This could potentially cause a bug in running trunk hive on hadoop 0.17.x as indicated by the comment on the removed code. Is this acceptable or should an attempt be made at reimplementation of intention using non-depreciated/removed interfaces?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-26T04:57:49.673+0000","updated":"2009-05-26T04:57:49.673+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12713348","id":"12713348","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Actually this has to compile with hadoop 0.17.x otherwise we will not be able to deploy this internally at FB. We are still on hadoop 0.17 and we have already lauched trunk into production.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-27T00:54:45.852+0000","updated":"2009-05-27T00:54:45.852+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12713349","id":"12713349","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Actually this has to compile with hadoop 0.17.x otherwise we will not be able to deploy this internally at FB. We are still on hadoop 0.17 and we have already lauched trunk into production.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-27T00:54:46.317+0000","updated":"2009-05-27T00:54:46.317+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12713357","id":"12713357","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"body":"Understood, I'll see what I can do. However, it appears that the API is starting to pull away with what would easily be reverse compatible. A 0.20.0+ branch might be warranted.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=justinlynn","name":"justinlynn","key":"justinlynn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Lynn","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-27T01:14:07.889+0000","updated":"2009-05-27T01:14:07.889+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12713448","id":"12713448","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kimballa","name":"kimballa","key":"kimballa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Kimball","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm +1 on an 0.20 branch. Cloudera's Distribution for Hadoop will be moving toward an 0.20 base and we would like to offer a compatible edition of Hive.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kimballa","name":"kimballa","key":"kimballa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Kimball","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-05-27T06:55:29.772+0000","updated":"2009-05-27T06:55:29.772+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12713450","id":"12713450","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashk","name":"ashk","key":"ashk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashwani Kumar","active":true,"timeZone":"Etc/UTC"},"body":"Another +1 for the 0.20 branch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashk","name":"ashk","key":"ashk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashwani Kumar","active":true,"timeZone":"Etc/UTC"},"created":"2009-05-27T06:59:28.747+0000","updated":"2009-05-27T06:59:28.747+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12713780","id":"12713780","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"I agree that at some point we would drop support for older branches (<=17). But it's still worth looking at whether we can avoid doing this right now. For example for the ExecDriver change:\n\n-      // workaround for hadoop-17 - jobclient only looks at commandlineconfig                                                                    \n-      Configuration commandConf = JobClient.getCommandLineConfig();                                                                              \n-      if (commandConf != null) {                                                                                                                 \n-        commandConf.set(\"tmpfiles\", realFiles);         \n\nwe can do this using reflection - (grep -i declaredmethod HiveInputFormat.java).\n\nare the mapredtask.java changes necessary?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-05-27T22:30:48.246+0000","updated":"2009-05-27T22:30:48.246+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12715946","id":"12715946","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"this version uses reflection in a couple of places so that ql continues to compile with older versions.\n\ni haven't had a chance to look at the hwi code and make that portable (it doesn't compile with 19 currently). If Edward could take a look - that would be awesome.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-06-03T15:07:49.372+0000","updated":"2009-06-03T15:07:49.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12723588","id":"12723588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"body":"I gave a quick try and was getting hunk errors. Are these patches cumulative? Should I apply them in order HIVE-487.patch, HIVE-487-2.patch, hive-487.3.patch?\n\nI looked at jetty the HWI server in the patch. The changes are cosmetic.  We might be able to make that portable with reflection as well if that is what we want. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-06-24T14:54:53.110+0000","updated":"2009-06-24T14:54:53.110+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12725662","id":"12725662","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"regenerated. \n\nthe HWI stuff does not compile against 0.19 and prior because of the change to using new jetty apis. one option is to bundle the new jetty jar with hive. hadoop seems to have moved to using ivy and i am wondering if we should do the same.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-06-30T15:08:14.720+0000","updated":"2009-06-30T15:08:14.720+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12725667","id":"12725667","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"have to use reflection. putting new jetty jars in hive does not matter since hadoop's jars take precedence at runtime (since we launch everything via hadoop)\n\ncan take a shot - looks simple ..","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-06-30T15:29:22.439+0000","updated":"2009-06-30T15:29:22.439+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12725669","id":"12725669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasadc","name":"prasadc","key":"prasadc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasad Chakka","active":true,"timeZone":"Etc/UTC"},"body":"i don't think we can keep single version of Hive for all active versions of Hadoop. Why don't we release a branch for 20 and periodically merge from trunk to 20?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prasadc","name":"prasadc","key":"prasadc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Prasad Chakka","active":true,"timeZone":"Etc/UTC"},"created":"2009-06-30T15:32:27.413+0000","updated":"2009-06-30T15:32:27.413+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12725715","id":"12725715","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"branching will get fairly complicated. where will 0.4.0 be branched off? sure there will be a time to deprecate support for older hadoop ersions - just not convinced this is it.\n\nNote that the dependency in this case is particularly frivolous. We could ship Hive with a single version of jetty that Hive components require - but instead we are depending on Hadoop to provide it. This seems more like a setup problem on our side.\n\nOne simple option (to not use reflection) is to add the right version of jetty into the runtime classpath (if it's not there already). the compile time works fine already. (since we control the classpath from build xmls)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-06-30T17:30:41.894+0000","updated":"2009-06-30T17:30:41.894+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12726820","id":"12726820","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"so i tried a custom classloader to force the new jetty jars to be used preferentially for loading classes.\n\nalas - it does not work. it seems that some classes from the hadoop jetty jars are already loaded by the time control is transferred to hive/hwi. trying to load remaining classes from the new jetty jar causes a 'sealing violation exception'. (this is with hadoop-19)\n\nonly reasonable alternative i can think of now is to run the hwiserver by spawning a new jvm (with a modified classpath that omits hadoop's jetty jars)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-03T08:06:12.458+0000","updated":"2009-07-03T08:06:12.458+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12727039","id":"12727039","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"body":"Joydeep,\nWe do depend on Hadoop to provide Jetty. The rational was not to require extra or external libraries for the user. At the time Hive had just become its own project from being a Hadoop contrib project so it made sense to depend on Hadoop Jetty. We have a few other options. We can use a completely different Web Server. http://tjws.sourceforge.net/. Now we have no conflicts. Or we can just build a war with no embedded type options. Even if we switch to tjws we still might end up using reflection since the API could change over time although we would chose when to upgrade the servlet engine, not hadoop. For now I will make a version that uses reflection to start up the server, since these changes are mostly cosmetic.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-03T16:36:11.107+0000","updated":"2009-07-03T16:36:11.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12732929","id":"12732929","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"body":"Ok half way there. I added an abstraction to use reflection  to completely kick up the HWI Jetty Server. Right now I only added the code for jetty5 0.19.0. 20 soon. Is this what everyone had in mind?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-18T19:40:21.825+0000","updated":"2009-07-18T19:40:21.825+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12733948","id":"12733948","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"This sounds reasonable to me. Will go over the patch in more detail. Are you planning to upload another one soon or should I just review this one?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-22T01:49:08.712+0000","updated":"2009-07-22T01:49:08.712+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12733973","id":"12733973","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"body":"This is going a little slow. The reflection aspect is pretty painful coding. I  think I am 98% percent complete. New test cases added. Hopefully I can have a final take in a day or two, sometimes its is hard to decide what exceptions to throw etc since there are very few design patters based around reflecting entire applications :) ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-22T04:01:15.238+0000","updated":"2009-07-22T04:01:15.238+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734609","id":"12734609","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"body":"This patch passes all unit tests. Also deployed and tested to a 0.19.0 cluster and a 0.20.0 cluster. \n\nChanges to hive-default.conf are to correct \nhive-hwi.war\nto\nhive_hwi.war\n\nMy changes to HWIServer.java clobbered other changes in the previous 0.20 patch since HWIServer.java delegates most duty to ServerWrapper.java","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-23T15:04:35.754+0000","updated":"2009-07-23T15:04:35.754+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734674","id":"12734674","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"body":"Overall, it looks good - but can you do a simple cosmetic changes.\n\n1. Have 1 patch instead of different patches for jetty and 487\n2. Add more comments:\n\n/**\n\t\t\t\t29 \t\t Hadoop 17-19 used Jetty5. Hadoop 20 uses jetty6. Hive still should compile and \n...run with all versions.\n\t\t\t\t30 \t\t Java is strongly typed Class based language. The Reflection API is required to \n...circumvent the strong \n\t\t\t\t31 \t\t typing. We have used the reflection API to deal with the known versions of Jetty \n...we must work with. \n\t\t\t\t32 \t\t CS students: If you are ever in a debate about classless VS classful programming \n...be sure to \n\t\t\t\t33 \t\t reference this code.\n\t\t\t\t34 \t\t */\n\n\nis very good:\n\nCan you repeat a subset of this in HadoopVersion also ?\nHive still should compile and \n...run with all versions. (17-20)\n\n\n3. usesJobShell: can you add more comments here -- it is true for version 20 but not for 20 etc.\n4. This may be outside the scope of this - but should some unit tests run for hadoop17, and some for hadoop 20, as part of ant test.\n    Currently, all of them use the default 19. As I mentioned before, this can be done in a follow-up also.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-23T18:08:07.985+0000","updated":"2009-07-23T18:08:07.985+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734696","id":"12734696","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"body":"4. is not needed - we can enable 20 from hudson\n\n+1\n\nCan you add some more comments, and then I can commit it","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-23T18:45:45.022+0000","updated":"2009-07-23T18:45:45.022+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734749","id":"12734749","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"A couple thoughts:\n\n- Does the same compiled jar truly work in all versions of Hadoop between 0.17 and 0.19? That is to say, can we consider an option in which we use some build.xml rules to, depending on the value of a hadoop.version variable, swap between two implementations of the same .java file (one compatible with Jetty 5, one with Jetty 6)? Then in the build product we could simply include two jars and have the wrapper scripts swap between them based on version. If size is a concern, the variant classes could be put in their own jar that would only be a few KB.\n\n- The reflection code in this patch is pretty messy. I mocked up an idea for a slightly cleaner way to do it, and will attach it as a tarball momentarily. The idea is to define our own interfaces which have the same methods as we need to use in Jetty, and use a dynamic proxy to forward those invocations through to the actual implementation class. Dynamically choosing between the two interfaces is simple at runtime by simply checking that the method signatures correspond. This is still dirty (and a bad role model for CS students ;-) ) but it should reduce the number of Class.forName and .getMethod calls in the wrapper class","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-23T19:37:09.354+0000","updated":"2009-07-23T19:37:09.354+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734750","id":"12734750","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Here's a tarball showing the technique mentioned in the comment above. The script \"run.sh\" will compile and run the example once with \"v1\" on the classpath, and a second time with \"v2\" on the classpath. I'm not certain that this will cover all the cases that are needed for Jetty, but I figured I would throw it out there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-23T19:41:23.471+0000","updated":"2009-07-23T19:41:23.471+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734781","id":"12734781","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"body":"@Todd - Where were you a few weeks ago? :)\n\n{noformat}\nThen in the build product we could simply include two jars and have the wrapper scripts swap between them based on version\n{noformat}\nThe jars are upstream in Hadoop core. I did not look into this closely but the talk about 'Sealing exceptions' above led me to believe I should not try this.\n\nI have wrapped my head around most of your Dynamic Proxy idea. My only concern is will the ant process cooperate? Will eclipse think the HWI classes are broken? Can we translate your run.sh into something ant/eclipse can deal with?\n\n{noformat}\npublic class WebServer {\n  public void someMethod(String arg) {\n    System.out.println(\"Webserver v1: \" + arg);\n  }\n}\n{noformat}\n\nI really don't want to have one 'someMethod' per each Jetty method. Just start(), stop(), init(). I like your implementation, but this is such a 'hacky' thing, I wonder is it worth thinking that hard? Hopefully the Jetty crew will be happy with their API for the next few years. Hopefully, we will not be supporting Hadoop 0.17.0 indefinitely. Honestly all that reflection has me 'burnt out'.\n\nIf you/we can tackle the ant/eclipse issues I would be happy to use the 'Dynamic Proxy', but maybe we tackle it in a different Jira because this is a pretty big blocker and I am sure many people want to see this in the trunk. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=appodictic","name":"appodictic","key":"appodictic","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Edward Capriolo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-23T20:56:54.354+0000","updated":"2009-07-23T20:56:54.354+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734795","id":"12734795","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"bq. @Todd - Where were you a few weeks ago? \n\nChillin' over on the HADOOP jira ;-) We're gearing up for release of our distribution that includes Hadoop 0.20.0, so just started watching this one more carefully.\n\nbq. The jars are upstream in Hadoop core. I did not look into this closely but the talk about 'Sealing exceptions' above led me to believe I should not try this.\n\nSorry, what I meant here is that the hive tarball would include lib/hive-0.4.0.jar, lib/jetty-shims/hive-jetty-shim-v6.jar and lib/jetty-shims/hive-jetty-shim-v5.jar\n\nIn those jars we'd have two different implementations of the shim. The hive wrapper script would then do something like:\n\n{code}\nHADOOP_JAR=$HADOOP_HOME/hadoop*core*jar\nif [[ $HADOOP_JAR =~ 0.1[789] ]]; then\n  JETTY_SHIM=lib/jetty-shims/jetty-shim-v5.jar\nelse\n  JETTY_SHIM=lib/jetty-shims/jetty-shim-v6.jar\nfi\nCLASSPATH=$CLASSPATH:$JETTY_SHIM\n{code}\n\nTo generate the shim jars at compile time, we'd compile two different JettyShim.java files - one against the v5 API, and one against the v6 API.\n\nAs for eclipse properly completing/warning for the right versions for the right files, I haven't the foggiest idea. But I am pretty sure it's not going to warn if your reflective calls are broken either ;-)\n\nbq. My only concern is will the ant process cooperate?\n\nI don't see why not - my example build here is just to show how it works in a self contained way. The stuff inside v1-classes and v2-classes in the example are the equivalent of the two jetty jar versions - we don't have to compile them. The only code that has to compile is DynamicProxy.java which is completely normal code.\n\nbq. If you/we can tackle the ant/eclipse issues I would be happy to use the 'Dynamic Proxy', but maybe we tackle it in a different Jira because this is a pretty big blocker and I am sure many people want to see this in the trunk. \n\nAs for committing now and not worrying, that sounds pretty reasonable, as long as there's some kind of deprecation timeline set out. (e.g \"in Hive 0.5.0 we will drop support for versions of Hadoop that use Jetty v5\" or whatever). As someone who isn't a major Hive contributor, I'll defer to you guys completely -- I just wanted to throw the idea up on the JIRA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-23T21:25:06.991+0000","updated":"2009-07-23T21:25:06.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734830","id":"12734830","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"need to add the shell script hack to switch the -libjars option as well based on the jar version.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-23T23:03:13.447+0000","updated":"2009-07-23T23:03:13.447+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12734972","id":"12734972","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Here's a patch which adds a project called \"shims\" with separate source directories for 0.17, 0.18, 0.19, and 0.20. Inside each there is an implementation of JettyShims and HadoopShims which encapsulate all of the version-dependent code. The build.xml is set in such a way that ${hadoop.version} determines which one gets compiled.\n\nThis probably needs a bit more javadoc before it's commitable, but I think it's worth considering this approach over reflection.\n\nAlso, it seems like hadoop.version may be 0.18.0, 0.18.1, 0.18.2, etc. As long as it's kosher by Apache SVN standards, we should put a symlink for each of those versions in the shims/src/ directory pointing to 0.18, and same for the other minor releases. If symlinks aren't kosher, we need some way of parsing out the major version from within ant.\n\nNot being a regular contributor, I don't have a good test environment set up, but I've verified that this at least builds in all of the above versions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-24T08:38:30.136+0000","updated":"2009-07-24T08:38:30.136+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12735772","id":"12735772","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"I had added a GetVersionPref.java some time back to ant extensions in hive. It was later not used because we decided not to use preprocessing for 0.19 changes to validateInput and instead decided to rely on reflection. That can easily be resurrected.\n\nLet me look at this version as well. Also I am going to change this to a blocker as many people are waiting for this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-27T21:00:09.223+0000","updated":"2009-07-27T21:00:09.223+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12735773","id":"12735773","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"changing to a blocker.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-27T21:00:29.802+0000","updated":"2009-07-27T21:00:29.802+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12735783","id":"12735783","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Looks like a clean implementation. However, I do think that this will need some changes to the eclipse-templates to make it work with eclipse. We would want to conditionally add the src directory in shims corresponding to the proper version of hadoop to the eclipse launch templates in hive/eclipse-templates. Will try this out.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-27T21:22:12.218+0000","updated":"2009-07-27T21:22:12.218+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12735787","id":"12735787","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Seems to not compile with 0.17.0 \n\nant -Dhadoop.version=0.17.0 clean package ....\n\n\n[ivy:retrieve]  1 artifacts copied, 0 already retrieved (14101kB/79ms)\n\ninstall-hadoopcore-internal:\n    [untar] Expanding: /data/users/athusoo/commits/hive_trunk_ws9/.ptest_0/build/hadoopcore/hadoop-0.17.0.tar.gz into /data/users/athusoo/commits/hive_trunk_ws9/.ptest_0/build/hadoopcore\n    [touch] Creating /data/users/athusoo/commits/hive_trunk_ws9/.ptest_0/build/hadoopcore/hadoop-0.17.0.installed\n\ncompile:\n     [echo] Compiling: shims\n    [javac] Compiling 2 source files to /data/users/athusoo/commits/hive_trunk_ws9/.ptest_0/build/shims/classes\n    [javac] /data/users/athusoo/commits/hive_trunk_ws9/.ptest_0/shims/src/0.17.0/java/org/apache/hadoop/hive/shims/HadoopShims.java:48: cannot find symbol\n    [javac] symbol  : variable JobClient\n    [javac] location: class org.apache.hadoop.hive.shims.HadoopShims\n    [javac]     Configuration conf = JobClient.getCommandLineConfig();\n    [javac]                          ^\n    [javac] 1 error\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-27T21:33:43.816+0000","updated":"2009-07-27T21:33:43.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12735789","id":"12735789","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Woops, sorry about that. Simply add an import for o.a.h.mapred.JobClient and it compiles. New patch in a second","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-27T21:39:05.060+0000","updated":"2009-07-27T21:39:05.060+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12735791","id":"12735791","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Fixes the missing import. Now compiles with hadoop.version=0.17.0","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-27T21:39:56.736+0000","updated":"2009-07-27T21:39:56.736+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737126","id":"12737126","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"Modified Todd's patch so that it compiles cleanly with 0.20 and 0.17 as well. I have also added support in this patch to generate the proper eclipse files and have verified that this works with eclipse. Additionally the directory names within in shims have been renamed to 0.17, 0.18, ... 0.20 instead of 0.17.0, .. 0.20.0\n\nPlease take a look at this. Want to get this in as soon as possible so that we can move ahead with the branching.\n\nJoy was mentioning that an additional change to the cli shell script needs to be made for -libjars support. Joy, can you elaborate on that?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-30T15:02:01.720+0000","updated":"2009-07-30T15:02:01.720+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737191","id":"12737191","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Patch looks good for me (just inspected it visually over here)\n\nOne question: once we use these shims, is it possible that we could have just a single hive distribution which works for all versions of Hadoop? I think we may be able to accomplish this by making the shim jar output be libs/shims/hive_shims-{$hadoop.version.prefix}.jar. Then either through ClassLoader magic or shell wrapper magic, we put the right one on the classpath at runtime based on which hadoop version is on the classpath.\n\nIs this possible? Having different tarballs of hive for different versions of hadoop makes our lives slightly difficult for packaging.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-30T17:34:10.180+0000","updated":"2009-07-30T17:34:10.180+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737230","id":"12737230","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"It would be ideal if we can make a single jar work with different hadoop versions through classloader magic. There are also some things that are needed in the hive cli script which would have to be abstracted away through a configuration/envrionment variable. Lets try to do that for the long term, but get this in for 0.4.0. Does that sound reasonable?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-30T18:57:24.989+0000","updated":"2009-07-30T18:57:24.989+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737236","id":"12737236","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Ashish,\n\nThat does sound reasonable, though I will likely take it on in the short term, as we will be distributing packages for hadoop-0.18 and hadoop-0.20 until the majority of the community and our customers have transitioned over. During that time period we'd like to have a single \"hive\" package which will function with either. We can apply my work on top of the 0.4.0 release for our distribution, so it shouldn't block it, but I do think it would be nice if this feature were \"upstream\" in the Apache release.\n\nI've got some time blocked off to work on this - if I get something working this week do you think it might be able to go into 0.4.0?\n\n-Todd","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-30T19:06:03.708+0000","updated":"2009-07-30T19:06:03.708+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737239","id":"12737239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"body":"sure. We can get it into 0.4.0. We can wait for your checkin before freezing on 0.4.0 but we would like to at least branch 0.4.0 this week (will have a vote out for it soon). All that means is that if we branch before your checkin, you will have to provide patches for trunk and 0.4.0. Is that ok?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=athusoo","name":"athusoo","key":"athusoo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashish Thusoo","active":true,"timeZone":"Etc/UTC"},"created":"2009-07-30T19:20:31.789+0000","updated":"2009-07-30T19:20:31.789+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737258","id":"12737258","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Yep, that's fine. I'm a git user, branches don't faze me ;-)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-07-30T19:59:08.604+0000","updated":"2009-07-30T19:59:08.604+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737263","id":"12737263","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"attached the previous version with modifications for cli.sh. these modifications are required (even though they don't fix the problem entirely - see below).\n\nthe reason i am not able to fix the problem entirely is because -libjars is no longer processed automatically by RunJar. We have to convert CliDriver to implement 'Tool' interface for this to happen. this is easy - but i would rather not hold up things for that.\n\nI would suggest incorporating the patch as such - open a new jira for auxlibs/auxpath not working in 0.4/trunk and fix it there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-30T20:22:40.650+0000","updated":"2009-07-30T20:22:40.650+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737268","id":"12737268","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"on second thoughts - there's some code in execdriver that i need to call from CliDriver and things should work. will upload another one soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-30T20:37:09.112+0000","updated":"2009-07-30T20:37:09.112+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737345","id":"12737345","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"one more:\n\n- --auxpath works in both 19 and 20 now. auxlib should also work - i haven't tested it separately\n- removed -libjars for hadoop versions 20 and above from cli shell script. changes to CliDriver to add aux jars to classpath at runtime\n\nnote that hive server and hwi don't work with auxpath/lib in 20 and above (since that would also require non trivial changes to HWIServer and HiveServer). we can fix this as a followon (in case someone is using the two in combination - which seems doubtful).\n\nplease review changes to bin/ext/cli.sh and CliDriver ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-30T22:59:18.245+0000","updated":"2009-07-30T22:59:18.245+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12737774","id":"12737774","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"body":"   [junit] Begin query: alter2.q\n    [junit] diff -a -I \\(file:\\)\\|\\(/tmp/.*\\) /data/users/njain/hive_commit1/hive_commit1/build/ql/test/logs/clientpositive/alter2.q.out /data/users/njain/hive_commit1/hive_commit1/ql/src/test/results/clientpositive/alter2.q.out\n    [junit] Done query: alter2.q\n    [junit] Begin query: alter3.q\n    [junit] plan = /tmp/plan60193.xml\n    [junit] java.lang.NoClassDefFoundError: org/apache/hadoop/hive/shims/HadoopShims\n    [junit] \tat org.apache.hadoop.hive.ql.exec.ExecDriver.initializeFiles(ExecDriver.java:95)\n    [junit] \tat org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:358)\n    [junit] \tat org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:571)\n    [junit] \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    [junit] \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    [junit] \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n    [junit] \tat java.lang.reflect.Method.invoke(Method.java:597)\n    [junit] \tat org.apache.hadoop.util.RunJar.main(RunJar.java:165)\n    [junit] \tat org.apache.hadoop.mapred.JobShell.run(JobShell.java:54)\n    [junit] \tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)\n    [junit] \tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)\n    [junit] \tat org.apache.hadoop.mapred.JobShell.main(JobShell.java:68)\n    [junit] Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.shims.HadoopShims\n    [junit] \tat java.net.URLClassLoader$1.run(URLClassLoader.java:200)\n    [junit] \tat java.security.AccessController.doPrivileged(Native Method)\n    [junit] \tat java.net.URLClassLoader.findClass(URLClassLoader.java:188)\n    [junit] \tat java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    [junit] \tat java.lang.ClassLoader.loadClass(ClassLoader.java:251)\n    [junit] \tat java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319)\n    [junit] \t... 12 more\n\n\n\n\nMost of the tests are failing","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-07-31T23:40:34.485+0000","updated":"2009-07-31T23:40:34.485+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12738571","id":"12738571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Taking a look at these failing tests now... any chance someone could hop on IRC in ##hive on freenode? I'm happy to do the work, but would appreciate having someone to hit with quick questions since I'm not too familiar with the code base.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-08-03T20:38:44.817+0000","updated":"2009-08-03T20:38:44.817+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12738596","id":"12738596","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"The issue turned out to be that the shim classes weren't getting built into hive_exec.jar, which seems to include the built classes of many other of the components. I'm not entirely sure why this is designed like this (why not just have hive_exec.jar add the other jars to its own classloader at startup?) but including build/shims/classes in there fixed the tests. Attaching new patch momentarily","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-08-03T21:15:46.983+0000","updated":"2009-08-03T21:15:46.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12738613","id":"12738613","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"hive_exec is the one that's submitted to hadoop to execute the map-reduce jobs. so we bundle all the required classes in it up front.\n\nit could be done differently (using libjars) - but was the path of least resistance at the start.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-08-03T21:30:59.718+0000","updated":"2009-08-03T21:30:59.718+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12738844","id":"12738844","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Attaching a new patch which makes the shim behavior happen at runtime. Here's the general idea:\n\n- the shims/build.xml now uses Ivy to download tarballs for Hadoop 17, 18, 19, and 20. It builds each of the shim sources (from src/0.XX/), which have now been renamed so that each classname is unique (eg Hadoop20Shims.class).\n- The results of all of these builds end up in a single hive_shims.jar\n- Instead of being classes with all static methods, the shim classes are now non-static and are instantiated using ShimLoader.class, in a new shims/src/common/ directory\n- ShimLoader simply uses o.a.h.util.VersionInfo to determine the current version info, and reflection to instantiate the proper shims for the current version.\n\nI've tested this against pseudodistributed 18 and 20 clusters and it seemed to work. Unit tests also appear to work, though I haven't had a chance to let them run all the way through. I have not tested HWI at all as of yet.\n\nStill TODO:\n- I may have broken eclipse integration somewhat. I'm hoping someone who uses Eclipse can twiddle the necessary stuff there.\n- I would appreciate a review of the javadocs for the HadoopShims interface. I don't know the specifics of some of the 17 behavior, so my docs are lame and vague.\n- I think build.xml needs to be modified just a bit more so that the output directory/tarball no longer includes ${hadoop.version} in it. Additionally there are one or two ant conditionals based on hadoop version - I haven't had a chance to investigate them, but they should probably be removed\n- I think we should have a policy that hadoop.version defaults to the most recently released apache trunk - right now it defaults to 0.19.\n- To compile the shims we're downloading the entire release tarballs off the apache mirror. Would be nicer if we could just download the specific jars we need to compile against, but that might be a pipe dream.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-08-04T05:49:30.287+0000","updated":"2009-08-04T05:49:30.287+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12738851","id":"12738851","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"hey - how do i apply this git diff using patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-08-04T06:22:26.121+0000","updated":"2009-08-04T06:22:26.121+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12738855","id":"12738855","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Normal patch -p0 ought to work:\n\ntodd@todd-laptop:~/cloudera/cdh/repos/hive$ patch -p0 < /tmp/hive-487-runtime.patch \npatching file ant/build.xml\npatching file bin/ext/cli.sh\npatching file build-common.xml\npatching file build.xml\netc...\n\n(from a clean trunk checkout)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-08-04T06:30:31.808+0000","updated":"2009-08-04T06:30:31.808+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12738864","id":"12738864","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"my bad .. code looks pretty clean.\n\none concern is the stuff that u mentioned already - that all hadoop versions need to be downloaded. in particular - sometime back i had made some fixes to allow hive to compile against a specific hadoop tree (see http://bit.ly/2d4Ch). but this would be reverting that i imagine.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-08-04T06:47:29.226+0000","updated":"2009-08-04T06:47:29.226+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12739233","id":"12739233","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"body":"Committed. Thanks Todd","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=namit","name":"namit","key":"namit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Namit Jain","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-08-04T23:11:12.436+0000","updated":"2009-08-04T23:11:12.436+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12739356","id":"12739356","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"When I try to start Hive with hadoop built by myself, I saw an exception:\n\njava.lang.RuntimeException: Illegal Hadoop Version: Unknown (expected A.B.* format)\n        at org.apache.hadoop.hive.shims.ShimLoader.getMajorVersion(ShimLoader.java:101)\n        at org.apache.hadoop.hive.shims.ShimLoader.loadShims(ShimLoader.java:80)\n        at org.apache.hadoop.hive.shims.ShimLoader.getHadoopShims(ShimLoader.java:62)\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:226)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:166)\n        at org.apache.hadoop.mapred.JobShell.run(JobShell.java:194)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)\n        at org.apache.hadoop.mapred.JobShell.main(JobShell.java:220)\n\nI guess I need to specify some Hadoop version information when compiling hadoop?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-08-05T07:09:53.228+0000","updated":"2009-08-05T07:09:53.228+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12739556","id":"12739556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Zheng,\n\nThere is some kind of bug I've seen before in Hadoop's build process where the version info doesn't get generated on your first compile. It's silly, but try running 'ant package' a second time in your Hadoop build tree? Running \"hadoop version\" should let you know whether the version info got compiled in.\n\n-Todd","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-08-05T15:11:38.047+0000","updated":"2009-08-05T15:11:38.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12425378/comment/12739636","id":"12739636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"By doing \"ant ... package package\" I am able to generate the hadoop distribution with version information, and Hive runs fine with it now! Thanks, Todd!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-08-05T17:29:51.813+0000","updated":"2009-08-05T17:29:51.813+0000"}],"maxResults":63,"total":63,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-487/votes","votes":3,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0la1r:"}}