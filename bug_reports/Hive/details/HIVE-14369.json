{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12993218","self":"https://issues.apache.org/jira/rest/api/2/issue/12993218","key":"HIVE-14369","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-07-29T02:26:14.378+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jul 29 09:07:35 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14369/watchers","watchCount":4,"isWatching":false},"created":"2016-07-28T11:50:17.375+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-07-29T09:07:35.231+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"In our environment, we have two hadoop clusters with HA,  named hivecluster and sparkcluster.\nhivecluster is a HA hadoop cluster for hive, which has large hard disk.\nsparkcluster is a HA hadoop cluster for spark, which has large memory.\ne.g. below is a hdfs-site.xml of hivecluster:\n{code}\n<property>\n        <name>dfs.ha.namenodes.hivecluster</name>\n        <value>nn1,nn2</value>\n</property>\n<property>\n        <name>dfs.namenode.rpc-address.hivecluster.nn1</name>\n        <value>10.17.21.32:9000</value>\n</property>\n<property>\n        <name>dfs.namenode.rpc-address.hivecluster.nn2</name>\n        <value>10.17.21.77:9000</value>\n</property>\n<property>\n        <name>dfs.namenode.http-address.hivecluster.nn1</name>\n        <value>10.17.21.32:50070</value>\n</property>\n<property>\n        <name>dfs.namenode.http-address.hivecluster.nn2</name>\n        <value>10.17.21.77:50070</value>\n</property>\n{code}\n\nFirstly, I created a hive table located as hdfs://hivecluster/hive/warehouse/xxx\nIf I use hive on mr, it will run successfully.\nBut if I use hive on spark to submit a task to yarn cluster of sparkcluster, it says:\n{code}\nFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.spark.SparkTask\nyarn日志显示：\nDiagnostics: java.lang.IllegalArgumentException: java.net.UnknownHostException: hivecluster\nFailing this attempt. Failing the application.\n{code}\n\nI didn't set host of hivecluster into hdfs-site.xml of sparkcluster","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"submit a task with hive on spark to other yarn cluster failed","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Huang+Xiaomeng","name":"Huang Xiaomeng","key":"huang xiaomeng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaomeng Huang","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Huang+Xiaomeng","name":"Huang Xiaomeng","key":"huang xiaomeng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaomeng Huang","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12993218/comment/15398610","id":"15398610","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~Huang Xiaomeng] discussed this with me offline and we think the possible reason is sparkcluster cannot resolve the logical URI of the hive table.\nI'm not sure if this is specific to HoS. Xiaomeng, how did you submit the spark job to sparkcluster? Can you try the same thing with HoMR?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-07-29T02:26:14.378+0000","updated":"2016-07-29T02:26:14.378+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12993218/comment/15399006","id":"15399006","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Huang+Xiaomeng","name":"Huang Xiaomeng","key":"huang xiaomeng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaomeng Huang","active":true,"timeZone":"Etc/UTC"},"body":"Hi [~ruili] \nIt can't work, too. I think I should set both hivecluster and sparkcluster in hdfs-site.xml of sparkcluster.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Huang+Xiaomeng","name":"Huang Xiaomeng","key":"huang xiaomeng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaomeng Huang","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-29T09:07:35.231+0000","updated":"2016-07-29T09:07:35.231+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14369/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i31mcv:"}}