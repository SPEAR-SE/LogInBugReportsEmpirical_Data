{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12676507","self":"https://issues.apache.org/jira/rest/api/2/issue/12676507","key":"HIVE-5685","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324986","id":"12324986","description":"released","name":"0.13.0","archived":false,"released":true,"releaseDate":"2014-04-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2013-10-29T23:48:19.323+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Nov 15 06:08:54 UTC 2013","customfield_12310420":"355939","customfield_12312320":null,"customfield_12310222":"10002_*:*_5_*:*_1216552550_*|*_1_*:*_5_*:*_194132469_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-11-15T06:08:54.273+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5685/watchers","watchCount":3,"isWatching":false},"created":"2013-10-29T22:17:29.286+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"5.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-11-15T06:08:54.300+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"It seems like it works if there's more than one partition column, and doesn't work if there's just one. At least that's the case that I found. The situation for different types is the same.\n\n{noformat}\nhive> create table zzz(c string) partitioned by (i int);\nOK\nTime taken: 0.41 seconds\nhive> alter table zzz add partition (i='foo');\nOK\nTime taken: 0.185 seconds\nhive> create table zzzz(c string) partitioned by (i int,j int); \nOK\nTime taken: 0.085 seconds\nhive> alter table zzzz add partition (i='foo',j=5);            \nFAILED: SemanticException [Error 10248]: Cannot add partition column i of type string as it cannot be converted to type int\nhive> alter table zzzz add partition (i=5,j='foo');\nFAILED: SemanticException [Error 10248]: Cannot add partition column j of type string as it cannot be converted to type int\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12610952","id":"12610952","filename":"HIVE-5685.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-10-29T23:46:27.532+0000","size":1785,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12610952/HIVE-5685.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12612504","id":"12612504","filename":"HIVE-5685.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-07T02:04:09.263+0000","size":1785,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12612504/HIVE-5685.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12612667","id":"12612667","filename":"HIVE-5685.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-07T19:00:29.531+0000","size":1785,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12612667/HIVE-5685.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12613186","id":"12613186","filename":"HIVE-5685.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-11T18:05:13.037+0000","size":1785,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12613186/HIVE-5685.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12613692","id":"12613692","filename":"HIVE-5685.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-13T21:14:42.652+0000","size":1785,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12613692/HIVE-5685.5.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"356227","customfield_12312823":null,"summary":"partition column type validation doesn't work in some cases","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13808592","id":"13808592","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"https://reviews.apache.org/r/15069/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-10-29T23:48:19.323+0000","updated":"2013-10-29T23:48:19.323+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13808603","id":"13808603","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-10-30T00:03:39.842+0000","updated":"2013-10-30T00:03:39.842+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13808631","id":"13808631","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-10-30T00:44:32.618+0000","updated":"2013-10-30T00:44:32.618+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13815246","id":"13815246","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"body":"hmm","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sershe","name":"sershe","key":"sershe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sergey Shelukhin","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-06T20:17:24.496+0000","updated":"2013-11-06T20:17:24.496+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13815425","id":"13815425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"[~vikram.dixit] Can you reupload the patch to have Hive QA run on it?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-06T23:10:48.960+0000","updated":"2013-11-06T23:10:48.960+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13815552","id":"13815552","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"Refreshed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-07T02:04:09.267+0000","updated":"2013-11-07T02:04:09.267+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13816138","id":"13816138","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12612504/HIVE-5685.2.patch\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/174/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/174/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests failed with: NonZeroExitCodeException: Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n '' ]]\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ cd /data/hive-ptest/working/\n+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-174/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ svn = \\s\\v\\n ]]\n+ [[ -n '' ]]\n+ [[ -d apache-svn-trunk-source ]]\n+ [[ ! -d apache-svn-trunk-source/.svn ]]\n+ [[ ! -d apache-svn-trunk-source ]]\n+ cd apache-svn-trunk-source\n+ svn revert -R .\nReverted 'pom.xml'\n++ egrep -v '^X|^Performing status on external'\n++ awk '{print $2}'\n++ svn status --no-ignore\n+ rm -rf pom.xml.orig target datanucleus.log ant/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target metastore/target common/target common/src/gen serde/target\n+ svn update\n\nFetching external item into 'hcatalog/src/test/e2e/harness'\nExternal at revision 1539719.\n\nAt revision 1539719.\n+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hive-ptest/working/scratch/build.patch\n+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]\n+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\npatching file ql/src/test/queries/clientnegative/illegal_partition_type3.q\npatching file ql/src/test/results/clientnegative/illegal_partition_type3.q.out\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hive-ptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven\n[INFO] Scanning for projects...\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Build Order:\n[INFO] \n[INFO] Hive\n[INFO] Hive Ant Utilities\n[INFO] Hive Shims Common\n[INFO] Hive Shims 0.20\n[INFO] Hive Shims Secure Common\n[INFO] Hive Shims 0.20S\n[INFO] Hive Shims 0.23\n[INFO] Hive Shims\n[INFO] Hive Common\n[INFO] Hive Serde\n[INFO] Hive Metastore\n[INFO] Hive Query Language\n[INFO] Hive Service\n[INFO] Hive JDBC\n[INFO] Hive Beeline\n[INFO] Hive CLI\n[INFO] Hive Contrib\n[INFO] Hive HBase Handler\n[INFO] Hive HCatalog\n[INFO] Hive HCatalog Core\n[INFO] Hive HCatalog Pig Adapter\n[INFO] Hive HCatalog Server Extensions\n[INFO] Hive HCatalog Webhcat Java Client\n[INFO] Hive HCatalog Webhcat\n[INFO] Hive HCatalog HBase Storage Handler\n[INFO] Hive HWI\n[INFO] Hive ODBC\n[INFO] Hive Shims Aggregator\n[INFO] Hive TestUtils\n[INFO] Hive Packaging\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive/0.13.0-SNAPSHOT/hive-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ant (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---\n[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---\n[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20 ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20 (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---\n[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20 ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20 ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common-secure ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---\n[INFO] Compiling 12 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common-secure ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common-secure ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20S ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---\n[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20S ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20S ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.23 ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23 (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---\n[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.23 ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.23 ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Shims 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---\n[WARNING] JAR will be empty - no content was marked for inclusion!\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-assembly-plugin:2.3:single (uberjar) @ hive-shims ---\n[INFO] Reading assembly descriptor: src/assemble/uberjar.xml\n[WARNING] Artifact: org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[INFO] META-INF/MANIFEST.MF already added, skipping\n[WARNING] Configuration options: 'appendAssemblyId' is set to false, and 'classifier' is missing.\nInstead of attaching the assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar, it will become the file for main project artifact.\nNOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!\n[WARNING] Replacing pre-existing project main-artifact file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/archive-tmp/hive-shims-0.13.0-SNAPSHOT.jar\nwith assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Common 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/common (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---\n[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes\n[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---\n[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-common ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-common ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Serde 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-serde ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/serde (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---\n[INFO] Compiling 351 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---\n[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/test-classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-serde ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-serde ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Metastore 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-metastore ---\n[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/metastore (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.\n[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.\n[INFO] \n[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---\n[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java\nANTLR Parser Generator  Version 3.4\norg/apache/hadoop/hive/metastore/parser/Filter.g\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---\n[INFO] Compiling 132 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes\n[WARNING] Note: Some input files use or override a deprecated API.\n[WARNING] Note: Recompile with -Xlint:deprecation for details.\n[WARNING] Note: Some input files use unchecked or unsafe operations.\n[WARNING] Note: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---\n[INFO] DataNucleus Enhancer (version 3.2.2) for API \"JDO\" using JRE \"1.6\"\nDataNucleus Enhancer : Classpath\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar\n>>  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar\n>>  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar\n>>  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar\n>>  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar\n>>  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar\n>>  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar\n>>  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar\n>>  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes\n>>  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar\n>>  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar\n>>  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar\n>>  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar\n>>  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar\n>>  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar\n>>  /data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar\n>>  /data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar\n>>  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar\n>>  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar\n>>  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar\n>>  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar\n>>  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar\n>>  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar\n>>  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar\n>>  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar\n>>  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar\n>>  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar\n>>  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar\n>>  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar\n>>  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar\n>>  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar\n>>  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar\n>>  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar\n>>  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar\n>>  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar\n>>  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar\n>>  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar\n>>  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar\n>>  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar\n>>  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar\n>>  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar\n>>  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar\n>>  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar\n>>  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar\n>>  /data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar\n>>  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar\n>>  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar\n>>  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar\n>>  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar\n>>  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar\n>>  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar\n>>  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar\n>>  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar\n>>  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar\n>>  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar\n>>  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar\n>>  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar\n>>  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar\n>>  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar\n>>  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar\n>>  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar\n>>  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar\n>>  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar\n>>  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar\n>>  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar\n>>  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nDataNucleus Enhancer completed with success for 25 classes. Timings : input=575 ms, enhance=917 ms, total=1492 ms. Consult the log for full details\n\n[INFO] \n[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---\n[debug] execute contextualize\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---\n[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/test-classes\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---\n[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Query Language 0.13.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.626s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [7.092s]\n[INFO] Hive Shims Common ................................. SUCCESS [2.763s]\n[INFO] Hive Shims 0.20 ................................... SUCCESS [1.905s]\n[INFO] Hive Shims Secure Common .......................... SUCCESS [3.043s]\n[INFO] Hive Shims 0.20S .................................. SUCCESS [1.329s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [3.103s]\n[INFO] Hive Shims ........................................ SUCCESS [3.575s]\n[INFO] Hive Common ....................................... SUCCESS [5.213s]\n[INFO] Hive Serde ........................................ SUCCESS [11.132s]\n[INFO] Hive Metastore .................................... SUCCESS [24.081s]\n[INFO] Hive Query Language ............................... FAILURE [0.212s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:08.563s\n[INFO] Finished at: Thu Nov 07 12:14:09 EST 2013\n[INFO] Final Memory: 43M/202M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal on project hive-exec: Could not resolve dependencies for project org.apache.hive:hive-exec:jar:0.13.0-SNAPSHOT: Could not find artifact org.apache.hive:hive-shims:jar:uberjar:0.13.0-SNAPSHOT -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12612504","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2013-11-07T17:14:21.388+0000","updated":"2013-11-07T17:14:21.388+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13816225","id":"13816225","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"I am able to successfully build hive with this patch. I am not sure if something is amiss in the HiveQA build environment. [~brocknoland] any input would be appreciated.\n\nThanks\nVikram.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-07T18:41:39.490+0000","updated":"2013-11-07T18:41:39.490+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13816239","id":"13816239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"See email to dev@ titled \"Build broken due to HIVE-5773 - Fix build due to conflict between HIVE-5711 and HIVE-5713\"","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-07T18:50:54.204+0000","updated":"2013-11-07T18:50:54.204+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13818186","id":"13818186","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"[~vikram.dixit] Seems like you need to re-upload the patch for Hive QA","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-09T16:32:47.220+0000","updated":"2013-11-09T16:32:47.220+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13819160","id":"13819160","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"Re-uploading patch for Hive QA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-11T18:05:13.042+0000","updated":"2013-11-11T18:05:13.042+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13821846","id":"13821846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"HiveQA has not picked up the previously uploaded patch. Will re-upload.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-13T21:14:16.874+0000","updated":"2013-11-13T21:14:16.874+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13821848","id":"13821848","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"body":"Re-uploading patch for HiveQA again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vikram.dixit","name":"vikram.dixit","key":"vikram.dixit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vikram Dixit K","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-13T21:14:42.657+0000","updated":"2013-11-13T21:14:42.657+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13822802","id":"13822802","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:green}Overall{color}: +1 all checks pass\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12613692/HIVE-5685.5.patch\n\n{color:green}SUCCESS:{color} +1 4612 tests passed\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/279/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/279/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12613692","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2013-11-14T19:31:53.538+0000","updated":"2013-11-14T19:31:53.538+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12676507/comment/13823335","id":"13823335","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to trunk. Thanks, Vikram!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-15T06:08:54.296+0000","updated":"2013-11-15T06:08:54.296+0000"}],"maxResults":15,"total":15,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5685/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1pd1z:"}}