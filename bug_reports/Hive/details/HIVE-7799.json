{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12735361","self":"https://issues.apache.org/jira/rest/api/2/issue/12735361","key":"HIVE-7799","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329363","id":"12329363","name":"1.1.0","archived":false,"released":true,"releaseDate":"2015-03-07"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-08-22T10:45:12.273+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Aug 25 20:39:46 UTC 2014","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_2_*:*_40996930_*|*_1_*:*_2_*:*_430268158_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-08-25T20:39:46.200+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7799/watchers","watchCount":3,"isWatching":false},"created":"2014-08-20T09:45:21.161+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["Spark-M1"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12394592","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12394592","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"inwardIssue":{"id":"12723734","key":"HIVE-7292","self":"https://issues.apache.org/jira/rest/api/2/issue/12723734","fields":{"summary":"Hive on Spark","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12394593","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12394593","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12735266","key":"HIVE-7793","self":"https://issues.apache.org/jira/rest/api/2/issue/12735266","fields":{"summary":"Enable tests on Spark branch (3) [Sparch Branch]","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12395136","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12395136","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12736619","key":"HIVE-7873","self":"https://issues.apache.org/jira/rest/api/2/issue/12736619","fields":{"summary":"Re-enable lazy HiveBaseFunctionResultList [Spark Branch]","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-05-29T02:29:29.084+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323200","id":"12323200","name":"Spark","description":"Hive on Spark"}],"timeoriginalestimate":null,"description":"Here is the exception:\n{noformat}\n2014-08-20 01:14:36,594 ERROR executor.Executor (Logging.scala:logError(96)) - Exception in task 0.0 in stage 1.0 (TID 0)\njava.lang.NullPointerException\n        at org.apache.hadoop.hive.ql.exec.spark.HiveKVResultCache.next(HiveKVResultCache.java:113)\n        at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.next(HiveBaseFunctionResultList.java:124)\n        at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.next(HiveBaseFunctionResultList.java:82)\n        at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:42)\n        at scala.collection.Iterator$class.foreach(Iterator.scala:727)\n        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)\n        at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:65)\n        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)\n        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n        at org.apache.spark.scheduler.Task.run(Task.scala:54)\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:199)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n{noformat}\n\nBasically, the cause is that RowContainer is misused(it's not allowed to write once someone read row from it), i'm trying to figure out whether it's a hive issue or just in hive on spark mode.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12663631","id":"12663631","filename":"HIVE-7799.1-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-22T09:20:46.051+0000","size":1013,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12663631/HIVE-7799.1-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12663637","id":"12663637","filename":"HIVE-7799.2-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-22T09:42:58.040+0000","size":2894,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12663637/HIVE-7799.2-spark.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12664112","id":"12664112","filename":"HIVE-7799.3-spark.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-25T07:25:51.435+0000","size":1013,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12664112/HIVE-7799.3-spark.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"TRANSFORM failed in transform_ppr1.q[Spark Branch]","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14106661","id":"14106661","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"HiveBaseFunctionResultList use RowContainer to store collected map output row, all rows should be added into RowContainer then start read from it, RowContainer does not support write after read. Remove current lazy execution mode as it depends on RowContainer write-after-read.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-22T09:20:46.057+0000","updated":"2014-08-22T09:20:46.057+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14106673","id":"14106673","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"Process all inputs and stored output rows in RowContainer and then read from it is not very performance efficient. We could just use a queue to store output rows as ResultIterator only process next record while get next output row.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-22T09:42:58.046+0000","updated":"2014-08-22T09:42:58.046+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14106708","id":"14106708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12663637/HIVE-7799.2-spark.patch\n\n{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 5980 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_null\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/79/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/79/console\nTest logs: http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-79/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 4 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12663637","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-08-22T10:45:12.273+0000","updated":"2014-08-22T10:45:12.273+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14106868","id":"14106868","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"body":"I think with the v2 patch we need unbounded memory as we store the results in Queue and sometime a single input record could generate more than one record (UDTF) or some operators (such as group by) flush after processing many input records.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T14:08:29.981+0000","updated":"2014-08-22T14:08:29.981+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14106874","id":"14106874","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"body":"Let me look at the RowContainer and see if we can modify/extend it to support read/write like a queue with a persistent support. As far as I see we need persistent support.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T14:11:19.327+0000","updated":"2014-08-22T14:11:19.327+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14107106","id":"14107106","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"Thanks,[~venki387], it seems i miss something here, group by does need a persistent storage support here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-22T17:11:48.236+0000","updated":"2014-08-22T17:11:48.236+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14107139","id":"14107139","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"body":"Whenever {{ResultIterator.hasNext()}} or {{ResultIterator.next()}} is called we first serve records from RowContainer until all records in RowContainer are consumed. If there are no more records in RowContainer then we clear RowContainer and call {{processNextRecord}} or {{closeRecordProcessor}} in {{ResultIterator.hasNext()}} to get the next output record(s). So we start adding records only when RowContainer is empty (or cleared). I am trying to understand how we got into the situation where we are trying to write after reading has started. One scenario I can think of is if Spark has two threads like in producer-consumer.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T17:32:28.285+0000","updated":"2014-08-22T17:32:28.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14107462","id":"14107462","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"body":"ScriptOperator is spawning a separate thread which is adding the records to collector. Iterator thread is trying to read from RowContainer while ScriptOperator spawned thread is adding the records. There may be other operators that may spawn threads for processing. Looks like we need a synchronized queue with persistence support. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T20:48:35.979+0000","updated":"2014-08-22T20:48:35.979+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14107466","id":"14107466","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"MapDB might offer something we use or wrap: https://github.com/jankotek/mapdb","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T20:53:18.219+0000","updated":"2014-08-22T20:53:18.219+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14108598","id":"14108598","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"When resolved me might consider adding \n\n * orc_merge1.q\n * orc_merge2.q\n * orc_merge3.q\n * orc_merge4.q\n\nfrom HIVE-7792.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-24T21:51:56.147+0000","updated":"2014-08-24T21:51:56.147+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14108843","id":"14108843","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"Depends on the implementation of {{ResultIterator.hasNext()}}, it is designed to be a lazy iterator as it only try to call {{processNextRecord()}} while RowContainer is empty, but RowContainer does not support add more rows after already read as mentioned in previous comments. Here is what happens while different queries is executed:\n# For Map only job, it write map output into file directly, no need Collector in this case.\n# For Map Reduce job with GroupByOperator, {{HiveBaseFunctionResultList.collect()}} is triggered by {{closeRecordProcessor()}}, which is beyond the lazy-computing logic, so the ResultIterator does not do lazy computing in this case.\n# For Map Reduce job without GroupByOperator(like cluster by queries), ResultIterator do lazy computing, and it clear RowContainer each time befor call {{processNextRecord()}}. While read/write HiveBaseFunctionResultList in the same thread, access progress of RowContainer is like .....clear()->addRow()->first()->clear()->addRow()->first()...... so it won't violate RowContainer's access rule. But with mutli threads to read/write HiveBaseFunctionResultList, as the ScriptOperator does which venki mentioned above, it would definitely hit this JIRA issue.\n\nIn my opinion, there are 2 solutions:\n# remove ResultIterator lazy computing feature as patch1 does.\n# implement a RowConatiner-like class, which support current RowContainer features. it also need to be thread-safe, and support add row after {{first()}} is already called. \n\nThe second solution is quite complex, it may introduce performance degrade after support thread-safe access and write-after-read, compare with the performance upgrade of lazy-computing support, it's hardly to say whether it's worthy or not now. So I suggest we take the first solution to fix this issue, and left the possible optimization to milestone 4.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-25T07:24:16.033+0000","updated":"2014-08-25T07:24:16.033+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14108847","id":"14108847","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"body":"reattach the first patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengxiang+li","name":"chengxiang li","key":"chengxiang li","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=chengxiang+li&avatarId=25535","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=chengxiang+li&avatarId=25535","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=chengxiang+li&avatarId=25535","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=chengxiang+li&avatarId=25535"},"displayName":"Chengxiang Li","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-25T07:25:51.438+0000","updated":"2014-08-25T07:25:51.438+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14109246","id":"14109246","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"body":"[~chengxiang li] Your plan sounds good. Lets log a JIRA to enable lazy computing and we will revisit in milestone 4.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vkorukanti","name":"vkorukanti","key":"vkorukanti","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venki Korukanti","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T16:11:48.445+0000","updated":"2014-08-25T16:11:48.445+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14109398","id":"14109398","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12664112/HIVE-7799.3-spark.patch\n\n{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 6253 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_fs_default_name2\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/92/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/92/console\nTest logs: http://ec2-54-176-176-199.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-92/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 3 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12664112","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-08-25T17:56:46.654+0000","updated":"2014-08-25T17:56:46.654+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14109679","id":"14109679","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"Hey guys, I created HIVE-7873 to track the improvement in M4.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T20:37:02.467+0000","updated":"2014-08-25T20:37:02.467+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12735361/comment/14109682","id":"14109682","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you guys! I have committed this to spark!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brocknoland","name":"brocknoland","key":"brocknoland","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brock Noland","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T20:39:46.234+0000","updated":"2014-08-25T20:39:46.234+0000"}],"maxResults":16,"total":16,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-7799/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1z4fz:"}}