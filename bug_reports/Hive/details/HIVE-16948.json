{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13081984","self":"https://issues.apache.org/jira/rest/api/2/issue/13081984","key":"HIVE-16948","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-06-23T03:28:31.924+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 22 23:59:24 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_2764596342_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_2088406422","customfield_12312321":null,"resolutiondate":"2017-08-18T07:26:53.050+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16948/watchers","watchCount":8,"isWatching":false},"created":"2017-06-23T03:23:30.361+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"7.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12513342","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12513342","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13098676","key":"HIVE-17414","self":"https://issues.apache.org/jira/rest/api/2/issue/13098676","fields":{"summary":"HoS DPP + Vectorization generates invalid explain plan due to CombineEquivalentWorkResolver","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-22T23:59:24.891+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"in [union_subquery.q|https://github.com/apache/hive/blob/master/ql/src/test/queries/clientpositive/spark_dynamic_partition_pruning.q#L107] in spark_dynamic_partition_pruning.q\n{code}\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.spark.dynamic.partition.pruning=true;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.strict.checks.cartesian.product=false;\nexplain select ds from (select distinct(ds) as ds from srcpart union all select distinct(ds) as ds from srcpart) s where s.ds in (select max(srcpart.ds) from srcpart union all select min(srcpart.ds) from srcpart);\n{code}\nexplain \n{code}\nSTAGE DEPENDENCIES:\n  Stage-2 is a root stage\n  Stage-1 depends on stages: Stage-2\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-2\n    Spark\n      Edges:\n        Reducer 11 <- Map 10 (GROUP, 1)\n        Reducer 13 <- Map 12 (GROUP, 1)\n      DagName: root_20170622231525_20a777e5-e659-4138-b605-65f8395e18e2:2\n      Vertices:\n        Map 10 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string)\n                    outputColumnNames: ds\n                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                    Group By Operator\n                      aggregations: max(ds)\n                      mode: hash\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        sort order: \n                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                        value expressions: _col0 (type: string)\n        Map 12 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string)\n                    outputColumnNames: ds\n                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                    Group By Operator\n                      aggregations: min(ds)\n                      mode: hash\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        sort order: \n                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                        value expressions: _col0 (type: string)\n        Reducer 11 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: max(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                Filter Operator\n                  predicate: _col0 is not null (type: boolean)\n                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                  Group By Operator\n                    keys: _col0 (type: string)\n                    mode: hash\n                    outputColumnNames: _col0\n                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: _col0 (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: ds\n                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                          target column name: ds\n                          target work: Map 1\n                    Select Operator\n                      expressions: _col0 (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: ds\n                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                          target column name: ds\n                          target work: Map 4\n        Reducer 13 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: min(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                Filter Operator\n                  predicate: _col0 is not null (type: boolean)\n                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                  Group By Operator\n                    keys: _col0 (type: string)\n                    mode: hash\n                    outputColumnNames: _col0\n                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: _col0 (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: ds\n                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                          target column name: ds\n                          target work: Map 1\n                    Select Operator\n                      expressions: _col0 (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: ds\n                          Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                          target column name: ds\n                          target work: Map 4\n\n  Stage: Stage-1\n    Spark\n      Edges:\n        Reducer 2 <- Map 1 (GROUP, 2)\n        Reducer 3 <- Reducer 2 (PARTITION-LEVEL SORT, 2), Reducer 2 (PARTITION-LEVEL SORT, 2), Reducer 7 (PARTITION-LEVEL SORT, 2), Reducer 9 (PARTITION-LEVEL SORT, 2)\n        Reducer 7 <- Map 6 (GROUP, 1)\n        Reducer 9 <- Map 8 (GROUP, 1)\n      DagName: root_20170622231525_20a777e5-e659-4138-b605-65f8395e18e2:1\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  filterExpr: ds is not null (type: boolean)\n                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                  Group By Operator\n                    keys: ds (type: string)\n                    mode: hash\n                    outputColumnNames: _col0\n                    Statistics: Num rows: 1 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string)\n                      sort order: +\n                      Map-reduce partition columns: _col0 (type: string)\n                      Statistics: Num rows: 1 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\n        Map 6 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string)\n                    outputColumnNames: ds\n                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                    Group By Operator\n                      aggregations: max(ds)\n                      mode: hash\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        sort order: \n                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                        value expressions: _col0 (type: string)\n        Map 8 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string)\n                    outputColumnNames: ds\n                    Statistics: Num rows: 1 Data size: 23248 Basic stats: PARTIAL Column stats: NONE\n                    Group By Operator\n                      aggregations: min(ds)\n                      mode: hash\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        sort order: \n                        Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                        value expressions: _col0 (type: string)\n        Reducer 2 \n            Reduce Operator Tree:\n              Group By Operator\n                keys: KEY._col0 (type: string)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 23248 Basic stats: COMPLETE Column stats: NONE\n                Reduce Output Operator\n                  key expressions: _col0 (type: string)\n                  sort order: +\n                  Map-reduce partition columns: _col0 (type: string)\n                  Statistics: Num rows: 2 Data size: 46496 Basic stats: COMPLETE Column stats: NONE\n        Reducer 3 \n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Left Semi Join 0 to 1\n                keys:\n                  0 _col0 (type: string)\n                  1 _col0 (type: string)\n                outputColumnNames: _col0\n                Statistics: Num rows: 2 Data size: 51145 Basic stats: COMPLETE Column stats: NONE\n                File Output Operator\n                  compressed: false\n                  Statistics: Num rows: 2 Data size: 51145 Basic stats: COMPLETE Column stats: NONE\n                  table:\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n        Reducer 7 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: max(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                Filter Operator\n                  predicate: _col0 is not null (type: boolean)\n                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                  Group By Operator\n                    keys: _col0 (type: string)\n                    mode: hash\n                    outputColumnNames: _col0\n                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string)\n                      sort order: +\n                      Map-reduce partition columns: _col0 (type: string)\n                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n        Reducer 9 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: min(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                Filter Operator\n                  predicate: _col0 is not null (type: boolean)\n                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n                  Group By Operator\n                    keys: _col0 (type: string)\n                    mode: hash\n                    outputColumnNames: _col0\n                    Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string)\n                      sort order: +\n                      Map-reduce partition columns: _col0 (type: string)\n                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: -1\n      Processor Tree:\n        ListSink\n{code}\nthe target work of Reducer11 and Reducer13 is Map4 , but Map4 does not exist in the explain ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893484","id":"12893484","filename":"17193_compare_RS_in_Map_5_1.PNG","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-10-23T05:22:24.574+0000","size":305955,"mimeType":"image/png","content":"https://issues.apache.org/jira/secure/attachment/12893484/17193_compare_RS_in_Map_5_1.PNG"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12879093","id":"12879093","filename":"HIVE-16948_1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-27T01:34:25.898+0000","size":6031,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12879093/HIVE-16948_1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12879315","id":"12879315","filename":"HIVE-16948.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-28T08:36:10.272+0000","size":6955,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12879315/HIVE-16948.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12880794","id":"12880794","filename":"HIVE-16948.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-08T08:18:37.116+0000","size":13540,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12880794/HIVE-16948.5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12881698","id":"12881698","filename":"HIVE-16948.6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-14T08:28:42.531+0000","size":17038,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12881698/HIVE-16948.6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12882506","id":"12882506","filename":"HIVE-16948.7.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-18T03:50:38.560+0000","size":14336,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12882506/HIVE-16948.7.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12878733","id":"12878733","filename":"HIVE-16948.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-25T03:19:43.393+0000","size":6031,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12878733/HIVE-16948.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Invalid explain when running dynamic partition pruning query in Hive On Spark","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16060371","id":"16060371","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pxiong","name":"pxiong","key":"pxiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pengcheng Xiong","active":true,"timeZone":"America/Los_Angeles"},"body":"HoS? Hive on Spark?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pxiong","name":"pxiong","key":"pxiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pengcheng Xiong","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-23T03:28:31.924+0000","updated":"2017-06-23T03:28:31.924+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16060374","id":"16060374","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~pxiong]: i found it in HoS, will modify the description soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-23T03:30:32.438+0000","updated":"2017-06-23T03:30:32.438+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16060377","id":"16060377","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pxiong","name":"pxiong","key":"pxiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pengcheng Xiong","active":true,"timeZone":"America/Los_Angeles"},"body":"thanks. :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pxiong","name":"pxiong","key":"pxiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pengcheng Xiong","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-23T03:36:03.600+0000","updated":"2017-06-23T03:36:03.600+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16099424","id":"16099424","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"the reason why Map4 does not exist in the explain is because of [CombineEquivalentWorkResolver|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java]\n\nbefore CombineEquivalentWorkResolver optimization is enabled,Map4 exists in the explain, after CombineEquivalentWorkResolver which will find and combine equivalent works.  Map4 is deleted because Map4 equals Map1. So we need to remove the spark dynamic pruning sink branch in Reducer 11 and Reducer 13 in Stage-2.\n\n[~lirui], [~stakiar], [~csun] please help review, thanks!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-25T03:15:12.161+0000","updated":"2017-07-25T03:15:12.161+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16099616","id":"16099616","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"One thing need to be mentioned here:\n why remove dynamic partition pruning sink operator branch directly in CombineEquivalentWorkResolver#dispatch?\n{code}\n   @Override\n    public Object dispatch(Node nd, Stack<Node> stack, Object... nodeOutputs) throws SemanticException {\n      if (nd instanceof SparkTask) {\n        SparkTask sparkTask = (SparkTask) nd;\n        SparkWork sparkWork = sparkTask.getWork();\n        Set<BaseWork> roots = sparkWork.getRoots();\n        compareWorksRecursively(roots, sparkWork);\n        +removeDynamicPartitionPruningSinkBranch(removedMapWorkNames, sparkWork);\n      }\n      return null;\n    }\n{code}\n We found that Map4 equals to Map1 in Stage-1 and remove the dynamic partition pruning sink operator branch in Reducer 11 and Reducer 13 in Stage-2. Stage-1 is the child task of Stage-2. And the traverse order is definite, first Stage-1 then Stage-2 because [TaskGraphWalker|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/lib/TaskGraphWalker.java#L184] will first put children task in the front of task queue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-25T07:16:01.684+0000","updated":"2017-07-25T07:16:01.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16101050","id":"16101050","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui], [~stakiar], [~csun] please help review, thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-26T01:35:17.115+0000","updated":"2017-07-26T01:35:17.115+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16102502","id":"16102502","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"Overall, the approach LGTM. You may need to re-attach the patch, seem Hive QA hasn't run yet.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-27T00:13:00.743+0000","updated":"2017-07-27T00:13:00.743+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16102563","id":"16102563","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"upload HIVE-16948_1.patch to trigger HiveQA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-27T01:35:19.662+0000","updated":"2017-07-27T01:35:19.662+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16102762","id":"16102762","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Is it possible that the DPP work doesn't contain branches, and therefore when the target work is gone, the whole DPP work/task should be removed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-27T06:04:23.054+0000","updated":"2017-07-27T06:04:23.054+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16102849","id":"16102849","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: \n{quote}\nIs it possible that the DPP work doesn't contain branches, and therefore when the target work is gone, the whole DPP work/task should be removed?\n{quote}\n There are 3 places to remove spark dynamic partition pruning sink before CombineEquivalentWorkResolver \n1. SparkRemoveDynamicPruningBySize \n2. SparkCompiler#runCycleAnalysisForPartitionPruning\n3. SparkMapJoinOptimizer(HIVE-17087)\n\nIn this jira, there are two dynamic partition pruning sink operators which are target to two same Maps. If we need remove dynamic partition pruning operators in above three conditions. These 2 dynamic partition pruning sink operators will be removed together. In theory, there will not happen the DPP work doesn't contain branches( remove 1 and remain another).\n\nif my understanding is not correct, please tell me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-27T07:31:49.049+0000","updated":"2017-07-27T07:31:49.049+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16102900","id":"16102900","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12879093/HIVE-16948_1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6145/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6145/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6145/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-07-27 08:10:44.402\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6145/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-07-27 08:10:44.405\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 0f7c33d HIVE-17088: HS2 WebUI throws a NullPointerException when opened (Sergio Pena, reviewed by Aihua Xu)\n+ git clean -f -d\nRemoving ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/IfVectorExpression.java\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 0f7c33d HIVE-17088: HS2 WebUI throws a NullPointerException when opened (Sergio Pena, reviewed by Aihua Xu)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-07-27 08:10:51.019\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java: No such file or directory\nerror: a/ql/src/test/results/clientpositive/spark/spark_dynamic_partition_pruning.q.out: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12879093 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-27T08:10:51.625+0000","updated":"2017-07-27T08:10:51.625+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16102999","id":"16102999","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], my point is, in your example, both Reducer11 and Reducer13 contain two DPP sinks, and we need to remove one of them in each Reducer. Is it possible the reduce works only contain one DPP sink?\nMore specifically, you use {{OperatorUtils.removeBranch(pruneSinkOp)}} to remove the DPP sink, which only works if the DPP sink is in a branch. The other 3 places you mentioned can use {{OperatorUtils.removeBranch}} because DPP sinks are always in a branch in logical plan. But in physical plan (after {{SplitOpTreeForDPP}} has split the tree), I'm not sure whether the assumption will hold.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-27T09:34:09.669+0000","updated":"2017-07-27T09:34:09.669+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16104017","id":"16104017","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: \n{quote}\n\n Is it possible the reduce works only contain one DPP sink?\n{quote}\nthere are 3 conditions to remove dpp sink:\n1. SparkRemoveDynamicPruningBySize \n2. SparkCompiler#runCycleAnalysisForPartitionPruning\n3. SparkMapJoinOptimizer(HIVE-17087)\n\nIf i use 1 condition to remove dpp sink, can you give one example to show to remove 1 and remain another?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-27T22:25:17.682+0000","updated":"2017-07-27T22:25:17.682+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16104374","id":"16104374","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], I'm not talking about the 3 places. Here's an example:\n{noformat}\nset hive.cbo.enable=false;\nexplain select * from (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) a join (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) b on a.key=b.key;\n\nSTAGE DEPENDENCIES:\n  Stage-2 is a root stage\n  Stage-1 depends on stages: Stage-2\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-2\n    Spark\n      DagName: lirui_20170728110559_4c2bc0ba-ab9a-428b-bf09-23f1b19b068f:16\n      Vertices:\n        Map 8\n            Map Operator Tree:\n                TableScan\n                  alias: src\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: key is not null (type: boolean)\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: key (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: ds\n                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                          target column name: ds\n                          target work: Map 1\n            Execution mode: vectorized\n        Map 9\n            Map Operator Tree:\n                TableScan\n                  alias: src\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: key is not null (type: boolean)\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: key (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: ds\n                          Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                          target column name: ds\n                          target work: Map 5\n            Execution mode: vectorized\n\n  Stage: Stage-1\n    Spark\n      Edges:\n        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 1), Map 4 (PARTITION-LEVEL SORT, 1)\n        Reducer 3 <- Reducer 2 (PARTITION-LEVEL SORT, 1), Reducer 6 (PARTITION-LEVEL SORT, 1)\n        Reducer 6 <- Map 1 (PARTITION-LEVEL SORT, 1), Map 4 (PARTITION-LEVEL SORT, 1)\n      DagName: lirui_20170728110559_4c2bc0ba-ab9a-428b-bf09-23f1b19b068f:15\n      Vertices:\n        Map 1\n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: key is not null (type: boolean)\n                    Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: ds (type: string)\n                      sort order: +\n                      Map-reduce partition columns: ds (type: string)\n                      Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE\n                      value expressions: key (type: string)\n            Execution mode: vectorized\n        Map 4\n            Map Operator Tree:\n                TableScan\n                  alias: src\n                  Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: key is not null (type: boolean)\n                    Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: key (type: string)\n                      sort order: +\n                      Map-reduce partition columns: key (type: string)\n                      Statistics: Num rows: 58 Data size: 5812 Basic stats: COMPLETE Column stats: NONE\n            Execution mode: vectorized\n        Reducer 2\n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 ds (type: string)\n                  1 key (type: string)\n                outputColumnNames: _col0, _col2\n                Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE\n                Select Operator\n                  expressions: _col2 (type: string), _col0 (type: string)\n                  outputColumnNames: _col0, _col1\n                  Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE\n                  Reduce Output Operator\n                    key expressions: _col1 (type: string)\n                    sort order: +\n                    Map-reduce partition columns: _col1 (type: string)\n                    Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE\n                    value expressions: _col0 (type: string)\n        Reducer 3\n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 _col1 (type: string)\n                  1 _col1 (type: string)\n                outputColumnNames: _col0, _col1, _col2, _col3\n                Statistics: Num rows: 2420 Data size: 25709 Basic stats: COMPLETE Column stats: NONE\n                File Output Operator\n                  compressed: false\n                  Statistics: Num rows: 2420 Data size: 25709 Basic stats: COMPLETE Column stats: NONE\n                  table:\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n        Reducer 6\n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 ds (type: string)\n                  1 key (type: string)\n                outputColumnNames: _col0, _col2\n                Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE\n                Select Operator\n                  expressions: _col2 (type: string), _col0 (type: string)\n                  outputColumnNames: _col0, _col1\n                  Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE\n                  Reduce Output Operator\n                    key expressions: _col1 (type: string)\n                    sort order: +\n                    Map-reduce partition columns: _col1 (type: string)\n                    Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE\n                    value expressions: _col0 (type: string)\n{noformat}\nMap1 and Map5 are equivalent and Map5 is removed. Therefore the whole Map9 should be removed. But I think your patch won't work because Map9 doesn't have branches.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-28T03:10:02.212+0000","updated":"2017-07-28T03:10:02.212+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16104380","id":"16104380","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Thinking more about this, I find a bug in combing equivalent works. If 2 map works contain same operators, but will be pruned by different DPP sinks, then they can't be combined. E.g., let's slightly change the above example into:\n{code}\nexplain select * from (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.key) a join (select srcpart.ds,srcpart.key from srcpart join src on srcpart.ds=src.value) b on a.key=b.key;\n{code}\nThe two map works for {{srcpart}} still get combined. However, they need to be pruned by different values: {{src.key}} and {{src.value}} respectively. In the current implementation we'll probably have incorrect results.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-28T03:18:32.268+0000","updated":"2017-07-28T03:18:32.268+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16104637","id":"16104637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]:  thanks for your catch, it needs to remove the whole map work if there is no branch in map work contain spark pruning sink operator.  update HIVE-16948.2.patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-28T08:24:28.656+0000","updated":"2017-07-28T08:24:28.656+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16104700","id":"16104700","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"{quote}\n\nThinking more about this, I find a bug in combing equivalent works. If 2 map works contain same operators, but will be pruned by different DPP sinks, then they can't be combined. E.g.,\n{quote}\n\nCombineEquivalentWorkResolver.EquivalentWorkMatcher#compareCurrentOperator only compare the self property of operator. Will not compare the relationship with other operators. Suggest to have a configuration to enable/disable combine equivalent work so that if users disable combine equivalent to cross above issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-28T09:13:27.118+0000","updated":"2017-07-28T09:13:27.118+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16105873","id":"16105873","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12879315/HIVE-16948.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 11013 tests executed\n*Failed tests:*\n{noformat}\nTestPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=240)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=240)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=168)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=100)\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreStatsMerge.testStatsMerge (batchId=206)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=179)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=179)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=179)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6176/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6176/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6176/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 9 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12879315 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-07-28T23:56:15.061+0000","updated":"2017-07-28T23:56:15.061+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16118025","id":"16118025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"changes:\n1.\tremove the empty sparkWork and sparkTask\n2.\tadd test in TestSparkTask to test removeEmptySparkTask. Directly copy part code of CombineEquivalentWorkResolver.EquivalentWorkMatcher#removeEmptySparkTask to TestSparkTask to test. It is better to mock some situation to test EquivalentWorkMatcher#removeEmptySparkTask even this situation is rarely occurred. If this is unnecessary, i can remove them.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-08T08:19:12.260+0000","updated":"2017-08-08T08:19:12.260+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16118112","id":"16118112","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12880794/HIVE-16948.5.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6294/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6294/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6294/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-08-08 09:46:15.376\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6294/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-08-08 09:46:15.379\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 6b03a9c HIVE-17247: HoS DPP: UDFs on the partition column side does not evaluate correctly (Sahil Takiar, reviewed by Rui Li)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 6b03a9c HIVE-17247: HoS DPP: UDFs on the partition column side does not evaluate correctly (Sahil Takiar, reviewed by Rui Li)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-08-08 09:46:21.472\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/exec/OperatorUtils.java: No such file or directory\nerror: a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java: No such file or directory\nerror: a/ql/src/test/org/apache/hadoop/hive/ql/exec/spark/TestSparkTask.java: No such file or directory\nerror: a/ql/src/test/results/clientpositive/spark/spark_dynamic_partition_pruning.q.out: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12880794 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-08-08T09:46:22.099+0000","updated":"2017-08-08T09:46:22.099+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16125366","id":"16125366","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: attached is HIVE-16948.6.patch. Update code with latest master.  Can you spend some time to review, thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-14T08:29:37.102+0000","updated":"2017-08-14T08:29:37.102+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16125474","id":"16125474","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12881698/HIVE-16948.6.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 11005 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=240)\norg.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_merge_move] (batchId=243)\norg.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_merge_only] (batchId=243)\norg.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_move_only] (batchId=243)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_mapjoin_only] (batchId=170)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)\norg.apache.hive.jdbc.TestJdbcWithMiniHS2.testJoinThriftSerializeInTasks (batchId=228)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6381/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6381/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6381/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 13 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12881698 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-08-14T09:47:42.814+0000","updated":"2017-08-14T09:47:42.814+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16129993","id":"16129993","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~lirui]: Can you spend some time to review HIVE-16948.6.patch, thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-17T06:19:08.407+0000","updated":"2017-08-17T06:19:08.407+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16130024","id":"16130024","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~kellyzly], sorry about the delay. I've left some comments on RB.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-17T06:56:36.631+0000","updated":"2017-08-17T06:56:36.631+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16130420","id":"16130420","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pvary","name":"pvary","key":"pvary","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Peter Vary","active":true,"timeZone":"Europe/Budapest"},"body":"I do not find my comment on the review board, so I leave a comment here too:\nI think {{spark_dynamic_partition_pruning.q.out}} changes are caused by HIVE-17148 - \"Incorrect result for Hive join query with COALESCE in WHERE condition\". Created HIVE-17346 to track the progress there","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pvary","name":"pvary","key":"pvary","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Peter Vary","active":true,"timeZone":"Europe/Budapest"},"created":"2017-08-17T13:53:58.311+0000","updated":"2017-08-17T13:53:58.311+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16131675","id":"16131675","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~pvary]: I saw your comment on review board.  Thanks for your tracking HIVE-17346.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-18T03:50:20.024+0000","updated":"2017-08-18T03:50:20.024+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16131822","id":"16131822","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12882506/HIVE-16948.7.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10977 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6451/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6451/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6451/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 6 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12882506 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-08-18T07:00:31.324+0000","updated":"2017-08-18T07:00:31.324+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16131834","id":"16131834","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"+1. Thanks for the update [~kellyzly]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-18T07:14:03.383+0000","updated":"2017-08-18T07:14:03.383+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16131842","id":"16131842","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"thanks for your review, [~lirui],[~stakiar],[~pvary]!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-18T07:19:49.792+0000","updated":"2017-08-18T07:19:49.792+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16131848","id":"16131848","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Pushed to master. Thanks [~kellyzly] for the work.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lirui","name":"lirui","key":"lirui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rui Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-18T07:26:53.096+0000","updated":"2017-08-18T07:26:53.096+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13081984/comment/16486165","id":"16486165","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"body":"Hive 3.0.0 has been released so closing this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-22T23:59:24.887+0000","updated":"2018-05-22T23:59:24.887+0000"}],"maxResults":31,"total":31,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-16948/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3gn4v:"}}