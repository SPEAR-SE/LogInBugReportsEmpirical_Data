{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12687099","self":"https://issues.apache.org/jira/rest/api/2/issue/12687099","key":"HIVE-6131","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-01-06T18:54:28.916+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Aug 24 02:13:10 UTC 2017","customfield_12310420":"366094","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6131/watchers","watchCount":14,"isWatching":false},"created":"2014-01-03T01:10:56.826+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323587","id":"12323587","description":"Hive 0.11.0","name":"0.11.0","archived":false,"released":true,"releaseDate":"2013-05-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12324986","id":"12324986","description":"released","name":"0.13.0","archived":false,"released":true,"releaseDate":"2014-04-21"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"}],"issuelinks":[{"id":"12512735","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12512735","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13055513","key":"IMPALA-4894","self":"https://issues.apache.org/jira/rest/api/2/issue/13055513","fields":{"summary":"Impala changes table schema when you do ALTER TABLE .. ADD COLUMNS but not partition schema resulting in false NULL values in Hive.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12386697","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12386697","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12706464","key":"HIVE-6835","self":"https://issues.apache.org/jira/rest/api/2/issue/12706464","fields":{"summary":"Reading of partitioned Avro data fails if partition schema does not match table schema","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-08-24T02:13:10.689+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"Hi folks,\n\nI found and verified a bug on our CDH 4.0.3 install of Hive when adding columns to tables with Partitions using 'REPLACE COLUMNS'.  I dug through the Jira a little bit and didn't see anything for it so hopefully this isn't just noise on the radar.\n\nBasically, when you alter a table with partitions and then reupload data to that partition, it doesn't seem to recognize the extra data that actually exists in HDFS- as in, returns NULL values on the new column despite having the data and recognizing the new column in the metadata.\n\nHere's some steps to reproduce using a basic table:\n\n1.  Run this hive command:  CREATE TABLE jvaughan_test (col1 string) partitioned by (day string);\n2.  Create a simple file on the system with a couple of entries, something like \"hi\" and \"hi2\" separated by newlines.\n3.  Run this hive command, pointing it at the file:  LOAD DATA LOCAL INPATH '<FILEDIR>' OVERWRITE INTO TABLE jvaughan_test PARTITION (day = '2014-01-02');\n4.  Confirm the data with:  SELECT * FROM jvaughan_test WHERE day = '2014-01-02';\n5.  Alter the column definitions:  ALTER TABLE jvaughan_test REPLACE COLUMNS (col1 string, col2 string);\n6.  Edit your file and add a second column using the default separator (ctrl+v, then ctrl+a in Vim) and add two more entries, such as \"hi3\" on the first row and \"hi4\" on the second\n7.  Run step 3 again\n8.  Check the data again like in step 4\n\nFor me, this is the results that get returned:\n\nhive> select * from jvaughan_test where day = '2014-01-01';\nOK\nhi\tNULL\t2014-01-02\nhi2\tNULL\t2014-01-02\n\nThis is despite the fact that there is data in the file stored by the partition in HDFS.\n\nLet me know if you need any other information.  The only workaround for me currently is to drop partitions for any I'm replacing data in and THEN reupload the new data file.\n\n\nThanks,\n\n-James\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12637927","id":"12637927","filename":"HIVE-6131.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-31T21:44:17.372+0000","size":7746,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12637927/HIVE-6131.1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"366405","customfield_12312823":null,"summary":"New columns after table alter result in null values despite data","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jvaughan","name":"jvaughan","key":"jvaughan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"James Vaughan","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jvaughan","name":"jvaughan","key":"jvaughan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"James Vaughan","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13863231","id":"13863231","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you please clarify in your step #6 whether you're editing local file or HDFS file? If you're editing your local file, then you will need to load the data again as you do in step #3, or manually replace the file on HDFS with your local edited file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xuefuz","name":"xuefuz","key":"xuefuz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xuefu Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-06T18:54:28.916+0000","updated":"2014-01-06T18:54:28.916+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13863242","id":"13863242","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jvaughan","name":"jvaughan","key":"jvaughan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"James Vaughan","active":true,"timeZone":"Etc/UTC"},"body":"Editing the local file.  Step 7 is supposed to handle re-uploading the file using an OVERWRITE command like you say.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jvaughan","name":"jvaughan","key":"jvaughan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"James Vaughan","active":true,"timeZone":"Etc/UTC"},"created":"2014-01-06T18:59:59.060+0000","updated":"2014-01-06T18:59:59.060+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13920691","id":"13920691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yangguo1220","name":"yangguo1220","key":"yangguo1220","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ning Zhang","active":true,"timeZone":"Etc/UTC"},"body":"Verified this issue with Apache Hive 0.10, 0.11, 0.12\n\nThe conclusion is: Hive 0.11 and 0.12 have this issue, while Hive 0.10 doesn't. That is to say, starting from Hive 0.11, the issue was introduced.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yangguo1220","name":"yangguo1220","key":"yangguo1220","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ning Zhang","active":true,"timeZone":"Etc/UTC"},"created":"2014-03-05T09:27:07.969+0000","updated":"2014-03-05T09:27:07.969+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13941289","id":"13941289","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"Browsing the code, it seems like this was introduced by fix for HIVE-3833 in Hive 0.11. In that patch, the partition schema is used to read results, instead of the table schema as it was before. Since partition schema is a snapshot of table schema at the time of partition creation, it doesn't contain all the new columns added later. So, the result is read using stale schema and thus do not contain new column values, even though they are present in underlying data.\n\nClearly the intent of the 3833 patch is to use partition specific metadata, to allow for multiple serdes for partitions of a table (as i understand it). This issue seems to be a regression introduced by that patch.\n\nOne possible fix is to use partition metadata, except update column list from table metadata. It is quite possible that while this will work, this may not be the 'right' fix. [~namitjain]] [~ashutoshc], any thoughts on this?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-20T01:31:21.662+0000","updated":"2014-03-20T01:31:21.662+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13941305","id":"13941305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"[~pala] Your suggested fix makes sense.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-20T01:59:56.832+0000","updated":"2014-03-20T01:59:56.832+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13942410","id":"13942410","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"Ok, i'll work on the patch.\n\n[~ashutoshc], my fix assumes all serdes can work with latest table schema, even though partition data is in older schema. Is that valid? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-20T22:20:00.086+0000","updated":"2014-03-20T22:20:00.086+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13942429","id":"13942429","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Currently, hive only allows to add new columns in newer partition via alter table add column, so Hive should insert nulls for new columns which are absent in old partitions. Serdes should honor this. \nOn the other hand, if user is doing alter table replace columns than all bets are off and they should know what they are doing, Hive doesnt handle those scenarios and as far as I see it, its very hard to support that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-20T22:31:10.339+0000","updated":"2014-03-20T22:31:10.339+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13943226","id":"13943226","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"We saw this issue earlier while working with schema evolution for parquet and other serde, but had thought it was expected behavior (that different partition keep old column schema after HIVE-3833).  This will be a good fix to have.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-03-21T16:49:30.014+0000","updated":"2014-03-21T16:49:30.014+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13945585","id":"13945585","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"HIVE-6131: Honor latest table schema for partition data\n\n    Ensure partition schema object for data read always picks\n    up the schema from table metadata. Otherwise, it gets the\n    metadata snapshot during partition creation which may now\n    be stale.\n\n    Added .q tests for verification.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-24T19:31:57.366+0000","updated":"2014-03-24T19:31:57.366+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13945589","id":"13945589","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"The above was intended to be code review description. [~ashutoshc], can you please review or have the right owner look at this change? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-24T19:34:19.299+0000","updated":"2014-03-24T19:34:19.299+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13945626","id":"13945626","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"Honor latest table schema for partition data\n\nEnsure partition schema object for data read always picks\nup the schema from table metadata. Otherwise, it gets the\nmetadata snapshot during partition creation which may now\nbe stale.\nAdded .q tests for verification.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-24T20:05:15.793+0000","updated":"2014-03-24T20:05:15.793+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13945746","id":"13945746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"Hi , I'm wondering if its possible to instead set the correct column metadata on the partition during 'alter table'? \n\nThis patch changes hive to use table instead of partition metadata on initializing the de-serializer for partition.  While it works to return correct query result, the partition metadata (for example if you do 'describe partition' after 'alter table add columns') still shows the old columns before the alter, which is now inconsistent with the results returned.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-03-24T21:50:01.915+0000","updated":"2014-03-24T21:50:01.915+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13945773","id":"13945773","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"That thought did cross my mind. However, I wasn't sure if there are other dependencies that actually need the table schema snapshot during partition creation (which is stored as partition level schema). \n\nA related question is why store partition specific column schema if it is always identical to current table column schema? Then partition metadata should not include column schema at all and always pick it up from table metadata. \n\nI guess i am unsure about semantics of partition schema. Does it represent current table schema, and if so, why we keep a copy separate from table schema. If not, then it represents schema during partition creation, so it is possible that it is out of date, leading to the inconsistency you describe.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-24T22:13:13.937+0000","updated":"2014-03-24T22:13:13.937+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13945824","id":"13945824","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"bq. That thought did cross my mind. However, I wasn't sure if there are other dependencies that actually need the table schema snapshot during partition creation (which is stored as partition level schema).\n\nYou mean a use-case to keep partition.sd() as the original table.sd()?  Doesnt seem likely, but I could be wrong.\n\nbq. A related question is why store partition specific column schema if it is always identical to current table column schema?  Does it represent current table schema, and if so, why we keep a copy separate from table schema. If not, then it represents schema during partition creation, so it is possible that it is out of date, leading to the inconsistency you describe.\n\nYea I wonder that as well, thats why I had originally assumed it was by design that partition columns can be different than table column.  Otherwise why waste all the metastore's memory/storage and store it in different places?   But again I dont have the full context, does [~ashutoshc] or others have some background, if theres a use-case of what Pala described?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-03-24T22:59:08.026+0000","updated":"2014-03-24T22:59:08.026+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955570","id":"13955570","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"[~ashutoshc], any thoughts on this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-31T19:33:10.891+0000","updated":"2014-03-31T19:33:10.891+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955685","id":"13955685","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"There are lots of test cases in Hive covering these scenarios. It will be good to get this patch tested on those and see where we stand. You can follow https://cwiki.apache.org/confluence/display/Hive/Hive+PreCommit+Patch+Testing to get Hive QA to kick a CI build.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-31T20:41:46.757+0000","updated":"2014-03-31T20:41:46.757+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955727","id":"13955727","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks, will do [~ashutoshc]. However, i need a login with apache jenkins. Could you or somebody else add a login for me?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-31T21:13:23.292+0000","updated":"2014-03-31T21:13:23.292+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955734","id":"13955734","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"Hi Pala, you can just re-upload the same patch again.  Jenkins job will pick it up automatically.  I think the first patch you uploaded got missed by the jenkins job during an outage.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-03-31T21:21:57.337+0000","updated":"2014-03-31T21:21:57.337+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955735","id":"13955735","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"Sorry I assigned to myself accidentally while commenting, please assign back to yourself.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-03-31T21:23:42.516+0000","updated":"2014-03-31T21:23:42.516+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955767","id":"13955767","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"[~szehon], i have reuploaded the patch with expected name. I still don't see a job in progress for jenkins Hive precommit build. Let me know if something else is needed. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-03-31T21:50:33.433+0000","updated":"2014-03-31T21:50:33.433+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955772","id":"13955772","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"It should be there, are you looking at [http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/|http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/]?   I think its either build 2054-2056 depending on when it was uploaded.  Let's wait for those and see.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-03-31T21:56:12.258+0000","updated":"2014-03-31T21:56:12.258+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13955954","id":"13955954","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12637927/HIVE-6131.1.patch\n\n{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 5514 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat11\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat13\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat14\norg.apache.hadoop.hive.metastore.TestRetryingHMSHandler.testRetryingHMSHandler\n{noformat}\n\nTest results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/2054/testReport\nConsole output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/2054/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 5 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12637927","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2014-04-01T00:46:21.271+0000","updated":"2014-04-01T00:46:21.271+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13963641","id":"13963641","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"I looked into the failures above and revisited HIVE-3833 with more context now:\n1. LazyBinaryColumnarSerde requires partition level metadata to read existing data, it needs exact metadata used when serializing the data. So cannot use table level metadata which could have changed.\n2. Other serdes/format, which support schema change, needs updated schema to support newly appended data with new columns.\n\nSo, it seems we should pass the table metadata or partition metadata selectively, depending on what the storage/serde supports. Is there a way to identify the serdes/format that do not support newer schema, programmatically? I don't see anything obvious. Alternative is to\na.  Add such metadata to serde info and populate that for all serdes. This may have been discussed briefly in HIVE-3833, and looks like this will be a large change because it essentially modifies interface for a plugin.\nb.  Hardcode a white or blacklist of serdes and pass table/partition level metadata accordingly.\n\n[~ashutoshc], [~szehon], any thoughts on the above, particularly are there other alternatives?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-09T00:01:50.840+0000","updated":"2014-04-09T00:01:50.840+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13963728","id":"13963728","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"Hm I understand file-format may differ between partition and table, that was the point of HIVE-3833.   But just for my understanding, did you find any use for the partition-columns being different from table-columns (being the original)? \n\nIn my experience, I had seen that LazyBinaryColumnarSerde (and other serde) can use a schema with more columns to de-serialize data than what the data was written with.  If thats the case, cant we make the column set same for partition and table, during 'alter table'?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-04-09T02:46:43.792+0000","updated":"2014-04-09T02:46:43.792+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13964556","id":"13964556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, one case where partition column is different than table column is the type of an existing column is changed (e.g: from string to int) at the table level, after a partition is created. So column1 is string on partition, but int on table.\n\nThat is the cause of failure for the unit test 'org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat11' you see above.\n\nSo we can't alter the partition schema to match table schema, because underlying data in LazyBinaryColumnarSerde was written to adhere to old schema. If you just change the schema, but not the data, the data will be read incorrectly.\n\nYes serdes can handle additional columns by treating them as null valued. However, we are trying to address a more complex case: e.g: Table and partition has 3 columns. We add one more column at table level. Then at the partition, we append (not overwrite) data with 4th column too. Now the partition has some data with 3 columns, but some data with 4 columns. LazySimpleSerde can work in this scenario, but LazyBinaryColumnarSerde doesn't.  ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-09T19:09:02.694+0000","updated":"2014-04-09T19:09:02.694+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13964571","id":"13964571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"Makes sense.  I had fixed LazyBinaryColumnarSerde to handle one of those case in HIVE-5788 (add column), but it did not fix handling change column-type as you observed.  Maybe we can try fixing that, but I guess its not easily supported by all the serdes.\n\nAn alternate thought I had is to introduce an 'alter partition' statement, to allow the user specify what schema to use on read.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-04-09T19:26:18.869+0000","updated":"2014-04-09T19:26:18.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13966111","id":"13966111","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"Do you mean allowing schema update statements also at partition level? Probably a more specific 'sync partition schema to table schema' command would be better, but even that i think is not natural.\n\nI think best approach is to change implementation - use table schema whenever a serde can support latest schema correctly, otherwise use partition schema.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-11T01:20:24.606+0000","updated":"2014-04-11T01:20:24.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13966352","id":"13966352","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"Yea thats what I meant, 'alter table partition (spec) add column', etc, I wonder why its not natural?  Imo it would gives more flexibility to user.\n\nMy concern with your approach is it locking user to have only one choice per Serde.  For example take Rcfile's serdes, which would you pick?  If it is 'table-schema' , then you hit the partition..11.q issue (error after column-type change).  If it is 'partition-schema', then you hit the JIRA's issue (add column, new data loaded in that column is null) because partition schema is never updated.  There might be users interested in both cases (we ourselves are interested to get the latter use case for RCFile).\n\n\n\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-04-11T09:10:28.417+0000","updated":"2014-04-11T09:10:28.417+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13967001","id":"13967001","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"body":"You are right, types of existing columns may change so partition schema may never be same as table schema, so cannot pick one or the other. \n\nLet's say we support add columns DDL at partition level. What can be allowed? Can users add arbitrarily different columns compared to table, or should they only add columns that are present in table level, but are missing at partition level, in the same order? \n\ne.g: Initial schema: Table t (A, B, C, D), Partition p (A', B'). Can users only execute 'Alter table t partition (p) add columns C,D'? Or can they do something else also 'alter table t partition (p) add columns E, F, G'? \n\nIf it is only the former, then we still can do the same programmatically, by 'merging' the partition and table schema at runtime. However, if the table schema itself can be wildly different compared to partition schema, then yes, DDL is the only option, and users have to manage it themselves.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pala","name":"pala","key":"pala","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pala M Muthaia","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-11T19:23:18.822+0000","updated":"2014-04-11T19:23:18.822+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/13974492","id":"13974492","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"body":"There is a related proposal over at HIVE-6835 to pass both to the serde and let them choose.\n\nHowever, it doesnt seem to solve the issue about RCFile serde.   I agree its a mess, unfortunately the case like change column type for RCFile makes it possible for partition + table schemas to go out of sync with more than just #cols, and hard to do the 'merge' as you proposed.  I think it would be nice not to support it going out of sync this way, not sure if its possible to change at this point.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szehon","name":"szehon","key":"szehon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Szehon Ho","active":true,"timeZone":"Europe/Paris"},"created":"2014-04-18T21:17:42.297+0000","updated":"2014-04-18T21:17:42.297+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/14300839","id":"14300839","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jasonliao","name":"jasonliao","key":"jasonliao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liao, Xiaoge","active":true,"timeZone":"Etc/UTC"},"body":"how did this bug fix?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jasonliao","name":"jasonliao","key":"jasonliao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Liao, Xiaoge","active":true,"timeZone":"Etc/UTC"},"created":"2015-02-02T02:57:07.746+0000","updated":"2015-02-02T02:57:07.746+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/14952829","id":"14952829","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Huang+Xiaomeng","name":"Huang Xiaomeng","key":"huang xiaomeng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaomeng Huang","active":true,"timeZone":"Etc/UTC"},"body":"I met this bug too. And this patch really can solve my problem.\nCould anyone have a look at this patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Huang+Xiaomeng","name":"Huang Xiaomeng","key":"huang xiaomeng","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaomeng Huang","active":true,"timeZone":"Etc/UTC"},"created":"2015-10-12T09:03:23.912+0000","updated":"2015-10-12T09:03:23.912+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/15285949","id":"15285949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=niklaus.xiao","name":"niklaus.xiao","key":"niklaus.xiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"Niklaus Xiao","active":true,"timeZone":"Asia/Shanghai"},"body":"This is not a bug, you can use `alter table t1 replace columns (c1 string, c2 string) cascade`, see https://issues.apache.org/jira/browse/HIVE-8839\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=niklaus.xiao","name":"niklaus.xiao","key":"niklaus.xiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"Niklaus Xiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-17T03:24:50.832+0000","updated":"2016-05-17T03:24:50.832+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/15289556","id":"15289556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12637927/HIVE-6131.1.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 69 failed/errored test(s), 9899 tests executed\n*Failed tests:*\n{noformat}\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniLlapCliDriver - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-auto_sortmerge_join_7.q-orc_merge9.q-tez_union_dynamic_partition.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-join1.q-mapjoin_decimal.q-union5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-load_dyn_part2.q-selectDistinctStar.q-vector_decimal_5.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-mapjoin_mapjoin.q-insert_into1.q-vector_decimal_2.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_distinct_2.q-tez_joins_explain.q-cte_mat_1.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vector_interval_2.q-schema_evol_text_nonvec_mapwork_part_all_primitive.q-tez_fsstat.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-vectorized_parquet.q-insert_values_non_partitioned.q-schema_evol_orc_nonvec_mapwork_part.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-join4.q-groupby_cube1.q-auto_join20.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-parallel_join1.q-escape_distributeby1.q-auto_sortmerge_join_7.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_partition_change_col\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_table_cascade\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_data_after_schema_update\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat11\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat13\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat14\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_nonvec_mapwork_part\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_nonvec_mapwork_part_all_complex\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_nonvec_mapwork_part_all_primitive\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_vec_mapwork_part\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_vec_mapwork_part_all_complex\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_vec_mapwork_part_all_primitive\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_vecrow_mapwork_part\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_vecrow_mapwork_part_all_complex\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_schema_evol_text_vecrow_mapwork_part_all_primitive\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_partition_diff_num_cols\norg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_nonvec_mapwork_part\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_nonvec_mapwork_part_all_complex\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_vec_mapwork_part\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_vec_mapwork_part_all_complex\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_vec_mapwork_part_all_primitive\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_vecrow_mapwork_part\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_vecrow_mapwork_part_all_complex\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_text_vecrow_mapwork_part_all_primitive\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_partition_diff_num_cols\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_many\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join18\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_reordering_values\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_simple_select\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cbo_udf_udaf\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_dynamic_rdd_cache\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_identity_project_remove_skip\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_merge_multi_expressions\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_in\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_5\norg.apache.hadoop.hive.llap.tez.TestConverters.testFragmentSpecToTaskSpec\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreGetMetaConf.org.apache.hadoop.hive.metastore.TestHiveMetaStoreGetMetaConf\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreStatsMerge.testStatsMerge\norg.apache.hadoop.hive.metastore.TestMetaStoreInitListener.testMetaStoreInitListener\norg.apache.hadoop.hive.metastore.TestMetaStoreMetrics.org.apache.hadoop.hive.metastore.TestMetaStoreMetrics\norg.apache.hadoop.hive.metastore.TestRemoteUGIHiveMetaStoreIpAddress.testIpAddress\norg.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testRevokeTimedOutWorkers\norg.apache.hadoop.hive.ql.security.TestExtendedAcls.org.apache.hadoop.hive.ql.security.TestExtendedAcls\norg.apache.hadoop.hive.ql.security.TestFolderPermissions.org.apache.hadoop.hive.ql.security.TestFolderPermissions\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.org.apache.hive.hcatalog.api.repl.commands.TestCommands\norg.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc.org.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc\norg.apache.hive.minikdc.TestJdbcWithDBTokenStore.org.apache.hive.minikdc.TestJdbcWithDBTokenStore\norg.apache.hive.service.cli.session.TestHiveSessionImpl.testLeakOperationHandle\norg.apache.hive.spark.client.TestSparkClient.testSyncRpc\n{noformat}\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/315/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/315/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-315/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 69 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12637927 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-18T18:41:09.518+0000","updated":"2016-05-18T18:41:09.518+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/15731797","id":"15731797","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tianwan.zhao","name":"tianwan.zhao","key":"tianwan.zhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tianwan Zhao","active":true,"timeZone":"Etc/UTC"},"body":"Hive provides new DDL to handle such situation in later versions after HIVE-3833 is applied in 0.11.0.\nSee: [Language Manual CASCADE|https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Add/ReplaceColumns]\n\n??The CASCADE|RESTRICT clause is available in Hive 0.15.0. ALTER TABLE ADD|REPLACE COLUMNS with CASCADE command changes the columns of a table's metadata, and cascades the same change to all the partition metadata. RESTRICT is the default, limiting column changes only to table metadata.??\n\nIn this case you can change your step 5 to\n5. Alter the column definitions: ALTER TABLE jvaughan_test REPLACE COLUMNS (col1 string, col2 string) *CASCADE*;","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tianwan.zhao","name":"tianwan.zhao","key":"tianwan.zhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tianwan Zhao","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-08T10:34:19.984+0000","updated":"2016-12-08T10:34:19.984+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/15732234","id":"15732234","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12637927/HIVE-6131.1.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 24 failed/errored test(s), 10723 tests executed\n*Failed tests:*\n{noformat}\nTestMiniLlapLocalCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=143)\n\t[vectorized_rcfile_columnar.q,vector_elt.q,explainuser_1.q,multi_insert.q,tez_dml.q,vector_bround.q,schema_evol_orc_acid_table.q,vector_when_case_null.q,orc_ppd_schema_evol_1b.q,vector_join30.q,vectorization_11.q,cte_3.q,update_tmp_table.q,vector_decimal_cast.q,groupby_grouping_id2.q,vector_decimal_round.q,tez_smb_empty.q,orc_merge6.q,vector_decimal_trailing.q,cte_5.q,tez_union.q,cbo_rp_subq_not_in.q,vector_decimal_2.q,columnStatsUpdateForStatsOptimizer_1.q,vector_outer_join3.q,schema_evol_text_vec_part_all_complex.q,tez_dynpart_hashjoin_2.q,auto_sortmerge_join_12.q,offset_limit.q,tez_union_multiinsert.q]\nTestMiniLlapLocalCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=148)\n\t[auto_sortmerge_join_13.q,union_top_level.q,vector_left_outer_join2.q,schema_evol_text_vecrow_part_all_primitive.q,constprog_semijoin.q,update_where_partitioned.q,drop_partition_with_stats.q,smb_mapjoin_14.q,skiphf_aggr.q,vectorized_ptf.q,auto_join_filters.q,join0.q,insert_orig_table.q,mergejoin.q,join_filters.q,orc_split_elimination.q,subquery_in.q,vector_outer_join0.q,schema_evol_text_vec_part_all_primitive.q,vector_complex_all.q,auto_sortmerge_join_4.q,bucket_many.q,vectorization_15.q,union3.q,vectorization_nested_udf.q,windowing_windowspec2.q,auto_smb_mapjoin_14.q,vector_mr_diff_schema_alias.q,vector_join_filters.q,reduce_deduplicate_extended.q]\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_partition_change_col] (batchId=23)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_table_cascade] (batchId=79)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_data_after_schema_update] (batchId=17)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat11] (batchId=6)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat12] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat13] (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat14] (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample2] (batchId=5)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample4] (batchId=15)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample6] (batchId=61)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample7] (batchId=60)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample9] (batchId=38)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=134)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=134)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_complex] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_primitive] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_complex] (batchId=151)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[stats_based_fetch_decision] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=92)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/2487/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/2487/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2487/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 24 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12637927 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-12-08T13:37:56.259+0000","updated":"2016-12-08T13:37:56.259+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12687099/comment/16139468","id":"16139468","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12637927/HIVE-6131.1.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 20 failed/errored test(s), 11000 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_partition_change_col] (batchId=24)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_table_cascade] (batchId=84)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_data_after_schema_update] (batchId=17)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat11] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat12] (batchId=79)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat13] (batchId=61)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat14] (batchId=73)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_complex] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_primitive] (batchId=156)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_complex] (batchId=153)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_primitive] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_complex] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_primitive] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6504/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6504/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6504/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 20 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12637927 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-08-24T02:13:10.689+0000","updated":"2017-08-24T02:13:10.689+0000"}],"maxResults":37,"total":37,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-6131/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1r3sv:"}}