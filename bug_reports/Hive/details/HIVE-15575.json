{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13033553","self":"https://issues.apache.org/jira/rest/api/2/issue/13033553","key":"HIVE-15575","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-01-11T13:36:06.563+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jan 11 13:36:06 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15575/watchers","watchCount":6,"isWatching":false},"created":"2017-01-10T23:43:45.063+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-01-11T13:36:06.563+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"Hive {{UNION ALL}} produces data in sub-directories under the table/partition directories. E.g.\n\n{noformat}\nhive (mythdb_hadooppf_17544)> create table source ( foo string, bar string, goo string ) stored as textfile;\nOK\nTime taken: 0.322 seconds\nhive (mythdb_hadooppf_17544)> create table results_partitioned( foo string, bar string, goo string ) partitioned by ( dt string ) stored as orcfile;\nOK\nTime taken: 0.322 seconds\nhive (mythdb_hadooppf_17544)> set hive.merge.tezfiles=false; insert overwrite table results_partitioned partition( dt ) select 'goo', 'bar', 'foo', '1' from source UNION ALL select 'go', 'far', 'moo', '1' from source;\n...\nLoading data to table mythdb_hadooppf_17544.results_partitioned partition (dt=null)\n         Time taken for load dynamic partitions : 311\n        Loading partition {dt=1}\n         Time taken for adding to write entity : 3\nOK\nTime taken: 27.659 seconds\nhive (mythdb_hadooppf_17544)> dfs -ls -R /tmp/mythdb_hadooppf_17544/results_partitioned;\ndrwxrwxrwt   - dfsload hdfs          0 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1\ndrwxrwxrwt   - dfsload hdfs          0 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/1\n-rwxrwxrwt   3 dfsload hdfs        349 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/1/000000_0\ndrwxrwxrwt   - dfsload hdfs          0 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/2\n-rwxrwxrwt   3 dfsload hdfs        368 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/2/000000_0\n{noformat}\n\nThese results can only be read if {{mapred.input.dir.recursive=true}}, as {{TezCompiler::init()}} seems to do. But the Hadoop default for this is {{false}}. This leads to the following errors:\n1. Running {{CONCATENATE}} on the partition on the partition causes data-loss.\n{noformat}\nhive --database mythdb_hadooppf_17544 -e \" set mapred.input.dir.recursive; alter table results_partitioned partition ( dt='1' ) concatenate ; set mapred.input.dir.recursive; \"\n...\nOK\nTime taken: 2.151 seconds\nmapred.input.dir.recursive=false\n\n\nStatus: Running (Executing on YARN cluster with App id application_1481756273279_5088754)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nFile Merge         SUCCEEDED      0          0        0        0       0       0\n--------------------------------------------------------------------------------\nVERTICES: 01/01  [>>--------------------------] 0%    ELAPSED TIME: 0.35 s\n--------------------------------------------------------------------------------\nLoading data to table mythdb_hadooppf_17544.results_partitioned partition (dt=1)\nMoved: 'hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/1' to trash at: hdfs://cluster-nn1.mygrid.myth.net:8020/user/dfsload/.Trash/Current\nMoved: 'hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/2' to trash at: hdfs://cluster-nn1.mygrid.myth.net:8020/user/dfsload/.Trash/Current\nOK\nTime taken: 25.873 seconds\n\n$ hdfs dfs -count -h /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1\n           1            0                  0 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1\n{noformat}\n\n2. hive.merge.tezfiles is busted, because the merge-task attempts to merge files across {{results_partitioned/dt=1/1}} and {{results_partitioned/dt=1/2}}:\n{noformat}\n$ hive --database mythdb_hadooppf_17544 -e \" set hive.merge.tezfiles=true; insert overwrite table results_partitioned partition( dt ) select 'goo', 'bar', 'foo', '1' from source UNION ALL select 'go', 'far', 'moo', '1' from source; \"\n...\nQuery ID = dfsload_20170110233558_51289333-d9da-4851-8671-bfe653d26e45\nTotal jobs = 3\nLaunching Job 1 out of 3\n\n\nStatus: Running (Executing on YARN cluster with App id application_1481756273279_5089989)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nMap 1 ..........   SUCCEEDED      1          1        0        0       0       0\nMap 3 ..........   SUCCEEDED      1          1        0        0       0       0\n--------------------------------------------------------------------------------\nVERTICES: 02/02  [==========================>>] 100%  ELAPSED TIME: 13.07 s\n--------------------------------------------------------------------------------\nStage-4 is filtered out by condition resolver.\nStage-3 is selected by condition resolver.\nStage-5 is filtered out by condition resolver.\nLaunching Job 3 out of 3\n\n\nStatus: Running (Executing on YARN cluster with App id application_1481756273279_5089989)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nFile Merge           RUNNING      1          0        1        0       2       0\n--------------------------------------------------------------------------------\nVERTICES: 00/01  [>>--------------------------] 0%    ELAPSED TIME: 3.06 s\n--------------------------------------------------------------------------------\n...\n{noformat}\n\nThe {{File Merge}} fails with the following:\n\n{noformat}\nTaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileTezProcessor.run(MergeFileTezProcessor.java:42)\n        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:362)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:192)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:184)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1738)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:184)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:180)\n        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.processRow(MergeFileRecordProcessor.java:217)\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.run(MergeFileRecordProcessor.java:151)\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n        ... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.processKeyValuePairs(OrcFileMergeOperator.java:159)\n        at org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.process(OrcFileMergeOperator.java:62)\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.processRow(MergeFileRecordProcessor.java:208)\n        ... 16 more\nCaused by: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.checkPartitionsMatch(AbstractFileMergeOperator.java:174)\n        at org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.fixTmpPath(AbstractFileMergeOperator.java:191)\n        at org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.processKeyValuePairs(OrcFileMergeOperator.java:86)\n        ... 18 more\n]], Vertex did not succeed due to OWN_TASK_FAILURE, failedTasks:1 killedTasks:0, Vertex vertex_1481756273279_5089989_2_00 [File Merge] killed/failed due to:OWN_TASK_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:0\n{noformat}\n\n3. Data produced with Hive {{UNION ALL}} will not be readable by Pig/HCatalog, without {{mapred.input.dir.recursive}}.\n\nSetting {{mapred.input.dir.recursive=true}} in {{hive-site.xml}} should resolve the first and third problem. But is this the recommendation? This is intrusive, and doesn't solve #2. The Pig {{UNION}} doesn't work this way, as per my limited understanding.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"ALTER TABLE CONCATENATE and hive.merge.tezfiles seems busted for UNION ALL output","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mithun","name":"mithun","key":"mithun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mithun&avatarId=18936","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mithun&avatarId=18936","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mithun&avatarId=18936","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mithun&avatarId=18936"},"displayName":"Mithun Radhakrishnan","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mithun","name":"mithun","key":"mithun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mithun&avatarId=18936","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mithun&avatarId=18936","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mithun&avatarId=18936","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mithun&avatarId=18936"},"displayName":"Mithun Radhakrishnan","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13033553/comment/15818351","id":"15818351","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohini","name":"rohini","key":"rohini","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohini Palaniswamy","active":true,"timeZone":"America/Los_Angeles"},"body":"The concept of VertexGroups was added in Tez specifically for the case of union to support writing to same directory from different vertices. Inclusion of vertex id and output id in the part file name avoids any file name conflicts causing overwrites. So sub-directories should not be required to implement union with Tez.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohini","name":"rohini","key":"rohini","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohini Palaniswamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-11T13:36:06.563+0000","updated":"2017-01-11T13:36:06.563+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-15575/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i38iz3:"}}