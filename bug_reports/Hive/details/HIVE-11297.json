{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12845984","self":"https://issues.apache.org/jira/rest/api/2/issue/12845984","key":"HIVE-11297","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-05-09T06:07:36.201+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 22 23:58:15 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_59128303581_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_2151412917","customfield_12312321":null,"resolutiondate":"2017-06-26T02:58:01.876+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11297/watchers","watchCount":6,"isWatching":false},"created":"2015-07-17T20:49:25.455+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"9.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"issuelinks":[{"id":"12431236","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12431236","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12762414","key":"HIVE-9152","self":"https://issues.apache.org/jira/rest/api/2/issue/12762414","fields":{"summary":"Dynamic Partition Pruning [Spark Branch]","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-22T23:58:15.739+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Currently, for dynamic partition pruning in Spark, if a small table generates partition info for more than one partition columns, multiple operator trees are created, which all start from the same table scan op, but have different spark partition pruning sinks.\n\nAs an optimization, we can combine these op trees and so don't have to do table scan multiple times.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12870495","id":"12870495","filename":"HIVE-11297.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-31T02:38:14.147+0000","size":29519,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12870495/HIVE-11297.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12871201","id":"12871201","filename":"HIVE-11297.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-05T08:35:54.699+0000","size":29200,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12871201/HIVE-11297.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12872813","id":"12872813","filename":"HIVE-11297.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-13T06:34:01.864+0000","size":64132,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12872813/HIVE-11297.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873086","id":"12873086","filename":"HIVE-11297.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-15T08:32:17.715+0000","size":69490,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873086/HIVE-11297.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873251","id":"12873251","filename":"HIVE-11297.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-16T08:59:08.793+0000","size":69294,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873251/HIVE-11297.5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873432","id":"12873432","filename":"HIVE-11297.6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-19T04:52:31.143+0000","size":66912,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873432/HIVE-11297.6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12873780","id":"12873780","filename":"HIVE-11297.7.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-21T02:12:01.174+0000","size":67717,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12873780/HIVE-11297.7.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874190","id":"12874190","filename":"HIVE-11297.8.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-23T03:59:34.090+0000","size":69283,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874190/HIVE-11297.8.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874174","id":"12874174","filename":"hive-site.xml","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-23T02:43:39.950+0000","size":4806,"mimeType":"text/xml","content":"https://issues.apache.org/jira/secure/attachment/12874174/hive-site.xml"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Combine op trees for partition info generating tasks","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16002113","id":"16002113","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"the explain plan of the multiple columns single source case in spark_dynamic_partition_pruning.q is \n{code}\n-- multiple columns single source\nEXPLAIN select count(*) from srcpart join srcpart_date_hour on (srcpart.ds = srcpart_date_hour.ds and srcpart.hr = srcpart_date_hour.hr) where srcpart_date_hour.`date` = '2008-04-08' and srcpart_date_hour.hour = 11;\n{code}\n\nthe explain plan is \n{code}\nSTAGE DEPENDENCIES:\n  Stage-2 is a root stage\n  Stage-1 depends on stages: Stage-2\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-2\n    Spark\n#### A masked pattern was here ####\n      Vertices:\n        Map 5 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date_hour\n                  filterExpr: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                  Statistics: Num rows: 4 Data size: 108 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string), hr (type: string)\n                      outputColumnNames: _col0, _col2\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col0 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          Spark Partition Pruning Sink Operator\n                            partition key expr: ds\n                            Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                            target column name: ds\n                            target work: Map 1\n        Map 6 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date_hour\n                  filterExpr: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                  Statistics: Num rows: 4 Data size: 108 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string), hr (type: string)\n                      outputColumnNames: _col0, _col2\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col2 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          Spark Partition Pruning Sink Operator\n                            partition key expr: hr\n                            Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                            target column name: hr\n                            target work: Map 1\n\n  Stage: Stage-1\n    Spark\n      Edges:\n        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)\n        Reducer 3 <- Reducer 2 (GROUP, 1)\n#### A masked pattern was here ####\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string), hr (type: string)\n                    outputColumnNames: _col0, _col1\n                    Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string)\n                      sort order: ++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string)\n                      Statistics: Num rows: 2000 Data size: 21248 Basic stats: COMPLETE Column stats: NONE\n        Map 4 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date_hour\n                  filterExpr: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                  Statistics: Num rows: 4 Data size: 108 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string), hr (type: string)\n                      outputColumnNames: _col0, _col2\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string), _col2 (type: string)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: string), _col2 (type: string)\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n        Reducer 2 \n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 _col0 (type: string), _col1 (type: string)\n                  1 _col0 (type: string), _col2 (type: string)\n                Statistics: Num rows: 2200 Data size: 23372 Basic stats: COMPLETE Column stats: NONE\n                Group By Operator\n                  aggregations: count()\n                  mode: hash\n                  outputColumnNames: _col0\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  Reduce Output Operator\n                    sort order: \n                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                    value expressions: _col0 (type: bigint)\n        Reducer 3 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: count(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                File Output Operator\n                  compressed: false\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  table:\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: -1\n      Processor Tree:\n        ListSink\n{code}\n\nComparing Map5,Map6，actually they are similar except Spark Partition Pruning Sink Operator).\n\nthe query in tez, there is only 1 Map(Map4) contains {{Dynamic Partitioning Event Operator}}\n{code}\n\nSTAGE DEPENDENCIES:\n  Stage-1 is a root stage\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-1\n    Tez\n#### A masked pattern was here ####\n      Edges:\n        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)\n        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)\n#### A masked pattern was here ####\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 2000 Data size: 757248 Basic stats: COMPLETE Column stats: COMPLETE\n                  Select Operator\n                    expressions: ds (type: string), hr (type: string)\n                    outputColumnNames: _col0, _col1\n                    Statistics: Num rows: 2000 Data size: 736000 Basic stats: COMPLETE Column stats: COMPLETE\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string), _col1 (type: string)\n                      sort order: ++\n                      Map-reduce partition columns: _col0 (type: string), _col1 (type: string)\n                      Statistics: Num rows: 2000 Data size: 736000 Basic stats: COMPLETE Column stats: COMPLETE\n            Execution mode: llap\n            LLAP IO: no inputs\n        Map 4 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date_hour\n                  filterExpr: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                  Statistics: Num rows: 4 Data size: 108 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string), hr (type: string)\n                      outputColumnNames: _col0, _col2\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string), _col2 (type: string)\n                        sort order: ++\n                        Map-reduce partition columns: _col0 (type: string), _col2 (type: string)\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col0 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          Dynamic Partitioning Event Operator\n                            Target column: ds (string)\n                            Target Input: srcpart\n                            Partition key expr: ds\n                            Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                            Target Vertex: Map 1\n                      Select Operator\n                        expressions: _col2 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          Dynamic Partitioning Event Operator\n                            Target column: hr (string)\n                            Target Input: srcpart\n                            Partition key expr: hr\n                            Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                            Target Vertex: Map 1\n            Execution mode: llap\n            LLAP IO: no inputs\n        Reducer 2 \n            Execution mode: llap\n            Reduce Operator Tree:\n              Merge Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 _col0 (type: string), _col1 (type: string)\n                  1 _col0 (type: string), _col2 (type: string)\n                Statistics: Num rows: 2200 Data size: 809600 Basic stats: COMPLETE Column stats: NONE\n                Group By Operator\n                  aggregations: count()\n                  mode: hash\n                  outputColumnNames: _col0\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  Reduce Output Operator\n                    sort order: \n                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                    value expressions: _col0 (type: bigint)\n        Reducer 3 \n            Execution mode: llap\n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: count(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                File Output Operator\n                  compressed: false\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  table:\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: -1\n      Processor Tree:\n        ListSink\n\n{code}\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-09T06:07:36.201+0000","updated":"2017-05-09T06:07:36.201+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16030524","id":"16030524","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: update patch, as in my environment,[case \"multiple sources, single key\"|https://issues.apache.org/jira/browse/HIVE-16780] in spark_dynamic_pruning.q fails, i could not generate new spark_dynamic_partition_pruning.q.out. I extract the test case about \"multi columns, single source\" in a new qfile \"spark_dynamic_partition_pruning_combine.q\"( here i create a configuration item \" hive.spark.dynamic.partition.pruning.combine\" ,so if this config item is not enabled, combine op trees for partiition info will not happen)\n{code}\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.spark.dynamic.partition.pruning=true;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.strict.checks.cartesian.product=false;\nset hive.spark.dynamic.partition.pruning=true;\nset hive.spark.dynamic.partition.pruning.combine=true;\n\n\n-- SORT_QUERY_RESULTS\ncreate table srcpart_date_hour as select ds as ds, ds as `date`, hr as hr, hr as hour from srcpart group by ds, hr;\n-- multiple columns single source\nEXPLAIN select count(*) from srcpart join srcpart_date_hour on (srcpart.ds = srcpart_date_hour.ds and srcpart.hr = srcpart_date_hour.hr) where srcpart_date_hour.`date` = '2008-04-08' and srcpart_date_hour.hour = 11;\nselect count(*) from srcpart join srcpart_date_hour on (srcpart.ds = srcpart_date_hour.ds and srcpart.hr = srcpart_date_hour.hr) where srcpart_date_hour.`date` = '2008-04-08' and srcpart_date_hour.hour = 11;\nset hive.spark.dynamic.partition.pruning.combine=false;\nEXPLAIN select count(*) from srcpart join srcpart_date_hour on (srcpart.ds = srcpart_date_hour.ds and srcpart.hr = srcpart_date_hour.hr) where srcpart_date_hour.`date` = '2008-04-08' and srcpart_date_hour.hour = 11;\nselect count(*) from srcpart join srcpart_date_hour on (srcpart.ds = srcpart_date_hour.ds and srcpart.hr = srcpart_date_hour.hr) where srcpart_date_hour.`date` = '2008-04-08' and srcpart_date_hour.hour = 11;\n{code}\n\nI think we can parallel, you can review and i continue to fix HIVE-16780. after fixing HIVE-16780 in my environment, i can update the spark_dynamic_partition_pruning.q.out with the change of HIVE-11297.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-05-31T02:38:14.154+0000","updated":"2017-05-31T02:38:14.154+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16032558","id":"16032558","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12870495/HIVE-11297.1.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10813 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_queries] (batchId=228)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5495/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5495/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5495/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 4 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12870495 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-01T07:01:49.391+0000","updated":"2017-06-01T07:01:49.391+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16036446","id":"16036446","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun],[~Ferd]: can you help review HIVE-11297.1.patch if have time?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-05T01:23:20.421+0000","updated":"2017-06-05T01:23:20.421+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16036514","id":"16036514","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for working on this [~kellyzly]!. Sorry for the delay but I added some comments in RB.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-05T04:25:59.418+0000","updated":"2017-06-05T04:25:59.418+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16036554","id":"16036554","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: thanks for review. reply you on review board.\nbq.Seems this removes the extra map work after it was generated. Is there a way to avoid generating the map work in the first place?\nphysical operator tree will by spark partition pruningsink\noriginal tree:\n{noformat}\nTS[1]-FIL[17]-RS[4]-JOIN[5]\n             -SEL[18]-GBY[19]-SPARKPRUNINGSINK[20]\n             -SEL[21]-GBY[22]-SPARKPRUNINGSINK[23]\n{noformat}\nafter split by spark partition pruningsink:\n{noformat}\nTS[1]-FIL[17]-RS[4]-JOIN[5]\nTS[1]-FIL[17]-SEL[18]-GBY[19]-SPARKPRUNINGSINK[20]\nTS[1]-FIL[17]-SEL[21]-GBY[22]-SPARKPRUNINGSINK[23]\n{noformat}\nIf we want to avoid generating multiple map works({noformat}TS[1]-FIL[17]-SEL[18]-GBY[19]-SPARKPRUNINGSINK[20],TS[1]-FIL[17]-SEL[18]-GBY[22]-SPARKPRUNINGSINK[23]{noformat}), we need remove the rule of spark dynamic partition pruning. If we remove that rule, exception will be thrown because the remaining tree will not be in a MapWork (   \n{noformat}\n             -SEL[18]-GBY[19]-SPARKPRUNINGSINK[20]\n             -SEL[21]-GBY[22]-SPARKPRUNINGSINK[23]\n{noformat}\n             )\n{code}\nopRules.put(new RuleRegExp(\"Split Work - SparkPartitionPruningSink\",\n    SparkPartitionPruningSinkOperator.getOperatorName() + \"%\"), genSparkWork);\n\n{code}\n\nIf you have idea about this, please give me your suggestion.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-05T05:40:07.311+0000","updated":"2017-06-05T05:40:07.311+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16036830","id":"16036830","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12871201/HIVE-11297.2.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10820 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query78] (batchId=232)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5531/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5531/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5531/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 5 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12871201 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-05T11:28:28.411+0000","updated":"2017-06-05T11:28:28.411+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16037305","id":"16037305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"[~kellyzly]: it seems the same TableScan [could be added multiple times|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SplitOpTreeForDPP.java#L116] in {{SplitOpTreeForDPP}}, and so multiple MapWorks are generated for the same TableScan. Can you check if we can avoid doing that? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-05T18:09:46.757+0000","updated":"2017-06-05T18:09:46.757+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16038414","id":"16038414","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]:   we can not do that because GenSparkProcContext#clonedPruningTableScanSet will be sent to topNodes of GenSparkWorkWalker#startWalking. And GenSparkWorkWalker will split tree in min cost. So if topNode is 1, it will split following tree\n{noformat}\nTS[1]-FIL[17]- SEL[18] -GBY[19]-SPARKPRUNINGSINK[20]\n                    -SEL[21] -GBY[22]-SPARKPRUNINGSINK[23]\n{noformat}\ninto  only 1 tree\n{noformat}\nTS[1]-FIL[17]- SEL[18] -GBY[19]-SPARKPRUNINGSINK[20]\n{noformat}\n\nThe log of GenSparkWork\n{code}\n[root@bdpe41 hive]# grep GenSparkWork logs/hive.log \n2017-06-06T16:34:12,527 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Root operator: TS[0]\n2017-06-06T16:34:12,527 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Leaf operator: RS[2]\n2017-06-06T16:34:19,070 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: First pass. Leaf operator: RS[2]\n2017-06-06T16:34:19,070 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Root operator: JOIN[5]\n2017-06-06T16:34:19,070 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Leaf operator: RS[9]\n2017-06-06T16:34:22,858 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Removing RS[2] as parent from JOIN[5]\n2017-06-06T16:34:22,859 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Removing RS[4] as parent from JOIN[5]\n2017-06-06T16:34:22,859 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: First pass. Leaf operator: RS[9]\n2017-06-06T16:34:22,859 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Root operator: GBY[10]\n2017-06-06T16:34:22,859 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Leaf operator: FS[12]\n2017-06-06T16:34:27,322 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Removing RS[9] as parent from GBY[10]\n2017-06-06T16:34:27,322 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: First pass. Leaf operator: FS[12]\n2017-06-06T16:34:27,322 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Root operator: TS[1]\n2017-06-06T16:34:27,322 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Leaf operator: RS[4]\n2017-06-06T16:36:14,669 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Second pass. Leaf operator: RS[4] has common downstream work:org.apache.hadoop.hive.ql.plan.ReduceWork@7e7f72\n2017-06-06T16:36:14,672 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Root operator: TS[1]\n2017-06-06T16:36:14,672 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: Leaf operator: SPARKPRUNINGSINK[20]\n2017-06-06T16:38:22,338 DEBUG [7e080689-d76b-498f-9a41-d8843a9b199f main] spark.GenSparkWork: First pass. Leaf operator: SPARKPRUNINGSINK[20]\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-06T08:57:59.316+0000","updated":"2017-06-06T08:57:59.316+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16043316","id":"16043316","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"[~kellyzly]: more changes are needed in {{SplitOpTreeForDPP}}: you also need to make sure when splitting the OP tree, all pruning sinks will be kept. For instance, given:\n{code}\n                   TS\n                   |\n                   FIL\n                   |\n                   SEL\n                 /  | \\\n               B1  B2  B3\n{code}\nsuppose {{B2}} and {{B3}} contains pruning sinks, in {{SplitOpTreeForDPP}} we should clone the OP tree for both of them. The result should be:\n{code}\nOriginal Tree    Generated Tree\nTS               TS\n |                |\nFIL              FIL\n |                |\nSEL              SEL\n |               / \\\nB1              B2  B3\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-08T19:50:41.504+0000","updated":"2017-06-08T19:50:41.504+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16046348","id":"16046348","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: will try to modify the [SplitOpTreeForDPP|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SplitOpTreeForDPP.java#L107].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-12T08:54:01.380+0000","updated":"2017-06-12T08:54:01.380+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16047513","id":"16047513","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]:  update SplitOpTreeForDPP and to split the trees like what you mentioned last time.\nbecause the explain plan is changed after this jira\n{code}\nset hive.execution.engine=spark; \nset hive.auto.convert.join.noconditionaltask.size=20; \nset hive.spark.dynamic.partition.pruning=true;\nselect count(*) from srcpart join srcpart_date_hour on (srcpart.ds = srcpart_date_hour.ds and srcpart.hr = srcpart_date_hour.hr) where srcpart_date_hour.`date` = '2008-04-08' and srcpart_date_hour.hour = 11;\n{code}\n\nbefore\n{code}\nSTAGE PLANS:\n  Stage: Stage-2\n    Spark\n#### A masked pattern was here ####\n      Vertices:\n        Map 5 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date_hour\n                  filterExpr: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                  Statistics: Num rows: 4 Data size: 108 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string), hr (type: string)\n                      outputColumnNames: _col0, _col2\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col0 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          Spark Partition Pruning Sink Operator\n                            partition key expr: ds\n                            Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                            target column name: ds\n                            target work: Map 1\n        Map 6 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date_hour\n                  filterExpr: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                  Statistics: Num rows: 4 Data size: 108 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string), hr (type: string)\n                      outputColumnNames: _col0, _col2\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col2 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          Spark Partition Pruning Sink Operator\n                            partition key expr: hr\n                            Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                            target column name: hr\n                            target work: Map 1\n\n  Stage: Stage-1\n    Spark\n      Edges:\n        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)\n        Reducer 3 <- Reducer 2 (GROUP, 1)\n{code}\n\nnow\n{code}\nStage: Stage-2  Spark\n#### A masked pattern was here ####\n    Vertices:\n      Map 5 \n          Map Operator Tree:\n              TableScan\n                alias: srcpart_date_hour\n                filterExpr: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                Statistics: Num rows: 4 Data size: 108 Basic stats: COMPLETE Column stats: NONE\n                Filter Operator\n                  predicate: ((date = '2008-04-08') and (UDFToDouble(hour) = 11.0) and ds is not null and hr is not null) (type: boolean)\n                  Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string), hr (type: string)\n                    outputColumnNames: _col0, _col2\n                    Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: _col0 (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: ds\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          target column name: ds\n                          target work: Map 1\n                    Select Operator\n                      expressions: _col2 (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                      Group By Operator\n                        keys: _col0 (type: string)\n                        mode: hash\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                        Spark Partition Pruning Sink Operator\n                          partition key expr: hr\n                          Statistics: Num rows: 1 Data size: 27 Basic stats: COMPLETE Column stats: NONE\n                          target column name: hr\n                          target work: Map 1\n\nStage: Stage-1\n  Spark\n    Edges:\n      Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 4 (PARTITION-LEVEL SORT, 2)\n      Reducer 3 <- Reducer 2 (GROUP, 1)\n{code}\n\nbut when i use following command to generate new spark_dynamic_partition_pruning.q.out\n{code}\nmvn clean test -Dtest=TestSparkCliDriver -Dtest.output.overwrite=true -Dqfile= spark_dynamic_partition_pruning.q\n{code}\n\nI found it not only changed above explain, but also change others. the changes like\n1. comment like \"SORT_QUERY_RESULTS\" deleted, how to keep original format?\n{code}\n-PREHOOK: query: -- SORT_QUERY_RESULTS\n-\n-select distinct ds from srcpart\n+PREHOOK: query: select distinct ds from srcpart\n+POSTHOOK: query: EXPLAIN select count(*) from srcpart join srcpart_date on (srcpart.ds = srcpart_date.ds) join srcpart_hour on (srcpart.hr = srcpart_hour.hr) \n{code}\n\n2.  some changes is not caused by HIVE-11297.3.patch. like \"filter Operator is added in the explain plan\"\n{code}\nPOSTHOOK: type: QUERY\n STAGE DEPENDENCIES:\n   Stage-2 is a root stage\n@@ -3168,16 +3141,19 @@ STAGE PLANS:\n                 mode: mergepartial\n                 outputColumnNames: _col0\n                 Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n-                Group By Operator\n-                  keys: _col0 (type: string)\n-                  mode: hash\n-                  outputColumnNames: _col0\n-                  Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n-                  Reduce Output Operator\n-                    key expressions: _col0 (type: string)\n-                    sort order: +\n-                    Map-reduce partition columns: _col0 (type: string)\n+                Filter Operator\n+                  predicate: _col0 is not null (type: boolean)\n+                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: NONE\n+                  Group By Operator\n+                    keys: _col0 (type: string)\n+                    mode: hash\n+                    outputColumnNames: _col0\n                     Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n+                    Reduce Output Operator\n+                      key expressions: _col0 (type: string)\n+                      sort order: +\n+                      Map-reduce partition columns: _col0 (type: string)\n+                      Statistics: Num rows: 2 Data size: 368 Basic stats: COMPLETE Column stats: NONE\n{code}\n\nHow to solve the changes in spark.dynamic.partition.pruning.q.out?\n1. just copy the change caused by HIVE-11297.3\n2. use \"-Dtest.output.overwrite=true\" to generate a new *q.out\nwhich do you prefer?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-13T07:00:37.282+0000","updated":"2017-06-13T07:00:37.282+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16047548","id":"16047548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12872813/HIVE-11297.3.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10829 tests executed\n*Failed tests:*\n{noformat}\nTestSSLWithMiniKdc - did not produce a TEST-*.xml file (likely timed out) (batchId=238)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)\norg.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[0] (batchId=180)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5633/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5633/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5633/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 8 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12872813 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-13T08:14:24.455+0000","updated":"2017-06-13T08:14:24.455+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16049902","id":"16049902","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: can you help to view HIVE-11297.3.patch which changes {{SplitOpTreeForDPP.java}} and {{spark.dynamic.partition.pruning.q.out}}? thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-15T01:43:04.641+0000","updated":"2017-06-15T01:43:04.641+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16049923","id":"16049923","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"Sure. Added comments in RB. Regarding the output file, you can just use {{-Dtest.output.overwrite=true}} to generate new file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-15T02:15:15.622+0000","updated":"2017-06-15T02:15:15.622+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16050151","id":"16050151","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: update HIVE-11297.4.patch according to what you mentioned on RB.\n{noformat}\n         TS1    TS2\n          |           |\n          FIL1    FIL2\n          |           |\n          RS     SEL---\n          |          |   \\        \\\n          |        RS  SEL  SEL\n          \\   /      |     |\n          JOIN      GBY   GBY\n                      |    |\n                      |  SPARKPRUNINGSINK\n                      |\n                  SPARKPRUNINGSINK\n{noformat}\ncurrent algorithms:\n1. find the filter FIL2, tranverse each branch of FIL2 and get the children which start branches contain SPARKPRUNINGSINK.\n2.  split the tree into 2 seperate tree","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-15T08:31:12.871+0000","updated":"2017-06-15T08:31:12.871+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16051628","id":"16051628","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: help review and update patch on the RB.thanks!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-16T08:59:36.949+0000","updated":"2017-06-16T08:59:36.949+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16051742","id":"16051742","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12873251/HIVE-11297.5.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 10831 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5659/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5659/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5659/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 14 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12873251 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-16T10:29:03.225+0000","updated":"2017-06-16T10:29:03.225+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16052699","id":"16052699","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: just 1 thing need to be confirmed:\n{code}\nOperator<?> filterOp = pruningSinkOp;\n    Operator<?> selOp = null;\n  while (filterOp != null) {\n      if (filterOp.getNumChild() > 1) {\n        break;\n      } else {\n        selOp = filterOp;\n        filterOp = filterOp.getParentOperators().get(0);\n      }\n    }\n\n{code}\nHere the original code is find the filterOp from pruningSinkOp(tranverse back award).  why need rename filterOp to something else?  I think we can remove selOp here because it will not used anymore.   If my understanding is wrong, please tell me .\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-17T05:32:03.437+0000","updated":"2017-06-17T05:32:03.437+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16052701","id":"16052701","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"[~kellyzly] I think in the original code the parent node of all branches is a filter op, but now it is changed. That's why I think it's better to rename it to something else to avoid confusion. And yes, the selOp is no longer needed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-17T05:46:33.338+0000","updated":"2017-06-17T05:46:33.338+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16053446","id":"16053446","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: When i print the operator tree of multi_column_single_source.q  when debugging in [SplitOpTreeForDPP|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SplitOpTreeForDPP.java#L75 ], the physical plan is \n{code}\nset hive.execution.engine=spark; \nset hive.auto.convert.join.noconditionaltask.size=20; \nset hive.spark.dynamic.partition.pruning=true;\nselect count(*) from srcpart join srcpart_date_hour on (srcpart.ds = srcpart_date_hour.ds and srcpart.hr = srcpart_date_hour.hr) where srcpart_date_hour.`date` = '2008-04-08' and srcpart_date_hour.hour = 11;\n{code}\n\nphysical plan \n{code}\nTS[1]-FIL[17]-RS[4]-JOIN[5]-GBY[8]-RS[9]-GBY[10]-FS[12]\n             -SEL[18]-GBY[19]-SPARKPRUNINGSINK[20]\n             -SEL[21]-GBY[22]-SPARKPRUNINGSINK[23]\n{code}\n{noformat}RS[4],SEL[18],SEL[21] is children of FIL[17]{noformat}\nbq. I think in the original code the parent node of all branches is a filter op, but now it is changed\nI don't think so, i think now filter op is still {noformat}FIL[17]{noformat}.  the difference between previous is now.  Before we split above tree into three trees\n{noformat}\ntree1: TS[1]-FIL[17]-RS[4]-JOIN[5]-GBY[8]-RS[9]-GBY[10]-FS[12]\ntree2: TS[1]-FIL[17]-SEL[18]-GBY[19]-SPARKPRUNINGSINK[20]\ntree3: TS[1]-FIL[17]-SEL[21]-GBY[22]-SPARKPRUNINGSINK[23]\n{noformat}\n\nNow we split above tree into two trees\n{noformat}\ntree1: TS[1]-FIL[17]-RS[4]-JOIN[5]-GBY[8]-RS[9]-GBY[10]-FS[12]\ntree2: TS[1]-FIL[17]-SEL[18]-GBY[19]-SPARKPRUNINGSINK[20]\n                   -SEL[21]-GBY[22]-SPARKPRUNINGSINK[23]\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-19T03:41:28.632+0000","updated":"2017-06-19T03:41:28.632+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16053473","id":"16053473","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: in HIVE-11297.6, fix all comments except renaming filterOp.  About this, i explain more in above, if there is misunderstanding ,tell me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-19T04:53:52.936+0000","updated":"2017-06-19T04:53:52.936+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16053510","id":"16053510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12873432/HIVE-11297.6.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 10831 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=157)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5673/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5673/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5673/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 12 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12873432 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-19T06:05:43.324+0000","updated":"2017-06-19T06:05:43.324+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16056531","id":"16056531","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]:  can you spend some time to review HIVE-11297.6.patch? thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-20T21:52:52.908+0000","updated":"2017-06-20T21:52:52.908+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16056577","id":"16056577","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry for the late response. Will put comments in the RB.\nRegarding the filterOp issue, It's a little strange since I'm seeing something different on my side (with the latest master branch). \nFor the query you posted above, I saw:\n{code}\nTS[3] -> FIL[18] -> SEL[5] -> SEL[19] -> GBY[20] -> SPARKPRUNINGSINK[21]\nTS[3] -> FIL[18] -> SEL[5] -> SEL[22] -> GBY[23] -> SPARKPRUNINGSINK[24]\nTS[3] -> FIL[18] -> SEL[5] -> RS[7] -> JOIN[8] -> ...\n{code}\ninside {{SplitOpTreeForDPP}}.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-20T22:22:15.154+0000","updated":"2017-06-20T22:22:15.154+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16056837","id":"16056837","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]:   I patch HIVE-11297.6.patch on latest master branch(8c5f55e) and run query i posted above, i print the operator tree  \n\nSplitOpTreeForDPP#process\n{code}\n.....\n/** print the operator tree **/\n  ArrayList<TableScanOperator> tableScanList = new ArrayList ();\n tableScanList.add((TableScanOperator)stack.get(0));\n LOG.debug(\"operator tree:\"+Operator.toString(tableScanList));\n/** print the operator tree**/\nOperator<?> filterOp = pruningSinkOp;\n    while (filterOp != null) {\n      if (filterOp.getNumChild() > 1) {\n        break;\n      } else {\n        filterOp = filterOp.getParentOperators().get(0);\n      }\n    }\n....\n\n{code}\n\nthe operator tree is:\n{code}\nTS[1]-FIL[17]-RS[4]-JOIN[5]-GBY[8]-RS[9]-GBY[10]-FS[12]\nTS[1]-FIL[17]-SEL[18]-GBY[19]-SPARKPRUNINGSINK[20]\nTS[1]-FIL[17]-SEL[21]-GBY[22]-SPARKPRUNINGSINK[23]\n{code}\n\nSo can you retest it in your env? if the operator tree is like what you mentioned, i think all the operator tree in spark_dynamic_partition_pruning.q.out will be different as i generated in my env.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-21T02:05:37.015+0000","updated":"2017-06-21T02:09:47.531+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16056846","id":"16056846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]:  update HIVE-11297.7.patch according to the last round of review in review board.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-21T02:12:31.491+0000","updated":"2017-06-21T02:12:31.491+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16056908","id":"16056908","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nSo can you retest it in your env? if the operator tree is like what you mentioned, i think all the operator tree in spark_dynamic_partition_pruning.q.out will be different as i generated in my env.\n{quote}\n\nInteresting.. I'm not sure what caused the difference, may be some configurations? I've tried several times in my env and the FIL is always followed by a SEL operator. Nevertheless, this is not an important issue. Will take a look a the RB.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-21T03:10:48.374+0000","updated":"2017-06-21T03:10:48.374+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16057086","id":"16057086","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12873780/HIVE-11297.7.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 10841 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5706/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5706/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5706/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 12 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12873780 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-21T07:21:45.410+0000","updated":"2017-06-21T07:21:45.410+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16060336","id":"16060336","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: about the questions you mentioned in RB. there are two queries are different.  \nexplain query1( please use the attached hive-site.xml to verify, without the configuration in hive-site.xml,  i can not reproduce following explain)\n{code}\nset hive.execution.engine=spark; \nset hive.spark.dynamic.partition.pruning=true;\nset hive.optimize.ppd=true;\nset hive.ppd.remove.duplicatefilters=true;\nset hive.optimize.metadataonly=false;\nset hive.optimize.index.filter=true;\nset hive.strict.checks.cartesian.product=false;\nexplain select count(*) from srcpart join srcpart_date on (srcpart.ds = srcpart_date.ds) join srcpart_hour on (srcpart.hr = srcpart_hour.hr) \nwhere srcpart_date.`date` = '2008-04-08' and srcpart_hour.hour = 11 and srcpart.hr = 11\n{code}\nprevious explain \n{code}\nSTAGE DEPENDENCIES:\n  Stage-2 is a root stage\n  Stage-1 depends on stages: Stage-2\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-2\n    Spark\n      DagName: root_20170622213734_eb4c35e8-952a-4c4d-8972-ba5381bf51a3:2\n      Vertices:\n        Map 7 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date\n                  filterExpr: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                  Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col0 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                          Spark Partition Pruning Sink Operator\n                            partition key expr: ds\n                            Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                            target column name: ds\n                            target work: Map 1\n\n  Stage: Stage-1\n    Spark\n      Edges:\n        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 5 (PARTITION-LEVEL SORT, 2)\n        Reducer 3 <- Map 6 (PARTITION-LEVEL SORT, 2), Reducer 2 (PARTITION-LEVEL SORT, 2)\n        Reducer 4 <- Reducer 3 (GROUP, 1)\n      DagName: root_20170622213734_eb4c35e8-952a-4c4d-8972-ba5381bf51a3:1\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string), hr (type: string)\n                    outputColumnNames: _col0, _col1\n                    Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string)\n                      sort order: +\n                      Map-reduce partition columns: _col0 (type: string)\n                      Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                      value expressions: _col1 (type: string)\n        Map 5 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date\n                  filterExpr: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                  Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: string)\n                        Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n        Map 6 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_hour\n                  filterExpr: ((UDFToDouble(hour) = 11.0) and (UDFToDouble(hr) = 11.0)) (type: boolean)\n                  Statistics: Num rows: 2 Data size: 10 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((UDFToDouble(hour) = 11.0) and (UDFToDouble(hr) = 11.0)) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: hr (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: string)\n                        Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n        Reducer 2 \n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 _col0 (type: string)\n                  1 _col0 (type: string)\n                outputColumnNames: _col1\n                Statistics: Num rows: 1 Data size: 12786 Basic stats: COMPLETE Column stats: NONE\n                Reduce Output Operator\n                  key expressions: _col1 (type: string)\n                  sort order: +\n                  Map-reduce partition columns: _col1 (type: string)\n                  Statistics: Num rows: 1 Data size: 12786 Basic stats: COMPLETE Column stats: NONE\n        Reducer 3 \n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 _col1 (type: string)\n                  1 _col0 (type: string)\n                Statistics: Num rows: 1 Data size: 14064 Basic stats: COMPLETE Column stats: NONE\n                Group By Operator\n                  aggregations: count()\n                  mode: hash\n                  outputColumnNames: _col0\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  Reduce Output Operator\n                    sort order: \n                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                    value expressions: _col0 (type: bigint)\n        Reducer 4 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: count(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                File Output Operator\n                  compressed: false\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  table:\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: -1\n      Processor Tree:\n        ListSink\n\n{code}\n\ncurrent explain\n{code}\nSTAGE DEPENDENCIES:\n  Stage-2 is a root stage\n  Stage-1 depends on stages: Stage-2\n  Stage-0 depends on stages: Stage-1\n\nSTAGE PLANS:\n  Stage: Stage-2\n    Spark\n      DagName: root_20170622213734_eb4c35e8-952a-4c4d-8972-ba5381bf51a3:2\n      Vertices:\n        Map 7 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date\n                  filterExpr: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                  Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col0 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                          Spark Partition Pruning Sink Operator\n                            partition key expr: ds\n                            Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                            target column name: ds\n                            target work: Map 1\n                 Map 8 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_hour\n                  filterExpr: ((UDFToDouble(hour) = 11.0) and (UDFToDouble(hr) = 11.0)) (type: boolean)\n                  Statistics: Num rows: 2 Data size: 10 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((UDFToDouble(hour) = 11.0) and (UDFToDouble(hr) = 11.0)) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: hr (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                      Select Operator\n                        expressions: _col0 (type: string)\n                        outputColumnNames: _col0\n                        Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                        Group By Operator\n                          keys: _col0 (type: string)\n                          mode: hash\n                          outputColumnNames: _col0\n                          Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                          Spark Partition Pruning Sink Operator\n                            partition key expr: hr\n                            Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                            target column name: hr\n                            target work: Map 1Best Regards\n\n\n  Stage: Stage-1\n    Spark\n      Edges:\n        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 2), Map 5 (PARTITION-LEVEL SORT, 2)\n        Reducer 3 <- Map 6 (PARTITION-LEVEL SORT, 2), Reducer 2 (PARTITION-LEVEL SORT, 2)\n        Reducer 4 <- Reducer 3 (GROUP, 1)\n      DagName: root_20170622213734_eb4c35e8-952a-4c4d-8972-ba5381bf51a3:1\n      Vertices:\n        Map 1 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart\n                  Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                  Select Operator\n                    expressions: ds (type: string), hr (type: string)\n                    outputColumnNames: _col0, _col1\n                    Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                    Reduce Output Operator\n                      key expressions: _col0 (type: string)\n                      sort order: +\n                      Map-reduce partition columns: _col0 (type: string)\n                      Statistics: Num rows: 1 Data size: 11624 Basic stats: PARTIAL Column stats: NONE\n                      value expressions: _col1 (type: string)\n        Map 5 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_date\n                  filterExpr: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                  Statistics: Num rows: 2 Data size: 42 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((date = '2008-04-08') and ds is not null) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: ds (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: string)\n                        Statistics: Num rows: 1 Data size: 21 Basic stats: COMPLETE Column stats: NONE\n        Map 6 \n            Map Operator Tree:\n                TableScan\n                  alias: srcpart_hour\n                  filterExpr: ((UDFToDouble(hour) = 11.0) and (UDFToDouble(hr) = 11.0)) (type: boolean)\n                  Statistics: Num rows: 2 Data size: 10 Basic stats: COMPLETE Column stats: NONE\n                  Filter Operator\n                    predicate: ((UDFToDouble(hour) = 11.0) and (UDFToDouble(hr) = 11.0)) (type: boolean)\n                    Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                    Select Operator\n                      expressions: hr (type: string)\n                      outputColumnNames: _col0\n                      Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n                      Reduce Output Operator\n                        key expressions: _col0 (type: string)\n                        sort order: +\n                        Map-reduce partition columns: _col0 (type: string)\n                        Statistics: Num rows: 1 Data size: 5 Basic stats: COMPLETE Column stats: NONE\n        Reducer 2 \n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 _col0 (type: string)\n                  1 _col0 (type: string)\n                outputColumnNames: _col1\n                Statistics: Num rows: 1 Data size: 12786 Basic stats: COMPLETE Column stats: NONE\n                Reduce Output Operator\n                  key expressions: _col1 (type: string)\n                  sort order: +\n                  Map-reduce partition columns: _col1 (type: string)\n                  Statistics: Num rows: 1 Data size: 12786 Basic stats: COMPLETE Column stats: NONE\n        Reducer 3 \n            Reduce Operator Tree:\n              Join Operator\n                condition map:\n                     Inner Join 0 to 1\n                keys:\n                  0 _col1 (type: string)\n                  1 _col0 (type: string)\n                Statistics: Num rows: 1 Data size: 14064 Basic stats: COMPLETE Column stats: NONE\n                Group By Operator\n                  aggregations: count()\n                  mode: hash\n                  outputColumnNames: _col0\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  Reduce Output Operator\n                    sort order: \n                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                    value expressions: _col0 (type: bigint)\n        Reducer 4 \n            Reduce Operator Tree:\n              Group By Operator\n                aggregations: count(VALUE._col0)\n                mode: mergepartial\n                outputColumnNames: _col0\n                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                File Output Operator\n                  compressed: false\n                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE\n                  table:\n                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n\n  Stage: Stage-0\n    Fetch Operator\n      limit: -1\n      Processor Tree:\n        ListSink\n{code}\n\nthe difference between previous and now is an extra Map8.  After quering the history of spark_dynamic_partiton_pruning.q.out, I found in {{commit 42216997f7fcff1853524b03e3961ec5c21f3fd7}}, the Map8 exists. After {{commit 677e5d20109e31203129ef5090c8989e9bb7c366}} the Map8 is removed.  \nThe reason that cause the Map8 is removed in {{commit 677e5d20109e31203129ef5090c8989e9bb7c366}} is because the [filterDesc|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/DynamicPartitionPruningOptimization.java#L128 ] changed, in  {{commit 677e5d20109e31203129ef5090c8989e9bb7c366}}, filterDesc is {noformat}((ds) IN (RS[10]) and true) (type: boolean){noformat} in latest version its value is {noformat}Filter: ((ds) IN (RS[5]) and (hr) IN (RS[9])) (type: boolean)){noformat}  that's why there is no Map8 in  {{commit 677e5d20109e31203129ef5090c8989e9bb7c366}}.  In fact, Map8 should exist because we should build dpp operator tree for {{srcpart_date}} and {{srcpart_hour}} as {{srcpart}} has two partitions(srcpart.ds and srcpart.hr).  But i will not  deep investigate why Map8 is lost in  {{commit 677e5d20109e31203129ef5090c8989e9bb7c366}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-23T02:34:09.747+0000","updated":"2017-06-23T02:34:09.747+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16060369","id":"16060369","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~csun]: for the second query you mentioned in RB. file HIVE-16948 to trace","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-23T03:25:54.032+0000","updated":"2017-06-23T03:25:54.032+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16060387","id":"16060387","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"some minor changes about spark_partition_pruning.q.out","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-23T03:59:54.946+0000","updated":"2017-06-23T03:59:54.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16060440","id":"16060440","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874190/HIVE-11297.8.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 15 failed/errored test(s), 10846 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[create_merge_compressed] (batchId=238)\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_create] (batchId=83)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5739/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5739/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5739/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 15 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874190 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-23T05:58:32.309+0000","updated":"2017-06-23T05:58:32.309+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16060632","id":"16060632","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12874190/HIVE-11297.8.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 10846 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5743/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5743/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5743/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 12 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12874190 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-23T09:38:38.068+0000","updated":"2017-06-23T09:38:38.068+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16061436","id":"16061436","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~kellyzly]! +1 on the latest patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=csun","name":"csun","key":"csun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=csun&avatarId=23340","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=csun&avatarId=23340","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=csun&avatarId=23340","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=csun&avatarId=23340"},"displayName":"Chao Sun","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-23T19:58:58.428+0000","updated":"2017-06-23T19:58:58.428+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16062470","id":"16062470","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~ferd]:  as [~csun] finished review, let's commit HIVE-11297.8.patch. [~csun]: thanks for helping review!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kellyzly","name":"kellyzly","key":"kellyzly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liyunzhang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-06-26T01:14:13.425+0000","updated":"2017-06-26T01:14:13.425+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16062507","id":"16062507","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Ferd","name":"Ferd","key":"ferd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ferd&avatarId=21543","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ferd&avatarId=21543","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ferd&avatarId=21543","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ferd&avatarId=21543"},"displayName":"Ferdinand Xu","active":true,"timeZone":"Asia/Hong_Kong"},"body":"Committed to the upstream. Thanks [~kellyzly] for the patch and [~csun] for the review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Ferd","name":"Ferd","key":"ferd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ferd&avatarId=21543","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ferd&avatarId=21543","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ferd&avatarId=21543","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ferd&avatarId=21543"},"displayName":"Ferdinand Xu","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2017-06-26T02:58:01.920+0000","updated":"2017-06-26T02:58:01.920+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12845984/comment/16485919","id":"16485919","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"body":"Hive 3.0.0 has been released so closing this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vgarg","name":"vgarg","key":"vgarg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=vgarg&avatarId=30430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=vgarg&avatarId=30430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=vgarg&avatarId=30430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=vgarg&avatarId=30430"},"displayName":"Vineet Garg","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-22T23:58:15.732+0000","updated":"2018-05-22T23:58:15.732+0000"}],"maxResults":38,"total":38,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11297/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2heiv:"}}