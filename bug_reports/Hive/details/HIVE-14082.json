{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12982397","self":"https://issues.apache.org/jira/rest/api/2/issue/12982397","key":"HIVE-14082","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Sep 28 23:33:58 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14082/watchers","watchCount":2,"isWatching":false},"created":"2016-06-23T17:02:09.958+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329363","id":"12329363","name":"1.1.0","archived":false,"released":true,"releaseDate":"2015-03-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334255","id":"12334255","name":"2.1.0","archived":false,"released":true,"releaseDate":"2016-06-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-09-28T23:33:58.253+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"The following MULTI-INSERT Query Fails in Hive. I've listed the query required to re-produce this failure, as well as a few similar queries that work properly.\n\nSetup Queries:\n\n{code}\nDROP SCHEMA IF EXISTS multi_table_insert_bug CASCADE;\nCREATE SCHEMA multi_table_insert_bug;\nUSE multi_table_insert_bug;\n\nDROP TABLE IF EXISTS multi_table_insert_source;\nDROP TABLE IF EXISTS multi_table_insert_test;\n\nCREATE TABLE multi_table_insert_source (\n  date_column DATE,\n  column_1 STRING,\n  column_2 STRING,\n  column_3 STRING,\n  column_4 STRING\n);\n\nCREATE TABLE multi_table_insert_test (\n  column_1 STRING,\n  column_2 STRING,\n  line_count INT,\n  distinct_count_by_1_column INT,\n  distinct_count_by_2_columns INT\n)\nPARTITIONED BY (partition_column INT);\n\nINSERT OVERWRITE TABLE multi_table_insert_source VALUES\n  ('2016-01-22', 'value_1_1', 'value_1_2', 'value_1_3', 'value_1_4'),\n  ('2016-01-22', 'value_2_1', 'value_2_2', 'value_2_3', 'value_2_4'),\n  ('2016-01-22', 'value_3_1', 'value_3_2', 'value_3_3', 'value_3_4'),\n  ('2016-01-22', 'value_4_1', 'value_4_2', 'value_4_3', 'value_4_4'),\n  ('2016-01-22', 'value_5_1', 'value_5_2', 'value_5_3', 'value_5_4');\n{code}\n\n\nThe following queries run successfully:\n\n*Query 1:*\n\n{code}\nFROM multi_table_insert_source\n  INSERT OVERWRITE TABLE multi_table_insert_test PARTITION (partition_column = 365)\n  SELECT\n    column_1,\n    column_2,\n    COUNT(*) AS line_count,\n    COUNT(DISTINCT column_3) AS distinct_count_by_1_column,\n    COUNT(DISTINCT date_column, column_3) AS distinct_count_by_2_columns\n  WHERE date_column >= DATE_SUB(FROM_UNIXTIME(UNIX_TIMESTAMP()), 365)\n  GROUP BY\n    column_1,\n    column_2;\n{code}\n\n*Query 2:*\n\n{code}\nFROM multi_table_insert_source\n  INSERT OVERWRITE TABLE multi_table_insert_test PARTITION (partition_column = 365)\n  SELECT\n    column_1,\n    column_2,\n    COUNT(*) AS line_count,\n    COUNT(DISTINCT column_3) AS distinct_count_by_1_column,\n    COUNT(DISTINCT date_column, column_3) AS distinct_count_by_2_columns\n--  WHERE date_column >= DATE_SUB(FROM_UNIXTIME(UNIX_TIMESTAMP()), 365)\n  GROUP BY\n    column_1,\n    column_2\n  INSERT OVERWRITE TABLE multi_table_insert_test PARTITION (partition_column = 1096)\n  SELECT\n    column_1,\n    column_2,\n    COUNT(*) AS line_count,\n    COUNT(DISTINCT column_3) AS distinct_count_by_1_column,\n    COUNT(DISTINCT date_column, column_3) AS distinct_count_by_2_columns\n--  WHERE date_column >= DATE_SUB(FROM_UNIXTIME(UNIX_TIMESTAMP()), 1096)\n  GROUP BY\n    column_1,\n    column_2;\n{code}\n\nThe following query fails with a {{ClassCastException}}:\n\n*Query 3:*\n\n{code}\nFROM multi_table_insert_source\n  INSERT OVERWRITE TABLE multi_table_insert_test PARTITION (partition_column = 365)\n  SELECT\n    column_1,\n    column_2,\n    COUNT(*) AS line_count,\n    COUNT(DISTINCT column_3) AS distinct_count_by_1_column,\n    COUNT(DISTINCT date_column, column_3) AS distinct_count_by_2_columns\n  WHERE date_column >= DATE_SUB(FROM_UNIXTIME(UNIX_TIMESTAMP()), 365)\n  GROUP BY\n    column_1,\n    column_2\n  INSERT OVERWRITE TABLE multi_table_insert_test PARTITION (partition_column = 1096)\n  SELECT\n    column_1,\n    column_2,\n    COUNT(*) AS line_count,\n    COUNT(DISTINCT column_3) AS distinct_count_by_1_column,\n    COUNT(DISTINCT date_column, column_3) AS distinct_count_by_2_columns\n  WHERE date_column >= DATE_SUB(FROM_UNIXTIME(UNIX_TIMESTAMP()), 1096)\n  GROUP BY\n    column_1,\n    column_2;\n{code}\n\nHere is the full stack-trace of the exception:\n\n*Exception 1:*\n\n{code}\njava.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"_col0\":\"value_1_1\",\"_col1\":\"value_1_2\",\"_col2\":{0:{\"_col0\":\"value_1_3\"}}},\"value\":null}\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:257)\n\tat org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:506)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:447)\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:449)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"_col0\":\"value_1_1\",\"_col1\":\"value_1_2\",\"_col2\":{0:{\"_col0\":\"value_1_3\"}}},\"value\":null}\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:245)\n\t... 3 more\nCaused by: java.lang.ClassCastException: org.apache.hadoop.io.Text cannot be cast to org.apache.hadoop.hive.serde2.io.DateWritable\n\tat org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableDateObjectInspector.getPrimitiveWritableObject(WritableDateObjectInspector.java:38)\n\tat org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.compare(ObjectInspectorUtils.java:938)\n\tat org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.compare(ObjectInspectorUtils.java:818)\n\tat org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.compare(ObjectInspectorUtils.java:809)\n\tat org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualOrGreaterThan.evaluate(GenericUDFOPEqualOrGreaterThan.java:141)\n\tat org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator._evaluate(ExprNodeGenericFuncEvaluator.java:186)\n\tat org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:77)\n\tat org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:65)\n\tat org.apache.hadoop.hive.ql.exec.FilterOperator.process(FilterOperator.java:112)\n\tat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:878)\n\tat org.apache.hadoop.hive.ql.exec.ForwardOperator.process(ForwardOperator.java:38)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:236)\n\t... 3 more\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Multi-Insert Query Fails with GROUP BY, DISTINCT, and WHERE clauses","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982397/comment/15346772","id":"15346772","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"Furthermore, if {{hive.exec.post.hooks}} is set to {{org.apache.hadoop.hive.ql.hooks.LineageLogger}}, a different exception is thrown, but this time it is thrown in the Query Planning Phase. The full stack trace is below:\n\n*Exception 2:*\n\n{code}\nError: Error while compiling statement: FAILED: IndexOutOfBoundsException Index: 3, Size: 3 (state=42000,code=40000)\norg.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: IndexOutOfBoundsException Index: 3, Size: 3\n\tat org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:239)\n\tat org.apache.hive.jdbc.Utils.verifySuccessWithInfo(Utils.java:225)\n\tat org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:244)\n\tat org.apache.hive.beeline.Commands.executeInternal(Commands.java:934)\n\tat org.apache.hive.beeline.Commands.execute(Commands.java:1120)\n\tat org.apache.hive.beeline.Commands.sql(Commands.java:1017)\n\tat org.apache.hive.beeline.BeeLine.dispatch(BeeLine.java:1095)\n\tat org.apache.hive.beeline.BeeLine.execute(BeeLine.java:927)\n\tat org.apache.hive.beeline.BeeLine.begin(BeeLine.java:855)\n\tat org.apache.hive.beeline.BeeLine.mainWithInputRedirection(BeeLine.java:488)\n\tat org.apache.hive.beeline.BeeLine.main(BeeLine.java:471)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: org.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: IndexOutOfBoundsException Index: 3, Size: 3\n\tat org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:388)\n\tat org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:145)\n\tat org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:215)\n\tat org.apache.hive.service.cli.operation.Operation.run(Operation.java:326)\n\tat org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:424)\n\tat org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:401)\n\tat org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:258)\n\tat org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:503)\n\tat org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)\n\tat org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:718)\n\tat org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3\n\tat java.util.ArrayList.rangeCheck(ArrayList.java:635)\n\tat java.util.ArrayList.get(ArrayList.java:411)\n\tat org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$ReduceSinkLineage.process(OpProcFactory.java:607)\n\tat org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)\n\tat org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:94)\n\tat org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:78)\n\tat org.apache.hadoop.hive.ql.lib.LevelOrderWalker.walk(LevelOrderWalker.java:143)\n\tat org.apache.hadoop.hive.ql.lib.LevelOrderWalker.walk(LevelOrderWalker.java:149)\n\tat org.apache.hadoop.hive.ql.lib.LevelOrderWalker.walk(LevelOrderWalker.java:149)\n\tat org.apache.hadoop.hive.ql.lib.LevelOrderWalker.startWalking(LevelOrderWalker.java:122)\n\tat org.apache.hadoop.hive.ql.optimizer.lineage.Generator.transform(Generator.java:102)\n\tat org.apache.hadoop.hive.ql.optimizer.Optimizer.optimize(Optimizer.java:198)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10054)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:9868)\n\tat org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:223)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:446)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:312)\n\tat org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1201)\n\tat org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1188)\n\tat org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:143)\n\t... 15 more\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-23T17:07:12.929+0000","updated":"2016-06-23T17:09:37.996+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982397/comment/15346777","id":"15346777","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"After a lot of investigation into these two errors, they seem to be slightly related.\n\nThe TL;DR is that I think there is a bug in the class {{ReduceSinkOperator}}, but I am not 100% sure.\n\nI started debugging Exception 1 first. It seems that {{GenericUDFOPEqualOrGreaterThan}} tries to compare a {{Text}} object with value {{value_1_3}} to a {{DateWritable}} object with value {{2015-06-22}}. This happens inside the reduce method, and causes the code to throw a {{ClassCastException}} and fail.\n\nI compared the query plans for Query 1 vs. Query 3 (the output of {{EXPLAIN ...}}). Both plans require a single Map-Reduce job. The major difference is that the Query 3 runs a Filter Operator in both the Map Task and the Reduce Task, while Query 1 only runs a Filter Operator in the Map Task. I suspect the Filter Operator in the Reduce Task of Query 3 is having some type of issue.\n\nHere is the output of the {{EXPLAIN}} query:\n\n{code}\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n|                                                                                   Explain                                                                                   |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n| STAGE DEPENDENCIES:                                                                                                                                                         |\n|   Stage-2 is a root stage                                                                                                                                                   |\n|   Stage-0 depends on stages: Stage-2                                                                                                                                        |\n|   Stage-3 depends on stages: Stage-0                                                                                                                                        |\n|   Stage-1 depends on stages: Stage-2                                                                                                                                        |\n|   Stage-4 depends on stages: Stage-1                                                                                                                                        |\n|                                                                                                                                                                             |\n| STAGE PLANS:                                                                                                                                                                |\n|   Stage: Stage-2                                                                                                                                                            |\n|     Map Reduce                                                                                                                                                              |\n|       Map Operator Tree:                                                                                                                                                    |\n|           TableScan                                                                                                                                                         |\n|             alias: multi_table_insert_source                                                                                                                                |\n|             Statistics: Num rows: 5 Data size: 250 Basic stats: COMPLETE Column stats: NONE                                                                                 |\n|             Filter Operator                                                                                                                                                 |\n|               predicate: ((date_column >= 2013-06-21) or (date_column >= 2015-06-22)) (type: boolean)                                                                       |\n|               Statistics: Num rows: 2 Data size: 100 Basic stats: COMPLETE Column stats: NONE                                                                               |\n|               Select Operator                                                                                                                                               |\n|                 expressions: column_1 (type: string), column_2 (type: string), column_3 (type: string), date_column (type: date)                                            |\n|                 outputColumnNames: column_1, column_2, column_3, date_column                                                                                                |\n|                 Statistics: Num rows: 2 Data size: 100 Basic stats: COMPLETE Column stats: NONE                                                                             |\n|                 Reduce Output Operator                                                                                                                                      |\n|                   key expressions: column_1 (type: string), column_2 (type: string), column_3 (type: string), date_column (type: date)                                      |\n|                   sort order: ++++                                                                                                                                          |\n|                   Map-reduce partition columns: column_1 (type: string), column_2 (type: string)                                                                            |\n|                   Statistics: Num rows: 2 Data size: 100 Basic stats: COMPLETE Column stats: NONE                                                                           |\n|       Reduce Operator Tree:                                                                                                                                                 |\n|         Forward                                                                                                                                                             |\n|           Statistics: Num rows: 2 Data size: 100 Basic stats: COMPLETE Column stats: NONE                                                                                   |\n|           Filter Operator                                                                                                                                                   |\n|             predicate: (KEY._col2:1._col0 >= 2015-06-22) (type: boolean)                                                                                                    |\n|             Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                                  |\n|             Group By Operator                                                                                                                                               |\n|               aggregations: count(), count(DISTINCT KEY._col2:0._col0), count(DISTINCT KEY._col2:1._col0, KEY._col2:1._col1)                                                |\n|               keys: KEY._col0 (type: string), KEY._col1 (type: string)                                                                                                      |\n|               mode: complete                                                                                                                                                |\n|               outputColumnNames: _col0, _col1, _col2, _col3, _col4                                                                                                          |\n|               Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                                |\n|               Select Operator                                                                                                                                               |\n|                 expressions: _col0 (type: string), _col1 (type: string), UDFToInteger(_col2) (type: int), UDFToInteger(_col3) (type: int), UDFToInteger(_col4) (type: int)  |\n|                 outputColumnNames: _col0, _col1, _col2, _col3, _col4                                                                                                        |\n|                 Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                              |\n|                 File Output Operator                                                                                                                                        |\n|                   compressed: false                                                                                                                                         |\n|                   Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                            |\n|                   table:                                                                                                                                                    |\n|                       input format: org.apache.hadoop.mapred.TextInputFormat                                                                                                |\n|                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                                                                             |\n|                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                                                                             |\n|                       name: multi_table_insert_bug.multi_table_insert_test                                                                                                  |\n|           Filter Operator                                                                                                                                                   |\n|             predicate: (KEY._col2:1._col0 >= 2013-06-21) (type: boolean)                                                                                                    |\n|             Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                                  |\n|             Group By Operator                                                                                                                                               |\n|               aggregations: count(), count(DISTINCT KEY._col2:0._col0), count(DISTINCT KEY._col2:1._col0, KEY._col2:1._col1)                                                |\n|               keys: KEY._col0 (type: string), KEY._col1 (type: string)                                                                                                      |\n|               mode: complete                                                                                                                                                |\n|               outputColumnNames: _col0, _col1, _col2, _col3, _col4                                                                                                          |\n|               Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                                |\n|               Select Operator                                                                                                                                               |\n|                 expressions: _col0 (type: string), _col1 (type: string), UDFToInteger(_col2) (type: int), UDFToInteger(_col3) (type: int), UDFToInteger(_col4) (type: int)  |\n|                 outputColumnNames: _col0, _col1, _col2, _col3, _col4                                                                                                        |\n|                 Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                              |\n|                 File Output Operator                                                                                                                                        |\n|                   compressed: false                                                                                                                                         |\n|                   Statistics: Num rows: 1 Data size: 50 Basic stats: COMPLETE Column stats: NONE                                                                            |\n|                   table:                                                                                                                                                    |\n|                       input format: org.apache.hadoop.mapred.TextInputFormat                                                                                                |\n|                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                                                                             |\n|                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                                                                             |\n|                       name: multi_table_insert_bug.multi_table_insert_test                                                                                                  |\n|                                                                                                                                                                             |\n|   Stage: Stage-0                                                                                                                                                            |\n|     Move Operator                                                                                                                                                           |\n|       tables:                                                                                                                                                               |\n|           partition:                                                                                                                                                        |\n|             partition_column 365                                                                                                                                            |\n|           replace: true                                                                                                                                                     |\n|           table:                                                                                                                                                            |\n|               input format: org.apache.hadoop.mapred.TextInputFormat                                                                                                        |\n|               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                                                                                     |\n|               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                                                                                     |\n|               name: multi_table_insert_bug.multi_table_insert_test                                                                                                          |\n|                                                                                                                                                                             |\n|   Stage: Stage-3                                                                                                                                                            |\n|     Stats-Aggr Operator                                                                                                                                                     |\n|                                                                                                                                                                             |\n|   Stage: Stage-1                                                                                                                                                            |\n|     Move Operator                                                                                                                                                           |\n|       tables:                                                                                                                                                               |\n|           partition:                                                                                                                                                        |\n|             partition_column 1096                                                                                                                                           |\n|           replace: true                                                                                                                                                     |\n|           table:                                                                                                                                                            |\n|               input format: org.apache.hadoop.mapred.TextInputFormat                                                                                                        |\n|               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                                                                                     |\n|               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                                                                                     |\n|               name: multi_table_insert_bug.multi_table_insert_test                                                                                                          |\n|                                                                                                                                                                             |\n|   Stage: Stage-4                                                                                                                                                            |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n|                                                                                   Explain                                                                                   |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n|     Stats-Aggr Operator                                                                                                                                                     |\n|                                                                                                                                                                             |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n{code}\n\nThe {{ReduceSinkOperator}} class is emitting the record:\n\n*Record 1:*\n\n{code}\n{\"key\":{\"_col0\":\"value_1_1\",\"_col1\":\"value_1_2\",\"_col2\":{0:{\"_col0\":\"value_1_3\"}}},\"value\":null}\n{code}\n\nWhich does not contain the {{date_column}} column, causing the {{FilterOperator}} in the {{ExecReducer}} to fail.\n\nOnce I determined that {{ReduceSinkOperator}} is emitting this record, I did my best to trace through the logic of {{ReduceSinkOperator}} to figure out why it is emitting Record 1. The {{ReduceSinkOperator}} seems to emit a single record for each {{DISTINCT}} keyword in the query, but the record will only have a subset of its original columns. For each {{DISTINCT}} clause it will emit the columns in the {{DISTINCT}} clause itself, as well as the columns in the {{GROUP BY}}. For example, for {{COUNT(DISTINCT column_3)}} it will emit {{column_1}}, {{column_2}}, and {{column_3}}, but not the {{date_column}}. *I'm not sure the {{ReduceSinkOperator}} takes into account the situation where a {{FilterOperator}} can occur on the reduce-side of a Hive query, over a column not in the {{DISTINCT}} or {{GROUP BY}} clause.*\n\nException 2 seems to be related to Exception 1. Exception 2 is thrown in the class {{OpProcFactory.ReduceSinkLineage.process(...)}} method. This method does some type of processing on the {{ReduceSinkOperator}} class (the same class mentioned above when analyzing Exception 1), so my guess is that they are related.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-23T17:11:45.448+0000","updated":"2016-07-18T20:50:53.791+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982397/comment/15346779","id":"15346779","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"I would like to work on fixing this, but I'm looking for some advice / help on how to debug this further, and what the correct approach for the fix would be.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-23T17:12:49.838+0000","updated":"2016-06-23T17:12:49.838+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982397/comment/15347105","id":"15347105","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"[~sershe], [~amareshwari] I noticed you both had made some additions to the {{ReduceSinkOperator}} class in HIVE-5657 and HIVE-474, respectively. Do you have any insight into the bug reported here?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-23T20:21:41.109+0000","updated":"2016-06-23T20:21:41.109+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12982397/comment/15531236","id":"15531236","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"body":"Ping, anyone have any idea on this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stakiar","name":"stakiar","key":"stakiar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sahil Takiar","active":true,"timeZone":"Etc/UTC"},"created":"2016-09-28T23:33:58.253+0000","updated":"2016-09-28T23:33:58.253+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-14082/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2zzg7:"}}