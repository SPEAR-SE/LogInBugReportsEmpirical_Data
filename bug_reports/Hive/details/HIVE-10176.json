{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12787256","self":"https://issues.apache.org/jira/rest/api/2/issue/12787256","key":"HIVE-10176","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-03-09T18:08:06.638+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Mar 25 21:35:38 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10176/watchers","watchCount":8,"isWatching":false},"created":"2015-04-01T05:16:53.346+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"17.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329278","id":"12329278","description":"Branch 1.0 release","name":"1.0.0","archived":false,"released":true,"releaseDate":"2015-02-04"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332384","id":"12332384","name":"1.2.1","archived":false,"released":true,"releaseDate":"2015-06-26"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-03-25T21:35:38.259+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"When inserting values in to tables with TBLPROPERTIES (\"skip.header.line.count\"=\"1\") the first value listed is also skipped. \n\ncreate table test (row int, name string) TBLPROPERTIES (\"skip.header.line.count\"=\"1\"); \nload data local inpath '/root/data' into table test;\ninsert into table test values (1, 'a'), (2, 'b'), (3, 'c');\n\n(1, 'a') isn't inserted into the table. ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12340268","id":"12340268","name":"3.0.0","archived":false,"released":true,"releaseDate":"2018-05-21"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12708752","id":"12708752","filename":"data","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wwenbow","name":"wwenbow","key":"wwenbow","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wenbo Wang","active":true,"timeZone":"Etc/UTC"},"created":"2015-04-01T17:49:56.296+0000","size":85,"mimeType":"text/html","content":"https://issues.apache.org/jira/secure/attachment/12708752/data"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12792299","id":"12792299","filename":"HIVE-10176.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-09T18:08:06.634+0000","size":2319,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12792299/HIVE-10176.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12797309","id":"12797309","filename":"HIVE-10176.10.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-06T13:59:03.449+0000","size":32844,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12797309/HIVE-10176.10.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12798733","id":"12798733","filename":"HIVE-10176.11.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-14T13:46:38.967+0000","size":32844,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12798733/HIVE-10176.11.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12800565","id":"12800565","filename":"HIVE-10176.12.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-25T17:07:28.893+0000","size":38427,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12800565/HIVE-10176.12.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12800569","id":"12800569","filename":"HIVE-10176.13.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-25T17:14:23.712+0000","size":38519,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12800569/HIVE-10176.13.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12800836","id":"12800836","filename":"HIVE-10176.14.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-26T18:08:04.167+0000","size":40097,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12800836/HIVE-10176.14.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803104","id":"12803104","filename":"HIVE-10176.15.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-09T22:32:43.448+0000","size":41297,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12803104/HIVE-10176.15.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803224","id":"12803224","filename":"HIVE-10176.16.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-05-10T12:57:05.619+0000","size":41524,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12803224/HIVE-10176.16.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12792500","id":"12792500","filename":"HIVE-10176.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-10T12:28:58.997+0000","size":2327,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12792500/HIVE-10176.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12793284","id":"12793284","filename":"HIVE-10176.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-14T10:09:10.675+0000","size":2732,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12793284/HIVE-10176.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12793600","id":"12793600","filename":"HIVE-10176.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-15T17:44:55.179+0000","size":2958,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12793600/HIVE-10176.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12794237","id":"12794237","filename":"HIVE-10176.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-18T19:07:09.768+0000","size":17431,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12794237/HIVE-10176.5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12794491","id":"12794491","filename":"HIVE-10176.6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-21T10:54:00.425+0000","size":15165,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12794491/HIVE-10176.6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12795016","id":"12795016","filename":"HIVE-10176.7.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-23T16:14:14.072+0000","size":17311,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12795016/HIVE-10176.7.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12795840","id":"12795840","filename":"HIVE-10176.8.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-29T13:23:29.694+0000","size":32895,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12795840/HIVE-10176.8.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12796278","id":"12796278","filename":"HIVE-10176.9.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-31T10:28:18.835+0000","size":32844,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12796278/HIVE-10176.9.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"skip.header.line.count causes values to be skipped when performing insert values","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wwenbow","name":"wwenbow","key":"wwenbow","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wenbo Wang","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wwenbow","name":"wwenbow","key":"wwenbow","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wenbo Wang","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/14391071","id":"14391071","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wwenbow","name":"wwenbow","key":"wwenbow","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wenbo Wang","active":true,"timeZone":"Etc/UTC"},"body":"data file for reproduction","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wwenbow","name":"wwenbow","key":"wwenbow","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wenbo Wang","active":true,"timeZone":"Etc/UTC"},"created":"2015-04-01T17:49:56.302+0000","updated":"2015-04-01T17:49:56.302+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15187545","id":"15187545","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"Regex used as filter for data inserted by sql query.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-09T18:08:06.638+0000","updated":"2016-03-09T18:08:06.638+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15189216","id":"15189216","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"I changed regex in view of bucketed tables.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-10T12:28:59.001+0000","updated":"2016-03-10T12:28:59.001+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15194279","id":"15194279","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12793284/HIVE-10176.3.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7267/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7267/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7267/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]\n+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera\n+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera\n+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin\n+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ cd /data/hive-ptest/working/\n+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-7267/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ cd apache-github-source-source\n+ git fetch origin\nFrom https://github.com/apache/hive\n   214e4b6..1c44f4c  branch-1   -> origin/branch-1\n   d4c1fdc..b6af012  master     -> origin/master\n+ git reset --hard HEAD\nHEAD is now at d4c1fdc HIVE-13251: hive can't read the decimal in AVRO file generated from previous version (Reviewed by Szehon Ho)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is behind 'origin/master' by 2 commits, and can be fast-forwarded.\n+ git reset --hard origin/master\nHEAD is now at b6af012 HIVE-13201 : Compaction shouldn't be allowed on non-ACID table (Wei Zheng, reviewed by Alan Gates)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ git gc\n+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hive-ptest/working/scratch/build.patch\n+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]\n+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12793284 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-03-14T22:18:11.164+0000","updated":"2016-03-14T22:18:11.164+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15199364","id":"15199364","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12793600/HIVE-10176.4.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7290/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7290/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7290/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] ------------------------------------------------------------------------\n[INFO] Building Spark Remote Client 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-client ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ spark-client ---\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-client ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ spark-client ---\n[INFO] Compiling 28 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java uses or overrides a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n     [copy] Copying 16 files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-client ---\n[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/test-classes\n[INFO] \n[INFO] --- maven-dependency-plugin:2.8:copy (copy-guava-14) @ spark-client ---\n[INFO] Configured Artifact: com.google.guava:guava:14.0.1:jar\n[INFO] Copying guava-14.0.1.jar to /data/hive-ptest/working/apache-github-source-source/spark-client/target/dependency/guava-14.0.1.jar\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ spark-client ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ spark-client ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ spark-client ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ spark-client ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Query Language 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-exec ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\nGenerating vector expression code\nGenerating vector expression test code\n[INFO] Executed tasks\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/thrift/gen-javabean added.\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java added.\n[INFO] \n[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---\n[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-github-source-source/ql/src/java\nANTLR Parser Generator  Version 3.4\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 2674 source files to /data/hive-ptest/working/apache-github-source-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java:[328,9] cannot find symbol\n  symbol: variable targetInputSplit\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java:[329,46] cannot find symbol\n  symbol: variable targetInputSplit\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java:[465,16] cannot find symbol\n  symbol:   variable targetInputSplit\n  location: class org.apache.hadoop.hive.ql.exec.FetchOperator\n[INFO] 3 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [10.184s]\n[INFO] Hive Shims Common ................................. SUCCESS [16.142s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [11.842s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [3.137s]\n[INFO] Hive Shims ........................................ SUCCESS [2.511s]\n[INFO] Hive Storage API .................................. SUCCESS [6.823s]\n[INFO] Hive ORC .......................................... SUCCESS [10.564s]\n[INFO] Hive Common ....................................... SUCCESS [26.292s]\n[INFO] Hive Serde ........................................ SUCCESS [14.486s]\n[INFO] Hive Metastore .................................... SUCCESS [50.923s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [1.961s]\n[INFO] Hive Llap Common .................................. SUCCESS [14.997s]\n[INFO] Hive Llap Client .................................. SUCCESS [9.234s]\n[INFO] Hive Llap Tez ..................................... SUCCESS [14.339s]\n[INFO] Hive Service RPC .................................. SUCCESS [9.445s]\n[INFO] Spark Remote Client ............................... SUCCESS [17.192s]\n[INFO] Hive Query Language ............................... FAILURE [1:04.896s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive ODBC ......................................... SKIPPED\n[INFO] Hive Llap Server .................................. SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 4:48.407s\n[INFO] Finished at: Thu Mar 17 07:40:38 EDT 2016\n[INFO] Final Memory: 153M/1107M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-2\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java:[328,9] cannot find symbol\n[ERROR] symbol: variable targetInputSplit\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java:[329,46] cannot find symbol\n[ERROR] symbol: variable targetInputSplit\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java:[465,16] cannot find symbol\n[ERROR] symbol:   variable targetInputSplit\n[ERROR] location: class org.apache.hadoop.hive.ql.exec.FetchOperator\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12793600 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-03-17T11:40:40.115+0000","updated":"2016-03-17T11:40:40.115+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15201978","id":"15201978","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"Now temporary file is created before LOAD within which the header and footer are removed. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-18T19:07:09.773+0000","updated":"2016-03-18T19:07:09.773+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15203866","id":"15203866","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12794237/HIVE-10176.5.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7327/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7327/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7327/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]\n+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera\n+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera\n+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin\n+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ cd /data/hive-ptest/working/\n+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-7327/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at a0a5371 HIVE-13125: Support masking and filtering of rows/columns (Pengcheng Xiong, reviewed by Ashutosh Chauhan)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\n+ git reset --hard origin/master\nHEAD is now at a0a5371 HIVE-13125: Support masking and filtering of rows/columns (Pengcheng Xiong, reviewed by Ashutosh Chauhan)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ git gc\n+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hive-ptest/working/scratch/build.patch\n+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]\n+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12794237 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-03-21T07:49:43.527+0000","updated":"2016-03-21T07:49:43.527+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15207456","id":"15207456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12794491/HIVE-10176.6.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7339/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7339/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7339/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-service-rpc ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/service-rpc/target/hive-service-rpc-2.1.0-SNAPSHOT-tests.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-service-rpc ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/service-rpc/target/hive-service-rpc-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service-rpc/2.1.0-SNAPSHOT/hive-service-rpc-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/service-rpc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-service-rpc/2.1.0-SNAPSHOT/hive-service-rpc-2.1.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/service-rpc/target/hive-service-rpc-2.1.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service-rpc/2.1.0-SNAPSHOT/hive-service-rpc-2.1.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Spark Remote Client 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-client ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ spark-client ---\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-client ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ spark-client ---\n[INFO] Compiling 28 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java uses or overrides a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n     [copy] Copying 16 files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-client ---\n[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/test-classes\n[INFO] \n[INFO] --- maven-dependency-plugin:2.8:copy (copy-guava-14) @ spark-client ---\n[INFO] Configured Artifact: com.google.guava:guava:14.0.1:jar\n[INFO] Copying guava-14.0.1.jar to /data/hive-ptest/working/apache-github-source-source/spark-client/target/dependency/guava-14.0.1.jar\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ spark-client ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ spark-client ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ spark-client ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ spark-client ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Query Language 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-exec ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\nGenerating vector expression code\nGenerating vector expression test code\n[INFO] Executed tasks\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/thrift/gen-javabean added.\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java added.\n[INFO] \n[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---\n[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-github-source-source/ql/src/java\nANTLR Parser Generator  Version 3.4\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 2674 source files to /data/hive-ptest/working/apache-github-source-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java:[341,65] cannot find symbol\n  symbol:   method getHoldDDLTime()\n  location: variable tbd of type org.apache.hadoop.hive.ql.plan.LoadTableDesc\n[INFO] 1 error\n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [14.724s]\n[INFO] Hive Shims Common ................................. SUCCESS [19.366s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [15.668s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [2.624s]\n[INFO] Hive Shims ........................................ SUCCESS [2.968s]\n[INFO] Hive Storage API .................................. SUCCESS [8.033s]\n[INFO] Hive ORC .......................................... SUCCESS [13.983s]\n[INFO] Hive Common ....................................... SUCCESS [27.205s]\n[INFO] Hive Serde ........................................ SUCCESS [15.361s]\n[INFO] Hive Metastore .................................... SUCCESS [51.458s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [1.829s]\n[INFO] Hive Llap Common .................................. SUCCESS [16.940s]\n[INFO] Hive Llap Client .................................. SUCCESS [8.522s]\n[INFO] Hive Llap Tez ..................................... SUCCESS [8.131s]\n[INFO] Hive Service RPC .................................. SUCCESS [5.467s]\n[INFO] Spark Remote Client ............................... SUCCESS [9.827s]\n[INFO] Hive Query Language ............................... FAILURE [1:14.416s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive Llap Server .................................. SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 5:00.151s\n[INFO] Finished at: Tue Mar 22 18:43:08 EDT 2016\n[INFO] Final Memory: 169M/1274M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-2\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java:[341,65] cannot find symbol\n[ERROR] symbol:   method getHoldDDLTime()\n[ERROR] location: variable tbd of type org.apache.hadoop.hive.ql.plan.LoadTableDesc\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12794491 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-03-22T22:43:11.180+0000","updated":"2016-03-22T22:43:11.180+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15212856","id":"15212856","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12795016/HIVE-10176.7.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 9863 tests executed\n*Failed tests:*\n{noformat}\nTestSparkCliDriver-groupby3_map.q-sample2.q-auto_join14.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-groupby_map_ppr_multi_distinct.q-table_access_keys_stats.q-groupby4_noskew.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-join_rc.q-insert1.q-vectorized_rcfile_columnar.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-ppd_join4.q-join9.q-ppd_join3.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skiphf_aggr\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_file_with_header_footer\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_file_with_header_footer\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testNegativeCliDriver_file_with_header_footer_negative\norg.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorTimestampExpressions.testVectorUDFMonthString\norg.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorTimestampExpressions.testVectorUDFMonthTimestamp\norg.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorTimestampExpressions.testVectorUDFYearString\norg.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorTimestampExpressions.testVectorUDFYearTimestamp\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7373/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7373/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7373/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 12 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12795016 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-03-26T07:13:01.580+0000","updated":"2016-03-26T07:13:01.580+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15219277","id":"15219277","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12795840/HIVE-10176.8.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7420/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7420/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7420/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service-rpc ---\n[INFO] No sources to compile\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service-rpc ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-service-rpc ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/service-rpc/target/hive-service-rpc-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-service-rpc ---\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-service-rpc ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/service-rpc/target/hive-service-rpc-2.1.0-SNAPSHOT-tests.jar\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-service-rpc ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/service-rpc/target/hive-service-rpc-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service-rpc/2.1.0-SNAPSHOT/hive-service-rpc-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/service-rpc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-service-rpc/2.1.0-SNAPSHOT/hive-service-rpc-2.1.0-SNAPSHOT.pom\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/service-rpc/target/hive-service-rpc-2.1.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service-rpc/2.1.0-SNAPSHOT/hive-service-rpc-2.1.0-SNAPSHOT-tests.jar\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Spark Remote Client 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-client ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ spark-client ---\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-client ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ spark-client ---\n[INFO] Compiling 28 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java uses or overrides a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n     [copy] Copying 16 files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-client ---\n[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/test-classes\n[INFO] \n[INFO] --- maven-dependency-plugin:2.8:copy (copy-guava-14) @ spark-client ---\n[INFO] Configured Artifact: com.google.guava:guava:14.0.1:jar\n[INFO] Copying guava-14.0.1.jar to /data/hive-ptest/working/apache-github-source-source/spark-client/target/dependency/guava-14.0.1.jar\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ spark-client ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ spark-client ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ spark-client ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ spark-client ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Query Language 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-exec ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\nGenerating vector expression code\nGenerating vector expression test code\n[INFO] Executed tasks\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/thrift/gen-javabean added.\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java added.\n[INFO] \n[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---\n[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-github-source-source/ql/src/java\nANTLR Parser Generator  Version 3.4\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 2622 source files to /data/hive-ptest/working/apache-github-source-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java:[475,28] not a statement\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java:[475,50] ';' expected\n[INFO] 2 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [12.493s]\n[INFO] Hive Shims Common ................................. SUCCESS [17.773s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [13.649s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [2.810s]\n[INFO] Hive Shims ........................................ SUCCESS [2.939s]\n[INFO] Hive Storage API .................................. SUCCESS [7.606s]\n[INFO] Hive ORC .......................................... SUCCESS [11.545s]\n[INFO] Hive Common ....................................... SUCCESS [25.700s]\n[INFO] Hive Serde ........................................ SUCCESS [15.896s]\n[INFO] Hive Metastore .................................... SUCCESS [54.834s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [1.616s]\n[INFO] Hive Llap Common .................................. SUCCESS [13.092s]\n[INFO] Hive Llap Client .................................. SUCCESS [5.428s]\n[INFO] Hive Llap Tez ..................................... SUCCESS [6.962s]\n[INFO] Hive Service RPC .................................. SUCCESS [8.815s]\n[INFO] Spark Remote Client ............................... SUCCESS [15.307s]\n[INFO] Hive Query Language ............................... FAILURE [56.037s]\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive Llap Server .................................. SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 4:37.585s\n[INFO] Finished at: Wed Mar 30 23:40:41 EDT 2016\n[INFO] Final Memory: 118M/780M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-2\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java:[475,28] not a statement\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java:[475,50] ';' expected\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12795840 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-03-31T03:40:43.774+0000","updated":"2016-03-31T03:40:43.774+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15223072","id":"15223072","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12796278/HIVE-10176.9.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9944 tests executed\n*Failed tests:*\n{noformat}\nTestMiniTezCliDriver-schema_evol_text_nonvec_mapwork_table.q-vector_left_outer_join2.q-vector_outer_join5.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7447/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7447/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7447/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 2 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12796278 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-04-02T22:53:47.151+0000","updated":"2016-04-02T22:53:47.151+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15226105","id":"15226105","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"The tests are not executed locally, when I checkout on master branch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-05T11:42:25.515+0000","updated":"2016-04-05T11:42:25.515+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15231496","id":"15231496","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12797309/HIVE-10176.10.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9978 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7505/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7505/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7505/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 2 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12797309 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-04-08T02:06:59.449+0000","updated":"2016-04-08T02:06:59.449+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15234889","id":"15234889","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"All the 2 failures are not related:","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-11T11:14:34.908+0000","updated":"2016-04-11T11:14:34.908+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15234891","id":"15234891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"All the 2 failures are not related:\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery.\nNeed code review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-11T11:17:26.802+0000","updated":"2016-04-11T11:17:26.802+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15244426","id":"15244426","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12798733/HIVE-10176.11.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 9956 tests executed\n*Failed tests:*\n{noformat}\nTestMiniTezCliDriver-vector_acid3.q-vector_decimal_trailing.q-lvj_mapjoin.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas\norg.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping\norg.apache.hive.jdbc.TestSSL.testSSLFetchHttp\norg.apache.hive.spark.client.TestSparkClient.testRemoteClient\n{noformat}\n\nTest results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7621/testReport\nConsole output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7621/console\nTest logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7621/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 8 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12798733 - PreCommit-HIVE-TRUNK-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-04-16T22:01:22.202+0000","updated":"2016-04-16T22:01:22.202+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15250361","id":"15250361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you create a ReviewBoard entry for this? Also, can you comment why you chose to create a new temp file and write data into it. This doesnt look efficient way of dealing with the problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T17:49:27.963+0000","updated":"2016-04-20T17:49:27.963+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15256600","id":"15256600","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"[~ashutoshc]\nI created one before: https://reviews.apache.org/r/46020. Yes, I agree with you that my deсision wasn't optimal. I had faced several problems in the beginning that is why I decided to create temp file for this issue. I know now how to solve it. That is why I do not create temp file in the new patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-25T17:07:08.602+0000","updated":"2016-04-25T17:07:08.602+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15256613","id":"15256613","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"Forget delete file if it in hdfs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-25T17:14:23.717+0000","updated":"2016-04-25T17:14:23.717+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15256645","id":"15256645","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"I like new patch. It makes sense to deal with files containing header/footer separately then trying to conflate logic with files not containing those. Had a question on RB. Other than that looks good. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-25T17:27:12.963+0000","updated":"2016-04-25T17:27:12.963+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15258586","id":"15258586","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"Ok, I do what you ask. About question from RB, I found related ticked: https://issues.apache.org/jira/browse/HIVE-11996. Table doesn't have properties \"line.delimiter\" or equals. And I don't found workaround for it problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-26T18:08:04.171+0000","updated":"2016-04-26T18:08:04.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15259209","id":"15259209","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12800836/HIVE-10176.14.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/91/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/91/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-91/\n\nMessages:\n{noformat}\n**** This message was trimmed, see log for full details ****\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Spark Remote Client 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-client ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/spark-client (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ spark-client ---\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-client ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ spark-client ---\n[INFO] Compiling 28 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/classes\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java uses or overrides a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/SparkClientUtilities.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/spark-client/src/main/java/org/apache/hive/spark/client/rpc/RpcDispatcher.java: Recompile with -Xlint:unchecked for details.\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark-client ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 1 resource\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ spark-client ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/warehouse\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n     [copy] Copying 15 files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-client ---\n[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/test-classes\n[INFO] \n[INFO] --- maven-dependency-plugin:2.8:copy (copy-guava-14) @ spark-client ---\n[INFO] Configured Artifact: com.google.guava:guava:14.0.1:jar\n[INFO] Copying guava-14.0.1.jar to /data/hive-ptest/working/apache-github-source-source/spark-client/target/dependency/guava-14.0.1.jar\n[INFO] \n[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ spark-client ---\n[INFO] Tests are skipped.\n[INFO] \n[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ spark-client ---\n[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] \n[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ spark-client ---\n[INFO] \n[INFO] --- maven-install-plugin:2.4:install (default-install) @ spark-client ---\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.1.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.jar\n[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/spark-client/2.1.0-SNAPSHOT/spark-client-2.1.0-SNAPSHOT.pom\n[INFO]                                                                         \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Hive Query Language 2.1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\n[INFO] \n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql/target\n[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql (includes = [datanucleus.log, derby.log], excludes = [])\n[INFO] \n[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-exec ---\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen\n    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen\nGenerating vector expression code\nGenerating vector expression test code\n[INFO] Executed tasks\n[INFO] \n[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/thrift/gen-javabean added.\n[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java added.\n[INFO] \n[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---\n[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-github-source-source/ql/src/java\nANTLR Parser Generator  Version 3.4\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\n[INFO] \n[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---\n[INFO] \n[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\n[INFO] Copying 4 resources\n[INFO] Copying 3 resources\n[INFO] \n[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---\n[INFO] Executing tasks\n\nmain:\n[INFO] Executed tasks\n[INFO] \n[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---\n[INFO] Compiling 2623 source files to /data/hive-ptest/working/apache-github-source-source/ql/target/classes\n[INFO] -------------------------------------------------------------\n[WARNING] COMPILATION WARNING : \n[INFO] -------------------------------------------------------------\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Some input files use or override a deprecated API.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkPartitionPruningSinkOperator.java: Recompile with -Xlint:deprecation for details.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Some input files use unchecked or unsafe operations.\n[WARNING] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java: Recompile with -Xlint:unchecked for details.\n[INFO] 4 warnings \n[INFO] -------------------------------------------------------------\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[1534,30] cannot find symbol\n  symbol:   method getHiveOperation()\n  location: class org.apache.hadoop.hive.ql.session.SessionState\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[1539,16] method getProperty in class org.apache.hadoop.hive.ql.metadata.Table cannot be applied to given types;\n  required: java.lang.String\n  found: no arguments\n  reason: actual and formal argument lists differ in length\n[INFO] 2 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Hive .............................................. SUCCESS [2.553s]\n[INFO] Hive Shims Common ................................. SUCCESS [4.667s]\n[INFO] Hive Shims 0.23 ................................... SUCCESS [3.320s]\n[INFO] Hive Shims Scheduler .............................. SUCCESS [0.944s]\n[INFO] Hive Shims ........................................ SUCCESS [0.742s]\n[INFO] Hive Storage API .................................. SUCCESS [1.637s]\n[INFO] Hive ORC .......................................... SUCCESS [2.589s]\n[INFO] Hive Common ....................................... SUCCESS [7.034s]\n[INFO] Hive Service RPC .................................. SUCCESS [2.782s]\n[INFO] Hive Serde ........................................ SUCCESS [3.511s]\n[INFO] Hive Metastore .................................... SUCCESS [17.816s]\n[INFO] Hive Ant Utilities ................................ SUCCESS [0.528s]\n[INFO] Hive Llap Common .................................. SUCCESS [4.288s]\n[INFO] Hive Llap Client .................................. SUCCESS [1.110s]\n[INFO] Hive Llap Tez ..................................... SUCCESS [1.262s]\n[INFO] Spark Remote Client ............................... SUCCESS [2.737s]\n[INFO] Hive Query Language ............................... FAILURE [23.106s]\n[INFO] Hive Llap Server .................................. SKIPPED\n[INFO] Hive Service ...................................... SKIPPED\n[INFO] Hive Accumulo Handler ............................. SKIPPED\n[INFO] Hive JDBC ......................................... SKIPPED\n[INFO] Hive Beeline ...................................... SKIPPED\n[INFO] Hive CLI .......................................... SKIPPED\n[INFO] Hive Contrib ...................................... SKIPPED\n[INFO] Hive HBase Handler ................................ SKIPPED\n[INFO] Hive HCatalog ..................................... SKIPPED\n[INFO] Hive HCatalog Core ................................ SKIPPED\n[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED\n[INFO] Hive HCatalog Server Extensions ................... SKIPPED\n[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED\n[INFO] Hive HCatalog Webhcat ............................. SKIPPED\n[INFO] Hive HCatalog Streaming ........................... SKIPPED\n[INFO] Hive HPL/SQL ...................................... SKIPPED\n[INFO] Hive HWI .......................................... SKIPPED\n[INFO] Hive Shims Aggregator ............................. SKIPPED\n[INFO] Hive TestUtils .................................... SKIPPED\n[INFO] Hive Packaging .................................... SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:21.596s\n[INFO] Finished at: Tue Apr 26 23:50:36 GMT 2016\n[INFO] Final Memory: 121M/1102M\n[INFO] ------------------------------------------------------------------------\n[WARNING] The requested profile \"hadoop-1\" could not be activated because it does not exist.\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[1534,30] cannot find symbol\n[ERROR] symbol:   method getHiveOperation()\n[ERROR] location: class org.apache.hadoop.hive.ql.session.SessionState\n[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[1539,16] method getProperty in class org.apache.hadoop.hive.ql.metadata.Table cannot be applied to given types;\n[ERROR] required: java.lang.String\n[ERROR] found: no arguments\n[ERROR] reason: actual and formal argument lists differ in length\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12800836 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-04-26T23:50:26.102+0000","updated":"2016-04-26T23:50:26.102+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15274563","id":"15274563","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lmephistol]  Looks like patch doesnt apply cleanly and needs to be rebased.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-06T18:50:17.056+0000","updated":"2016-05-06T18:50:17.056+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15278046","id":"15278046","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"body":"Fixed double copy in patch in case when file has a footer or/and header.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lmephistol","name":"lmephistol","key":"lmephistol","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=lmephistol&avatarId=26263","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=lmephistol&avatarId=26263","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=lmephistol&avatarId=26263","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=lmephistol&avatarId=26263"},"displayName":"Vladyslav Pavlenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-05-10T12:57:05.624+0000","updated":"2016-05-10T12:57:05.624+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15278297","id":"15278297","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you update RB also?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-10T15:38:23.215+0000","updated":"2016-05-10T15:38:23.215+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15278343","id":"15278343","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-10T16:02:22.435+0000","updated":"2016-05-10T16:02:22.435+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15280345","id":"15280345","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12803224/HIVE-10176.16.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 111 failed/errored test(s), 9882 tests executed\n*Failed tests:*\n{noformat}\nTestCliDriver-gen_udf_example_add10.q-ppd_join4.q-union27.q-and-12-more - did not produce a TEST-*.xml file\nTestCliDriver-partition_timestamp.q-ppd_random.q-vector_outer_join5.q-and-12-more - did not produce a TEST-*.xml file\nTestCliDriver-ptf_general_queries.q-unionDistinct_1.q-groupby1_noskew.q-and-12-more - did not produce a TEST-*.xml file\nTestHBaseAggrStatsCacheIntegration - did not produce a TEST-*.xml file\nTestHWISessionManager - did not produce a TEST-*.xml file\nTestMiniLlapCliDriver - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-enforce_order.q-vector_partition_diff_num_cols.q-unionDistinct_1.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-join1.q-schema_evol_orc_nonvec_mapwork_part.q-mapjoin_decimal.q-and-12-more - did not produce a TEST-*.xml file\nTestMiniTezCliDriver-mapjoin_mapjoin.q-insert_into1.q-vector_decimal_2.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-auto_join30.q-join2.q-input17.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-bucketsortoptimize_insert_7.q-smb_mapjoin_15.q-mapreduce1.q-and-12-more - did not produce a TEST-*.xml file\nTestSparkCliDriver-skewjoinopt3.q-union27.q-multigroupby_singlemr.q-and-12-more - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_11\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_4\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_7\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_8\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucket_map_join_spark1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucket_map_join_spark2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucket_map_join_spark3\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_3\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_4\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_6\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_7\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_8\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketizedhiveinputformat_auto\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin1\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin10\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin11\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin12\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin3\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin5\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin8\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin9\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin_negative\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin_negative2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_global_limit\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input40\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_insert2_overwrite_partitions\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_merge_dynamic_partition\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_merge_dynamic_partition2\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_merge_dynamic_partition3\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_merge_dynamic_partition4\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_merge_dynamic_partition5\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mergejoin\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats11\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats18\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_bucketmapjoin7\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_1\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_12\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_2\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_4\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_7\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_8\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez1\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez2\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning_2\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_2\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_fsstat\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_smb_1\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_smb_main\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucketmapjoin7\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_bucket_mapjoin_mismatch1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_4\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_spark1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_spark2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_spark3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin1\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin10\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin11\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin12\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin3\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin5\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin7\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin8\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin9\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative2\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats18\norg.apache.hadoop.hive.llap.daemon.impl.comparator.TestShortestJobFirstComparator.testWaitQueueComparatorWithinDagPriority\norg.apache.hadoop.hive.llap.tez.TestConverters.testFragmentSpecToTaskSpec\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure\norg.apache.hadoop.hive.llap.tezplugins.TestLlapTaskSchedulerService.testDelayedLocalityNodeCommErrorImmediateAllocation\norg.apache.hadoop.hive.metastore.TestMetaStoreEndFunctionListener.testEndFunctionListener\norg.apache.hadoop.hive.metastore.TestMetaStoreInitListener.testMetaStoreInitListener\norg.apache.hadoop.hive.metastore.hbase.TestHBaseSchemaTool.oneMondoTest\norg.apache.hadoop.hive.ql.exec.tez.TestDynamicPartitionPruner.testSingleSourceMultipleFiltersOrdering1\norg.apache.hadoop.hive.ql.security.TestClientSideAuthorizationProvider.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestExtendedAcls.org.apache.hadoop.hive.ql.security.TestExtendedAcls\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadDbSuccess\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationReads.testReadTableFailure\norg.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc.org.apache.hive.minikdc.TestJdbcNonKrbSASLWithMiniKdc\norg.apache.hive.service.TestHS2ImpersonationWithRemoteMS.org.apache.hive.service.TestHS2ImpersonationWithRemoteMS\norg.apache.hive.service.cli.session.TestHiveSessionImpl.testLeakOperationHandle\n{noformat}\n\nTest results: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/237/testReport\nConsole output: http://ec2-54-177-240-2.us-west-1.compute.amazonaws.com/job/PreCommit-HIVE-MASTER-Build/237/console\nTest logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-237/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 111 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12803224 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-05-11T16:10:43.341+0000","updated":"2016-05-11T16:10:43.341+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15291476","id":"15291476","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"[~lmephistol] Are any of the reported failures related to patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-19T16:41:26.965+0000","updated":"2016-05-19T16:41:26.965+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15297576","id":"15297576","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"Reported failures looks related.\n{code}\norg.apache.hadoop.hive.ql.parse.SemanticException: Bucketed table metadata is not correct. Fix the metadata or don't use bucketed mapjoin, by setting hive.enforce.bucketmapjoin to false. The number of buckets for table bucket_small partition ds=2008-04-08 is 2, whereas the number of files is 1\n        at org.apache.hadoop.hive.ql.optimizer.AbstractBucketJoinProc.checkConvertBucketMapJoin(AbstractBucketJoinProc.java:290)\n        at org.apache.hadoop.hive.ql.optimizer.AbstractSMBJoinProc.canConvertJoinToBucketMapJoin(AbstractSMBJoinProc.java:497)\n        at org.apache.hadoop.hive.ql.optimizer.AbstractSMBJoinProc.canConvertJoinToSMBJoin(AbstractSMBJoinProc.java:414)\n        at org.apache.hadoop.hive.ql.optimizer.SortedMergeJoinProc.process(SortedMergeJoinProc.java:45)\n        at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:158)\n        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120)\n        at org.apache.hadoop.hive.ql.optimizer.SortedMergeBucketMapJoinOptimizer.transform(SortedMergeBucketMapJoinOptimizer.java:109)\n        at org.apache.hadoop.hive.ql.optimizer.Optimizer.optimize(Optimizer.java:244)\n        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10745)\n        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:236)\n        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:250)\n        at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:75)\n        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:250)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:437)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:329)\n        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1157)\n        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1252)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1083)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1071)\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:232)\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:183)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:399)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:335)\n        at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1137)\n        at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1111)\n        at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:135)\n        at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_11(TestCliDriver.java:108)\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-24T03:00:05.614+0000","updated":"2016-05-24T03:00:05.614+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15300381","id":"15300381","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jcamachorodriguez","name":"jcamachorodriguez","key":"jcamachorodriguez","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jesus Camacho Rodriguez","active":true,"timeZone":"America/Los_Angeles"},"body":"Removing 2.1.0 target. Please feel free to commit to branch-2.1 anyway and fix for 2.1.0 if this happens before the release.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jcamachorodriguez","name":"jcamachorodriguez","key":"jcamachorodriguez","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jesus Camacho Rodriguez","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-25T16:31:33.371+0000","updated":"2016-05-25T16:31:33.371+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12787256/comment/15941986","id":"15941986","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pxiong","name":"pxiong","key":"pxiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pengcheng Xiong","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello, I am deferring this to Hive 3.0 as we are going to cut the first RC and it is not marked as blocker. Please feel free to commit to the branch if this can be resolved before the release.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pxiong","name":"pxiong","key":"pxiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Pengcheng Xiong","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-03-25T21:35:38.259+0000","updated":"2017-03-25T21:35:38.259+0000"}],"maxResults":31,"total":31,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-10176/votes","votes":4,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i27mov:"}}