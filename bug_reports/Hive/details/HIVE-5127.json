{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12664743","self":"https://issues.apache.org/jira/rest/api/2/issue/12664743","key":"HIVE-5127","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2013-09-07T02:52:31.132+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Oct 15 23:31:23 UTC 2013","customfield_12310420":"344686","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_594490717_*|*_1_*:*_1_*:*_1473308634_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-09-13T22:30:41.960+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5127/watchers","watchCount":4,"isWatching":false},"created":"2013-08-21T00:07:22.634+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324312","id":"12324312","description":"released","name":"0.12.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-01-21T18:39:10.586+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320912","id":"12320912","name":"WebHCat","description":"Provides rest interface for HCatalog "}],"timeoriginalestimate":null,"description":"Currently webhcat log files are full of exceptions like this, which obscures the real output and may cause perf issues.\n\nUpgrading to more recent versions of xerces/xalan fixes this.\n\nAdd the following to hive/hcatalog/webhcat/svr/pom.xml\n        <dependency>\n            <groupId>xerces</groupId>\n            <artifactId>xercesImpl</artifactId>\n            <version>2.9.1</version>\n        </dependency>\n\n13/08/20 16:54:04 ERROR conf.Configuration: Failed to set setXIncludeAware(true) for parser org.apache.xerces.jaxp.DocumentBuilderFactoryImpl@48dbb335:java.lang.UnsupportedOperationException: This parser does not support specification \"null\" version \"null\"\njava.lang.UnsupportedOperationException: This parser does not support specification \"null\" version \"null\"\n        at javax.xml.parsers.DocumentBuilderFactory.setXIncludeAware(DocumentBuilderFactory.java:590)\n        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1892)\n        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1861)\n        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1778)\n        at org.apache.hadoop.conf.Configuration.get(Configuration.java:870)\n        at org.apache.hadoop.fs.FileSystem.getDefaultUri(FileSystem.java:171)\n        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:305)\n        at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:288)\n        at org.apache.hadoop.util.GenericOptionsParser.validateFiles(GenericOptionsParser.java:383)\n        at org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:281)\n        at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:422)\n        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:168)\n        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:151)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:64)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)\n        at org.apache.hcatalog.templeton.LauncherDelegator$1.run(LauncherDelegator.java:99)\n        at org.apache.hcatalog.templeton.LauncherDelegator$1.run(LauncherDelegator.java:95)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1441)\n        at org.apache.hcatalog.templeton.LauncherDelegator.queueAsUser(LauncherDelegator.java:95)\n        at org.apache.hcatalog.templeton.LauncherDelegator.enqueueController(LauncherDelegator.java:77)\n        at org.apache.hcatalog.templeton.JarDelegator.run(JarDelegator.java:52)\n        at org.apache.hcatalog.templeton.StreamingDelegator.run(StreamingDelegator.java:53)\n        at org.apache.hcatalog.templeton.Server.mapReduceStreaming(Server.java:596)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1480)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1411)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1360)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1350)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:538)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:716)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:847)\n        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:565)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1360)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:384)\n        at org.apache.hadoop.hdfs.web.AuthFilter.doFilter(AuthFilter.java:85)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1331)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:477)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1031)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:406)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:965)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117)\n        at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:47)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:111)\n        at org.eclipse.jetty.server.Server.handle(Server.java:349)\n        at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:449)\n        at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:925)\n        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:857)\n        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n        at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:76)\n        at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:609)\n        at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:45)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:599)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:534)\n        at java.lang.Thread.run(Thread.java:680)\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12601945","id":"12601945","filename":"HIVE-5127.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-07T01:22:17.487+0000","size":736,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12601945/HIVE-5127.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"344986","customfield_12312823":null,"summary":"Upgrade xerces and xalan for WebHCat","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13760844","id":"13760844","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"Turns out only Xerces needs to be upgrade.  Ran WebHCat e2e tests - exception is gone.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-07T01:22:17.490+0000","updated":"2013-09-07T01:22:17.490+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13760890","id":"13760890","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\n{color:red}Overall{color}: -1 no tests executed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12601945/HIVE-5127.patch\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/653/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/653/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests failed with: NonZeroExitCodeException: Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n '' ]]\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'\n+ cd /data/hive-ptest/working/\n+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-653/source-prep.txt\n+ mkdir -p maven ivy\n+ [[ svn = \\s\\v\\n ]]\n+ [[ -n '' ]]\n+ [[ -d apache-svn-trunk-source ]]\n+ [[ ! -d apache-svn-trunk-source/.svn ]]\n+ [[ ! -d apache-svn-trunk-source ]]\n+ cd apache-svn-trunk-source\n+ svn revert -R .\n++ awk '{print $2}'\n++ egrep -v '^X|^Performing status on external'\n++ svn status --no-ignore\n+ rm -rf\n+ svn update\n\nFetching external item into 'hcatalog/src/test/e2e/harness'\nExternal at revision 1520721.\n\nAt revision 1520721.\n+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hive-ptest/working/scratch/build.patch\n+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]\n+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh\n+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch\nGoing to apply patch with: patch -p0\npatching file hcatalog/webhcat/svr/pom.xml\n+ [[ true == \\t\\r\\u\\e ]]\n+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven\n+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven\n+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing\nBuildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml\n\nclean:\n     [echo] Project: hive\n\nclean:\n     [echo] Project: anttasks\n\nclean:\n     [echo] Project: shims\n\nclean:\n     [echo] Project: common\n\nclean:\n     [echo] Project: serde\n\nclean:\n     [echo] Project: metastore\n\nclean:\n     [echo] Project: ql\n\nclean:\n     [echo] Project: contrib\n\nclean:\n     [echo] Project: service\n\nclean:\n     [echo] Project: cli\n\nclean:\n     [echo] Project: jdbc\n\nclean:\n     [echo] Project: beeline\n\nclean:\n     [echo] Project: hwi\n\nclean:\n     [echo] Project: hbase-handler\n\nclean:\n     [echo] Project: testutils\n\nclean:\n     [echo] hcatalog\n\nclean:\n     [echo] hcatalog-core\n\nclean:\n     [echo] hcatalog-pig-adapter\n\nclean:\n     [echo] hcatalog-server-extensions\n\nclean:\n     [echo] webhcat\n\nclean:\n     [echo] webhcat-java-client\n\nclean:\n\nclean:\n     [echo] Project: odbc\n     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs\n\nclean-online:\n     [echo] Project: hive\n\nclean-offline:\n\nivy-init-dirs:\n     [echo] Project: hive\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven\n\nivy-download:\n     [echo] Project: hive\n      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar\n      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar\n\nivy-probe-antlib:\n     [echo] Project: hive\n\nivy-init-antlib:\n     [echo] Project: hive\n\ncompile-ant-tasks:\n     [echo] Project: hive\n\ncreate-dirs:\n     [echo] Project: anttasks\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.\n\ninit:\n     [echo] Project: anttasks\n\nivy-init-settings:\n     [echo] Project: anttasks\n\nivy-resolve:\n     [echo] Project: anttasks\n[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound velocity#velocity;1.5 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...\n[ivy:resolve] ..... (255kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...\n[ivy:resolve] ....... (382kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (36ms)\n[ivy:resolve] :: resolution report :: resolve 5465ms :: artifacts dl 95ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html\n\nivy-retrieve:\n     [echo] Project: anttasks\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t2 artifacts copied, 0 already retrieved (638kB/7ms)\n\ncompile:\n     [echo] anttasks\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds\n    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n\ndeploy-ant-tasks:\n     [echo] Project: hive\n\ncreate-dirs:\n     [echo] Project: anttasks\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.\n\ninit:\n     [echo] Project: anttasks\n\nivy-init-settings:\n     [echo] Project: anttasks\n\nivy-resolve:\n     [echo] Project: anttasks\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound velocity#velocity;1.5 in maven2\n[ivy:resolve] :: resolution report :: resolve 498ms :: artifacts dl 3ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html\n\nivy-retrieve:\n     [echo] Project: anttasks\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t0 artifacts copied, 2 already retrieved (0kB/7ms)\n\ncompile:\n     [echo] anttasks\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds\n\njar:\n     [echo] anttasks\n     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar\n\ninit:\n     [echo] Project: hive\n\ncreate-dirs:\n     [echo] Project: anttasks\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.\n\ninit:\n     [echo] Project: anttasks\n\ncreate-dirs:\n     [echo] Project: shims\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.\n\ninit:\n     [echo] Project: shims\n\ncreate-dirs:\n     [echo] Project: common\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources\n\ninit:\n     [echo] Project: common\n\ncreate-dirs:\n     [echo] Project: serde\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.\n\ninit:\n     [echo] Project: serde\n\ncreate-dirs:\n     [echo] Project: metastore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.\n\ninit:\n     [echo] Project: metastore\n\ncreate-dirs:\n     [echo] Project: ql\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources\n     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources\n\ninit:\n     [echo] Project: ql\n\ncreate-dirs:\n     [echo] Project: contrib\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.\n\ninit:\n     [echo] Project: contrib\n\ncreate-dirs:\n     [echo] Project: service\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.\n\ninit:\n     [echo] Project: service\n\ncreate-dirs:\n     [echo] Project: cli\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.\n\ninit:\n     [echo] Project: cli\n\ncreate-dirs:\n     [echo] Project: jdbc\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.\n\ninit:\n     [echo] Project: jdbc\n\ncreate-dirs:\n     [echo] Project: beeline\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.\n\ninit:\n     [echo] Project: beeline\n\ncreate-dirs:\n     [echo] Project: hwi\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.\n\ninit:\n     [echo] Project: hwi\n\ncreate-dirs:\n     [echo] Project: hbase-handler\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.\n\ninit:\n     [echo] Project: hbase-handler\n\ncreate-dirs:\n     [echo] Project: testutils\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.\n\ninit:\n     [echo] Project: testutils\n\ninit:\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.12.0-SNAPSHOT\n\njar:\n     [echo] Project: hive\n\nivy-init-settings:\n     [echo] Project: shims\n\ncheck-ivy:\n     [echo] Project: shims\n\nivy-resolve:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.zookeeper#zookeeper;3.4.3 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libthrift;0.9.0 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.0.4 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging-api;1.0.4 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound commons-io#commons-io;2.4 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...\n[ivy:resolve] .............. (749kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (39ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...\n[ivy:resolve] ....... (339kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (29ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar ...\n[ivy:resolve] .. (37kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-logging#commons-logging;1.0.4!commons-logging.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...\n[ivy:resolve] .. (25kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...\n[ivy:resolve] ..... (222kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (27ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...\n[ivy:resolve] ............. (652kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...\n[ivy:resolve] ......... (470kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (31ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...\n[ivy:resolve] ............................ (1609kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (50ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...\n[ivy:resolve] .... (180kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (26ms)\n[ivy:resolve] :: resolution report :: resolve 9410ms :: artifacts dl 318ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html\n\nmake-pom:\n     [echo] Project: shims\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: shims\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.\n\ninit:\n     [echo] Project: shims\n\nivy-retrieve:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t9 artifacts copied, 0 already retrieved (4287kB/19ms)\n\ncompile:\n     [echo] Project: shims\n     [echo] Building shims 0.20\n\nbuild-shims:\n     [echo] Project: shims\n     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)\n\nivy-init-settings:\n     [echo] Project: shims\n\nivy-resolve-hadoop-shim:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [hadoop0.20.shim]\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-core;0.20.2 in maven2\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound xmlenc#xmlenc;0.52 in maven2\n[ivy:resolve] \tfound commons-httpclient#commons-httpclient;3.0.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.0.3 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.3 in maven2\n[ivy:resolve] \tfound commons-net#commons-net;1.4.1 in maven2\n[ivy:resolve] \tfound oro#oro;2.0.8 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty-util;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2\n[ivy:resolve] \tfound tomcat#jasper-runtime;5.5.12 in maven2\n[ivy:resolve] \tfound tomcat#jasper-compiler;5.5.12 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.eclipse.jdt#core;3.1.1 in maven2\n[ivy:resolve] \tfound ant#ant;1.6.5 in maven2\n[ivy:resolve] \tfound commons-el#commons-el;1.0 in maven2\n[ivy:resolve] \tfound net.java.dev.jets3t#jets3t;0.7.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.1.1 in maven2\n[ivy:resolve] \tfound net.sf.kosmosfs#kfs;0.3 in maven2\n[ivy:resolve] \tfound junit#junit;4.5 in maven2\n[ivy:resolve] \tfound hsqldb#hsqldb;1.8.0.10 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-tools;0.20.2 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-test;0.20.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftplet-api;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.mina#mina-core;2.0.0-M5 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.5.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-core;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...\n[ivy:resolve] ............................................. (2624kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (91ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...\n[ivy:resolve] ... (68kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...\n[ivy:resolve] .......................... (1527kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (32ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...\n[ivy:resolve] .. (40kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (35ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...\n[ivy:resolve] .. (14kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (34ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...\n[ivy:resolve] ...... (273kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.3/commons-codec-1.3.jar ...\n[ivy:resolve] .. (45kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-codec#commons-codec;1.3!commons-codec.jar (34ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...\n[ivy:resolve] .... (176kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (39ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...\n[ivy:resolve] ......... (504kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (43ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...\n[ivy:resolve] .... (159kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (50ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...\n[ivy:resolve] ... (74kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (37ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...\n[ivy:resolve] ........ (395kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (47ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...\n[ivy:resolve] .... (131kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (36ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...\n[ivy:resolve] .................. (1000kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (57ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...\n[ivy:resolve] ... (109kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (41ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...\n[ivy:resolve] ....... (368kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (64ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...\n[ivy:resolve] .... (129kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...\n[ivy:resolve] .. (11kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (37ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...\n[ivy:resolve] ..... (194kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] junit#junit;4.5!junit.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...\n[ivy:resolve] ............ (690kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (47ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...\n[ivy:resolve] .. (63kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (34ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...\n[ivy:resolve] .................................................................................................. (3483kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (100ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...\n[ivy:resolve] ................. (1009kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (53ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...\n[ivy:resolve] .. (59kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (42ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...\n[ivy:resolve] .. (22kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...\n[ivy:resolve] ........... (622kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (47ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...\n[ivy:resolve] ...... (264kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (78ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...\n[ivy:resolve] .. (31kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (59ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...\n[ivy:resolve] .. (16kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (34ms)\n[ivy:resolve] :: resolution report :: resolve 38865ms :: artifacts dl 1435ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tjunit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]\n[ivy:resolve] \tcommons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]\n[ivy:resolve] \tcommons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.3] in [hadoop0.20.shim]\n[ivy:resolve] \tcommons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|  hadoop0.20.shim |   37  |   30  |   30  |   8   ||   29  |   29  |\n\t---------------------------------------------------------------------\n\nivy-retrieve-hadoop-shim:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [hadoop0.20.shim]\n[ivy:retrieve] \t29 artifacts copied, 0 already retrieved (14115kB/94ms)\n    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n     [echo] Building shims 0.20S\n\nbuild-shims:\n     [echo] Project: shims\n     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)\n\nivy-init-settings:\n     [echo] Project: shims\n\nivy-resolve-hadoop-shim:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [hadoop0.20S.shim]\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-core;1.1.2 in maven2\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound xmlenc#xmlenc;0.52 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-core;1.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-json;1.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jettison#jettison;1.1 in maven2\n[ivy:resolve] \tfound stax#stax-api;1.0.1 in maven2\n[ivy:resolve] \tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2\n[ivy:resolve] \tfound javax.xml.bind#jaxb-api;2.2.2 in maven2\n[ivy:resolve] \tfound javax.xml.stream#stax-api;1.0-2 in maven2\n[ivy:resolve] \tfound javax.activation#activation;1.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-xc;1.7.1 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-server;1.8 in maven2\n[ivy:resolve] \tfound asm#asm;3.1 in maven2\n[ivy:resolve] \tfound commons-io#commons-io;2.1 in maven2\n[ivy:resolve] \tfound commons-httpclient#commons-httpclient;3.0.1 in maven2\n[ivy:resolve] \tfound junit#junit;3.8.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.0.3 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-math;2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.1.1 in maven2\n[ivy:resolve] \tfound commons-digester#commons-digester;1.8 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils;1.7.0 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils-core;1.8.0 in maven2\n[ivy:resolve] \tfound commons-net#commons-net;1.4.1 in maven2\n[ivy:resolve] \tfound oro#oro;2.0.8 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty-util;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#servlet-api;2.5-20081211 in maven2\n[ivy:resolve] \tfound tomcat#jasper-runtime;5.5.12 in maven2\n[ivy:resolve] \tfound tomcat#jasper-compiler;5.5.12 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jsp-2.1;6.1.14 in maven2\n[ivy:resolve] \tfound org.eclipse.jdt#core;3.1.1 in maven2\n[ivy:resolve] \tfound ant#ant;1.6.5 in maven2\n[ivy:resolve] \tfound commons-el#commons-el;1.0 in maven2\n[ivy:resolve] \tfound net.java.dev.jets3t#jets3t;0.6.1 in maven2\n[ivy:resolve] \tfound hsqldb#hsqldb;1.8.0.10 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-tools;1.1.2 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-test;1.1.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftplet-api;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.mina#mina-core;2.0.0-M5 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.5.2 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-core;1.0.0 in maven2\n[ivy:resolve] \tfound org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...\n[ivy:resolve] .......................................................................................................... (3941kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (95ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...\n[ivy:resolve] ...... (299kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (19ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...\n[ivy:resolve] ...................................................... (2712kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (57ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...\n[ivy:resolve] ........ (447kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (43ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...\n[ivy:resolve] .... (144kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (37ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...\n[ivy:resolve] ............ (678kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (53ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...\n[ivy:resolve] .... (159kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...\n[ivy:resolve] .. (56kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (37ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...\n[ivy:resolve] ............... (812kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (49ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...\n[ivy:resolve] ...... (291kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (44ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...\n[ivy:resolve] .......... (527kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (45ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...\n[ivy:resolve] .... (172kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (42ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...\n[ivy:resolve] ...... (314kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (44ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...\n[ivy:resolve] ... (66kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (37ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...\n[ivy:resolve] ................ (869kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (48ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...\n[ivy:resolve] .. (17kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (59ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...\n[ivy:resolve] .. (30kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (51ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...\n[ivy:resolve] .. (25kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (55ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...\n[ivy:resolve] ... (102kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (36ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...\n[ivy:resolve] .. (22kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (39ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...\n[ivy:resolve] .. (61kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (37ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...\n[ivy:resolve] .. (42kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] asm#asm;3.1!asm.jar (35ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...\n[ivy:resolve] ... (118kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...\n[ivy:resolve] ........... (561kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (48ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...\n[ivy:resolve] .... (140kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (43ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...\n[ivy:resolve] ..... (201kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...\n[ivy:resolve] .... (184kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (48ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...\n[ivy:resolve] .... (130kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (57ms)\n[ivy:resolve] :: resolution report :: resolve 36181ms :: artifacts dl 1329ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \torg.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]\n[ivy:resolve] \tcommons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]\n[ivy:resolve] \torg.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t| hadoop0.20S.shim |   62  |   30  |   30  |   11  ||   51  |   28  |\n\t---------------------------------------------------------------------\n\nivy-retrieve-hadoop-shim:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [hadoop0.20S.shim]\n[ivy:retrieve] \t51 artifacts copied, 0 already retrieved (22876kB/75ms)\n    [javac] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n     [echo] Building shims 0.23\n\nbuild-shims:\n     [echo] Project: shims\n     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.0.5-alpha (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.0.5-alpha)\n\nivy-init-settings:\n     [echo] Project: shims\n\nivy-resolve-hadoop-shim:\n     [echo] Project: shims\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [hadoop0.23.shim]\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-common;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-annotations;2.0.5-alpha in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-math;2.1 in maven2\n[ivy:resolve] \tfound xmlenc#xmlenc;0.52 in maven2\n[ivy:resolve] \tfound commons-httpclient#commons-httpclient;3.1 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.1.1 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound commons-io#commons-io;2.1 in maven2\n[ivy:resolve] \tfound commons-net#commons-net;3.1 in maven2\n[ivy:resolve] \tfound javax.servlet#servlet-api;2.5 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty-util;6.1.26 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-core;1.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-json;1.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jettison#jettison;1.1 in maven2\n[ivy:resolve] \tfound stax#stax-api;1.0.1 in maven2\n[ivy:resolve] \tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2\n[ivy:resolve] \tfound javax.xml.bind#jaxb-api;2.2.2 in maven2\n[ivy:resolve] \tfound javax.activation#activation;1.1 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-xc;1.8.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey#jersey-server;1.8 in maven2\n[ivy:resolve] \tfound asm#asm;3.2 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.17 in maven2\n[ivy:resolve] \tfound net.java.dev.jets3t#jets3t;0.6.1 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.5 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-digester#commons-digester;1.8 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils;1.7.0 in maven2\n[ivy:resolve] \tfound commons-beanutils#commons-beanutils-core;1.8.0 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.5.3 in maven2\n[ivy:resolve] \tfound com.thoughtworks.paranamer#paranamer;2.3 in maven2\n[ivy:resolve] \tfound org.xerial.snappy#snappy-java;1.0.3.2 in maven2\n[ivy:resolve] \tfound net.sf.kosmosfs#kfs;0.3 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.0a in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-auth;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound com.jcraft#jsch;0.1.42 in maven2\n[ivy:resolve] \tfound org.apache.zookeeper#zookeeper;3.4.2 in maven2\n[ivy:resolve] \tfound tomcat#jasper-compiler;5.5.23 in maven2\n[ivy:resolve] \tfound tomcat#jasper-runtime;5.5.23 in maven2\n[ivy:resolve] \tfound commons-el#commons-el;1.0 in maven2\n[ivy:resolve] \tfound javax.servlet.jsp#jsp-api;2.1 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha in maven2\n[ivy:resolve] \tfound com.google.inject.extensions#guice-servlet;3.0 in maven2\n[ivy:resolve] \tfound com.google.inject#guice;3.0 in maven2\n[ivy:resolve] \tfound javax.inject#javax.inject;1 in maven2\n[ivy:resolve] \tfound aopalliance#aopalliance;1.0 in maven2\n[ivy:resolve] \tfound org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2\n[ivy:resolve] \tfound io.netty#netty;3.5.11.Final in maven2\n[ivy:resolve] \tfound com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2\n[ivy:resolve] \tfound com.sun.jersey.contribs#jersey-guice;1.8 in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-archives;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-hdfs;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha in maven2\n[ivy:resolve] \tfound org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha.jar ...\n[ivy:resolve] ....................................... (2295kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar (47ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha-tests.jar ...\n[ivy:resolve] .................... (1151kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar(tests) (26ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.0.5-alpha/hadoop-mapreduce-client-core-2.0.5-alpha.jar ...\n[ivy:resolve] ...................... (1325kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha!hadoop-mapreduce-client-core.jar (27ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.0.5-alpha/hadoop-archives-2.0.5-alpha.jar ...\n[ivy:resolve] .. (20kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.0.5-alpha!hadoop-archives.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha.jar ...\n[ivy:resolve] ........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................ (4241kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar (298ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha-tests.jar ...\n[ivy:resolve] ............................ (1631kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar(tests) (35ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha-tests.jar ...\n[ivy:resolve] ....................... (1350kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar(tests) (30ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha.jar ...\n[ivy:resolve] .. (32kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.0.5-alpha/hadoop-mapreduce-client-common-2.0.5-alpha.jar ...\n[ivy:resolve] ........... (579kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha!hadoop-mapreduce-client-common.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.0.5-alpha/hadoop-yarn-server-tests-2.0.5-alpha-tests.jar ...\n[ivy:resolve] .. (39kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha!hadoop-yarn-server-tests.jar(tests) (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.0.5-alpha/hadoop-mapreduce-client-app-2.0.5-alpha.jar ...\n[ivy:resolve] ......... (463kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha!hadoop-mapreduce-client-app.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.0.5-alpha/hadoop-mapreduce-client-hs-2.0.5-alpha.jar ...\n[ivy:resolve] ... (111kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha!hadoop-mapreduce-client-hs.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.0.5-alpha/hadoop-annotations-2.0.5-alpha.jar ...\n[ivy:resolve] .. (16kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.0.5-alpha!hadoop-annotations.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...\n[ivy:resolve] ...... (297kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...\n[ivy:resolve] ...... (266kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (17ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...\n[ivy:resolve] ... (102kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...\n[ivy:resolve] ......... (478kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (17ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...\n[ivy:resolve] ...... (272kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...\n[ivy:resolve] .. (24kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...\n[ivy:resolve] ...... (257kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar ...\n[ivy:resolve] ........ (439kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.0a!protobuf-java.jar (39ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.0.5-alpha/hadoop-auth-2.0.5-alpha.jar ...\n[ivy:resolve] .. (46kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.0.5-alpha!hadoop-auth.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...\n[ivy:resolve] .... (181kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...\n[ivy:resolve] .............. (746kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (24ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...\n[ivy:resolve] .. (32kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...\n[ivy:resolve] .. (17kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...\n[ivy:resolve] .. (31kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (31ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...\n[ivy:resolve] .. (42kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] asm#asm;3.2!asm.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...\n[ivy:resolve] .. (28kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...\n[ivy:resolve] ................. (972kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (28ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...\n[ivy:resolve] .. (9kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...\n[ivy:resolve] ........ (398kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (18ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...\n[ivy:resolve] ... (75kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...\n[ivy:resolve] ... (98kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.0.5-alpha/hadoop-yarn-common-2.0.5-alpha.jar ...\n[ivy:resolve] .................. (1050kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha!hadoop-yarn-common.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...\n[ivy:resolve] .. (63kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...\n[ivy:resolve] ................... (1106kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (24ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.0.5-alpha/hadoop-yarn-api-2.0.5-alpha.jar ...\n[ivy:resolve] .................. (1014kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha!hadoop-yarn-api.jar (23ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...\n[ivy:resolve] ............ (693kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (17ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...\n[ivy:resolve] .. (12kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...\n[ivy:resolve] .. (14kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...\n[ivy:resolve] .. (2kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (9ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...\n[ivy:resolve] .. (4kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...\n[ivy:resolve] ...... (272kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (15ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.0.5-alpha/hadoop-yarn-client-2.0.5-alpha.jar ...\n[ivy:resolve] .. (28kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha!hadoop-yarn-client.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.0.5-alpha/hadoop-yarn-server-common-2.0.5-alpha.jar ...\n[ivy:resolve] .... (148kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha!hadoop-yarn-server-common.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.0.5-alpha/hadoop-yarn-server-nodemanager-2.0.5-alpha.jar ...\n[ivy:resolve] ........ (404kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha!hadoop-yarn-server-nodemanager.jar (12ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.0.5-alpha/hadoop-yarn-server-resourcemanager-2.0.5-alpha.jar ...\n[ivy:resolve] .......... (517kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha!hadoop-yarn-server-resourcemanager.jar (14ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.0.5-alpha/hadoop-yarn-server-web-proxy-2.0.5-alpha.jar ...\n[ivy:resolve] .. (24kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha!hadoop-yarn-server-web-proxy.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.0.5-alpha/hadoop-mapreduce-client-shuffle-2.0.5-alpha.jar ...\n[ivy:resolve] .. (20kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha!hadoop-mapreduce-client-shuffle.jar (5ms)\n[ivy:resolve] :: resolution report :: resolve 64293ms :: artifacts dl 1139ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|  hadoop0.23.shim |   74  |   47  |   47  |   0   ||   77  |   50  |\n\t---------------------------------------------------------------------\n\nivy-retrieve-hadoop-shim:\n     [echo] Project: shims\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims\n[ivy:retrieve] \tconfs: [hadoop0.23.shim]\n[ivy:retrieve] \t77 artifacts copied, 0 already retrieved (31997kB/108ms)\n    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n\njar:\n     [echo] Project: shims\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:48:50 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-shims\n[ivy:publish] \tpublished hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: common\n\ncheck-ivy:\n     [echo] Project: common\n\nivy-resolve:\n     [echo] Project: common\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar ...\n[ivy:resolve] .... (140kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-shims;0.13.0-SNAPSHOT!hive-shims.jar (4ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...\n[ivy:resolve] ..... (235kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (14ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...\n[ivy:resolve] ... (92kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (12ms)\n[ivy:resolve] :: resolution report :: resolve 9206ms :: artifacts dl 36ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   6   |   3   |   3   |   0   ||   6   |   3   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html\n\nmake-pom:\n     [echo] Project: common\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: common\n\ninit:\n     [echo] Project: common\n\nsetup:\n     [echo] Project: common\n\nivy-retrieve:\n     [echo] Project: common\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t4 artifacts copied, 2 already retrieved (508kB/6ms)\n\ncompile:\n     [echo] Project: common\n    [javac] Compiling 25 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n\njar:\n     [echo] Project: common\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:49:19 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-common\n[ivy:publish] \tpublished hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: serde\n\ncheck-ivy:\n     [echo] Project: serde\n\nivy-resolve:\n     [echo] Project: serde\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar ...\n[ivy:resolve] ... (95kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-common;0.13.0-SNAPSHOT!hive-common.jar (3ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...\n[ivy:resolve] ...................... (1315kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (27ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...\n[ivy:resolve] ...... (268kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (14ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...\n[ivy:resolve] ...... (290kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...\n[ivy:resolve] .... (164kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (8ms)\n[ivy:resolve] :: resolution report :: resolve 7401ms :: artifacts dl 74ms\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html\n\nmake-pom:\n     [echo] Project: serde\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: serde\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.\n\ninit:\n     [echo] Project: serde\n\nivy-retrieve:\n     [echo] Project: serde\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t8 artifacts copied, 6 already retrieved (2227kB/25ms)\n\ndynamic-serde:\n\ncompile:\n     [echo] Project: serde\n    [javac] Compiling 325 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes/org/apache/hadoop/hive/serde2/typeinfo/package-info.class\n\njar:\n     [echo] Project: serde\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:49:38 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-serde\n[ivy:publish] \tpublished hive-serde to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: metastore\n\ncheck-ivy:\n     [echo] Project: metastore\n\nivy-resolve:\n     [echo] Project: metastore\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar ...\n[ivy:resolve] ............ (663kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-serde;0.13.0-SNAPSHOT!hive-serde.jar (19ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr/3.4/antlr-3.4.jar ...\n[ivy:resolve] ................... (1086kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.antlr#antlr;3.4!antlr.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar ...\n[ivy:resolve] .... (160kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.antlr#antlr-runtime;3.4!antlr-runtime.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/ST4/4.0.4/ST4-4.0.4.jar ...\n[ivy:resolve] ..... (231kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.antlr#ST4;4.0.4!ST4.jar (8ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar ...\n[ivy:resolve] ... (112kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.jolbox#bonecp;0.7.1.RELEASE!bonecp.jar(bundle) (36ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar ...\n[ivy:resolve] ... (93kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] commons-pool#commons-pool;1.5.4!commons-pool.jar (7ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar ...\n[ivy:resolve] ....... (329kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.datanucleus#datanucleus-api-jdo;3.2.1!datanucleus-api-jdo.jar (10ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar ...\n[ivy:resolve] ............................. (1759kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.datanucleus#datanucleus-core;3.2.2!datanucleus-core.jar (36ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar ...\n[ivy:resolve] ............................. (1728kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.datanucleus#datanucleus-rdbms;3.2.1!datanucleus-rdbms.jar (35ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar ...\n[ivy:resolve] ..... (196kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javax.jdo#jdo-api;3.0.1!jdo-api.jar (38ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar ...\n[ivy:resolve] ....................................... (2389kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.derby#derby;10.4.2.0!derby.jar (85ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/r08/guava-r08.jar ...\n[ivy:resolve] ................... (1088kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.guava#guava;r08!guava.jar (72ms)\n[ivy:resolve] :: resolution report :: resolve 10845ms :: artifacts dl 419ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   27  |   12  |   12  |   1   ||   26  |   12  |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-metastore-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-metastore-default.html\n\nmake-pom:\n     [echo] Project: metastore\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: metastore\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.\n\ninit:\n     [echo] Project: metastore\n\nmetastore-init:\n     [echo] Project: metastore\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser\n\nivy-retrieve:\n     [echo] Project: metastore\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-metastore\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t12 artifacts copied, 14 already retrieved (9838kB/31ms)\n\nbuild-grammar:\n     [echo] Project: metastore\n     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....\n\nmodel-compile:\n     [echo] Project: metastore\n    [javac] Compiling 24 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n\ncore-compile:\n     [echo] Project: metastore\n    [javac] Compiling 104 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes/org/apache/hadoop/hive/metastore/parser/package-info.class\n\nmodel-enhance:\n     [echo] Project: metastore\n[datanucleusenhancer] log4j:WARN No appenders could be found for logger (DataNucleus.General).\n[datanucleusenhancer] log4j:WARN Please initialize the log4j system properly.\n[datanucleusenhancer] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n[datanucleusenhancer] DataNucleus Enhancer (version 3.2.2) for API \"JDO\" using JRE \"1.6\"\n[datanucleusenhancer] DataNucleus Enhancer : Classpath\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/activation-1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ant-1.6.5.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/asm-3.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-1.7.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-core-1.8.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-cli-1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-codec-1.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-collections-3.2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-configuration-1.6.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-digester-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-el-1.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-httpclient-3.0.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-io-2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-lang-2.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-logging-1.1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-math-2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-net-1.4.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/core-3.1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftplet-api-1.0.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-core-1.0.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-deprecated-1.0.0-M2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-core-1.1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-test-1.1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-tools-1.1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hsqldb-1.8.0.10.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-core-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-jaxrs-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-mapper-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-xc-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-compiler-5.5.12.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-runtime-5.5.12.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-api-2.2.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-impl-2.2.3-1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-core-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-json-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-server-1.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jets3t-0.6.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jettison-1.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-6.1.26.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-util-6.1.26.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-2.1-6.1.14.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-api-2.1-6.1.14.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/junit-3.8.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/mina-core-2.0.0-M5.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/oro-2.0.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-20081211.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-6.1.14.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/slf4j-api-1.5.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0-2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/xmlenc-0.52.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/ST4-4.0.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-3.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-runtime-3.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/bonecp-0.7.1.RELEASE.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-cli-1.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-codec-1.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-compress-1.4.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-io-2.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-1.0.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-api-1.0.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-pool-1.5.4.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-api-jdo-3.2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-core-3.2.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-rdbms-3.2.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/derby-10.4.2.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-r08.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-common-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-serde-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-shims-0.13.0-SNAPSHOT.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jdo-api-3.0.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libfb303-0.9.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/log4j-1.2.16.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/mockito-all-1.8.2.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-api-1.6.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-log4j12-1.6.1.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/velocity-1.5.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/xz-1.0.jar\n[datanucleusenhancer] >>  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/zookeeper-3.4.3.jar\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\n[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\n[datanucleusenhancer] DataNucleus Enhancer completed with success for 24 classes. Timings : input=688 ms, enhance=1171 ms, total=1859 ms. Consult the log for full details\n\ncompile:\n     [echo] Project: metastore\n\njar:\n     [echo] Project: metastore\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:50:18 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-metastore\n[ivy:publish] \tpublished hive-metastore to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: ql\n\ncheck-ivy:\n     [echo] Project: ql\n\nivy-resolve:\n     [echo] Project: ql\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-exec;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar ...\n[ivy:resolve] ..................................................... (3268kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-metastore;0.13.0-SNAPSHOT!hive-metastore.jar (44ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar ...\n[ivy:resolve] ........ (439kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.1!protobuf-java.jar (13ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/iq80/snappy/snappy/0.2/snappy-0.2.jar ...\n[ivy:resolve] .. (47kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.iq80.snappy#snappy;0.2!snappy.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/json/json/20090211/json-20090211.jar ...\n[ivy:resolve] .. (44kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.json#json;20090211!json.jar (22ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar ...\n[ivy:resolve] .. (16kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.googlecode.javaewah#JavaEWAH;0.3.2!JavaEWAH.jar (5ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/javolution/javolution/5.5.1/javolution-5.5.1.jar ...\n[ivy:resolve] ........ (385kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] javolution#javolution;5.5.1!javolution.jar(bundle) (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...\n[ivy:resolve] ... (85kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (120ms)\n[ivy:resolve] :: resolution report :: resolve 10685ms :: artifacts dl 246ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   38  |   7   |   7   |   2   ||   36  |   7   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-exec-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-exec-default.html\n\nmake-pom:\n     [echo] Project: ql\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: ql\n\ninit:\n     [echo] Project: ql\n\nql-init:\n     [echo] Project: ql\n    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse\n\nivy-retrieve:\n     [echo] Project: ql\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-exec\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t10 artifacts copied, 26 already retrieved (5174kB/24ms)\n\nbuild-grammar:\n     [echo] Project: ql\n     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g  ....\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:866:5: \n     [java] Decision can match input such as \"Identifier KW_RENAME KW_TO\" using multiple alternatives: 1, 10\n     [java] \n     [java] As a result, alternative(s) 10 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: \n     [java] Decision can match input such as \"KW_TEXTFILE\" using multiple alternatives: 2, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: \n     [java] Decision can match input such as \"KW_SEQUENCEFILE\" using multiple alternatives: 1, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: \n     [java] Decision can match input such as \"KW_ORCFILE\" using multiple alternatives: 4, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: \n     [java] Decision can match input such as \"KW_RCFILE\" using multiple alternatives: 3, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: \n     [java] Decision can match input such as \"KW_KEY_TYPE\" using multiple alternatives: 2, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: \n     [java] Decision can match input such as \"KW_ELEM_TYPE\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: \n     [java] Decision can match input such as \"KW_VALUE_TYPE\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: \n     [java] Decision can match input such as \"KW_VALUE_TYPE\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: \n     [java] Decision can match input such as \"KW_ELEM_TYPE\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: \n     [java] Decision can match input such as \"KW_KEY_TYPE\" using multiple alternatives: 2, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: \n     [java] Decision can match input such as \"KW_PRETTY KW_PARTITION\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: \n     [java] Decision can match input such as \"KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: \n     [java] Decision can match input such as \"KW_PRETTY Identifier\" using multiple alternatives: 3, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: \n     [java] Decision can match input such as \"KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: \n     [java] Decision can match input such as \"KW_FORMATTED KW_PARTITION\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: \n     [java] Decision can match input such as \"KW_FORMATTED Identifier\" using multiple alternatives: 1, 4\n     [java] \n     [java] As a result, alternative(s) 4 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:116: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_DIRECTORIES\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_INPUTFORMAT\" using multiple alternatives: 5, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_SEQUENCEFILE\" using multiple alternatives: 1, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_ORCFILE\" using multiple alternatives: 4, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_RCFILE\" using multiple alternatives: 3, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: \n     [java] Decision can match input such as \"KW_STORED KW_AS KW_TEXTFILE\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): SelectClauseParser.g:149:5: \n     [java] Decision can match input such as \"KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): SelectClauseParser.g:149:5: \n     [java] Decision can match input such as \"KW_NULL DOT Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:127:2: \n     [java] Decision can match input such as \"KW_LATERAL KW_VIEW KW_OUTER\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:25: \n     [java] Decision can match input such as \"LPAREN StringLiteral RPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:25: \n     [java] Decision can match input such as \"LPAREN StringLiteral EQUAL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:25: \n     [java] Decision can match input such as \"LPAREN StringLiteral COMMA\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:179:68: \n     [java] Decision can match input such as \"Identifier LPAREN KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): FromClauseParser.g:237:16: \n     [java] Decision can match input such as \"Identifier LPAREN KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL GREATERTHAN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL GREATERTHANOREQUALTO\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LESSTHAN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LESSTHANOREQUALTO\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL DOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN CharSetName\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL NOTEQUAL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL EQUAL_NS\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL BITWISEXOR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL EQUAL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT Identifier\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL RPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_AND\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CAST LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL BITWISEOR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_BETWEEN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_CASE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_NOT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_ARRAY\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_IN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_STRUCT\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_NULL\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_UNIONTYPE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_IF\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL AMPERSAND\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LSQUARE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_MAP\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT Number\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL {MINUS, PLUS}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN CharSetName CharSetLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE BigintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_DATE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_TRUE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_WHEN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_FALSE\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_IS\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN StringLiteral StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN {MINUS, PLUS, TILDE}\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_DATE StringLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NULL KW_OR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT TinyintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT SmallintLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_CASE KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN LPAREN KW_CAST\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:68:4: \n     [java] Decision can match input such as \"LPAREN KW_NOT DecimalLiteral\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:108:5: \n     [java] Decision can match input such as \"KW_ORDER KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:121:5: \n     [java] Decision can match input such as \"KW_CLUSTER KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:133:5: \n     [java] Decision can match input such as \"KW_PARTITION KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:144:5: \n     [java] Decision can match input such as \"KW_DISTRIBUTE KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:155:5: \n     [java] Decision can match input such as \"KW_SORT KW_BY LPAREN\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:172:7: \n     [java] Decision can match input such as \"STAR\" using multiple alternatives: 1, 2\n     [java] \n     [java] As a result, alternative(s) 2 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:185:5: \n     [java] Decision can match input such as \"KW_STRUCT\" using multiple alternatives: 4, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:185:5: \n     [java] Decision can match input such as \"KW_UNIONTYPE\" using multiple alternatives: 5, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:185:5: \n     [java] Decision can match input such as \"KW_ARRAY\" using multiple alternatives: 2, 6\n     [java] \n     [java] As a result, alternative(s) 6 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_NULL\" using multiple alternatives: 1, 8\n     [java] \n     [java] As a result, alternative(s) 8 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_DATE StringLiteral\" using multiple alternatives: 2, 3\n     [java] \n     [java] As a result, alternative(s) 3 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_TRUE\" using multiple alternatives: 3, 8\n     [java] \n     [java] As a result, alternative(s) 8 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:267:5: \n     [java] Decision can match input such as \"KW_FALSE\" using multiple alternatives: 3, 8\n     [java] \n     [java] As a result, alternative(s) 8 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"KW_BETWEEN KW_MAP LPAREN\" using multiple alternatives: 6, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:390:5: \n     [java] Decision can match input such as \"{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE\" using multiple alternatives: 2, 7\n     [java] \n     [java] As a result, alternative(s) 7 were disabled for that input\n     [java] warning(200): IdentifiersParser.g:514:5: \n     [java] Decision can match input such as \"{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}\" using multiple alternatives: 1, 3\n     [java] \n     [java] As a result, alternative(s) 3 were disabled for that input\n\ncompile:\n     [echo] Project: ql\n    [javac] Compiling 918 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/package-info.class\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/io/orc/package-info.class\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/udf/generic/package-info.class\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/errors/package-info.class\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/lockmgr/package-info.class\n     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes\n\njar:\n     [echo] Project: ql\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/thrift/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/commons-lang/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/json-20090211.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/json/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/JavaEWAH-0.3.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javaewah/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro-mapred/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/javolution-5.5.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javolution/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/protobuf-java-2.4.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/protobuf-java/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/guava/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/snappy-0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/snappy/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-core-asl/classes\n    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-mapper-asl/classes\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/hive-exec-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-exec;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:20 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-exec\n[ivy:publish] \tpublished hive-exec to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.13.0-SNAPSHOT/jars/hive-exec.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: contrib\n\ncheck-ivy:\n     [echo] Project: contrib\n\nivy-resolve:\n     [echo] Project: contrib\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-contrib;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.13.0-SNAPSHOT/jars/hive-exec.jar ...\n[ivy:resolve] ............................................................................................................................................ (8837kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-exec;0.13.0-SNAPSHOT!hive-exec.jar (123ms)\n[ivy:resolve] :: resolution report :: resolve 7013ms :: artifacts dl 141ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   39  |   1   |   1   |   2   ||   37  |   1   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-contrib-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-contrib-default.html\n\nmake-pom:\n     [echo] Project: contrib\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: contrib\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.\n\ninit:\n     [echo] Project: contrib\n\nsetup:\n     [echo] Project: contrib\n\nivy-retrieve:\n     [echo] Project: contrib\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-contrib\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t1 artifacts copied, 36 already retrieved (8837kB/59ms)\n\ncompile:\n     [echo] Project: contrib\n    [javac] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/conf does not exist.\n\njar:\n     [echo] Project: contrib\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/hive-contrib-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-contrib;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:28 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-contrib\n[ivy:publish] \tpublished hive-contrib to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.13.0-SNAPSHOT/jars/hive-contrib.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: service\n\ncheck-ivy:\n     [echo] Project: service\n\nivy-resolve:\n     [echo] Project: service\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-service;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] :: resolution report :: resolve 6867ms :: artifacts dl 17ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   39  |   0   |   0   |   2   ||   37  |   0   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-service-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-service-default.html\n\nmake-pom:\n     [echo] Project: service\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/service/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: service\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.\n\ninit:\n     [echo] Project: service\n\nivy-retrieve:\n     [echo] Project: service\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-service\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t0 artifacts copied, 37 already retrieved (0kB/20ms)\n\ncompile:\n     [echo] Project: service\n    [javac] Compiling 151 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n\njar:\n     [echo] Project: service\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/service/hive-service-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-service;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:41 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/service/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-service\n[ivy:publish] \tpublished hive-service to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.13.0-SNAPSHOT/jars/hive-service.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: cli\n\ncheck-ivy:\n     [echo] Project: cli\n\nivy-resolve:\n     [echo] Project: cli\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-cli;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-service;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.13.0-SNAPSHOT/jars/hive-service.jar ...\n[ivy:resolve] ........................ (1469kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-service;0.13.0-SNAPSHOT!hive-service.jar (21ms)\n[ivy:resolve] :: resolution report :: resolve 6800ms :: artifacts dl 39ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   40  |   1   |   1   |   2   ||   38  |   1   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-cli-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-cli-default.html\n\nmake-pom:\n     [echo] Project: cli\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: cli\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.\n\ninit:\n     [echo] Project: cli\n\nsetup:\n     [echo] Project: cli\n\nivy-retrieve:\n     [echo] Project: cli\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-cli\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t1 artifacts copied, 37 already retrieved (1469kB/14ms)\n\ncompile:\n     [echo] Project: cli\n    [javac] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:71: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac] import sun.misc.Signal;\n    [javac]                ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:72: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release\n    [javac] import sun.misc.SignalHandler;\n    [javac]                ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:362: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release\n    [javac]     SignalHandler oldSignal = null;\n    [javac]     ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:363: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]     Signal interupSignal = null;\n    [javac]     ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:368: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]       interupSignal = new Signal(\"INT\");\n    [javac]                           ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release\n    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {\n    [javac]                                                    ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release\n    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {\n    [javac]                                                    ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:374: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]         public void handle(Signal signal) {\n    [javac]                            ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {\n    [javac]                   ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:430: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]         Signal.handle(interupSignal, oldSignal);\n    [javac]         ^\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/RCFileCat.java uses or overrides a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java uses unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] 10 warnings\n\njar:\n     [echo] Project: cli\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/hive-cli-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-cli;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:48 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-cli\n[ivy:publish] \tpublished hive-cli to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.13.0-SNAPSHOT/jars/hive-cli.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: jdbc\n\ncheck-ivy:\n     [echo] Project: jdbc\n\nivy-resolve:\n     [echo] Project: jdbc\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-jdbc;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-cli;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-service;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.13.0-SNAPSHOT/jars/hive-cli.jar ...\n[ivy:resolve] .. (33kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hive#hive-cli;0.13.0-SNAPSHOT!hive-cli.jar (3ms)\n[ivy:resolve] :: resolution report :: resolve 6738ms :: artifacts dl 21ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   41  |   1   |   1   |   2   ||   39  |   1   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-jdbc-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-jdbc-default.html\n\nmake-pom:\n     [echo] Project: jdbc\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: jdbc\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.\n\ninit:\n     [echo] Project: jdbc\n\nivy-retrieve:\n     [echo] Project: jdbc\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-jdbc\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t1 artifacts copied, 38 already retrieved (33kB/21ms)\n\ncompile:\n     [echo] Project: jdbc\n    [javac] Compiling 28 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n\njar:\n     [echo] Project: jdbc\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/hive-jdbc-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-jdbc;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:57 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-jdbc\n[ivy:publish] \tpublished hive-jdbc to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.13.0-SNAPSHOT/jars/hive-jdbc.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: beeline\n\ncheck-ivy:\n     [echo] Project: beeline\n\nivy-resolve:\n     [echo] Project: beeline\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-beeline;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-service;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] \tfound commons-io#commons-io;2.4 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging;1.0.4 in maven2\n[ivy:resolve] \tfound commons-logging#commons-logging-api;1.0.4 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libthrift;0.9.0 in maven2\n[ivy:resolve] :: resolution report :: resolve 7662ms :: artifacts dl 26ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   44  |   0   |   0   |   2   ||   42  |   0   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-beeline-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-beeline-default.html\n\nmake-pom:\n     [echo] Project: beeline\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: beeline\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.\n\ninit:\n     [echo] Project: beeline\n\nsetup:\n     [echo] Project: beeline\n\nivy-retrieve:\n     [echo] Project: beeline\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-beeline\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t0 artifacts copied, 42 already retrieved (0kB/23ms)\n\ncompile:\n     [echo] Project: beeline\n    [javac] Compiling 29 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:28: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac] import sun.misc.Signal;\n    [javac]                ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:29: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release\n    [javac] import sun.misc.SignalHandler;\n    [javac]                ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:31: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release\n    [javac] public class SunSignalHandler implements BeeLineSignalHandler, SignalHandler {\n    [javac]                                                                ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:44: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]   public void handle (Signal signal) {\n    [javac]                       ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]     Signal.handle (new Signal (\"INT\"), this);\n    [javac]                        ^\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release\n    [javac]     Signal.handle (new Signal (\"INT\"), this);\n    [javac]     ^\n    [javac] Note: Some input files use unchecked or unsafe operations.\n    [javac] Note: Recompile with -Xlint:unchecked for details.\n    [javac] 6 warnings\n     [copy] Copying 2 files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes\n\njar:\n     [echo] Project: beeline\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/hive-beeline-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-beeline;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:05 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-beeline\n[ivy:publish] \tpublished hive-beeline to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.13.0-SNAPSHOT/jars/hive-beeline.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: hwi\n\ncheck-ivy:\n     [echo] Project: hwi\n\nivy-resolve:\n     [echo] Project: hwi\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hwi;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-cli;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-service;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#jetty-util;6.1.26 in maven2\n[ivy:resolve] \tfound org.mortbay.jetty#servlet-api;2.5-20081211 in maven2\n[ivy:resolve] :: resolution report :: resolve 7125ms :: artifacts dl 19ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   44  |   0   |   0   |   2   ||   42  |   0   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hwi-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hwi-default.html\n\nmake-pom:\n     [echo] Project: hwi\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: hwi\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.\n\ninit:\n     [echo] Project: hwi\n\nsetup:\n     [echo] Project: hwi\n\nivy-retrieve:\n     [echo] Project: hwi\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hwi\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t3 artifacts copied, 39 already retrieved (831kB/14ms)\n\nwar:\n     [echo] Project: hwi\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.13.0-SNAPSHOT.war\n\ncompile:\n     [echo] Project: hwi\n    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hwi/build.xml:67: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds\n    [javac] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes\n\njar:\n     [echo] Project: hwi\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-hwi;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:13 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-hwi\n[ivy:publish] \tpublished hive-hwi to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.13.0-SNAPSHOT/jars/hive-hwi.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: hbase-handler\n\ncheck-ivy:\n     [echo] Project: hbase-handler\n\nivy-resolve:\n     [echo] Project: hbase-handler\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hbase-handler;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-common;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local\n[ivy:resolve] \tfound commons-cli#commons-cli;1.2 in maven2\n[ivy:resolve] \tfound org.apache.commons#commons-compress;1.4.1 in maven2\n[ivy:resolve] \tfound org.tukaani#xz;1.0 in maven2\n[ivy:resolve] \tfound commons-lang#commons-lang;2.4 in maven2\n[ivy:resolve] \tfound log4j#log4j;1.2.16 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-api;1.6.1 in maven2\n[ivy:resolve] \tfound org.slf4j#slf4j-log4j12;1.6.1 in maven2\n[ivy:resolve] \tfound org.mockito#mockito-all;1.8.2 in maven2\n[ivy:resolve] \tfound org.apache.thrift#libfb303;0.9.0 in maven2\n[ivy:resolve] \tfound commons-codec#commons-codec;1.4 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro;1.7.1 in maven2\n[ivy:resolve] \tfound org.apache.avro#avro-mapred;1.7.1 in maven2\n[ivy:resolve] \tfound org.antlr#antlr;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#antlr-runtime;3.4 in maven2\n[ivy:resolve] \tfound org.antlr#ST4;4.0.4 in maven2\n[ivy:resolve] \tfound com.jolbox#bonecp;0.7.1.RELEASE in maven2\n[ivy:resolve] \tfound com.google.guava#guava;r08 in maven2\n[ivy:resolve] \tfound commons-pool#commons-pool;1.5.4 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-core;3.2.2 in maven2\n[ivy:resolve] \tfound org.datanucleus#datanucleus-rdbms;3.2.1 in maven2\n[ivy:resolve] \tfound javax.jdo#jdo-api;3.0.1 in maven2\n[ivy:resolve] \tfound org.apache.derby#derby;10.4.2.0 in maven2\n[ivy:resolve] \tfound com.google.protobuf#protobuf-java;2.4.1 in maven2\n[ivy:resolve] \tfound org.iq80.snappy#snappy;0.2 in maven2\n[ivy:resolve] \tfound org.json#json;20090211 in maven2\n[ivy:resolve] \tfound commons-collections#commons-collections;3.2.1 in maven2\n[ivy:resolve] \tfound commons-configuration#commons-configuration;1.6 in maven2\n[ivy:resolve] \tfound com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2\n[ivy:resolve] \tfound javolution#javolution;5.5.1 in maven2\n[ivy:resolve] \tfound jline#jline;0.9.94 in maven2\n[ivy:resolve] \tfound com.google.guava#guava;11.0.2 in maven2\n[ivy:resolve] \tfound com.google.code.findbugs#jsr305;1.3.9 in maven2\n[ivy:resolve] \tfound org.apache.hbase#hbase;0.94.6.1 in maven2\n[ivy:resolve] \tfound com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1 in maven2\n[ivy:resolve] \tfound com.yammer.metrics#metrics-core;2.1.2 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2\n[ivy:resolve] \tfound org.codehaus.jackson#jackson-xc;1.8.8 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1-tests.jar ...\n[ivy:resolve] ........................................ (2360kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar(test-jar) (49ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1.jar ...\n[ivy:resolve] ......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... (4952kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar (455ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar ...\n[ivy:resolve] ... (93kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1!high-scale-lib.jar (22ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/yammer/metrics/metrics-core/2.1.2/metrics-core-2.1.2.jar ...\n[ivy:resolve] ... (80kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.yammer.metrics#metrics-core;2.1.2!metrics-core.jar (6ms)\n[ivy:resolve] :: resolution report :: resolve 10622ms :: artifacts dl 557ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tcom.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]\n[ivy:resolve] \torg.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   46  |   3   |   3   |   2   ||   45  |   4   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hbase-handler-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hbase-handler-default.html\n\nmake-pom:\n     [echo] Project: hbase-handler\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: hbase-handler\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.\n\ninit:\n     [echo] Project: hbase-handler\n\nsetup:\n     [echo] Project: hbase-handler\n\nivy-retrieve:\n     [echo] Project: hbase-handler\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hbase-handler\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t6 artifacts copied, 39 already retrieved (7536kB/44ms)\n\ncompile:\n     [echo] Project: hbase-handler\n    [javac] Compiling 13 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes\n    [javac] Note: Some input files use or override a deprecated API.\n    [javac] Note: Recompile with -Xlint:deprecation for details.\n    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes/org/apache/hadoop/hive/hbase/package-info.class\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/conf does not exist.\n\njar:\n     [echo] Project: hbase-handler\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/hive-hbase-handler-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-hbase-handler;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:25 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-hbase-handler\n[ivy:publish] \tpublished hive-hbase-handler to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.13.0-SNAPSHOT/jars/hive-hbase-handler.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.13.0-SNAPSHOT/ivys/ivy.xml\n\nivy-init-settings:\n     [echo] Project: testutils\n\ncheck-ivy:\n     [echo] Project: testutils\n\nivy-resolve:\n     [echo] Project: testutils\n[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-testutils;0.13.0-SNAPSHOT\n[ivy:resolve] \tconfs: [default]\n[ivy:resolve] \tfound junit#junit;4.10 in maven2\n[ivy:resolve] \tfound org.hamcrest#hamcrest-core;1.1 in maven2\n[ivy:resolve] \tfound com.google.code.tempus-fugit#tempus-fugit;1.1 in maven2\n[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.10/junit-4.10.jar ...\n[ivy:resolve] ..... (247kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] junit#junit;4.10!junit.jar (11ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/tempus-fugit/tempus-fugit/1.1/tempus-fugit-1.1.jar ...\n[ivy:resolve] .. (54kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] com.google.code.tempus-fugit#tempus-fugit;1.1!tempus-fugit.jar (6ms)\n[ivy:resolve] downloading http://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar ...\n[ivy:resolve] ... (74kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve] \t[SUCCESSFUL ] org.hamcrest#hamcrest-core;1.1!hamcrest-core.jar (6ms)\n[ivy:resolve] :: resolution report :: resolve 2155ms :: artifacts dl 33ms\n[ivy:resolve] \t:: evicted modules:\n[ivy:resolve] \tjunit#junit;4.7 by [junit#junit;4.10] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   4   |   3   |   3   |   1   ||   3   |   3   |\n\t---------------------------------------------------------------------\n[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-testutils-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-testutils-default.html\n\nmake-pom:\n     [echo] Project: testutils\n     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/pom.xml\n[ivy:makepom] DEPRECATED: 'ivy.conf.file' is deprecated, use 'ivy.settings.file' instead\n[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml\n\ncreate-dirs:\n     [echo] Project: testutils\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.\n\ninit:\n     [echo] Project: testutils\n\nsetup:\n     [echo] Project: testutils\n\nivy-retrieve:\n     [echo] Project: testutils\n[ivy:retrieve] :: retrieving :: org.apache.hive#hive-testutils\n[ivy:retrieve] \tconfs: [default]\n[ivy:retrieve] \t3 artifacts copied, 0 already retrieved (376kB/4ms)\n\ncompile:\n     [echo] Project: testutils\n    [javac] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes\n     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/java/conf does not exist.\n\njar:\n     [echo] Project: testutils\n      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/hive-testutils-0.13.0-SNAPSHOT.jar\n[ivy:publish] :: delivering :: org.apache.hive#hive-testutils;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:28 EDT 2013\n[ivy:publish] \tdelivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/ivy-0.13.0-SNAPSHOT.xml\n[ivy:publish] :: publishing :: org.apache.hive#hive-testutils\n[ivy:publish] \tpublished hive-testutils to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.13.0-SNAPSHOT/jars/hive-testutils.jar\n[ivy:publish] \tpublished ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.13.0-SNAPSHOT/ivys/ivy.xml\n\ninit:\n\njar:\n\nmvn-init:\n     [echo] hcatalog-core\n      [get] Getting: http://repo2.maven.org/maven2/org/apache/maven/maven-ant-tasks/2.1.3/maven-ant-tasks-2.1.3.jar\n      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/maven-ant-tasks-2.1.3.jar\n\nhive-mvn-publish:\n     [echo] Installing local artifact for maven : shims\n[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar\n[artifact:install] An error has occurred while processing the Maven artifact tasks.\n[artifact:install]  Diagnosis:\n[artifact:install] \n[artifact:install] Error installing artifact 'org.apache.hive:hive-shims:jar': Error installing artifact: File /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar does not exist\n\nBUILD FAILED\n/data/hive-ptest/working/apache-svn-trunk-source/build.xml:327: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build.xml:68: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/deploy.xml:81: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/deploy.xml:57: The following error occurred while executing this line:\n/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/deploy.xml:48: Error installing artifact 'org.apache.hive:hive-shims:jar': Error installing artifact: File /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar does not exist\n\nTotal time: 6 minutes 37 seconds\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2013-09-07T02:52:31.132+0000","updated":"2013-09-07T02:52:31.132+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13766163","id":"13766163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"[~ekoifman] Did the patch accidentally get created as a reverse patch ?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-13T01:52:05.152+0000","updated":"2013-09-13T01:52:05.152+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13766241","id":"13766241","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"body":"no, the patch is fine.  There was a block of text commented out.  Now it just adds a latest version of Xerces as a dependency.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ekoifman","name":"ekoifman","key":"ekoifman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eugene Koifman","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-13T04:51:08.746+0000","updated":"2013-09-13T04:51:08.746+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13766288","id":"13766288","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"Got it now. I failed to notice the comment being removed!\n+1 Will be useful to have this in 0.12 as well.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-13T06:59:46.375+0000","updated":"2013-09-13T06:59:46.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13767070","id":"13767070","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"body":"The hcat unit tests passed. Committed to trunk and 0.12 branch. Thanks for the contribution Eugene!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thejas","name":"thejas","key":"thejas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thejas&avatarId=15902","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thejas&avatarId=15902","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thejas&avatarId=15902","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thejas&avatarId=15902"},"displayName":"Thejas M Nair","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-13T22:30:41.978+0000","updated":"2013-09-13T22:30:41.978+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13767426","id":"13767426","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hive-trunk-h0.21 #2331 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2331/])\nHIVE-5127: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523134)\n* /hive/trunk/hcatalog/webhcat/svr/pom.xml\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-14T09:32:55.997+0000","updated":"2013-09-14T09:32:55.997+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13767660","id":"13767660","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"ABORTED: Integrated in Hive-trunk-hadoop2 #428 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/428/])\nHIVE-5127: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523134)\n* /hive/trunk/hcatalog/webhcat/svr/pom.xml\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-15T02:50:42.459+0000","updated":"2013-09-15T02:50:42.459+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13767743","id":"13767743","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hive-trunk-hadoop2-ptest #97 (See [https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/97/])\nHIVE-5127: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523134)\n* /hive/trunk/hcatalog/webhcat/svr/pom.xml\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-15T09:33:09.812+0000","updated":"2013-09-15T09:33:09.812+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13767752","id":"13767752","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hive-trunk-hadoop1-ptest #164 (See [https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/164/])\nHIVE-5127: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523134)\n* /hive/trunk/hcatalog/webhcat/svr/pom.xml\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-15T09:34:53.757+0000","updated":"2013-09-15T09:34:53.757+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12664743/comment/13796155","id":"13796155","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"body":"This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ashutoshc","name":"ashutoshc","key":"ashutoshc","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ashutosh Chauhan","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-10-15T23:31:23.949+0000","updated":"2013-10-15T23:31:23.949+0000"}],"maxResults":11,"total":11,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5127/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1nfv3:"}}