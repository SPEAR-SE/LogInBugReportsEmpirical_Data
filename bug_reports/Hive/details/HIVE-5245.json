{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12667539","self":"https://issues.apache.org/jira/rest/api/2/issue/12667539","key":"HIVE-5245","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2013-09-10T07:32:49.148+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Oct 12 18:50:12 UTC 2013","customfield_12310420":"347476","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_2521007656_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-10-08T14:05:05.266+0000","workratio":0,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5245/watchers","watchCount":3,"isWatching":false},"created":"2013-09-09T09:48:17.636+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10342","value":"Incompatible change","id":"10342"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["CTAS","hive"],"customfield_12312333":null,"customfield_12310230":"hive CTAS","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":345600,"aggregatetimeoriginalestimate":345600,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323587","id":"12323587","description":"Hive 0.11.0","name":"0.11.0","archived":false,"released":true,"releaseDate":"2013-05-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-10-12T18:50:12.216+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320408","id":"12320408","name":"HiveServer2","description":"Tracks issues related to HiveServer2"}],"timeoriginalestimate":345600,"description":"hello everyone, recently i came across one hive problem as below:\nhive (test)> create table test_09 as\n           > select a.* from test_01 a\n           > join test_02 b\n           > on (a.id=b.id);\nAutomatically selecting local only mode for query\nTotal MapReduce jobs = 2\nsetting HADOOP_USER_NAME        hadoop\n13/09/09 17:22:36 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-09_17-22-34_848_1629553341892012305/-local-10008/jobconf.xml:a attempt to override final parameter: mapred.system.dir;  Ignoring.\n13/09/09 17:22:36 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-09_17-22-34_848_1629553341892012305/-local-10008/jobconf.xml:a attempt to override final parameter: mapred.local.dir;  Ignoring.\nExecution log at: /tmp/hadoop/.log\n2013-09-09 05:22:36     Starting to launch local task to process map join;      maximum memory = 932118528\n2013-09-09 05:22:37     Processing rows:        4       Hashtable size: 4       Memory usage:   113068056       rate:   0.121\n2013-09-09 05:22:37     Dump the hashtable into file: file:/tmp/hadoop/hive_2013-09-09_17-22-34_848_1629553341892012305/-local-10005/HashTable-Stage-6/MapJoin-mapfile90--.hashtable\n2013-09-09 05:22:37     Upload 1 File to: file:/tmp/hadoop/hive_2013-09-09_17-22-34_848_1629553341892012305/-local-10005/HashTable-Stage-6/MapJoin-mapfile90--.hashtable File size: 788\n2013-09-09 05:22:37     End of local task; Time Taken: 0.444 sec.\nExecution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\nMapred Local Task Succeeded . Convert the Join into MapJoin\nLaunching Job 1 out of 2\nNumber of reduce tasks is set to 0 since there's no reduce operator\n13/09/09 17:22:38 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-09_17-22-34_848_1629553341892012305/-local-10009/jobconf.xml:a attempt to override final parameter: mapred.system.dir;  Ignoring.\n13/09/09 17:22:38 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-09_17-22-34_848_1629553341892012305/-local-10009/jobconf.xml:a attempt to override final parameter: mapred.local.dir;  Ignoring.\nExecution log at: /tmp/hadoop/.log\nJob running in-process (local Hadoop)\nHadoop job information for null: number of mappers: 0; number of reducers: 0\n2013-09-09 17:22:41,807 null map = 0%,  reduce = 0%\n2013-09-09 17:22:44,814 null map = 100%,  reduce = 0%\nEnded Job = job_local_0001\nExecution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\nStage-7 is filtered out by condition resolver.\nOK\nTime taken: 13.138 seconds\nhive (test)> select * from test_09;\nFAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'test_09'\nhive (test)>\nProblem:\nI can't get the created table, namely this CTAS is nonavailable, and this table is not created by this hql sentence at all.who can explain for me.Thanks.","customfield_10010":null,"timetracking":{"originalEstimate":"96h","remainingEstimate":"96h","originalEstimateSeconds":345600,"remainingEstimateSeconds":345600},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":345600,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"347775","customfield_12312823":null,"summary":"hive create table as select(CTAS) can not work(not support) with join on operator","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":345600,"percent":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":345600,"percent":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13762819","id":"13762819","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"body":"Cannot reproduce in trunk.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2013-09-10T07:32:49.148+0000","updated":"2013-09-10T07:32:49.148+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13762821","id":"13762821","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"what the mean \"Cannot reproduce in trunk.\"? Could you explain detailedly. I suppose that Hive.0.11.0 can not support the join on operator for CTAS. But it is available for left outer join & right outer join!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-10T07:41:08.569+0000","updated":"2013-09-10T07:41:08.569+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13762823","id":"13762823","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"hive (test)> create table test_09 as\n           > select a.* from test_01 a\n           > left outer join test_02 b\n           > on (a.id=b.id);\nAutomatically selecting local only mode for query\nTotal MapReduce jobs = 1\nsetting HADOOP_USER_NAME        hadoop\n13/09/10 15:44:32 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-10_15-44-30_620_3609535307275149310/-local-10005/jobconf.xml:a attempt to override final parameter: mapred.system.dir;  Ignoring.\n13/09/10 15:44:32 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-10_15-44-30_620_3609535307275149310/-local-10005/jobconf.xml:a attempt to override final parameter: mapred.local.dir;  Ignoring.\nExecution log at: /tmp/hadoop/.log\n2013-09-10 03:44:32     Starting to launch local task to process map join;      maximum memory = 932118528\n2013-09-10 03:44:33     Processing rows:        4       Hashtable size: 4       Memory usage:   110986304       rate:   0.119\n2013-09-10 03:44:33     Dump the hashtable into file: file:/tmp/hadoop/hive_2013-09-10_15-44-30_620_3609535307275149310/-local-10002/HashTable-Stage-4/MapJoin-mapfile01--.hashtable\n2013-09-10 03:44:33     Upload 1 File to: file:/tmp/hadoop/hive_2013-09-10_15-44-30_620_3609535307275149310/-local-10002/HashTable-Stage-4/MapJoin-mapfile01--.hashtable File size: 444\n2013-09-10 03:44:33     End of local task; Time Taken: 0.562 sec.\nExecution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\nMapred Local Task Succeeded . Convert the Join into MapJoin\nLaunching Job 1 out of 1\nNumber of reduce tasks is set to 0 since there's no reduce operator\n13/09/10 15:44:35 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-10_15-44-30_620_3609535307275149310/-local-10006/jobconf.xml:a attempt to override final parameter: mapred.system.dir;  Ignoring.\n13/09/10 15:44:35 WARN conf.Configuration: file:/tmp/hadoop/hive_2013-09-10_15-44-30_620_3609535307275149310/-local-10006/jobconf.xml:a attempt to override final parameter: mapred.local.dir;  Ignoring.\nExecution log at: /tmp/hadoop/.log\nJob running in-process (local Hadoop)\nHadoop job information for null: number of mappers: 0; number of reducers: 0\n2013-09-10 15:44:38,793 null map = 0%,  reduce = 0%\n2013-09-10 15:44:41,800 null map = 100%,  reduce = 0%\nEnded Job = job_local_0001\nExecution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\nMoving data to: hdfs://namenode:9000/user/hive/warehouse/test.db/test_09\nTable test.test_09 stats: [num_partitions: 0, num_files: 2, num_rows: 26, total_size: 491, raw_data_size: 465]\nOK\nTime taken: 14.86 seconds\nhive (test)> select * from test_09;\nOK\n11      jeff    f       20130812\n11      jeff    f       20130812\n11      jeff    f       20130812\n11      jeff    f       20130812\n12      smith   f       20130812\n12      smith   f       20130812\n12      smith   f       20130812\n12      smith   f       20130812\n13      alex    f       20130812\n13      alex    f       20130812\n13      alex    f       20130812\n13      alex    f       20130812\n14      tom     f       20130812\n14      tom     f       20130812\n14      tom     f       20130812\n14      tom     f       20130812\n11      jeff    f       20130813\n11      jeff    f       20130813\n11      jeff    f       20130813\n11      jeff    f       20130813\n17      smith   f       20130813\n18      alex    f       20130813\n14      tom     f       20130813\n14      tom     f       20130813\n14      tom     f       20130813\n14      tom     f       20130813\nTime taken: 0.071 seconds, Fetched: 26 row(s)\nProblem:\nwhy? the left outer join operator for CTAS, otherwise join not!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-10T07:45:38.143+0000","updated":"2013-09-10T07:45:38.143+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13762829","id":"13762829","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"body":"I've checked out hive-0.11.0 and still cannot reproduce. The query I've used is,\n{noformat}\nhive> create table src_join as select a.* from src a join src b on a.key=b.key + 1000;\n\n......\n\nhive> desc src_join;                                                                  \nOK\nkey                 \tstring              \tNone                \nvalue               \tstring              \tNone                \nTime taken: 0.091 seconds, Fetched: 2 row(s)\n{noformat}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=navis","name":"navis","key":"navis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=navis&avatarId=19885","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=navis&avatarId=19885","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=navis&avatarId=19885","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=navis&avatarId=19885"},"displayName":"Navis","active":true,"timeZone":"Asia/Seoul"},"created":"2013-09-10T07:52:36.019+0000","updated":"2013-09-10T07:52:36.019+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13762832","id":"13762832","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"that is why?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-09-10T07:58:22.267+0000","updated":"2013-09-10T07:58:22.267+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13789227","id":"13789227","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"body":"[~jeff_little] In the description of this jira, your log shows that you created a table called \"test_09\" and then you queried a table \"test_08\". Since \"test_08\" had not been created, you got \"FAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'test_08'\". ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"created":"2013-10-08T14:02:24.090+0000","updated":"2013-10-08T14:02:24.090+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13789228","id":"13789228","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"body":"I am resolving it as \"Not A Problem\".","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"created":"2013-10-08T14:05:05.286+0000","updated":"2013-10-08T14:05:05.286+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13791333","id":"13791333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"hive (test)> create table test_10 as\n           > select a.* from test_01 a\n           > join test_02 b\n           > on (a.id=b.id);\nTotal MapReduce jobs = 2\nsetting HADOOP_USER_NAME        hadoop\nExecution log at: /tmp/hadoop/.log\n2013-10-10 04:53:51     Starting to launch local task to process map join;      maximum memory = 932118528\n2013-10-10 04:53:51     Processing rows:        6       Hashtable size: 6       Memory usage:   110948712       rate:   0.119\n2013-10-10 04:53:51     Dump the hashtable into file: file:/tmp/hadoop/hive_2013-10-10_16-53-48_503_1486914121771638453/-local-10005/HashTable-Stage-6/MapJoin-mapfile10--.hashtable\n2013-10-10 04:53:51     Upload 1 File to: file:/tmp/hadoop/hive_2013-10-10_16-53-48_503_1486914121771638453/-local-10005/HashTable-Stage-6/MapJoin-mapfile10--.hashtable File size: 692\n2013-10-10 04:53:51     End of local task; Time Taken: 0.413 sec.\nExecution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\nMapred Local Task Succeeded . Convert the Join into MapJoin\nLaunching Job 1 out of 2\nNumber of reduce tasks is set to 0 since there's no reduce operator\nStarting Job = job_201308241420_3453, Tracking URL = http://namenode:50030/jobdetails.jsp?jobid=job_201308241420_3453\nKill Command = /home/hadoop/package/hadoop-1.0.4/libexec/../bin/hadoop job  -kill job_201308241420_3453\nHadoop job information for Stage-6: number of mappers: 2; number of reducers: 0\n2013-10-10 16:54:03,981 Stage-6 map = 0%,  reduce = 0%\n2013-10-10 16:54:10,015 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec\n2013-10-10 16:54:11,022 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec\n2013-10-10 16:54:12,029 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec\n2013-10-10 16:54:13,035 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec\n2013-10-10 16:54:14,041 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec\n2013-10-10 16:54:15,047 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec\n2013-10-10 16:54:16,053 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 2.82 sec\nMapReduce Total cumulative CPU time: 2 seconds 820 msec\nEnded Job = job_201308241420_3453\nStage-7 is filtered out by condition resolver.\n24 Rows loaded to hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-10_16-53-48_503_1486914121771638453/-ext-10000\nMapReduce Jobs Launched:\nJob 0: Map: 2   Cumulative CPU: 2.82 sec   HDFS Read: 822 HDFS Write: 452 SUCCESS\nTotal MapReduce CPU Time Spent: 2 seconds 820 msec\nOK\nTime taken: 27.598 seconds\nhive (test)> select * from test_10;\nFAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'test_10'\nhive (test)>\nwhy???","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-10-10T08:55:48.393+0000","updated":"2013-10-10T08:55:48.393+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13791546","id":"13791546","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"body":"[~jeff_little] I tried both trunk and 0.11 with tables used in our unit tests (src and src1) with the query \n{code:sql}\ncreate table test_10 as\nselect a.* from src a join src1 b on (a.key=b.key);\n{code}\nI did not see the error in your post. \n\nSince \"Stage-7 is filtered out by condition resolver.\" appears in your log, seems hive.auto.convert.join.noconditionaltask was false in your test. Can you post the results of EXPLAIN with hive.auto.convert.join.noconditionaltask=true and hive.auto.convert.join.noconditionaltask=false?\n\nBecause it is a CTAS query, in the query plan, we should see two extra stages besides stages for the select query, one for Move Operator and another for Create Table Operator.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"created":"2013-10-10T14:33:36.558+0000","updated":"2013-10-10T14:33:36.558+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13791563","id":"13791563","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"hive (test)> set hive.auto.convert.join.noconditionaltask=true;\nhive (test)> explain\n           > create table test_10 as\n           > select a.* from test_01 a\n           > join test_02 b\n           > on (a.id=b.id);\nOK\nABSTRACT SYNTAX TREE:\n  (TOK_CREATETABLE (TOK_TABNAME test_10) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME test_01) a) (TOK_TABREF (TOK_TABNAME test_02) b) (= (. (TOK_TABLE_OR_COL a) id) (. (TOK_TABLE_OR_COL b) id)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF (TOK_TABNAME a)))))))\n\nSTAGE DEPENDENCIES:\n  Stage-8 is a root stage\n  Stage-6 depends on stages: Stage-8\n  Stage-5 depends on stages: Stage-6 , consists of Stage-7\n  Stage-7\n  Stage-4 depends on stages: Stage-7\n  Stage-0 depends on stages: Stage-1, Stage-4\n  Stage-9 depends on stages: Stage-0\n  Stage-2 depends on stages: Stage-9\n\nSTAGE PLANS:\n  Stage: Stage-8\n    Map Reduce Local Work\n      Alias -> Map Local Tables:\n        a\n          Fetch Operator\n            limit: -1\n      Alias -> Map Local Operator Tree:\n        a\n          TableScan\n            alias: a\n            HashTable Sink Operator\n              condition expressions:\n                0 {id} {name} {sex} {record_day}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[id]]\n                1 [Column[id]]\n              Position of Big Table: 1\n\n  Stage: Stage-6\n    Map Reduce\n      Alias -> Map Operator Tree:\n        b\n          TableScan\n            alias: b\n            Map Join Operator\n              condition map:\n                   Inner Join 0 to 1\n              condition expressions:\n                0 {id} {name} {sex} {record_day}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[id]]\n                1 [Column[id]]\n              outputColumnNames: _col0, _col1, _col2, _col3\n              Position of Big Table: 1\n              Select Operator\n                expressions:\n                      expr: _col0\n                      type: int\n                      expr: _col1\n                      type: string\n                      expr: _col2\n                      type: string\n                      expr: _col3\n                      type: string\n                outputColumnNames: _col0, _col1, _col2, _col3\n                File Output Operator\n                  compressed: false\n                  GlobalTableId: 1\n                  table:\n                      input format: org.apache.hadoop.mapred.TextInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n                      name: test.test_10\n      Local Work:\n        Map Reduce Local Work\n\n  Stage: Stage-5\n    Conditional Operator\n\n  Stage: Stage-7\n    Map Reduce Local Work\n      Alias -> Map Local Tables:\n        1\n          Fetch Operator\n            limit: -1\n      Alias -> Map Local Operator Tree:\n        1\n            HashTable Sink Operator\n              condition expressions:\n                0 {0_VALUE_0} {0_VALUE_1} {0_VALUE_2} {0_VALUE_3}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[joinkey0]]\n                1 [Column[joinkey0]]\n              Position of Big Table: 0\n\n  Stage: Stage-4\n    Map Reduce\n      Alias -> Map Operator Tree:\n        0\n            Map Join Operator\n              condition map:\n                   Inner Join 0 to 1\n              condition expressions:\n                0 {0_VALUE_0} {0_VALUE_1} {0_VALUE_2} {0_VALUE_3}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[joinkey0]]\n                1 [Column[joinkey0]]\n              outputColumnNames: _col0, _col1, _col2, _col3\n              Position of Big Table: 0\n              Select Operator\n                expressions:\n                      expr: _col0\n                      type: int\n                      expr: _col1\n                      type: string\n                      expr: _col2\n                      type: string\n                      expr: _col3\n                      type: string\n                outputColumnNames: _col0, _col1, _col2, _col3\n                File Output Operator\n                  compressed: false\n                  GlobalTableId: 1\n                  table:\n                      input format: org.apache.hadoop.mapred.TextInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n                      name: test.test_10\n      Local Work:\n        Map Reduce Local Work\n\n  Stage: Stage-0\n    Move Operator\n      files:\n          hdfs directory: true\n          destination: hdfs://namenode:9000/user/hive/warehouse/test.db/test_10\n\n  Stage: Stage-9\n      Create Table Operator:\n        Create Table\n          columns: id int, name string, sex string, record_day string\n          if not exists: false\n          input format: org.apache.hadoop.mapred.TextInputFormat\n          # buckets: -1\n          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat\n          name: test_10\n          isExternal: false\n\n  Stage: Stage-2\n    Stats-Aggr Operator\n\n\nTime taken: 0.293 seconds, Fetched: 152 row(s)\nhive (test)>set hive.auto.convert.join.noconditionaltask=false;\nhive (test)> explain\n           > create table test_10 as\n           > select a.* from test_01 a\n           > join test_02 b\n           > on (a.id=b.id);\nABSTRACT SYNTAX TREE:\n  (TOK_CREATETABLE (TOK_TABNAME test_10) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME test_01) a) (TOK_TABREF (TOK_TABNAME test_02) b) (= (. (TOK_TABL\nE_OR_COL a) id) (. (TOK_TABLE_OR_COL b) id)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF (TOK_TABNAME a)))))))\n\nSTAGE DEPENDENCIES:\n  Stage-8 is a root stage\n  Stage-6 depends on stages: Stage-8\n  Stage-5 depends on stages: Stage-6 , consists of Stage-7\n  Stage-7\n  Stage-4 depends on stages: Stage-7\n  Stage-0 depends on stages: Stage-1, Stage-4\n  Stage-9 depends on stages: Stage-0\n  Stage-2 depends on stages: Stage-9\n\nSTAGE PLANS:\n  Stage: Stage-8\n    Map Reduce Local Work\n      Alias -> Map Local Tables:\n        a\n          Fetch Operator\n            limit: -1\n      Alias -> Map Local Operator Tree:\n        a\n          TableScan\n            alias: a\n            HashTable Sink Operator\n              condition expressions:\n                0 {id} {name} {sex} {record_day}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[id]]\n                1 [Column[id]]\n              Position of Big Table: 1\n\n  Stage: Stage-6\n    Map Reduce\n      Alias -> Map Operator Tree:\n        b\n          TableScan\n            alias: b\n            Map Join Operator\n              condition map:\n                   Inner Join 0 to 1\n              condition expressions:\n                0 {id} {name} {sex} {record_day}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[id]]\n                1 [Column[id]]\n              outputColumnNames: _col0, _col1, _col2, _col3\n              Position of Big Table: 1\n              Select Operator\n                expressions:\n                      expr: _col0\n                      type: int\n                      expr: _col1\n                      type: string\n                      expr: _col2\n                      type: string\n                      expr: _col3\n                      type: string\n                outputColumnNames: _col0, _col1, _col2, _col3\n                File Output Operator\n                  compressed: false\n                  GlobalTableId: 1\n                  table:\n                      input format: org.apache.hadoop.mapred.TextInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n                      name: test.test_10\n      Local Work:\n        Map Reduce Local Work\n\n  Stage: Stage-5\n    Conditional Operator\n\n  Stage: Stage-7\n    Map Reduce Local Work\n      Alias -> Map Local Tables:\n        1\n          Fetch Operator\n            limit: -1\n      Alias -> Map Local Operator Tree:\n        1\n            HashTable Sink Operator\n              condition expressions:\n                0 {0_VALUE_0} {0_VALUE_1} {0_VALUE_2} {0_VALUE_3}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[joinkey0]]\n                1 [Column[joinkey0]]\n              Position of Big Table: 0\n\n  Stage: Stage-4\n    Map Reduce\n      Alias -> Map Operator Tree:\n        0\n            Map Join Operator\n              condition map:\n                   Inner Join 0 to 1\n              condition expressions:\n                0 {0_VALUE_0} {0_VALUE_1} {0_VALUE_2} {0_VALUE_3}\n                1\n              handleSkewJoin: false\n              keys:\n                0 [Column[joinkey0]]\n                1 [Column[joinkey0]]\n              outputColumnNames: _col0, _col1, _col2, _col3\n              Position of Big Table: 0\n              Select Operator\n                expressions:\n                      expr: _col0\n                      type: int\n                      expr: _col1\n                      type: string\n                      expr: _col2\n                      type: string\n                      expr: _col3\n                      type: string\n                outputColumnNames: _col0, _col1, _col2, _col3\n                File Output Operator\n                  compressed: false\n                  GlobalTableId: 1\n                  table:\n                      input format: org.apache.hadoop.mapred.TextInputFormat\n                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n                      name: test.test_10\n      Local Work:\n        Map Reduce Local Work\n\n  Stage: Stage-0\n    Move Operator\n      files:\n          hdfs directory: true\n          destination: hdfs://namenode:9000/user/hive/warehouse/test.db/test_10\n\n  Stage: Stage-9\n      Create Table Operator:\n        Create Table\n          columns: id int, name string, sex string, record_day string\n          if not exists: false\n          input format: org.apache.hadoop.mapred.TextInputFormat\n          # buckets: -1\n          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat\n          name: test_10\n          isExternal: false\n\n  Stage: Stage-2\n    Stats-Aggr Operator\n\nHi, Yin Huai. I had tried to set hive.auto.convert.join.noconditionaltask=true or false, but it was still noneffective. The explain content above. Plz help me! Thanks!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-10-10T14:53:55.840+0000","updated":"2013-10-10T14:53:55.840+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13791577","id":"13791577","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"And, what the mean \"is filtered out by condition resolver.\" I think that \"is filtered out by condition resolver\" causing built table failure.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-10-10T15:13:45.766+0000","updated":"2013-10-10T15:13:45.766+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13791578","id":"13791578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"body":"Can you check your log and see you can find something like (after the line of \"INFO exec.ExecDriver: Execution completed successfully\") ...\n{code}\n13/10/10 11:10:23 INFO exec.Task: Moving data to: ...\n13/10/10 11:10:23 INFO exec.DDLTask: Default to LazySimpleSerDe for table test_10\n13/10/10 11:10:23 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:test_10, ...\n{code}\n\nYou can direct the log to you console by using \n{code}\nbin/hive -hiveconf hive.root.logger=INFO,console \n{code}\n\nWhat version of hive are you using? 0.11?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"created":"2013-10-10T15:14:45.138+0000","updated":"2013-10-10T15:14:45.138+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13791589","id":"13791589","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"Task Logs: 'attempt_201308241420_3665_m_000000_0'\nsyslog logs\n2013-10-10 23:25:14,771 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library\n2013-10-10 23:25:14,841 INFO org.apache.hadoop.mapred.TaskRunner: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/distcache/-6415303628198910415_1127677245_586502988/namenode/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/-mr-10010/319df19a-bb7f-44d8-8bc5-e2cc1b034bb2 <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/HIVE_PLAN319df19a-bb7f-44d8-8bc5-e2cc1b034bb2\n2013-10-10 23:25:14,846 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/org <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/org\n2013-10-10 23:25:14,847 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/javolution <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/javolution\n2013-10-10 23:25:14,847 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/META-INF <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/META-INF\n2013-10-10 23:25:14,848 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/.job.jar.crc <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/.job.jar.crc\n2013-10-10 23:25:14,849 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/javaewah <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/javaewah\n2013-10-10 23:25:14,850 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/com <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/com\n2013-10-10 23:25:14,850 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/hive-exec-log4j.properties <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/hive-exec-log4j.properties\n2013-10-10 23:25:14,851 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/javax <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/javax\n2013-10-10 23:25:14,852 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/job.jar <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/job.jar\n2013-10-10 23:25:15,089 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0\n2013-10-10 23:25:15,091 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@28bb494b\n2013-10-10 23:25:15,493 INFO com.hadoop.compression.lzo.GPLNativeCodeLoader: Loaded native gpl library\n2013-10-10 23:25:15,495 INFO com.hadoop.compression.lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 6bb1b7f8b9044d8df9b4d2b6641db7658aab3cf8]\n2013-10-10 23:25:15,503 INFO org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader: Processing file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813/test_02.txt\n2013-10-10 23:25:15,503 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 0\n2013-10-10 23:25:15,511 INFO ExecMapper: maximum memory = 200998912\n2013-10-10 23:25:15,511 INFO ExecMapper: conf classpath = [file:/home/hadoop/package/hadoop-1.0.4/conf.cluster/, file:/usr/lib/jvm/java-1.6.0-sun-1.6.0.30.x86_64/lib/tools.jar, file:/home/hadoop/package/hadoop-1.0.4/build/classes/, file:/home/hadoop/package/hadoop-1.0.4/build/test/classes/, file:/home/hadoop/package/hadoop-1.0.4/, file:/home/hadoop/package/hadoop-1.0.4/hadoop-core-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/asm-3.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjrt-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjtools-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-1.7.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-core-1.8.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-cli-1.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-codec-1.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-collections-3.2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-configuration-1.6.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-daemon-1.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-digester-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-el-1.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-httpclient-3.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-io-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-lang-2.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-1.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-api-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-math-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-net-1.4.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/core-3.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-capacity-scheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-fairscheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-lzo-0.4.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-thriftfs-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hsqldb-1.8.0.10.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-core-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-mapper-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-compiler-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-runtime-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jdeb-0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-core-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-json-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-server-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jets3t-0.6.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-util-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsch-0.1.42.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/junit-4.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/kfs-0.2.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/log4j-1.2.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/mockito-all-1.8.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/oro-2.0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/servlet-api-2.5-20081211.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-api-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-log4j12-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/xmlenc-0.52.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-api-2.1.jar, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/classes, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/distcache/-7362175280706972069_54005676_586503270/namenode/home/hadoop/hdfs/tmp/mapred/staging/hadoop/.staging/job_201308241420_3665/libjars/hive-contrib-0.11.0.jar/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/]\n2013-10-10 23:25:15,511 INFO ExecMapper: thread classpath = [file:/home/hadoop/package/hadoop-1.0.4/conf.cluster/, file:/usr/lib/jvm/java-1.6.0-sun-1.6.0.30.x86_64/lib/tools.jar, file:/home/hadoop/package/hadoop-1.0.4/build/classes/, file:/home/hadoop/package/hadoop-1.0.4/build/test/classes/, file:/home/hadoop/package/hadoop-1.0.4/, file:/home/hadoop/package/hadoop-1.0.4/hadoop-core-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/asm-3.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjrt-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjtools-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-1.7.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-core-1.8.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-cli-1.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-codec-1.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-collections-3.2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-configuration-1.6.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-daemon-1.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-digester-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-el-1.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-httpclient-3.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-io-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-lang-2.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-1.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-api-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-math-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-net-1.4.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/core-3.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-capacity-scheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-fairscheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-lzo-0.4.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-thriftfs-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hsqldb-1.8.0.10.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-core-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-mapper-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-compiler-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-runtime-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jdeb-0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-core-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-json-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-server-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jets3t-0.6.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-util-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsch-0.1.42.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/junit-4.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/kfs-0.2.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/log4j-1.2.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/mockito-all-1.8.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/oro-2.0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/servlet-api-2.5-20081211.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-api-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-log4j12-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/xmlenc-0.52.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-api-2.1.jar, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/classes, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/distcache/-7362175280706972069_54005676_586503270/namenode/home/hadoop/hdfs/tmp/mapred/staging/hadoop/.staging/job_201308241420_3665/libjars/hive-contrib-0.11.0.jar/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000000_0/work/]\n2013-10-10 23:25:15,548 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Adding alias b to work list for file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812\n2013-10-10 23:25:15,549 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Adding alias b to work list for file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.MapOperator: dump TS struct<id:int,course:string,score:string,record_day:string>\n2013-10-10 23:25:15,551 INFO ExecMapper: \n<MAP>Id =5\n  <Children>\n    <TS>Id =0\n      <Children>\n        <MAPJOIN>Id =1\n          <Children>\n            <SEL>Id =2\n              <Children>\n                <FS>Id =3\n                  <Parent>Id = 2 null<\\Parent>\n                <\\FS>\n              <\\Children>\n              <Parent>Id = 1 null<\\Parent>\n            <\\SEL>\n          <\\Children>\n          <Parent>Id = 4 \n        <HASHTABLEDUMMY>Id =4\n          <Children>null\n          <\\Children>\n        <\\HASHTABLEDUMMY>Id = 0 null<\\Parent>\n        <\\MAPJOIN>\n      <\\Children>\n      <Parent>Id = 5 null<\\Parent>\n    <\\TS>\n  <\\Children>\n<\\MAP>\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Initializing Self 5 MAP\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Initializing Self 0 TS\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Operator 0 TS initialized\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Initializing children of 0 TS\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing child 1 MAPJOIN\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Initialization Done 0 TS\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Initialization Done 5 MAP\n2013-10-10 23:25:15,552 INFO ExecMapper: Initializing dummy operator\n2013-10-10 23:25:15,552 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Initializing Self 4 HASHTABLEDUMMY\n2013-10-10 23:25:15,564 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Operator 4 HASHTABLEDUMMY initialized\n2013-10-10 23:25:15,565 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Initializing children of 4 HASHTABLEDUMMY\n2013-10-10 23:25:15,565 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing child 1 MAPJOIN\n2013-10-10 23:25:15,565 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing Self 1 MAPJOIN\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: JOIN struct<_col0:int,_col1:string,_col2:string,_col3:string> totalsz = 4\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Operator 1 MAPJOIN initialized\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing children of 1 MAPJOIN\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initializing child 2 SEL\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initializing Self 2 SEL\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: SELECT struct<_col0:int,_col1:string,_col2:string,_col3:string>\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Operator 2 SEL initialized\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initializing children of 2 SEL\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initializing child 3 FS\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initializing Self 3 FS\n2013-10-10 23:25:15,580 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Operator 3 FS initialized\n2013-10-10 23:25:15,580 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initialization Done 3 FS\n2013-10-10 23:25:15,580 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initialization Done 2 SEL\n2013-10-10 23:25:15,584 INFO org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper: maximum memory: 200998912\n2013-10-10 23:25:15,584 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initialization Done 1 MAPJOIN\n2013-10-10 23:25:15,584 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Initialization Done 4 HASHTABLEDUMMY\n2013-10-10 23:25:15,588 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Processing alias b for file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813\n2013-10-10 23:25:15,589 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: ******* Load from HashTable File: input : hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813/test_02.txt\n2013-10-10 23:25:15,590 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: \tLoad back 1 hashtable file from tmp file uri:/home/hadoop/hdfs/mapred/local/taskTracker/distcache/-8026335471844171088_-517161708_586502978/namenode/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/-mr-10006/HashTable-Stage-6/Stage-6.tar.gz/MapJoin-mapfile480--.hashtable\n2013-10-10 23:25:15,605 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 forwarding 1 rows\n2013-10-10 23:25:15,605 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 forwarding 1 rows\n2013-10-10 23:25:15,606 WARN org.apache.hadoop.hive.serde2.lazy.LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.\n2013-10-10 23:25:15,606 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 forwarding 1 rows\n2013-10-10 23:25:15,606 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 forwarding 1 rows\n2013-10-10 23:25:15,606 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Final Path: FS hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/_tmp.-ext-10001/000000_0\n2013-10-10 23:25:15,607 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Writing to temp file: FS hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/_task_tmp.-ext-10001/_tmp.000000_0\n2013-10-10 23:25:15,607 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: New Final Path: FS hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/_tmp.-ext-10001/000000_0\n2013-10-10 23:25:15,657 INFO ExecMapper: ExecMapper: processing 1 rows: used memory = 31440456\n2013-10-10 23:25:15,657 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 forwarding 10 rows\n2013-10-10 23:25:15,657 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 forwarding 10 rows\n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 finished. closing... \n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 forwarded 8 rows\n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.MapOperator: DESERIALIZE_ERRORS:0\n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 finished. closing... \n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 forwarded 8 rows\n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 Close done\n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 Close done\n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: 4 finished. closing... \n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: 4 forwarded 0 rows\n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 finished. closing... \n2013-10-10 23:25:15,658 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 forwarded 12 rows\n2013-10-10 23:25:15,662 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 finished. closing... \n2013-10-10 23:25:15,662 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 forwarded 12 rows\n2013-10-10 23:25:15,662 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 3 finished. closing... \n2013-10-10 23:25:15,662 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 3 forwarded 0 rows\n2013-10-10 23:25:15,719 ERROR org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher: Error during instantiating JDBC driver org.apache.derby.jdbc.EmbeddedDriver. \njava.lang.ClassNotFoundException: org.apache.derby.jdbc.EmbeddedDriver\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:202)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:169)\n\tat org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher.connect(JDBCStatsPublisher.java:68)\n\tat org.apache.hadoop.hive.ql.exec.FileSinkOperator.publishStats(FileSinkOperator.java:963)\n\tat org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:872)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597)\n\tat org.apache.hadoop.hive.ql.exec.ExecMapper.close(ExecMapper.java:201)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:249)\n2013-10-10 23:25:15,720 ERROR org.apache.hadoop.hive.ql.exec.FileSinkOperator: StatsPublishing error: cannot connect to database\n2013-10-10 23:25:15,720 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: TABLE_ID_1_ROWCOUNT:12\n2013-10-10 23:25:15,720 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 Close done\n2013-10-10 23:25:15,720 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 Close done\n2013-10-10 23:25:15,720 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: 4 Close done\n2013-10-10 23:25:15,720 INFO ExecMapper: ExecMapper: processed 8 rows: used memory = 34940376\n2013-10-10 23:25:15,724 INFO org.apache.hadoop.mapred.Task: Task:attempt_201308241420_3665_m_000000_0 is done. And is in the process of commiting\n2013-10-10 23:25:18,083 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201308241420_3665_m_000000_0' done.\n2013-10-10 23:25:18,098 INFO org.apache.hadoop.mapred.TaskLogsTruncater: Initializing logs' truncater with mapRetainSize=-1 and reduceRetainSize=-1\n2013-10-10 23:25:18,115 INFO org.apache.hadoop.io.nativeio.NativeIO: Initialized cache for UID to User mapping with a cache timeout of 14400 seconds.\n2013-10-10 23:25:18,115 INFO org.apache.hadoop.io.nativeio.NativeIO: Got UserName hadoop for UID 500 from the native implementation\n\nTask Logs: 'attempt_201308241420_3665_m_000001_0'\n2013-10-10 23:25:14,771 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library\n2013-10-10 23:25:14,841 INFO org.apache.hadoop.mapred.TaskRunner: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/distcache/-6415303628198910415_1127677245_586502988/namenode/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/-mr-10010/319df19a-bb7f-44d8-8bc5-e2cc1b034bb2 <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/HIVE_PLAN319df19a-bb7f-44d8-8bc5-e2cc1b034bb2\n2013-10-10 23:25:14,845 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/org <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/org\n2013-10-10 23:25:14,846 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/javolution <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/javolution\n2013-10-10 23:25:14,847 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/META-INF <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/META-INF\n2013-10-10 23:25:14,848 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/.job.jar.crc <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/.job.jar.crc\n2013-10-10 23:25:14,849 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/javaewah <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/javaewah\n2013-10-10 23:25:14,849 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/com <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/com\n2013-10-10 23:25:14,850 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/hive-exec-log4j.properties <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/hive-exec-log4j.properties\n2013-10-10 23:25:14,851 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/javax <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/javax\n2013-10-10 23:25:14,852 INFO org.apache.hadoop.filecache.TrackerDistributedCacheManager: Creating symlink: /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/job.jar <- /home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/job.jar\n2013-10-10 23:25:15,089 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0\n2013-10-10 23:25:15,092 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5d2412e7\n2013-10-10 23:25:15,493 INFO com.hadoop.compression.lzo.GPLNativeCodeLoader: Loaded native gpl library\n2013-10-10 23:25:15,495 INFO com.hadoop.compression.lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 6bb1b7f8b9044d8df9b4d2b6641db7658aab3cf8]\n2013-10-10 23:25:15,503 INFO org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader: Processing file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812/test_02.txt\n2013-10-10 23:25:15,503 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 0\n2013-10-10 23:25:15,510 INFO ExecMapper: maximum memory = 200998912\n2013-10-10 23:25:15,510 INFO ExecMapper: conf classpath = [file:/home/hadoop/package/hadoop-1.0.4/conf.cluster/, file:/usr/lib/jvm/java-1.6.0-sun-1.6.0.30.x86_64/lib/tools.jar, file:/home/hadoop/package/hadoop-1.0.4/build/classes/, file:/home/hadoop/package/hadoop-1.0.4/build/test/classes/, file:/home/hadoop/package/hadoop-1.0.4/, file:/home/hadoop/package/hadoop-1.0.4/hadoop-core-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/asm-3.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjrt-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjtools-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-1.7.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-core-1.8.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-cli-1.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-codec-1.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-collections-3.2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-configuration-1.6.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-daemon-1.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-digester-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-el-1.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-httpclient-3.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-io-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-lang-2.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-1.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-api-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-math-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-net-1.4.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/core-3.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-capacity-scheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-fairscheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-lzo-0.4.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-thriftfs-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hsqldb-1.8.0.10.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-core-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-mapper-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-compiler-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-runtime-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jdeb-0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-core-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-json-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-server-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jets3t-0.6.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-util-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsch-0.1.42.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/junit-4.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/kfs-0.2.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/log4j-1.2.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/mockito-all-1.8.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/oro-2.0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/servlet-api-2.5-20081211.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-api-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-log4j12-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/xmlenc-0.52.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-api-2.1.jar, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/classes, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/distcache/-7362175280706972069_54005676_586503270/namenode/home/hadoop/hdfs/tmp/mapred/staging/hadoop/.staging/job_201308241420_3665/libjars/hive-contrib-0.11.0.jar/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/]\n2013-10-10 23:25:15,511 INFO ExecMapper: thread classpath = [file:/home/hadoop/package/hadoop-1.0.4/conf.cluster/, file:/usr/lib/jvm/java-1.6.0-sun-1.6.0.30.x86_64/lib/tools.jar, file:/home/hadoop/package/hadoop-1.0.4/build/classes/, file:/home/hadoop/package/hadoop-1.0.4/build/test/classes/, file:/home/hadoop/package/hadoop-1.0.4/, file:/home/hadoop/package/hadoop-1.0.4/hadoop-core-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/asm-3.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjrt-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/aspectjtools-1.6.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-1.7.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-beanutils-core-1.8.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-cli-1.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-codec-1.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-collections-3.2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-configuration-1.6.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-daemon-1.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-digester-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-el-1.0.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-httpclient-3.0.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-io-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-lang-2.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-1.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-logging-api-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-math-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/commons-net-1.4.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/core-3.1.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-capacity-scheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-fairscheduler-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-lzo-0.4.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hadoop-thriftfs-1.0.4.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/hsqldb-1.8.0.10.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-core-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jackson-mapper-asl-1.8.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-compiler-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jasper-runtime-5.5.12.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jdeb-0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-core-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-json-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jersey-server-1.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jets3t-0.6.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jetty-util-6.1.26.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsch-0.1.42.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/junit-4.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/kfs-0.2.2.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/log4j-1.2.15.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/mockito-all-1.8.5.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/oro-2.0.8.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/servlet-api-2.5-20081211.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-api-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/slf4j-log4j12-1.4.3.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/xmlenc-0.52.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-2.1.jar, file:/home/hadoop/package/hadoop-1.0.4/lib/jsp-2.1/jsp-api-2.1.jar, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/classes, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/jars/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/distcache/-7362175280706972069_54005676_586503270/namenode/home/hadoop/hdfs/tmp/mapred/staging/hadoop/.staging/job_201308241420_3665/libjars/hive-contrib-0.11.0.jar/, file:/home/hadoop/hdfs/mapred/local/taskTracker/hadoop/jobcache/job_201308241420_3665/attempt_201308241420_3665_m_000001_0/work/]\n2013-10-10 23:25:15,547 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Adding alias b to work list for file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812\n2013-10-10 23:25:15,549 INFO org.apache.hadoop.hive.ql.exec.MapOperator: dump TS struct<id:int,course:string,score:string,record_day:string>\n2013-10-10 23:25:15,550 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Adding alias b to work list for file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813\n2013-10-10 23:25:15,550 INFO ExecMapper: \n<MAP>Id =5\n  <Children>\n    <TS>Id =0\n      <Children>\n        <MAPJOIN>Id =1\n          <Children>\n            <SEL>Id =2\n              <Children>\n                <FS>Id =3\n                  <Parent>Id = 2 null<\\Parent>\n                <\\FS>\n              <\\Children>\n              <Parent>Id = 1 null<\\Parent>\n            <\\SEL>\n          <\\Children>\n          <Parent>Id = 4 \n        <HASHTABLEDUMMY>Id =4\n          <Children>null\n          <\\Children>\n        <\\HASHTABLEDUMMY>Id = 0 null<\\Parent>\n        <\\MAPJOIN>\n      <\\Children>\n      <Parent>Id = 5 null<\\Parent>\n    <\\TS>\n  <\\Children>\n<\\MAP>\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Initializing Self 5 MAP\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Initializing Self 0 TS\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Operator 0 TS initialized\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Initializing children of 0 TS\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing child 1 MAPJOIN\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: Initialization Done 0 TS\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Initialization Done 5 MAP\n2013-10-10 23:25:15,551 INFO ExecMapper: Initializing dummy operator\n2013-10-10 23:25:15,551 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Initializing Self 4 HASHTABLEDUMMY\n2013-10-10 23:25:15,564 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Operator 4 HASHTABLEDUMMY initialized\n2013-10-10 23:25:15,564 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Initializing children of 4 HASHTABLEDUMMY\n2013-10-10 23:25:15,564 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing child 1 MAPJOIN\n2013-10-10 23:25:15,564 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing Self 1 MAPJOIN\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.CommonJoinOperator: JOIN struct<_col0:int,_col1:string,_col2:string,_col3:string> totalsz = 4\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Operator 1 MAPJOIN initialized\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initializing children of 1 MAPJOIN\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initializing child 2 SEL\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initializing Self 2 SEL\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: SELECT struct<_col0:int,_col1:string,_col2:string,_col3:string>\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Operator 2 SEL initialized\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initializing children of 2 SEL\n2013-10-10 23:25:15,575 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initializing child 3 FS\n2013-10-10 23:25:15,576 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initializing Self 3 FS\n2013-10-10 23:25:15,580 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Operator 3 FS initialized\n2013-10-10 23:25:15,580 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Initialization Done 3 FS\n2013-10-10 23:25:15,580 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: Initialization Done 2 SEL\n2013-10-10 23:25:15,583 INFO org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper: maximum memory: 200998912\n2013-10-10 23:25:15,583 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: Initialization Done 1 MAPJOIN\n2013-10-10 23:25:15,583 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: Initialization Done 4 HASHTABLEDUMMY\n2013-10-10 23:25:15,587 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Processing alias b for file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812\n2013-10-10 23:25:15,588 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: ******* Load from HashTable File: input : hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812/test_02.txt\n2013-10-10 23:25:15,589 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: \tLoad back 1 hashtable file from tmp file uri:/home/hadoop/hdfs/mapred/local/taskTracker/distcache/-8026335471844171088_-517161708_586502978/namenode/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/-mr-10006/HashTable-Stage-6/Stage-6.tar.gz/MapJoin-mapfile480--.hashtable\n2013-10-10 23:25:15,605 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 forwarding 1 rows\n2013-10-10 23:25:15,605 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 forwarding 1 rows\n2013-10-10 23:25:15,605 WARN org.apache.hadoop.hive.serde2.lazy.LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.\n2013-10-10 23:25:15,605 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 forwarding 1 rows\n2013-10-10 23:25:15,605 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 forwarding 1 rows\n2013-10-10 23:25:15,606 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Final Path: FS hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/_tmp.-ext-10001/000001_0\n2013-10-10 23:25:15,606 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Writing to temp file: FS hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/_task_tmp.-ext-10001/_tmp.000001_0\n2013-10-10 23:25:15,606 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: New Final Path: FS hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-10_23-21-25_380_3054038040192061682/_tmp.-ext-10001/000001_0\n2013-10-10 23:25:15,649 INFO ExecMapper: ExecMapper: processing 1 rows: used memory = 31506032\n2013-10-10 23:25:15,649 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 forwarding 10 rows\n2013-10-10 23:25:15,649 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 forwarding 10 rows\n2013-10-10 23:25:15,649 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 finished. closing... \n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 forwarded 8 rows\n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.MapOperator: DESERIALIZE_ERRORS:0\n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 finished. closing... \n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 forwarded 8 rows\n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 Close done\n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 Close done\n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: 4 finished. closing... \n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: 4 forwarded 0 rows\n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 finished. closing... \n2013-10-10 23:25:15,650 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 forwarded 12 rows\n2013-10-10 23:25:15,653 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 finished. closing... \n2013-10-10 23:25:15,654 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 forwarded 12 rows\n2013-10-10 23:25:15,654 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 3 finished. closing... \n2013-10-10 23:25:15,654 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 3 forwarded 0 rows\n2013-10-10 23:25:15,713 ERROR org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher: Error during instantiating JDBC driver org.apache.derby.jdbc.EmbeddedDriver. \njava.lang.ClassNotFoundException: org.apache.derby.jdbc.EmbeddedDriver\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:202)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:169)\n\tat org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher.connect(JDBCStatsPublisher.java:68)\n\tat org.apache.hadoop.hive.ql.exec.FileSinkOperator.publishStats(FileSinkOperator.java:963)\n\tat org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:872)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597)\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597)\n\tat org.apache.hadoop.hive.ql.exec.ExecMapper.close(ExecMapper.java:201)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:249)\n2013-10-10 23:25:15,714 ERROR org.apache.hadoop.hive.ql.exec.FileSinkOperator: StatsPublishing error: cannot connect to database\n2013-10-10 23:25:15,714 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: TABLE_ID_1_ROWCOUNT:12\n2013-10-10 23:25:15,714 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 2 Close done\n2013-10-10 23:25:15,714 INFO org.apache.hadoop.hive.ql.exec.MapJoinOperator: 1 Close done\n2013-10-10 23:25:15,714 INFO org.apache.hadoop.hive.ql.exec.HashTableDummyOperator: 4 Close done\n2013-10-10 23:25:15,714 INFO ExecMapper: ExecMapper: processed 8 rows: used memory = 35005952\n2013-10-10 23:25:15,718 INFO org.apache.hadoop.mapred.Task: Task:attempt_201308241420_3665_m_000001_0 is done. And is in the process of commiting\n2013-10-10 23:25:18,085 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201308241420_3665_m_000001_0' done.\n2013-10-10 23:25:18,100 INFO org.apache.hadoop.mapred.TaskLogsTruncater: Initializing logs' truncater with mapRetainSize=-1 and reduceRetainSize=-1\n2013-10-10 23:25:18,117 INFO org.apache.hadoop.io.nativeio.NativeIO: Initialized cache for UID to User mapping with a cache timeout of 14400 seconds.\n2013-10-10 23:25:18,117 INFO org.apache.hadoop.io.nativeio.NativeIO: Got UserName hadoop for UID 500 from the native implementation\n\nHi,Yin Huai, this are the logs of 2 tasks for this CTAS. Otherwise, the hive version is 0.11!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-10-10T15:29:58.902+0000","updated":"2013-10-10T15:29:58.902+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13791604","id":"13791604","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"body":"Seems those logs are at runtime from Map tasks. I meant the log from the Hive driver.\n\nCan you use \n{code}\nbin/hive -hiveconf hive.root.logger=INFO,console \n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"created":"2013-10-10T15:50:59.078+0000","updated":"2013-10-10T15:50:59.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13792214","id":"13792214","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"hive (test)> create table test_10 as\n           > select a.* from test_01 a\n           > join test_02 b\n           > on (a.id=b.id);\n13/10/11 09:17:16 INFO ql.Driver: <PERFLOG method=Driver.run>\n13/10/11 09:17:16 INFO ql.Driver: <PERFLOG method=TimeToSubmit>\n13/10/11 09:17:16 INFO ql.Driver: <PERFLOG method=compile>\n13/10/11 09:17:17 INFO parse.ParseDriver: Parsing command: create table test_10 as\nselect a.* from test_01 a\njoin test_02 b\non (a.id=b.id)\n13/10/11 09:17:17 INFO parse.ParseDriver: Parse Completed\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Starting Semantic Analysis\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Creating table test_10 position=13\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_database: test\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_database: test\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_table : db=test tbl=test_10\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_table : db=test tbl=test_10\n13/10/11 09:17:17 ERROR metastore.RetryingHMSHandler: NoSuchObjectException(message:test.test_10 table not found)\n        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1369)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:102)\n        at $Proxy10.get_table(Unknown Source)\n        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:838)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:74)\n        at $Proxy11.getTable(Unknown Source)\n        at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:948)\n        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:9385)\n        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:8647)\n        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:278)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:433)\n        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:337)\n        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:902)\n        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)\n        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)\n        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)\n        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:756)\n        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)\n\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Completed phase 1 of Semantic Analysis\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Get metadata for source tables\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_table : db=test tbl=test_02\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_table : db=test tbl=test_02\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_table : db=test tbl=test_01\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_table : db=test tbl=test_01\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Get metadata for subqueries\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Get metadata for destination tables\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_database: test\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_database: test\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Completed getting MetaData in Semantic Analysis\n13/10/11 09:17:17 WARN parse.TypeCheckProcFactory: Invalid type entry TOK_TABLE_OR_COL=null\n13/10/11 09:17:17 WARN parse.TypeCheckProcFactory: Invalid type entry TOK_TABLE_OR_COL=null\n13/10/11 09:17:17 INFO ppd.OpProcFactory: Processing for FS(6)\n13/10/11 09:17:17 INFO ppd.OpProcFactory: Processing for SEL(5)\n13/10/11 09:17:17 INFO ppd.OpProcFactory: Processing for JOIN(4)\n13/10/11 09:17:17 INFO ppd.OpProcFactory: Processing for RS(3)\n13/10/11 09:17:17 INFO ppd.OpProcFactory: Processing for TS(0)\n13/10/11 09:17:17 INFO ppd.OpProcFactory: Processing for RS(2)\n13/10/11 09:17:17 INFO ppd.OpProcFactory: Processing for TS(1)\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_database: test\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_database: test\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_database: test\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_database: test\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_partitions_with_auth : db=test tbl=test_02\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_partitions_with_auth : db=test tbl=test_02\n13/10/11 09:17:17 INFO metastore.HiveMetaStore: 0: get_partitions_with_auth : db=test tbl=test_01\n13/10/11 09:17:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_partitions_with_auth : db=test tbl=test_01\n13/10/11 09:17:17 INFO exec.Utilities: Cache Content Summary for hdfs://namenode:9000/user/hive/warehouse/test.db/test_01/record_day=20130812 length: 76 file count: 1 directory count: 1\n13/10/11 09:17:17 INFO exec.Utilities: Cache Content Summary for hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813 length: 169 file count: 1 directory count: 1\n13/10/11 09:17:17 INFO exec.Utilities: Cache Content Summary for hdfs://namenode:9000/user/hive/warehouse/test.db/test_01/record_day=20130813 length: 76 file count: 1 directory count: 1\n13/10/11 09:17:17 INFO exec.Utilities: Cache Content Summary for hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812 length: 169 file count: 1 directory count: 1\n13/10/11 09:17:17 INFO physical.MetadataOnlyOptimizer: Looking for table scans where optimization is applicable\n13/10/11 09:17:17 INFO physical.MetadataOnlyOptimizer: Found 0 metadata only table scans\n13/10/11 09:17:17 INFO physical.MetadataOnlyOptimizer: Looking for table scans where optimization is applicable\n13/10/11 09:17:17 INFO physical.MetadataOnlyOptimizer: Found 0 metadata only table scans\n13/10/11 09:17:17 INFO parse.SemanticAnalyzer: Completed plan generation\n13/10/11 09:17:17 INFO ql.Driver: Semantic Analysis Completed\n13/10/11 09:17:17 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:id, type:int, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:sex, type:string, comment:null), FieldSchema(name:record_day, type:string, comment:null)], properties:null)\n13/10/11 09:17:17 INFO ql.Driver: </PERFLOG method=compile start=1381454236999 end=1381454237416 duration=417>\n13/10/11 09:17:17 INFO ql.Driver: <PERFLOG method=Driver.execute>\n13/10/11 09:17:17 INFO ql.Driver: Starting command: create table test_10 as\nselect a.* from test_01 a\njoin test_02 b\non (a.id=b.id)\nTotal MapReduce jobs = 2\n13/10/11 09:17:17 INFO ql.Driver: Total MapReduce jobs = 2\n13/10/11 09:17:17 INFO ql.Driver: </PERFLOG method=TimeToSubmit start=1381454236999 end=1381454237422 duration=423>\n13/10/11 09:17:17 INFO exec.MapredLocalTask: Generating plan file file:/tmp/hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-local-10007/plan.xml\n13/10/11 09:17:17 INFO exec.MapredLocalTask: Executing: /home/hadoop/package/hadoop-1.0.4/libexec/../bin/hadoop jar /home/hadoop/package/hive-0.11.0/lib/hive-exec-0.11.0.jar org.apache.hadoop.hive.ql.exec.ExecDriver -localtask -plan file:/tmp/hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-local-10007/plan.xml   -jobconffile file:/tmp/hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-local-10008/jobconf.xml\nsetting HADOOP_USER_NAME        hadoop\n13/10/11 09:17:17 INFO exec.Task: setting HADOOP_USER_NAME      hadoop\nExecution log at: /tmp/hadoop/.log\n2013-10-11 09:17:19     Starting to launch local task to process map join;      maximum memory = 932118528\n2013-10-11 09:17:19     Processing rows:        6       Hashtable size: 6       Memory usage:   111004256       rate:   0.119\n2013-10-11 09:17:19     Dump the hashtable into file: file:/tmp/hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-local-10005/HashTable-Stage-6/MapJoin-mapfile30--.hashtable\n2013-10-11 09:17:19     Upload 1 File to: file:/tmp/hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-local-10005/HashTable-Stage-6/MapJoin-mapfile30--.hashtable File size: 692\n2013-10-11 09:17:19     End of local task; Time Taken: 0.44 sec.\nExecution completed successfully\n13/10/11 09:17:19 INFO exec.Task: Execution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\n13/10/11 09:17:19 INFO exec.Task: Mapred Local Task Succeeded . Convert the Join into MapJoin\n13/10/11 09:17:19 INFO exec.MapredLocalTask: Execution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\n13/10/11 09:17:19 INFO exec.Task: Mapred Local Task Succeeded . Convert the Join into MapJoin\nLaunching Job 1 out of 2\n13/10/11 09:17:19 INFO ql.Driver: Launching Job 1 out of 2\nNumber of reduce tasks is set to 0 since there's no reduce operator\n13/10/11 09:17:19 INFO exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator\n13/10/11 09:17:19 INFO exec.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat\n13/10/11 09:17:19 INFO exec.ExecDriver: adding libjars: file:///home/hadoop/hive/lib/hive-contrib-0.11.0.jar\n13/10/11 09:17:19 INFO exec.ExecDriver: Archive 1 hash table files to /tmp/hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-local-10005/HashTable-Stage-6/Stage-6.tar.gz\n13/10/11 09:17:19 INFO exec.ExecDriver: Upload 1 archive file  from/tmp/hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-local-10005/HashTable-Stage-6/Stage-6.tar.gz to: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-mr-10006/HashTable-Stage-6/Stage-6.tar.gz\n13/10/11 09:17:19 INFO exec.ExecDriver: Add 1 archive file to distributed cache. Archive file: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-mr-10006/HashTable-Stage-6/Stage-6.tar.gz\n13/10/11 09:17:19 INFO exec.ExecDriver: Processing alias b\n13/10/11 09:17:19 INFO exec.ExecDriver: Adding input file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812\n13/10/11 09:17:19 INFO exec.Utilities: Content Summary hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812length: 169 num files: 1 num directories: 1\n13/10/11 09:17:19 INFO exec.ExecDriver: Adding input file hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813\n13/10/11 09:17:19 INFO exec.Utilities: Content Summary hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813length: 169 num files: 1 num directories: 1\n13/10/11 09:17:21 INFO exec.ExecDriver: Making Temp Directory: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-ext-10001\n13/10/11 09:17:21 INFO exec.ExecDriver: Making Temp Directory: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-ext-10001\n13/10/11 09:17:21 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.\n13/10/11 09:17:21 INFO io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812; using filter path hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130812\n13/10/11 09:17:21 INFO io.CombineHiveInputFormat: CombineHiveInputSplit: pool is already created for hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813; using filter path hdfs://namenode:9000/user/hive/warehouse/test.db/test_02/record_day=20130813\n13/10/11 09:17:21 INFO mapred.FileInputFormat: Total input paths to process : 2\n13/10/11 09:17:21 INFO io.CombineHiveInputFormat: number of splits 2\nStarting Job = job_201308241420_3712, Tracking URL = http://namenode:50030/jobdetails.jsp?jobid=job_201308241420_3712\n13/10/11 09:17:21 INFO exec.Task: Starting Job = job_201308241420_3712, Tracking URL = http://namenode:50030/jobdetails.jsp?jobid=job_201308241420_3712\nKill Command = /home/hadoop/package/hadoop-1.0.4/libexec/../bin/hadoop job  -kill job_201308241420_3712\n13/10/11 09:17:21 INFO exec.Task: Kill Command = /home/hadoop/package/hadoop-1.0.4/libexec/../bin/hadoop job  -kill job_201308241420_3712\nHadoop job information for Stage-6: number of mappers: 2; number of reducers: 0\n13/10/11 09:17:34 INFO exec.Task: Hadoop job information for Stage-6: number of mappers: 2; number of reducers: 0\n2013-10-11 09:17:34,882 Stage-6 map = 0%,  reduce = 0%\n13/10/11 09:17:34 INFO exec.Task: 2013-10-11 09:17:34,882 Stage-6 map = 0%,  reduce = 0%\n2013-10-11 09:17:40,967 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n13/10/11 09:17:40 INFO exec.Task: 2013-10-11 09:17:40,967 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n2013-10-11 09:17:41,975 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n13/10/11 09:17:41 INFO exec.Task: 2013-10-11 09:17:41,975 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n2013-10-11 09:17:42,981 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n13/10/11 09:17:42 INFO exec.Task: 2013-10-11 09:17:42,981 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n2013-10-11 09:17:43,987 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n13/10/11 09:17:43 INFO exec.Task: 2013-10-11 09:17:43,987 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n2013-10-11 09:17:44,993 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n13/10/11 09:17:44 INFO exec.Task: 2013-10-11 09:17:44,993 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n2013-10-11 09:17:46,005 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\n13/10/11 09:17:46 INFO exec.Task: 2013-10-11 09:17:46,005 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.69 sec\nMapReduce Total cumulative CPU time: 2 seconds 690 msec\n13/10/11 09:17:46 INFO exec.Task: MapReduce Total cumulative CPU time: 2 seconds 690 msec\nEnded Job = job_201308241420_3712\n13/10/11 09:17:46 INFO exec.Task: Ended Job = job_201308241420_3712\n13/10/11 09:17:46 INFO exec.FileSinkOperator: Moving tmp dir: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/_tmp.-ext-10001 to: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/_tmp.-ext-10001.intermediate\n13/10/11 09:17:46 INFO exec.FileSinkOperator: Moving tmp dir: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/_tmp.-ext-10001.intermediate to: hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-ext-10001\nStage-7 is filtered out by condition resolver.\n13/10/11 09:17:46 INFO exec.Task: Stage-7 is filtered out by condition resolver.\n24 Rows loaded to hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-ext-10000\n13/10/11 09:17:46 INFO exec.HiveHistory: 24 Rows loaded to hdfs://namenode:9000/tmp/hive-hadoop/hive_2013-10-11_09-17-16_999_5875059535154038958/-ext-10000\n13/10/11 09:17:46 INFO ql.Driver: </PERFLOG method=Driver.execute start=1381454237416 end=1381454266048 duration=28632>\nMapReduce Jobs Launched:\n13/10/11 09:17:46 INFO ql.Driver: MapReduce Jobs Launched:\nJob 0: Map: 2   Cumulative CPU: 2.69 sec   HDFS Read: 822 HDFS Write: 452 SUCCESS\n13/10/11 09:17:46 INFO ql.Driver: Job 0: Map: 2   Cumulative CPU: 2.69 sec   HDFS Read: 822 HDFS Write: 452 SUCCESS\nTotal MapReduce CPU Time Spent: 2 seconds 690 msec\n13/10/11 09:17:46 INFO ql.Driver: Total MapReduce CPU Time Spent: 2 seconds 690 msec\nOK\n13/10/11 09:17:46 INFO ql.Driver: OK\n13/10/11 09:17:46 INFO ql.Driver: <PERFLOG method=releaseLocks>\n13/10/11 09:17:46 INFO ql.Driver: </PERFLOG method=releaseLocks start=1381454266049 end=1381454266049 duration=0>\n13/10/11 09:17:46 INFO ql.Driver: </PERFLOG method=Driver.run start=1381454236999 end=1381454266050 duration=29051>\nTime taken: 29.057 seconds\n13/10/11 09:17:46 INFO CliDriver: Time taken: 29.057 seconds\n13/10/11 09:17:46 INFO ql.Driver: <PERFLOG method=releaseLocks>\n13/10/11 09:17:46 INFO ql.Driver: </PERFLOG method=releaseLocks start=1381454266057 end=1381454266057 duration=0>\nhive (test)>","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-10-11T01:20:47.048+0000","updated":"2013-10-11T01:20:47.048+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13792252","id":"13792252","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"\"ERROR metastore.RetryingHMSHandler: NoSuchObjectException(message:test.test_10 table not found)\", that may be the key factor of this problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-10-11T01:58:17.553+0000","updated":"2013-10-11T01:58:17.553+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13792648","id":"13792648","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"body":"I think that error log is fine. Because you have a CTAS query and test_10 did not exist in your db, so when we first tried to get the table for test_10, we would not be able to get the corresponding object.\n\nSeems stages for move operator and create table operator were not executed. Can you try the trunk?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"created":"2013-10-11T14:21:55.115+0000","updated":"2013-10-11T14:21:55.115+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13793280","id":"13793280","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"body":"Hi, Yin Huai.  What is going on next step \"Can you try the trunk?\"\nI deem that the middle join results of join operator may not be saved and not be written to the temp HDFS. In other words, it may be failure, like 'Stage-7 is filtered out by condition resolver'. \nThe other problem that we encountered recently is like below:\nhive (test)> select a.* from test_01 a\n           > join (select b.id from test_02 b\n           > join test_03 c\n           > on (b.id =c.id)) d\n           > on (a.id=d.id);\nTotal MapReduce jobs = 4\nsetting HADOOP_USER_NAME        hadoop\nExecution log at: /tmp/hadoop/.log\n2013-10-12 02:36:42     Starting to launch local task to process map join;      maximum memory = 932118528\n2013-10-12 02:36:43     Processing rows:        4       Hashtable size: 4       Memory usage:   110930744       rate:   0.119\n2013-10-12 02:36:43     Dump the hashtable into file: file:/tmp/hadoop/hive_2013-10-12_14-36-40_657_1301190087196742169/-local-10011/HashTable-Stage-9/MapJoin-mapfile41--.hashtable\n2013-10-12 02:36:43     Upload 1 File to: file:/tmp/hadoop/hive_2013-10-12_14-36-40_657_1301190087196742169/-local-10011/HashTable-Stage-9/MapJoin-mapfile41--.hashtable File size: 444\n2013-10-12 02:36:43     End of local task; Time Taken: 0.413 sec.\nExecution completed successfully\nMapred Local Task Succeeded . Convert the Join into MapJoin\nMapred Local Task Succeeded . Convert the Join into MapJoin\nLaunching Job 1 out of 4\nNumber of reduce tasks is set to 0 since there's no reduce operator\nStarting Job = job_201308241420_4028, Tracking URL = http://namenode:50030/jobdetails.jsp?jobid=job_201308241420_4028\nKill Command = /home/hadoop/package/hadoop-1.0.4/libexec/../bin/hadoop job  -kill job_201308241420_4028\nHadoop job information for Stage-9: number of mappers: 2; number of reducers: 0\n2013-10-12 14:36:58,185 Stage-9 map = 0%,  reduce = 0%\n2013-10-12 14:37:04,207 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec\n2013-10-12 14:37:05,213 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec\n2013-10-12 14:37:06,218 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec\n2013-10-12 14:37:07,223 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec\n2013-10-12 14:37:08,228 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec\n2013-10-12 14:37:09,232 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec\n2013-10-12 14:37:10,237 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.66 sec\nMapReduce Total cumulative CPU time: 2 seconds 660 msec\nEnded Job = job_201308241420_4028\nStage-12 is filtered out by condition resolver.\nMapReduce Jobs Launched:\nJob 0: Map: 2   Cumulative CPU: 2.66 sec   HDFS Read: 822 HDFS Write: 2190 SUCCESS\nTotal MapReduce CPU Time Spent: 2 seconds 660 msec\nOK\nTime taken: 29.662 seconds\nhive (test)>\n\nNote： the table of test_01, test_02 and test_03 have data, and have the same values of id, but we can't get results. Inversely, it returns nothing. The problem may also be caused by “Stage-12 is filtered out by condition resolver”. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeff_little","name":"jeff_little","key":"jeff_little","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jeff little","active":true,"timeZone":"Etc/UTC"},"created":"2013-10-12T06:43:16.578+0000","updated":"2013-10-12T06:43:16.578+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12667539/comment/13793439","id":"13793439","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"body":"I meant you can try hive trunk and see if the error also exist. If the error also exist, we need to find a way to reproduce it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhuai","name":"yhuai","key":"yhuai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yhuai&avatarId=23452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yhuai&avatarId=23452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yhuai&avatarId=23452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yhuai&avatarId=23452"},"displayName":"Yin Huai","active":true,"timeZone":"America/New_York"},"created":"2013-10-12T18:50:12.216+0000","updated":"2013-10-12T18:50:12.216+0000"}],"maxResults":19,"total":19,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-5245/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1nx1b:"}}