{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12840640","self":"https://issues.apache.org/jira/rest/api/2/issue/12840640","key":"HIVE-11116","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310843","id":"12310843","key":"HIVE","name":"Hive","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-12-10T07:56:58.671+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Oct 13 09:38:33 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11116/watchers","watchCount":17,"isWatching":false},"created":"2015-06-25T20:46:23.133+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329345","id":"12329345","description":"Hive 1.2.0","name":"1.2.0","archived":false,"released":true,"releaseDate":"2015-05-18"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12329363","id":"12329363","name":"1.1.0","archived":false,"released":true,"releaseDate":"2015-03-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332154","id":"12332154","description":"","name":"1.3.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332641","id":"12332641","description":"Hive 2.0.0","name":"2.0.0","archived":false,"released":true,"releaseDate":"2016-02-15"}],"issuelinks":[{"id":"12506070","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12506070","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12993410","key":"HIVE-14380","self":"https://issues.apache.org/jira/rest/api/2/issue/12993410","fields":{"summary":"Queries on tables with remote HDFS paths fail in \"encryption\" checks.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12428941","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12428941","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12765172","key":"HIVE-9264","self":"https://issues.apache.org/jira/rest/api/2/issue/12765172","fields":{"summary":"Merge encryption branch to trunk","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-10-13T09:38:33.259+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12324791","id":"12324791","name":"Encryption"}],"timeoriginalestimate":null,"description":"I tried to create new table which points to remote hdfs location and select data from it.\n\nIt works for hive-0.14 and hive-1.0  but it does not work starting from hive-1.1\n\nto reproduce the issue\n1. create folder on remote hdfs\n{code}\nhadoop fs -mkdir -p hdfs://remote-nn/tmp/et1\n{code}\n\n2. create table \n{code}\nCREATE TABLE et1 (\n  a string\n) stored as textfile\nLOCATION 'hdfs://remote-nn/tmp/et1';\n{code}\n\n3. run select\n{code}\nselect * from et1 limit 10;\n{code}\n\n4. Should get the following error\n{code}\nselect * from et1;\n15/06/25 13:43:44 [main]: ERROR parse.CalcitePlanner: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to determine if hdfs://remote-nn/tmp/et1is encrypted: java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-nn/tmp/et1, expected: hdfs://localhost:8020\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.isPathEncrypted(SemanticAnalyzer.java:1763)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getStagingDirectoryPathname(SemanticAnalyzer.java:1875)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:1689)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:1427)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:10132)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10147)\n\tat org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:190)\n\tat org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:222)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:421)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:307)\n\tat org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1112)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1160)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1039)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:207)\n\tat org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:159)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:370)\n\tat org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:754)\n\tat org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)\n\tat org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:615)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-nn/tmp/et1, expected: hdfs://localhost:8020\n\tat org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getEZForPath(DistributedFileSystem.java:1906)\n\tat org.apache.hadoop.hdfs.client.HdfsAdmin.getEncryptionZoneForPath(HdfsAdmin.java:262)\n\tat org.apache.hadoop.hive.shims.Hadoop23Shims$HdfsEncryptionShim.isPathEncrypted(Hadoop23Shims.java:1097)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.isPathEncrypted(SemanticAnalyzer.java:1759)\n\t... 25 more\n\nFAILED: SemanticException Unable to determine if hdfs://remote-nn/tmp/et1is encrypted: java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-nn/tmp/et1, expected: hdfs://localhost:8020\n15/06/25 13:43:44 [main]: ERROR ql.Driver: FAILED: SemanticException Unable to determine if hdfs://remote-nn/tmp/et1is encrypted: java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-nn/tmp/et1, expected: hdfs://localhost:8020\norg.apache.hadoop.hive.ql.parse.SemanticException: Unable to determine if hdfs://remote-nn/tmp/et1is encrypted: java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-nn/tmp/et1, expected: hdfs://localhost:8020\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:1743)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:1427)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:10132)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10147)\n\tat org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:190)\n\tat org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:222)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:421)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:307)\n\tat org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1112)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1160)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1039)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:207)\n\tat org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:159)\n\tat org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:370)\n\tat org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:754)\n\tat org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)\n\tat org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:615)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to determine if hdfs://remote-nn/tmp/et1is encrypted: java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-nn/tmp/et1, expected: hdfs://localhost:8020\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.isPathEncrypted(SemanticAnalyzer.java:1763)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getStagingDirectoryPathname(SemanticAnalyzer.java:1875)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:1689)\n\t... 23 more\nCaused by: java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-nn/tmp/et1, expected: hdfs://localhost:8020\n\tat org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getEZForPath(DistributedFileSystem.java:1906)\n\tat org.apache.hadoop.hdfs.client.HdfsAdmin.getEncryptionZoneForPath(HdfsAdmin.java:262)\n\tat org.apache.hadoop.hive.shims.Hadoop23Shims$HdfsEncryptionShim.isPathEncrypted(Hadoop23Shims.java:1097)\n\tat org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.isPathEncrypted(SemanticAnalyzer.java:1759)\n\t... 25 more\n{code}\n\n5. can you also fix bug with log message below. It should be space before \"is encrypted\"\n{code}\nUnable to determine if hdfs://remote-nn/tmp/et1is encrypted\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12820392","id":"12820392","filename":"HIVE-11116.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"created":"2016-07-27T08:27:32.846+0000","size":2055,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12820392/HIVE-11116.1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Can not select data from table which points to remote hdfs location","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apivovarov","name":"apivovarov","key":"apivovarov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apivovarov&avatarId=25851","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apivovarov&avatarId=25851","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apivovarov&avatarId=25851","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apivovarov&avatarId=25851"},"displayName":"Alexander Pivovarov","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apivovarov","name":"apivovarov","key":"apivovarov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apivovarov&avatarId=25851","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apivovarov&avatarId=25851","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apivovarov&avatarId=25851","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apivovarov&avatarId=25851"},"displayName":"Alexander Pivovarov","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15050272","id":"15050272","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sivasaravanakumar","name":"sivasaravanakumar","key":"sivasaravanakumar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sivasaravanakumar","active":true,"timeZone":"Etc/UTC"},"body":"I found that the Hive metastore tracks the location of each table. You can see the that location be running the following in the Hive console.\n\nhive> DESCRIBE EXTENDED test_table;\nThus, this issue occurs if the NameNode in core-site.xml was changed while the metastore service was still running. Therefore, to resolve this issue the service should be restarted on that machine:\n\n$ sudo service hive-metastore restart\nThen, the metastore will use the new fs.defaultFS for newly created tables such.\n\nAlready Existing Tables\nThe location for tables that already exist can be corrected by running the following set of commands. These were obtained from Cloudera documentation to configure the Hive metastore to use High-Availability.\n\n$ /usr/lib/hive/bin/metatool -listFSRoot\n...\nListing FS Roots..\nhdfs://localhost:8020/user/hive/warehouse\nhdfs://localhost:8020/user/hive/warehouse/test.db\nCorrecting the NameNode location:\n\n$ /usr/lib/hive/bin/metatool -updateLocation hdfs://hadoop:8020 hdfs://localhost:8020\nNow the listed NameNode is correct.\n\n$ /usr/lib/hive/bin/metatool -listFSRoot\n...\nListing FS Roots..\nhdfs://hadoop:8020/user/hive/warehouse\nhdfs://hadoop:8020/user/hive/warehouse/test.db","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sivasaravanakumar","name":"sivasaravanakumar","key":"sivasaravanakumar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sivasaravanakumar","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-10T07:56:58.671+0000","updated":"2015-12-10T07:56:58.671+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15395224","id":"15395224","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"body":"attaching a simple workaround that allows to read from remote HDFS locations at least when there are no encryption zones","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"created":"2016-07-27T08:27:32.871+0000","updated":"2016-07-27T08:29:18.845+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15400614","id":"15400614","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ychena","name":"ychena","key":"ychena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongzhi Chen","active":true,"timeZone":"Etc/UTC"},"body":"[~DavidKaroly], the fix looks good, could you add some tests if possible?\nAnd in order to run precommit build, you have to submit your patch. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ychena","name":"ychena","key":"ychena","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongzhi Chen","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-30T09:49:58.829+0000","updated":"2016-07-30T09:49:58.829+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15401601","id":"15401601","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"body":"[~ychena] thanks for the hint. I've submitted the patch for a precommit run, meanwhile I'm trying to think up a unit test for this. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"created":"2016-08-01T06:36:29.136+0000","updated":"2016-08-01T06:36:29.136+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15402731","id":"15402731","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12820392/HIVE-11116.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 10419 tests executed\n*Failed tests:*\n{noformat}\nTestMsgBusConnection - did not produce a TEST-*.xml file\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_nullable_union\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_auto_partitioned\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_avro_non_nullable_union\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns\norg.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/724/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/724/console\nTest logs: http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-724/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 8 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12820392 - PreCommit-HIVE-MASTER-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2016-08-01T20:09:55.274+0000","updated":"2016-08-01T20:09:55.274+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15402918","id":"15402918","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"body":"\n\ntestCliDriver_avro_nullable_union, testNegativeCliDriver_avro_non_nullable_union - failing recently because data files were missing in HIVE-14205, shall be fixed in HIVE-14395\n\nstringifyValidTxns, testTxnRange - failing in recent builds\n\ntestCliDriver_stats_list_bucket - seems to be unstable\n\nnot sure about testCliDriver_index_auto_mult_tables and testCliDriver_index_bitmap_auto_partitioned, will look into that","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=DavidKaroly","name":"DavidKaroly","key":"davidkaroly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=davidkaroly&avatarId=27002","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=davidkaroly&avatarId=27002","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=davidkaroly&avatarId=27002","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=davidkaroly&avatarId=27002"},"displayName":"David Karoly","active":true,"timeZone":"Europe/Budapest"},"created":"2016-08-01T22:12:16.995+0000","updated":"2016-08-01T22:12:16.995+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15795956","id":"15795956","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shyamsunderrai%40gmail.com","name":"shyamsunderrai@gmail.com","key":"shyamsunderrai@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shyam Rai","active":true,"timeZone":"America/Los_Angeles"},"body":"This issue seems to be encountered only when FQDN:8020 is used for creating the table when the cluster is in HA. It would be ideal to let users learn the new way of using HA name rather than FQDN:8020 ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shyamsunderrai%40gmail.com","name":"shyamsunderrai@gmail.com","key":"shyamsunderrai@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shyam Rai","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-03T19:29:05.202+0000","updated":"2017-01-03T19:29:05.202+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/15796104","id":"15796104","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12820392/HIVE-11116.1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/2767/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/2767/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2767/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-01-03 20:30:27.980\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-2767/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-01-03 20:30:27.982\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at c928ad3 HIVE-15528: Expose Spark job error in SparkTask (Zhihai via Xuefu)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at c928ad3 HIVE-15528: Expose Spark job error in SparkTask (Zhihai via Xuefu)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-01-03 20:30:28.949\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p1\npatching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java\nHunk #1 succeeded at 2268 with fuzz 1 (offset 70 lines).\npatching file ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java\nHunk #1 succeeded at 483 with fuzz 1 (offset 29 lines).\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nDataNucleus Enhancer (version 4.1.6) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nDataNucleus Enhancer completed with success for 30 classes. Timings : input=144 ms, enhance=177 ms, total=321 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nGenerating vector expression code\nGenerating vector expression test code\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2271,46] cannot find symbol\n  symbol:   variable path\n  location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2272,74] cannot find symbol\n  symbol:   variable path\n  location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2271,46] cannot find symbol\n[ERROR] symbol:   variable path\n[ERROR] location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2272,74] cannot find symbol\n[ERROR] symbol:   variable path\n[ERROR] location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12820392 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-01-03T20:31:39.089+0000","updated":"2017-01-03T20:31:39.089+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/16043557","id":"16043557","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks like HIVE-14380 is a dupe of this issue, and that one was fixed/landed, although the solution approach was different.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sushanth","name":"sushanth","key":"sushanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=sushanth&avatarId=26812","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sushanth&avatarId=26812","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sushanth&avatarId=26812","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sushanth&avatarId=26812"},"displayName":"Sushanth Sowmyan","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-08T22:43:20.034+0000","updated":"2017-06-08T22:43:20.034+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/16043857","id":"16043857","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12820392/HIVE-11116.1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5593/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5593/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5593/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-06-09 03:04:44.892\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-5593/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-06-09 03:04:44.895\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at a186969 HIVE-16644 : Hook Change Manager to Insert Overwrite (Sankar Hariappan via Thejas Nair)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at a186969 HIVE-16644 : Hook Change Manager to Insert Overwrite (Sankar Hariappan via Thejas Nair)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-06-09 03:04:49.102\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p1\npatching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java\nHunk #1 succeeded at 2326 with fuzz 1 (offset 128 lines).\npatching file ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java\nHunk #1 succeeded at 503 with fuzz 1 (offset 49 lines).\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nDataNucleus Enhancer (version 4.1.17) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMetastoreDBProperties\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nDataNucleus Enhancer completed with success for 31 classes. Timings : input=189 ms, enhance=263 ms, total=452 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g\norg/apache/hadoop/hive/ql/parse/HintParser.g\nGenerating vector expression code\nGenerating vector expression test code\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2329,46] cannot find symbol\n  symbol:   variable path\n  location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2330,74] cannot find symbol\n  symbol:   variable path\n  location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2329,46] cannot find symbol\n[ERROR] symbol:   variable path\n[ERROR] location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2330,74] cannot find symbol\n[ERROR] symbol:   variable path\n[ERROR] location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12820392 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-06-09T03:06:15.638+0000","updated":"2017-06-09T03:06:15.638+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/16202630","id":"16202630","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mithun","name":"mithun","key":"mithun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mithun&avatarId=18936","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mithun&avatarId=18936","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mithun&avatarId=18936","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mithun&avatarId=18936"},"displayName":"Mithun Radhakrishnan","active":true,"timeZone":"America/Los_Angeles"},"body":"[~sushanth] is right. This should have been resolved as part of HIVE-14380. If yes, can this JIRA be closed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mithun","name":"mithun","key":"mithun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mithun&avatarId=18936","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mithun&avatarId=18936","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mithun&avatarId=18936","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mithun&avatarId=18936"},"displayName":"Mithun Radhakrishnan","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-12T21:13:11.864+0000","updated":"2017-10-12T21:13:11.864+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12840640/comment/16203306","id":"16203306","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"body":"\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12820392/HIVE-11116.1.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7271/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7271/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7271/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-10-13 09:37:19.979\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-7271/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-10-13 09:37:19.982\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 0a9fabb HIVE-17790: Export/Import: Bug while getting auth entities due to which we write partition info during compilation phase (Vaibhav Gumashta reviewed by Thejas Nair)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 0a9fabb HIVE-17790: Export/Import: Bug while getting auth entities due to which we write partition info during compilation phase (Vaibhav Gumashta reviewed by Thejas Nair)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-10-13 09:37:20.667\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nGoing to apply patch with: patch -p1\npatching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java\nHunk #1 succeeded at 2313 with fuzz 1 (offset 115 lines).\npatching file ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java\nHunk #1 succeeded at 511 with fuzz 1 (offset 57 lines).\n+ [[ maven == \\m\\a\\v\\e\\n ]]\n+ rm -rf /data/hiveptest/working/maven/org/apache/hive\n+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven\nprotoc-jar: protoc version: 250, detected platform: linux/amd64\nprotoc-jar: executing: [/tmp/protoc5070043626498153362.exe, -I/data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/protobuf/org/apache/hadoop/hive/metastore, --java_out=/data/hiveptest/working/apache-github-source-source/standalone-metastore/target/generated-sources, /data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/protobuf/org/apache/hadoop/hive/metastore/metastore.proto]\nDataNucleus Enhancer (version 4.1.17) for API \"JDO\"\nDataNucleus Enhancer : Classpath\n>>  /usr/share/maven/boot/plexus-classworlds-2.x.jar\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDatabase\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFieldSchema\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MType\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MConstraint\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MOrder\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStringList\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartition\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MIndex\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRole\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MRoleMap\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMasterKey\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MDelegationToken\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MVersionTable\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MMetastoreDBProperties\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MResourceUri\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MFunction\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationLog\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MNotificationNextId\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMResourcePlan\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMPool\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMTrigger\nENHANCED (Persistable) : org.apache.hadoop.hive.metastore.model.MWMMapping\nDataNucleus Enhancer completed with success for 35 classes. Timings : input=259 ms, enhance=253 ms, total=512 ms. Consult the log for full details\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/metastore/target/generated-sources/antlr3/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g\norg/apache/hadoop/hive/metastore/parser/Filter.g\nANTLR Parser Generator  Version 3.5.2\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\norg/apache/hadoop/hive/ql/parse/HiveLexer.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\norg/apache/hadoop/hive/ql/parse/HiveParser.g\nOutput file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g\norg/apache/hadoop/hive/ql/parse/HintParser.g\nGenerating vector expression code\nGenerating vector expression test code\n[ERROR] COMPILATION ERROR : \n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2316,46] cannot find symbol\n  symbol:   variable path\n  location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2317,74] cannot find symbol\n  symbol:   variable path\n  location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2316,46] cannot find symbol\n[ERROR] symbol:   variable path\n[ERROR] location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[2317,74] cannot find symbol\n[ERROR] symbol:   variable path\n[ERROR] location: class org.apache.hadoop.hive.ql.parse.SemanticAnalyzer\n[ERROR] -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hive-exec\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12820392 - PreCommit-HIVE-Build","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hiveqa","name":"hiveqa","key":"hiveqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hiveqa&avatarId=17060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hiveqa&avatarId=17060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hiveqa&avatarId=17060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hiveqa&avatarId=17060"},"displayName":"Hive QA","active":true,"timeZone":"America/Chicago"},"created":"2017-10-13T09:38:33.259+0000","updated":"2017-10-13T09:38:33.259+0000"}],"maxResults":12,"total":12,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HIVE-11116/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2gibb:"}}