{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [{
            "description": "Tracks issue dealing with metastore.",
            "id": "12312584",
            "name": "Metastore",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312584"
        }],
        "created": "2015-01-26T19:40:21.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Manish Malhotra",
            "key": "manish.hadoop.work@gmail.com",
            "name": "manish.hadoop.work@gmail.com",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=manish.hadoop.work%40gmail.com",
            "timeZone": "America/Los_Angeles"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2015-02-11T05:54:38.121+0000",
        "customfield_12310222": null,
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "2.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i24t7r:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Tue May 05 19:55:22 UTC 2015",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Hi All,\n\nPlease review the following problem, I also posted same in the hive-user group, but didnt got any response yet. \nThis is happening quite frequently in our environment. \nSo, it would be great if somebody can see and advise. \n\nI'm using Hive Thrift Server in Production which at peak handles around 500 req/min.\nAfter certain point the Hive Thrift Server is going into the no response mode and throws \nFollowing exception \n\"org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: Read timed out\" \n\nAs the metastore we are using MySQL, that is being used by Thrift server. \nThe design / architecture is like this: \n\nOozie -- > Hive Action --> ELB (AWS) --> Hive Thrift ( 2 servers) --> MySQL (Master) -- > MySQL (Slave).\n\nSoftware versions: \n\n   Hive version : 0.10.0\n   Hadoop: 1.2.1\n\n\nLooks like when the load is beyond some threshold for certain operations it is having problem in responding. \nAs the hive jobs sometimes fails because of this issue, we also have a auto-restart check to see if the Thrift server is not responding, it stops / kills and restart the service. \n\nOther tuning done: \n\nThrift Server: \n\nGiven 11gb heap, and configured CMS GC algo. \n\nMySQL: \n\nTuned innodb_buffer, tmp_table and max_heap parameters.\n\nSo, can somebody please help to understand, what could be the root cause for this or somebody faced the similar issue. \n\nI found one related JIRA :https://issues.apache.org/jira/browse/HCATALOG-541\n\nBut this JIRA shows that Hive Thrift Server shows OOM error, but in my case I didnt see any OOM error in my case.\n\n\nRegards,\nManish\n\nFull Exception Stack: \n\n    at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:378)\n    at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:297)\n    at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:204)\n    at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_database(ThriftHiveMetastore.java:412)\n    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_database(ThriftHiveMetastore.java:399)\n    at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:736)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:74)\n    at $Proxy7.getDatabase(Unknown Source)\n    at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1110)\n    at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1099)\n    at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2206)\n    at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:334)\n    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:138)\n    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)\n    at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1336)\n    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1122)\n    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:935)\n    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)\n    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)\n    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412)\n    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:347)\n    at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:706)\n    at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:613)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at org.apache.hadoop.util.RunJar.main(RunJar.java:160)\nCaused by: java.net.SocketTimeoutException: Read timed out\n    at java.net.SocketInputStream.socketRead0(Native Method)\n    at java.net.SocketInputStream.read(SocketInputStream.java:150)\n    at java.net.SocketInputStream.read(SocketInputStream.java:121)\n    at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n    at java.io.BufferedInputStream.read1(BufferedInputStream.java:275)\n    at java.io.BufferedInputStream.read(BufferedInputStream.java:334)\n    at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)\n    ... 34 more\n2015-01-20 22:44:12,978 ERROR exec.Task (SessionState.java:printError(401)) - FAILED: Error in metadata: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: Read timed out\norg.apache.hadoop.hive.ql.metadata.HiveException: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: Read timed out\n    at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1114)\n    at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1099)\n    at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2206)\n    at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:334)\n    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:138)\n    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)\n    at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1336)\n    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1122)\n    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:935)\n    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)\n    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)",
        "duedate": null,
        "environment": "4 core cpu, 15gb memory. 2 thrift server behind load balancer",
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935"
            },
            "id": "12310843",
            "key": "HIVE",
            "name": "Hive",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310843"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Manish Malhotra",
            "key": "manish.hadoop.work@gmail.com",
            "name": "manish.hadoop.work@gmail.com",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=manish.hadoop.work%40gmail.com",
            "timeZone": "America/Los_Angeles"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "Hive Thrift Server throws Socket Timeout Exception: Read time out",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2015-05-05T19:55:22.000+0000",
        "versions": [{
            "archived": false,
            "description": "released",
            "id": "12320745",
            "name": "0.10.0",
            "releaseDate": "2013-01-11",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12320745"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-9469/votes",
            "votes": 1
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-9469/watchers",
            "watchCount": 5
        },
        "workratio": -1
    },
    "id": "12770161",
    "key": "HIVE-9469",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12770161"
}