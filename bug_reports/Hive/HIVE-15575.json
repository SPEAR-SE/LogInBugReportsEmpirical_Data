{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [],
        "created": "2017-01-10T23:43:45.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mithun&avatarId=18936",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mithun&avatarId=18936",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mithun&avatarId=18936",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mithun&avatarId=18936"
            },
            "displayName": "Mithun Radhakrishnan",
            "key": "mithun",
            "name": "mithun",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=mithun",
            "timeZone": "America/Los_Angeles"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2017-01-11T13:36:06.563+0000",
        "customfield_12310222": null,
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i38iz3:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Jan 11 13:36:06 UTC 2017",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Hive {{UNION ALL}} produces data in sub-directories under the table/partition directories. E.g.\n\n{noformat}\nhive (mythdb_hadooppf_17544)> create table source ( foo string, bar string, goo string ) stored as textfile;\nOK\nTime taken: 0.322 seconds\nhive (mythdb_hadooppf_17544)> create table results_partitioned( foo string, bar string, goo string ) partitioned by ( dt string ) stored as orcfile;\nOK\nTime taken: 0.322 seconds\nhive (mythdb_hadooppf_17544)> set hive.merge.tezfiles=false; insert overwrite table results_partitioned partition( dt ) select 'goo', 'bar', 'foo', '1' from source UNION ALL select 'go', 'far', 'moo', '1' from source;\n...\nLoading data to table mythdb_hadooppf_17544.results_partitioned partition (dt=null)\n         Time taken for load dynamic partitions : 311\n        Loading partition {dt=1}\n         Time taken for adding to write entity : 3\nOK\nTime taken: 27.659 seconds\nhive (mythdb_hadooppf_17544)> dfs -ls -R /tmp/mythdb_hadooppf_17544/results_partitioned;\ndrwxrwxrwt   - dfsload hdfs          0 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1\ndrwxrwxrwt   - dfsload hdfs          0 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/1\n-rwxrwxrwt   3 dfsload hdfs        349 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/1/000000_0\ndrwxrwxrwt   - dfsload hdfs          0 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/2\n-rwxrwxrwt   3 dfsload hdfs        368 2017-01-10 23:13 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/2/000000_0\n{noformat}\n\nThese results can only be read if {{mapred.input.dir.recursive=true}}, as {{TezCompiler::init()}} seems to do. But the Hadoop default for this is {{false}}. This leads to the following errors:\n1. Running {{CONCATENATE}} on the partition on the partition causes data-loss.\n{noformat}\nhive --database mythdb_hadooppf_17544 -e \" set mapred.input.dir.recursive; alter table results_partitioned partition ( dt='1' ) concatenate ; set mapred.input.dir.recursive; \"\n...\nOK\nTime taken: 2.151 seconds\nmapred.input.dir.recursive=false\n\n\nStatus: Running (Executing on YARN cluster with App id application_1481756273279_5088754)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nFile Merge         SUCCEEDED      0          0        0        0       0       0\n--------------------------------------------------------------------------------\nVERTICES: 01/01  [>>--------------------------] 0%    ELAPSED TIME: 0.35 s\n--------------------------------------------------------------------------------\nLoading data to table mythdb_hadooppf_17544.results_partitioned partition (dt=1)\nMoved: 'hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/1' to trash at: hdfs://cluster-nn1.mygrid.myth.net:8020/user/dfsload/.Trash/Current\nMoved: 'hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/dt=1/2' to trash at: hdfs://cluster-nn1.mygrid.myth.net:8020/user/dfsload/.Trash/Current\nOK\nTime taken: 25.873 seconds\n\n$ hdfs dfs -count -h /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1\n           1            0                  0 /tmp/mythdb_hadooppf_17544/results_partitioned/dt=1\n{noformat}\n\n2. hive.merge.tezfiles is busted, because the merge-task attempts to merge files across {{results_partitioned/dt=1/1}} and {{results_partitioned/dt=1/2}}:\n{noformat}\n$ hive --database mythdb_hadooppf_17544 -e \" set hive.merge.tezfiles=true; insert overwrite table results_partitioned partition( dt ) select 'goo', 'bar', 'foo', '1' from source UNION ALL select 'go', 'far', 'moo', '1' from source; \"\n...\nQuery ID = dfsload_20170110233558_51289333-d9da-4851-8671-bfe653d26e45\nTotal jobs = 3\nLaunching Job 1 out of 3\n\n\nStatus: Running (Executing on YARN cluster with App id application_1481756273279_5089989)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nMap 1 ..........   SUCCEEDED      1          1        0        0       0       0\nMap 3 ..........   SUCCEEDED      1          1        0        0       0       0\n--------------------------------------------------------------------------------\nVERTICES: 02/02  [==========================>>] 100%  ELAPSED TIME: 13.07 s\n--------------------------------------------------------------------------------\nStage-4 is filtered out by condition resolver.\nStage-3 is selected by condition resolver.\nStage-5 is filtered out by condition resolver.\nLaunching Job 3 out of 3\n\n\nStatus: Running (Executing on YARN cluster with App id application_1481756273279_5089989)\n\n--------------------------------------------------------------------------------\n        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED\n--------------------------------------------------------------------------------\nFile Merge           RUNNING      1          0        1        0       2       0\n--------------------------------------------------------------------------------\nVERTICES: 00/01  [>>--------------------------] 0%    ELAPSED TIME: 3.06 s\n--------------------------------------------------------------------------------\n...\n{noformat}\n\nThe {{File Merge}} fails with the following:\n\n{noformat}\nTaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileTezProcessor.run(MergeFileTezProcessor.java:42)\n        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:362)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:192)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:184)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1738)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:184)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:180)\n        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.processRow(MergeFileRecordProcessor.java:217)\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.run(MergeFileRecordProcessor.java:151)\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)\n        ... 14 more\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.processKeyValuePairs(OrcFileMergeOperator.java:159)\n        at org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.process(OrcFileMergeOperator.java:62)\n        at org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.processRow(MergeFileRecordProcessor.java:208)\n        ... 16 more\nCaused by: java.io.IOException: Multiple partitions for one merge mapper: hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/2 NOT EQUAL TO hdfs://cluster-nn1.mygrid.myth.net:8020/tmp/mythdb_hadooppf_17544/results_partitioned/.hive-staging_hive_2017-01-10_23-35-58_881_4062579557908207136-1/-ext-10002/dt=1/1\n        at org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.checkPartitionsMatch(AbstractFileMergeOperator.java:174)\n        at org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.fixTmpPath(AbstractFileMergeOperator.java:191)\n        at org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.processKeyValuePairs(OrcFileMergeOperator.java:86)\n        ... 18 more\n]], Vertex did not succeed due to OWN_TASK_FAILURE, failedTasks:1 killedTasks:0, Vertex vertex_1481756273279_5089989_2_00 [File Merge] killed/failed due to:OWN_TASK_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:0\n{noformat}\n\n3. Data produced with Hive {{UNION ALL}} will not be readable by Pig/HCatalog, without {{mapred.input.dir.recursive}}.\n\nSetting {{mapred.input.dir.recursive=true}} in {{hive-site.xml}} should resolve the first and third problem. But is this the recommendation? This is intrusive, and doesn't solve #2. The Pig {{UNION}} doesn't work this way, as per my limited understanding.\n",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
            "id": "2",
            "name": "Critical",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/2"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935"
            },
            "id": "12310843",
            "key": "HIVE",
            "name": "Hive",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310843"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mithun&avatarId=18936",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mithun&avatarId=18936",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mithun&avatarId=18936",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mithun&avatarId=18936"
            },
            "displayName": "Mithun Radhakrishnan",
            "key": "mithun",
            "name": "mithun",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=mithun",
            "timeZone": "America/Los_Angeles"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "ALTER TABLE CONCATENATE and hive.merge.tezfiles seems busted for UNION ALL output",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2017-01-11T13:36:06.000+0000",
        "versions": [],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-15575/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-15575/watchers",
            "watchCount": 6
        },
        "workratio": -1
    },
    "id": "13033553",
    "key": "HIVE-15575",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13033553"
}