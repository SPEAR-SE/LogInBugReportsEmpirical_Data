[more notes:
When it's in the blocking state and I stop all producers and all consumers so nothing is hitting the broker then I go to the web admin panel and hit "delete" to remove the queue I get hit with some errors in my activemq log file in the data dir

http://pastebin.com/q7mxzGzK

I cannot purge or delete this queue at this time, the browser just hangs.  http://cache07:8161/admin/queues.jsp  (internal host)


When I now run bin/activemq stop localhost I'm seeing this in my log file even though there are no producers or consumers attached to it any longer:

2010-11-12 15:56:40,265 | INFO  | The connection to '/10.128.129.20:33830' is taking a long time to shutdown. | org.apache.activemq.broker.TransportConnection | ActiveMQ ShutdownHook
2010-11-12 15:56:40,827 | INFO  | The connection to '/10.128.129.20:33830' is taking a long time to shutdown. | org.apache.activemq.broker.TransportConnection | Thread-22

I'm in a state where I have to kill -9 the process to get the server back.

, Wonder if this is the same as amq-3061. Maybe you can try the three patch files that I put on that, see if they work for you., I've experienced a seemingly-similar issue.
2011-02-15 15:29:54,521 [t: tcp:///10.0.3.22:43259] INFO  Queue                          - Usage Manager Temp Store is Full (98% of 1073741824). Stopping producer (ID:dev-1-dist1.meteostar.local-35179-1296853527353-4:9824:-1:1) to prevent flooding queue://nagiosTestQueue. See http://activemq.apache.org/producer-flow-control.html for more info (blocking for: 17108s)
2011-02-15 15:29:55,036 [t: tcp:///10.0.3.22:50435] INFO  Queue                          - Usage Manager Temp Store is Full (98% of 1073741824). Stopping producer (ID:dev-1-dist1.meteostar.local-35179-1296853527353-4:9786:-1:1) to prevent flooding queue://nagiosTestQueue. See http://activemq.apache.org/producer-flow-control.html for more info (blocking for: 33910s)

I'm unable to access the ActiveMQ web console, no clients can connect, and I'm unable to shutdown ActiveMQ except using 'kill -9'., This is also present in 5.5., Would be great if you could turn this into a JUnit test case to allow easy reproduction of the issue., This could be a case of using all of the broker's memory so that nothing else continues to operate.  Check that the broker's memory limits are higher than the limits for queues and topics so there is room to recover.  Also, once this condition is hit, it may be necessary to use the JMX console to increase the destination's limit.

One other hint: try "kill -ALRM <pid>" instead of kill -9 if you want a less severe shutdown.

*Individual Destination*
{quote}
<destinationPolicy>
...
<policyEntry topic=">" ... memoryLimit="$\{smaller_limit\}" />
<policyEntry queue=">" ... memoryLimit="$\{smaller_limit\}" />
...
</destinationPolicy>
{quote}

*All Destinations*
{quote}
<systemUsage>
...
<memoryUsage>
<memoryUsage limit="$\{larger_limit\}" />
</memoryUsage>
...
</systemUsage>
{quote}

Don't forget the JVM's -Xmx setting as well.
, Since the producer is submitting messages in batches in a transaction its possible memory limits are getting hit before the commit and your consumer then has nothing to consume, so @Arther could be right about needing to raise you memory limits., Could not reproduce this issue.  If you can provide a JUnit test case that still fails on the current release please reopen.]