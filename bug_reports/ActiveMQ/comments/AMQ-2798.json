[I can reproduce this issue. I am using Master/Slave configuration with Master set to waitForSlave="true" 
Start Master and then start consumer. Consumer hangs at ensureConnectionInfoSent() does not matter if I am using shared or unshared connection.

I added a property syncResponseTimeout in factory and connection and wired it in. Changed syncSendPacket to use timeout and I dont get hung consumer.

I am going to attach a patch., Patch I used to fix this issue. I am not expert in this codebase but ping me if this is not the best way. This is STOPPING us from going to production with this issue open., Attaching new patch as FailoverTransactionTest was failing. Still running tests., Have you tried just adding in the startupMaxReconnectAttempts option to your connection URI?  This option will limit the number of time the Failover Transport will attempt to reconnect on startup and allow the client to fail after that number of tries., I have startupMaxReconnectAttempts=2 and it does not work.

my brokerURL looks like failover:(tcp://hostname:61616?keepAlive=true)?randomize=false&amp;startupMaxReconnectAttempts=2

keepAlive or not it fails., @Tim, I think the problem is happening at a lower level than that. As in, I think the the {{ensureConnectionInfoSent}} does the {{syncSendPacket}} on some sort of advisorial transport (I think org.apache.activemq.transport.ResponseCorrelator) and not the actual specified transport. This seems likely since syncSendPacket calls {{(Response)this.transport.request(command)}} and for FailoverTransport, the implementation for this is:

{code}
    public Object request(Object command) throws IOException {
        throw new AssertionError("Unsupported Method");
    }
{code}

, The attached patch may throw an NPE on timeout, depending on transport.
, Do you think ResponseCrrelator needs to guard against nulls? I always assumes that Command (Object o) is a valid object. Or Can we assume if Response is null the connection is closed?, Version 5.4.0 adds a RequestTimeoutException that is thrown on timeout in ResponseCorrelator so the NPE is not an issue any longer.

Currently the code is operating as designed, the case where the connection.start or createSession is hanging is awaiting a response from the broker for its ConnectionInfo.  The case in which this is happening in regards to this issue is when the Master broker is up but awaiting its slave to start as well.  In this case the Master is there but it won't respond to the ConnectionInfo and the connection breaks at which time the FailoverTransport tries again to connect.  This explains why the maxReconnectAttempts and startupMaxReconnectAttempts don't apply here since it is able to actually open a socket successfully to the Master broker, it just doesn't complete the connect cycle because the master is awaiting its slave before it will allow any connections.  Once the slave comes online and the Master completes its start-up then the Connection should be established as normal.


, I am not sure whether it's also an issue, but it seems that although ResponseCorrelator is fixed, ReliableTransport may still return null, since it does:
{code}
while (timeout > 0) {
...
}
return response.getResult(0);
{code}

and FutureResponse does:

{code}
if (result == null && timeout > 0) {
       throw new RequestTimedOutIOException();
}
return result;
{code}, I see that 5.4.0 behaves better. Is there any property that controlls the timeout? Additionally I see excessive logging in this situation and activemq takes over CPU.
Here is the exception:
2010-08-19 09:39:17,090 INFO  [org.apache.activemq.broker.TransportConnection.Transport] Transport failed: java.io.IOException: The transport is not running.
java.io.IOException: The transport is not running.
	at org.apache.activemq.transport.TransportSupport.checkStarted(TransportSupport.java:107)
	at org.apache.activemq.transport.tcp.TcpTransport.oneway(TcpTransport.java:179)
	at org.apache.activemq.transport.InactivityMonitor.oneway(InactivityMonitor.java:244)
	at org.apache.activemq.transport.TransportFilter.oneway(TransportFilter.java:85)
	at org.apache.activemq.transport.WireFormatNegotiator.oneway(WireFormatNegotiator.java:104)
	at org.apache.activemq.transport.MutexTransport.oneway(MutexTransport.java:40)
	at org.apache.activemq.broker.TransportConnection.dispatch(TransportConnection.java:1247)
	at org.apache.activemq.broker.TransportConnection.processDispatch(TransportConnection.java:808)
	at org.apache.activemq.broker.TransportConnection.dispatchSync(TransportConnection.java:768)
	at org.apache.activemq.broker.TransportConnection$1.onCommand(TransportConnection.java:187)
	at org.apache.activemq.transport.TransportFilter.onCommand(TransportFilter.java:69)
	at org.apache.activemq.transport.WireFormatNegotiator.onCommand(WireFormatNegotiator.java:113)
	at org.apache.activemq.transport.InactivityMonitor.onCommand(InactivityMonitor.java:217)
	at org.apache.activemq.transport.TransportSupport.doConsume(TransportSupport.java:83)
	at org.apache.activemq.transport.tcp.TcpTransport.doRun(TcpTransport.java:219)
	at org.apache.activemq.transport.tcp.TcpTransport.run(TcpTransport.java:201)
	at java.lang.Thread.run(Thread.java:619)
, I believe this has been resolved, please reopen if there's still an issue here, Sadly, I still have this exact issue in 5.5.0 (reproducible every time). Jstack shows the same stack as described. Is there a workaround ?

Edit: Also tested with 5.5.1 and 5.6-snapshot, same behaviour., We encountered the error too.  We're on 5.7.0.  Below is the thread stack of the hanging thread.  It doesn't happen often, but it's there.  We're using the failover uri.

<networkConnector name="perform33" uri="static:(tcp://perform31:61616?keepAlive=true&amp;wireFormat.tightEncodingEnabled=false&amp;wireFormat.cacheEnabled=false,tcp://perform38:61616?keepAlive=true&amp;wireFormat.tightEncodingEnabled=false&amp;wireFormat.cacheEnabled=false)?useExponentialBackOff=false">



Name: defaultQuartzScheduler_Worker-1
State: WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@3bd8ed5f
Total blocked: 10  Total waited: 10

Stack trace: 
sun.misc.Unsafe.park(Native Method)
java.util.concurrent.locks.LockSupport.park(Unknown Source)
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
java.util.concurrent.ArrayBlockingQueue.take(Unknown Source)
org.apache.activemq.transport.FutureResponse.getResult(FutureResponse.java:40)
org.apache.activemq.transport.ResponseCorrelator.request(ResponseCorrelator.java:87)
org.apache.activemq.ActiveMQConnection.syncSendPacket(ActiveMQConnection.java:1366)
org.apache.activemq.ActiveMQConnection.ensureConnectionInfoSent(ActiveMQConnection.java:1481)
   - locked java.lang.Object@4bdacc2e

org.apache.activemq.ActiveMQConnection.start(ActiveMQConnection.java:516)
org.mule.transport.jms.JmsConnector.doStart(JmsConnector.java:626)
org.mule.transport.AbstractConnector$2.onTransition(AbstractConnector.java:459)
org.mule.transport.AbstractConnector$2.onTransition(AbstractConnector.java:454)
org.mule.lifecycle.AbstractLifecycleManager.invokePhase(AbstractLifecycleManager.java:141)
org.mule.transport.ConnectorLifecycleManager.fireStartPhase(ConnectorLifecycleManager.java:63)
org.mule.transport.AbstractConnector.startAfterConnect(AbstractConnector.java:453)
   - locked org.mule.transport.jms.activemq.ActiveMQJmsConnector@20fb07d4

org.mule.transport.AbstractConnector$5.doWork(AbstractConnector.java:1601)
org.mule.retry.policies.AbstractPolicyTemplate.execute(AbstractPolicyTemplate.java:67)
org.mule.transport.AbstractConnector.connect(AbstractConnector.java:1611)
org.mule.transport.AbstractConnector.start(AbstractConnector.java:419)
   - locked org.mule.transport.jms.activemq.ActiveMQJmsConnector@20fb07d4

sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
java.lang.reflect.Method.invoke(Unknown Source)
org.mule.lifecycle.phases.DefaultLifecyclePhase.applyLifecycle(DefaultLifecyclePhase.java:225)
org.mule.lifecycle.RegistryLifecycleManager$RegistryLifecycleCallback.onTransition(RegistryLifecycleManager.java:276)
org.mule.lifecycle.RegistryLifecycleManager.invokePhase(RegistryLifecycleManager.java:155)
org.mule.lifecycle.RegistryLifecycleManager.fireLifecycle(RegistryLifecycleManager.java:126)
org.mule.registry.AbstractRegistryBroker.fireLifecycle(AbstractRegistryBroker.java:80)
org.mule.registry.MuleRegistryHelper.fireLifecycle(MuleRegistryHelper.java:121)
org.mule.lifecycle.MuleContextLifecycleManager$MuleContextLifecycleCallback.onTransition(MuleContextLifecycleManager.java:94)
org.mule.lifecycle.MuleContextLifecycleManager$MuleContextLifecycleCallback.onTransition(MuleContextLifecycleManager.java:90)
org.mule.lifecycle.MuleContextLifecycleManager.invokePhase(MuleContextLifecycleManager.java:72)
org.mule.lifecycle.MuleContextLifecycleManager.fireLifecycle(MuleContextLifecycleManager.java:64)
org.mule.DefaultMuleContext.start(DefaultMuleContext.java:202)
   - locked org.mule.DefaultMuleContext@13aaf18f
, By the way, we turned off the producer flow control.

<policyEntry queue=">" timeBeforeDispatchStarts="30000" producerFlowControl="false" useCache="false">
</policyEntry>, You can not talk to the master which the slave is not attached.
The master being waiting for the slave essentially opens a server socket but never accepts/reads the client socket.
Have you tried to enable soTimeout option?
http://activemq.apache.org/tcp-transport-reference.html, Hi SuoNayi,
Thank you for your feedback.  Your second point about soTimeout is a valuable suggestion for me to try!  Since this issue happens rarely for us, I will tell if this will fix our case over time.
About your first point, I'm confused.  We're using the "shared storage master/slave".  The slave is simply standby and keeps trying to grab the distributed file lock.  The master has no knowledge of the slave(s).  The Jms clients (the mule connectors in our case) can establish connections only to the master.  I don't follow when you said "you can not talk to the master which the slave is not attached."  Or am I mistaken somewhere?
Thanks., Anish said he can reproduce the issue when he uses the pure master/slave and the master is waiting for the slave to be attached.
I think the master is half-started and unable to communicate with clients so I said "You can not talk to the master which the slave is not attached to".
The issue can not be reproduced when I use AMQ 5.7 in my test,I'm not sure how the issue of this case is solved at the moment., I just met this problem in our environment. 

My stacktrace revelas the same dead-lock, but with a different command:
"default-threads - 38" prio=10 tid=0x000000001803f800 nid=0x4dd4 waiting on condition [0x00002aced9085000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000000b07c6010> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:374)
        at org.apache.activemq.transport.FutureResponse.getResult(FutureResponse.java:40)
        at org.apache.activemq.transport.ResponseCorrelator.request(ResponseCorrelator.java:87)
        at org.apache.activemq.ActiveMQConnection.syncSendPacket(ActiveMQConnection.java:1406)
        at org.apache.activemq.ActiveMQConnection.cleanup(ActiveMQConnection.java:1626)
        at org.apache.activemq.ra.ActiveMQManagedConnection.cleanup(ActiveMQManagedConnection.java:235)
        at org.jboss.jca.core.connectionmanager.pool.mcp.SemaphoreArrayListManagedConnectionPool.returnConnection(SemaphoreArrayListManagedConnectionPool.java:435)
        at org.jboss.jca.core.connectionmanager.pool.AbstractPool.returnConnection(AbstractPool.java:561)
        at org.jboss.jca.core.connectionmanager.AbstractConnectionManager.returnManagedConnection(AbstractConnectionManager.java:425)
        at org.jboss.jca.core.connectionmanager.listener.TxConnectionListener$TransactionSynchronization.afterCompletion(TxConnectionListener.java:732)
        at org.jboss.jca.core.connectionmanager.transaction.TransactionSynchronizer.invokeAfter(TransactionSynchronizer.java:380)
        at org.jboss.jca.core.connectionmanager.transaction.TransactionSynchronizer.afterCompletion(TransactionSynchronizer.java:329)
        at com.arjuna.ats.internal.jta.resources.arjunacore.SynchronizationImple.afterCompletion(SynchronizationImple.java:96)
        at com.arjuna.ats.arjuna.coordinator.TwoPhaseCoordinator.afterCompletion(TwoPhaseCoordinator.java:402)
        - locked <0x00000000b072ab98> (a java.lang.Object)
        at com.arjuna.ats.arjuna.coordinator.TwoPhaseCoordinator.end(TwoPhaseCoordinator.java:103)
        at com.arjuna.ats.arjuna.AtomicAction.commit(AtomicAction.java:162)
        at com.arjuna.ats.internal.jta.transaction.arjunacore.TransactionImple.commitAndDisassociate(TransactionImple.java:1165)
        at com.arjuna.ats.internal.jta.transaction.arjunacore.BaseTransaction.commit(BaseTransaction.java:126)
        at com.arjuna.ats.jbossatx.BaseTransactionManagerDelegate.commit(BaseTransactionManagerDelegate.java:75)
        at org.jboss.as.ejb3.inflow.MessageEndpointInvocationHandler.afterDelivery(MessageEndpointInvocationHandler.java:72)
        at sun.reflect.GeneratedMethodAccessor128.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.jboss.as.ejb3.inflow.AbstractInvocationHandler.handle(AbstractInvocationHandler.java:60)
        at org.jboss.as.ejb3.inflow.MessageEndpointInvocationHandler.doInvoke(MessageEndpointInvocationHandler.java:136)
        at org.jboss.as.ejb3.inflow.AbstractInvocationHandler.invoke(AbstractInvocationHandler.java:73)
        at com.sun.proxy.$Proxy151.afterDelivery(Unknown Source)
        at org.apache.activemq.ra.MessageEndpointProxy$MessageEndpointAlive.afterDelivery(MessageEndpointProxy.java:128)
        at org.apache.activemq.ra.MessageEndpointProxy.afterDelivery(MessageEndpointProxy.java:69)
        at org.apache.activemq.ra.ServerSessionImpl.afterDelivery(ServerSessionImpl.java:225)
        at org.apache.activemq.ActiveMQSession.run(ActiveMQSession.java:1029)
        at org.apache.activemq.ra.ServerSessionImpl.run(ServerSessionImpl.java:169)
        at org.jboss.jca.core.workmanager.WorkWrapper.run(WorkWrapper.java:218)
        at org.jboss.threads.SimpleDirectExecutor.execute(SimpleDirectExecutor.java:33)
        at org.jboss.threads.QueueExecutor.runTask(QueueExecutor.java:808)
        at org.jboss.threads.QueueExecutor.access$100(QueueExecutor.java:45)
        at org.jboss.threads.QueueExecutor$Worker.run(QueueExecutor.java:849)
        at java.lang.Thread.run(Thread.java:744)
        at org.jboss.threads.JBossThread.run(JBossThread.java:122)
, Actially there is a general problem behind the scenes:

The component ResponseCorrelator is written in an optimistic manner. The assumption is that in case a command sent to the broker, an answer will reach us guaranteed.

This is not true in case of failover situations. It might happen, that we were able to serialize the last bit of the command just before the broker has crashed/killed. This is true for the failover-transport as well.

This means ResponseCorrelator could hang forever at very different locations.

The solution would be to define a time-to-live for the commands. Some of the commands do have timeout, the calling code also takes care of timeouts. (Callers without timeout does not cope with the situation well. In my case I interrupted the above thread, and then JBoss started to process the messages using two different processors at the same time). Thus, ResponseCorrelator should repeat the command to the server using the same commandID(?). 
In case the command ID is known to the failover-transport (ResponseMap) it might ignore the resend, because most likely it is still attempting to send it. TTL could be a larger number like 30-40 sec with infinite as default.




, Issue still happening in 5.13.0:

sun.misc.Unsafe.park(Native Method)
java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
org.apache.activemq.transport.FutureResponse.getResult(FutureResponse.java:48)
org.apache.activemq.transport.ResponseCorrelator.request(ResponseCorrelator.java:87)
org.apache.activemq.ActiveMQConnection.syncSendPacket(ActiveMQConnection.java:1381)
org.apache.activemq.ActiveMQConnection.ensureConnectionInfoSent(ActiveMQConnection.java:1495)
org.apache.activemq.ActiveMQConnection.start(ActiveMQConnection.java:522)
, We are also experiencing this occasional hang with master/slave configuration using 5.11.1.

{code}
        sun.misc.Unsafe.park(Native Method)
        java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        org.apache.activemq.transport.FutureResponse.getResult(FutureResponse.java:40)
        org.apache.activemq.transport.ResponseCorrelator.request(ResponseCorrelator.java:87)
        org.apache.activemq.ActiveMQConnection.syncSendPacket(ActiveMQConnection.java:1387)
        org.apache.activemq.ActiveMQConnection.ensureConnectionInfoSent(ActiveMQConnection.java:1501)
        org.apache.activemq.ActiveMQConnection.createSession(ActiveMQConnection.java:323)
        org.springframework.jms.support.JmsAccessor.createSession(JmsAccessor.java:192)
{code}
, Yes, we have validated that the issue was resolved in version 5.14.0
https://issues.apache.org/jira/browse/AMQ-6362
]