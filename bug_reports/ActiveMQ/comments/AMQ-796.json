[Fix in rev 587504

   The threads associated with the session are now setup to be non-daemon so that if you 
   setup a MessageListener and let the main thread exit, your program will not terminate
   if there are no active transport threads which is the case when the failover transport
   is in the middle of reconnecting to a broker., This issue occurs again on the trunk, This is a Windows cmd script that uses 2 instances of the ProducerTool sample app to create 2 embedded brokers, and the single-threaded ConsumerTool with a failover URI to demonstrate the problem., The solution to this should be simple - just make sure the thread that performs the failover logic does NOT call setDaemon(true).

Since this bug was fixed three years ago and came back to life, it would be nice if the code took more steps to prevent this from happening in the future, for example:

- Override setDaemon(boolean) on that thread so that it never allows itself to be flagged as a daemon.  If it is called in that way, output a stack trace with a message specifically refering to this bug (AMQ-796).

- Add unit tests that would fail if another part of the code set the failover thread as a daemon.  This seems like it would be a lot harder than the override approach above, but would be nice if it were possible., Fixed by Subversion: Committed revision 1327443, This issue still persists. attaching the jstack on broker. It still doesn't show any non-daemon thread which would have fixed the issue i guess., This issue occurs again on the trunk and Version 5.7.0.
Using:
1. start a broker in command line
2. create and run a connection with a consumer and TransportListener(for track reconnecting) in eclipse
3. stop the broker and restart the broker
4. then we can see client transportInterupted and transportResumed
5. stop the broker again 
6. the client process will quit!!!

The early fix for this bug is to remove daemon=true on ActiveMQ Connection Executor,
but sometimes this executor does not create new thread.

The solution is to make the reconnectTask thread is non-daemon:
// FailoverTransport.java row: 132 
reconnectTaskFactory = new TaskRunnerFactory();
reconnectTaskFactory.setDaemon(false); // to set daemon=false by kimmking
reconnectTaskFactory.init();

After the fix, the reconnecting of this client works well during broker's stop for many times., We just found that non-daemon thread for the executor in the connection may not fix this issue.
The executor in the connection is used to async take action when internal exceptions occur.
If no internal exceptions the executor will not be initiated by filling up with non-daemon threads.
In this case client still can shutdown when failover connection is reconnecting 
because non-daemon threads do not exist in JVM .
One simple solution is to keep the thread attached with the reconnectTask non-daemon.
, Another suggestion, named the reconnectTask thread：
reconnectTaskFactory = new TaskRunnerFactory();
in FailoverTransport.java line 132 is modified to 
reconnectTaskFactory = new TaskRunnerFactory("FailoverTransport-ReconnectTask");, We see same behaviour with our simple producer/consumer with 5.7.0. If we attach TransportListener to consumer then things work fine.
Poducer doesn't have issues as noted by others.
, Still an issue with ActiveMQ v5.8 !!  Can somebody resolve this please..., Attaching the jstack output for v5.8. The only non-daemon thread is the main thread which I stopped from exiting only for the purpose of taking a jstack snapshot., This is really very strange since the creation time for this issue is 2006. Is it really this tough to make the relevant thread non-daemon?, Ping! Any updates here ?, Use a 5.9-SNAPSHOT, should get you sorted. , This issue still seem to exists with client version 5.14.0 using a MessageListener and single threaded application. The reconnect tasks are still daemon threads.

Thread output:

"ActiveMQ Task-2" #14 daemon prio=5 os_prio=0 tid=0x000000001e616000 nid=0x11b4 waiting on condition [0x000000001f5cf000]
"ActiveMQ Task-1" #11 daemon prio=5 os_prio=0 tid=0x000000001e3df000 nid=0x7cc waiting on condition [0x000000001ef8e000]

Cause:

When the FailoverTransport is created the associated task runner will have daemon = true set. Code path:

FailoverTransport.java: 

 136         reconnectTaskFactory = new TaskRunnerFactory();
 137         reconnectTaskFactory.init();


TaskRunnerFactory.java:

  58     public TaskRunnerFactory() {
  59         this("ActiveMQ Task");
  60     }
  61 
  62     public TaskRunnerFactory(String name) {
  63         this(name, Thread.NORM_PRIORITY, true, 1000);
  64     }

The third parameter (daemon = true) is the culpit. 

It seems that the simplest solution is what has been suggested previously, explicitly setting daemon = false on the reconnect factory:

reconnectTaskFactory.setDaemon(false);


, Yes,we have the some problem in activemq 5.10.0 and 5.13.4. we use failover tcp protocol like:
failover://(tcp://127.0.0.1:61624,tcp://127.0.0.1:61626)?nested.wireFormat.maxInactivityDuration=3000&nested.connectionTimeout=2000&maxReconnectAttempts=2&timeout=2000&randomize=false&initialReconnectDelay=50&startupMaxReconnectAttempts=2&maxReconnectDelay=100

first keep all Mq server up
then shutdown one of the server
see the log keep create a new connection on the up server and then closed the new connection and the recreate a new connection on the up server ...... dead loop....

threaddump the thread and see the threadDump.txt and the test code Sender.java in the attach file.

"ActiveMQ Task-1" daemon prio=6 tid=0x000000000d5c3800 nid=0x2bc8 waiting on condition [0x000000000dc2e000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000db305ec8> (a java.util.concurrent.CountDownLatch$Sync)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1033)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:282)
	at org.apache.activemq.transport.WireFormatNegotiator.oneway(WireFormatNegotiator.java:97)
	at org.apache.activemq.transport.failover.FailoverTransport.restoreTransport(FailoverTransport.java:841)
	at org.apache.activemq.transport.failover.FailoverTransport.doReconnect(FailoverTransport.java:1020)
	- locked <0x0000000090c6a228> (a java.lang.Object)
	at org.apache.activemq.transport.failover.FailoverTransport$2.iterate(FailoverTransport.java:148)
	- locked <0x0000000090c6a238> (a java.lang.Object)
	at org.apache.activemq.thread.PooledTaskRunner.runTask(PooledTaskRunner.java:133)
	at org.apache.activemq.thread.PooledTaskRunner$1.run(PooledTaskRunner.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
, Just a small reminder to tells that this issue is still in 5.12.1.

Adding these in FailoverTransport.class fix the issue like [~kimmking] said before..
{code:java}
reconnectTaskFactory = new TaskRunnerFactory();
reconnectTaskFactory.setDaemon(false); // to set daemon=false by kimmking
reconnectTaskFactory.init();
{code}
If i look that Jira this issue is solved from 5.6.0 but we are a lot here to explain that it is not corrected because we have to edit FailoverTRansport.class by ourselves. So he's it the only workaround for now or maybe is resolved in the last version?

 ]