[Yeah there should IMHO be some upper limit to cap, so the max rows wont get as large as yours., A patch that caps at max rows., Gary do you mind taking a look at this, and the proposed patch.

As the default max rows is at 200, it may be lowered than maxReturned * 2.
, I wonder what is causing the request for 50871918. It should be based on the page size for the destination. 
@PJ, can you attach your xml configuration.

The original intent of maxrows was to force a table scan to see more than page size messages such that priority messages or selector matching would work independent of the prefetch size or requested dispatch size. It was not intended as a limit, rather as a way of extending the scan.
In this case, it looks like the value being requested is way too large through some error.

Making maxRows an upper limit means we need to pick a better default value, one that is based on the destination pageSize I think.
For the priority and sparse selecto use case, explicit values for pageSize are needed in any event., Hi Gary, Claus,
I raised this issue in 2008 and I don't really use ActiveMQ much these days.
I have never modified the ActiveMQ default config, other than to set some environmental settings (eg the MySQL connection details).
Thanks for looking at the issue though.
For the prefetch logic, it does seem sensible to limit the rows to the 100s as opposed to 1000s.
Sorry I can't be of much assistance., fix in http://svn.apache.org/viewvc?view=revision&revision=1439933

maxRows is now a max value, limiting the statements result set. the min of maxrows and the current request is used, Hi Gary,

It appears that maxRows is still computed using the max of maxrows and the current request rather than the min in one of the DefaultJDBCAdapter#doRecoverNextMessages overloads.  Please see line 1037 in DefaultJDBCAdapter.

Thanks,

Keith , @Keith, thanks for the catch - fix in http://svn.apache.org/r1492698]