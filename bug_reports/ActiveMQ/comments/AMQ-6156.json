[This looks normal for any connect attempt that fails, the connection will block waiting for the failover transport to connect., Hi Timothy,

That does not explain then why some threads connect and operate correctly while approx 60-70% of them become parked and parked permanently.
What do you mean by "waiting for the failover transport to connect"? Its my understanding that in active/passive mode that the client will connect to active node initially and that based on the passive node in the failover URL, it will switch to the passive node if the active goes down. Is this correct understanding?

Thanks,
Ger.
, Not being in your environment I can't say exactly what is connecting to what but the client should attempt to connect to the salve broker once the master goes down.  You need to do some debugging in the logs to see what the clients are doing, they generally tell you what's up.  , Hi Timothy,

I've started making changes in respect of your comments above to my AMQ producer client to improve the failover transport handling.
In doing so I have added the following query parameters onto the failover URL

failover:(tcp://localhost:61616?startupMaxReconnectAttempts=10&timeout=1000,tcp://localhost:61616?startupMaxReconnectAttempts=10&timeout=1000)?maxReconnectAttempts=5&maxReconnectDelay=30000&randomize=false

I am now getting an error where the connection fails due to incorrect connect parameters {startupMaxReconnectAttempts=10, timeout=1000}
If you would prefer I open a new case for this issue then let me know, but I am wondering if you've seen this before and have any ideas as to what is wrong - all parameters being passed are listed as transport parameters on the failover transport page: http://activemq.apache.org/failover-transport-reference.html

Thanks,
Ger.
, Your URI is incorrect, the failover options don't get applied to each TCP transport instance in the URI, try this:

{noformat}
failover:(tcp://localhost:61616)?maxReconnectAttempts=5&maxReconnectDelay=30000&randomize=false&startupMaxReconnectAttempts=10&timeout=1000
{noformat}

I don't really know why you have the same address in there twice, no need for two {{tcp://localhost:61616}} addresses in there., Hi,

I also tried the format you suggest e.g. 
failover:(tcp://localhost:61616)?maxReconnectAttempts=5&maxReconnectDelay=30000&startupMaxReconnectAttempts=3&timeout=1000&randomize=false

This is the error I get:

Invalid connect parameters: {startupMaxReconnectAttempts=3, timeout=1000}

Thus the reason for me moving them onto the tcp transport URL. I had the double tcp localhost urls in their for primary/failover testing previously, so that can be ignored. According to the docs, the above should work.

Thoughts?
Ger.
, I've upgraded from 5.11.1 to 5.13.0 on suspicion that the error may have been because the failover transport parameter documentation only related to latest version. I also linked to the activemq-all.jar file from the 5.13.0 installation so as to ensure I was working with latest. I see the same outcome with invalid connect parameters as per URL above., Would need to check your tests, I just did this and it works as expected.  

{code}
    @Test
    public void test() throws JMSException {

        ActiveMQConnectionFactory cf = new ActiveMQConnectionFactory(
            "failover:(tcp://localhost:61616)?" +
                "maxReconnectAttempts=5&" +
                "maxReconnectDelay=30000&" +
                "startupMaxReconnectAttempts=3&" +
                "timeout=1000&randomize=false");

        cf.createConnection().start();
    }
{code}

{noformat}
2016-02-05 11:42:21,719 [ActiveMQ Task-1] - ERROR FailoverTransport              - Failed to connect to [tcp://localhost:61616] after: 3 attempt(s)
{noformat}
, Hi Timothy,

The issue turned out to be a mixed activemq-all.jar file in my deployment environment. The jar is needed in multiple locations, so I'd not updated correctly and this left me with a mixed environment of 1.7.0_60 and 1.7.0_80 versioned jar files. I updated to the 1.7.0_80 version JAR files from the latest ActiveMQ and all works fine now. 

I have to place my implementation in a load environment to create the scenario where the threads get parked as shown above and I'm hoping new implementation details such as the parameters we talked about and a TransportListener implementation will improve the behavior of the client.

Thanks,
Ger., Thanks for closing the loop, will close this for now then and you can reopen if there is any further issue in this area.  ]