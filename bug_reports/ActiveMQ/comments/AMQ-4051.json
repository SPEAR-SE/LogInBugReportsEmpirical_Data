[Hi Edwin,

I was looking at the configuration file and noticed that you defined the carinaIOExceptionHandler bean but this is not part of the list of attached files.  Does this get called anytime throughout the test? Is it even required?

There is also the question of what is the type of use-case that you are using that reproduces this issue?  Are you expecting all of the messages to pump through the network connection between the brokers or are they also being consumed by consumers that are connected to the broker that contains the queues?

How many consumers are you connecting to these brokers?  What protocol are you using?  Are the consumers coming and going or are they permanently connected throughout the test?

Have you been able to reproduce this issue using the latest release v5.7?

--Claudio
, Hi Claudio,

Thanks for looking into this issue.  To answer your questions:

1) You can ignore carinaIOExceptionHandler for the purpose of this jira issue.  We needed it because we need to cleanly shut down the JVM when the persistent directory is filled up, or when the persistent directory is on a network drive that becomes unreachable.  I don't think it's involved for this issue.

2) In our use case, there were two nodes, each of which embedded an ActiveMQ broker with persistent storage.  A mule jms outbound connector heavily sent messages to a queue on the first node, which defined a network connector that dynamically included the destination to a second node.  A mule jms inbound connector on the second node listened to this queue.  This jms inbound connector is the only consumer of this queue.  It permanently connected.  In the healthy operation, this consumer was able to keep up consuming the incoming messages.  The queue size stayed under 2 most of the time.  When this error occurred, messages from the first node were still being delivered to the second node just fine.  It was the second node that complained about the missing data file, and the queue size started increasing and the dequeue count stayed flat.

3) The mule jms inbound connector used the vm protocol.  It was defined like below.
    <jms:activemq-connector
            name="jmsExternalConnector"
            specification="1.1"
            disableTemporaryReplyToDestinations="true"
            brokerURL="vm://xps-amq-broker_HPC-HAIFA-HAIFA-HAIFA"
            numberOfConsumers="1"
            maxRedelivery="1"
            persistentDelivery="true">
    </jms:activemq-connector>


4) We're planning to do upgrade to v5.7, but it'll take couple months before we roll out to our performance lab to do load testing.  Plus, it may take few weeks of operation to see it happen again.

Lastly, I still have the remaining journal data in the persistent folder from the error case.  If they are useful for your investigation, I can try to upload to this jira issue.  It's about 100MB in total.  They are named:

db.data
db.redo
db-11.log
db-12.log
db-13.log
lock

Thanks,
-Edwin, taking this off the 5.8 critical list (blocking a release) pending validation on 5.7, I just want to add new information.  After we upgraded to 5.8.0, we encountered the same error one more time.  So the bug is still in 5.8.0.

2013-11-19 08:33:39,827 ERROR | ActiveMQ BrokerService[broker Task-3975 | [Queue:1494] Failed to page in more queue messages 
java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: Could not locate data file .\esb\amq_perform77a\db-958.log
            at org.apache.activemq.broker.region.cursors.AbstractStoreCursor.reset(AbstractStoreCursor.java:113)
            at org.apache.activemq.broker.region.cursors.StoreQueueCursor.reset(StoreQueueCursor.java:157)
            at org.apache.activemq.broker.region.Queue.doPageInForDispatch(Queue.java:1775)
            at org.apache.activemq.broker.region.Queue.pageInMessages(Queue.java:2003)
            at org.apache.activemq.broker.region.Queue.iterate(Queue.java:1491)
            at org.apache.activemq.thread.PooledTaskRunner.runTask(PooledTaskRunner.java:129)
            at org.apache.activemq.thread.PooledTaskRunner$1.run(PooledTaskRunner.java:47)
            at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
            at java.lang.Thread.run(Thread.java:722)
Caused by: java.lang.RuntimeException: java.io.IOException: Could not locate data file .\esb\amq_n4-perform77a\db-958.log
            at org.apache.activemq.broker.region.cursors.AbstractStoreCursor.fillBatch(AbstractStoreCursor.java:277)
            at org.apache.activemq.broker.region.cursors.AbstractStoreCursor.reset(AbstractStoreCursor.java:110)
            ... 9 more
Caused by: java.io.IOException: Could not locate data file .\esb\amq_perform77a\db-958.log
            at org.apache.activemq.store.kahadb.disk.journal.Journal.getDataFile(Journal.java:353)
            at org.apache.activemq.store.kahadb.disk.journal.Journal.read(Journal.java:600)
            at org.apache.activemq.store.kahadb.MessageDatabase.load(MessageDatabase.java:961)
            at org.apache.activemq.store.kahadb.KahaDBStore.loadMessage(KahaDBStore.java:1029)
            at org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore$4.execute(KahaDBStore.java:557)
            at org.apache.activemq.store.kahadb.disk.page.Transaction.execute(Transaction.java:779)
            at org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.recoverNextMessages(KahaDBStore.java:546)
            at org.apache.activemq.store.ProxyMessageStore.recoverNextMessages(ProxyMessageStore.java:106)
            at org.apache.activemq.broker.region.cursors.QueueStorePrefetch.doFillBatch(QueueStorePrefetch.java:97)
            at org.apache.activemq.broker.region.cursors.AbstractStoreCursor.fillBatch(AbstractStoreCursor.java:274)
            ... 10 more
, v5.9.0 is the latest release, you should test against that version.  , Without additional information on how to reproduce or evidence that this still exists after two additional broker releases there's not much that can be done here. ]