[Recommend you create a unit test to reproduce.  , [~tabish121]

Hi Timothy I attached the test case project which will be able to replicate given issue.

Please find README.txt inside zip file to run the test case .
As it is only happening when we are using resource adapter so I created a small ear file with a junit test case.

Please let me know if you will face any issue while running above project., [~grijesh.saini], Thanks for uploading a test case.  I'll take a look at this when I get a chance., [~christopher.l.shannon]

Yes sure Christopher, Thanks., [~gtully] and [~tabish121],

Sorry in advance for the long message but this is a kind of complicated issue and was pretty hard to track down.

There is a race condition of sorts and it is caused by the unique circumstances of this test case and the environment.  The short version is that message acks are being received out of order due to messages being handled concurrently in different threads.  Sometimes this causes an exception because by the time some of the acks are received by the broker, the broker has already expired the messages so the acknowledgement check fails.  This is happening in Wildfly because the container is creating a pool of threads to handle multiple messages at the same time (ie ServerSession pool).  This is unique to application servers because of the use of a ConnectionConsumer and ServerSessions so multiple threads can handle messages from 1 consumer.

What's going on is as a message producer is sending messages to the broker with a TTL value set at 10 milliseconds, the Wildfly consumer is quickly dequeing messages in parallel.  The run() method in ActiveMQSession is being executed for each new message in different threads.  The first thing that happens is the message is checked to see if it has expired (around line 885 of ActiveMQSession).  If it's not expired, then the code continues on and the messageListener (in this case the MDB) eventually runs (around line 1037). The example that was submitted here has the MDB sleeping for 1 second which is  longer than the TTL of the messages being sent.  So a bunch of threads are sleeping for 1 second and then when they are finished the run() method continues on and at the end sends a normal acknowledgement back to the broker in the finally block (around line 1052)

However, as the ConnectionConsumer is rapidly consuming more messages and dispatching to different Sessions, eventually one of the threads runs into a message that is expired because the time out period is so short.  Since the message is expired, it is acked early and sent to the broker.  The MDB never fires when the message is expired.   This triggers the broker to iterate through all of the dispatched messages and to expire ones that it can.  This happens in the PrefetchSubscription class around line 325 when an expired Ack is received.  So, all of the messages that were dispatched essentially get removed from that dispatch list since all of the messages are expired.  Then, when some of the threads in Wildfly finish sleeping they continue on and get around to sending back an ack.  Except that by the time this acknowledgement is sent to the broker, the messages have already been expired because the thread that detected the expired message already sent an expired ack to the broker so the message attempting to be acked doesn't exist in the dispatched list.

Below is a printout from my log file with some extra debug statements that I added.  The "handling message" line is a debug statement that I added to print right after a message is dequeued in the run() method.  You can see multiple threads executing at the same time in Wildfly.  "Expired Message" prints out when a message is detected as being expired. "Sending Ack" prints out when the thread finishes the normal execution and sends a normal ack back to the broker.  As you can see below, we run into trouble when the thread handling the 4th message finishes and sends an acknowledgement to the broker.  During the period of time that the thread handling message 4 was sleeping for 1 second, 13 other messages were handled in parallel.  Just before thread 4 finished, one of the other threads had detected that message 13 expired and sent back an expiration ack which triggered all of the acks to be expired(including message 4) so by the time the ack for the 4th message reached the broker that message was already removed from the dispatch list and we get an exception.

So, as far as solutions go, I'm not sure what the best approach would be.  This situation could happen anytime messages are processed slowly in parallel and there is a TTL set.  Obviously one work around is to not concurrently process messages off the same subscription but that is pretty common with MDBs and application servers.  One solution could be to check a second time to see if the message has expired after the messageListener has been called and send an expired ack instead of a normal ack in that case.  But we'd need to change the server logic to not fail if it couldn't find the message to ack because it was already expired.  I think another solution could be to keep track of of which messages have already been expired on a subscription for some window of time so that so that if an acknowledgement comes later it could be detected as being for an expired message and no error would be thrown.  What do you guys thing?  I can work on a PR and introduce a fix but wanted to discuss what you thought would be the best approach.

{noformat}
20:20:52,347 INFO  [org.apache.activemq.ra.ActiveMQEndpointWorker] (default-threads - 1) Successfully established connection to broker [tcp://localhost:61616]
20:21:00,745 INFO  [stdout] (default-threads - 2) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:3:1
20:21:00,747 INFO  [stdout] (default-threads - 2) Expired Ack (ActiveMQSession) for: null,ID:localhost.localdomain-53475-1434846046033-2:1:1:3:1
20:21:00,763 INFO  [stdout] (default-threads - 3) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1
20:21:00,868 INFO  [stdout] (default-threads - 4) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:5:1
20:21:00,980 INFO  [stdout] (default-threads - 5) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:6:1
20:21:01,087 INFO  [stdout] (default-threads - 6) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:7:1
20:21:01,199 INFO  [stdout] (default-threads - 7) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:8:1
20:21:01,315 INFO  [stdout] (default-threads - 8) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:9:1
20:21:01,316 INFO  [stdout] (default-threads - 8) Expired Ack (ActiveMQSession) for: null,ID:localhost.localdomain-53475-1434846046033-2:1:1:9:1
20:21:01,423 INFO  [stdout] (default-threads - 9) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:10:1
20:21:01,539 INFO  [stdout] (default-threads - 10) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:11:1
20:21:01,655 INFO  [stdout] (default-threads - 11) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:12:1
20:21:01,768 INFO  [stdout] (default-threads - 12) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:13:1
20:21:01,806 INFO  [stdout] (default-threads - 12) Expired Ack (ActiveMQSession) for: null,ID:localhost.localdomain-53475-1434846046033-2:1:1:13:1
20:21:01,809 INFO  [stdout] (default-threads - 3) Hello world!3
20:21:01,810 INFO  [stdout] (default-threads - 3) Sending Ack (ActiveMQSession line 1010) for: 2; ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1,ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1
20:21:01,872 INFO  [stdout] (default-threads - 4) Hello world!4
20:21:01,872 INFO  [stdout] (default-threads - 4) Sending Ack (ActiveMQSession line 1010) for: 2; ID:localhost.localdomain-53475-1434846046033-2:1:1:5:1,ID:localhost.localdomain-53475-1434846046033-2:1:1:5:1
20:21:01,874 INFO  [stdout] (default-threads - 13) handling message: ID:localhost.localdomain-53475-1434846046033-2:1:1:14:1
20:21:01,888 ERROR [org.apache.activemq.ra.ActiveMQEndpointWorker] (ActiveMQ Connection Executor: tcp://localhost/127.0.0.1:61616@43165) Connection to broker failed: Unmatched acknowledge: MessageAck {commandId = 16, responseRequired = false, ackType = 2, consumerId = ID:localhost.localdomain-46056-1434846051491-1:1:-1:2, firstMessageId = ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1, lastMessageId = ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1, destination = queue://TEST.FOO, transactionId = null, messageCount = 1, poisonCause = null}; Could not find Message-ID ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1 in dispatched-list (start of ack): javax.jms.JMSException: Unmatched acknowledge: MessageAck {commandId = 16, responseRequired = false, ackType = 2, consumerId = ID:localhost.localdomain-46056-1434846051491-1:1:-1:2, firstMessageId = ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1, lastMessageId = ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1, destination = queue://TEST.FOO, transactionId = null, messageCount = 1, poisonCause = null}; Could not find Message-ID ID:localhost.localdomain-53475-1434846046033-2:1:1:4:1 in dispatched-list (start of ack)
{noformat}
, [~christopher.l.shannon] great detail ;-). Seems that the broker reaction to the expiredAck is excessive. maybe that should be treated as a single/individual ack and just remove the single message that has expired, it can check the count attribute to ensure it should match a single message. Currently in prefetchsub there is a check on all dispatched messages which seems excessive in this scenario. I think that is the crux of the problem.

For a long time, there was no message expiry processing thread so the only checks were on dispatch, it seems when there is periodic expiry some of the additional checks are candidates from removal., It seems like switching the logic to only remove the message or messages that the ack refers to might be the best way to go. The rest of the acknowledgements seem to work like this already so it seems like a good idea to make them behave the same.

Besides expiring pending messages waiting to be dispatched, does the expiry task also look at dispatched messages? , the expiry task does not deal with dispatched messages. that was sorted via : https://issues.apache.org/jira/browse/AMQ-5274?focusedCommentId=14130650&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14130650, I can work on a patch for this for this week.  Some of the users that connect to the brokers that my team manages use message driven beans so it would be nice to try and get this sorted out in time for 5.12.0., GitHub user cshannon opened a pull request:

    https://github.com/apache/activemq/pull/123

    https://issues.apache.org/jira/browse/AMQ-5851

    This commit resolves an issue where unmatched acknowledgement
    messages could be received when running a MDB consumer and
    sending messages with a short TTL.  The expiration logic when
    receiveing an expired Message Ack will now only expire messages
    in dispatch relating to the received ack, not all expired messages
    in the dispatch list.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/cshannon/activemq AMQ-5851

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/activemq/pull/123.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #123
    
----
commit 1bce29ac6f55394fa9ebf2ee347dcde415bac7e0
Author: Christopher L. Shannon (cshannon) <christopher.l.shannon@gmail.com>
Date:   2015-06-25T18:22:32Z

    https://issues.apache.org/jira/browse/AMQ-5851
    
    This commit resolves an issue where unmatched acknowledgement
    messages could be received when running a MDB consumer and
    sending messages with a short TTL.  The expiration logic when
    receiveing an expired Message Ack will now only expire messages
    in dispatch relating to the received ack, not all expired messages
    in the dispatch list.

----
, I created a pull request to address this issue and to update the expired ack to only expire the messages in dispatched relating to the ack, and not all expired messages.  I added a unit test that simulates the issue with how it would be run in an application container.  The test passes with my patch but fails without it.  Take a look and let me know what you think., [~christopher.l.shannon] the changes look good - however I did a sanity check with some tests and the first one I tried - org.apache.activemq.JMSConsumerTest#testMessageListenerWithConsumerCanBeStoppedConcurently had a failure that seems related.
Can you investigate and possibly validate with a full test run of the unit tests., [~gtully],  
 
Thanks for pointing that out, my logic was slightly off when I tried to move the isAckRange check into a helper method, so I will back that part of the patch out.

I had run through a bunch of tests already that I could find relating to expired messages and they had passed but of course there are a lot of tests.  The JMSConsumerTest seems like a good one to run for a sanity check though.

I'll go ahead and do a full run through all the tests and amend my pull request if everything looks good., great. A good trick is to poke around the git annotations in the code you are changing to find relevant commits and corresponding tests. That is why I chose JMSConsumerTest. 
This does point to the need to have some good sanity tests in the PR build., Thanks Gary, that's a good point.  I pushed up my modified PR.  The tests have been running for 6+ hours and I think it is good to go.  There were a couple that failed but those tests always fail on my machine so it doesn't have anything to do with the patch.  For example, TopicClusterTest always fails for me but seems to work fine in the Apache Jenkins setup.

I agree it would be nice to run some sanity tests that hit core parts of the code base on the PR build, just as long as the build isn't too long, maybe something that can run in 15 or 20 minutes., Github user asfgit closed the pull request at:

    https://github.com/apache/activemq/pull/123
, patch applied with thanks to cshannon in http://git-wip-us.apache.org/repos/asf/activemq/commit/f10aab64, [~christopher.l.shannon] [~gtully]

Thank you for the fix :)
]