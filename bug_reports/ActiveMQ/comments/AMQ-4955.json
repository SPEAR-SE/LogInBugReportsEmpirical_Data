[I have further did remote debugging on this. It points to the following area of the code.
InactivityMonitor.configuredOk()
This method is coded is such a way that it returns false if the wire protocol from the client has not been received. Because of this the connection is not yet added to be monitored by the inactivity monitor so the Client connections that did not finish the wire protocol negotiation are never can be cleaned up by the Broker leaking and eventually running out of threads and memory.
, 1. When the server starts a transport connection, the first command it is dispatching is BrokerInfo command
Note: BrokerInfo command is not tagged as DispatchMessage ( isMessageDispatch() is false on Broker Command)	

2. WireFormatNegotiator::oneway  method throws a IOException with Wire format negotiation timeout
3. TransportConnection::processDispatch method ignores that IOException because the command that was sent out is not a MessageDispatch Command.
Result is Wire format negotiation timeout is thrown out without being handled resulting the ActiveMQ Transport thread leak

I have fixed this by added the following lines of code to the TransportConnection:processDispatch  's IOException handling block of code.
            if(command.isBrokerInfo())
                   throw e;, Have you created a test case that reproduces this problem?  Have you tested against the latest code?, Hey,
I am facing the similar issue in which I can see lot of connections from the same client ( around 100). I think connections are not getting closed properly. 

Configuration:
1. All clients are using pooled connection factory where max Connection limit is specified as 3.
2. ActiveMQ version: 5.8

I suspect that default value of 'maxInactivityDuration' is less (30 sec) and broker might not able to send/read heartbeats  for all the connections in this given specified time. So I think by increasing the value of  'maxInactivityDuration' we could avoid this issue since broker will have enough time to handle heartbeat related stuff.

I think Tim might help us here.

Thanks,
Anuj, Based on the description of the steps to reproduce, I tried a client program that doesn't use a connection factory, but instead just opens a socket to the server, then closes it.  This test failed to produce any sort of leak.  One difference - I'm testing 5.9.0.

Is there anything else that needs to happen in the normal connection sequence that my test might miss?

Can you try to reproduce the problem with 5.9.0?, Open the socket connection, and before closing the socket disconnect your client machine from the network, so that RST or the FIN packets never makes it to the server.
I am also planning to do the test on 5.9.

, If it's necessary to prevent RST or FIN, then doesn't that point to either a tcp/ip timeout issue or a bug in the server's tcp/ip stack?

Please check netstat on the broker system when this happens.  If the socket is listed there, then this is not an ActiveMQ bug. 

Sent from my iPhone

, Its not clear this is a broker problem - and not a application problem - downgrading to major, Unit test, Attached the unit test both for the TCP and SSL. Tested on 5.9 too with no success.
The fix I have proposed to TransportConnection:ProcessDispatch catch block to add these lines of code at the beginning fixes only TCP connector, but not the SSL connector

         boolean isBrokerInfo=command.isBrokerInfo();
         if(isBrokerInfo)
         	 throw e;
Please suggest any alternative ideas that fixes both for all the transports, I can try coding that., Looking at the comments in the unit test, it appears to be attempting to avoid problems caused by opening socket connections to the broker without the broker timing them out.  Is that correct?

Is that the focus of this issue now?
, Throwing an exception on dispatching a BrokerInfo in TransportConnection sounds like a major problem since BrokerInfo's do need to cross transports.

What's the state of this issue?, Reading back through the comments, I see the issue being raised now -- the eaten IOException for all commands except MessageDispatch.

I think the right thing to do here is to always re-throw the exception.  Can anyone think of a case in which an IOException on Broker.preProcessDispatch() or TransportConnection.dispatch() could have a non-fatal meaning?, This scenario should be addressed by enhancements in AMQ-5794 broker will close incoming connections that have not completed their negotiation after the connection attempt timeout value has been reached.]