[I tried several more tests using the script and test program above, with similarly bad results.  So far I am unable to find a completly reliable way to implement master/slave failover with a shared filesystem.

I have tried all tests so far on both Apache ActiveMQ 5.2.0 and the new FUSE message broker 5.3.0.0 with identical results.


1. In my original test, the syncOnWrite parameter for the amqPersistenceAdapter was set to the default value "false".  I thought this might be part of my problem, so I changed it to syncOnWrite="true".  I am certain changing syncOnWrite had an effect, because it reduced the rate of messages being sent and received to 20 per second.  The test program still used AUTO_ACKNOWLEDGE in the sender and receiver.  This failed after 3 master/slave failovers:

Mar 7, 2009 7:35:42 AM org.aaron.MasterSlaveTest$Receiver onMessage
WARNING: test.queue.9 received 1904 expected 1903


2. Next I set syncOnWrite="false" and enabled transactions in both Sender and Receiver.  To do this I changed the call to createSession to have parameters "true" and "Session.SESSION_TRANSACTED".  I called session.commit after each send and receive.  See MasterSlaveTestWithTransactions.java.

This failed after 4 master/slave failovers:

Mar 7, 2009 7:12:55 AM org.aaron.MasterSlaveTest$Receiver onMessage
WARNING: test.queue.8 received 1530 expected 3703


3. Finally I set syncOnWrite="true" and ran again with transactions enabled in both Sender and Receiver (MasterSlaveTestWithTransactions.java).

This failed after 6 master/slave failovers:

Mar 7, 2009 7:32:19 AM org.aaron.MasterSlaveTest$Receiver onMessage
WARNING: test.queue.3 received 1734 expected 1725
, One more piece of information that is hopefully useful: I often see a number of exceptions in the activemq log when a message is delivered out of order just after a master broker fails and the slave takes over.

Here's an example - in this case I was running the non-transacted test program (MasterSlaveTest.java) and syncOnWrite=false.  run_master_slave_brokers.sh does the following:

Sat Mar  7 15:06:09 CST 2009 killing master broker pid 24470, new master pid 24678
Sat Mar  7 15:06:29 CST 2009 started slave broker pid 24883
Sat Mar  7 15:06:49 CST 2009 killing master broker pid 24678, new master pid 24883

The last master failure and slave promotion at 15:06:49 causes test.queue.3 to miss messages 6620 and 6621:

Mar 7, 2009 3:06:51 PM org.aaron.MasterSlaveTest$Receiver onMessage
WARNING: test.queue.3 received 6622 expected 6620

At the same time (15:06:51), there are a number of exceptions in the activemq log complaining about messages not being able to be recovered from the data store - already dispatched.  I've attached the log as "activemq.log" if its helpful., It seems whats happening is that the default prefetch of 1000 is being used. When the active master is killed, there are unack'd inflight messages on the broker->consumer connection. At that  point all bets are off in terms of the message order, as order will not be guaranteed when the messages are put back on the queue.

If you set the prefetch to 1, everything looks like it works correctly, for example: 
failover:(tcp://localhost:61616)?maxReconnectDelay=1000&jms.prefetchPolicy.queuePrefetch=1&useExponentialBackOff=false

I think if you added some buffering (vs the System.exit()) to the test to handle out of order messages, the consumer will get the messages - albeit out of order.

Regards
/Dave


, I did some more testing today and it turns out this can be reproduced even in a single broker environment. Try starting/stopping a single broker until it happens. So IMHO this has to be related to the store recovery. It's also indicative that it usually happens when there is more active data files (4 or 5). Hope to have more info tomorrow. , Just some heads up.

It turns out that with <systemUsage> on you can reproduce this problem even without restarting the broker, so the first step would be turn it off in this case, until we find the cause of this problem.
In this configuration it will not be lost messages for a fair number of consumers (like 10 in your original test case). Though you may experience some duplicate messages. Duplicates are normal in the failover situations and they are usually handled by the connection audit itself. The problem is that in this case the duplicate messages are not in the default 2k audit window so they reach the consumer. I filled the issue to make this window size configurable (https://issues.apache.org/activemq/browse/AMQ-2160), but until then you can add a bit of logic in your consumer to skip these messages.
For a large number of consumers this will still fail for the default broker shutdown rate of 20 secs, but increasing it to 60 secs or more makes this test runs fine for a quite a while. We'll keep investigating it further, but maybe this could help you get started. Can you post back your test results with these workarounds?

Thanks
Dejan, Dejan -

Based on your comments, I tried a couple of tests.  In these tests I was running FUSE message broker 5.3.0.0.  I did not set the prefetch size, so it had the default value.  I did comment out the entire <systemUsage> stanza of the broker's configuration.

1. I tried running with the default broker shutdown rate of 20 seconds as in my original test, to test the effect of removing <systemUsage> only.  This failed after 3 broker failovers.  The activemq log for this run is attached as activemq.log.2009_03_12_1

{{Thu Mar 12 17:59:15 CDT 2009 started master broker pid 28845}}
{{Thu Mar 12 17:59:25 CDT 2009 started slave broker pid 29069}}
{{Thu Mar 12 17:59:35 CDT 2009 killing master broker pid 28845, new master pid 29069}}
{{Thu Mar 12 17:59:55 CDT 2009 started slave broker pid 29285}}
{{Thu Mar 12 18:00:15 CDT 2009 killing master broker pid 29069, new master pid 29285}}
{{Thu Mar 12 18:00:35 CDT 2009 started slave broker pid 29515}}
{{Thu Mar 12 18:00:55 CDT 2009 killing master broker pid 29285, new master pid 29515}}

{{Mar 12, 2009 6:00:56 PM org.apache.activemq.transport.failover.FailoverTransport doReconnect}}
{{INFO: Successfully reconnected to tcp://localhost:61616}}
{{Mar 12, 2009 6:00:56 PM org.aaron.MasterSlaveTest$Receiver onMessage}}
{{WARNING: test.queue.8 received 520 expected 2712}}


2. Then I modified the script so it kills brokers every 60 seconds.  This also failed after 3 broker failovers.  The activemq log for this run is attached as activemq.log.2009_03_12_2

{{Thu Mar 12 18:03:34 CDT 2009 started master broker pid 29871}}
{{Thu Mar 12 18:03:44 CDT 2009 started slave broker pid 30090}}
{{Thu Mar 12 18:04:44 CDT 2009 killing master broker pid 29871, new master pid 30090}}
{{Thu Mar 12 18:05:44 CDT 2009 started slave broker pid 30402}}
{{Thu Mar 12 18:06:44 CDT 2009 killing master broker pid 30090, new master pid 30402}}
{{Thu Mar 12 18:07:44 CDT 2009 started slave broker pid 30725}}
{{Thu Mar 12 18:08:44 CDT 2009 killing master broker pid 30402, new master pid 30725}}

{{Mar 12, 2009 6:08:46 PM org.apache.activemq.transport.failover.FailoverTransport doReconnect}}
{{INFO: Successfully reconnected to tcp://localhost:61616}}
{{Mar 12, 2009 6:08:46 PM org.aaron.MasterSlaveTest$Receiver onMessage}}
{{WARNING: test.queue.5 received 1049 expected 3205}}
, Hi Aaron,

what you are seeing now are duplicates that are out of default 2048 audit window size (see sequence numbers). I attached a modified MasterSlave test that skips these kind of messages (along with the activemq.xml used for testing). This should help a bit, but it's not a final solution to your problem. I'll implement now a fix for AMQ-2160 which will allow you to set window size to a larger value and avoid dealing with duplicates in your consumer. We'll also try to make this more stable afterwards, so stay tuned., Dejan -

Thanks for the information.  I'm not sure I understand the audit window size.  How large would the window need to be in my test for clients not to receive duplicates on failover?  Why does the broker still have messages that were delivered and acknowledged thousands of messages ago (ie 1049 when 3205 is expected)?  Why are these old, already delivered and acknowledged messages being processed on failover?, Hi Aaron,

I'm not sure why it happens in this case and it definitely should not send messages processed long time ago. All I can recommend at the moment is that if you receive duplicates in your real-world application, you should deal with them in your consumer. Shutting down the master every 20 sec or so, after all, isn't something you'll have in your production environment. We'll of course try get to the root of the problem and make it work even in this use case., Dejan -

Thanks for your comments.

I agree a production system would probably not kill a broker every 20 seconds.  I developed this test case after observing occasional problems in testing broker failover in our application.  In our application, causing individual failovers sometimes causes old messages to be redelivered or new messages to be delivered out of order.

Based on testing I have done, I believe there is currently some chance of redelivery of old messages or out of order delivery of new messages on *any* failover, not just after several rapid failovers.  I have observed the test case sometimes causes these problems on the *first* failover.

The reason for the rapid 20-second failovers is just to increase the probability of showing the problem in a short amount of time., Here is a patch for this issue. 
There were a bunch of related problems originating from replayed messages from the failover transport. The failover transport replays any message that is in the process of being sent when the connection to the broker is goes down and is resumed. This is fine and expected. The message can be a duplicate and should be suppressed either on the broker side or on the consumer side.

One problem with the persisted hashindex that backs the reference store could result in a spurious message reference and "could not be recovered, already dispatched message". This ocurred when the duplicate reference caused an index to be changed and te original freed. The original can still be reference in the recoverNext() from the kahaReferenceStore. DataContainerImplTest shows this. 

In addition, if the duplicate message is received before the existing message is dispatched and acked, the duplicate reference remains and will eventually get dispatched on restart or when the duplicate checker exceeds its range.
Eliminating the duplicate reference at source in the reference store resolves both these issues.
When memory limits are reached, it was possible for a stores messages to be exhausted (cursor gets to the end) causing dispatch to halt until a restart. Dealing with recovery failure due to no space resolves this.
A consumer ack of a duplicate message could be replaced with a delivery ack and get lost, thus leaving the duplicate to be redsipatched on restart and delivered to the consumer when the client side message audit is exceeded. This explains redelivery of old messages. Ensuring each duplicate is acked in turn resolves this.
Finally, an unmatched ack can occur if recovery dispatch has not yet happened after a restart and an ack is received from a consumer as it was outstanding. In this case, the subscription can wait for recovery and a dispatch to kick in such that it will have a record of the target message. 
, resolved in r758678, committed some additional changes for this to deal with reaching the cache memory limits. r760075, added some additional tests variants to exercise topics and queues in a large transaction. main change is in the way acks were delivered post failover. The failover transport state tracker no longer replays acks and the consumer acks duplcates in a transaction as deliveries to ensure the prefetch extension on the broker is extended. deliverAcks on transport resume has also been replaced with ack related state being reset so that normal acking of the redeliveries can ensue. (deliverAcks on resume lead to acks being received before they were dispatched by the recovering broker)
r761597, I checked out the current activemq 5.3-SNAPSHOT from trunk (r762095) and built it.  This should have all of Gary's fixes in it, correct?

I used the attached activemq.xml configuration file and ran my MasterSlaveTest and run_master_slave_brokers.sh to cause failovers.  This version of the test does not use transactions, and syncOnWrite was set to false.

After 3 master/slave failovers one of the queues redelivered message 705 when the client expected 3570.

From my perspective, it appears the problem is not solved by the changes listed so far.  Therefore I am reopening this issue.


Output from MasterSlaveTest:

{{INFO: Successfully reconnected to tcp://localhost:61616}}
{{Apr 5, 2009 7:31:55 AM org.apache.activemq.transport.failover.FailoverTransport doReconnect}}
{{INFO: Successfully reconnected to tcp://localhost:61616}}
{{Apr 5, 2009 7:31:56 AM org.aaron.MasterSlaveTest$Receiver onMessage}}
{{WARNING: test.queue.2 received 705 expected 3570}}


Output from run_master_slave_brokers.sh:

{{Sun Apr  5 07:30:13 CDT 2009 started master broker pid 5691}}
{{Sun Apr  5 07:30:23 CDT 2009 started slave broker pid 5901}}
{{Sun Apr  5 07:30:33 CDT 2009 killing master broker pid 5691, new master pid 5901}}
{{Sun Apr  5 07:30:53 CDT 2009 started slave broker pid 6112}}
{{Sun Apr  5 07:31:13 CDT 2009 killing master broker pid 5901, new master pid 6112}}
{{Sun Apr  5 07:31:33 CDT 2009 started slave broker pid 6336}}
{{Sun Apr  5 07:31:53 CDT 2009 killing master broker pid 6112, new master pid 6336}}


Log file is attached as activemq.log.2009_04_05., Hi Aaron, thanks for the fast feedback. I have been able to reproduce the failure/duplicate with the junit test case by changing the sleep send time from 3 to the 25ms, which is what you are using. will work to resolve this today. , Aaron, if you refresh and pick up r762464, that should nail it., Hi Gary -

So far I am unable to break your latest fix.  Will let you know if I run into issues.  Thanks for the fast turnaround.

Will the r762464 piece of the fix be included with the fix for FUSE issue MB-456?, this looks resolved to me]