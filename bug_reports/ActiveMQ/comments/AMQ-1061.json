[Looking closer at this, it appears I goofed and didn't set the 200M in my config file.

However, this is still an issue because it is possible for a client to send a single big message (or several big messages in succession) and kill the server.

It would be nice if the prefetch/page in could be configured in terms of bytes, not just number of messages.  Also, some kind of global optimization that looks at the current memory usage percentage and tries to keep it below some threshold.

My application has some use cases where big messages will be going into the queues, where the queues usually contain lots of small messages but there can be much larger ones and possible even streams of larger ones in succession.  It would be great if the server could handle this gracefully., SVN revision 478967.]