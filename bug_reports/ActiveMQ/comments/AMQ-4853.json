[You should investigate why all the consumers are coming and going so often.  , I am. But it is worrying that Activemq 5.9 seemingly can't handle the consumers coming and going in the same way as 5.8. Also, it isn't just that the CPU usage is higher but that it continually grows. 

I am also looking over the changes from 5.8 to 5.9 in case something jumps out., Timothy,

I just had a look at the code and I believe I see what the issue is. The change you made[1] moving the consumers hashmap to a queue is causing the performance issue. We have quite a few consumers so on remove we would have to potentially traverse all the consumers to remove the one. 

As far as our code we do use camel with maxConsumers settings and request reply messages. So I would expect a bit of churn when it comes consumers coming and going.

1. https://git-wip-us.apache.org/repos/asf?p=activemq.git;a=commitdiff;h=74dafd7f24028c3503758581166ec10bb3d5116a, The code that was there, using the map was completely broken so the Queue was used instead.  If you want to create a test case that shows how this impacts performance we can look to try and improve things however the basic functionality needs to stand as it resolves issues with replaying advisories over a network in the correct order.  , LinkedHashMap may be the way to go on this one, +1 Rob.

Tim,
I will try to come up with a stress test for this code. Attached is a Profiling session when the cpu was at nearly 100% usage to show just how badly it is performing. (Note: we were not seeing such CPU usage issues in 5.8.), After doing a bit more research I think the issue is a bit more fundamental than simply using the Queue vs a Map. (The queue implementation definitely makes it worse.) I have been looking at the profiling information more and doing a few tests. I see that the queue is continually growing. Digging a bit deeper I see that the ConsumerInfo class does not have an equals method. Without an equals method the consumers.remove() call in AdvisoryBroker.removeConsumer is pretty useless if we ever create another consumer info object - which I believe to be the case., For completeness a unit test:
{code}
  public void testEqualsNeeded() throws Exception{
    	  //setup
    	  AdvisoryBroker testObj = (AdvisoryBroker) broker.getBroker().getAdaptor(
      			AdvisoryBroker.class);
    	  ActiveMQDestination destination = new ActiveMQQueue("foo");
          ConnectionInfo connectionInfo = createConnectionInfo();
          ConnectionContext connectionContext =  new ConnectionContext(connectionInfo);
          connectionContext.setBroker(broker.getBroker());
          SessionInfo sessionInfo = createSessionInfo(connectionInfo);
          ConsumerInfo consumerInfo = createConsumerInfo(sessionInfo, destination);
          
          testObj.addConsumer(connectionContext, consumerInfo);
          ConsumerInfo duplicateConsumer = consumerInfo.copy();
          
          //act
          testObj.removeConsumer(connectionContext, duplicateConsumer);
          
          
          //assert
          assertEquals(0, testObj.getAdvisoryConsumers().size()); 
    }

{code}, Yes, there's definitely some issues to tackle. Can you attach you test as a complete Java source file?  , I've added the appropriate equals and hashCode overrides on trunk for ConsumerInfo which when run with this test reduces the time from 182 seconds to 2 seconds.  

{code}
    @Test
    public void testEqualsNeeded() throws Exception {
        // setup
        AdvisoryBroker testObj = (AdvisoryBroker) brokerService.getBroker().getAdaptor(AdvisoryBroker.class);
        ActiveMQDestination destination = new ActiveMQQueue("foo");
        ConnectionInfo connectionInfo = createConnectionInfo();
        ConnectionContext connectionContext = new ConnectionContext(connectionInfo);
        connectionContext.setBroker(brokerService.getBroker());
        SessionInfo sessionInfo = createSessionInfo(connectionInfo);

        long start = System.currentTimeMillis();

        for (int i = 0; i < 100; ++i) {

            for (int j = 0; j < 1000; j++) {
                ConsumerInfo consumerInfo = createConsumerInfo(sessionInfo, i, destination);
                testObj.addConsumer(connectionContext, consumerInfo);
                ConsumerInfo duplicateConsumer = consumerInfo.copy();
                testObj.removeConsumer(connectionContext, duplicateConsumer);
            }
        }

        long finish = System.currentTimeMillis();

        long totalTime = finish - start;

        LOG.info("Total test time: {} seconds", TimeUnit.MILLISECONDS.toSeconds(totalTime));

        // assert
        // assertEquals(0, testObj.getAdvisoryConsumers().size());
    }
{code}, Timothy, Thanks for that. I am on GMT and missed the message. Can we get this patched in 5.9 with a new release? , Fixed on trunk, will appear in the next release.  , Is there no possibility of getting this ported to the 5.9 and getting a 5.9.1 release? (Perhaps folding in a fix for the "Leveldb being corrupted in a cluster" for 5.9.1? [1]) As 5.9 just came out, then trunk would not be released for another ~6 months. This is a pretty long time to go with Advisory support and therefore broker networks being effectively broken (unless they are statically configured). Furthermore this is worse than a normal memory leak because the CPU will eventually become pegged.


1. https://issues.apache.org/jira/browse/AMQ-4837, Also see https://issues.apache.org/jira/browse/AMQ-5337]