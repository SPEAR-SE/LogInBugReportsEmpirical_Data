[
I guess When the master loose the network connection to the database,the underlying jdbc connection can not detect the network connection is broken in time.
You can try to set the value of property lockKeepAlivePeriod of jdbcPersistenceAdapter to be smaller than default value(default 30s).
If it works please let me know,thanks., Thanks for the suggestion, i tried to set the property lockKeepAlivePeriod to 3s with this configuration :

<jdbcPersistenceAdapter lockKeepAlivePeriod="3000"  dataDirectory="${activemq.base}/data" dataSource="#oracle-ds" />

But it didn't work. When the network connection on the master is lost, the lock is still present in the database. Any other idea which can solve the network failure test ?

Do you think, i can use the jdbc mode configured with useDatabaseLock="false" ? It seem to be a master/master solution. We need to have a HA Solution with no message lost. With the shared database, the message are stored in the same place. So if the master1 fail, the message is stored in the database and our client switch to the master2 and he can consume the message. Is it correct or i must use a Jdbc master/slave with useDatabaseLock="true" to have a HA solution ?, Seem it's the business for oracle to handle this situation because it doest not detect the broken connection and release the row lock in time.
You can consult your DBA for more advice.
, If the database connection is abruptly lost (no TCP FIN nor RST), for instance when the network cable is unplugged, the DB client application cannot release the lock anymore.
The DB server itself needs to detect the dead connection.
On Oracle the parameter "SQLNET.EXPIRE_TIME" can be used.
, metatech's suggestion is nice.

Exclusive Lock in this point is magic and dangerous way.
 Under certain conditions, this error will occur.
   And if a storage do not support the lock like this, sadness happens., i use the mysql database to store messages ,and i met the same problem. When the master loose the network connection to the database, the lock in the database is not removed and the slave connot acquire the database lock.after the network recovery connection ,the master still can't acquire lock to the database  so now, we have two slaves and no master.period of time , the master process automatically exit,remaining a slave.Any other idea which can solve the network failure test ?, Added a lease based data base locker. Use as follows from xml config with the 5.7-SNAPSHOT{code}       <ioExceptionHandler>
            <jDBCIOExceptionHandler/>
        </ioExceptionHandler>

        <persistenceAdapter>
            <jdbcPersistenceAdapter lockKeepAlivePeriod="1000" lockAcquireSleepInterval="2000">
                <databaseLocker>
                    <lease-database-locker/>
                </databaseLocker>
            </jdbcPersistenceAdapter>
        </persistenceAdapter>
{code}
The optional IOExceptionHandler will pause/resume the transport connectors on any IO exception related to access to the DB.
The lease based lock is acquired by blocking at start and retained by the keepAlivePeriod. To retain, the lease is extended by the lockAcquireSleepInterval, so in theory the master is always {code}lockAcquireSleepInterval-lockKeepAlivePeriod{code} ahead of the slave w.r.t the lease.
The lease is dropped on normal shutdown.
The broker system clock is not in sync with the db, a maxAllowableDiffFromDBTime > 0 will adjust the lease duration if the skew exceeds the absolute maxAllowableDiffFromDBTime value, allowing the db to dictate the utc basis for the lease., would appreciate if you could validate the efficacy of this lease based approach in your environment using the latest 5.7-SNAPSHOT 
, Thanks Gary. What is the suggested patch back-porting process in case I want to apply this patch to my v5.6 broker running the jdbc master-slave configuration against oracle? Should I just build the core jar from source after applying the changes to v5.6 code in my local svn repo?, maybe first try a 5.7-SNAPSHOT to validate it works in your use case, but sure, an updated activemq-core is all that you will need., Thanks Gary, will first test with the 5.7-SNAPSHOT., +1 for the lock lease approach with the deck loaded in favor of the current leasee. That's how i have seen it work with Terracotta and many other implementations...Seems like just the implementation needs to be tested out., Tested 5.7-SNAPSHOT with MySQL and the patch works just fine. The BROKER_NAME also seems to be getting populated in the lock table., For row lock based database locker, I use the same configuration file for all brokers.
This makes deployment job simple really.
LeaseDatabaseLocker need specify the unique lease id, by default it's broker name, 
so does this mean I have to specify different broker name for each one in the cluster?
The last confusion is should lockAcquireSleepInterval be greater than lockKeepAlivePeriod anyway?
, @SuoNayi 
yes, either the brokerName or the lease-database-locker.leaseHolderId needs to be unique for a master/slave pair.
And yes, lockAcquireSleepInterval > lockKeepAlivePeriod is necessary.]