[This behavior is the result of the fileQueueCursor recovery. It caches messages in memory and subsequently on disk when the memory limit is exhausted. On a restart, it wants to refill its memory cache which requires a replay of all messages through that cache and a refill of the temp store. This is not optimal for a deep queue but it means that subsequent message consumption will come from memory (the cache).

The default store based cursor has a similar cache and batch mechanism to load from the store but it does not reload the cache on startup, the cache is disabled till the store is depleted. For deep queues, this will provide a faster restart time, but consumers will be batching from the store rather than reading from the cache. With kahaDB, which is fast, this should not be   problem. One config item that may help is the default maxPageSize attribute, configurable through a PolicyEntry, this defaults to 200, increasing to 1000 may give you a performance impact for a deep queue if you are doing simple load and consume tests.

To use the default store cursor for queues, remove the "<pendingQueuePoicy>" entry or replace "fileQueueCursor" with " storeCursor".
, resolving, working as designed, see explanation in earlier comment., small update, following some sensible user comment, thanks Fredrik, I added some progress notification to the log when cursor recovery is in progress, with 500000 messages you will see something like:{code}2010-09-03 10:16:48,458 [main  ] INFO  Queue - cursor for queue://TEST.FOO has recovered 50000 messages. 10% complete
2010-09-03 10:17:02,057 [main  ] INFO  Queue - cursor for queue://TEST.FOO has recovered 100000 messages. 20% complete
2010-09-03 10:17:37,641 [main  ] INFO  Queue - cursor for queue://TEST.FOO has recovered 150000 messages. 30% complete{code}, Changing to storeCursor resolved this issue. Tested with million queue messages and  no delay in startup. With KahaDb, I haven't seen any performance change with storeCursor. 
Thanks for the quick resolution. , I am facing the same issue but the recommended solution does not work.

I am embedding activeMQ in a process where producer and consumer are in the same process.
The consumers can be turned off for long periods of time.

When i re-start the process which has about 1.1 million persistent message( KahaDB directory around 14GB), it takes
479 seconds to bootup with fileQueueCursor and 113 seconds to bootup with storeCursor.



Any ideas on how to speed up the bootup would be greatly appreciated!!

Version: ActiveMQ 5.5.1 
OS: CentOS 5.6
H/W: 24 core machine with 12 GB ram

code snippet
{
                BrokerService broker = new BrokerService();
		brokerName = "somename";
		broker.setBrokerName(brokerName);
		broker.setDataDirectory("/something");
		brokerUrl = "vm://" + brokerName + "?marshal=false&broker.persistent=true";
		broker.addConnector(brokerUrl);
		
		SystemUsage sm = broker.getSystemUsage();
		sm.setSendFailIfNoSpace(true);
		
		// set broker memory and disk limits
		if( memoryLimit > 0 )
			sm.getMemoryUsage().setLimit(memoryLimit);
		
		if( storageLimit > 0 )
			sm.getStoreUsage().setLimit(storageLimit);
		
		if( tempStorageLimit > 0 )
			sm.getTempUsage().setLimit(tempStorageLimit);

		// kahaDB settings for data recovery in case of corruption
		KahaDBPersistenceAdapter adapter = (KahaDBPersistenceAdapter) broker
				.getPersistenceAdapter();
		adapter.setCheckForCorruptJournalFiles(true);
		adapter.setChecksumJournalFiles(true);
		adapter.setIgnoreMissingJournalfiles(true);
		
		PolicyMap policyMap = new PolicyMap();
   	    PolicyEntry policy = new PolicyEntry();
	    StorePendingQueueMessageStoragePolicy storePolicy = new StorePendingQueueMessageStoragePolicy();
	    policy.setPendingQueuePolicy(storePolicy);
	    policy.setProducerFlowControl(false);
	    
	    policyMap.setDefaultEntry(policy);
	    broker.setDestinationPolicy(policyMap);
	        
		// start the broker
		broker.start();
		

thanks,
Raghav, @Raghav How do you stop the broker? If the broker does not do a clean shutdown it will initiate recovery on restart which involves replaying the journal from the last checkpoint which can be slow with large volumes. This should be the exception (jvm abort) and not the norm. 
, @Gary 

Thanks for your reply. I have found another issue....

Let's consider the case where the JVM process crashed.
Now when the broker restarts KahaDB is not able to load the messages and reports out of memory error.

The KahaDB database size on disk is 34GB and has about 3 million records.

I set the broker memory limit to 2GB but still it crashes. Is it trying to load the entire 34 GB in memory??

Stack Trace
-----------
exception in thread "main" java.lang.OutOfMemoryError: Java heap space
        at org.apache.activemq.protobuf.BaseMessage.mergeFramed(BaseMessage.java:228)
        at org.apache.activemq.store.kahadb.MessageDatabase.load(MessageDatabase.java:825)
        at org.apache.activemq.store.kahadb.KahaDBStore.loadMessage(KahaDBStore.java:955)
        at org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore$4.execute(KahaDBStore.java:471)
        at org.apache.kahadb.page.Transaction.execute(Transaction.java:728)
        at org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.recover(KahaDBStore.java:464)
        at org.apache.activemq.store.ProxyMessageStore.recover(ProxyMessageStore.java:52)
        at org.apache.activemq.broker.region.Queue.initialize(Queue.java:270)
        at org.apache.activemq.broker.region.DestinationFactoryImpl.createDestination(DestinationFactoryImpl.java:86)
        at org.apache.activemq.broker.region.AbstractRegion.createDestination(AbstractRegion.java:473)
        at org.apache.activemq.broker.jmx.ManagedQueueRegion.createDestination(ManagedQueueRegion.java:56)
        at org.apache.activemq.broker.region.AbstractRegion.addDestination(AbstractRegion.java:123)
        at org.apache.activemq.broker.region.RegionBroker.addDestination(RegionBroker.java:298)
        at org.apache.activemq.broker.BrokerFilter.addDestination(BrokerFilter.java:145)
        at org.apache.activemq.advisory.AdvisoryBroker.addDestination(AdvisoryBroker.java:145)
        at org.apache.activemq.broker.BrokerFilter.addDestination(BrokerFilter.java:145)
        at org.apache.activemq.broker.BrokerFilter.addDestination(BrokerFilter.java:145)
        at org.apache.activemq.broker.MutableBrokerFilter.addDestination(MutableBrokerFilter.java:151)
        at org.apache.activemq.broker.region.AbstractRegion.start(AbstractRegion.java:95)
        at org.apache.activemq.broker.region.RegionBroker.start(RegionBroker.java:198)
        at org.apache.activemq.broker.jmx.ManagedRegionBroker.start(ManagedRegionBroker.java:106)
        at org.apache.activemq.broker.BrokerFilter.start(BrokerFilter.java:157)
        at org.apache.activemq.broker.BrokerFilter.start(BrokerFilter.java:157)
        at org.apache.activemq.broker.TransactionBroker.start(TransactionBroker.java:109)
        at org.apache.activemq.broker.BrokerService$3.start(BrokerService.java:1803)
        at org.apache.activemq.broker.BrokerService.start(BrokerService.java:497)


Log messages from ActiveMQ broker
---------------------------------
[2011-12-09 10:26:29.339]  DEBUG: Main:memory: usage change from: 24822% of available memory, to: 24823% of available memory
[2011-12-09 10:26:30.322]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 24823% of available memory, to: 24824% of available memory
[2011-12-09 10:26:30.323]  DEBUG: Main:memory: usage change from: 24823% of available memory, to: 24824% of available memory
[2011-12-09 10:26:31.714]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 24824% of available memory, to: 24825% of available memory
[2011-12-09 10:26:31.715]  DEBUG: Main:memory: usage change from: 24824% of available memory, to: 24825% of available memory
[2011-12-09 10:26:32.696]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 24825% of available memory, to: 24826% of available memory
[2011-12-09 10:26:32.696]  DEBUG: Main:memory: usage change from: 24825% of available memory, to: 24826% of available memory
[2011-12-09 10:26:34.657]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 24826% of available memory, to: 24827% of available memory
[2011-12-09 10:26:34.657]  DEBUG: Main:memory: usage change from: 24826% of available memory, to: 24827% of available memory

thanks,
Raghav, recovery should not be any more onerous on memory resources than normal operation. What is the JVM heap allowance (-Xmx ?? command line option to the jvm)? Did the JVM process crash with an OOM initially?, @Gary

My Bad: please ignore the previous comment. 

i was playing around with vmQueueCursor and left it in the code base.
It was causing the out of memory issue.

Regarding the original issue i reported with KahaDB being slow, i am not shutting down the broker cleanly all the time since i am using the JVM shutdown hook, which does not run if the process is killed externally.

I would add the logic to shut it down cleanly and then re-run the tests to report the number.

Thanks for your help.

thanks,
Raghav
, @Gary

The issue where Broker is starting slowly even after shutting it down cleanly is still there..

It takes 117 seconds to restart the broker with KahaDB size on disk = 14GB with 1 million records.
Subsequent starts after clean shutdown also take the same amount of time.

When i stop the broker i am calling broker.stop();

Thoughts??

Log statements
--------------
[2011-12-09 12:18:43.372]  DEBUG: binding to broker: stitcher1-UDCServer
[2011-12-09 12:18:43.461]   INFO: PListStore:/home/rrao/myudc/stitcher1-UDCServer/tmp_storage started
[2011-12-09 12:18:43.572]  DEBUG: Probably not using JRE 1.4: mx4j.tools.naming.NamingService
[2011-12-09 12:18:43.574]  DEBUG: Starting JMXConnectorServer...
[2011-12-09 12:18:43.694]   INFO: Using Persistence Adapter: KahaDBPersistenceAdapter[/home/rrao/myudc/stitcher1-UDCServer/KahaDB]
[2011-12-09 12:18:43.700]   INFO: JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[2011-12-09 12:20:34.390]   INFO: KahaDB is version 3
[2011-12-09 12:20:34.391]  DEBUG: loading
[2011-12-09 12:20:34.400]  DEBUG: loading
[2011-12-09 12:20:34.400]  DEBUG: loading
[2011-12-09 12:20:34.400]  DEBUG: loading
[2011-12-09 12:20:34.409]  DEBUG: loading
[2011-12-09 12:20:34.409]  DEBUG: loading
[2011-12-09 12:20:34.464]   INFO: Recovering from the journal ...
[2011-12-09 12:20:34.464]   INFO: Recovery replayed 1 operations from the journal in 0.055 seconds.
[2011-12-09 12:20:36.905]   INFO: ActiveMQ null JMS Message Broker (stitcher1-UDCServer) is starting
[2011-12-09 12:20:36.905]   INFO: For help or more information please see: http://activemq.apache.org/
[2011-12-09 12:20:37.076]  DEBUG: stitcher1-UDCServer adding destination: queue://queue-AVIR
[2011-12-09 12:20:40.731]  DEBUG: Checkpoint started.
[2011-12-09 12:20:40.752]  DEBUG: Checkpoint done.
[2011-12-09 12:20:40.794]  DEBUG: queue-AVIR toPageIn: 200, Inflight: 0, pagedInMessages.size 0, enqueueCount: 0, dequeueCount: 0
[2011-12-09 12:20:40.800]  DEBUG: Publishing: vm://stitcher1-UDCServer for broker transport URI: vm://stitcher1-UDCServer?marshal=false&broker.persistent=true
[2011-12-09 12:20:40.800]  DEBUG: stitcher1-UDCServer adding destination: topic://ActiveMQ.Advisory.Queue
[2011-12-09 12:20:40.811]  DEBUG: queue-AVIR toPageIn: 200, Inflight: 0, pagedInMessages.size 0, enqueueCount: 0, dequeueCount: 0
[2011-12-09 12:20:40.814]   INFO: Connector vm://stitcher1-UDCServer?marshal=false&broker.persistent=true Started
[2011-12-09 12:20:40.830]   INFO: ActiveMQ JMS Message Broker (stitcher1-UDCServer, ID:stitcher1-38687-1323462036935-0:1) started
[2011-12-09 12:20:40.940]  DEBUG: Setting up new connection id: ID:stitcher1-38687-1323462036935-2:1, address: vm://stitcher1-UDCServer?marshal=false&broker.persistent=true#0
[2011-12-09 12:20:40.941]  DEBUG: stitcher1-UDCServer adding destination: topic://ActiveMQ.Advisory.Connection
[2011-12-09 12:20:40.949]  DEBUG: stitcher1-UDCServer adding consumer: ID:stitcher1-38687-1323462036935-2:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
[2011-12-09 12:20:41.080]  DEBUG: Setting up new connection id: ID:stitcher1-38687-1323462036935-2:2, address: vm://stitcher1-UDCServer?marshal=false&broker.persistent=true#2
[2011-12-09 12:20:41.082]  DEBUG: stitcher1-UDCServer adding consumer: ID:stitcher1-38687-1323462036935-2:2:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
[2011-12-09 12:20:41.088]  DEBUG: stitcher1-UDCServer adding consumer: ID:stitcher1-38687-1323462036935-2:2:1:1 for destination: queue://queue-AVIR
[2011-12-09 12:20:41.095]  DEBUG: queue://queue-AVIR add sub: QueueSubscription: consumer=ID:stitcher1-38687-1323462036935-2:2:1:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
[2011-12-09 12:20:41.095]  DEBUG: stitcher1-UDCServer adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.queue-AVIR
[2011-12-09 12:20:41.096]  DEBUG: queue-AVIR toPageIn: 200, Inflight: 0, pagedInMessages.size 0, enqueueCount: 0, dequeueCount: 0
[2011-12-09 12:20:41.101]   INFO: started dispatcher [AVIR-1] (com.activevideo.udc.server.dispatcher.DispatcherManager.start:832)
[2011-12-09 12:20:41.157]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 0% of available memory, to: 1% of available memory
[2011-12-09 12:20:41.158]  DEBUG: Main:memory: usage change from: 0% of available memory, to: 1% of available memory
[2011-12-09 12:20:41.169]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 1% of available memory, to: 2% of available memory
[2011-12-09 12:20:41.169]  DEBUG: Main:memory: usage change from: 1% of available memory, to: 2% of available memory
[2011-12-09 12:20:41.184]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 2% of available memory, to: 3% of available memory
[2011-12-09 12:20:41.184]  DEBUG: Main:memory: usage change from: 2% of available memory, to: 3% of available memory
[2011-12-09 12:20:41.199]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 3% of available memory, to: 4% of available memory
[2011-12-09 12:20:41.199]  DEBUG: Main:memory: usage change from: 3% of available memory, to: 4% of available memory
[2011-12-09 12:20:41.213]  DEBUG: Main:memory:queue://queue-AVIR:memory: usage change from: 4% of available memory, to: 5% of available memory
[2011-12-09 12:20:41.213]  DEBUG: Main:memory: usage change from: 4% of available memory, to: 5% of available memory
]