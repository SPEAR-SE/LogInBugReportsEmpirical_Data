[The test case is here,http://activemq.2283324.n4.nabble.com/file/n4665800/MemoryUsageBrokerTest.java
, One simple solution is when the cursor calls the hasSpace method to see if it has space to cache messages we also check it's parent to see if it's full.
The patch is based on 5.6 codebase., This is now fixed with svn revision 1477574. Thanks for raising the issue and providing the test case., The fix applies the cursor high water mark value to the shared system usage limit in error.
When checking if the shared or parent system usage is exhausted a value of 100% should be used while the per destination limit can be validated against the memoryUsageHighWaterMark via the perDestination percentUsage.

This becomes apparent with low values for memoryUsageHighWaterMark. With N destinations, the shared system usage can easily exceed this low per destination value and starve dispatch/pageIn for subsequent destinations.
, Commit c76f109692749b8bf7d7cd39ed75022875c39213 in activemq's branch refs/heads/master from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=c76f109 ]

https://issues.apache.org/jira/browse/AMQ-4467 - modify fix check full against shared limit and high water mark against local limit, additional test
, shared limit check now independent of the per destination watermark., Good catch [~gtully].  A couple things...., First, if memory usage now properly goes up to 100% usage across all destinations instead of stopping at the high water mark (typically 70%) will that ever effect paging in for dispatch?  I'm pretty sure the pending cursors will still page in for dispatch and that the memory usage is just used for producers and not consumers but want to see if you could think of any scenarios where dispatch would stop.

Second, should Topics honor this value as well? I.e. on this line in Topic https://github.com/apache/activemq/blob/activemq-5.14.3/activemq-broker/src/main/java/org/apache/activemq/broker/region/Topic.java#L376 memory usage is checked for full but should it honor the high water mark instead?, Thanks for the feedback @Christopher L], It can stop dispatch which is a little worrying alright. The reasoning is more from the intent of the linked issue: AMQ-4494, it there is no room for dispatch (due to bad configuration) then rather than OOM the vm, the limits are enforced and some in-memory messages need to be consumed before more can be paged in.
To have a better solution in this scenario - having a mechanism to purge the cache for inactive destinations would be needed. I guess gcInactiveDestinations would do it with a variant that just purged the cursor rather than deleted the messages.

Peek at the additional test - it failed due to not being able to page in at 50% ( its high water mark) of the system limit. Now it will fail at 100% of the shared limit.

Note: hasSpace is queried by the cursor prior to pageIn: https://github.com/apache/activemq/blob/activemq-5.14.3/activemq-broker/src/main/java/org/apache/activemq/broker/region/cursors/QueueStorePrefetch.java#L118

Topics use only the shared limit to gate pageIn for subscriptions., Ah ok, I understand better now thanks for the explanation.  So the core behavior hasn't changed and now the usage just goes up to 100% if using multiple destinations.  Now that I think about it, I'm pretty sure I've seen this behavior happen where dispatch slows to a crawl down when memory usage hits the high water mark because future dispatched messages have to wait for messages to be acked as shown in your test at 50%.

Purging the cursor is an interesting idea and I think would be a nice improvement.  Clearing out the the cursor cache if the destination is inactive so other active destinations get access to all of the memory certainly seems like the ideal solution.  If I get some time I will play around with this a little bit as a feature for the 5.15 release.
, Commit 25f112c5c9a843f162296ad38eb79be47183e0be in activemq's branch refs/heads/master from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=25f112c ]

[AMQ-6687] ensure transacted sends blocked on pfc do not resume after tx completion. AMQ-4467 refine the fix such that PFC kicks in such that the cache will accept messsages that push it over it's limit while it is still under the limit
, With transactions or concurrentStoreAndDispatch - memory is accounted for before it reaches the cache which typically means that the cursor cache stops accepting messages early. If we want the cache and PFC we have to let the cache consume >100% of memory. To achieve this we must set the cursorHighWaterMark>100% something like 120% such that it will still allow a message to be cached while is is <100 that will put it over the 100% (full) limit.
Ie: we check is full and we are at 99%, we accept another message that pushes us to 101%, without a cursorHighWaterMark > 101 the cursor won't cache and will stick at 99% and producer flow control (PFC) won't kick in.]