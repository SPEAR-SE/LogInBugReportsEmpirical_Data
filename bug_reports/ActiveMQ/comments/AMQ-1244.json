[A few thoughts. Firstly note that this locking transaction never updates any data and never needs to be replicated.

Couldn't the replication server just ignore the lock table? Or we could allow the lock table to be in a different schema (logical database) if that helps?

There needs to be some table used for locking; as we need to ensure multiple brokers don't write to the same logical database. Though by all means suggest a suitable workaround that works for you with database replication; would ignoring the table, or moving it to a separate logical database/schema work?

Worst case scenario; we could use a completely separate database entirely (even a different JDBC provider! :) but I'd rather reuse the same DataSource if we can (it makes things much simpler to code and removes a multitude of possible issues such as folks using a local Derby DB for the lock :), Our DBAs confirm that configuring the replication server to ignore the lock-table is a possible workaround with our system. This might be manufacturer-dependent. Using a lock table in a different logical database (not to be replicated) is another possible solution.

Wouldn't it though be easier and much more portable to actually insert a (dummy) row in the lock-table as the inter-broker communication mechanism? This wouldn't require a transaction to be kept open for the whole lifetime of the broker., The idea of keeping the transaction open is to keep a lock; so that if the connection/transaction fails, the broker stops being the master, then all the brokers fight to get the lock again.

Inserting a row in a database doesn't really help; if the master dies; how do the slaves know?

If you can come up with a workable alternative I'm all ears. (Especially if its with [a patch|http://activemq.apache.org/contributing.html] :) but until then, I think the long transaction is the only real alternative we have. 

You could experiement with the SQL (the Statements class)  so that the lock table is named to be in a different logical database; yet using the same DataSource .
, I assume that the only communication channel that two brokers have in common is the database. What about leveraging on the usual concept of a heartbeat? Let the Lock-Table have a datetime row and let the active broker update periodically the row with the current (database) time. If the standby broker detects that the row value diverges from the current time more than a delta, then the active broker is stalled/dead. Advantages of this technique:
a) No transaction kept open for an undetermined time window
b) To my eyes, this is even more effective in detecting a failure that the current mechanism, for it requires now the active broker to actually undertake an action,and not just remain inactive holding a token.

Comments?, We have addressed an issue mentioned in TS-1244 with a snippet of code.
We would like to contribute our fix to the ActiveMQ 5.2 code base for consideration for permanent inclusion.

This fix has proven out in our customer environment, and our customer is happy with the code.
We would now like to be sure our fix gets into the main branch so we do not have to patch a one off version with every release.

Any chance in getting this patch accepted to the community through any channel that works?  
The fix is fairly simple in that it basically does what James Strachan suggests in the ticket...
   (i.e., optionally use a different data source for the lock).  

This code change is submitted by Jason Theune on behalf of Rod Cope.

Here's the changed and added code in JDBCPersistenceAdapter.java:
 ======================================================
    // Added by Rod Cope of OpenLogic to allow the lock table to
    // reside in a separate database.  This makes sure that the
    // main database's transaction logs don't fill up because
    // the ActiveMQ lock transaction never closes.
    private DataSource lockDataSource;
 
    // Modified by Rod Cope of OpenLogic to allow the lock table to
    // reside in a separate database.  This makes sure that the
    // main database's transaction logs don't fill up because
    // the ActiveMQ lock transaction never closes. 
    protected DatabaseLocker createDatabaseLocker() throws IOException {
        return new DefaultDatabaseLocker(getLockDataSource(), getStatements());
    }

 
    // Added by Rod Cope of OpenLogic to allow the lock table to
    // reside in a separate database.  This makes sure that the
    // main database's transaction logs don't fill up because
    // the ActiveMQ lock transaction never closes.
    public DataSource getLockDataSource() throws IOException {
        if (lockDataSource == null) {
            lockDataSource = getDataSource();
            if (lockDataSource == null) {
                throw new IllegalArgumentException("No dataSource property has been configured");
            }
        } else {
            LOG.info("Using a separate dataSource for locking: " + lockDataSource);
        }
        return lockDataSource;
    }
    // Added by Rod Cope of OpenLogic to allow the lock table to
    // reside in a separate database.  This makes sure that the
    // main database's transaction logs don't fill up because
    // the ActiveMQ lock transaction never closes.
    public void setLockDataSource(DataSource dataSource) {
        this.lockDataSource = dataSource;
    }
 
Of course, it's fine if they resolve the issue in some other way that makes sense and/or change any comments.  
I'd just like to avoid having our customer on a forked version because support efforts would be complicated.
, Fixed by SVN revision 669733]