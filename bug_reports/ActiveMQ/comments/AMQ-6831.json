[[~gtully] - Do you think this issue is related to AMQ-6771 ?, [~cshannon] I hope not. I would need to check the journal files to verify the corrupt locations. A sanity check to see if a current snapshot has the same determination may help narrow this down.

The logs should indicate the journal locations in question? How do we know there is no corruption present at the moment?, Yeah I just find it interesting that the description says downgrading to 5.15.0 fixes the issue.  

[~masc3d], are you able to upload a small KahaDB store that reproduces the issue?, yes, that would be possible, as it's my local dev db, it shouldn't contain anything sensitive.

I also found that this issue is related to the preallocation kahadb settings:
{code}
        pa.preallocationScope = Journal.PreallocationScope.ENTIRE_JOURNAL_ASYNC.name
        pa.preallocationStrategy = Journal.PreallocationStrategy.ZEROS.name
{code}

which I enabled for performance reasons.

Disabling preallocation will yield both
{code}
2017-10-09 18:34:57.512  WARN 10617 --- [pool-3-thread-1] o.a.a.store.kahadb.MessageDatabase       : Cannot recover message audit

java.io.IOException: Invalid location size: 1:28, size: 0
	at org.apache.activemq.store.kahadb.disk.journal.DataFileAccessor.readRecord(DataFileAccessor.java:88) ~[activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.disk.journal.Journal.read(Journal.java:936) ~[activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.load(MessageDatabase.java:1151) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.recoverProducerAudit(MessageDatabase.java:784) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.recover(MessageDatabase.java:674) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.open(MessageDatabase.java:473) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.load(MessageDatabase.java:493) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.doStart(MessageDatabase.java:297) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.KahaDBStore.doStart(KahaDBStore.java:219) [activemq-kahadb-store-5.15.1.jar:5.15.1]
{code}
and subsequently
{code}
2017-10-09 18:34:57.513  WARN 10617 --- [pool-3-thread-1] o.a.a.store.kahadb.MessageDatabase       : Cannot recover ackMessageFileMap

java.io.IOException: Invalid location size: 1:431, size: 0
	at org.apache.activemq.store.kahadb.disk.journal.DataFileAccessor.readRecord(DataFileAccessor.java:88) ~[activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.disk.journal.Journal.read(Journal.java:936) ~[activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.load(MessageDatabase.java:1151) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.recoverAckMessageFileMap(MessageDatabase.java:805) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.recover(MessageDatabase.java:675) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.open(MessageDatabase.java:473) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.load(MessageDatabase.java:493) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.MessageDatabase.doStart(MessageDatabase.java:297) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.KahaDBStore.doStart(KahaDBStore.java:219) [activemq-kahadb-store-5.15.1.jar:5.15.1]
	at org.apache.activemq.util.ServiceSupport.start(ServiceSupport.java:55) [activemq-client-5.15.1.jar:5.15.1]
	at org.apache.activemq.store.kahadb.KahaDBPersistenceAdapter.doStart(KahaDBPersistenceAdapter.java:232) [activemq-kahadb-store-5.15.1.jar:5.15.1]
{code}

but the broker will at least start.
, [~masc3d] I had a quick peek at the kahadb.zip but there are no journal files in there. Can you check. Also, if possible describe simple steps to reproduce. I flipped the bits to enable PreallocationStrategy.ZEROS on a few of the recovery unit tests and did not reproduce., yes sorry, checked again and replaced the archive with the full kahadb folder, Commit f9899922783e0e94de030f4c867e5d48a3d869a9 in activemq's branch refs/heads/master from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=f989992 ]

[AMQ-6831, AMQ-6771] fix up recovery check to ensure full batch is available in memory, regression from AMQ-6771
, This is a regression - AMQ-6771 batched the recovery reads but in this case the alignment on a batch record meant a the batch buffer was not refilled. Disabling the recoveryCheck will avoid this problem but it is a serious bug., Commit 0f544fd54bde5d39f5e6e19d189580884740768b in activemq's branch refs/heads/activemq-5.15.x from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=0f544fd ]

[AMQ-6831, AMQ-6771] fix up recovery check to ensure full batch is available in memory, regression from AMQ-6771

(cherry picked from commit f9899922783e0e94de030f4c867e5d48a3d869a9)
, Thanks for taking a look Gary, when this is good to go I can do a 5.15.2 release since this is a serious issue., [~masc3d] thanks for the kahadb.zip it made it easy to track down.

[~cshannon] it should be sorted however another set of eyes on the change set for AMQ-6831 would be valuable. Thanks., Commit e793260573f30365572a1e7507cd98e9ed17b1b5 in activemq's branch refs/heads/master from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=e793260 ]

[AMQ-6831, AMQ-6771] trigger eofexception on read -1 - AMQ6522Test
, There is a workaround but it is temporary. Here is the background, there is a problem with AMQ-6771 that speeds up the checkForCorruptJournalFiles. On a restart, it is possible that the check will report corruption when there is none. It is independent of the preallocation strategy or preallocation scope. 
If ignoreMissingJournalFiles=true is configured, this can lead to unnecessary loss of data, otherwise the broker will fail to start and report the corruption and there will be no loss.
If there is no reason to suspect corruption it may be this defect. The defect relates to the parsing of a batch of journal data. If the journal record header crosses a batch boundary at a particular point, the defect can happen. 
Disabling the checkForCorruptJournalFiles will avoid the problem but also changing or varying the read batch size may avoid the problem.
The read batch size is controlled by journalMaxWriteBatchSize which default to 4mb. Setting that to 10mb or some larger number may help. It is a little random but the window for this to occur is quite small. If the journalMaxWriteBatchSize is half of of the journalSize (and there is enough memory) then two reads will parse a journal file and the chance of a batch being on a boundary and hitting this defect is very small., Commit d66e96e8bc7be51a93835149e132204407d79b5f in activemq's branch refs/heads/activemq-5.15.x from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=d66e96e ]

[AMQ-6831, AMQ-6771] trigger eofexception on read -1 - AMQ6522Test

(cherry picked from commit e793260573f30365572a1e7507cd98e9ed17b1b5)
, [~gtully] - The fix looks good to me, I ran through some of my tests and everything seemed fine so far]