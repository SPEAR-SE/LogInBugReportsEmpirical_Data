[most likely there are some duplicate sends in the mix. Producers that use failover and had an inflight send when they lost their connection and reconnected. 
The first approach may be to use maxReconnectAttempts=0 in the failover urls such that the application sees these connection failures and can deal with them with new messages that won't be seen as duplicates by the broker.

the other option is some bug in the sync between the cursor and the store. disabling the cursor cache may avoid that scenario.

There are message audits on the cursors, if they detect a duplicate they will redirect it to the DLQ in case there is some error in the duplicate suppression to ensure no message loss. From that perspective the DLQ logging looks ok.
However with 8 duplicates, it may be that the cursor audit needs to be configured with larger limits such that it will suppress more duplicates.
see: PolicyEntry - setMaxProducersToAudit  (the number for max concurrent producers - default to 64) and setMaxAuditDepth (the range to track - a transaction batch size). Most likely setMaxProducersToAudit needs to be larger for your setup.

To fully understand what is going on, we need a scenario that will reproduce and really against the master code base, which will contain all of the latest fixes.
, Thanks! We'll look into the suggestions, and check logs on the clients (there is quite a bit of app-side logging when receiving and sending messages, and committing transactions).

However, what about the 7 lost messages, of which 6 evidently are present in DB but AMQ fails to "see" them when "introspected" via JMX, QueueBrowser and BrokerDestinationView? Also, the last one of those messages is utterly gone.

Any clues in the time-aspect? It all happened within 1 second.]