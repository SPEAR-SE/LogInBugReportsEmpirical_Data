[GitHub user cshannon opened a pull request:

    https://github.com/apache/activemq/pull/84

    Modified StoreQueueCursor to prevent a broker deadlock

    Modified StoreQueueCursor to properly implement tryAddMessageLast so that the message lock can be released during a timeout when the temporary store is full.  Updated Queue to call tryAddMessageLast instead of addMessageLast in the cursorAdd method.
    
        This resolves https://issues.apache.org/jira/browse/AMQ-5712


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/cshannon/activemq AMQ-5712

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/activemq/pull/84.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #84
    
----
commit 631518cda7ce81d5ff677b06db9c833d0b8538ee
Author: Christopher L. Shannon (cshannon) <christopher.l.shannon@gmail.com>
Date:   2015-04-08T18:49:57Z

    Modified StoreQueueCursor to properly implement tryAddMessageLast so that the message lock can be released during a timeout when the temporary store is full.  Updated Queue to call tryAddMessageLast instead of addMessageLast in the cursorAdd method.
    
    This resolves https://issues.apache.org/jira/browse/AMQ-5712

----
, I just submitted a pull request: https://github.com/apache/activemq/pull/84

This seems to fix the issues that I am having.  Without the patch, the broker would deadlock (I could not purge, etc) when the temp store limit was hit for non-persistent messages for both sync and async sends and also both when sendFailIfNoSpace is true or false.  

With this patch, I am able to purge and no longer have deadlock issues.  For async sends, if {{sendFailIIfNoSpace}} is false the producer will block but I can purge and then the producer resumes.  I {{sendFailIfNoSpace}} is true, exceptions are logged to the broker and I can still purge.  For non-persistent sync sends, if {{sendFailIIfNoSpace}} is false the producer will block but I can purge and then the producer resumes.  I {{sendFailIfNoSpace}} is true, the producer gets an exception which is what should happen.

Let me know if this looks ok. I looked at what was done for Topics in AMQ-2475 and I tried to follow the same strategy. I can also try and add a test or 2 if needed., I general it's a good idea to add some unit tests that cover the problem you are trying to address, this provides context to the person reviewing the patch, and protects the fix into the future.  , [~tabish121], sounds good.  I don't have time today but tomorrow morning I will try and get some tests together to cover this fix.  I'll push up my change to my branch when I am done., I believe I've run into this while doing some testing for AMQP flow control issues.  Once I did some debugging I remembered this issue while looking into the stack traces.  , I started working on a unit test today to replicate this issue but I haven't quite been able to reproduce the bug in a unit test yet.  In my simple unit test (just one producer), when the temp storage fills the broker detects this at line 821 of {{Queue.java}} when {{checkUsage(context, producerExchange, message);}} is called.

When I run our real broker, it gets past that line until it hits the {{cursorAdd}} method and ultimately gets stuck spinning in {{FilePendingMessageCursor.java}} on line 235 at {{if (systemUsage.getTempUsage().waitForSpace(maxWaitTime))}}

Our broker is configured for persistent messaging, but the producer is sending non-persistent messages which is why the temp store is used.  I'll continue to try and put a test together next week or figure out what's different about my set up.  We have some custom code that we are using so it could be that or it could just be our configuration. (Maybe something in the Queue Policy that we have configured)  What I do know is that when I apply my pull request it fixes the dead lock and the broker no longer gets stuck on line 235 of {{FilePendingMessageCursor.java}}, Timothy,

I just pushed up my updated [pull request|https://github.com/apache/activemq/pull/84/] with a unit test.  If you run the test before my patch, it will timeout because of a deadlock.  With my patch applied it completes successfully.  The key in this test to making it deadlock is the issue only occurs when the temporary storage size is configured to be less than the memory storage size.  (such as 4 gig of memory storage and 1 gig of temp storage).  While this configuration probably isn't too likely, it's still a possibility.  When memory fills up and it is dumped to disk, the deadlock occurs and the queue can not be purged.  My unit test demonstrates this.

Also, I still think there other conditions that cause the broker to deadlock in the same spot (in one of our servers this has happened and the temporary storage was greater than memory size) but this unit test was the easiest way I could reproduce the problem reliably.

Let me know what you think,
Chris

, Thanks for the patch, I had uncovered much the same, in my testing and have a smaller but similar test case using the AMQP test client.  The issue occurs due to a race when the temp store is initialize by a change in memory usage that trips the limit causing the in memory message to need to be sent to disk.  The problem is that in the Queue send we don't see that temp storage is full yet and try to do the add.  While your fix does work around this is would result in the lose of the message(s) that arrive while this is happening which is not something we would want to do in the case of a Queue which has specific QOS guarantees.  

I am taking a look at how things work today and rethinking some of the layering of add vs tryAdd as it seems a bit wrong to me and can lead to this sort of error in more than one case as you have pointed out.  , Perhaps I've missed something but if you're working with non-persistent messages then why not configure a policyEntry for the queue to use a vmCursor rather than the default storeCursor? 

Regardless, I agree that the temp store's implementation needs some work. Ideally it should honor the sendFailIfNoSpaceAfterTimeout when configured on the systemUsage element., Great, thanks for your help and for taking a look this issue in detail as it is very important to us and it is causing us a lot of problems.  I suspected my patch may not be the best solution and would need some rework because when the tryAdd method times out with my patch nothing is actually done with that message.  After returning false it just continues on and the message gets lost as you pointed out.  However, I figured submitting something that at least demonstrated the issue as well as a unit test where it is consistently reproducible would help get things started towards finding the best solution to fix the issue permanently.

Chris, [~paulgale], Our issue is that we occasionally have slow consumers which fill up our entire memory store (and temporary store) which is causing the deadlock.  This is the reason we can't use the vmCursor as we need to be able to spill over onto to disk when the memory store fills up.  Also, in our case the jms producer is setting the delivery mode as non-persistent (so the temp store gets used), but it could just as easily switch to persistent.  We want the queue to be set up so the producer can decide if it wants to publish persistent or non persistent messages., I too have hit the same limitations of the temp store. In the interim you can always force the broker to treat all messages as persistent using the {{forcePersistencyModeBrokerPlugin}}. Alternatively use the broker component. 

Perhaps you might need to supplement it with (it's been a while) this to force the cursor to not use the temp store:

{code}
<pendingQueuePolicy>
  <storeCursor/>
</pendingQueuePolicy>
{code}

Is PFC disabled for your queue? If so, why?

Regardless, even if the temp store worked correctly both memory and disk are limited resources so you're only delaying the inevitable as one of them will eventually fill up - that is, not unless the producer is flow controlled.
, PFC in this case doesn't matter as the problem occurs outside the normal checks and the add of the message into the cursor stalls while holding the message lock preventing any consumer from ever pulling a message off the Queue so basically the Queue becomes unusable until a broker restart. , As Timothy said, PFC doesn't make a difference and we have tried it both on and off.  For now we have the producer switched to being persistent to fix the issue temporarily. {{forcePersistencyModeBrokerPlugin}} doesn't really help because we want to be able to support both persistent and non-persistent messages on the same destination and don't want to enforce what the producer sets the delivery mode as. , I don't see how this plugin puts a requirement on the producer. For example, setting {{<forcePersistencyModeBrokerPlugin persistenceFlag="true"/>}} allows the producer to send either form. It simply makes all messages persistent (or non-persistent if {{false}}).
, Patch with test and a hacked workaround that allows the Queue to stall but still recover via purge or consumption that you can apply to your local broker build for now.  The problem starts to run deep if you track it far enough so we should probably do more work here to clean things up and work more sensibly, and predictably.  , Thanks Timothy.  I have tested out this patch and it looks good.  I will go ahead and apply this to our broker so we can use it for now., Github user cshannon closed the pull request at:

    https://github.com/apache/activemq/pull/84
, Commit cc6213ebf25a129b278a2ff0d7c32c25edd71eaa in activemq's branch refs/heads/master from [~cshannon]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=cc6213e ]

https://issues.apache.org/jira/browse/AMQ-5712

Switching addMessageLast to tryAddMessageLast when messages are added
to a Queue pending cursor to allow a potential deadlock to be
avoided. There is more work to be done here but this will at least
prevent a deadlock from occurring.

Fix and test based off of a patch created by Timothy Bish.
, This has been fixed by applying the patch submitted here.  I have created a new ticket to track progress for a better solution in the future AMQ-6056]