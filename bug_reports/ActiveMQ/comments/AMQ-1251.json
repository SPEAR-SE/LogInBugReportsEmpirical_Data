[This issue now occurs on a very slow and busy machine after consumer gets a dozen of messages it stops getting others., Can you explain how this issue is resolved?  I see this issue still occurring with a svn checkout of trunk from yesterday (revision number 568479).  From what I can see, RoundRobinDispatchPolicy hasn't been changed as recommended by the author of this bug.

Was there any code committed to fix this bug?  If so, what was it?

I see exactly the same issue - after a while in my application, the consumers stop consuming messages, and I can confirm via JMX there are a couple of messages left in a persistent queue.  When I start up a new process which is a consumer for this queue, it immediately gets these messages, and the older consumers never receive any more, despite having subscriptions to the queue (as confirmed by JMX).

, As noted by my previous comment - I still see this issue occurring, so I am re-opening this bug.
, David, 

You may be having a different issue though. If you have idle consumers some messages can be stack in the pre-fetch buffer. You can check this out by setting pre-fetch buffer to 0 for all consumer connections, but keep in mind that it does not work with asynchronous MessageListener interface. You have to call recieve*(*) methods for it to work. 

Pre-fetch buffer is on the client / consumer JVM. Messages are pushed to the consumer until the buffer size is not exceeded. This is a performance solution, so if you are not getting 1000 msgs/sec you can pull messages from the queue with prefetchSize = 0.

To set prefetch size you can use this code or google amq site to figure out how to set it in connection URL.

            ActiveMQConnectionFactory cf = new ActiveMQConnectionFactory(user, password, url);
            cf.setPrefetchPolicy(getPrefetchPolicy());


Regards., Hi Vadim,

I can't use the receive call, since my application uses the async MessageListener interface.  I posted on the activemq-user mailing list more detail on my application, with a unit test which demonstrates the issue.  http://www.nabble.com/Large-PendingQueueSize-values-for-subscriptions-on-a-queue-with-one-message-tf4316080s2354.html.

I've attached a unit test which demonstrates the problem.  I tried to make the code as small as possible.

In this situation, the issue (program hangs) seems to happen when QUEUE_PREFETCH_SIZE == 1 and NUM_WORKERS = 2 (90% of the time).
Changing NUM_WORKERS to 1 seems to make it work.

Increasing the QUEUE_PREFETCH_SIZE also seems to make things work.

, Example unit test which demonstrates the issue.
, this seems fixed - svn  revision 571150.
, Thanks for that Rob, I'll try out the latest code soon.

Following Vadim's advice, I restructured my application to use synchronous receives, and setting prefetchSize = 0 prevented the issue from occurring.  Setting it to a value of 1 or more in my application causes the issues of messages not being delivered.

When I get some time soon, I'll update my activemq and let you know if your changes have indeed fixed the problems I am seeing for other prefetch sizes.


, Hi Rob,

I updated my activemq to 572492, but the problem still occurs when I run the unit test.  Not every time, but it still happens, around 75% of the time on the machine I am using.

Can you not reproduce this on your end?
, Similar unit test to TestActiveMQ, except it has been rewritten to use synchronous receives, which is how my main application works now.

I still get the unit test hanging about 50% of the time when the number of worker threads is 2 or more, and interestingly when the prefetch size is 0.  If the prefetch is set to 1 or more, then the program _seems_ to work.

Whatever the problem is, both with this test and the previous one, there is some sort of race condition, since the program doesn't always hang.

Whenever the program hangs, it seems the PendingQueueSize values for the queue subscriptions are very large, in fact when I add the values up from all worker queue subscriptions, it seems to equal the total number of messages which have been sent to the queue.

When the program works, as expected, the PendingQueueSize on the subscriptions is 0.

Any ideas what is wrong?  This is with checkout 572492 and built using mvn -Dmaven.test.skip=true clean install.

, To add a bit more potentially relevant information, I am running these unit tests under Vista, JDK 1.6.0_02 on a duo core machine.  Perhaps the fact it is running on duo core means it is exposing a race condition that may not be as easy to reproduce on a single core machine.

, In case it is hard for you to reproduce, here are the relevant statistics obtained using JMX when the unit test hangs after the first batch of 1000 messages are processed:

For the work-items queue (which has two worker thread consumers):

ConsumerCount: 2
DequeueCount: 1000
DispatchCount: 1000
EnqueueCount: 1001

This makes sense - the 1001 enqueue count indicates the message the master has sent to the work-items queue to indicate to the workers to start processing the second batch of 1000 items, but for whatever reason, this message hasn't been dispatched to a worker.

For the two worker subscriptions on this queue, here are their stats:

Worker 1:

DequeueCounter: 998
DispatchedCounter: 998
DispatchedQueueSize: 0
EnqueueCounter: 1001
MaximumPendingMessageLimit: 0
PendingQueueSize: 3
PrefetchSize: 0

Worker 2:

DequeueCounter: 2
DispatchedCounter: 2
DispatchedQueueSize: 0
EnqueueCounter: 1001
MaximumPendingMessageLimit: 0
PendingQueueSize: 998
PrefetchSize: 0

I can also confirm that all 3 threads (two workers, one master) and waiting in receive(), by dumping the thread stacks:

at org.apache.activemq.MessageDispatchChannel.dequeue(MessageDispatchChannel.java:75)
-locked <0x199c50d8> (a java.lang.Object)
at org.apache.activemq.ActiveMQMessageConsumer.dequeue(ActiveMQMessageConsumer.java:405)
at org.apache.activemq.ActiveMQMessageConsumer.receive(ActiveMQMessageConsumer.java:453)

Looking at the numbers, it really looks like a new message has been put into the queue, but hasn't been dispatched.

Is there any more information you need apart from the above and the unit tests provided to squash this issue?


, Attaching a version of the test case that does not seem to fail.  All I did was avoid some of the synchronization contention that the test case had by avoiding those big sychronization blocks., Hiram - thanks for your comment.  Your unit test confirms that what we are dealing with here is a race condition in the activemq code, somewhere.  Although the original unit tests do have excessive synchronization, it is not invalid code from what I can tell, and it should complete to the end.

I started to have a little look at the activemq code under a debugger, and noticed the case when both workers are stuck, is when they have non-empty pending queues where all message references have dropped is true.  When the dispatcher sends the next message from the master, it is just added to both pending queues for the worker, and according to the logic I saw, it wasn't immediately dispatched since the pending queue was not empty.

I tried pressing the gc() operation on various objects from JMX, but it didn't seem to clear out any of the messages.

At this stage - nothing seems to happen, the pending queues stay non-empty, and the new message is never delivered., actually I spoke too soon.I ran it a few more times and it got stuck again.

but I think I have cornnered the cause of the problem and should have a fix soon., Hi David,

I think the issue is now resolved in the trunk version of activemq as of revision 573400.  If you get a chance could you double check it for me?? 

/Regards,
Hiram, Hi Hiram,

Many thanks for fixing this issue - all my unit tests now work, and my application runs far further than it used to - I suspect these problems are mine now :).

I am curious though, your change to VMPendingMessageCursor makes sense in that isEmpty() need to ignore dropped messages.  Do we not need to make a similar change for other implementations of PendingMessageCursor, such as FilePendingMessageCursor and StoreQueueCursor?

Cheers,
David
, Hi Hiram,

Incidentally, https://issues.apache.org/activemq/browse/AMQ-1333 I believe was created as a clone of this bug, so that any fixes could be applied to the 4.1.X release.  Can/should your changes be applied to 4.1.X as well?

Cheers,
David
, Hi all, 

I have tried revision 574216 of activemq trunk. I'm still having a problem when I set the queue prefetch size to 1, when using a pure master slave configuration. Here what I have done:
1. Start two brokers, one master, one slave (with shutdownIfMasterFailure set to false).
2. Start one consumer (with prefetch set to 1), and with sleeptime = 5000 millisecond
3. Start one producer (for example: 10 durable messages)
4. After the consumer have consumed 1 or 2 messages, kill the master
5. The consumer will eat only one message from the slave (and they are more message in the queue).

If the prefetch is not set, then the in step 5, the consumer will eat all the remaining messages.
, Hi Hiram,

I have found an issue with your change I believe.  While running my code, I received the following exception:

[ActiveMQ Task] 881755 ERROR org.apache.activemq.broker.region.Queue.worker-items - Failed to page in more queue messages 
java.lang.RuntimeException: not implemented
	at org.apache.activemq.broker.region.NullMessageReference.isDropped(NullMessageReference.java:47)
	at org.apache.activemq.broker.region.cursors.VMPendingMessageCursor.isEmpty(VMPendingMessageCursor.java:43)
	at org.apache.activemq.broker.region.PrefetchSubscription.add(PrefetchSubscription.java:119)
	at org.apache.activemq.broker.region.policy.RoundRobinDispatchPolicy.dispatch(RoundRobinDispatchPolicy.java:70)
	at org.apache.activemq.broker.region.Queue.doDispatch(Queue.java:1054)
	at org.apache.activemq.broker.region.Queue.pageInMessages(Queue.java:1069)
	at org.apache.activemq.broker.region.Queue.iterate(Queue.java:940)
	at org.apache.activemq.thread.PooledTaskRunner.runTask(PooledTaskRunner.java:118)
	at org.apache.activemq.thread.PooledTaskRunner$1.run(PooledTaskRunner.java:42)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

I can't look at the code where I am writing this from, but is this something easy to fix?  Thanks.

Cheers,
David
, David,

worked around that issue with the Runtime Exception

cheers,

Rob, Hi Rob,

Thanks - I can confirm that I no longer see the following messages:

"java.lang.RuntimeException: not implemented
at org.apache.activemq.broker.region.NullMessageReference.isDropped(NullMessageReference.java:47)"

Now I would mark this issue as resolved from my perspective, except I hadn't heard back from Hiram about one of my previous comments above:

> Hi Hiram,
> 
> Many thanks for fixing this issue - all my unit tests now work, and my application runs far further than it used to - I suspect these problems are mine now .
>
> I am curious though, your change to VMPendingMessageCursor makes sense in that isEmpty() need to ignore dropped messages. Do we not need to make a similar 
> change for other implementations of PendingMessageCursor, such as FilePendingMessageCursor and StoreQueueCursor?
>
> Cheers,
> David, It makes sense to update FilePendingMessageCursor.isEmpty() logic to check that nodes haven't been dropped from the in memory list it holds.
However, the disk part of the list - or the StoreQueueCursor will not hold the same instance as used by the Queue - and persisted references aren't updated., Update FilePendingMessageCursor.isEmpty() method to check for dropped message references in its in-memory list
svn revision: 585853]