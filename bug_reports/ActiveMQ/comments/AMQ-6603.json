[Reproducer {{spring-amq-client.zip}} attached.

To reproduce the issue:

# Create broker {{sample-broker}}, apply the configurations: {{activemq.xml}}, {{users.properties}}, {{groups.properties}} and run it.
# Run this project:
{quote}
$ mvn spring-boot:run
{quote}
# Change {{groups.properties}} to make user {{test}} belong to {{users}} instead of {{guests}} and restart the broker (while keep the reproducer project running):
{quote}
admins=admin
users=test
#guests=test
{quote}
# Check the number of consumers connecting to queue {{TEST}}. , I think the issue is with your configuration.  It usually doesn't make sense to use a connection pool with a DefaultMessageLIstenerContainer because you want to let the DefaultMessageListenerContainer do its own caching.  If you just pass a normal connection factory to the DefaultMessageListenerContainer then it should just create 1 connection and 10 consumers.

From the Spring docs:

"Note: Don't use Spring's CachingConnectionFactory in combination with dynamic scaling. Ideally, don't use it with a message listener container at all, since it is generally preferable to let the listener container itself handle appropriate caching within its lifecycle. Also, stopping and restarting a listener container will only work with an independent, locally cached Connection - not with an externally cached one.", Also you said you could reproduce it without using Spring DMLC.  What was your setup in that case?  Something needs to be detecting the failed consumer/connections and trying to create new ones on ACL change., Hi [~cshannon],

Thank you for your comments, and sorry for my late response.

{quote}
I think the issue is with your configuration. It usually doesn't make sense to use a connection pool with a DefaultMessageLIstenerContainer because you want to let the DefaultMessageListenerContainer do its own caching.
{quote}

I can see your point, but one itchy situation about it is that Apache Camel has long been promoting the combination of {{PooledConnectionFactory}} + DMLC as the best practice ({{camel-jms}} is effectively just a DMLC inside).
http://camel.apache.org/activemq.html#ActiveMQ-Usingconnectionpooling

We could say that Apache Camel has been wrong on this, but please note that the issue happens only when a {{failover:\(...)}} broker URL is used with {{ActiveMQConnectionFactory}} and for a plain {{tcp://...}} URL we see no issues even with the above combination. That's why I think there might be something that can be improved in ActiveMQ side (especially between {{PooledConnectionFactory}} and Failover transport).

Or we could instead argue that the specific combination of Failover transport + PooledConnectionFactory + DMLC is evil; in this case, what do you think would be the correct configuration if users need to use Failover transport?

{quote}
If you just pass a normal connection factory to the DefaultMessageListenerContainer then it should just create 1 connection and 10 consumers.
{quote}

Yes, but then doesn't the number of connection instances grow proportionately to the number of DMLC instances used?  I think that's why people want to use {{PooledConnectionFactory}} in combination with DMLC (or {{camel-jms}}).

{quote}
Also you said you could reproduce it without using Spring DMLC. What was your setup in that case? 
{quote}

Attached {{pooled-amq-client.zip}} is a reproducer that doesn't use DMLC. I admit it's rather a contrived example and mostly just mimics what's being done inside DMLC, but it still reproduces the issue with only ActiveMQ., Right, if you really want to share connections across multiple DMLCs then you'd still need a pooled factory.  I wouldn't say using failover + pooled factory + DMLC is necessarily evil...just that there's a lot going on there that could cause problems and it would simply things if you didn't use a pooled connection factory (such as if you were only a small number of DMLCs) unless you really need it.  And yes Spring doesn't really recommend doing it that way so if you can get away with creating 1 connection per DMLC then that is usually the way to go.

The use case should still work however and there is probably some improvement here that needs to be done in order to properly handle the failover case in this set up so that an excessive number of consumers don't get created., I think there is something in this. The consumer creation failing with an exception is not being tracked by the failover transport and when it reconnects, b/c the session is still present b/c it was pooled, it gets recreated along with the failed consumer.
The connection state tracker needs to respond to the failure to create the consumer such that it is not recreated on reconnect. I think.
Will see if I can validate with that test code and peek at a possible fix., Creation of MessageProducer would likely also suffer from this issue as it can also fail for security exceptions when access control prevents writes.  , Commit 8641928553e0f1d97416fd010c2f7d6f165b3660 in activemq's branch refs/heads/master from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=8641928 ]

[AMQ-6603] ensure failover does not track consumer creation that fails with an exception, fix and test. Thanks for the test Tadayoshi Sato
, [~tabish121] need to check if producers are cached by the pool but yep, would have the same problem. may be able to make the logic to deal with exceptions more generic.
as as workaround for both, is it possible to have the connection pool not cache sessions in wonder?, You can't currently cache sessions, and it'd probably be way more trouble than it's worth.  I believe there's two options for the producers in the pool, one cached anonymous producer or a cached producer for each destination that a producer is requested for.  , Commit 90b808ab98b760f06885a5f45628353c9d2224f2 in activemq's branch refs/heads/master from [~tabish121]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=90b808a ]

AMQ-6603 Stop tracking producer if creation failed

Track the message producer create and ensure it is not recreated on
failover if the creation resulted in an error response.  Add failover
level tests to cover consumer and producer failed create tracking., Commit 5a52bf2a51909bcb2b4a7e5301e4bddf5aadb0c4 in activemq's branch refs/heads/activemq-5.14.x from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=5a52bf2 ]

[AMQ-6603] ensure failover does not track consumer creation that fails with an exception, fix and test. Thanks for the test Tadayoshi Sato

(cherry picked from commit 8641928553e0f1d97416fd010c2f7d6f165b3660)
, Commit 4c5a70421c2ed39d0faeb78593728ac170812343 in activemq's branch refs/heads/activemq-5.14.x from [~tabish121]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=4c5a704 ]

AMQ-6603 Stop tracking producer if creation failed

Track the message producer create and ensure it is not recreated on
failover if the creation resulted in an error response.  Add failover
level tests to cover consumer and producer failed create tracking.
(cherry picked from commit 90b808ab98b760f06885a5f45628353c9d2224f2)
, Thanks for the follow up [~tabish121] :-), Commit eab9a0d05758fd0e8e83e7e482f4f0406cd9af5e in activemq's branch refs/heads/master from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=eab9a0d ]

[AMQ-6603] pull unnecessary guava dep from the new test
, Commit 2dfe0c7c291b5e1beca7ab80d6eea8639f070d6f in activemq's branch refs/heads/activemq-5.14.x from [~gtully]
[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=2dfe0c7 ]

[AMQ-6603] pull unnecessary guava dep from the new test

(cherry picked from commit eab9a0d05758fd0e8e83e7e482f4f0406cd9af5e)
]