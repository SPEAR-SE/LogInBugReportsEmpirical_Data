[Doesn't the logic described here imply that we're almost never going to be able to delete data files that follow the first unconsumed message?  Won't it usually be true that there's at least one ack in file N+1 of a message in file N, for all values of N, so file N+1 will always need to stick around for as long as N does?, This is an adjustment test for AMQ2832Test.java which fails currently on trunk, 5.10.1, and 5.10.0.
The adjustment is relative to the trunk version of AMQ2832Test.java.
, This is the possible patch.
Just removed the copy of gcCandidateSet. It is unclear to me what was the purpose of this copy., The consequence of the fix is that if you are really unlucky you will get all files blocked beginning from the one with unconsumed message/messages through all next files containing acks pointing to the files before them.
So having some unconsumed messages for a long term (like messages in a DLQ) in such an unlucky case will eat quite a lot of space., AMQ-2736 actually introduced the problem. See the comment of Gary https://issues.apache.org/jira/browse/AMQ-2736#comment-12942986.
It was thought to be a logical error, but it was not. It is not possible just to drop the files, when they contain acks pointing to other files, which are blocked., Tim, I think, you are right. Otherwise KahaDB will loose acks and replay messages.
If this is true, than the current cleanup mechanism have to be reconsidered. It will not work well for scenarios, where messages may stay unconsumed for some time. Some sort of compaction has to be done.
In the current project we have nearly always some messages in DLQs sitting there for maximum 2 days. This means that we would always have nearly all data files for the last two days.
Currently it is ok, we have enough of place on the SAN. But what if that would be 2 weeks instead of 2 days?
I think in this case we would use JDBC storage.
Another possibility would be to use mKahaDB and put DLQs to a separate storage. That storage would not grow fast since there would not be much traffic., mKahaDB is the current answer to the need for compaction/rewrite problem. that is why it emerged. Partition based on the average length of time a message spends in a queue., To Tim's point -- if there is *any* content in the data file that means it is needed, then the file must not be removed.  That problem exists even for messages - one, small message can hold an entire data file.

Therefore, if there is an acknowledgement in the data file that still needs to be processed, the data file must not be removed.

As Gary mentioned, multi-kahadb can be used to better prevent the scenario of large holes in data files.

Keep in mind - it's in the JMS specification that consumers are expected to be "timely" (I forget the exact wording).  ActiveMQ (and other JMS solutions) are not "message stores" - using them as such leads to many issues.  If messages need to be stored for a length of time, I generally recommend adding a store to the architecture and moving those messages out of ActiveMQ and into the store as-needed.

With that said, a solution to the compaction problem would be quite welcome., Consumers can be timely but unsuccessful, leading to messages going to the DLQ, where they can cause exactly this kind of behavior.  So as ActiveMQ is currently implemented the expectation Art referenced (that consumers be timely) needs to be applied to the DLQ as well, which isn't how I'd expect to need to interact with a DLQ.  I would assume that I could come in the next morning, see that there were messages in the DLQ that failed for some reason, and decide what to do about them.  But even if we simply fix this bug by not deleting the KahaDB files that are still needed (potentially all of them), then the consequence of that is going to be potentially large KahaDB disk usage for just a few messages, which I think most developers/admins won't be expecting.

The way I just described interacting with the DLQ does in fact use it as a message store, and I think that's a valid use case.

I think that fixing this specific bug is better than not (high disk usage is better than invalid message redelivery, IMO), but I think another solution (which could be mKahaDB, or something else such as having a separate KahaDB for the DLQ) is still needed (in a separate JIRA enhancement).  I submitted AMQ-5547 to capture that need., This is correct. This is what we have in production. We have some messages in DLQs. They stay there for max 2 days. After that a special job removes messages older than 2 days from the DLQs.
Now we expect that ActiveMQ will always retain nearly all data files for the last two days because of those messages in the DLQs. So this would take quite a lot of space I think and we did not expect that when we set up the servers - may be we will have to get a larger SAN volume for that.

Another consideration is that this is not only the space which will be eaten by KahaDB but also the time ActiveMQ needs to recover after the crash. ActiveMQ will need quite a lot of time to replay all the data files which are sitting there just because of several DLQ messages.
And the periodic cleanup may take more time to check all the data files (and KahaDB cleanup is a single threaded storage blocking operation)., One option to work around this problem might be to have a job that periodically consumes all DLQ messages and re-sends them to the DLQ as a new message.  That way the dead messages are always near the newest messages in KahaDB and it can delete the old files.  You'll lose metadata about when the original message was sent/received/etc., but that may be better than what you have now.  (And you could always wrap the original message, with all its metadata, in a wrapper message if you wanted to keep that info.)  This should still get fixed and the improvement I submitted should still get implemented, but that workaround might get you by until the improvement gets implemented., DLQs are a common cause of this problem.  My recommendation when using DLQs is *always* have a plan for handling them and consume them in a timely manner.

Again, if the messages need to be stored for a period of time (like 2 days), the best approach is to get them out of ActiveMQ and put them in some type of message store.  Another consideration of this use-case: keeping the messages for this period means some manual action is expected.  ActiveMQ is not designed to give "random access" to messages, which would typically be needed for manual intervention, but instead to produce and consume as a queue.  This use-case would be better served with a database in which individual messages could be referenced.

Regardless, this is how ActiveMQ currently functions.  Until something better is implemented, these data files must not be deleted until they are no longer used., i will review and try and recall the need for the copy. great find. patch with test case is always much appreciated :-), test and fix applied (reverted the change from AMQ-2736) with thanks. all tests look good. The copy looks plain wrong to me.]