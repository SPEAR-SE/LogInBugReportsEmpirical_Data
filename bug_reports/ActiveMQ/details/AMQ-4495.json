{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12645235","self":"https://issues.apache.org/jira/rest/api/2/issue/12645235","key":"AMQ-4495","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12311210","id":"12311210","key":"AMQ","name":"ActiveMQ","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12311210&avatarId=10011","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12311210&avatarId=10011","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12311210&avatarId=10011","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12311210&avatarId=10011"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/11160","id":"11160","description":"ActiveMQ","name":"ActiveMQ"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323932","id":"12323932","name":"5.9.0","archived":false,"released":true,"releaseDate":"2013-10-21"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2013-05-02T06:54:16.537+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Mar 08 17:30:27 UTC 2016","customfield_12310420":"325597","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_349847402_*|*_4_*:*_1_*:*_681343072_*|*_5_*:*_2_*:*_89170741961","customfield_12312321":null,"resolutiondate":"2016-03-08T13:49:53.436+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/AMQ-4495/watchers","watchCount":6,"isWatching":false},"created":"2013-04-29T13:44:21.068+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-03-08T17:30:27.432+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"customfield_12310080":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10091","value":"Regression","id":"10091"}],"description":"As currently stands, the store queue cursor will cache producer messages until it gets to the 70% (high watermark) of its usage. After that caching stops and messages goes only in store. When consumers comes, messages get dispatched to it, but memory isn't released until they are acked. The problem is with the use case where producer flow control is off and we have a prefetch large enough to get all our messages from the cache. Then, basically the cursor gets empty and as message acks release memory one by one, we go to the store and try to batch one message at the time. You can guess that things start to be really slow at that point. \n\nThe solution for this scenario is to wait with batching until we have more space so that store access is optimized. We can do this by adding a new limit (smaller then the high watermark) which will be used as the limit after which we start filling cursor from the store again.\n\nAll this led us to the following questions:\n\n1. Why do we use 70% as the limit (instead of 100%) when we stop caching producer messages?\n\n2. Would a solution that stop caching producer messages at 100% of usage and then start batching messages from the store when usage drops below high watermark value be enough. Of course, high watermark would be configurable, but 100% by default so we don't alter any behavior for regular use cases.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12582066","id":"12582066","filename":"FasterDispatchTest.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2013-05-07T09:25:20.619+0000","size":3538,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12582066/FasterDispatchTest.java"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310041":null,"customfield_12310921":null,"customfield_12310920":"325942","customfield_12312823":null,"summary":"Improve cursor memory management","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dejanb","name":"dejanb","key":"dejanb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dejan Bosanac","active":true,"timeZone":"Europe/Berlin"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dejanb","name":"dejanb","key":"dejanb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dejan Bosanac","active":true,"timeZone":"Europe/Berlin"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/13647354","id":"13647354","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"body":"Before we can enjoy the improvement,is the optimization acknowledge option for consumers able to rescue the poor performance b/w of loading messages one by one from the store?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2013-05-02T06:54:16.537+0000","updated":"2013-05-02T06:54:16.537+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/13647381","id":"13647381","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dejanb","name":"dejanb","key":"dejanb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dejan Bosanac","active":true,"timeZone":"Europe/Berlin"},"body":"Unfortunately not, as memory is released one message at the time even in that case (which triggers new store batch and basically just load one message)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dejanb","name":"dejanb","key":"dejanb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dejan Bosanac","active":true,"timeZone":"Europe/Berlin"},"created":"2013-05-02T08:26:32.449+0000","updated":"2013-05-02T08:26:32.449+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/13647471","id":"13647471","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"body":"allowing a batch load from the store to exceed the memory limit may be the simplest approach. The batch size is already configurable so the excess is controllable. In essence, once we go to the store we always load a full batch if we can so we don't check the usage on each message recovery.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-02T12:34:50.840+0000","updated":"2013-05-02T12:34:50.840+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/13648476","id":"13648476","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dejanb","name":"dejanb","key":"dejanb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dejan Bosanac","active":true,"timeZone":"Europe/Berlin"},"body":"Fixed with svn revision 1478823\n\nThe solution Gary mentioned has been implemented, basically allowing us to exceed a memory limit a bit for the more optimal store reads.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dejanb","name":"dejanb","key":"dejanb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dejan Bosanac","active":true,"timeZone":"Europe/Berlin"},"created":"2013-05-03T14:55:08.462+0000","updated":"2013-05-03T14:55:08.462+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/13650655","id":"13650655","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"body":"there is only 2% performance improvement in my observation.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2013-05-07T09:25:20.622+0000","updated":"2013-05-07T09:25:20.622+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/13650656","id":"13650656","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"body":"I have tried to add a testcase to verify the improvement, but I can only see a little effect.\nIt would be better you can take a look at the testcase and give it a try to see the effect.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2013-05-07T09:25:44.580+0000","updated":"2013-05-07T09:25:44.580+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/13651765","id":"13651765","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"body":"More concurrence tests indicate load on the database server decreases noticeably than the original design when the memory usage of queues is exhausted.\nSeems we can not see the dispatch speed increases while the load of the store server is lower than before.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangyin","name":"wangyin","key":"wangyin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"SuoNayi","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2013-05-08T10:27:30.220+0000","updated":"2013-05-08T10:27:30.220+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15172095","id":"15172095","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"body":"There is a problem with this change. Going past the highWaterMark can have a negative influence on other consumers and destinations leading to the inability to page messages for dispatch.\nThis is a general problem for a shared limit but it is made worse with this fix.\nConsider destinations that has stopped caching at 70% usage, so that\nflow control does not kick in and producers can send directly to disk.\nIf the cache is less than the pageSize this is particularly problematic.\nAs messages page in, the usage goes past 100% and now producers will be flow controlled, rather than still going directly to disk. That is not what we want.\n\nI am thinking that paging in for dispatch should respect the highWaterMark, so it is not safe to just \"always page in a full page\"","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"created":"2016-02-29T16:34:10.261+0000","updated":"2016-02-29T16:34:10.261+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15173654","id":"15173654","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira-bot","name":"jira-bot","key":"jira-bot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF subversion and git services","active":true,"timeZone":"Etc/UTC"},"body":"Commit d8cf54b0a9eee4b86db1ffef2cb3dd1171067307 in activemq's branch refs/heads/master from [~gtully]\n[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=d8cf54b ]\n\nhttps://issues.apache.org/jira/browse/AMQ-4495 - revisit. Reinstate check for space on pagein, so that highWaterMark is respected and full state is not reached, hense pfc is not triggered in error\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira-bot","name":"jira-bot","key":"jira-bot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF subversion and git services","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-01T11:55:24.018+0000","updated":"2016-03-01T11:55:24.018+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15173744","id":"15173744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cshannon","name":"cshannon","key":"christopher.l.shannon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=christopher.l.shannon&avatarId=24614","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=christopher.l.shannon&avatarId=24614","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=christopher.l.shannon&avatarId=24614","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=christopher.l.shannon&avatarId=24614"},"displayName":"Christopher L. Shannon","active":true,"timeZone":"America/New_York"},"body":"[~gtully],\n\nTwo questions/comments,\n\nFirst, with this new commit, I assume that means there will be reduced performance again? Some of the brokers I've run are on machines with relatively slow disk performance so that is a potential concern.\n\nSecond, do you think your new change might reduce potential OOM errors?  I've seen out of memory problems occasionally even though proper usage limits are set and I've always thought that maybe that had something to do with the fact that paging in on dispatch could load more than 100% of the usage into memory.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cshannon","name":"cshannon","key":"christopher.l.shannon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=christopher.l.shannon&avatarId=24614","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=christopher.l.shannon&avatarId=24614","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=christopher.l.shannon&avatarId=24614","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=christopher.l.shannon&avatarId=24614"},"displayName":"Christopher L. Shannon","active":true,"timeZone":"America/New_York"},"created":"2016-03-01T13:25:24.206+0000","updated":"2016-03-01T13:25:24.206+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15173767","id":"15173767","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"body":"[~cshannon] yes to both.\n\nIt was oom that brought me back, then i saw the producer flow control (pfc) use case and was convinced.\n\nThe original perf issue is a case where a consumer takes a page and as the acks come back, the page is empty so we go to the store, take in one message (as we again hit our limit (b/c the prefetched messages are not acked yet) and dispatch it. Then repeat.\n\nI think the pref issue can be addressed with some taking account of the prefetch, but it may be tricky.\n\nI am now thinking that we need a high and low water mark. using the low for caching on the producer side, and using the high for page in. That is sort of what we have with the high and full mark at the moment. so maybe there is no need to change much.\nhowever the full trigger is what causes pfc to kick in so it is not isolated.\nThinking now, the pfc check could be conditional on the cursor caching messages. That may separate the concerns some which would help simplify.\nNeed to investigate that a bit. Thanks for your eyes on this, it is a tricky area, dispatch on memory limits. Not sure there is a perfect answer but I think it can be improved.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-01T13:42:26.531+0000","updated":"2016-03-01T13:42:26.531+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15173781","id":"15173781","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"body":"The second use case here is starvation, simplest when there is a shared memory limit, so just a broker usage limit.\nSend to q1, it stops caching at < 70%. Send to q2, it stops caching immediately, same for q3.\nConsume from q2, you get to page in some messages, brings you possibly > 70%, consume from q3, you get nothing, till q2 or q1 gets some acks.\n\nThis is all expected, but with the usage based on %, and varying message size it is very random.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-01T13:54:53.875+0000","updated":"2016-03-01T13:54:53.875+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15183230","id":"15183230","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira-bot","name":"jira-bot","key":"jira-bot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF subversion and git services","active":true,"timeZone":"Etc/UTC"},"body":"Commit 13ec9949397848c57653845b35e8003f8c490ebd in activemq's branch refs/heads/master from [~gtully]\n[ https://git-wip-us.apache.org/repos/asf?p=activemq.git;h=13ec994 ]\n\nRevert \"https://issues.apache.org/jira/browse/AMQ-4495 - revisit. Reinstate check for space on pagein, so that highWaterMark is respected and full state is not reached, hense pfc is not triggered in error\"\n\nThis reverts commit d8cf54b0a9eee4b86db1ffef2cb3dd1171067307.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira-bot","name":"jira-bot","key":"jira-bot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF subversion and git services","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-07T16:35:51.712+0000","updated":"2016-03-07T16:35:51.712+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15183267","id":"15183267","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"body":"I have not found a straight forward way to deal with performance issue so I am reverting. Going to tackle the flow control issue on it own.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-07T17:01:11.795+0000","updated":"2016-03-07T17:01:11.795+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15184926","id":"15184926","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"body":"On review - i have retained the status quo. The performance implications of going to the store for a batch (page) of messages and dropping them due to no space is too high.\n\nUsing a destination limit of X, and a cursorHighWaterMark of 70, only if usage is < 0.7*X will we page in from the store. If we page In, it will be a pageSize and we will accept the full page if a full page of messages exists. This may cause usage to increase past X. However we won't go back to page in till usage is again < 0.7*X.\nThe 0.7 is the cursorHighWaterMark and X is the memoryUsage (via policy entries). PageSize is also configurable.\n\nIf per destinations limits are not set, then the global shared usage is available to all destinations which can lead to starvation of consumers due to the inability to page in because usage > 0.7*X due to messages in memory for other destinations. Their consumers may have dropped off for example.\n\nTo divide a shared usage between N destinations:\n 0.7*X will be used for caching if the cache is enabled (useCache=true). \nThen be prepared for potential increase of pageSize*messageSize usage when we page in from the store for dispatch. This happens when the cache is exhausted and usage drops below 0.7*X. Ideally, the 0.3*X that remains for pageIn is < pageSize*messageSize. \nFor N destinations, the fraction available to each destinations needs to account for the above.\nThis will ensure that the global shared usage is respected so the JVM heap metrics can be sized sensibly.\n\nMitigation:\nlazyDispatch - where we only page in what can be consumed can help limit the pageSize dynamically if consumers are exact about their prefetch limit or use pull consumers. With 3 pull consumers, we will only pageIn 3 messages if lazyDispatch=true","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gtully","name":"gtully","key":"gtully","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gary Tully","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-08T13:49:53.481+0000","updated":"2016-03-08T13:49:53.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15185007","id":"15185007","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tmielke","name":"tmielke","key":"tmielke","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Torsten Mielke","active":true,"timeZone":"Europe/Berlin"},"body":"[~cshannon]\n{quote}\n I've seen out of memory problems occasionally even though proper usage limits are set \n{quote}\n\nThis bug could also be related to what you observed [ENTMQ-1526|https://issues.jboss.org/browse/ENTMQ-1526].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tmielke","name":"tmielke","key":"tmielke","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Torsten Mielke","active":true,"timeZone":"Europe/Berlin"},"created":"2016-03-08T14:55:17.860+0000","updated":"2016-03-08T14:55:17.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12645235/comment/15185312","id":"15185312","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cshannon","name":"cshannon","key":"christopher.l.shannon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=christopher.l.shannon&avatarId=24614","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=christopher.l.shannon&avatarId=24614","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=christopher.l.shannon&avatarId=24614","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=christopher.l.shannon&avatarId=24614"},"displayName":"Christopher L. Shannon","active":true,"timeZone":"America/New_York"},"body":"Yes, this is another issue too. The size computation is currently an approximation as you pointed out in that ticket.  Another thing that helped in the queue case with OOM errors was setting the reduceMemoryFootprint flag to true.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cshannon","name":"cshannon","key":"christopher.l.shannon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=christopher.l.shannon&avatarId=24614","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=christopher.l.shannon&avatarId=24614","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=christopher.l.shannon&avatarId=24614","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=christopher.l.shannon&avatarId=24614"},"displayName":"Christopher L. Shannon","active":true,"timeZone":"America/New_York"},"created":"2016-03-08T17:30:27.432+0000","updated":"2016-03-08T17:30:27.432+0000"}],"maxResults":17,"total":17,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/AMQ-4495/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1k68n:"}}