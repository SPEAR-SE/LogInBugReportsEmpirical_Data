{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12954651","self":"https://issues.apache.org/jira/rest/api/2/issue/12954651","key":"AMQ-6226","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12311210","id":"12311210","key":"AMQ","name":"ActiveMQ","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12311210&avatarId=10011","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12311210&avatarId=10011","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12311210&avatarId=10011","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12311210&avatarId=10011"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/11160","id":"11160","description":"ActiveMQ","name":"ActiveMQ"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-03-30T16:33:16.399+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Mar 30 16:33:16 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/AMQ-6226/watchers","watchCount":2,"isWatching":false},"created":"2016-03-30T14:44:24.823+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["performance"],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315619","id":"12315619","description":"","name":"5.2.0","archived":false,"released":true,"releaseDate":"2008-11-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-03-30T16:33:53.417+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"customfield_12310080":null,"description":"This mailing list thread (http://activemq.2283324.n4.nabble.com/ActiveMQ-with-KahaDB-as-persistent-store-becomes-very-slow-almost-unresponsive-after-creating-large-s-td4709985.html) described awful performance problems when creating large numbers of destinations in parallel, and provided thread dumps that pointed to lots of threads contending for AbstractRegion.destinationsLock.\n\nAbstractRegion has lots of places where we do something like this:\n\n455        destinationsLock.readLock().lock();\n456        try {\n457            dest = destinations.get(destination);\n458        } finally {\n459            destinationsLock.readLock().unlock();\n460        }\n\ndestinations is a ConcurrentHashMap, so it's already thread-safe.  Why are we using a single external lock around a ConcurrentHashMap that would be concurrent if we weren't making it single-locked???\n\nI suspect that the primary goal is to make sure that addDestination() and receiveDestination() don't create or remove the same destination twice, but there are other ways to do that (for example, having the map be ConcurrentHashMap<ActiveMQDestination, AtomicReference<Destination>> and putting the AtomicReference into the map immediately and then later populating the reference once the object is constructed).\n\nWe need to eliminate this singleton lock and use the thread-safe ConcurrentHashMap's own locking, possibly coupled with thread-safe objects (AtomicReference, etc.) and/or explicit per-key locking, to implement the same algorithm in a way that allows reasonable parallelism under heavy load.\n\nNOTE: This might also help eliminate AMQ-5901.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310041":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Eliminate AbstractRegion.destinationsLock","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tbain98","name":"tbain98","key":"tbain98","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Bain","active":true,"timeZone":"America/Denver"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tbain98","name":"tbain98","key":"tbain98","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Bain","active":true,"timeZone":"America/Denver"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12954651/comment/15218268","id":"15218268","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cshannon","name":"cshannon","key":"christopher.l.shannon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=christopher.l.shannon&avatarId=24614","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=christopher.l.shannon&avatarId=24614","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=christopher.l.shannon&avatarId=24614","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=christopher.l.shannon&avatarId=24614"},"displayName":"Christopher L. Shannon","active":true,"timeZone":"America/New_York"},"body":"This is worth looking at but would need some investigation to see what side effects there might be.  I know the lock is used for iterating and also to synchronize across the destinationMap (which is not a concurrent hash map).  I am also not sure how much removing that lock will help with contention without truly understanding the cause of the slowness.  While there are threads waiting on that lock, if you remove the lock you could just push the contention down stream.  For example, if the reason that lots of threads are waiting on the destinations lock is because some threads are being slow to write to disk then it's possible removing this lock wouldn't help much because those threads would now just be waiting on the locks in the message store instead.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cshannon","name":"cshannon","key":"christopher.l.shannon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=christopher.l.shannon&avatarId=24614","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=christopher.l.shannon&avatarId=24614","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=christopher.l.shannon&avatarId=24614","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=christopher.l.shannon&avatarId=24614"},"displayName":"Christopher L. Shannon","active":true,"timeZone":"America/New_York"},"created":"2016-03-30T16:33:16.399+0000","updated":"2016-03-30T16:33:53.411+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/AMQ-6226/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2velr:"}}