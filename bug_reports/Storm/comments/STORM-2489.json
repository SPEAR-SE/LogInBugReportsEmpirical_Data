[[~wangkui] thanks for reporting the issue. Processing-time based windows internally uses a ScheduledExecutor. It maybe that the tasks are not triggered exactly after the tumbling window interval causing some overlap. To debug further, can you also print the window end timestamp (https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/windowing/Window.java#L55) each time the execute is invoked? "getEndTimestamp" returns the reference processing time which is used to calculate the window boundaries.

You will need build storm from the latest master and run your examples against that since "getEndTimestamp" is not available in any of the released versions of storm., [~arunmahadevan] Sorry for late response, call on getStartTimestamp() and getEndTimestamp(), I got following log:
Timestamp_start-end=1493089795102-1493089800102
expired=1...56
get=57...4085
new=57...4085
Recived=4029,RecivedTotal=4029
Timestamp_start-end=1493089800101-1493089805101
expired=57...4084
get=4085...8049
new=4086...8049
Recived=3965,RecivedTotal=7994
SendTotal=11705
Timestamp_start-end=1493089805102-1493089810102
expired=4085...8047
get=8048...11705
new=8050...11705
Recived=3658,RecivedTotal=11652
, [~wangkui], posted a potential fix - https://github.com/apache/storm/pull/2090

You might want to try your tests with the patch (you can apply the patch or clone https://github.com/arunmahadevan/storm/tree/STORM-2489), [~arunmahadevan] I tested several times with your patch, now it seems all right, no tuples overlap. Thank you!, [~arunmahadevan] Eh, it still lose data, following is one test result, and you can see that the 15073 is lost:
Timestamp_start-end=1493195565070-1493195570070
expired=
get=1...3757
new=1...3757
Recived=3757,RecivedTotal=3757
Timestamp_start-end=1493195570070-1493195575070
expired=1...3757
get=3758...7579
new=3758...7579
Recived=3822,RecivedTotal=7579
Timestamp_start-end=1493195575070-1493195580070
expired=3758...7579
get=7580...11276
new=7580...11276
Recived=3697,RecivedTotal=11276
Timestamp_start-end=1493195580070-1493195585070
expired=7580...11276
get=11277...15072
new=11277...15072
Recived=3796,RecivedTotal=15072
SendTotal=15162
Timestamp_start-end=1493195585070-1493195590070
expired=11277...15073
get=15074...15162
new=15074...15162
Recived=89,RecivedTotal=15161, [~wangkui] thanks for the update. I made some minor changes to the patch today. If you could pull the latest changes and run your tests a few times will be great. , [~wangkui], I made some minor tweak to process the tuples with some time offset, please pull the current changes and test., [~arunmahadevan] I pull and test again, yes, no tuple lost now. Thanks., [~wangkui], when you get some time can you pull the updated changes and test again ? The earlier approach might have issues if the clock continuously drifts and lead to lost and overlapping tuples. I made some changes to address it., [~arunmahadevan] I test again, as the same arguments as before, it seems all right. But when I make the spout emit more frequently, the ahead tuples are expired, following test I spout data with out sleep() and use Duration(4sec) window bolt, 
Timestamp_start-end=1493271145887-1493271149887
expired=1...291972
get=291973...1189440
new=291973...1189440
Recived=897468,RecivedTotal=897468
13:32:34.470 [pool-45-thread-1] WARN  o.a.s.w.TimeEvictionPolicy - Possible clock drift or long running computation in window; Previous eviction time: 1493271149887, current eviction time: 1493271154469
Timestamp_start-end=1493271150469-1493271154469
expired=291973...1189440
get=1189441...2888803
new=1189441...2888803
Recived=1699363,RecivedTotal=2596831
13:32:39.213 [pool-45-thread-1] WARN  o.a.s.w.TimeEvictionPolicy - Possible clock drift or long running computation in window; Previous eviction time: 1493271154469, current eviction time: 1493271159212
SendTotal=5435440
Timestamp_start-end=1493271155212-1493271159212
expired=1189441...2888803
get=2888804...5069647
new=2888804...5069647
Recived=2180844,RecivedTotal=4777675
13:32:42.311 [pool-45-thread-1] WARN  o.a.s.w.TimeEvictionPolicy - Possible clock drift or long running computation in window; Previous eviction time: 1493271159212, current eviction time: 1493271162310
Timestamp_start-end=1493271158310-1493271162310
expired=2888804...5069647
get=5069648...5435440
new=5069648...5435440
Recived=365793,RecivedTotal=5143468
13:32:45.195 [pool-45-thread-1] WARN  o.a.s.w.TimeEvictionPolicy - Possible clock drift or long running computation in window; Previous eviction time: 1493271162310, current eviction time: 1493271165194
, [~wangkui], the initial tuples expired because the trigger was not fired exactly after the window interval but after a delay. When I tested in local mode with spout emitting without a delay, the trigger happened after 6s (for a 4s tumbling window). This may be because the system is overwhelmed with data and not able to schedule the trigger thread on time. In this case the initial tuples (0 - 2s) will not be considered in the first window. 

Typically the window duration should be such that all the tuples within a window can be processed before the next window trigger, otherwise the next window trigger will be delayed and it will lead to incorrect results. You should use a real cluster with multiple hosts/workers and split the data among these workers to handle such high data rates.

Another option would be to use event time windows where each event contains a "timestamp" field and the window calculations are done based on the actual event time instead of system time., [~arunmahadevan] So that's it, I got, thanks!]