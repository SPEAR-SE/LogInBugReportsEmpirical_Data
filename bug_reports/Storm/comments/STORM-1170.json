[I also met the same problem in CI. I think that is because the producer sometimes cannot finish publishing 1M tuples before TIMEOUT(1000ms). The root cause is that the producer.interrupt() can set the interrupted flag to be true but not really terminate the producer thread. As there is no blocking functions (sleep, wait, join) inside producer's run function, so no InterruptedException will be thrown.

We can solve the issue by checking the interrupted flag inside producer's run function. , GitHub user zhuoliu opened a pull request:

    https://github.com/apache/storm/pull/859

    [STORM-1170] Fix the producer alive issue in DisruptorQueueTest

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/zhuoliu/storm 1170

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/859.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #859
    
----
commit 77aa363ddf9de8a1bd0a11e86ee29c1c283424c2
Author: zhuol <zhuol@yahoo-inc.com>
Date:   2015-11-04T20:24:18Z

    [STORM-1170] Fix the producer alive issue in DisruptoQueueTest

----
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/859#issuecomment-153856336
  
    Looks good to me +1
, Github user kishorvpatil commented on the pull request:

    https://github.com/apache/storm/pull/859#issuecomment-153882993
  
    LGTM. +1.
, Github user jerrypeng commented on the pull request:

    https://github.com/apache/storm/pull/859#issuecomment-154126288
  
    +1 @zhuoliu  thanks for fixing this
, Github user asfgit closed the pull request at:

    https://github.com/apache/storm/pull/859
, Thanks [~zhuoliu],

I merged this into master]