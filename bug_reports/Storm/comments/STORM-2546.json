[Will look at fixing this once https://github.com/apache/storm/pull/2156 has been resolved., Here's my suggestion for a fix, which depends on the changes in https://issues.apache.org/jira/browse/STORM-2549:
The only way to know that a tuple has been deleted from Kafka is to try polling for it. We can know for sure that a failed tuple has been deleted if we seek to the failed tuple's offset (or earlier) on the relevant partition and poll, and we then encounter a tuple that has a higher offset than the failed tuple on that partition earlier in the result set.

For instance:
Offset 0...5 have failed and also been compacted away. Offset 6 has failed and is present, offset 7 has failed and is not present.
We seek to offset 0 for the partition.
If we then see that the first message in the poll result is offset 6, we can be sure that offset 0...5 are deleted, because otherwise they would have been returned in the poll. Offset 7 cannot be removed from the spout because we can't be sure that it was deleted, the consumer may just have received too few messages.

I think we can use this method to remove failed, deleted tuples from the offset manager. When we do a poll, we examine the retriable offsets for each partition. For each partition where we received messages, we compare the earliest received message's offset to the retriable offsets for that partition. If a given retriable offset is lower than the offset of the earliest received message, then the retriable offset must have been deleted. , Consider the following example:
 - Kafka offsets initially emitted  [0..10]
 - Offsets 6 & 7 fail. Other offsets succeed
 - Compaction happens and Kafka broker now has offsets [4,6,10]
 - Let's assume we seek to Offset 0
 - If the _auto.offset.reset_ property is set to 'latest' then poll will return Offset 10
 - If the _auto.offset.reset_ property is set to 'earliest' then poll will return Offset 4

We need to factor in the effect of the _auto.offset.reset_ property in the solution. Will think through this and suggest updates to the solution., I think for compaction support we might be lucky enough to avoid this. I haven't used log compaction, so I may be misunderstanding the documentation, but it's my impression that offsets always stay valid even when compacted away.

The relevant passage from https://kafka.apache.org/documentation/#design_compactionbasics is "The picture above shows a log with a compacted tail. Note that the messages in the tail of the log retain the original offset assigned when they were first writtenâ€”that never changes. Note also that all offsets remain valid positions in the log, even if the message with that offset has been compacted away; in this case this position is indistinguishable from the next highest offset that does appear in the log. "

I'm reading this as we don't need to worry about auto offset reset because for your example 0 remains a valid offset that just translates to 4, so auto.offset.reset isn't triggered.

If the cleanup.policy is delete and not compact, I think your example is right. I don't have a good solution off hand either, so I'm hoping you come up with something :), I thought about it a bit more, and think we can reduce to 6 different situations for cleanup.policy = delete. I don't think we need to support auto offset reset policy being none, since that'll just cause an exception and restart the spout:

* Auto offset reset is latest
** 0 or more acked offsets when reset, no pending retries when reset happens:
Example: 0-3 are acked, 0-1 are deleted. 10 is the latest offset.
Consumer will seek to latest offset (10). When new tuples are acked after the reset, the OffsetManager will skip past all the unemitted tuples (4-9). I don't think we need to do anything special for this case.
** 0 or more acked offsets when reset, earliest pending retry is deleted:
Example: 0-3 are acked, 0-4 are deleted. 4-5 are retriable and 10 is the latest offset.
Consumer will seek to latest offset (10). The spout will handle acks as described in the previous case. When the retriable tuples become ready, the consumer will seek back to the earliest retriable offset (4). Since 4 is deleted, the consumer seeks to latest. Since the spout asked for retriable offset 4 and got 10 as the earliest, it will consider 4-9 deleted and mark them as acked. While offset 5 is technically still possible to retry, I don't think this is necessarily unexpected or bad behavior. I'd be okay with leaving this behavior as is.
** 0 or more acked offsets when reset, earliest pending retry is not deleted:
Example: 0-3 are acked, 0-3 are deleted. 4-5 are retriable and 10 is the latest offset.
Same as above, except when the retriable tuples become ready, the consumer will seek back to the earliest retriable offset (4). The spout continues processing from offset 4. This is a little inconsistent with the case above, but I don't think it's bad behavior, so I'm okay with leaving it like this.

* Auto offset reset is earliest, cleanup policy is delete
** 0 or more acked offsets when reset, no pending retries when reset happens:
Exactly the same as the case for latest, except the consumer seeks to earliest instead.
** 0 or more acked offsets when reset, earliest pending retry is deleted:
Broadly the same as for latest. When the retriable tuples become ready, the consumer will seek back to the earliest retriable offset (4). Since 4 is deleted, the consumer seeks to earliest (5). 5 is skipped initially because it is not ready for retry, and processing picks up at 6. 5 gets retried whenever it becomes ready.
** 0 or more acked offsets when reset, earliest pending retry is not deleted:
Should be the same as the case for latest. The consumer will seek to earliest and poll, receiving offset 4-10. Since 4 and 5 are scheduled for retry and not ready, they will be skipped but left in the retry service until they're ready. Processing starts at 6 and works as normal. This seems fine to me.

For these cases I'd be okay with not doing any more work. The only one that is a little counter intuitive is number 2, but I think when auto offset reset is set to latest, the user should expect that the spout may skip some tuples.

My only worry is what happens if the spout commits offsets that were deleted. The javadoc for KafkaConsumer.commitSync states that it may throw an exception in that case: "KafkaException - for any other unrecoverable errors (e.g. if offset metadata is too large or if the committed offset is invalid).". I tested it on an 0.11 broker and consumer and it doesn't appear to actually throw this exception even if the offset doesn't exist, so I've asked about it on the Kafka users list.

What do you think, is this a reasonable way to look at it or do we need to do more?, Copy pasting from the Kafka mailing list http://mail-archives.apache.org/mod_mbox/kafka-users/201709.mbox/%3CCA%2BOCqnYvhDTQ_dWthg68aO0JKgAENuwDyn-LgdnEyg%2BwAAgGMw%40mail.gmail.com%3E:

{quote}
I believe the Javadoc is slightly incorrect/misleading.
When it says "offset metadata is too large", it is about the metadata
you can commit along with the offset, not the offset. See
OffsetAndMetadata:
http://kafka.apache.org/0110/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html

Regarding the offset value, we only check if it's negative and that's
only performed client side (presumably 3rd party clients could commit
a negative offset). Apart from that, no checks are made if the offset
is "in range" or not.
We had a look a while back to check if the offset is "in range" when
committing but it's complicated, see the comments on
https://issues.apache.org/jira/browse/KAFKA-4081

I opened a PR to update the Javadoc: https://github.com/apache/kafka/pull/3780
{quote}

So we don't need to worry about committing offsets that are deleted., Regarding committing deleted offsets and compacted offsets:

The javadoc/documentation and reply on mailing list sounds conclusive enough. We should design a few tests to verify the behaviour such as
     1. Commit deleted offsets
     2. Seek / Commit compacted offsets

I particularly want to understand/confirm the broker behaviour when we seek or commit a compacted offset - will it return an earlier valid offset or a later one?, {quote}
Auto offset reset is latest
* 0 or more acked offsets when reset, no pending retries when reset happens:
    Example: 0-3 are acked, 0-1 are deleted. 10 is the latest offset.
   Consumer will seek to latest offset (10). When new tuples are acked after the reset, the OffsetManager will skip past all the unemitted tuples (4-9). I don't think we need to do anything special for this case.

* 0 or more acked offsets when reset, earliest pending retry is deleted:
   Example: 0-3 are acked, 0-4 are deleted. 4-5 are retriable and 10 is the latest offset.
   Consumer will seek to latest offset (10). The spout will handle acks as described in the previous case. When the retriable tuples become ready, the consumer will seek back to the earliest retriable offset (4). Since 4 is deleted, the consumer seeks to latest. Since the spout asked for retriable offset 4 and got 10 as the earliest, it will consider 4-9 deleted and mark them as acked. While offset 5 is technically still possible to retry, I don't think this is necessarily unexpected or bad behavior. I'd be okay with leaving this behavior as is.

*  0 or more acked offsets when reset, earliest pending retry is not deleted:
   Example: 0-3 are acked, 0-3 are deleted. 4-5 are retriable and 10 is the latest offset.
   Same as above, except when the retriable tuples become ready, the consumer will seek back to the earliest retriable offset (4). The spout continues processing from offset 4. This is a little inconsistent with the case above, but I don't think it's bad behavior, so I'm okay with leaving it like this.
{quote}

This approach sounds reasonable for #1 & #3. It will be good if we can identify the situations where offsets are being skipped and add appropriate logging. Kafka client prints a log when the consumer offset seek is invalid.

For #2, I am wondering if we need to identify the smallest valid offset larger than the invalid offset that the spout was trying to seek. In other words, we would be 'bridging' the gap as with the fix built for STORM-2505. The reason is that there could be a situation where a single deleted offset can result in the spout skipping ahead a lot and potentially pass over many valid offsets without even a single processing attempt. Need to think this over a bit more but feels like we can handle this scenario in a cleaner manner if the Kafka Consumer had an api to the effect of _seekNextValidOffset(Offset currentOffset)_, {quote}
Auto offset reset is earliest, cleanup policy is delete
* 0 or more acked offsets when reset, no pending retries when reset happens:
Exactly the same as the case for latest, except the consumer seeks to earliest instead.

* 0 or more acked offsets when reset, earliest pending retry is deleted:
Broadly the same as for latest. When the retriable tuples become ready, the consumer will seek back to the earliest retriable offset (4). Since 4 is deleted, the consumer seeks to earliest (5). 5 is skipped initially because it is not ready for retry, and processing picks up at 6. 5 gets retried whenever it becomes ready.

* 0 or more acked offsets when reset, earliest pending retry is not deleted:
Should be the same as the case for latest. The consumer will seek to earliest and poll, receiving offset 4-10. Since 4 and 5 are scheduled for retry and not ready, they will be skipped but left in the retry service until they're ready. Processing starts at 6 and works as normal. This seems fine to me.
{quote}

The approach detailed looks good to me. Thought through the possibility of offset reset resulting in tracking back to an extremely old offset. Then again, I don't think this can happen since in a 'delete' topic if we can go back to offset X then any offset greater than X has to be valid. 
, {quote}
Regarding committing deleted offsets and compacted offsets:

The javadoc/documentation and reply on mailing list sounds conclusive enough. We should design a few tests to verify the behaviour such as
1. Commit deleted offsets
2. Seek / Commit compacted offsets

I particularly want to understand/confirm the broker behaviour when we seek or commit a compacted offset - will it return an earlier valid offset or a later one?
{quote}
I feel like this type of test belongs in Kafka and not here, since it is testing KafkaConsumer behavior. About deleted offsets, I manually verified that the consumer doesn't care about commits of offsets that are out of range. See http://mail-archives.apache.org/mod_mbox/kafka-users/201709.mbox/%3CCAG09ER3XdnZyerPvD_pKJicg2FjtHmPXtmD2c4xAv9O%3DnZ94Yg%40mail.gmail.com%3E. So I don't think we need to worry about that, since committing a deleted offset doesn't hurt anything, and if we seek to that offset we'll just trigger the auto offset reset policy.

About compacted offsets, the documentation on log compaction specifies this behavior:
{quote}
Note also that all offsets remain valid positions in the log, even if the message with that offset has been compacted away; in this case this position is indistinguishable from the next highest offset that does appear in the log
{quote}
So for your questions in 2. the answers should be that committing has no extraordinary effect (it will just set the committed offset to the compacted offset and nothing else will happen), and seeking to the compacted offset will produce the next highest offset that hasn't been compacted.

{quote}
This approach sounds reasonable for #1 & #3. It will be good if we can identify the situations where offsets are being skipped and add appropriate logging. Kafka client prints a log when the consumer offset seek is invalid.
{quote}
If the consumer already logs that the auto offset reset policy is triggered, and we log any time we skip tuples due to offset gaps here https://github.com/apache/storm/pull/2307/files#diff-7d7cbc8f5444fa7ada7962033fc31c5eR363 and here https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/internal/OffsetManager.java#L99, I think we might be covered? If we skip an offset the consumer hasn't seen yet, the consumer log and the second link should cover it. If we skip an offset when it was emitted and acked, it wasn't skipped. If we skip an offset that was emitted and failed, we log it in the first link.

{quote}
For #2, I am wondering if we need to identify the smallest valid offset larger than the invalid offset that the spout was trying to seek. In other words, we would be 'bridging' the gap as with the fix built for STORM-2505. The reason is that there could be a situation where a single deleted offset can result in the spout skipping ahead a lot and potentially pass over many valid offsets without even a single processing attempt. Need to think this over a bit more but feels like we can handle this scenario in a cleaner manner if the Kafka Consumer had an api to the effect of seekNextValidOffset(Offset currentOffset)
{quote}
I think we should consider not doing anything in this case. Recall that the auto offset reset policy is set to latest, so seeking to the latest offset is the correct behavior. If we want to help people avoid a potential newbie trap here we could try to warn in the log if the spout is configured for at-least-once and the auto offset reset policy isn't set to earliest. Setting the offset reset policy to earliest has exactly the effect that a seekNextValidOffset function would have.

{quote}
The approach detailed looks good to me. Thought through the possibility of offset reset resulting in tracking back to an extremely old offset. Then again, I don't think this can happen since in a 'delete' topic if we can go back to offset X then any offset greater than X has to be valid. 
{quote}
I agree. For delete cleanup it doesn't seem like a problem. For compacted topics we hopefully never activate the auto offset reset policy, since all old offsets are valid and we don't seek "in front of" the Kafka log head., Agree on the tests belonging more in Kafka and not here. Goal is primarily to confirm our assumptions of the Kafka consumer behaviour and manual verification would suffice.

{quote}
If the consumer already logs that the auto offset reset policy is triggered, and we log any time we skip tuples due to offset gaps here https://github.com/apache/storm/pull/2307/files#diff-7d7cbc8f5444fa7ada7962033fc31c5eR363 and here https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/internal/OffsetManager.java#L99, I think we might be covered? If we skip an offset the consumer hasn't seen yet, the consumer log and the second link should cover it. If we skip an offset when it was emitted and acked, it wasn't skipped. If we skip an offset that was emitted and failed, we log it in the first link.
{quote}

The currently available logs seem sufficient. We can tweak it later if necessary.

{quote}
I think we should consider not doing anything in this case. Recall that the auto offset reset policy is set to latest, so seeking to the latest offset is the correct behavior. If we want to help people avoid a potential newbie trap here we could try to warn in the log if the spout is configured for at-least-once and the auto offset reset policy isn't set to earliest. Setting the offset reset policy to earliest has exactly the effect that a seekNextValidOffset function would have.
{quote}

+1 to adding warning in the log. Further to it, I feel we should go ahead and recommend _auto.offset.reset=earliest_ option for topics with _cleanup.policy=delete_ in the documentation for reliable at-least-once spout processing., {quote}
+1 to adding warning in the log. Further to it, I feel we should go ahead and recommend auto.offset.reset=earliest option for topics with cleanup.policy=delete in the documentation for reliable at-least-once spout processing.
{quote}
I agree. It seems easiest to base on the changes in https://github.com/apache/storm/pull/2249 IMO.]