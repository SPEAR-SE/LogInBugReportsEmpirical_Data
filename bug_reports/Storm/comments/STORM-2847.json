[[~erosebrook] Do you have a few more lines of the stack trace? I'm curious if the commit is happening in the rebalance listener.

Also just so I know which version of the code to look at, which commit is your build of 1.2.0 from?, [~Srdo] This is all I have at the moment. If you need more I can get that for you tomorrow. It was on the latest commit as of this morning.

java.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer. at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262) at org.apache.storm.kafka.spout.KafkaSpout.emitTupleIfNotEmitted(KafkaSpout.java:328) at org.apache.storm.kafka.spout.KafkaSpout.emit(KafkaSpout.java:309) at org.apache.storm.kafka.spout.KafkaSpout.nextTuple(KafkaSpout.java:233) at org.apache.storm.daemon.executor$fn__4976$fn__4991$fn__5022.invoke(executor.clj:644) at org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) at clojure.lang.AFn.run(AFn.java:22) at java.lang.Thread.run(Thread.java:745), [~erosebrook] Those line numbers don't match up with the line numbers from 1.x-branch (the 1.2.0 branch). See for example https://github.com/apache/storm/blob/1.x-branch/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L328 which is supposed to be where emitTupleIfNotEmitted starts according to the stack trace. We haven't merged anything to storm-kafka-client since a few days ago as far as I know. I checked 1.1.x-branch, 1.0.x-branch and master as well (1.0.6, 1.1.2 and 2.0.0 respectively) and the line numbers don't match up to your stack trace either.

I'm assuming the new stack trace is unrelated to the original, since the new trace doesn't contain org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)?

It would be good if you could find the commit hash you built from., Apologies [~Srdo] , the second stack trace is from a fix I was playing with for the 1.1.x-branch. I am having trouble with rebalance there as well. Ultimately it seemed like I needed some of your recent changes from the 1.x-branch. Here is the rest of the stack trace. Commit 31133fdcecb5e83317729de67ef7ea12a1bd9929

java.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer. at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262) at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473) at org.apache.storm.kafka.spout.KafkaSpout.nextTuple(KafkaSpout.java:239) at org.apache.storm.daemon.executor$fn__4976$fn__4991$fn__5022.invoke(executor.clj:644) at org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) at clojure.lang.AFn.run(AFn.java:22) at java.lang.Thread.run(Thread.java:745), the problems persists in 53c2c677e1066df1ac97b7a62a2d41cab484ecbd

java.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer. at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262) at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:475) at org.apache.storm.kafka.spout.KafkaSpout.nextTuple(KafkaSpout.java:239) at org.apache.storm.daemon.executor$fn__4976$fn__4991$fn__5022.invoke(executor.clj:644) at org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) at clojure.lang.AFn.run(AFn.java:22) at java.lang.Thread.run(Thread.java:745), [~erosebrook] Thanks. I'll try to figure out why this is happening. In the meantime could you post your KafkaSpout configuration and which Kafka version you're using (broker and client)?, [~Srdo] Here is the requested info:

kafka-clients: 0.10.2.0
kafka-broker: 0.10.1.0

    val retryService = new KafkaSpoutRetryExponentialBackoff(
      KafkaSpoutRetryExponentialBackoff.TimeInterval.microSeconds(500),
      KafkaSpoutRetryExponentialBackoff.TimeInterval.milliSeconds(2),
      10,
      KafkaSpoutRetryExponentialBackoff.TimeInterval.seconds(10))

    val recordTranslator = new CustomRecordTranslator(topics, SerializableFactories.getDeserializer)

    new KafkaSpoutConfig.Builder(hosts, classOf[CustomDeserializer], classOf[CustomDeserializer], topics)
      .setGroupId(consumerGroup)
      .setRetry(retryService)
      .setRecordTranslator(recordTranslator)
      .setProp(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 10000)
      .setProp(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false")
      .setProp(ConsumerConfig.RECEIVE_BUFFER_CONFIG, 1048576)
      .setOffsetCommitPeriodMs(500)
      .build(), Thanks [~erosebrook]. Your configuration and versions look fine to me.

I've spent some time going over the code, and I'm having a hard time spotting the problem.

The exception you're getting from https://github.com/apache/storm/blob/e2e3f5d19a8671e3759a04b94135fd6643b3aa61/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L475 is saying that the TopicPartition parameter to KafkaConsumer.position was not assigned to the consumer. I don't understand how that can happen, because the TopicPartition parameter is based on the offsetManagers map, and the key set of that map is set to be exactly the partitions that are assigned to the consumer, at https://github.com/apache/storm/blob/e2e3f5d19a8671e3759a04b94135fd6643b3aa61/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L174 and https://github.com/apache/storm/blob/e2e3f5d19a8671e3759a04b94135fd6643b3aa61/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L197.

Could you try to enable debug logging for the org.apache.storm.kafka.spout log domain and provoking the error again? I particularly want to see if the partitions logged at https://github.com/apache/storm/blob/e2e3f5d19a8671e3759a04b94135fd6643b3aa61/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L164 match the ones logged at https://github.com/apache/storm/blob/e2e3f5d19a8671e3759a04b94135fd6643b3aa61/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L469.

I'm also curious if the error happens at random, or does it happen at particular moments?, [~Srdo]

It happens at every manually triggered rebalance. It seemed to me like it has to do with partitions being revoked from kafka itself, but the spout still has a reference to them. I'll get you the debug data when I am able., When you refer to triggering a rebalance what do you mean? Asking Storm to rebalance the topology or something else?

Also as of 1.2.0 Kafka isn't responsible for managing consumer group partition assignment anymore, the spout handles distributing partitions without consulting Kafka. See https://issues.apache.org/jira/browse/STORM-2542 for why we made this change. Partition assignment is now handled by https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/subscription/ManualPartitionSubscription.java and associated classes., yes, asking storm to rebalance, I think I have a guess as to what could be wrong. If the spout is deactivated and then reactivated, we replace the KafkaConsumer with a new one. Unfortunately https://github.com/apache/storm/blob/master/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/subscription/ManualPartitionSubscription.java#L58 will ensure that we don't assign partitions to the new consumer unless the assignment changes, because we reuse the old ManualPartitionSubscription instance.

I'll look at fixing this in the next few days. Hopefully it's what's causing this., [~erosebrook] I believe I have a fix ready for this. Would you be willing to try it out? You can get it from https://github.com/srdo/storm/tree/STORM-2847-1.x., [~Srdo] I Tried your branch and got an error. Apparently the partitions provided to onPartitionsRevoked can be empty. I was able to resolve this by adding " && partitions.size() > 0" to line 152.

Partitions revoked. [consumer-group=MyStormTopology, consumer=org.apache.kafka.clients.consumer.KafkaConsumer@2ada06e4, topic-partitions=[]]
2017-12-11 15:21:19.908 o.a.s.k.s.KafkaSpout Thread-34-uisspout-executor[703 703] [DEBUG] Offsets successfully committed to Kafka [{uis-12=OffsetAndMetadata{offset=6606783674, metadata='{topic-partition=uis-12, offset=6606783673, numFails=0, thread='Thread-34-uisspout-executor[703 703]'}'}, uis-28=OffsetAndMetadata{offset=4262625500, metadata='{topic-partition=uis-28, offset=4262625499, numFails=0, thread='Thread-34-uisspout-executor[703 703]'}'}, uis-44=OffsetAndMetadata{offset=4263152272, metadata='{topic-partition=uis-44, offset=4263152271, numFails=0, thread='Thread-34-uisspout-executor[703 703]'}'}, uis-60=OffsetAndMetadata{offset=3855749917, metadata='{topic-partition=uis-60, offset=3855749916, numFails=0, thread='Thread-34-uisspout-executor[703 703]'}'}, uis-76=OffsetAndMetadata{offset=3196437627, metadata='{topic-partition=uis-76, offset=3196437626, numFails=0, thread='Thread-34-uisspout-executor[703 703]'}'}, uis-92=OffsetAndMetadata{offset=3209173441, metadata='{topic-partition=uis-92, offset=3209173440, numFails=0, thread='Thread-34-uisspout-executor[703 703]'}'}}]
	at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:467) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout.access$400(KafkaSpout.java:59) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout$KafkaSpoutConsumerRebalanceListener.onPartitionsRevoked(KafkaSpout.java:154) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout.subscribeKafkaConsumer(KafkaSpout.java:564) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout.activate(KafkaSpout.java:555) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:467) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout.access$400(KafkaSpout.java:59) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout$KafkaSpoutConsumerRebalanceListener.onPartitionsRevoked(KafkaSpout.java:154) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout.subscribeKafkaConsumer(KafkaSpout.java:564) ~[stormjar.jar:local]
	at org.apache.storm.kafka.spout.KafkaSpout.activate(KafkaSpout.java:555) ~[stormjar.jar:local], [~erosebrook] Thanks for testing it. I've updated the branch I linked earlier, please try again if you can. , Looks good [~Srdo]. I am no longer seeing any exception when manually triggering a rebalance. Nice work!]