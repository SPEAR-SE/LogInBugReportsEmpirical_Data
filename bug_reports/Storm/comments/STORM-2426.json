[Found the probable reason for why this is happening. Kafka rebalancing takes long time (over 2 minutes). The system ticks received by SpoutExecutor are queued for that time (?) and then received in quick succession after the rebalancing ends. This causes multiple (2 in the example case) rotations of executors RotatingMap which again causes the tuples that were just emitted to be timed out. Please see the attached log file 2017-03-21-Timeout-ticks.txt., [~Srdo] Does STORM-2542 fix this bug ?, Yes, I believe so. This looks a lot like how the subscribe API behaves when there are multiple KafkaConsumers in a thread, as described here https://issues.apache.org/jira/browse/STORM-2514?focusedCommentId=16014195&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16014195. I'm not really sure why the rebalance takes 3.5 minutes, since I would expect it to take 2.5 (the session timeout). In the linked demo code, the long rebalance happens because rebalancing can't finish until all the KafkaConsumers call (and block in) poll, which can't happen if there are multiple consumers in a thread. The rebalance times out at the session timeout.

Was the number of executors lower than the number of tasks when you had this problem [~EitZei]?

STORM-2542 gets rid of long rebalances, so it should be fixed in any case even if it's not the issue where the task count isn't equal to the executor number., First of all it very nice to hear that the issue is worked on.

In this case both the number of tasks and number of executors was 1., [~EitZei] Okay, it isn't exactly that issue then, but it's very similar. When the worker is killed, the KafkaConsumer doesn't get a chance to disconnect cleanly from Kafka, so Kafka will wait for the full session timeout before it declares the missing consumer dead and finishes rebalancing. I tried out killing workers with settings similar to yours, and the rebalance ends up taking a few minutes. This should explain the long rebalance. STORM-2542 will definitely solve this, since Kafka is not involved in assigning partitions with that change, so rebalances are local to each spout instance instead of being something the spouts need to coordinate through Kafka., This should no longer be an issue once we move away from the Named/PatternSubscription Subscription implementations. Those implementations are no longer an option in 2.0.0, and are deprecated from 1.2.0. Please switch to using the ManualPartitionSubscription class when configuring KafkaSpoutConfig. ManualPartitionSubscription should work from 1.1.2 on.]