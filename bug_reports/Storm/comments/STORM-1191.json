[GitHub user ashnazg opened a pull request:

    https://github.com/apache/storm/pull/869

    STORM-1191:  bump timeout by 50% due to intermittent travis build failures

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ashnazg/storm crb-transactionalTestTimeout

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/869.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #869
    
----
commit f5a46dbcbb6c44e3aca6074a51ab0d5c9f4e7f9a
Author: Chuck Burgess <cburgess@progressrail.com>
Date:   2015-11-09T16:37:08Z

    bump timeout by 50% due to intermittent travis build failures

----
, Github user kishorvpatil commented on the pull request:

    https://github.com/apache/storm/pull/869#issuecomment-155146265
  
    +1
, Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/869#issuecomment-155217116
  
    +1
    
    Btw, it could help, but it may not resolve origin issue since 100s should be long enough.
, Github user ashnazg commented on the pull request:

    https://github.com/apache/storm/pull/869#issuecomment-155220143
  
    True, but if the original issue is just that Travis is slow, ;-) ... I just want to minimize the false negatives of test failures that are caused when Travis is bogged down and the test case runs too slow.  I presume that the test will _logically_ pass if given enough time, and that the test case itself is not trying to enforce a performance speed spec.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/869#issuecomment-155431246
  
    @ashnazg the test "might" "logically" pass.  The code is a bit complex.  When debugging these in the past the tests use simulated time, which is a great thing it lets us run tests that would take a long time very quickly, but to make it work properly there are some critical points where we wait for the simulated cluster to be idle.  Typically we see timeouts happen here, waiting for the entire cluster to stop.  But for some reason on really slow hardware, that I don't totally understand yet, this does not always happen. and increasing the timeout does not always induce it to be in that state.
    
    I am +1 on merging this in, but I am not totally sure that it will "fix" the problem.
, Github user knusbaum commented on the pull request:

    https://github.com/apache/storm/pull/869#issuecomment-155847070
  
    Most all of the spurious test failures I've seen have been *real* failures and not timeouts.
    I'm okay with this going in, even though I don't like potentially making the build time longer and I'm not optimistic about this fixing any problems. 
, Github user asfgit closed the pull request at:

    https://github.com/apache/storm/pull/869
, Thanks [~ashnazg],

I merged this into master.  Hopefully it helps with the travis failures.]