[GitHub user tedxia opened a pull request:

    https://github.com/apache/storm/pull/600

    STORM-903: fix java.lang.ClassNotFoundException with org.apache.commo…

    …ns.codec.binary.Base64 when set ui.filter to org.apache.hadoop.security.authentication.server.AuthenticationFilter
    
    PR for [STORM-903](https://issues.apache.org/jira/browse/STORM-903)

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/tedxia/storm ted-fix-missing-codex-when-use-ui-filter-as-AuthenticationFilter

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/600.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #600
    
----
commit 155478204705e78777ccb5972ac495eb28f700d6
Author: xiajun <xiajun@xiaomi.com>
Date:   2015-06-19T08:18:26Z

    STORM-903: fix java.lang.ClassNotFoundException with org.apache.commons.codec.binary.Base64 when set ui.filter to org.apache.hadoop.security.authentication.server.AuthenticationFilter

----
, Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-114657493
  
    @kishorvpatil I think you may want to take care of it.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115263584
  
    @tedxia We shaded this for a reason.  If AutoHDFS is not able to find it, then we should look at updating AutoHDFS to use the shaded version of the library.  I am not sure if that is possible or not.  It depends on if it is us that is using commons-codec directly or if it is another dependency.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115269037
  
    @tedxia sorry I am wrong.  hadoop-hdfs itself depends on commons-codec.  But the issue is around the packaging of auto-hdfs.
    
    For most users who want to use storm-hdfs in their topologies they will include it as a dependency and include it as part of an uber-jar.  This will pull in commons-codec correctly.  The issue is if you want to just include it in the classpath by default.  If all you do is take storm-hdfs and put it in the lib directory you will get these errors.  If you don't want your users to have to package auto-hdfs with their topology then you need to include storm-hdfs, and all of its dependencies in the lib directory or set STORM_EXT_CLASSPATH before launching the various daemons.  This is nice because it lets you potentially query a hadoop install already on the box for it's classpath instead of trying to figure it all out yourself.
    
    Alternatively you could just set it up for storm-hdfs to be on the daemons classpath and not pollute the worker classpath.  You can do this by using STORM_EXT_CLASSPATH_DAEMON and/or extlib-daemon directory.  What we really need is some better documentation about how to install and setup atuo-hdfs.
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115349321
  
    @revans2 not sure this addresses the issue for using KerberosFilter from hadoop for securing UI when used in kerberos cluster. We excluded commons-codec from hadoop-auth because storm is including it in the classpath https://github.com/apache/storm/blob/master/storm-core/pom.xml#L259 
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115355904
  
    @harshach If you are pulling in an external library, like the KerberosFilter, you are responsible for making sure all of its dependencies are on the classpath.  If we have shaded some of them, then you need to pull them over and include them.  If it is something that a worker does not need access to, like the KerberosFilter, then you can include it in the extlib-damone directory where it will not show up on the worker's classpath.
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115360459
  
    @revans2 we are shipping security in 0.10 that means we need to provide a way for UI daemon to be secured hence the reason we are including kerberos filter as part of storm-core/pom.xml that its easier for users to just add a config ui.filter and use kerberos filter. Now the patch STORM-848 which shaded and removed commons-codec should also remove the exclusion of commons-codec from hadoop-auth. I don't think making this as user's responsibility makes sense here.
, Github user tedxia commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115479231
  
    @revans2 thanks for  your replay. But I still think we must add storm-hdfs and all of its dependencies to lib or extlib, and storm user must add storm-hdfs as topology's dependency as it use HdfsBolt and so on. The reason why we should add storm-hdfs to daemon's CLASS_PATH is that daemons such as nimbus and supervisor will directly call AutoHDFS‘s interface. I think it is a good idea if we add storm-hdfs and storm-hbase and all of their dependencies to extlib-daemon by default. The jars that have been shaded by storm-core must also add to extlib-daemon, if they are depended by storm-hdfs or storm-hbase, just because AutoHDFS and AutoHBase load by class loader and they can't identify the shaded jars. 
, Github user tedxia commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115479671
  
    @revans2  what do you think about add storm-hdfs and storm-hbase and all of their dependencies to extlib-daemon by default.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115699285
  
    @tedxia I don't really like the idea.  I think we should make it simple for people to do that, but the problem is hdfs and hbase are more than just a set of jars.  The configuration required to make them work is often extensive. 
    
    Perhaps what we can do is to have storm-hdfs and storm-hbase in extlib-daemon by default, and inside the default storm-env.sh we look for hadoop and hbase on the PATH, and if they are found we append the result of `hadoop classpath` and `hbase classpath` to STORM_EXT_CLASSPATH_DAEMON.
    
    That way they are there to be used if hadoop and hbase are setup on the node and we are not tied to a very specific version or configuration of hadoop and hbase.
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115835563
  
    @revans2 what about the hadoop-auth that we are including right now can we atleast remove the "exclude commons-codec" from hadoop-auth dependency. It will give users a filter to use it with UI in secure mode.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115845268
  
    @harshach which exclude are you talking about? If you want to make a change quickly I am OK with that.  I am just not totally sure what the impact that this is going to have.  Will we now have commons-codec as a dependency that we didn't before?  Will we now have a version of hadoop-auth with classes rewritten to point to the shaded commons-codec?
    
    If it is the former, then we will be stuck with commons-codec being a dependency until we go to another major version.  If it is the former I am a bit nervous about how hadoop might react to it, but not very nervous.
    
    I am fine either way, I just want to know what the impact is, and then have someone put together a pull request we can review it and check it in.
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115866496
  
    @revans2  this line https://github.com/apache/storm/blob/master/storm-core/pom.xml#L259 so the reason we excluded is there is commons-codec in path from storm as its dependency before we shaded it. Now since we removed it hadoop-auth is throwing this error that its unable to find.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115872534
  
    @harshach so what you are saying is that if we should remove the exclude, but leave in the shading.  This means we will have two copies of commons-codec, one shaded that storm will use, and one that hadoop-auth will use that is not shaded and will be on the path?
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115875141
  
    So this pull request is what you want to have happen.  I am OK with that, but if we are going to have commons-codec on the classpath, then lets not bother shading it at all.
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/600#issuecomment-115940765
  
    @revans2  agree on not shading. Thanks.
]