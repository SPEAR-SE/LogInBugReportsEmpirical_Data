[I used code in the HiveBolt as a starting point for handling retiring writers (see below), and I'll create a PR with the same:

{code}
 // Setting accessOrder to true to facilitate obtaining the LRU  entry
 writers = new LinkedHashMap<>(this.maxOpenFiles, 0.75f, true);

private AbstractHDFSWriter getOrCreateWriter(String writerKey, Tuple tuple) throws IOException {
    AbstractHDFSWriter writer = writers.get( writerKey );
    if (writer == null) {
        LOG.debug("Creating Writer for writerKey : " + writerKey);
        Path pathForNextFile = getBasePathForNextFile(tuple);
        writer = makeNewWriter(pathForNextFile, tuple);

        if (writers.size() > (this.maxOpenFiles - 1)) {
            LOG.info("cached writers size {} exceeded maxOpenFiles {} ", writers.size(), this.maxOpenFiles);
            retireEldestWriter();
        }
        this.writers.put(writerKey, writer);
    }
    return writer;
}

/**
 * Locate writer that has not been used for longest time and retire it
 */
private void retireEldestWriter() throws IOException {
    LOG.info("Attempting to close eldest writer");
    Iterator<String> iterator = this.writers.keySet().iterator();
    if (iterator.hasNext()) {
        String eldestKey = iterator.next();
        doRotationAndRemoveWriter(eldestKey, this.writers.get(eldestKey));
    }
}
{code}]