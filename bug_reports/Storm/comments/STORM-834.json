[[~longtimer]
Which component throws ClastCastException? (Spout / Bolt / Acker / etc), The error is coming from a bolt as best I can tell from the log file in which the error is found, but the lack of detail in the exception means i can tell little else., It might related to STORM-770 since both things could be related to Disruptor Queue.  , I've experienced this several times over the last few days when running a LocalCluster and have a misconfiguration in one of my bolts.  The log records the exception on the thread for an altogether different bolt, however, leading to a large amount of confusion.

I may be able to make a simple example that demonstrates the miscreant behavior.

Running storm 0.9.4 on OS X 10.10.3 using Oracle JDK jdk1.8.0_45., Yes if you could create a reproducible use case that would be great.  The code in question is the task receiver, which processes tuples sent to a bolt.  It expects to see a list of tuples in a batch, not individual tuples. If an individual tuple showed up it would cause an exception like this.  There are a few places in the code where tuples are injected directly into a receiver queue, the tick tuple, and the metrics tick are the ones that come to mind, but all of them explicitly insert a list for the single tuple they put in.  There is also the possibility that something in the batching code is not handling one use case properly and not putting in a list, but without a reproducible use case it is really hard to tell., I continue to get this happening after running for a while, but am at a loss as to the cause. I now have several different topologies and several have the error happening, but not all. I was wondering if some code could be put in to check on the insertion side of the storm queues to ensure what is being put on is a valid type? Does this make sense?, [~longtimer],

You could put in a check like that into DisruptorQueue.java.

I am not sure which version of storm you are using, but I would insert it into the publish method https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/utils/DisruptorQueue.java#L496

Be aware that there are a lot of unit tests that will probably fail with this change.  Another option is to modify the code around consumeBatchToCurser to catch the exception and print out more information about the object causing the issues.

https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/utils/DisruptorQueue.java#L425-L452

perhaps changing it to something like the following that adds some debug about what the event is when an exception happens.

{code}
    private void consumeBatchToCursor(long cursor, EventHandler<Object> handler) {
        for (long curr = _consumer.get() + 1; curr <= cursor; curr++) {
            Object o = null;
            try {
                AtomicReference<Object> mo = _buffer.get(curr);
                o = mo.getAndSet(null);
                if (o == INTERRUPT) {
                    throw new InterruptedException("Disruptor processing interrupted");
                } else if (o == null) {
                    LOG.error("NULL found in {}:{}", this.getName(), cursor);
                } else {
                    handler.onEvent(o, curr, curr == cursor);
                    if (_enableBackpressure && _cb != null && (_metrics.writePos() - curr + _overflowCount.get()) <= _lowWaterMark) {
                        try {
                            if (_throttleOn) {
                                _throttleOn = false;
                                _cb.lowWaterMark();
                            }
                        } catch (Exception e) {
                            throw new RuntimeException("Exception during calling lowWaterMark callback!");
                        }
                    }
                }
            } catch (Exception e) {
                throw new RuntimeException("Error while processing event ("+(o != null ? o.getClass() : "NULL") +") "+o, e);
            }
        }
        _consumer.set(cursor);
    }
{code}


, I've actually seen this issue when I had slf4j-log4j12 in my topology which seems to conflict with log4j-slf4j-impl from storm. Excluding it fixed my issue., [~lonerzzz] In fact I come into the same problem before, but it haven't happened after I rebuild the topology and rebuild the latest storm. ]