[Not really sure what is happening because I was able to successfully run the test with just a few hundred MB of heap, not the 1.5GB that we run the tests with normally.  I am going to put in a heap dump on OOM internally and hopefully catch it in the act., I found the root cause of the issue.

https://issues.apache.org/jira/browse/HDFS-12984

I am not totally sure why it is not happening more frequently.  I guess it must have something to do with how our build boxes are configured and the data nodes end up taking a small amount more ram then on other systems.  Because I don't think this is going to be fixed any time soon I will work around it by launching all of the tests in separate JVMs.  I'll see what the hit is, and might just do it only for the HDFS tests., I merged this into 1.x 1.1.x and master.  It didn't apply cleanly to 1.0.x.  If someone really wants it in there I can make the change, but it only impacts tests that pass most of the time anyways so I don't know how critical it is.]