[This is also the appropriate time to add javadoc to these APIs. , [~sureshms] Yes. I should have called that out explicitly. I assumed javadoc to be part of the documentation., +1 for the concept., GitHub user ptgoetz opened a pull request:

    https://github.com/apache/storm/pull/1029

    STORM-1214: add javadoc for Trident Streams and Operations

    JIRA: https://issues.apache.org/jira/browse/STORM-1214
    
    This is just a work in progress for STORM-1214, if this is merged, please don't resolve the JIRA.
    
    I plan on further docs. But I didn't want this to get lost in the 1.x work.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ptgoetz/storm wip-trident-javadoc

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/1029.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1029
    
----
commit b5181c2aba7908bd7b8f994fa238977de812a68b
Author: P. Taylor Goetz <ptgoetz@gmail.com>
Date:   2016-01-20T02:52:43Z

    add javadoc for Trident Streams and Operations

----
, Github user satishd commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50234893
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/Stream.java ---
    @@ -68,61 +85,160 @@ protected Stream(TridentTopology topology, String name, Node node) {
             _node = node;
             _name = name;
         }
    -    
    +
    +    /**
    +     * Applies a label to the stream. Naming a stream will append the label to the name of the bolt(s) created by
    +     * Trident and will be visible in the Storm UI.
    +     *
    +     * @param name - The label to apply to the stream
    +     * @return
    +     */
         public Stream name(String name) {
             return new Stream(_topology, name, _node);
         }
    -    
    +
    +    /**
    +     * Applies a parallelism hint to a stream.
    +     *
    +     * @param hint
    +     * @return
    +     */
         public Stream parallelismHint(int hint) {
             _node.parallelismHint = hint;
             return this;
         }
    -        
    +
    +    /**
    +     * Filters out fields from a stream, resulting in a Stream containing only the fields specified by `keepFields`.
    +     *
    +     * For example, if you had a Stream `mystream` containing the fields `["a", "b", "c","d"]`, calling"
    +     *
    +     * ```java
    +     * mystream.project(new Fields("b", "d"))
    +     * ```
    +     *
    +     * would produce a stream containing only the fields `["b", "d"]`.
    +     *
    +     *
    +     * @param keepFields The fields in the Stream to keep
    +     * @return
    +     */
         public Stream project(Fields keepFields) {
             projectionValidation(keepFields);
             return _topology.addSourcedNode(this, new ProcessorNode(_topology.getUniqueStreamId(), _name, keepFields, new Fields(), new ProjectedProcessor(keepFields)));
         }
     
    +    /**
    +     * ## Grouping Operation
    +     *
    +     * @param fields
    +     * @return
    +     */
         public GroupedStream groupBy(Fields fields) {
             projectionValidation(fields);
             return new GroupedStream(this, fields);        
         }
    -    
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * @param fields
    +     * @return
    +     */
         public Stream partitionBy(Fields fields) {
             projectionValidation(fields);
             return partition(Grouping.fields(fields.toList()));
         }
    -    
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * @param partitioner
    +     * @return
    +     */
         public Stream partition(CustomStreamGrouping partitioner) {
             return partition(Grouping.custom_serialized(Utils.javaSerialize(partitioner)));
         }
    -    
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * Use random round robin algorithm to evenly redistribute tuples across all target partitions
    +     *
    +     * @return
    +     */
         public Stream shuffle() {
             return partition(Grouping.shuffle(new NullStruct()));
         }
     
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * Use random round robin algorithm to evenly redistribute tuples across all target partitions, with a preference
    +     * for local tasks.
    +     *
    +     * @return
    +     */
         public Stream localOrShuffle() {
             return partition(Grouping.local_or_shuffle(new NullStruct()));
         }
    +
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * All tuples are sent to the same partition. The same partition is chosen for all batches in the stream.
    +     * @return
    +     */
         public Stream global() {
             // use this instead of storm's built in one so that we can specify a singleemitbatchtopartition
             // without knowledge of storm's internals
             return partition(new GlobalGrouping());
         }
    -    
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     *  All tuples in the batch are sent to the same partition. Different batches in the stream may go to different
    +     *  partitions.
    +     *
    +     * @return
    +     */
         public Stream batchGlobal() {
             // the first field is the batch id
             return partition(new IndexHashGrouping(0));
         }
    -        
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * Every tuple is replicated to all target partitions. This can useful during DRPC â€“ for example, if you need to do
    +     * a stateQuery on every partition of data.
    +     *
    +     * @return
    +     */
         public Stream broadcast() {
             return partition(Grouping.all(new NullStruct()));
         }
    -    
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * @return
    +     */
         public Stream identityPartition() {
             return partition(new IdentityGrouping());
         }
    -    
    +
    +    /**
    +     * ## Repartitioning Operation
    +     *
    +     * This method takes in a custom partitioning function that implements
    +     * {@link backtype.storm.grouping.CustomStreamGrouping}
    --- End diff --
    
    It should be org.apache.storm.grouping.CustomStreamGrouping
, Github user satishd commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50234998
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/BaseOperation.java ---
    @@ -19,12 +19,27 @@
     
     import java.util.Map;
     
    +/**
    + * Convenience implementation of the {@link storm.trident.operation.Operation} interface.
    --- End diff --
    
    It should be org.apache.storm.trident.operation.Operation
, Github user satishd commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50235575
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Operation.java ---
    @@ -20,7 +20,26 @@
     import java.io.Serializable;
     import java.util.Map;
     
    +/**
    + * Parent interface for Trident `Filter`s and `Function`s.
    + *
    + * `Operation` defines two lifecycle methods for Trident components. The `prepare()` method is called once when the
    + * `Operation` is first initialized. The `cleanup()` method is called in local mode when the local cluster is
    + * being shut down.
    + */
     public interface Operation extends Serializable {
    +    /**
    +     * Called when the `Operation` is first initialized.
    +     * @param conf the Storm configuration map
    +     * @param context the operation context which provides information such as the number of partitions in the stream,
    +     *                and the current partition index. It also provides methods for registering operation-specific
    +     *                metrics.
    +     * @see storm.trident.operation.TridentOperationContext
    --- End diff --
    
    It should be org.apache.storm.trident.operation.TridentOperationContext
, Github user satishd commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50235765
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Assembly.java ---
    @@ -20,6 +20,26 @@
     import org.apache.storm.trident.Stream;
     
     
    +/**
    + * The `Assembly` interface provides a means to encapsulate logic applied to a {@link storm.trident.Stream}.
    + *
    + * Usage:
    + *
    + * ```java
    + * Stream mystream = ...;
    + * Stream assemblyStream = mystream.applyAssembly(myAssembly);
    + * ```
    + *
    + * @see storm.trident.Stream
    --- End diff --
    
    It should be org.apache.storm.trident.Stream
, Github user satishd commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50235799
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Assembly.java ---
    @@ -20,6 +20,26 @@
     import org.apache.storm.trident.Stream;
     
     
    +/**
    + * The `Assembly` interface provides a means to encapsulate logic applied to a {@link storm.trident.Stream}.
    + *
    + * Usage:
    + *
    + * ```java
    + * Stream mystream = ...;
    + * Stream assemblyStream = mystream.applyAssembly(myAssembly);
    + * ```
    + *
    + * @see storm.trident.Stream
    + * @see storm.trident.operation.builtin.FirstN
    --- End diff --
    
    org.apache.storm.trident.operation.builtin.FirstN
, Github user satishd commented on the pull request:

    https://github.com/apache/storm/pull/1029#issuecomment-173157085
  
    backtype.storm and storm.* should be replaced with org.apache.storm.* in all the updated javadoc.
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50272891
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/Stream.java ---
    @@ -57,6 +57,23 @@
     import org.apache.storm.trident.state.StateUpdater;
     import org.apache.storm.trident.util.TridentUtils;
     
    +/**
    + * A Stream represents the core data model in Trident, and can be thought of as a "stream" of tuples that are processed
    + * as a series of small batches. A stream is partitioned accross the nodes in the in the cluster, and operations are
    --- End diff --
    
    `the nodes in the *in the* cluster` the second `in the` should probably go away.
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50273025
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/Stream.java ---
    @@ -57,6 +57,23 @@
     import org.apache.storm.trident.state.StateUpdater;
     import org.apache.storm.trident.util.TridentUtils;
     
    +/**
    + * A Stream represents the core data model in Trident, and can be thought of as a "stream" of tuples that are processed
    + * as a series of small batches. A stream is partitioned accross the nodes in the in the cluster, and operations are
    + * applied to a stream in parallel accross each partition.
    + *
    + * There are five types of operations that can be performed on streams in Trident
    + *
    + * 1. **Partiton-Local Operations** - Operations that are applied locally to each partition and do not involve network
    + * transfer
    + * 2. **Repartitioning Operations** - Operations that that change how tuples are partitioned across tasks(thus causing
    --- End diff --
    
    `Operations that *that* change` extra that
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50273965
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Assembly.java ---
    @@ -20,6 +20,26 @@
     import org.apache.storm.trident.Stream;
     
     
    +/**
    + * The `Assembly` interface provides a means to encapsulate logic applied to a {@link storm.trident.Stream}.
    --- End diff --
    
    This one too should be org.apache....
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50275791
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Filter.java ---
    @@ -19,6 +19,30 @@
     
     import org.apache.storm.trident.tuple.TridentTuple;
     
    +import java.util.Map;
    +
    +/**
    + * Filters take in a tuple as input and decide whether or not to keep that tuple or not.
    + *
    + * If the `isKeep()` method of a Filter returns `false` for a tuple, that tuple will be filtered out of the Stream
    + *
    + *
    + * ### Configuration
    + * If your `Filter` implementation has configuration requirements, you will typically want to extend
    + * {@link storm.trident.operation.BaseFilter} and override the
    + * {@link storm.trident.operation.Operation#prepare(Map, TridentOperationContext)} method to perform your custom
    + * initialization.
    +
    + *
    + * @see storm.trident.Stream
    + */
    --- End diff --
    
    all the links here need to be org.apache....
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50276631
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Function.java ---
    @@ -19,6 +19,73 @@
     
     import org.apache.storm.trident.tuple.TridentTuple;
     
    +import java.util.Map;
    +
    +/**
    + * A function takes in a set of input fields and emits zero or more tuples as output. The fields of the output tuple
    + * are appended to the original input tuple in the stream. If a function emits no tuples, the original input tuple is
    + * filtered out. Otherwise, the input tuple is duplicated for each output tuple.
    + *
    + * For example, if you have the following function:
    + *
    + * ```java
    + * public class MyFunction extends BaseFunction {
    + *      public void execute(TridentTuple tuple, TridentCollector collector) {
    + *      for(int i=0; i < tuple.getInteger(0); i++) {
    + *          collector.emit(new Values(i));
    + *      }
    + *    }
    + * }
    + *
    + * ```
    + *
    + * Now suppose you have a stream in the variable `mystream` with the fields `["a", "b", "c"]` with the following tuples:
    + *
    + * ```
    + * [1, 2, 3]
    + * [4, 1, 6]
    + * [3, 0, 8]
    + * ```
    + * If you had the following code in your topology definition:
    + *
    + * ```java
    + * mystream.each(new Fields("b"), new MyFunction(), new Fields("d")))
    + * ```
    + *
    + * The resulting tuples would have the fields `["a", "b", "c", "d"]` and look like this:
    + *
    + * ```
    + * [1, 2, 3, 0]
    + * [1, 2, 3, 1]
    + * [4, 1, 6, 0]
    + * ```
    + *
    + * In this case, the parameter `new Fields("b")` tells Trident that you would like to select the field "b" as input
    + * to the function, and that will be the only field in the Tuple passed to the `execute()` method. The value of "b" in
    + * the first tuple (2) causes the for loop to execute twice, so 2 tuples are emitted. similarly the second tuple causes
    + * one tuple to be emitted. For the third tuple, the value of 0 causes the `for` loop to be skipped, so nothing is
    + * emitted and the incoming tuple is filtered out of the stream.
    + *
    + * ### Configuration
    + * If your `Function` implementation has configuration requirements, you will typically want to extend
    + * {@link storm.trident.operation.BaseFunction} and override the
    + * {@link storm.trident.operation.Operation#prepare(Map, TridentOperationContext)} method to perform your custom
    + * initialization.
    + *
    + * ### Performance Considerations
    + * Because Trident Functions perform logic on individual tuples -- as opposed to batches -- it is advisable
    + * to avoid expensive operations such as database operations in a Function, if possible. For data store interactions
    + * it is better to use a {@link storm.trident.state.State} or {@link storm.trident.state.QueryFunction} implementation
    + * since Trident states operate on batch partitions and can perform bulk updates to a database.
    + *
    + *
    + */
    --- End diff --
    
    org.apache in the links here too.
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50277552
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Operation.java ---
    @@ -20,7 +20,26 @@
     import java.io.Serializable;
     import java.util.Map;
     
    +/**
    + * Parent interface for Trident `Filter`s and `Function`s.
    + *
    + * `Operation` defines two lifecycle methods for Trident components. The `prepare()` method is called once when the
    + * `Operation` is first initialized. The `cleanup()` method is called in local mode when the local cluster is
    + * being shut down.
    + */
     public interface Operation extends Serializable {
    +    /**
    +     * Called when the `Operation` is first initialized.
    +     * @param conf the Storm configuration map
    +     * @param context the operation context which provides information such as the number of partitions in the stream,
    +     *                and the current partition index. It also provides methods for registering operation-specific
    +     *                metrics.
    +     * @see storm.trident.operation.TridentOperationContext
    +     */
         void prepare(Map conf, TridentOperationContext context);
    +
    +    /**
    +     * When running in local mode, called when the local cluster is being shut down.
    --- End diff --
    
    Is this true for only local mode?  We made some changes so it should work in distributed mode, but it is best effort, and not guaranteed to happen.
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50277718
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/TridentCollector.java ---
    @@ -20,7 +20,33 @@
     import java.util.List;
     
     
    +/**
    + * Interface for publishing tuples to a stream and reporting exceptions (to be displayed in Storm UI).
    + *
    + * Trident components that have the ability to emit tuples to a stream are passed an instance of this
    + * interface.
    + *
    + * For example, to emit a new tuple to a stream, you would do something like the following:
    + *
    + * ```java
    + *      collector.emit(new Values("a", "b", "c"));
    + * ```
    + * @see storm.trident.Stream
    + * @see backtype.storm.tuple.Values
    --- End diff --
    
    Links need org.apache here too.
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50278349
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/TridentCollector.java ---
    @@ -20,7 +20,33 @@
     import java.util.List;
     
     
    +/**
    + * Interface for publishing tuples to a stream and reporting exceptions (to be displayed in Storm UI).
    + *
    + * Trident components that have the ability to emit tuples to a stream are passed an instance of this
    + * interface.
    + *
    + * For example, to emit a new tuple to a stream, you would do something like the following:
    + *
    + * ```java
    + *      collector.emit(new Values("a", "b", "c"));
    + * ```
    + * @see storm.trident.Stream
    + * @see backtype.storm.tuple.Values
    + */
     public interface TridentCollector {
    +    /**
    +     * Emits a tuple to a Stream
    +     * @param values a list of values of which the tuple will be composed
    +     */
         void emit(List<Object> values);
    +
    +    /**
    +     * Reports an error. The corresponding stack trace will be visible in the Storm UI.
    +     *
    +     * Note that calling this method does not alter the processing of a batch. To explicitly fail a batch and trigger
    +     * a replay, components should throw {@link backtype.storm.topology.FailedException}.
    --- End diff --
    
    Link here too
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50278465
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/builtin/FirstN.java ---
    @@ -28,6 +28,11 @@
     import org.apache.storm.trident.tuple.TridentTuple;
     
     
    +/**
    + *
    + * An {@link storm.trident.operation.Assembly} implementation
    --- End diff --
    
    org.apache.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/1029#issuecomment-173263005
  
    Looks good over all.  Just a few comments about org.apache.storm instead or backtype.storm and storm.trident
    
    Also one question about cleanup that I think needs to be updated.
, Github user ptgoetz commented on the pull request:

    https://github.com/apache/storm/pull/1029#issuecomment-173290288
  
    Sorry for the package renaming noise. I missed a commit.
, Github user ptgoetz commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50288291
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Operation.java ---
    @@ -20,7 +20,26 @@
     import java.io.Serializable;
     import java.util.Map;
     
    +/**
    + * Parent interface for Trident `Filter`s and `Function`s.
    + *
    + * `Operation` defines two lifecycle methods for Trident components. The `prepare()` method is called once when the
    + * `Operation` is first initialized. The `cleanup()` method is called in local mode when the local cluster is
    + * being shut down.
    + */
     public interface Operation extends Serializable {
    +    /**
    +     * Called when the `Operation` is first initialized.
    +     * @param conf the Storm configuration map
    +     * @param context the operation context which provides information such as the number of partitions in the stream,
    +     *                and the current partition index. It also provides methods for registering operation-specific
    +     *                metrics.
    +     * @see storm.trident.operation.TridentOperationContext
    +     */
         void prepare(Map conf, TridentOperationContext context);
    +
    +    /**
    +     * When running in local mode, called when the local cluster is being shut down.
    --- End diff --
    
    Good catch. I'll fix this.
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50577550
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Operation.java ---
    @@ -20,7 +20,26 @@
     import java.io.Serializable;
     import java.util.Map;
     
    +/**
    + * Parent interface for Trident `Filter`s and `Function`s.
    + *
    + * `Operation` defines two lifecycle methods for Trident components. The `prepare()` method is called once when the
    + * `Operation` is first initialized. The `cleanup()` method is called in local mode when the local cluster is
    + * being shut down.
    + */
     public interface Operation extends Serializable {
    +    /**
    +     * Called when the `Operation` is first initialized.
    +     * @param conf the Storm configuration map
    +     * @param context the operation context which provides information such as the number of partitions in the stream,
    +     *                and the current partition index. It also provides methods for registering operation-specific
    +     *                metrics.
    +     * @see storm.trident.operation.TridentOperationContext
    +     */
         void prepare(Map conf, TridentOperationContext context);
    +
    +    /**
    +     * When running in local mode, called when the local cluster is being shut down.
    --- End diff --
    
    ping? I am +1 after this is fixed
, Github user revans2 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1029#discussion_r50577719
  
    --- Diff: storm-core/src/jvm/org/apache/storm/trident/operation/Operation.java ---
    @@ -20,7 +20,26 @@
     import java.io.Serializable;
     import java.util.Map;
     
    +/**
    + * Parent interface for Trident `Filter`s and `Function`s.
    + *
    + * `Operation` defines two lifecycle methods for Trident components. The `prepare()` method is called once when the
    + * `Operation` is first initialized. The `cleanup()` method is called in local mode when the local cluster is
    + * being shut down.
    + */
     public interface Operation extends Serializable {
    +    /**
    +     * Called when the `Operation` is first initialized.
    +     * @param conf the Storm configuration map
    +     * @param context the operation context which provides information such as the number of partitions in the stream,
    +     *                and the current partition index. It also provides methods for registering operation-specific
    +     *                metrics.
    +     * @see storm.trident.operation.TridentOperationContext
    +     */
         void prepare(Map conf, TridentOperationContext context);
    +
    +    /**
    +     * When running in local mode, called when the local cluster is being shut down.
    --- End diff --
    
    Never mind this is fine.  I missed the fix somehow.
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/1029#issuecomment-174016131
  
    +1
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/1029#issuecomment-174048104
  
    @ptgoetz can I assume that you want this in 1.x as well?
, Github user ptgoetz commented on the pull request:

    https://github.com/apache/storm/pull/1029#issuecomment-174062054
  
    @revans2 Yes, please.
, Github user asfgit closed the pull request at:

    https://github.com/apache/storm/pull/1029
, Github user revans2 commented on the pull request:

    https://github.com/apache/storm/pull/1029#issuecomment-174067689
  
    @ptgoetz I merged this to master and 1.x-branch but I am not going to resolve the JIRA because like you said you are not done yet, and there is more to do for this.
]