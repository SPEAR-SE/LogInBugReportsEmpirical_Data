[GitHub user HeartSaVioR opened a pull request:

    https://github.com/apache/storm/pull/1362

    STORM-1731 Avoid looking up debug / backpressure enable flags within critical path

    This pull request is on top of STORM-1729 (#1361) to avoid merge conflicts.
    
    Even though we set topology.debug to false, we actually hit performance decrement at lookup flag.
    I'm curious why we didn't know about this... :(
    
    Let me summary the performance improvements with BasicTopology:
    
    || Patch || emitted/sec (around) ||
    | STORM 1.0.1-SNAPSHOT | 860,000 |
    | STORM-1729 | 940,000~960,000 |
    | STORM-1731 (including STORM-1729) | 1,500,000 ~ 1,600,000 |
    
    Nearly 2x improvement observed from the start.
    
    I measured the number with my dev. machine so numbers could be a bit unstable.
    I really appreciated if someone takes a benchmark with stable environment and stable way and posts the number.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/HeartSaVioR/storm STORM-1731-1.x

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/1362.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1362
    
----
commit ae78815e6ad27e2301d80c258f4ad535fa1193ff
Author: Jungtaek Lim <kabhwan@gmail.com>
Date:   2016-04-26T03:53:38Z

    STORM-1729 Get rid of reflections while recording stats
    
    * define MultiCount/LatencyStatAndMetric in let statement and set type hint to there

commit 7a15ebc57300a027f10a65046c85e9d1d0bef4dc
Author: Jungtaek Lim <kabhwan@gmail.com>
Date:   2016-04-26T10:29:44Z

    STORM-1731 Avoid looking up debug / backpressure enable flags within critical path
    
    * preload the value of flags and use that value
      * topology.debug
      * topology.backpressure.enable
    * also remove unnecessary lookup: receive-queue

----
, Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214781229
  
    I've done performance comparison test with ThroughputVsLatency with one machine.
    
    * disruptor batching size is set to default (100 / timeout 1ms)
    
    throughput | version | min | max | mean | stddev | 99% | 99.9%
    ---- | ---- | ---- | ---- | ---- | ---- | ---- | ----
    10000 | before patch | 9,437,184 | 23,609,343 | 16,875,865.63 | 1,342,051.21 | 19,611,647 | 20,987,903
    10000 | STORM-1731 | 9,273,344 | 23,609,343 | 16,639,346.99 | 1,401,096.42 | 19,333,119 | 20,660,223
    22000 | before patch | 9,134,080 | 157,155,327 | 18,968,494.02 | 13,125,204.89 | 95,551,487 | 27,729,663
    22000 | STORM-1731 | 8,871,936 | 27,869,183 | 16,865,395.47 | 1,306,652.91 | 19,660,799 | 21,233,663
    
    At throughput 22,000, latency increases steeply from version 'before patch', but latency increases relatively really small from version 'STORM-1731'.
    
    I will go on tests with throughput 25000, 30000 and post the results, too.
, Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214815353
  
    I found at throughput 22,000 current 1.x-branch doesn't keep up the SLA at some moment.
    
    ```
    uptime:  181 acked:   678,400 acked/sec:  22,613.33 failed:        0 99%:      88,866,815 99.9%:     119,668,735 min:       9,134,080 max:     154,402,815 mean:   18,610,826.60 stddev:   11,680,541.13 user:    110,933 sys:     37,832 gc:        375 mem:     499.06
    uptime:  211 acked:   413,040 acked/sec:  13,768.00 failed:        0 99%:      93,126,655 99.9%:     129,564,671 min:       9,093,120 max:     168,820,735 mean:   18,817,505.02 stddev:   12,642,217.74 user:    111,099 sys:     37,859 gc:        377 mem:     432.22
    uptime:  241 acked:   678,720 acked/sec:  22,624.00 failed:        0 99%:     102,105,087 99.9%:     189,267,967 min:       9,117,696 max:     237,109,247 mean:   19,483,050.58 stddev:   15,679,529.59 user:    111,690 sys:     38,045 gc:        526 mem:     479.78
    ```
    
    I guess it cannot keep up throughput higher than 22,000. Keeping up throughput 20,000 seems fine.
    
    throughput | version | min | max | mean | stddev | 99% | 99.9%
    ---- | ---- | ---- | ---- | ---- | ---- | ---- | ----
    20000 | before patch | 9,150,464 | 140,378,111 | 17,525,115.09 | 6,993,362.18 | 57,769,983 | 101,187,583
    
    So I guess current 1.x-branch can keep up with throughput around 20000 ~ 22000. That's it.
    
    I excluded current 1.x-branch and continue testing.
    
    throughput | version | min | max | mean | stddev | 99% | 99.9%
    ---- | ---- | ---- | ---- | ---- | ---- | ---- | ----
    30000 | STORM-1731 | 7,729,152 | 58,359,807 | 15,619,704.64 | 1,665,745.05 | 19,824,639 | 27,738,111
    35000 | STORM-1731 | 9,035,776 | 114,032,639 | 17,340,166.53 | 5,343,955.29 | 40,009,727 | 71,368,703
    
    At throughput 35,000 STORM-1731 doesn't keep up the SLA at some moment.
    ```
    uptime:  211 acked: 1,132,000 acked/sec:  37,733.33 failed:        0 99%:      36,470,783 99.9%:      63,438,847 min:       8,089,600 max:     105,316,351 mean:   16,146,505.98 stddev:    4,753,921.20 user:    153,736 sys:     58,653 gc:        653 mem:     707.02
    uptime:  241 acked:   737,120 acked/sec:  24,570.67 failed:        0 99%:      34,897,919 99.9%:      67,108,863 min:       8,781,824 max:     114,753,535 mean:   16,564,099.80 stddev:    4,599,850.66 user:    155,660 sys:     58,905 gc:        645 mem:     853.44
    uptime:  272 acked: 1,105,560 acked/sec:  35,663.23 failed:        0 99%:      40,009,727 99.9%:      71,368,703 min:       9,035,776 max:     114,032,639 mean:   17,340,166.53 stddev:    5,343,955.29 user:    156,610 sys:     57,884 gc:        664 mem:     678.84
    ```
    
    So I guess STORM-1731 can keep up with throughput around 30000 ~ 35000.
    
    Btw, let's compare the numbers when they doesn't keep up throughput SLA.
    
    throughput | version | min | max | mean | stddev | 99% | 99.9%
    ---- | ---- | ---- | ---- | ---- | ---- | ---- | ----
    22000 | before patch | 9,134,080 | 157,155,327 | 18,968,494.02 | 13,125,204.89 | 95,551,487 | 127,729,663
    35000 | STORM-1731 | 9,035,776 | 114,032,639 | 17,340,166.53 | 5,343,955.29 | 40,009,727 | 71,368,703
    
    STORM-1731 with throughput 35000 still has low latency compared to 1.x-branch with throughput 22000. I'd like to conclude that STORM-1731 ensures similar or over than 13,000 higher throughput SLA compared to 1.x-branch in my test environment.
, Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214815773
  
    Attaching full numbers,
    [throughput-vs-latency-tests-20160427.txt](https://github.com/apache/storm/files/237120/throughput-vs-latency-tests-20160427.txt)

, Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214926340
  
    New observation here: 
    Most of lines came from authentication feature introduced at 0.10.0. In other word, this performance hit is introduced at Apache Storm 0.10.0, and IMO it's a kind of 'performance regressionâ€™, not 'performance improvement'.
, GitHub user HeartSaVioR opened a pull request:

    https://github.com/apache/storm/pull/1364

    STORM-1731 (0.10.x) Avoid looking up debug / backpressure enable flags within critical path

    * preload the value of flags and use that value
      * topology.debug
    
    Pull request for 1.x version is here: #1362 
    I don't take performance tests on this pull request, since #1362 shows the benefit.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/HeartSaVioR/storm STORM-1731-0.10.x-branch

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/1364.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1364
    
----
commit 1cc5228e3195826836e353342407fea290ea9122
Author: Jungtaek Lim <kabhwan@gmail.com>
Date:   2016-04-27T01:03:04Z

    STORM-1731 Avoid looking up debug / backpressure enable flags within critical path
    
    * preload the value of flags and use that value
      * topology.debug

----
, Github user roshannaik commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214948085
  
    Ran the provided topology and a couple minor variations with this cumulative fix. 
    
    Was able to measure a 50% boost in throughput (ACKs/sec)  on the 1.x-branch. Also verified that the event logging feature continues to work correctly.
    
    I used Topology level ACKs/sec from the UI instead of emits/sec since IMO its a better metric to gauge throughput.
    
    **1.x-branch:**   ACK/s =   226,473  & Latency = 4.5ms
    **With fixes:**    ACK/s =   341,454  & Latency =  3.47ms

, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/1364#issuecomment-214956239
  
    +1
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214956338
  
    +1.
, Github user unsleepy22 commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214960183
  
    +1
, Github user hustfxj commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-214968261
  
    it's amazing, +1
, Github user satishd commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-215020195
  
    +1. Nice to remove unnecessary lookups in critical paths.
    
    [worker.clj#L768](https://github.com/apache/storm/blob/1.x-branch/storm-core/src/clj/org/apache/storm/daemon/worker.clj#L768)
    HashMap instance is received in [config.clj#L76](https://github.com/apache/storm/blob/1.x-branch/storm-core/src/clj/org/apache/storm/config.clj#L76) from `Utils/readStormConfig` and converts that into clojure's `PersistentHashMap` while `clojurify-structure` is done. This map is merged later with other configs. This is all done when a worker is initialized. Clojure's `PersistentHashMap` is based on _Hash Array Mapped Trie_ which can have performance issues in critical paths for adding elements but lookups may not cost much more than java's `HashMap` which uses an array with RB tree.
    
     
, Github user vesense commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-215084353
  
    +1 Great Finding.
, Github user vesense commented on the pull request:

    https://github.com/apache/storm/pull/1364#issuecomment-215084480
  
    +1 Great Finding.
, Github user ptgoetz commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-215150674
  
    +1
, Github user asfgit closed the pull request at:

    https://github.com/apache/storm/pull/1364
, Github user asfgit closed the pull request at:

    https://github.com/apache/storm/pull/1362
, Thanks [~kabhwan]. Merged to 1.x-branch and 0.10.x-branch., Github user roshannaik commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-215217692
  
    @satishd i had seen a clojure blog where the author believed clojure maps are very efficient (and even faster than the Java map) for read-only operations .. but didnt provide any numbers substantiate it.  IMO it does not appear to be an accurate claim and Java HashMap would hold up much better (relatively) even in critical paths.. those clojure lookups sometimes lead to reflection.
, Github user HeartSaVioR commented on the pull request:

    https://github.com/apache/storm/pull/1362#issuecomment-215264278
  
    @satishd @roshannaik 
    Yeah, I guess we should know about the whole things affecting performance as Storm claims very high performance, but we don't, and there's small materials to refer for Clojure.
    That's another point of why we should move outside of Clojure or even we should implement critical path to Java or at least other well-known and popular JVM languages (I mean Scala).
]