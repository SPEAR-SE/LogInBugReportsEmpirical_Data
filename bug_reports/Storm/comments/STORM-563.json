[GitHub user harshach opened a pull request:

    https://github.com/apache/storm/pull/321

    STORM-563. Kafka Spout doesn't pick up from the beginning of the queue unless forceFromStart specified.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/harshach/incubator-storm STORM-563

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/321.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #321
    
----
commit ecfa7d0825ca0c8e01ed1f97774015c1dd509d65
Author: Sriharsha Chintalapani <mail@harsha.io>
Date:   2014-11-20T01:07:27Z

    STORM-563. Kafka Spout doesn't pick up from the beginning of the queue unless forceFromStart specified.

----
, Github user nathanmarz commented on the pull request:

    https://github.com/apache/storm/pull/321#issuecomment-63757949
  
    That doesn't look right. That change makes the if statement there meaningless. That method should just be removed, and the other getOffset method should be changed to:
    
    ```
    public static long getOffset(SimpleConsumer consumer, String topic, int partition, Long startOffsetTime) {
       if(startOffsetTime==null) startOffsetTime = kafka.api.OffsetRequest.LatestTime();
       // the rest the same
    ```
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/321#issuecomment-63761302
  
    @nathanmarz  rethinking a bit on this patch. Having both startOffsetTime and forceFromStart is confusing a bit from user point of view.  If user deploys a topology and doesn't set forceFromStart and by default startOffsetTime is EarliestTime. It doesn't read from the beginning of the queue. 
    If the user sets forceFromStart to true and later kills the topology and redeploys it they must remember to turn off the forceFromStart to start from where they left off.  I'll send a updated patch.
, Is there any progress on this new patch?
It seems to me that the method should logically just do the following, and anything else is just plain confusing.

    public static long getOffset(SimpleConsumer consumer, String topic, int partition, KafkaConfig config) {
        long startOffsetTime = config.startOffsetTime;
        return getOffset(consumer, topic, partition, startOffsetTime);
    }

Also locally altered PartitionManager, as ignoring failure to read position from zookeeper is very dangerous if it makes everything get reprocessed everytime:

        try {
            Map<Object, Object> json = _state.readJSON(path);
            LOG.info("Read partition information from: " + path +  "  --> " + json );
            if (json != null) {
                jsonTopologyId = (String) ((Map<Object, Object>) json.get("topology")).get("id");
                jsonOffset = (Long) json.get("offset");
            }
        } catch (Throwable e) {
            LOG.warn("Error reading and/or parsing at ZkNode: " + path, e);
            // CHANGE HERE: throw this error rather than ignoring it
            throw e;
        }

Am not sure if this is wise or not though (haven't tested it)., Github user kishorvpatil commented on the pull request:

    https://github.com/apache/storm/pull/321#issuecomment-75573879
  
    @harshach would you like to provide update on this?
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/321#issuecomment-75575308
  
    @kishorvpatil  this JIRA will be addressed as part of STORM-650 refactoring.
, Github user harshach closed the pull request at:

    https://github.com/apache/storm/pull/321
, GitHub user harshach opened a pull request:

    https://github.com/apache/storm/pull/493

    STORM-563. Kafka Spout doesn't pick up from the beginning of the queue unless forceFromStart specified.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/harshach/incubator-storm STORM-563-V2

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/493.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #493
    
----
commit d2e10346e58527496bccaeca7b6a1b1d924e7b99
Author: Sriharsha Chintalapani <mail@harsha.io>
Date:   2015-03-30T23:11:22Z

    STORM-563. Kafka Spout doesn't pick up from the beginning of the queue unless forceFromStart specified.

----
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-87875138
  
    @ptgoetz @nathanmarz @revans2  Please take a look at the patch. I renamed forceFromStart to ignoreZkOffsets and users can configure where they want to start based on startOffsetTime .
, Github user Parth-Brahmbhatt commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-88197325
  
    :100: 
, Github user ptgoetz commented on a diff in the pull request:

    https://github.com/apache/storm/pull/493#discussion_r27512587
  
    --- Diff: external/storm-kafka/README.md ---
    @@ -120,6 +120,23 @@ spoutConf.scheme = new SchemeAsMultiScheme(new StringScheme());
     OpaqueTridentKafkaSpout spout = new OpaqueTridentKafkaSpout(spoutConf);
     ```
     
    +### How KafkaSpout stores offsets of a kafka topic and recovers incase of failures
    +
    +As shown in the above KafkaConfig properties , user can control where in the topic they can start reading by setting **KafkaConfig.startOffsetTime.**
    +
    +There are two options **kafka.api.OffsetRequest.EarliestTime()** which makes the KafkaSpout to read from the begining of the topic and 
    --- End diff --
    
    I would also document the actual values of `EarliestTime()` (`-2`) and `LatestTime()` (`-1`), and that it can also be set to a point in time (a la `System.currentTimeMillis()`).
    
    My reasoning behind documenting the values (as opposed to the kafka API constants) is that the start offset time is likely to be specified via configuration (i.e. outside java code). Either that, or add spout constants that would get evaluated to `EarliestTime()`/`LatestTime()` if for some reason those values were ever changed in the Kafka API -- that seems like a less "leaky" solution.
    

, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-88334297
  
    @ptgoetz updated the doc as per your suggestion.  Please take a look.
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-90309348
  
    @ptgoetz  addressed your comments. Can you please take a look at this.
, Github user ptgoetz commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-90313220
  
    It wouldn't hurt to expand on what `System.currentTimeMillis()` means in that context (i.e. if you have a specific time stored in epoch format, you can start from there).
, Github user ptgoetz commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-90320879
  
    That being said, I'm +1.
, Github user asfgit closed the pull request at:

    https://github.com/apache/storm/pull/493
, Github user Renkai commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-135604162
  
    If I set ignoreZkOffsets to true,will a spout recover from failure read from zk offsets or use startOffsetTime?
    How do spout detect it is first started or recover from failure?
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-135625738
  
    @Renkai ignoreZkOffsets is rename of forcefromStart. So if you set ignoreZkOffsets it wil ignore already set offsets in zookeeper and start from the startOffsetTime.
    "How do spout detect it is first started or recover from failure?"
    can you explain bit more on that. 
, Github user Renkai commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-135636635
  
    when ignoreZkOffsets set true and startOffsetTime = kafka.api.OffsetRequest.EarliestTime().
    `workers running` -> `topology shutdown by user and restart` -> `workers will read from earliest time again`
    `workers running` -> `one of workers shutdown by accident and supervisor restart the worker` -> `what offset will the restarted worker read from?`
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-135783234
  
    @Renkai In this case yes it won't read from zk offsets. Which is incorrect behavior. Can you file a jira on this.
, Github user Renkai commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-135805891
  
    @harshach  Issue created at https://issues.apache.org/jira/browse/STORM-1017
, Github user harshach commented on the pull request:

    https://github.com/apache/storm/pull/493#issuecomment-135807506
  
    Thanks @Renkai
, [~sriharsha] Due to this changes some off our changes are breaking. We had a following case
1) Our topologies were running for long time suddenly we started getting issue of not enough data to calculates spout lag. 
2) As remediation of this we had to changes consumer group. Changing consumer group caused processing duplicates in Trident.

In KafkaConfig
{code:java}
public long startOffsetTime = OffsetRequest.EarliestTime();
{code}
In doEmitNewPartitionBatch API of storm.kafka.trident.TridentKafkaEmitter, if consumer group is new calls goes to 109 line
{code:java}
  if (lastMeta != null) {
/*  98 */       String lastInstanceId = null;
/*  99 */       Map lastTopoMeta = (Map)lastMeta.get("topology");
/* 100 */       if (lastTopoMeta != null)
/* 101 */         lastInstanceId = (String)lastTopoMeta.get("id");
/*     */       long offset;
/* 103 */       if ((_config.ignoreZkOffsets) && (!_topologyInstanceId.equals(lastInstanceId))) {
/* 104 */         offset = KafkaUtils.getOffset(consumer, _config.topic, partition, _config.startOffsetTime);
/*     */       } else {
/* 106 */         offset = ((Long)lastMeta.get("nextOffset")).longValue();
/*     */       }
/*     */     } else {
/* 109 */      offset = KafkaUtils.getOffset(consumer, _config.topic, partition, _config);
/*     */     }
{code}
Which calls below API. As you can see this call will fetch earliest data rather than fetching latest
{code:java}
public static long getOffset(SimpleConsumer consumer, String topic, int partition, KafkaConfig config)
{
  long startOffsetTime = config.startOffsetTime;
    return getOffset(consumer, topic, partition, startOffsetTime);
}
{code}
How it should be (It was there in previous release 0.9.x)
{code:java}
public static long getOffset(SimpleConsumer consumer, String topic, int partition, KafkaConfig config) {
        long startOffsetTime = kafka.api.OffsetRequest.LatestTime();

        if ( config.ignoreZkOffsets) {
            startOffsetTime = config.startOffsetTime;
        }
        return getOffset(consumer, topic, partition, startOffsetTime);
    }
{code}

Why do you think Spout should pick up from beginning? It should pick up only when specified. This changes will also allow user if he wants to ignore zkoffset & read data from particular time. 

 ]