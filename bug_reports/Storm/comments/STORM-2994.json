[You've listed 1.1.0 and 1.1.2 as affected versions. Could you elaborate on which version your storm-kafka-client dependency is?, Hello Stig. This was observed in both versions, but the vast majority of tests I conducted was on 1.1.2. Let me know if you would like to know more details., Ok, thanks. I'm asking because the debug log you posted is definitely from 1.1.0, and versions prior to 1.0.6, 1.1.2 or 1.2.0 are known to suffer from a number of issues.

Your best bet to figure out what's going on would be to enable trace logging for this class https://github.com/apache/storm/blob/v1.1.2/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/internal/OffsetManager.java. The log you posted is here https://github.com/apache/storm/blob/v1.1.2/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/internal/OffsetManager.java#L156, and if you enable trace logging, the class will log all the message offsets that are pending commit. That should make it pretty easy to spot why the messages can't be committed. 

You might also want to look at trace logging for https://github.com/apache/storm/blob/v1.1.2/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutRetryExponentialBackoff.java#L264, and the KafkaSpout class itself.

Regarding the different Kafka versions, I took a quick look at the release notes for Kafka 0.10.2.0 and 0.10.2.1, and noticed https://issues.apache.org/jira/browse/KAFKA-4547. The spout uses kafkaConsumer.position a bunch, so maybe that's the issue? I believe the Kafka consumer is backwards compatible with older brokers https://cwiki.apache.org/confluence/display/KAFKA/KIP-97%3A+Improved+Kafka+Client+RPC+Compatibility+Policy. Could you try running your topology with the kafka-client dependency set to 0.10.2.1 against your 0.10.1.1 Kafka cluster, and see if that resolves the issue?, Thank you for your suggestions and for you time.

I was already using kafka-clients 0.10.2.1, so that shouldn't be the cause.

It seems the are pending messages in the Spout, i.e., acked but not commited

 

 
{code:java}
2018-03-14T21:19:16.348Z o.a.s.k.s.KafkaSpout [TRACE] - No offsets to commit. KafkaSpout{acked={sample.topic-0=OffsetManager{topic-partition=sample.topic-0, fetchOffset=32592, committedOffset=32591, ackedMsgs=[{topic-partition=sample.topic-0, offset=32802, numFails=0}, {topic-partition=sample.topic-0, offset=32803, numFails=0}, {topic-partition=sample.topic-0, offset=32805, numFails=0}, {topic-partition=sample.topic-0, offset=32806, numFails=0}, {topic-partition=sample.topic-0, offset=32807, numFails=0}, {topic-partition=sample.topic-0, offset=32809, numFails=0}, {topic-partition=sample.topic-0, offset=32810, numFails=0}, {topic-partition=sample.topic-0, offset=32811, numFails=0}, {topic-partition=sample.topic-0, offset=32813, numFails=0}, {topic-partition=sample.topic-0, offset=33243, numFails=0}, {topic-partition=sample.topic-0, offset=33244, numFails=0}, {topic-partition=sample.topic-0, offset=33246, numFails=0}, {topic-partition=sample.topic-0, offset=33247, numFails=0}, {topic-partition=sample.topic-0, offset=33248, numFails=0}, {topic-partition=sample.topic-0, offset=33250, numFails=0}]}}, emitted=[]}


2018-03-14T21:19:16.348Z o.a.s.k.s.i.OffsetManager [TRACE] - OffsetManager{topic-partition=sample.topic-0, fetchOffset=32592, committedOffset=32591, ackedMsgs=[{topic-partition=sample.topic-0, offset=32802, numFails=0}, {topic-partition=sample.topic-0, offset=32803, numFails=0}, {topic-partition=sample.topic-0, offset=32805, numFails=0}, {topic-partition=sample.topic-0, offset=32806, numFails=0}, {topic-partition=sample.topic-0, offset=32807, numFails=0}, {topic-partition=sample.topic-0, offset=32809, numFails=0}, {topic-partition=sample.topic-0, offset=32810, numFails=0}, {topic-partition=sample.topic-0, offset=32811, numFails=0}, {topic-partition=sample.topic-0, offset=32813, numFails=0}, {topic-partition=sample.topic-0, offset=33243, numFails=0}, {topic-partition=sample.topic-0, offset=33244, numFails=0}, {topic-partition=sample.topic-0, offset=33246, numFails=0}, {topic-partition=sample.topic-0, offset=33247, numFails=0}, {topic-partition=sample.topic-0, offset=33248, numFails=0}, {topic-partition=sample.topic-0, offset=33250, numFails=0}]}

2018-03-14T21:19:16.348Z o.a.s.k.s.i.OffsetManager [DEBUG] - topic-partition [sample.topic-0] has NO offsets ready to be committed


2018-03-14T21:19:16.348Z o.a.s.k.s.i.OffsetManager [DEBUG] - topic-partition [sample.topic-0] has non-continuous offset [32802]. It will be processed in a subsequent batch.
{code}
 I would expect them to be retried, however can't see any retry effort in the in the logs:


{code:java}
2018-03-14T21:22:54.091Z o.a.s.k.s.KafkaSpoutRetryExponentialBackoff [DEBUG] - Topic partitions with entries ready to be retried [[]]
{code}

Do you think this is similar to STORM-2639 ?

 , The version you are using which is producing those logs is 1.1.0, where e.g. STORM-2639 is not fixed. Please switch to 1.1.2 and post those logs, they are much easier to debug., Sorry, I had switched back to stom-kafka-client to 1.1.0 for a test and forgot to undo.

storm-kafka-clients 1.1.2 logs:

 

(Note: the message was expected not be emitted by the Spout, hence the "Not emitting null tuple")
{code:java}
2018-03-14T23:06:50.777Z o.a.k.c.c.i.Fetcher [TRACE] - Skipping fetch for partition sample.topic-0 because the
re is an in-flight request to worker:9092 (id: 1 rack: null)
2018-03-14T23:06:50.777Z o.a.k.c.NetworkClient [TRACE] - Completed receive from node 1, for key 1, received {throttle_time_ms=0,resp
onses=[{topic=sample.topic,partition_responses=[{partition_header={partition=0,error_code=0,high_watermark=38785}
,record_set=[(offset=38781,record=Record(magic = 0, attributes = 0, compression = NONE, crc = 1115540089, key = 3 bytes, value = 285 by
tes)), (offset=38782,record=Record(magic = 0, attributes = 0, compression = NONE, crc = 1115540089, key = 3 bytes, value = 285 bytes)),
(offset=38783,record=Record(magic = 0, attributes = 0, compression = NONE, crc = 1115540089, key = 3 bytes, value = 285 bytes)), (offs
et=38784,record=Record(magic = 0, attributes = 0, compression = NONE, crc = 1115540089, key = 3 bytes, value = 285 bytes))]}]}]}
2018-03-14T23:06:50.777Z o.a.s.k.s.KafkaSpoutRetryExponentialBackoff [DEBUG] - Topic partitions with entries ready to be retried [{}
] 
2018-03-14T23:06:50.777Z o.a.k.c.c.i.Fetcher [TRACE] - Adding fetched record for partition sample.topic-0 with
offset 38781 to buffered record list
2018-03-14T23:06:50.777Z o.a.k.c.c.i.Fetcher [TRACE] - Received 4 records in fetch response for partition sample.topic-0 with offset 38781
2018-03-14T23:06:50.777Z o.a.k.c.c.i.Fetcher [TRACE] - Returning fetched records at offset 38781 for assigned partition sample.topic-0 and update position to 38785
2018-03-14T23:06:50.777Z o.a.k.c.c.i.Fetcher [DEBUG] - Ignoring fetched records for sample.topic-0 at offset 3
8781 since the current position is 38785
2018-03-14T23:06:50.777Z o.a.k.c.c.i.Fetcher [TRACE] - Added fetch request for partition sample.topic-0 at off
set 38785 to node worker:9092 (id: 1 rack: null)
2018-03-14T23:06:50.777Z o.a.k.c.c.i.Fetcher [DEBUG] - Sending fetch for partitions [sample.topic-0] to broker
worker:9092 (id: 1 rack: null)
2018-03-14T23:06:50.777Z o.a.k.c.NetworkClient [TRACE] - Sending {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,top
ics=[{topic=sample.topic,partitions=[{partition=0,fetch_offset=38785,max_bytes=1048576}]}]} to node 1.
2018-03-14T23:06:50.777Z o.a.s.k.s.KafkaSpout [DEBUG] - Polled [4] records from Kafka
2018-03-14T23:06:50.778Z o.a.s.k.s.KafkaSpoutRetryExponentialBackoff [DEBUG] - Topic partitions with entries ready to be retried [{}
] 

2018-03-14T23:06:50.779Z o.a.s.k.s.KafkaSpout [DEBUG] - Not emitting null tuple for record [ConsumerRecord(topic = sample.topic, partition = 0, offset = 38781, NoTimestampType = -1, checksum = 1115540089, serialized key size = 3, serialized value size = 285, key = 123, value = {"id":"100"})] as defined in configuration.
2018-03-14T23:06:50.779Z o.a.s.k.s.KafkaSpout [DEBUG] - Received direct ack for message [{topic-partition=sample.topic-0, offset=38781, numFails=0, emitted=false}], associated with null tuple
2018-03-14T23:06:50.779Z o.a.s.k.s.KafkaSpoutRetryExponentialBackoff [DEBUG] - Topic partitions with entries ready to be retried [{}] 
2018-03-14T23:06:50.779Z o.a.s.k.s.KafkaSpoutRetryExponentialBackoff [DEBUG] - Topic partitions with entries ready to be retried [{}] 
2018-03-14T23:06:50.780Z o.a.s.k.s.KafkaSpout [DEBUG] - Not emitting null tuple for record [ConsumerRecord(topic = sample.topic, partition = 0, offset = 38782, NoTimestampType = -1, checksum = 1115540089, serialized key size = 3, serialized value size = 285, key = 123, value = {"id":"100"})] as defined in configuration.
2018-03-14T23:06:50.780Z o.a.s.k.s.KafkaSpout [DEBUG] - Received direct ack for message [{topic-partition=sample.topic-0, offset=38782, numFails=0, emitted=false}], associated with null tuple
2018-03-14T23:06:50.958Z o.a.s.k.s.KafkaSpout [TRACE] - No offsets to commit. KafkaSpout{offsetManagers ={}, emitted=[]}
2018-03-14T23:06:50.958Z o.a.s.k.s.KafkaSpoutRetryExponentialBackoff [DEBUG] - Topic partitions with entries ready to be retried [{}]

{code}
 

 , I've been injecting in the Kafka topic two types of messages
 * messages that are incorrect and won't be emitted by the Spout
 * messages that are correct and will be emitted by the Spout

Using storm-kafka-clients 1.1.0, even the messages that are emitted pile up and aren't commited

 

 
{code:java}
2018-03-15T12:22:25.880Z o.a.s.k.s.KafkaSpout [DEBUG] - Polled [0] records from Kafka. [1379] uncommitted offsets across all topic partitions

{code}
The incorrect messages aren't added to the total of uncommitted messages.

Using storm-kafka-clients 1.1.2, the behaviour is different.

I uploaded the same topology, bumping storm-kafka-clients to 1.1.2, picking up the previous lag of > 14000 and reducing it to ~3000.
 It didn't go to 0 and stayed firmly in that level.
 Once I started injecting correct messages, eventually all messages are committed (not sure at this point if it is when he commit interval elapses)

Question:

Aren't the tuples for which 
{code:java}
List<Object> apply(ConsumerRecord<K,V> record);
{code}
 returns null, supposed the be added to the list of uncommited offsets?

 

 , Yes, I think that's the bug. Nice find. Seems like there was a mistake when adding the null filtering code. See https://github.com/apache/storm/blob/v1.2.1/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L602. 

Just going to give a quick summary of how we got to this code, and what I think is wrong.

Originally the offset manager simply kept track of acked tuples, and committed tuples once there was a complete sequence of acked tuples to commit (e.g. if 1,2,3,5,6 were acked, the offset manager would commit 1,2,3 and wait for 4 to be acked). A later PR added support for topic compaction, i.e. topics where an offset sequence might look like 1,2,3,5,6, with offset 4 missing entirely. The offset manager now allows skipping offset 4 if it is known that it was never emitted by the spout.

When null tuple filtering was added, I think this functionality wasn't kept in mind. When a null tuple is filtered out, it's just discarded without being added to the offset manager emitted list, or the acked list. The result seems to be that the offset manager is never told about the null tuples, so won't commit them either. When the next non-null tuple gets acked, the offset manager is told about it. From the offset manager's perspective, it now looks like there was a gap of offsets that weren't emitted by the spout, so it reacts by committing past them. Unfortunately this only happens once a non-null tuple is acked, which can take arbitrarily long.

I think the fix should be fairly simple: We add the null filtered tuples to the offset manager acked and emitted lists, so null filtering will behave as if the null tuples were acked immediately. If you'd like to give fixing it a shot, the two places to look would be https://github.com/apache/storm/blob/v1.2.1/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L503 and https://github.com/apache/storm/blob/v1.2.1/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L602. If you don't, let me know and I'll take a look when I get a chance., Thank you for taking the time to look into this. I'll submit a patch ASAP., Great. Added you to the contributors list here, so you should be able to assign the issue to yourself now., Hello,

I've created [https://github.com/apache/storm/pull/2593] for this. Unit tests were missing and I'm adding them.
I'll have limited access to internet for the next days so I'll pick this up again as soon as possible, Thanks [~RAbreu], merged to master, 1.x, 1.1.x and 1.0.x branches. Keep up the good work.]