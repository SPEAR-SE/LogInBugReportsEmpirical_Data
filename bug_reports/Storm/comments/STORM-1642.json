[Is this 100% reproducible?  The NPE is happening because the buffer passed into the {{KryoTupleDeserializer}} and in turn into {{Input}} is null.  This means that the msg placed into a batch had to be null.  With the version fo disruptor that we have in 0.10 it is possible that you emitted sent a null, but I don't know for sure.

I don't see your attached code like you mentioned though.

, I do not know how to reproduce this NPE but it just happens several hours or several days. I've went through storm's code and I don't think it's possible for the msg to be null since the MessageDecoder only returns null when length of payload is zero but it's impossible since the payload   contains like source component id, source task id, etc. This means that even if I emit a null the payload can not be null., It turns out that this is caused by messages sent from machines outside storm cluster. When storm receives a TaskMessage that can not be deserialized, the worker will be shutdown. I'll propose a patch to fix this issue., GitHub user liurenjie1024 opened a pull request:

    https://github.com/apache/storm/pull/1316

    STORM-1642

    This patch aims to fix bug STORM-1642.  When we failed to deserialize a tuple, we should skip this tuple and print a log rather than just shutdown the work.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MediaV/storm STORM-1642

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/storm/pull/1316.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1316
    
----
commit fff27f37be6beb54a67f45071259aa2fb83614e4
Author: liurenjie1024 <liurenjie2008@gmail.com>
Date:   2016-04-06T10:51:00Z

    Bug fix

commit fbfcd8ce31410849f233d617881dc82bed8b9fbd
Author: liurenjie1024 <liurenjie2008@gmail.com>
Date:   2016-04-07T02:19:01Z

    fix build break

----
, Github user abhishekagarwal87 commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-206701464
  
    How was deserialization failure resulting in NPE? Other than that, deserialization failure is the problem with an application itself which application should correct by registering correct serializer/deserializer. storm framework should not skip such tuples on its own. 
, Github user liurenjie1024 commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-206713335
  
    As I have mentioned in bug report, the reason why NPE happens is that storm is vulnerable to fraud message from  processes outside the cluster. To reproduce the NPE, you just need to send a message [taskid 0] to [host]:[port] from anywhere, where taskid is id of one of the tasks running on [host]:[port]. In this case, storm will return a TaskMessage with payload set to null to the deserializer. 
    Storm does not check whether the task message is from processes within the cluster, so deserialization may fail. I  think storm should skip the fruad task message rather than shutdowning the worker when deserialization failed.
, Github user abhishekagarwal87 commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-206724794
  
    I can't think of a reason of why would such a message be sent to storm from outside the cluster. Ideally only cluster machines and daemons should have access to the worker ports. Or if it indeeds needs to be solved, then a better method would be to ignore the zero length payload and not add `new TaskMessage(task, null)`.  Before you make any change, let's wait for comments from someone who is more familiar with this part of code. 
, Github user liurenjie1024 commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-206732733
  
    The reason why such a message is sent is that our security team is scanning all the ports listened on each server and tries to detect potential weakness.
    At first thought I just wanted to ignore messages with zero payload, but I think ignoring messages failed to be deserialized would be more robust. I think this also matches storm's design since it throws away messages whose target task id is not in the worker and this patch is just a complement.
, Github user knusbaum commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1316#discussion_r58954552
  
    --- Diff: storm-core/src/clj/backtype/storm/daemon/executor.clj ---
    @@ -431,13 +431,14 @@
           (fn [tuple-batch sequence-id end-of-batch?]
             (fast-list-iter [[task-id msg] tuple-batch]
               (let [^TupleImpl tuple (if (instance? Tuple msg) msg (.deserialize deserializer msg))]
    -            (when debug? (log-message "Processing received message FOR " task-id " TUPLE: " tuple))
    -            (if task-id
    -              (tuple-action-fn task-id tuple)
    -              ;; null task ids are broadcast tuples
    -              (fast-list-iter [task-id task-ids]
    +            (if tuple
    +              ((when debug? (log-message "Processing received message FOR " task-id " TUPLE: " tuple))
    +              (if task-id
                     (tuple-action-fn task-id tuple)
    -                ))
    +                ;; null task ids are broadcast tuples
    +                (fast-list-iter [task-id task-ids]
    +                  (tuple-action-fn task-id tuple)
    +                  ))))
    --- End diff --
    
    Lots of parenthetical and formatting problems here.
, Github user knusbaum commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-207576535
  
    Why not no both? I don't see any reason to propagate `TaskMessage`s with null payloads, but I agree we should be dropping tuples that failed to deserialize in the iterator. 
    
    This is very much on the critical path, so someone else might want to weigh in.
, Github user liurenjie1024 commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-207660738
  
    NPE is just a special case of deserialization failure, right?
, Github user knusbaum commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-207676736
  
    What do you mean?
    
    If you mean null payloads are a special case, I disagree. In fact, it's not a failure at all. We received a null message, so we can perform a NOP as soon as possible.
, Github user liurenjie1024 commented on the pull request:

    https://github.com/apache/storm/pull/1316#issuecomment-207678155
  
    Yes, I agree with you that we should drop a task message with null payload as soon as possible, and I'll push another commit to drop task messages with null payload.
, Github user gzm55 commented on a diff in the pull request:

    https://github.com/apache/storm/pull/1316#discussion_r71503230
  
    --- Diff: storm-core/src/jvm/backtype/storm/messaging/netty/MessageBatch.java ---
    @@ -112,6 +115,9 @@ private void writeTaskMessage(ChannelBufferOutputStream bout, TaskMessage messag
                 throw new RuntimeException("Task ID should not exceed "+Short.MAX_VALUE);
             
             bout.writeShort((short)task_id);
    +        if (payload_len == 0) {
    +            LOG.warn("Zero length payload to task {}.", (short)task_id);
    --- End diff --
    
    is this a debugging log? should remove them? 
, Hello All,
I am using storm version 1.0.0 and I am still facing the same exception. Can anyone please confirm whether this issue still present in this version. Also what is the possible impact of this issue. Will it automatically get resolved on retry,

java.lang.NullPointerException
	at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:81) ~[kryo-3.0.3.jar:?]
	at org.apache.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:44) ~[storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.messaging.DeserializingConnectionCallback.recv(DeserializingConnectionCallback.java:56) ~[storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.messaging.netty.Server.enqueue(Server.java:133) ~[storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.messaging.netty.Server.received(Server.java:254) ~[storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.messaging.netty.StormServerHandler.messageReceived(StormServerHandler.java:61) ~[storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:310) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) [storm-core-1.0.0.jar:1.0.0]
	at org.apache.storm.shade.org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) [storm-core-1.0.0.jar:1.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_77]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_77]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_77], I've proposed a patch for this issue but the PMC does not accept that.]