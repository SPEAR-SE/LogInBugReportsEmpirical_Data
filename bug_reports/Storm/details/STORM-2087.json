{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13004109","self":"https://issues.apache.org/jira/rest/api/2/issue/13004109","key":"STORM-2087","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":41400,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12314820","id":"12314820","key":"STORM","name":"Apache Storm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12314820&avatarId=21667","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12314820&avatarId=21667","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12314820&avatarId=21667","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12314820&avatarId=21667"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/13260","id":"13260","description":"Apache Storm Related","name":"Storm"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334657","id":"12334657","name":"2.0.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335748","id":"12335748","name":"1.1.0","archived":false,"released":true,"releaseDate":"2017-03-29"}],"aggregatetimespent":41400,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-11-30T10:40:25.313+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Dec 20 07:47:00 UTC 2016","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_8658117707_*|*_5_*:*_1_*:*_0","customfield_12310420":"9223372036854775807","customfield_12312321":null,"resolutiondate":"2016-12-20T07:47:00.556+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-2087/watchers","watchCount":4,"isWatching":false},"created":"2016-09-11T02:45:03.117+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["pull-request-available"],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":0,"aggregatetimeoriginalestimate":null,"customfield_12311120":"STORM-1856","customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334657","id":"12334657","name":"2.0.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335747","id":"12335747","name":"1.0.2","archived":false,"released":true,"releaseDate":"2016-08-10"}],"customfield_12312339":null,"issuelinks":[{"id":"12527478","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12527478","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"13002018","key":"STORM-2077","self":"https://issues.apache.org/jira/rest/api/2/issue/13002018","fields":{"summary":"KafkaSpout doesn't retry failed tuples","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12527477","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12527477","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"13024691","key":"STORM-2229","self":"https://issues.apache.org/jira/rest/api/2/issue/13024691","fields":{"summary":"KafkaSpout does not resend failed tuples","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jfenc91","name":"jfenc91","key":"jfenc91","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Fenchel","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-02-19T19:36:17.125+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12331080","id":"12331080","name":"storm-kafka-client"}],"timeoriginalestimate":null,"description":"I am working with kafka 10 and the storm-kafka-client from master. It appears that tuples are not always being replayed when they are failed.\n\nWith a topology that randomly fails tuples a small percentage of the time I found that the committed kafka offset would get stuck and eventually processing would stop even though the committed offset was no where near the end of the topic. \n\nI have also replicated the issue in unit tests with this PR: \nhttps://github.com/apache/storm/pull/1679\n\nIt seems that increasing the number of times I call nextTuple for the in order case will make it work, but it doesn't seem to help the case where tuples are failed out of order from which they were emitted. ","customfield_10010":null,"timetracking":{"remainingEstimate":"0h","timeSpent":"11.5h","remainingEstimateSeconds":0,"timeSpentSeconds":41400},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"attachment":[],"customfield_12312340":null,"aggregatetimeestimate":0,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Storm-kafka-client: Failed tuples are not always replayed ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jfenc91","name":"jfenc91","key":"jfenc91","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Fenchel","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jfenc91","name":"jfenc91","key":"jfenc91","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Fenchel","active":true,"timeZone":"Etc/UTC"},"customfield_12310291":null,"customfield_12310290":null,"aggregateprogress":{"progress":41400,"total":41400,"percent":100},"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":41400,"total":41400,"percent":100},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/comment/15481263","id":"15481263","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jfenc91","name":"jfenc91","key":"jfenc91","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Fenchel","active":true,"timeZone":"Etc/UTC"},"body":"The fix is now in that PR as well","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jfenc91","name":"jfenc91","key":"jfenc91","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Fenchel","active":true,"timeZone":"Etc/UTC"},"created":"2016-09-11T07:22:51.850+0000","updated":"2016-09-11T07:22:51.850+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/comment/15708199","id":"15708199","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asmaier","name":"asmaier","key":"asmaier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andreas Maier","active":true,"timeZone":"Etc/UTC"},"body":"Is this a duplicate of STORM-2077 ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asmaier","name":"asmaier","key":"asmaier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andreas Maier","active":true,"timeZone":"Etc/UTC"},"created":"2016-11-30T10:40:25.313+0000","updated":"2016-11-30T10:40:25.313+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/comment/15749093","id":"15749093","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"[~asmaier] Yes, as far as I can tell. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2016-12-14T18:42:24.674+0000","updated":"2016-12-14T18:42:24.674+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/comment/15758882","id":"15758882","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kabhwan","name":"kabhwan","key":"kabhwan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jungtaek Lim","active":true,"timeZone":"Asia/Seoul"},"body":"Added to 1.1.0 epic since it's a major bug and patch is available (PR against master is merged.)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kabhwan","name":"kabhwan","key":"kabhwan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jungtaek Lim","active":true,"timeZone":"Asia/Seoul"},"created":"2016-12-18T14:04:16.935+0000","updated":"2016-12-18T14:04:16.935+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/comment/15763548","id":"15763548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kabhwan","name":"kabhwan","key":"kabhwan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jungtaek Lim","active":true,"timeZone":"Asia/Seoul"},"body":"Merged into master and 1.x branches.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kabhwan","name":"kabhwan","key":"kabhwan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jungtaek Lim","active":true,"timeZone":"Asia/Seoul"},"created":"2016-12-20T07:47:00.674+0000","updated":"2016-12-20T07:47:00.674+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-2087/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":88,"worklogs":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/28899","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user jfenc91 commented on the issue:\n\n    https://github.com/apache/storm/pull/1679\n  \n    A larger refactor here is probably needed to make this more performant. These changes understandably seem to make the spout struggle to get the processing tuple count anywhere near the max spout pending. \n","created":"2016-09-13T02:06:39.034+0000","updated":"2016-09-13T02:06:39.034+0000","started":"2016-09-13T02:06:39.034+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"28899","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29329","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79465128\n  \n    --- Diff: external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SingleTopicKafkaSpoutTest.java ---\n    @@ -0,0 +1,248 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + *   or more contributor license agreements.  See the NOTICE file\n    + *   distributed with this work for additional information\n    + *   regarding copyright ownership.  The ASF licenses this file\n    + *   to you under the Apache License, Version 2.0 (the\n    + *   \"License\"); you may not use this file except in compliance\n    + *   with the License.  You may obtain a copy of the License at\n    + *\n    + *   http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + *   Unless required by applicable law or agreed to in writing, software\n    + *   distributed under the License is distributed on an \"AS IS\" BASIS,\n    + *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + *   See the License for the specific language governing permissions and\n    + *   limitations under the License.\n    + */\n    +package org.apache.storm.kafka.spout;\n    +\n    +import info.batey.kafka.unit.KafkaUnitRule;\n    +import kafka.producer.KeyedMessage;\n    +import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n    +import org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration;\n    +import org.apache.storm.spout.SpoutOutputCollector;\n    +import org.apache.storm.task.TopologyContext;\n    +import org.apache.storm.tuple.Values;\n    +import org.junit.Rule;\n    +import org.junit.Test;\n    +import org.mockito.ArgumentCaptor;\n    +\n    +import static org.junit.Assert.*;\n    +\n    +import java.util.Map;\n    +import java.util.stream.IntStream;\n    +import static org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration.*;\n    +import static org.mockito.Mockito.*;\n    +\n    +public class SingleTopicKafkaSpoutTest {\n    +\n    +    @Rule\n    +    public KafkaUnitRule kafkaUnitRule = new KafkaUnitRule();\n    +\n    +\n    +    void populateTopicData(String topicName, int msgCount) {\n    +        kafkaUnitRule.getKafkaUnit().createTopic(topicName);\n    +\n    +        IntStream.range(0, msgCount).forEach(value -> {\n    +            KeyedMessage<String, String> keyedMessage = new KeyedMessage<>(\n    +                    topicName, ((Integer)value).toString(),\n    +                    ((Integer)value).toString());\n    +\n    +            kafkaUnitRule.getKafkaUnit().sendMessages(keyedMessage);\n    +        });\n    +    }\n    +\n    +    private void assertOffset(int offset, KafkaSpout.OffsetEntry entry) {\n    --- End diff --\n    \n    Consider renaming to something more descriptive, like assertOffsetCommitted or something like that. It isn't really obvious from the name what this does\n","created":"2016-09-19T20:09:04.021+0000","updated":"2016-09-19T20:09:04.021+0000","started":"2016-09-19T20:09:04.021+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29329","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29328","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79464164\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -479,16 +487,17 @@ public OffsetAndMetadata findNextCommitOffset() {\n                 KafkaSpoutMessageId nextCommitMsg = null;     // this is a convenience variable to make it faster to create OffsetAndMetadata\n     \n                 for (KafkaSpoutMessageId currAckedMsg : ackedMsgs) {  // complexity is that of a linear scan on a TreeMap\n    -                if ((currOffset = currAckedMsg.offset()) == initialFetchOffset || currOffset == nextCommitOffset + 1) {            // found the next offset to commit\n    +                if ((currOffset = currAckedMsg.offset()) == nextCommitOffset + 1) {            // found the next offset to commit\n                         found = true;\n                         nextCommitMsg = currAckedMsg;\n                         nextCommitOffset = currOffset;\n                     } else if (currAckedMsg.offset() > nextCommitOffset + 1) {    // offset found is not continuous to the offsets listed to go in the next commit, so stop search\n                         LOG.debug(\"topic-partition [{}] has non-continuous offset [{}]. It will be processed in a subsequent batch.\", tp, currOffset);\n                         break;\n                     } else {\n    -                    LOG.debug(\"topic-partition [{}] has unexpected offset [{}].\", tp, currOffset);\n    -                    break;\n    +                    //Received a redundant ack. Ignore and continue processing.\n    +                    LOG.debug(\"topic-partition [{}] has unexpected offset [{}]. Found with message on offset [{}]. Current committed Offset [{}]\",\n    +                            tp, currOffset, currAckedMsg.offset(), committedOffset);\n    --- End diff --\n    \n    Aren't currOffset and currAckedMsg.offset the same here, due to the assignment in L490?\n","created":"2016-09-19T20:09:04.021+0000","updated":"2016-09-19T20:09:04.021+0000","started":"2016-09-19T20:09:04.021+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29328","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29330","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79463551\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -266,26 +266,32 @@ private void doSeekRetriableTopicPartitions() {\n                 if (offsetAndMeta != null) {\n                     kafkaConsumer.seek(rtp, offsetAndMeta.offset() + 1);  // seek to the next offset that is ready to commit in next commit cycle\n                 } else {\n    -                kafkaConsumer.seekToEnd(toArrayList(rtp));    // Seek to last committed offset\n    +                kafkaConsumer.seek(rtp, acked.get(rtp).committedOffset + 1);    // Seek to last committed offset\n                 }\n             }\n         }\n     \n         // ======== emit  =========\n         private void emit() {\n    -        emitTupleIfNotEmitted(waitingToEmit.next());\n    +        //Keep trying to send a tuple when requested\n    +        while(!emitTupleIfNotEmitted(waitingToEmit.next()) && waitingToEmit.hasNext())\n    --- End diff --\n    \n    While I don't think it hurts, I don't see why this is necessary. Storm should call nextTuple repeatedly until something is emitted.\n","created":"2016-09-19T20:09:04.022+0000","updated":"2016-09-19T20:09:04.022+0000","started":"2016-09-19T20:09:04.021+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29330","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29331","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79465571\n  \n    --- Diff: external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SingleTopicKafkaSpoutTest.java ---\n    @@ -0,0 +1,248 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + *   or more contributor license agreements.  See the NOTICE file\n    + *   distributed with this work for additional information\n    + *   regarding copyright ownership.  The ASF licenses this file\n    + *   to you under the Apache License, Version 2.0 (the\n    + *   \"License\"); you may not use this file except in compliance\n    + *   with the License.  You may obtain a copy of the License at\n    + *\n    + *   http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + *   Unless required by applicable law or agreed to in writing, software\n    + *   distributed under the License is distributed on an \"AS IS\" BASIS,\n    + *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + *   See the License for the specific language governing permissions and\n    + *   limitations under the License.\n    + */\n    +package org.apache.storm.kafka.spout;\n    +\n    +import info.batey.kafka.unit.KafkaUnitRule;\n    +import kafka.producer.KeyedMessage;\n    +import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n    +import org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration;\n    +import org.apache.storm.spout.SpoutOutputCollector;\n    +import org.apache.storm.task.TopologyContext;\n    +import org.apache.storm.tuple.Values;\n    +import org.junit.Rule;\n    +import org.junit.Test;\n    +import org.mockito.ArgumentCaptor;\n    +\n    +import static org.junit.Assert.*;\n    +\n    +import java.util.Map;\n    +import java.util.stream.IntStream;\n    +import static org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration.*;\n    +import static org.mockito.Mockito.*;\n    +\n    +public class SingleTopicKafkaSpoutTest {\n    +\n    +    @Rule\n    +    public KafkaUnitRule kafkaUnitRule = new KafkaUnitRule();\n    +\n    +\n    +    void populateTopicData(String topicName, int msgCount) {\n    +        kafkaUnitRule.getKafkaUnit().createTopic(topicName);\n    +\n    +        IntStream.range(0, msgCount).forEach(value -> {\n    +            KeyedMessage<String, String> keyedMessage = new KeyedMessage<>(\n    +                    topicName, ((Integer)value).toString(),\n    --- End diff --\n    \n    The Integer cast seems unnecessary?\n","created":"2016-09-19T20:09:04.022+0000","updated":"2016-09-19T20:09:04.022+0000","started":"2016-09-19T20:09:04.021+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29331","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79463594\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -266,26 +266,32 @@ private void doSeekRetriableTopicPartitions() {\n                 if (offsetAndMeta != null) {\n                     kafkaConsumer.seek(rtp, offsetAndMeta.offset() + 1);  // seek to the next offset that is ready to commit in next commit cycle\n                 } else {\n    -                kafkaConsumer.seekToEnd(toArrayList(rtp));    // Seek to last committed offset\n    +                kafkaConsumer.seek(rtp, acked.get(rtp).committedOffset + 1);    // Seek to last committed offset\n    --- End diff --\n    \n    Nice catch. Is this code being hit by the tests?\n","created":"2016-09-19T20:09:04.022+0000","updated":"2016-09-19T20:09:04.022+0000","started":"2016-09-19T20:09:04.022+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29332","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29334","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79467177\n  \n    --- Diff: external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SingleTopicKafkaSpoutTest.java ---\n    @@ -0,0 +1,248 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + *   or more contributor license agreements.  See the NOTICE file\n    + *   distributed with this work for additional information\n    + *   regarding copyright ownership.  The ASF licenses this file\n    + *   to you under the Apache License, Version 2.0 (the\n    + *   \"License\"); you may not use this file except in compliance\n    + *   with the License.  You may obtain a copy of the License at\n    + *\n    + *   http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + *   Unless required by applicable law or agreed to in writing, software\n    + *   distributed under the License is distributed on an \"AS IS\" BASIS,\n    + *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + *   See the License for the specific language governing permissions and\n    + *   limitations under the License.\n    + */\n    +package org.apache.storm.kafka.spout;\n    +\n    +import info.batey.kafka.unit.KafkaUnitRule;\n    +import kafka.producer.KeyedMessage;\n    +import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n    +import org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration;\n    +import org.apache.storm.spout.SpoutOutputCollector;\n    +import org.apache.storm.task.TopologyContext;\n    +import org.apache.storm.tuple.Values;\n    +import org.junit.Rule;\n    +import org.junit.Test;\n    +import org.mockito.ArgumentCaptor;\n    +\n    +import static org.junit.Assert.*;\n    +\n    +import java.util.Map;\n    +import java.util.stream.IntStream;\n    +import static org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration.*;\n    +import static org.mockito.Mockito.*;\n    +\n    +public class SingleTopicKafkaSpoutTest {\n    +\n    +    @Rule\n    +    public KafkaUnitRule kafkaUnitRule = new KafkaUnitRule();\n    +\n    +\n    +    void populateTopicData(String topicName, int msgCount) {\n    +        kafkaUnitRule.getKafkaUnit().createTopic(topicName);\n    +\n    +        IntStream.range(0, msgCount).forEach(value -> {\n    +            KeyedMessage<String, String> keyedMessage = new KeyedMessage<>(\n    +                    topicName, ((Integer)value).toString(),\n    +                    ((Integer)value).toString());\n    +\n    +            kafkaUnitRule.getKafkaUnit().sendMessages(keyedMessage);\n    +        });\n    +    }\n    +\n    +    private void assertOffset(int offset, KafkaSpout.OffsetEntry entry) {\n    +        boolean currentOffsetMatch = entry.committedOffset == offset;\n    +        OffsetAndMetadata nextOffset = entry.findNextCommitOffset();\n    +        boolean nextOffsetMatch =  nextOffset != null && nextOffset.offset() == offset;\n    +        assertTrue(\"Next offset: \" +\n    +                        entry.findNextCommitOffset() +\n    +                        \", Current offset: \" +\n    +                        entry.committedOffset +\n    +                        \", Desired offset: \" +\n    +                        offset,\n    +                currentOffsetMatch | nextOffsetMatch);\n    +    }\n    +\n    +    @Test\n    +    public void shouldContinueWithSlowDoubleAcks() throws Exception {\n    +        int messageCount = 20;\n    +        populateTopicData(SingleTopicKafkaSpoutConfiguration.topic, messageCount);\n    +        int kafkaPort = kafkaUnitRule.getKafkaPort();\n    +\n    +        TopologyContext topology = mock(TopologyContext.class);\n    +        SpoutOutputCollector collector = mock(SpoutOutputCollector.class);\n    +        Map conf = mock(Map.class);\n    +\n    +        KafkaSpout spout = new KafkaSpout<>(getKafkaSpoutConfig(getKafkaSpoutStreams(), kafkaPort));\n    +        spout.open(conf, topology, collector);\n    +        spout.activate();\n    +\n    +        //play 1st tuple\n    +        ArgumentCaptor<Object> messageIdToDoubleAck = ArgumentCaptor.forClass(Object.class);\n    +        spout.nextTuple();\n    +        verify(collector).emit(anyObject(), anyObject(), messageIdToDoubleAck.capture());\n    +        spout.ack(messageIdToDoubleAck.getValue());\n    +\n    +        IntStream.range(0, messageCount/2).forEach(value -> {\n    +            spout.nextTuple();\n    +        });\n    +\n    +        spout.ack(messageIdToDoubleAck.getValue());\n    --- End diff --\n    \n    Not really sure the spout needs to support double acking.\n","created":"2016-09-19T20:09:04.023+0000","updated":"2016-09-19T20:09:04.023+0000","started":"2016-09-19T20:09:04.023+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29334","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79469916\n  \n    --- Diff: external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SingleTopicKafkaSpoutTest.java ---\n    @@ -0,0 +1,248 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + *   or more contributor license agreements.  See the NOTICE file\n    + *   distributed with this work for additional information\n    + *   regarding copyright ownership.  The ASF licenses this file\n    + *   to you under the Apache License, Version 2.0 (the\n    + *   \"License\"); you may not use this file except in compliance\n    + *   with the License.  You may obtain a copy of the License at\n    + *\n    + *   http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + *   Unless required by applicable law or agreed to in writing, software\n    + *   distributed under the License is distributed on an \"AS IS\" BASIS,\n    + *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + *   See the License for the specific language governing permissions and\n    + *   limitations under the License.\n    + */\n    +package org.apache.storm.kafka.spout;\n    +\n    +import info.batey.kafka.unit.KafkaUnitRule;\n    +import kafka.producer.KeyedMessage;\n    +import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n    +import org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration;\n    +import org.apache.storm.spout.SpoutOutputCollector;\n    +import org.apache.storm.task.TopologyContext;\n    +import org.apache.storm.tuple.Values;\n    +import org.junit.Rule;\n    +import org.junit.Test;\n    +import org.mockito.ArgumentCaptor;\n    +\n    +import static org.junit.Assert.*;\n    +\n    +import java.util.Map;\n    +import java.util.stream.IntStream;\n    +import static org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration.*;\n    +import static org.mockito.Mockito.*;\n    +\n    +public class SingleTopicKafkaSpoutTest {\n    +\n    +    @Rule\n    +    public KafkaUnitRule kafkaUnitRule = new KafkaUnitRule();\n    +\n    +\n    +    void populateTopicData(String topicName, int msgCount) {\n    +        kafkaUnitRule.getKafkaUnit().createTopic(topicName);\n    +\n    +        IntStream.range(0, msgCount).forEach(value -> {\n    +            KeyedMessage<String, String> keyedMessage = new KeyedMessage<>(\n    +                    topicName, ((Integer)value).toString(),\n    +                    ((Integer)value).toString());\n    +\n    +            kafkaUnitRule.getKafkaUnit().sendMessages(keyedMessage);\n    +        });\n    +    }\n    +\n    +    private void assertOffset(int offset, KafkaSpout.OffsetEntry entry) {\n    +        boolean currentOffsetMatch = entry.committedOffset == offset;\n    +        OffsetAndMetadata nextOffset = entry.findNextCommitOffset();\n    +        boolean nextOffsetMatch =  nextOffset != null && nextOffset.offset() == offset;\n    +        assertTrue(\"Next offset: \" +\n    +                        entry.findNextCommitOffset() +\n    +                        \", Current offset: \" +\n    +                        entry.committedOffset +\n    +                        \", Desired offset: \" +\n    +                        offset,\n    +                currentOffsetMatch | nextOffsetMatch);\n    +    }\n    +\n    +    @Test\n    +    public void shouldContinueWithSlowDoubleAcks() throws Exception {\n    +        int messageCount = 20;\n    +        populateTopicData(SingleTopicKafkaSpoutConfiguration.topic, messageCount);\n    +        int kafkaPort = kafkaUnitRule.getKafkaPort();\n    +\n    +        TopologyContext topology = mock(TopologyContext.class);\n    +        SpoutOutputCollector collector = mock(SpoutOutputCollector.class);\n    +        Map conf = mock(Map.class);\n    +\n    +        KafkaSpout spout = new KafkaSpout<>(getKafkaSpoutConfig(getKafkaSpoutStreams(), kafkaPort));\n    +        spout.open(conf, topology, collector);\n    +        spout.activate();\n    +\n    +        //play 1st tuple\n    +        ArgumentCaptor<Object> messageIdToDoubleAck = ArgumentCaptor.forClass(Object.class);\n    +        spout.nextTuple();\n    +        verify(collector).emit(anyObject(), anyObject(), messageIdToDoubleAck.capture());\n    +        spout.ack(messageIdToDoubleAck.getValue());\n    +\n    +        IntStream.range(0, messageCount/2).forEach(value -> {\n    +            spout.nextTuple();\n    +        });\n    +\n    +        spout.ack(messageIdToDoubleAck.getValue());\n    +\n    +        IntStream.range(0, messageCount).forEach(value -> {\n    +            spout.nextTuple();\n    +        });\n    +\n    +        ArgumentCaptor<Object> remainingIds = ArgumentCaptor.forClass(Object.class);\n    +\n    +        verify(collector, times(messageCount)).emit(\n    +                eq(SingleTopicKafkaSpoutConfiguration.stream),\n    +                anyObject(),\n    +                remainingIds.capture());\n    +        remainingIds.getAllValues().iterator().forEachRemaining(spout::ack);\n    +\n    +        spout.acked.values().forEach(item -> {\n    +            assertOffset(messageCount - 1, (KafkaSpout.OffsetEntry) item);\n    +        });\n    +    }\n    +\n    +    @Test\n    +    public void shouldEmitAllMessages() throws Exception {\n    +        int messageCount = 10;\n    +        populateTopicData(SingleTopicKafkaSpoutConfiguration.topic, messageCount);\n    +        int kafkaPort = kafkaUnitRule.getKafkaPort();\n    +\n    +        TopologyContext topology = mock(TopologyContext.class);\n    +        SpoutOutputCollector collector = mock(SpoutOutputCollector.class);\n    +        Map conf = mock(Map.class);\n    +\n    +        KafkaSpout spout = new KafkaSpout<>(getKafkaSpoutConfig(getKafkaSpoutStreams(), kafkaPort));\n    +        spout.open(conf, topology, collector);\n    +        spout.activate();\n    +\n    +        IntStream.range(0, messageCount).forEach(value -> {\n    +            spout.nextTuple();\n    +            ArgumentCaptor<Object> messageId = ArgumentCaptor.forClass(Object.class);\n    +            verify(collector).emit(\n    +                    eq(SingleTopicKafkaSpoutConfiguration.stream),\n    +                    eq(new Values(SingleTopicKafkaSpoutConfiguration.topic,\n    +                            ((Integer)value).toString(),\n    +                            ((Integer)value).toString())),\n    +                    messageId.capture());\n    +            spout.ack(messageId.getValue());\n    +            reset(collector);\n    +        });\n    +\n    +        spout.acked.values().forEach(item -> {\n    +            assertOffset(messageCount - 1, (KafkaSpout.OffsetEntry) item);\n    +        });\n    +    }\n    +\n    +    @Test\n    +    public void shouldReplayInOrderFailedMessages() throws Exception {\n    +        int messageCount = 10;\n    +        populateTopicData(SingleTopicKafkaSpoutConfiguration.topic, messageCount);\n    +        int kafkaPort = kafkaUnitRule.getKafkaPort();\n    +\n    +        TopologyContext topology = mock(TopologyContext.class);\n    +        SpoutOutputCollector collector = mock(SpoutOutputCollector.class);\n    +        Map conf = mock(Map.class);\n    +\n    +        KafkaSpout spout = new KafkaSpout<>(getKafkaSpoutConfig(getKafkaSpoutStreams(), kafkaPort));\n    +        spout.open(conf, topology, collector);\n    +        spout.activate();\n    +\n    +        //play and ack 1 tuple\n    +        ArgumentCaptor<Object> messageIdAcked = ArgumentCaptor.forClass(Object.class);\n    +        spout.nextTuple();\n    +        verify(collector).emit(anyObject(), anyObject(), messageIdAcked.capture());\n    +        spout.ack(messageIdAcked.getValue());\n    +        reset(collector);\n    +\n    +        //play and fail 1 tuple\n    +        ArgumentCaptor<Object> messageIdFailed = ArgumentCaptor.forClass(Object.class);\n    +        spout.nextTuple();\n    +        verify(collector).emit(anyObject(), anyObject(), messageIdFailed.capture());\n    +        spout.fail(messageIdFailed.getValue());\n    +        reset(collector);\n    +\n    +        //pause so that failed tuples will be retried\n    +        Thread.sleep(200);\n    +\n    +        //allow for some failures with +5 instead of -1\n    +        IntStream.range(0, messageCount + 5).forEach(value -> {\n    --- End diff --\n    \n    What kind of failure can happen here?\n","created":"2016-09-19T20:09:04.023+0000","updated":"2016-09-19T20:09:04.023+0000","started":"2016-09-19T20:09:04.023+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29333","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29335","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79464690\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -479,16 +487,17 @@ public OffsetAndMetadata findNextCommitOffset() {\n                 KafkaSpoutMessageId nextCommitMsg = null;     // this is a convenience variable to make it faster to create OffsetAndMetadata\n     \n                 for (KafkaSpoutMessageId currAckedMsg : ackedMsgs) {  // complexity is that of a linear scan on a TreeMap\n    -                if ((currOffset = currAckedMsg.offset()) == initialFetchOffset || currOffset == nextCommitOffset + 1) {            // found the next offset to commit\n    +                if ((currOffset = currAckedMsg.offset()) == nextCommitOffset + 1) {            // found the next offset to commit\n                         found = true;\n                         nextCommitMsg = currAckedMsg;\n                         nextCommitOffset = currOffset;\n                     } else if (currAckedMsg.offset() > nextCommitOffset + 1) {    // offset found is not continuous to the offsets listed to go in the next commit, so stop search\n                         LOG.debug(\"topic-partition [{}] has non-continuous offset [{}]. It will be processed in a subsequent batch.\", tp, currOffset);\n                         break;\n                     } else {\n    -                    LOG.debug(\"topic-partition [{}] has unexpected offset [{}].\", tp, currOffset);\n    -                    break;\n    +                    //Received a redundant ack. Ignore and continue processing.\n    --- End diff --\n    \n    Feel free to correct me, but it's my impression that Storm doesn't really support double acking. If a bolt acks the same tuple multiple times, I think Storm ends up failing the tuple tree. Have you seen double acking occur from Storm's side?\n","created":"2016-09-19T20:09:04.024+0000","updated":"2016-09-19T20:09:04.024+0000","started":"2016-09-19T20:09:04.023+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29335","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user jfenc91 commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79479970\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -266,26 +266,32 @@ private void doSeekRetriableTopicPartitions() {\n                 if (offsetAndMeta != null) {\n                     kafkaConsumer.seek(rtp, offsetAndMeta.offset() + 1);  // seek to the next offset that is ready to commit in next commit cycle\n                 } else {\n    -                kafkaConsumer.seekToEnd(toArrayList(rtp));    // Seek to last committed offset\n    +                kafkaConsumer.seek(rtp, acked.get(rtp).committedOffset + 1);    // Seek to last committed offset\n    --- End diff --\n    \n    Yup :) . shouldReplayInOrderFailedMessages and shouldReplayOutOfOrderFailedMessages Tests. \n","created":"2016-09-19T20:21:36.624+0000","updated":"2016-09-19T20:21:36.624+0000","started":"2016-09-19T20:21:36.624+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29338","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29339","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user jfenc91 commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79480290\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -266,26 +266,32 @@ private void doSeekRetriableTopicPartitions() {\n                 if (offsetAndMeta != null) {\n                     kafkaConsumer.seek(rtp, offsetAndMeta.offset() + 1);  // seek to the next offset that is ready to commit in next commit cycle\n                 } else {\n    -                kafkaConsumer.seekToEnd(toArrayList(rtp));    // Seek to last committed offset\n    +                kafkaConsumer.seek(rtp, acked.get(rtp).committedOffset + 1);    // Seek to last committed offset\n                 }\n             }\n         }\n     \n         // ======== emit  =========\n         private void emit() {\n    -        emitTupleIfNotEmitted(waitingToEmit.next());\n    +        //Keep trying to send a tuple when requested\n    +        while(!emitTupleIfNotEmitted(waitingToEmit.next()) && waitingToEmit.hasNext())\n    --- End diff --\n    \n    I was having issues with the spout reaching the max spout pending limit. Although it is apparent now that there are other contributing factors. So I will go back to the simpler way here. No need to overcomplicate. \n","created":"2016-09-19T20:22:56.487+0000","updated":"2016-09-19T20:22:56.487+0000","started":"2016-09-19T20:22:56.486+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29339","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29340","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user jfenc91 commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79480763\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -479,16 +487,17 @@ public OffsetAndMetadata findNextCommitOffset() {\n                 KafkaSpoutMessageId nextCommitMsg = null;     // this is a convenience variable to make it faster to create OffsetAndMetadata\n     \n                 for (KafkaSpoutMessageId currAckedMsg : ackedMsgs) {  // complexity is that of a linear scan on a TreeMap\n    -                if ((currOffset = currAckedMsg.offset()) == initialFetchOffset || currOffset == nextCommitOffset + 1) {            // found the next offset to commit\n    +                if ((currOffset = currAckedMsg.offset()) == nextCommitOffset + 1) {            // found the next offset to commit\n                         found = true;\n                         nextCommitMsg = currAckedMsg;\n                         nextCommitOffset = currOffset;\n                     } else if (currAckedMsg.offset() > nextCommitOffset + 1) {    // offset found is not continuous to the offsets listed to go in the next commit, so stop search\n                         LOG.debug(\"topic-partition [{}] has non-continuous offset [{}]. It will be processed in a subsequent batch.\", tp, currOffset);\n                         break;\n                     } else {\n    -                    LOG.debug(\"topic-partition [{}] has unexpected offset [{}].\", tp, currOffset);\n    -                    break;\n    +                    //Received a redundant ack. Ignore and continue processing.\n    --- End diff --\n    \n    So I added this because I was seeing acks on tuples that were behind the already committed offset. With that break statement in place, the result is a complete halt in processing. While this isn't pretty this is the only solution I could see.  \n","created":"2016-09-19T20:25:07.019+0000","updated":"2016-09-19T20:25:07.019+0000","started":"2016-09-19T20:25:07.018+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29340","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29341","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user jfenc91 commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79481211\n  \n    --- Diff: external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SingleTopicKafkaSpoutTest.java ---\n    @@ -0,0 +1,248 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + *   or more contributor license agreements.  See the NOTICE file\n    + *   distributed with this work for additional information\n    + *   regarding copyright ownership.  The ASF licenses this file\n    + *   to you under the Apache License, Version 2.0 (the\n    + *   \"License\"); you may not use this file except in compliance\n    + *   with the License.  You may obtain a copy of the License at\n    + *\n    + *   http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + *   Unless required by applicable law or agreed to in writing, software\n    + *   distributed under the License is distributed on an \"AS IS\" BASIS,\n    + *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + *   See the License for the specific language governing permissions and\n    + *   limitations under the License.\n    + */\n    +package org.apache.storm.kafka.spout;\n    +\n    +import info.batey.kafka.unit.KafkaUnitRule;\n    +import kafka.producer.KeyedMessage;\n    +import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n    +import org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration;\n    +import org.apache.storm.spout.SpoutOutputCollector;\n    +import org.apache.storm.task.TopologyContext;\n    +import org.apache.storm.tuple.Values;\n    +import org.junit.Rule;\n    +import org.junit.Test;\n    +import org.mockito.ArgumentCaptor;\n    +\n    +import static org.junit.Assert.*;\n    +\n    +import java.util.Map;\n    +import java.util.stream.IntStream;\n    +import static org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration.*;\n    +import static org.mockito.Mockito.*;\n    +\n    +public class SingleTopicKafkaSpoutTest {\n    +\n    +    @Rule\n    +    public KafkaUnitRule kafkaUnitRule = new KafkaUnitRule();\n    +\n    +\n    +    void populateTopicData(String topicName, int msgCount) {\n    +        kafkaUnitRule.getKafkaUnit().createTopic(topicName);\n    +\n    +        IntStream.range(0, msgCount).forEach(value -> {\n    +            KeyedMessage<String, String> keyedMessage = new KeyedMessage<>(\n    +                    topicName, ((Integer)value).toString(),\n    +                    ((Integer)value).toString());\n    +\n    +            kafkaUnitRule.getKafkaUnit().sendMessages(keyedMessage);\n    +        });\n    +    }\n    +\n    +    private void assertOffset(int offset, KafkaSpout.OffsetEntry entry) {\n    +        boolean currentOffsetMatch = entry.committedOffset == offset;\n    +        OffsetAndMetadata nextOffset = entry.findNextCommitOffset();\n    +        boolean nextOffsetMatch =  nextOffset != null && nextOffset.offset() == offset;\n    +        assertTrue(\"Next offset: \" +\n    +                        entry.findNextCommitOffset() +\n    +                        \", Current offset: \" +\n    +                        entry.committedOffset +\n    +                        \", Desired offset: \" +\n    +                        offset,\n    +                currentOffsetMatch | nextOffsetMatch);\n    +    }\n    +\n    +    @Test\n    +    public void shouldContinueWithSlowDoubleAcks() throws Exception {\n    +        int messageCount = 20;\n    +        populateTopicData(SingleTopicKafkaSpoutConfiguration.topic, messageCount);\n    +        int kafkaPort = kafkaUnitRule.getKafkaPort();\n    +\n    +        TopologyContext topology = mock(TopologyContext.class);\n    +        SpoutOutputCollector collector = mock(SpoutOutputCollector.class);\n    +        Map conf = mock(Map.class);\n    +\n    +        KafkaSpout spout = new KafkaSpout<>(getKafkaSpoutConfig(getKafkaSpoutStreams(), kafkaPort));\n    +        spout.open(conf, topology, collector);\n    +        spout.activate();\n    +\n    +        //play 1st tuple\n    +        ArgumentCaptor<Object> messageIdToDoubleAck = ArgumentCaptor.forClass(Object.class);\n    +        spout.nextTuple();\n    +        verify(collector).emit(anyObject(), anyObject(), messageIdToDoubleAck.capture());\n    +        spout.ack(messageIdToDoubleAck.getValue());\n    +\n    +        IntStream.range(0, messageCount/2).forEach(value -> {\n    +            spout.nextTuple();\n    +        });\n    +\n    +        spout.ack(messageIdToDoubleAck.getValue());\n    +\n    +        IntStream.range(0, messageCount).forEach(value -> {\n    +            spout.nextTuple();\n    +        });\n    +\n    +        ArgumentCaptor<Object> remainingIds = ArgumentCaptor.forClass(Object.class);\n    +\n    +        verify(collector, times(messageCount)).emit(\n    +                eq(SingleTopicKafkaSpoutConfiguration.stream),\n    +                anyObject(),\n    +                remainingIds.capture());\n    +        remainingIds.getAllValues().iterator().forEachRemaining(spout::ack);\n    +\n    +        spout.acked.values().forEach(item -> {\n    +            assertOffset(messageCount - 1, (KafkaSpout.OffsetEntry) item);\n    +        });\n    +    }\n    +\n    +    @Test\n    +    public void shouldEmitAllMessages() throws Exception {\n    +        int messageCount = 10;\n    +        populateTopicData(SingleTopicKafkaSpoutConfiguration.topic, messageCount);\n    +        int kafkaPort = kafkaUnitRule.getKafkaPort();\n    +\n    +        TopologyContext topology = mock(TopologyContext.class);\n    +        SpoutOutputCollector collector = mock(SpoutOutputCollector.class);\n    +        Map conf = mock(Map.class);\n    +\n    +        KafkaSpout spout = new KafkaSpout<>(getKafkaSpoutConfig(getKafkaSpoutStreams(), kafkaPort));\n    +        spout.open(conf, topology, collector);\n    +        spout.activate();\n    +\n    +        IntStream.range(0, messageCount).forEach(value -> {\n    +            spout.nextTuple();\n    +            ArgumentCaptor<Object> messageId = ArgumentCaptor.forClass(Object.class);\n    +            verify(collector).emit(\n    +                    eq(SingleTopicKafkaSpoutConfiguration.stream),\n    +                    eq(new Values(SingleTopicKafkaSpoutConfiguration.topic,\n    +                            ((Integer)value).toString(),\n    +                            ((Integer)value).toString())),\n    +                    messageId.capture());\n    +            spout.ack(messageId.getValue());\n    +            reset(collector);\n    +        });\n    +\n    +        spout.acked.values().forEach(item -> {\n    +            assertOffset(messageCount - 1, (KafkaSpout.OffsetEntry) item);\n    +        });\n    +    }\n    +\n    +    @Test\n    +    public void shouldReplayInOrderFailedMessages() throws Exception {\n    +        int messageCount = 10;\n    +        populateTopicData(SingleTopicKafkaSpoutConfiguration.topic, messageCount);\n    +        int kafkaPort = kafkaUnitRule.getKafkaPort();\n    +\n    +        TopologyContext topology = mock(TopologyContext.class);\n    +        SpoutOutputCollector collector = mock(SpoutOutputCollector.class);\n    +        Map conf = mock(Map.class);\n    +\n    +        KafkaSpout spout = new KafkaSpout<>(getKafkaSpoutConfig(getKafkaSpoutStreams(), kafkaPort));\n    +        spout.open(conf, topology, collector);\n    +        spout.activate();\n    +\n    +        //play and ack 1 tuple\n    +        ArgumentCaptor<Object> messageIdAcked = ArgumentCaptor.forClass(Object.class);\n    +        spout.nextTuple();\n    +        verify(collector).emit(anyObject(), anyObject(), messageIdAcked.capture());\n    +        spout.ack(messageIdAcked.getValue());\n    +        reset(collector);\n    +\n    +        //play and fail 1 tuple\n    +        ArgumentCaptor<Object> messageIdFailed = ArgumentCaptor.forClass(Object.class);\n    +        spout.nextTuple();\n    +        verify(collector).emit(anyObject(), anyObject(), messageIdFailed.capture());\n    +        spout.fail(messageIdFailed.getValue());\n    +        reset(collector);\n    +\n    +        //pause so that failed tuples will be retried\n    +        Thread.sleep(200);\n    +\n    +        //allow for some failures with +5 instead of -1\n    +        IntStream.range(0, messageCount + 5).forEach(value -> {\n    --- End diff --\n    \n    A call to the spout's emit() does not always mean a tuple is emitted. I will improve the comment. \n","created":"2016-09-19T20:27:08.032+0000","updated":"2016-09-19T20:27:08.032+0000","started":"2016-09-19T20:27:08.031+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29341","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29376","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user jfenc91 commented on the issue:\n\n    https://github.com/apache/storm/pull/1679\n  \n    Thanks for the review here @srdo! I will have a few more PRs headed your way in a week or two for this kafka client to make it fully usable.  \n","created":"2016-09-20T05:51:02.767+0000","updated":"2016-09-20T05:51:02.767+0000","started":"2016-09-20T05:51:02.764+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29376","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29377","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user jfenc91 commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79540459\n  \n    --- Diff: external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SingleTopicKafkaSpoutTest.java ---\n    @@ -0,0 +1,248 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + *   or more contributor license agreements.  See the NOTICE file\n    + *   distributed with this work for additional information\n    + *   regarding copyright ownership.  The ASF licenses this file\n    + *   to you under the Apache License, Version 2.0 (the\n    + *   \"License\"); you may not use this file except in compliance\n    + *   with the License.  You may obtain a copy of the License at\n    + *\n    + *   http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + *   Unless required by applicable law or agreed to in writing, software\n    + *   distributed under the License is distributed on an \"AS IS\" BASIS,\n    + *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + *   See the License for the specific language governing permissions and\n    + *   limitations under the License.\n    + */\n    +package org.apache.storm.kafka.spout;\n    +\n    +import info.batey.kafka.unit.KafkaUnitRule;\n    +import kafka.producer.KeyedMessage;\n    +import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n    +import org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration;\n    +import org.apache.storm.spout.SpoutOutputCollector;\n    +import org.apache.storm.task.TopologyContext;\n    +import org.apache.storm.tuple.Values;\n    +import org.junit.Rule;\n    +import org.junit.Test;\n    +import org.mockito.ArgumentCaptor;\n    +\n    +import static org.junit.Assert.*;\n    +\n    +import java.util.Map;\n    +import java.util.stream.IntStream;\n    +import static org.apache.storm.kafka.spout.builders.SingleTopicKafkaSpoutConfiguration.*;\n    +import static org.mockito.Mockito.*;\n    +\n    +public class SingleTopicKafkaSpoutTest {\n    +\n    +    @Rule\n    +    public KafkaUnitRule kafkaUnitRule = new KafkaUnitRule();\n    +\n    +\n    +    void populateTopicData(String topicName, int msgCount) {\n    +        kafkaUnitRule.getKafkaUnit().createTopic(topicName);\n    +\n    +        IntStream.range(0, msgCount).forEach(value -> {\n    +            KeyedMessage<String, String> keyedMessage = new KeyedMessage<>(\n    +                    topicName, ((Integer)value).toString(),\n    --- End diff --\n    \n    value is an int. So I changed the Integer casts to Integer.toString(value) .... that probably looks a bit nicer \n","created":"2016-09-20T05:57:41.781+0000","updated":"2016-09-20T05:57:41.781+0000","started":"2016-09-20T05:57:41.780+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29377","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29383","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user hmcl commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79576337\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -479,16 +482,17 @@ public OffsetAndMetadata findNextCommitOffset() {\n                 KafkaSpoutMessageId nextCommitMsg = null;     // this is a convenience variable to make it faster to create OffsetAndMetadata\n     \n                 for (KafkaSpoutMessageId currAckedMsg : ackedMsgs) {  // complexity is that of a linear scan on a TreeMap\n    -                if ((currOffset = currAckedMsg.offset()) == initialFetchOffset || currOffset == nextCommitOffset + 1) {            // found the next offset to commit\n    +                if ((currOffset = currAckedMsg.offset()) == nextCommitOffset + 1) {            // found the next offset to commit\n    --- End diff --\n    \n    With this change is the code going to work for a topic that does not yet have any records and/or commits in it?\n    \n    I recall testing the condition using initialFetchOffset was necessary. Why isn't it necessary?\n","created":"2016-09-20T10:13:27.179+0000","updated":"2016-09-20T10:13:27.179+0000","started":"2016-09-20T10:13:27.178+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29383","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29382","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user hmcl commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79575563\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -277,7 +277,10 @@ private void emit() {\n             waitingToEmit.remove();\n         }\n     \n    -    // emits one tuple per record\n    +    /**\n    +     * Emits one tuple per record\n    +     * @return True if tuple was emitted else false\n    --- End diff --\n    \n    This method returns void. What does the @return True comment mean?\n","created":"2016-09-20T10:13:27.179+0000","updated":"2016-09-20T10:13:27.179+0000","started":"2016-09-20T10:13:27.178+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29382","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29381","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user hmcl commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79575910\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -451,11 +454,11 @@ public int compare(KafkaSpoutMessageId m1, KafkaSpoutMessageId m2) {\n         /**\n          * This class is not thread safe\n          */\n    -    private class OffsetEntry {\n    +    class OffsetEntry {\n             private final TopicPartition tp;\n             private final long initialFetchOffset;  /* First offset to be fetched. It is either set to the beginning, end, or to the first uncommitted offset.\n                                                      * Initial value depends on offset strategy. See KafkaSpoutConsumerRebalanceListener */\n    -        private long committedOffset;     // last offset committed to Kafka. Initially it is set to fetchOffset - 1\n    +        long committedOffset;     // last offset committed to Kafka. Initially it is set to fetchOffset - 1\n    --- End diff --\n    \n    It violates encapsulation to make this field non private.\n    \n    Is this package protected for test purposes? If so, wouldn't it be better to use the testing tool reflection based methods to test for internal state, rather than exposing the state to the outside. \n","created":"2016-09-20T10:13:27.179+0000","updated":"2016-09-20T10:13:27.179+0000","started":"2016-09-20T10:13:27.178+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29381","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29384","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user hmcl commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79576762\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -479,16 +487,17 @@ public OffsetAndMetadata findNextCommitOffset() {\n                 KafkaSpoutMessageId nextCommitMsg = null;     // this is a convenience variable to make it faster to create OffsetAndMetadata\n     \n                 for (KafkaSpoutMessageId currAckedMsg : ackedMsgs) {  // complexity is that of a linear scan on a TreeMap\n    -                if ((currOffset = currAckedMsg.offset()) == initialFetchOffset || currOffset == nextCommitOffset + 1) {            // found the next offset to commit\n    +                if ((currOffset = currAckedMsg.offset()) == nextCommitOffset + 1) {            // found the next offset to commit\n                         found = true;\n                         nextCommitMsg = currAckedMsg;\n                         nextCommitOffset = currOffset;\n                     } else if (currAckedMsg.offset() > nextCommitOffset + 1) {    // offset found is not continuous to the offsets listed to go in the next commit, so stop search\n                         LOG.debug(\"topic-partition [{}] has non-continuous offset [{}]. It will be processed in a subsequent batch.\", tp, currOffset);\n                         break;\n                     } else {\n    -                    LOG.debug(\"topic-partition [{}] has unexpected offset [{}].\", tp, currOffset);\n    -                    break;\n    +                    //Received a redundant ack. Ignore and continue processing.\n    --- End diff --\n    \n    Do you have a test case where we can reproduce this consistently? This code is already  running in a large production environment, and according to the feedback I received, there are no issues of this nature. \n    \n    I am also a bit confused on what I mean by multiple acks. I am pretty sure storm guarantees that a tuple it's either acked (once), failed (once), or times out (which is equivalent to failing)\n","created":"2016-09-20T10:13:27.184+0000","updated":"2016-09-20T10:13:27.184+0000","started":"2016-09-20T10:13:27.184+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29384","issueId":"13004109"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004109/worklog/29385","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user hmcl commented on a diff in the pull request:\n\n    https://github.com/apache/storm/pull/1679#discussion_r79574175\n  \n    --- Diff: external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java ---\n    @@ -266,26 +266,32 @@ private void doSeekRetriableTopicPartitions() {\n                 if (offsetAndMeta != null) {\n                     kafkaConsumer.seek(rtp, offsetAndMeta.offset() + 1);  // seek to the next offset that is ready to commit in next commit cycle\n                 } else {\n    -                kafkaConsumer.seekToEnd(toArrayList(rtp));    // Seek to last committed offset\n    +                kafkaConsumer.seek(rtp, acked.get(rtp).committedOffset + 1);    // Seek to last committed offset\n    --- End diff --\n    \n    @jfenc91 Why is seekToEnd not correct? \n","created":"2016-09-20T10:13:27.185+0000","updated":"2016-09-20T10:13:27.185+0000","started":"2016-09-20T10:13:27.184+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"29385","issueId":"13004109"}]},"customfield_12311820":"0|i33hin:"}}