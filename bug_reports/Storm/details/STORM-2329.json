{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13038366","self":"https://issues.apache.org/jira/rest/api/2/issue/13038366","key":"STORM-2329","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12314820","id":"12314820","key":"STORM","name":"Apache Storm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12314820&avatarId=21667","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12314820&avatarId=21667","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12314820&avatarId=21667","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12314820&avatarId=21667"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/13260","id":"13260","description":"Apache Storm Related","name":"Storm"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Feb 14 16:40:27 UTC 2017","customfield_12312320":null,"customfield_12310222":null,"customfield_12310420":"9223372036854775807","customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-2329/watchers","watchCount":1,"isWatching":false},"created":"2017-01-27T05:29:04.644+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["patch"],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334140","id":"12334140","name":"0.10.1","archived":false,"released":true,"releaseDate":"2016-05-05"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334657","id":"12334657","name":"2.0.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12338104","id":"12338104","name":"1.x","archived":false,"released":false}],"customfield_12312339":null,"issuelinks":[],"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-08-30T05:42:21.722+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12324395","id":"12324395","name":"storm-hdfs","description":"Storm HDFS Integration"}],"timeoriginalestimate":null,"description":"Simple topologies writing to Kerberized HDFS will sometimes stop while getting a new writer (storm-hdfs) in a Kerberized environment: \n\njava.io.IOException: Failed on local exception: java.io.IOException: Couldn't setup connection for principal@realm to nn1/nn1IP; Host Details : local host is: \"hostname/ip\"; destination host is: \"nn hostname\":8020; at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772) at org.apache.hadoop.ipc.Client.call(Client.java:1473) at org.apache.hadoop.ipc.Client.call(Client.java:1400) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) at com.sun.proxy.$Proxy26.create(Unknown Source) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296) at sun.reflect.GeneratedMethodAccessor44.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) at com.sun.proxy.$Proxy27.create(Unknown Source) at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1726) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1668) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1593) at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:397) at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:393) at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:393) at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:337) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:908) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:889) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:786) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:775) at org.apache.storm.hdfs.bolt.AvroGenericRecordBolt.makeNewWriter(AvroGenericRecordBolt.java:115) at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.getOrCreateWriter(AbstractHdfsBolt.java:222) at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:154) at backtype.storm.daemon.executor$fn_3697$tuple_action_fn3699.invoke(executor.clj:670) at backtype.storm.daemon.executor$mk_task_receiver$fn3620.invoke(executor.clj:426) at backtype.storm.disruptor$clojure_handler$reify3196.onEvent(disruptor.clj:58) at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:125) at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:99) at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) at backtype.storm.daemon.executor$fn3697$fn3710$fn3761.invoke(executor.clj:808) at backtype.storm.util$async_loop$fn_544.invoke(util.clj:475) at clojure.lang.AFn.run(AFn.java:22) at java.lang.Thread.run(Thread.java:745) Caused by: java.io.IOException: Couldn't setup connection for principal@realm to nn1/nn1IP:8020 at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:673) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:644) at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:731) at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:369) at org.apache.hadoop.ipc.Client.getConnection(Client.java:1522) at org.apache.hadoop.ipc.Client.call(Client.java:1439) ... 35 more Caused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)] at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:413) at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:554) at org.apache.hadoop.ipc.Client$Connection.access$1800(Client.java:369) at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:723) at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:719) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:718) ... 38 more Caused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt) at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:147) at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:122) at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:187) at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:224) at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:212) at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ... 47 more\n\nTypically seen on low throughput topologies but recently witnessed in a topology that rotates files within minutes.  \n\nFrom the trace it happens here: https://github.com/apache/storm/blob/master/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java#L151\n\nMy suspicion is this happens only when opening a new file otherwise I don't see why there would be a Kerberos context to complain about until a flush/sync perhaps. \n\nMy shoot from the hip reaction is to pull that out of the current try and simply let the bolt fail and restart to establish a security context.  Thoughts? ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12852601","id":"12852601","filename":"STORM-2329.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kristopherkane","name":"kristopherkane","key":"kristopherkane","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kristopher Kane","active":true,"timeZone":"America/Detroit"},"created":"2017-02-14T16:40:27.280+0000","size":1014,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12852601/STORM-2329.patch"}],"customfield_12312340":null,"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Topology halts when getting HDFS writer in a secure environment","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kristopherkane","name":"kristopherkane","key":"kristopherkane","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kristopher Kane","active":true,"timeZone":"America/Detroit"},"subtasks":[],"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kristopherkane","name":"kristopherkane","key":"kristopherkane","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kristopher Kane","active":true,"timeZone":"America/Detroit"},"customfield_12310291":null,"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"environment":"Kerberos","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038366/comment/15841335","id":"15841335","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kristopherkane","name":"kristopherkane","key":"kristopherkane","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kristopher Kane","active":true,"timeZone":"America/Detroit"},"body":"Perhaps call HdfsSecurityUtil.login(conf, hdfsConfig); again?  Having worked with this bolt for a while I realized I don't actually know what renews the security context periodically. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kristopherkane","name":"kristopherkane","key":"kristopherkane","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kristopher Kane","active":true,"timeZone":"America/Detroit"},"created":"2017-01-27T05:35:58.252+0000","updated":"2017-01-27T05:35:58.252+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038366/comment/15866084","id":"15866084","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kristopherkane","name":"kristopherkane","key":"kristopherkane","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kristopher Kane","active":true,"timeZone":"America/Detroit"},"body":"Catch IOException from the getOrCreateWriter explicitly to prevent Kerberos errors from perpetually retrying and the topology stalling. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kristopherkane","name":"kristopherkane","key":"kristopherkane","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kristopher Kane","active":true,"timeZone":"America/Detroit"},"created":"2017-02-14T16:40:27.288+0000","updated":"2017-02-14T16:40:27.288+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-2329/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i39acn:"}}