{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13176665","self":"https://issues.apache.org/jira/rest/api/2/issue/13176665","key":"STORM-3176","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":1800,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12314820","id":"12314820","key":"STORM","name":"Apache Storm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12314820&avatarId=21667","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12314820&avatarId=21667","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12314820&avatarId=21667","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12314820&avatarId=21667"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/13260","id":"13260","description":"Apache Storm Related","name":"Storm"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341047","id":"12341047","name":"1.2.0","archived":false,"released":true,"releaseDate":"2018-02-15"}],"aggregatetimespent":1800,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2018-08-03T11:30:50.843+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Aug 03 13:20:28 UTC 2018","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_7493874_*|*_4_*:*_2_*:*_224744_*|*_6_*:*_3_*:*_6785717","customfield_12310420":"9223372036854775807","customfield_12312321":null,"resolutiondate":"2018-08-03T13:20:28.198+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-3176/watchers","watchCount":0,"isWatching":false},"created":"2018-08-03T09:18:43.894+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":["pull-request-available"],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":0,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341265","id":"12341265","name":"1.1.2","archived":false,"released":true,"releaseDate":"2018-02-15"}],"customfield_12312339":null,"issuelinks":[{"id":"12540242","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12540242","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"13077243","key":"STORM-2542","self":"https://issues.apache.org/jira/rest/api/2/issue/13077243","fields":{"summary":"Deprecate storm-kafka-client KafkaConsumer.subscribe API subscriptions on 1.x and remove them as options in 2.x","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-08-03T13:20:28.227+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12331080","id":"12331080","name":"storm-kafka-client"}],"timeoriginalestimate":null,"description":"KafkaSpout use the commitAsync api of Consumer, if the interval time between the call of consumer.poll() more than _max.poll.interval.ms_ or the heartbeat of consumer timeout, that will occur CommitFailedException,  and then the worker will die, the log like this: \r\n{code:java}\r\n// 2018-07-31 19:19:03.341 o.a.s.util [ERROR] Async loop died!\r\norg.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer th\r\nan the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in\r\npoll() with max.poll.records.\r\nat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:698) ~[stormjar.jar:?]\r\nat org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:577) ~[stormjar.jar:?]\r\nat org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1126) ~[stormjar.jar:?]\r\nat org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:XXX) ~[stormjar.jar:?]\r\nat org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:430) ~[stormjar.jar:?]\r\nat org.apache.storm.kafka.spout.KafkaSpout.nextTuple(KafkaSpout.java:264) ~[stormjar.jar:?]\r\nat org.apache.storm.daemon.executor$fn__10936$fn__10951$fn__10982.invoke(executor.clj:647) ~[XXX.jar:?]\r\nat org.apache.storm.util$async_loop$fn__553.invoke(util.clj:484) [XXX.jar:?]\r\nat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\r\nat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\r\n2018-07-31 19:19:03.342 o.a.s.d.executor [ERROR]\r\n{code}\r\nI find it will catch the Exception in auto-commit mode of consumer, the source code is:\r\n{code:java}\r\n// private void maybeAutoCommitOffsetsSync(long timeoutMs) {\r\n    if (autoCommitEnabled) {\r\n        Map<TopicPartition, OffsetAndMetadata> allConsumedOffsets = subscriptions.allConsumed();\r\n        try {\r\n            log.debug(\"Sending synchronous auto-commit of offsets {} for group {}\", allConsumedOffsets, groupId);\r\n            if (!commitOffsetsSync(allConsumedOffsets, timeoutMs))\r\n                log.debug(\"Auto-commit of offsets {} for group {} timed out before completion\",\r\n                        allConsumedOffsets, groupId);\r\n        } catch (WakeupException | InterruptException e) {\r\n            log.debug(\"Auto-commit of offsets {} for group {} was interrupted before completion\",\r\n                    allConsumedOffsets, groupId);\r\n            // rethrow wakeups since they are triggered by the user\r\n            throw e;\r\n        } catch (Exception e) {\r\n            // consistent with async auto-commit failures, we do not propagate the exception\r\n            log.warn(\"Auto-commit of offsets {} failed for group {}: {}\", allConsumedOffsets, groupId,\r\n                    e.getMessage());\r\n        }\r\n    }\r\n}\r\n{code}\r\nI think KafkaSpout should do like this, catch the Exception avoid to worker die. And when the msg ack failed, Spout should judge the offset of the msgID is larger than the last commit offset(Spout can guarantee that these msgs which offset less than the last commit offset are all ack), if not, the msg should not retry.\r\n\r\n ","customfield_10010":null,"timetracking":{"remainingEstimate":"0h","timeSpent":"0.5h","remainingEstimateSeconds":0,"timeSpentSeconds":1800},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"attachment":[],"customfield_12312340":null,"aggregatetimeestimate":0,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"KafkaSpout commit offset occurs CommitFailedException which leads to worker dead","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangzzu","name":"wangzzu","key":"wangzzu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangzzu&avatarId=29649","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangzzu&avatarId=29649","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangzzu&avatarId=29649","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangzzu&avatarId=29649"},"displayName":"Matt Wang","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangzzu","name":"wangzzu","key":"wangzzu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangzzu&avatarId=29649","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangzzu&avatarId=29649","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangzzu&avatarId=29649","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangzzu&avatarId=29649"},"displayName":"Matt Wang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310291":null,"customfield_12310290":null,"aggregateprogress":{"progress":1800,"total":1800,"percent":100},"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":1800,"total":1800,"percent":100},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13176665/comment/16568116","id":"16568116","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"I think this is a symptom of using the KafkaConsumer.subscribe API. We've deprecated this use on 1.x and removed the classes on 2.x.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2018-08-03T11:30:50.843+0000","updated":"2018-08-03T11:30:50.843+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13176665/comment/16568188","id":"16568188","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangzzu","name":"wangzzu","key":"wangzzu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangzzu&avatarId=29649","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangzzu&avatarId=29649","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangzzu&avatarId=29649","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangzzu&avatarId=29649"},"displayName":"Matt Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"modify some log","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangzzu","name":"wangzzu","key":"wangzzu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangzzu&avatarId=29649","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangzzu&avatarId=29649","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangzzu&avatarId=29649","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangzzu&avatarId=29649"},"displayName":"Matt Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-08-03T13:17:43.751+0000","updated":"2018-08-03T13:17:43.751+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13176665/comment/16568193","id":"16568193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangzzu","name":"wangzzu","key":"wangzzu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangzzu&avatarId=29649","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangzzu&avatarId=29649","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangzzu&avatarId=29649","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangzzu&avatarId=29649"},"displayName":"Matt Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"the log has been modified","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangzzu","name":"wangzzu","key":"wangzzu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangzzu&avatarId=29649","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangzzu&avatarId=29649","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangzzu&avatarId=29649","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangzzu&avatarId=29649"},"displayName":"Matt Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-08-03T13:20:28.223+0000","updated":"2018-08-03T13:20:28.223+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-3176/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":3,"worklogs":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13176665/worklog/130776","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"GitHub user wangzzu opened a pull request:\n\n    https://github.com/apache/storm/pull/2791\n\n    STORM-3176: KafkaSpout commit offset occurs CommitFailedException which leads to worker dead\n\n    KafkaSpout use the commitAsync api of Consumer, if the interval time between call consumer.poll() more than max.poll.interval.ms or the heartbeat of consumer timeout, that will occur CommitFailedException,  and then the worker will dead, the log like this:\r\n    \r\n    ```\r\n    2018-07-31 19:19:03.341 o.a.s.util [ERROR] Async loop died!\r\n    org.apache.mtkafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer th\r\n    an the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in\r\n    poll() with max.poll.records.\r\n    at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:698) ~[stormjar.jar:?]\r\n    at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:577) ~[stormjar.jar:?]\r\n    at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1126) ~[stormjar.jar:?]\r\n    at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:XXX) ~[stormjar.jar:?]\r\n    at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:430) ~[stormjar.jar:?]\r\n    at org.apache.storm.kafka.spout.KafkaSpout.nextTuple(KafkaSpout.java:264) ~[stormjar.jar:?]\r\n    at org.apache.storm.daemon.executor$fn__10936$fn__10951$fn__10982.invoke(executor.clj:647) ~[storm-core-1.1.2-mt001.jar:?]\r\n    at org.apache.storm.util$async_loop$fn__553.invoke(util.clj:484) [storm-core-1.1.2-mt001.jar:?]\r\n    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\r\n    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\r\n    2018-07-31 19:19:03.342 o.a.s.d.executor [ERROR]\r\n    ```\r\n    \r\n    I find it will catch the Exception in auto-commit mode of consumer, the source code is:\r\n    \r\n    ```java\r\n    private void maybeAutoCommitOffsetsSync(long timeoutMs) {\r\n        if (autoCommitEnabled) {\r\n            Map<TopicPartition, OffsetAndMetadata> allConsumedOffsets = subscriptions.allConsumed();\r\n            try {\r\n                log.debug(\"Sending synchronous auto-commit of offsets {} for group {}\", allConsumedOffsets, groupId);\r\n                if (!commitOffsetsSync(allConsumedOffsets, timeoutMs))\r\n                    log.debug(\"Auto-commit of offsets {} for group {} timed out before completion\",\r\n                            allConsumedOffsets, groupId);\r\n            } catch (WakeupException | InterruptException e) {\r\n                log.debug(\"Auto-commit of offsets {} for group {} was interrupted before completion\",\r\n                        allConsumedOffsets, groupId);\r\n                // rethrow wakeups since they are triggered by the user\r\n                throw e;\r\n            } catch (Exception e) {\r\n                // consistent with async auto-commit failures, we do not propagate the exception\r\n                log.warn(\"Auto-commit of offsets {} failed for group {}: {}\", allConsumedOffsets, groupId,\r\n                        e.getMessage());\r\n            }\r\n        }\r\n    }\r\n    ```\r\n    \r\n    I think KafkaSpout should do like this, catch the Exception avoid to worker die. And when the msg ack fail, Spout should judge the offset of the msgID is larger than the last commit offset(Spout can guarantee that these msgs which offset less than the last commit offset are all ack), if not, the msg should not retry.\r\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/wangzzu/storm storm-kafka-client\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/storm/pull/2791.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #2791\n    \n----\ncommit 54005a2bd28be7928cee05d6500136d3f1fb926d\nAuthor: wangmeng36 <wangmeng36@...>\nDate:   2018-08-03T08:44:40Z\n\n    storm-kafka-client fix the CommitFailedException bug\n\n----\n","created":"2018-08-03T09:20:34.285+0000","updated":"2018-08-03T09:20:34.285+0000","started":"2018-08-03T09:20:34.284+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"130776","issueId":"13176665"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13176665/worklog/130796","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on the issue:\n\n    https://github.com/apache/storm/pull/2791\n  \n    @wangzzu Hi, I'm not sure this should be happening. We're not using the `KafkaConsumer.subscribe` API anymore, so Kafka shouldn't be managing the partition assignment.\r\n    \r\n    Can you confirm that you're using storm-kafka-client 1.2.0? Could you please post your KafkaSpoutConfig? \n","created":"2018-08-03T10:55:59.568+0000","updated":"2018-08-03T10:55:59.568+0000","started":"2018-08-03T10:55:59.567+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"130796","issueId":"13176665"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13176665/worklog/130801","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user wangzzu commented on the issue:\n\n    https://github.com/apache/storm/pull/2791\n  \n    @srdo sorry, the version I used is 1.1.2. This problem has already fixed in 1.2.0.\n","created":"2018-08-03T11:22:55.582+0000","updated":"2018-08-03T11:22:55.582+0000","started":"2018-08-03T11:22:55.582+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"130801","issueId":"13176665"}]},"customfield_12311820":"0|i3wnm7:"}}