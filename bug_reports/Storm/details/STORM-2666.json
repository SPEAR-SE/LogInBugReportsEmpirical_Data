{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13091442","self":"https://issues.apache.org/jira/rest/api/2/issue/13091442","key":"STORM-2666","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":7800,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12314820","id":"12314820","key":"STORM","name":"Apache Storm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12314820&avatarId=21667","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12314820&avatarId=21667","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12314820&avatarId=21667","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12314820&avatarId=21667"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/13260","id":"13260","description":"Apache Storm Related","name":"Storm"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334657","id":"12334657","name":"2.0.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12341047","id":"12341047","name":"1.2.0","archived":false,"released":true,"releaseDate":"2018-02-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12341265","id":"12341265","name":"1.1.2","archived":false,"released":true,"releaseDate":"2018-02-15"}],"aggregatetimespent":7800,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-08-01T12:27:13.061+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Dec 05 07:43:45 UTC 2017","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_1340645440_*|*_3_*:*_1_*:*_4691998464_*|*_5_*:*_1_*:*_0","customfield_12310420":"9223372036854775807","customfield_12312321":null,"resolutiondate":"2017-10-09T23:16:23.132+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-2666/watchers","watchCount":5,"isWatching":false},"created":"2017-08-01T03:32:19.308+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["pull-request-available"],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":0,"aggregatetimeoriginalestimate":null,"customfield_12311120":"STORM-2709","customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329843","id":"12329843","name":"1.0.0","archived":false,"released":true,"releaseDate":"2016-04-12"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334657","id":"12334657","name":"2.0.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335748","id":"12335748","name":"1.1.0","archived":false,"released":true,"releaseDate":"2017-03-29"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12339656","id":"12339656","name":"1.1.1","archived":false,"released":true,"releaseDate":"2017-08-01"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12341047","id":"12341047","name":"1.2.0","archived":false,"released":true,"releaseDate":"2018-02-15"}],"customfield_12312339":null,"issuelinks":[{"id":"12523146","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12523146","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13123018","key":"STORM-2844","self":"https://issues.apache.org/jira/rest/api/2/issue/13123018","fields":{"summary":"KafkaSpout Throws IllegalStateException After Committing to Kafka When First Poll Strategy Set to EARLIEST","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-12-27T23:43:43.758+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12331080","id":"12331080","name":"storm-kafka-client"}],"timeoriginalestimate":null,"description":"Under a certain heavy load, for failed/timeout tuples, the retry service will ack tuple for failed max times. Kafka Client Spout will commit after reached the commit interval. However seems some 'on the way' tuples will be failed again, the retry service will cause Spout to emit again, and acked eventually to OffsetManager.\n\nIn some cases such offsets are too many, exceeding the max-uncommit, causing org.apache.storm.kafka.spout.internal.OffsetManager#findNextCommitOffset unable to find next commit point, and Spout for this partition will not poll any more.\n\nBy the way I've applied STORM-2549 PR#2156 from Stig Døssing to fix STORM-2625, and I'm using Python Shell Bolt as processing bolt, if this information helps.\n\nresulting logs like below. I'm not sure if the issue has already been raised/fixed, glad if anyone could help to point out existing JIRA. Thank you.\n\n\n2017-07-27 22:23:48.398 o.a.s.k.s.KafkaSpout Thread-23-spout-executor[248 248] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-20, offset=18204, numFails=0}].\n2017-07-27 22:23:49.203 o.a.s.k.s.i.OffsetManager Thread-23-spout-executor[248 248] [WARN] topic-partition [kafka_bd_trigger_action-18] has unexpected offset [16002]. Current committed Offset [16003]\n\nEdit:\nSee https://issues.apache.org/jira/browse/STORM-2666?focusedCommentId=16125893&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16125893 for the current best guess at the root cause of this issue.\n","customfield_10010":null,"timetracking":{"remainingEstimate":"0h","timeSpent":"2h 10m","remainingEstimateSeconds":0,"timeSpentSeconds":7800},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"attachment":[],"customfield_12312340":null,"aggregatetimeestimate":0,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Storm-kafka-client spout can sometimes emit messages that were already committed. ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310291":null,"customfield_12310290":null,"aggregateprogress":{"progress":7800,"total":7800,"percent":100},"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":7800,"total":7800,"percent":100},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16108420","id":"16108420","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"body":"hi [~Srdo] I'm at-ing you  as this could be a specific issue for your per-partition offset manager max-uncommit tracking solution.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-01T06:00:32.085+0000","updated":"2017-08-01T06:00:32.085+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16108813","id":"16108813","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"Hi [~GuangDu], thanks for your report. Can you verify if you have STORM-2544 fixed in your checkout of 1.1.1? It sounds a lot like what you describe.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2017-08-01T12:27:13.061+0000","updated":"2017-08-01T12:28:13.595+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16108952","id":"16108952","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~Srdo], thanks for reply. I checked and the STORM-2544 is included in my code. The issue is different from STORM-2544. \n\nSTORM-2544 is missing to ack offset, causing dis-continuous offsets in OffsetManager, as a result unable to commit the missing ones. \nMy observation is Spout is emitting already committed offsets again, and the newly acked duplicated ones will be added in OffsetManager. This is confusing Spout for the 'uncommitted count', as a result could block poll(), as well as blocking OffsetManager to find next feasible commitable offset in org.apache.storm.kafka.spout.internal.OffsetManager#findNextCommitOffset.\n\nCurrently I have no idea where these duplicated offsets come from, my guess is they're from the 'on the way' failed ones, which eventually will be acked by retry service.\n\nI'm making a temporary fix by removing offsets before committedOffset in org.apache.storm.kafka.spout.internal.OffsetManager#findNextCommitOffset, but I think probably this is not the best solution, and you could have better ideas.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-01T14:01:57.227+0000","updated":"2017-08-01T14:01:57.227+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16124701","id":"16124701","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"[~GuangDu] I've been looking at this for a while now, and I'm kind of stumped.\n\nSome things I've looked at:\n* Storm won't ack or fail multiple times for the same tuple. Once the spout executor receives either an ack or a fail for a tuple, any further acks or fails are discarded.\n* The spout disregards acks or fails for messages that are not in the emitted list. We remove message ids from emitted whenever we ack or fail a tuple, so we're effectively ensuring the same thing as the executor in the spout code as well. If partitions get reassigned, the emitted list for revoked partitions is emptied out, so we won't care about acks/fails for partitions that are not assigned to this spout. \n* We don't remove pending retries for messages when that message id is acked. I can't come up with a way for a tuple to be acked while the same message id is in the retry service though.\n* The spout won't emit a tuple for a message id that is already emitted, or is currently in the set of acked tuples. It is possible the spout will emit a tuple for a committed offset, since we don't check for that. This requires the tuple to somehow be in RetryService while it is also acked.\n* The default RetryService won't duplicate retry schedules, so an offset can't have multiple retries scheduled at the same time. We remove the scheduled retry before emitting a message, so I don't see how it is possible to have a pending tuple while the same message is scheduled on the retry service.\n\nSo as far as I can tell, it should not be possible that RetryService replays tuples that are already acked, and if a tuple gets acked, any subsequent ack/fail calls should not have any effect, unless the spout emits the tuple again after this happens.\n\nI agree that the spout code can't currently handle a tuple being acked and then replayed later, but I'm having trouble understanding how we can get into that situation. We could maybe get rid of some assumptions by making the spout remove scheduled retries once an ack is received, or dropping tuples if we're trying to emit something lower than the committed offset, but I can't really spout the faulty assumption I must be making, because in my mind those changes should not be necessary.\n\nCan you share the storm-kafka-client forked code you're running on?\nAre you using the default retry service?\nCan you share your Kafka spout configuration?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2017-08-12T20:33:40.422+0000","updated":"2017-08-12T20:33:40.422+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16124771","id":"16124771","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"body":"Thank you very much [~Srdo] for your time investigating into this. My folk is https://github.com/WolfeeTJ/storm.git in case this will help.\nI'm using the exponential retry service, also the kafka config is as below FYI if this helps.\n\n{code:java}\n        KafkaSpoutRetryExponentialBackoff kafkaSpoutRetryExponentialBackoff =\n            new KafkaSpoutRetryExponentialBackoff(\n                KafkaSpoutRetryExponentialBackoff.TimeInterval.seconds(5),\n                KafkaSpoutRetryExponentialBackoff.TimeInterval.seconds(5),\n                2,\n                KafkaSpoutRetryExponentialBackoff.TimeInterval.seconds(30));\n        KafkaSpoutConfig kafkaSpoutConfig = KafkaSpoutConfig.builder(configParameterMap.get(KAFKA_BROKER_LIST), configParameterMap.get(KAFKA_ACTION_TOPIC))\n            .setGroupId(configParameterMap.get(CONSUMER_GROUP))\n            .setMaxPollRecords(4)\n            .setMaxUncommittedOffsets(20)\n            .setOffsetCommitPeriodMs(2_000)\n            .setProp(\"session.timeout.ms\", \"120000\")\n            .setProp(\"request.timeout.ms\", \"180000\")\n            .setRetry(kafkaSpoutRetryExponentialBackoff)\n            .setFirstPollOffsetStrategy(KafkaSpoutConfig.FirstPollOffsetStrategy.UNCOMMITTED_LATEST)\n            .build();\n        KafkaSpout kafkaSpout = new KafkaSpout<>(kafkaSpoutConfig);\n\n{code}\n\nPlease kindly be noticed I've applied a simple fix to remove offsets before committed in my folk branch to make my production work.\n\nI'm not familiar about the core component code of storm, so I'm not sure if my assumption is correct:\nIn my scenario, my Python Shell Bolt will execute quite a long time (like 8 seconds) for each record, so it could be true to have a lot of tuples waiting in the Shell Bolt incoming queue. Under heavy loads, some tuples could timeout before they're able to be processed. In my opinion the fail() of Spout will be executed, thus the retry service will be involved at this time, ack & commit might happen at this time. \nHowever the tuples in the waiting queue could be processed again, and fail again, and enter the retry service again, resulting a resend after commit, causing this tuple to appear again in Spout's emitted list.\nPlease kindly help to review if my assumption could be valid.\n\nAgain thank you very much for your time, appreciate that very much.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-13T01:40:23.424+0000","updated":"2017-08-13T01:40:23.424+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16124849","id":"16124849","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"[~GuangDu] Am I right that the branch you're using is 1.1.x-branch in your fork? Just to be sure I'm looking at the right thing.\n\nAre you using Kafka's topic compaction, and do you ever see this log https://github.com/apache/storm/blob/v1.1.1/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/internal/OffsetManager.java#L94\n\nJust to explain why I think Storm doesn't ack/fail the same tuple more than once:\nWhen the spout emits a tuple, it is assigned a random id used for tracking whether the tuple tree has completed. This happens here https://github.com/apache/storm/blob/v1.1.1/storm-core/src/clj/org/apache/storm/daemon/executor.clj#L565, and is stored in a map id -> tuple info called \"pending\", where tuple info includes the msg id used by the spout internally. The store into the map is here https://github.com/apache/storm/blob/v1.1.1/storm-core/src/clj/org/apache/storm/daemon/executor.clj#L582. \nWhen the spout receives an ack or fail from the acker bolt, it removes the id -> tuple info mapping from the pending map. It checks that there was such a mapping, and if there were it will call either ack or fail on the spout instance. If the mapping isn't there, the message is ignored. This happens here https://github.com/apache/storm/blob/v1.1.1/storm-core/src/clj/org/apache/storm/daemon/executor.clj#L528 and in the line below that.\n\nGiven this mechanism, I think it isn't possible for Storm to call ack or fail multiple times for the same tuple, because any ack or fail after the first one is ignored. The reason we do a similar check in the Kafka spout code has to do with partition reassignment. If the spout emits msgId 0 on partition 0 and partition 0 gets assigned to some other spout instance, the spout will throw away its internal state relating to partition 0, including which message ids it thinks it emitted on that partition. If partition 0 then gets assigned back to this spout instance, it might receive the ack or fail for the tuple that was emitted before partitions were reassigned. Since the pending map in the generic Storm code still contains tracking information for that tuple, the spout must be able to handle this ack or fail. We do this by keeping the list of msg ids the spout has emitted, and if we receive an ack or fail for a tuple the spout doesn't think it emitted, we just ignore it. \n\nThis should be enough to ensure that we can't receive double acks or fails. The generic mechanism in Storm ensures that we can't get duplicates for the same tuple, while the mechanism in the Kafka spout ensures that if we receive an ack or fail for a message id (which can be duplicated when partition reassignment occurs), we ignore everything except the first one.\n\nTaking a look at the scenario you describe, I agree that some tuples may time out in the shell bolt queue. They will then fail on the spout, and be added to the retry service. Once this happens the tuple ids generated by Storm for those tuples have been removed from the pending map. So if an ack/fail for the same tuple tree is received, it should be dropped before even reaching the spout. If partition reassignment happens, you could get some message id duplication, but when the message id was failed and added to the retry service, it was removed from the emitted set inside the spout. This means any more acks/fails are ignored.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2017-08-13T08:43:41.587+0000","updated":"2017-08-13T08:43:41.587+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16124850","id":"16124850","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"By the way when you saw logs like \n{code}\n2017-07-27 22:23:49.203 o.a.s.k.s.i.OffsetManager Thread-23-spout-executor[248 248] [WARN] topic-partition [kafka_bd_trigger_action-18] has unexpected offset [16002]. Current committed Offset [16003]\n{code}\nwas it always off by one or was it random?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2017-08-13T08:44:48.494+0000","updated":"2017-08-13T08:44:48.494+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16124860","id":"16124860","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"body":"Thank you [~Srdo] for your detailed explanation.\n\nFirst to answer your questions: \nYes it's the 1.1.x branch;\nNo I'm not using Kafka's topic compaction, and didn't see the log;\n\nGiven your explanation for storm's underlying mechanism, I agree my assumption might not be valid. I think a better option would be add some more log information to find the underlying root cause. I'll try in our environment later, and get back with logs FYI later.\n\nRegarding the unexpected offset, I can't remember clearly if it was always off by one. I'll add logs to check again, and get back to you later.\n\nYour explanation about storm msg processing was great, thank you very much and I'll take time looking a little deeper into the clojure codes to get some better understanding. Thank you very much. :)\n\nGet back to you with more logs later.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-13T09:55:23.600+0000","updated":"2017-08-13T09:55:23.600+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16125123","id":"16125123","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"body":"First a quick check from previous logs, no it's not only offset off by one. It could be many unexpected offsets.\n{code:java}\n2017-07-28 07:43:00.506 o.a.s.k.s.i.OffsetManager Thread-72 [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17387]. Current committed Offset [17390]\n2017-07-28 07:43:00.506 o.a.s.k.s.i.OffsetManager Thread-72 [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17388]. Current committed Offset [17390]\n2017-07-28 07:43:00.506 o.a.s.k.s.i.OffsetManager Thread-72 [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17389]. Current committed Offset [17390]\n2017-07-28 07:43:00.506 o.a.s.k.s.i.OffsetManager Thread-72 [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17390]. Current committed Offset [17390]\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-14T01:44:47.975+0000","updated":"2017-08-14T01:44:47.975+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16125129","id":"16125129","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"body":"I grepped more logs below. To me seems Spout is resending after commit.\n\n{code:java}\n2017-07-27 23:55:41.100 o.a.s.k.s.i.OffsetManager Thread-59-spout-executor[128 128] [INFO] Instantiated OffsetManager{topic-partition=kafka_bd_trigger_action-1, fetchOffset=17387, committedOffset=17386, emittedOffsets=[], ackedMsgs=[]}\n2017-07-27 23:55:41.107 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] No offsets to commit. KafkaSpout{offsetManagers ={kafka_bd_trigger_action-5=OffsetManager{topic-partition=kafka_bd_trigger_action-5, fetchOffset=17518, committedOffset=17517, emittedOffsets=[], ackedMsgs=[]}, kafka_bd_trigger_action-4=OffsetManager{topic-partition=kafka_bd_trigger_action-4, fetchOffset=15235, committedOffset=15234, emittedOffsets=[], ackedMsgs=[]}, kafka_bd_trigger_action-3=OffsetManager{topic-partition=kafka_bd_trigger_action-3, fetchOffset=16656, committedOffset=16655, emittedOffsets=[], ackedMsgs=[]}, kafka_bd_trigger_action-2=OffsetManager{topic-partition=kafka_bd_trigger_action-2, fetchOffset=17074, committedOffset=17073, emittedOffsets=[], ackedMsgs=[]}, kafka_bd_trigger_action-1=OffsetManager{topic-partition=kafka_bd_trigger_action-1, fetchOffset=17387, committedOffset=17386, emittedOffsets=[], ackedMsgs=[]}, kafka_bd_trigger_action-0=OffsetManager{topic-partition=kafka_bd_trigger_action-0, fetchOffset=14494, committedOffset=14493, emittedOffsets=[], ackedMsgs=[]}}, emitted=[]}\n2017-07-27 23:55:42.078 c.q.d.s.h.HBaseDataLookupBolt Thread-53-pdl_lookup_hbase_bolt-executor[60 60] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17388, Key: null, Value: {\"appId\":\"A20170727200514663\",\"policyId\":\"PDL_BLACKLIST2\",\"transactionId\":\"150116558246620452\",\"timestamp\":\"20170727222705953\",\"dataKey\":\"['nuanxindai', 'BR_antifraudVerify|PULL', 'ZM_creditScore|PULL']\"}\n2017-07-27 23:55:42.132 c.q.d.s.h.HBaseDataLookupBolt Thread-23-pdl_lookup_hbase_bolt-executor[72 72] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17387, Key: null, Value: {\"appId\":\"A20170727200514803\",\"policyId\":\"PDL_TP\",\"transactionId\":\"150116300744862685\",\"timestamp\":\"20170727222427452\",\"dataKey\":\"['nuanxindai', 'HULU_tsp|DETAIL_PULL', 'HULU_tsp|SUMMARY_PUSH', 'ZM_creditScore|PULL', 'QF_history|PULL', 'TD_creditReport|PULL']\"}\n2017-07-27 23:55:42.182 c.q.d.s.h.HBaseDataLookupBolt Thread-23-pdl_lookup_hbase_bolt-executor[72 72] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17390, Key: null, Value: {\"appId\":\"A20170727200514953\",\"policyId\":\"PDL_TP\",\"transactionId\":\"150116342612677949\",\"timestamp\":\"20170727222759470\",\"dataKey\":\"['nuanxindai', 'HULU_tsp|DETAIL_PULL', 'HULU_tsp|SUMMARY_PUSH', 'ZM_creditScore|PULL', 'QF_history|PULL', 'TD_creditReport|PULL']\"}\n2017-07-27 23:55:42.233 c.q.d.s.h.HBaseDataLookupBolt Thread-9-pdl_lookup_hbase_bolt-executor[68 68] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17389, Key: null, Value: {\"appId\":\"A20170727200514823\",\"policyId\":\"PDL_TP\",\"transactionId\":\"150116328342980579\",\"timestamp\":\"20170727222715948\",\"dataKey\":\"['nuanxindai', 'HULU_tsp|DETAIL_PULL', 'HULU_tsp|SUMMARY_PUSH', 'ZM_creditScore|PULL', 'QF_history|PULL', 'TD_creditReport|PULL']\"}\n2017-07-27 23:57:41.105 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17388, numFails=0}].\n2017-07-27 23:57:41.105 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17388, numFails=0}].\n2017-07-27 23:57:41.105 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17387, numFails=0}].\n2017-07-27 23:57:41.105 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17387, numFails=0}].\n2017-07-27 23:57:41.106 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17389, numFails=0}].\n2017-07-27 23:57:41.106 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17389, numFails=0}].\n2017-07-27 23:57:41.107 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17390, numFails=0}].\n2017-07-27 23:57:41.107 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17390, numFails=0}].\n2017-07-27 23:57:41.112 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Offsets successfully committed to Kafka [{kafka_bd_trigger_action-3=OffsetAndMetadata{offset=16656, metadata='{topic-partition=kafka_bd_trigger_action-3, offset=16656, numFails=0, hostname=IDC-HADOOPSH-01, thread='Thread-59-spout-executor[128 128]', timestamp=20170727235741}'}, kafka_bd_trigger_action-1=OffsetAndMetadata{offset=17390, metadata='{topic-partition=kafka_bd_trigger_action-1, offset=17390, numFails=0, hostname=IDC-HADOOPSH-01, thread='Thread-59-spout-executor[128 128]', timestamp=20170727235741}'}}]\n2017-07-27 23:57:41.113 o.a.s.k.s.i.OffsetManager Thread-59-spout-executor[128 128] [INFO] committing to offset 17390\n2017-07-27 23:57:41.113 o.a.s.k.s.i.OffsetManager Thread-59-spout-executor[128 128] [INFO] Committed offsets [17387-17390 = 4] for topic-partition [kafka_bd_trigger_action-1].\n2017-07-27 23:57:41.125 c.q.d.s.h.HBaseDataLookupBolt Thread-25-pdl_lookup_hbase_bolt-executor[56 56] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17387, Key: null, Value: {\"appId\":\"A20170727200514803\",\"policyId\":\"PDL_TP\",\"transactionId\":\"150116300744862685\",\"timestamp\":\"20170727222427452\",\"dataKey\":\"['nuanxindai', 'HULU_tsp|DETAIL_PULL', 'HULU_tsp|SUMMARY_PUSH', 'ZM_creditScore|PULL', 'QF_history|PULL', 'TD_creditReport|PULL']\"}\n2017-07-27 23:57:41.125 c.q.d.s.h.HBaseDataLookupBolt Thread-23-pdl_lookup_hbase_bolt-executor[72 72] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17388, Key: null, Value: {\"appId\":\"A20170727200514663\",\"policyId\":\"PDL_BLACKLIST2\",\"transactionId\":\"150116558246620452\",\"timestamp\":\"20170727222705953\",\"dataKey\":\"['nuanxindai', 'BR_antifraudVerify|PULL', 'ZM_creditScore|PULL']\"}\n2017-07-27 23:57:41.195 c.q.d.s.h.HBaseDataLookupBolt Thread-53-pdl_lookup_hbase_bolt-executor[60 60] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17390, Key: null, Value: {\"appId\":\"A20170727200514953\",\"policyId\":\"PDL_TP\",\"transactionId\":\"150116342612677949\",\"timestamp\":\"20170727222759470\",\"dataKey\":\"['nuanxindai', 'HULU_tsp|DETAIL_PULL', 'HULU_tsp|SUMMARY_PUSH', 'ZM_creditScore|PULL', 'QF_history|PULL', 'TD_creditReport|PULL']\"}\n2017-07-27 23:57:41.219 c.q.d.s.h.HBaseDataLookupBolt Thread-9-pdl_lookup_hbase_bolt-executor[68 68] [INFO] Topic: kafka_bd_trigger_action, Partition: 1, Offset: 17389, Key: null, Value: {\"appId\":\"A20170727200514823\",\"policyId\":\"PDL_TP\",\"transactionId\":\"150116328342980579\",\"timestamp\":\"20170727222715948\",\"dataKey\":\"['nuanxindai', 'HULU_tsp|DETAIL_PULL', 'HULU_tsp|SUMMARY_PUSH', 'ZM_creditScore|PULL', 'QF_history|PULL', 'TD_creditReport|PULL']\"}\n2017-07-27 23:57:41.328 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17388, numFails=0}].\n2017-07-27 23:57:41.328 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17388, numFails=0}].\n2017-07-27 23:57:42.135 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17387, numFails=0}].\n2017-07-27 23:57:42.135 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17387, numFails=0}].\n2017-07-27 23:57:44.150 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17390, numFails=0}].\n2017-07-27 23:57:44.150 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17390, numFails=0}].\n2017-07-27 23:57:50.200 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Received ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17389, numFails=0}].\n2017-07-27 23:57:50.200 o.a.s.k.s.KafkaSpout Thread-59-spout-executor[128 128] [INFO] Successful ack for tuple message [{topic-partition=kafka_bd_trigger_action-1, offset=17389, numFails=0}].\n2017-07-27 23:57:53.103 o.a.s.k.s.i.OffsetManager Thread-59-spout-executor[128 128] [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17387]. Current committed Offset [17390]\n2017-07-27 23:57:53.103 o.a.s.k.s.i.OffsetManager Thread-59-spout-executor[128 128] [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17388]. Current committed Offset [17390]\n2017-07-27 23:57:53.103 o.a.s.k.s.i.OffsetManager Thread-59-spout-executor[128 128] [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17389]. Current committed Offset [17390]\n2017-07-27 23:57:53.103 o.a.s.k.s.i.OffsetManager Thread-59-spout-executor[128 128] [WARN] topic-partition [kafka_bd_trigger_action-1] has unexpected offset [17390]. Current committed Offset [17390]\n\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-14T02:01:26.770+0000","updated":"2017-08-14T02:01:26.770+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16125893","id":"16125893","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"You are right, those logs indicate that committed offsets are being emitted again. I think I've figured out what's happening. The consumer position can sometimes fall behind the committed offsets.\n\nSay there are partition 0 - 10, and this spout is assigned partition 0, and has currently committed up to offset 0.\nEmit offset 0-100\nAck offset 0-100, except offset 50\nReassign partitions before commit happens. Keep partition 0 assigned to this spout.\nReassignment logic does not remove the offset manager for partition 0, so 0-49 and 51-100 are still acked.\nReassignment logic seeks the consumer back to the committed offset for all assigned partitions, including partition 0. The consumer position for partition 0 is now 0.\nAck offset 50\nNextTuple is called, and commit of offset 0-100 happens.\nOffsets 0 - 100 are emitted again, because the consumer position was 0. The spout is now in a bad state, and when 0-100 are acked, the offset manager will complain in the log.\n\nA similar scenario can be constructed without partition reassignment\n\nSay max poll records is 10\nEmit offset 0-100 over 10 polls\nAck 1-100\nFail 0 and retry\nAck 0\nWhen nextTuple is called, 0-100 will be acked, but the consumer position will be at most 10 due to max.poll.records. Once the offsets are committed, the spout is again in a state where the consumer position is behind the committed offset, and the same problem occurs.\n\nI think the following changes will fix it:\nDon't seek to committed offsets for partitions during reassignment if they were assigned to the spout previously. This fix isn't strictly necessary, but I don't think it makes sense to seek when we keep the rest of the state.\nWhen committing offsets, we should check the consumer position. If the position is behind the committed offset, seek up to the committed offset.\n\nYour configuration sets max.poll.records to 4, so I suspect this might be the case you're seeing.\n\nI've put up a branch with proposed fixes here https://github.com/srdo/storm/tree/STORM-2666 (the last commit only, the others are from STORM-2549 which you should already have). I'd appreciate if you would try them out. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2017-08-14T16:10:07.037+0000","updated":"2017-08-14T16:10:07.037+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16125925","id":"16125925","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"1.x version. You should be able to check this one out and use it directly. https://github.com/srdo/storm/tree/STORM-2666-1.x","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2017-08-14T16:27:55.959+0000","updated":"2017-08-14T16:27:55.959+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16167492","id":"16167492","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"body":"Thank you [~Srdo]. Sorry I missed your comment last month, I was busy fixing our own issues. As also discussed in STORM-2549/PR-2156, I'll use 1.x-branch and merge all these in to give it a try. (I think srdo/STORM-2666-1.x will do, plus the last commit in STORM-2549. I'll do that locally.) \nAppreciate your help very much. (y)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=GuangDu","name":"GuangDu","key":"guangdu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Guang Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-15T07:57:45.535+0000","updated":"2017-09-15T07:57:45.535+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16197851","id":"16197851","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kabhwan","name":"kabhwan","key":"kabhwan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jungtaek Lim","active":true,"timeZone":"Asia/Seoul"},"body":"Thanks [~Srdo], I also merged it into 1.x and 1.1.x branches.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kabhwan","name":"kabhwan","key":"kabhwan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jungtaek Lim","active":true,"timeZone":"Asia/Seoul"},"created":"2017-10-09T23:16:23.186+0000","updated":"2017-10-09T23:16:23.186+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16277904","id":"16277904","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hmclouro","name":"hmclouro","key":"hmclouro","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hugo Louro","active":true,"timeZone":"Etc/UTC"},"body":"[~Srdo] [~GuangDu] Can you please clarify the comment made at 14/Aug/17 16:10. I think I have found another bug related to this.\r\n\r\nIn the presence of this [piece of code|https://github.com/apache/storm/blob/1.x-branch/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L158], how is it possible this to happen \"_Reassign partitions before commit happens. Keep partition 0 assigned to this spout._\" ?\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hmclouro","name":"hmclouro","key":"hmclouro","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hugo Louro","active":true,"timeZone":"Etc/UTC"},"created":"2017-12-05T02:24:25.333+0000","updated":"2017-12-05T02:24:25.333+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/comment/16278152","id":"16278152","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"body":"[~hmclouro] I think you are right and the example is wrong. It can't happen that partitions are reassigned before committing. It was still possible to produce the bad state though. Here's a modified sequence without the _Reassign partitions before commit happens. Keep partition 0 assigned to this spout._ part.\r\n\r\nSay there are partition 0 - 10, and this spout is assigned partition 0, and has currently committed up to offset 0.\r\nEmit offset 0-100\r\nAck offset 0-100, except offset 50\r\nCommit and reassign partitions. Keep partition 0 assigned to this spout. Offsets 0-49 are committed (i.e. we call commitSync with offset 50 so the consumer will restart there).\r\nReassignment logic does not remove the offset manager for partition 0, so 51-100 are still acked.\r\nReassignment logic seeks the consumer back to the committed offset for all assigned partitions, including partition 0. The consumer position for partition 0 is now 50.\r\nAck offset 50\r\nNextTuple is called, and commit of offset 50-100 happens.\r\nOffsets 50 - 100 are emitted again, because the consumer position was 50. Since 50-100 were committed, they're no longer considered emitted/acked, so the spout will emit them. The spout is now in a bad state, and when 50-100 are acked, the offset manager will complain in the log.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Srdo","name":"Srdo","key":"srdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Stig Rohde Døssing","active":true,"timeZone":"Europe/Copenhagen"},"created":"2017-12-05T07:43:45.653+0000","updated":"2017-12-05T07:43:45.653+0000"}],"maxResults":16,"total":16,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-2666/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":13,"worklogs":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/50549","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"GitHub user srdo opened a pull request:\n\n    https://github.com/apache/storm/pull/2277\n\n    STORM-2666: Fix storm-kafka-client spout sometimes emitting messages …\n\n    …that were already committed. Expand tests, add some runtime validation, minor refactoring to increase code readability. Ensure OffsetManager commits as many offsets as possible when an offset void (deleted offsets) occurs, rather than just up to the gap.\n    \n    See https://issues.apache.org/jira/browse/STORM-2666. I suspect this issue was also the root cause of the double acks we saw in https://github.com/apache/storm/pull/1679.\n    \n    The following changes are made here:\n    * Make OffsetManager commit as many offsets as possible when there is a gap in emitted offsets due to offsets being deleted from Kafka. We used to have to do two commits to get past a gap, because the OffsetManager would stop in findNextCommitOffset at the last offset before the gap, commit up to the gap, and then have to do another round to commit the acked tuples past the gap. It should now just pick the highest acked tuple to commit immediately, as long as the previous unacked tuples were not emitted.\n    * Fix case where the KafkaConsumer position could fall behind the committed offset. This can happen in some cases where there are a lot of acked uncommitted tuples, and an older tuple is preventing commit because it needs to be retried. Once the failed tuple is retried, all the acked tuples are committed, but the consumer position isn't necessarily caught up. \n    * Don't seek the consumer on partition reassignment for partitions that were previously assigned. Since the spout keeps the emitted/acked state for those partitions, we shouldn't be moving the consumer offset.\n    * Minor changes to the retry service, mainly stopping iterations once it has found what it was looking for.\n    * Add in some Validate calls to ensure that the spout state is good, e.g. check that the spout doesn't try to emit tuples that are already committed.\n    * Add more tests\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/srdo/storm STORM-2666-clean\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/storm/pull/2277.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #2277\n    \n----\ncommit 52b14d31038c04d81cb31a9668f4a77e5584aa7b\nAuthor: Stig Rohde Døssing <srdo@apache.org>\nDate:   2017-08-12T14:56:45Z\n\n    STORM-2666: Fix storm-kafka-client spout sometimes emitting messages that were already committed. Expand tests, add some runtime validation, minor refactoring to increase code readability. Ensure OffsetManager commits as many offsets as possible when an offset void (deleted offsets) occurs, rather than just up to the gap.\n\n----\n","created":"2017-08-15T15:27:56.957+0000","updated":"2017-08-15T15:27:56.957+0000","started":"2017-08-15T15:27:56.954+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"50549","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/50554","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on the issue:\n\n    https://github.com/apache/storm/pull/2277\n  \n    Test failure is the integration test and windowing, looks unrelated.\n","created":"2017-08-15T16:17:10.940+0000","updated":"2017-08-15T16:17:10.940+0000","started":"2017-08-15T16:17:10.939+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"50554","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/50558","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user hmcl commented on the issue:\n\n    https://github.com/apache/storm/pull/2277\n  \n    @srdo can you please update the JIRA ticket, thanks.\n","created":"2017-08-15T22:59:36.962+0000","updated":"2017-08-15T22:59:36.962+0000","started":"2017-08-15T22:59:36.959+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"50558","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/50614","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on the issue:\n\n    https://github.com/apache/storm/pull/2277\n  \n    @hmcl Updated the ticket (I hope this was what you meant?)\n","created":"2017-08-16T16:03:23.449+0000","updated":"2017-08-16T16:03:23.449+0000","started":"2017-08-16T16:03:23.446+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"50614","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/51312","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user revans2 commented on the issue:\n\n    https://github.com/apache/storm/pull/2277\n  \n    @hmcl do you have any concerns about the patch?\n","created":"2017-08-29T15:59:55.218+0000","updated":"2017-08-29T15:59:55.218+0000","started":"2017-08-29T15:59:55.216+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"51312","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/53741","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user srdo commented on the issue:\n\n    https://github.com/apache/storm/pull/2277\n  \n    @hmcl Will merge this in the next few days unless you have concerns.\n","created":"2017-10-02T16:14:24.242+0000","updated":"2017-10-02T16:14:24.242+0000","started":"2017-10-02T16:14:24.241+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"53741","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/53808","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"GitHub user srdo opened a pull request:\n\n    https://github.com/apache/storm/pull/2356\n\n    STORM-2666 (1.x)\n\n    Please see https://github.com/apache/storm/pull/2277. I've put all the changes for this branch in their own commit for easy review.\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/srdo/storm STORM-2666-clean-1.x\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/storm/pull/2356.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #2356\n    \n----\ncommit 9b95f3da608760b334bb8a9a272e64e0fb9fb3ac\nAuthor: Stig Rohde Døssing <srdo@apache.org>\nDate:   2017-08-12T14:56:45Z\n\n    STORM-2666: Fix storm-kafka-client spout sometimes emitting messages that were already committed. Expand tests, add some runtime validation, minor refactoring to increase code readability. Ensure OffsetManager commits as many offsets as possible when an offset void (deleted offsets) occurs, rather than just up to the gap.\n\ncommit 54fdcbc03be47c95b8e9d177f525e031afb5e946\nAuthor: Stig Rohde Døssing <srdo@apache.org>\nDate:   2017-10-04T18:46:46Z\n\n    Backport to Java 7 and revert changes to RetryService API\n\n----\n","created":"2017-10-04T18:54:25.183+0000","updated":"2017-10-04T18:54:25.183+0000","started":"2017-10-04T18:54:25.180+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"53808","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/53809","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"GitHub user srdo opened a pull request:\n\n    https://github.com/apache/storm/pull/2357\n\n    STORM-2666 (1.1.x)\n\n    This is https://github.com/apache/storm/pull/2356 plus one commit to fix conflicts.\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/srdo/storm STORM-2666-1.1.x\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/storm/pull/2357.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #2357\n    \n----\ncommit 4971543052e84161431887c5e471e6f4be917dff\nAuthor: Stig Rohde Døssing <srdo@apache.org>\nDate:   2017-08-12T14:56:45Z\n\n    STORM-2666: Fix storm-kafka-client spout sometimes emitting messages that were already committed. Expand tests, add some runtime validation, minor refactoring to increase code readability. Ensure OffsetManager commits as many offsets as possible when an offset void (deleted offsets) occurs, rather than just up to the gap.\n\ncommit 7d290affa44265c49665331a83271c0c33051c93\nAuthor: Stig Rohde Døssing <srdo@apache.org>\nDate:   2017-10-04T18:46:46Z\n\n    Backport to Java 7 and revert changes to RetryService API\n\ncommit d8da7ca08e6979df81544eb2add1adc7358bad30\nAuthor: Stig Rohde Døssing <srdo@apache.org>\nDate:   2017-10-04T19:19:16Z\n\n    Backport to 1.1.x\n\n----\n","created":"2017-10-04T19:21:04.641+0000","updated":"2017-10-04T19:21:04.641+0000","started":"2017-10-04T19:21:04.640+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"53809","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/53810","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user asfgit closed the pull request at:\n\n    https://github.com/apache/storm/pull/2277\n","created":"2017-10-04T19:24:12.936+0000","updated":"2017-10-04T19:24:12.936+0000","started":"2017-10-04T19:24:12.935+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"53810","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/54022","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user HeartSaVioR commented on the issue:\n\n    https://github.com/apache/storm/pull/2356\n  \n    +1\r\n    The build ran fine locally with JDK 7. The Travis build failure came from stuck on AvroGenericRecordBoltTest in storm-hdfs with JDK 7, not in local but often in Travis CI build.\n","created":"2017-10-09T23:06:21.841+0000","updated":"2017-10-09T23:06:21.841+0000","started":"2017-10-09T23:06:21.838+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"54022","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/54023","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user asfgit closed the pull request at:\n\n    https://github.com/apache/storm/pull/2356\n","created":"2017-10-09T23:11:20.900+0000","updated":"2017-10-09T23:11:20.900+0000","started":"2017-10-09T23:11:20.899+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"54023","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/54024","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user HeartSaVioR commented on the issue:\n\n    https://github.com/apache/storm/pull/2357\n  \n    +1\r\n    The build ran fine locally with JDK 7. The Travis build failure came from stuck on AvroGenericRecordBoltTest in storm-hdfs with JDK 7, not in local but often in Travis CI build.\n","created":"2017-10-09T23:14:16.945+0000","updated":"2017-10-09T23:14:16.945+0000","started":"2017-10-09T23:14:16.944+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"54024","issueId":"13091442"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091442/worklog/54025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user asfgit closed the pull request at:\n\n    https://github.com/apache/storm/pull/2357\n","created":"2017-10-09T23:14:41.212+0000","updated":"2017-10-09T23:14:41.212+0000","started":"2017-10-09T23:14:41.211+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"54025","issueId":"13091442"}]},"customfield_12311820":"0|i3i8x3:"}}