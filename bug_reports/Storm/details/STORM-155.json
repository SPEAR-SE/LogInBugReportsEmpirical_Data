{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12684782","self":"https://issues.apache.org/jira/rest/api/2/issue/12684782","key":"STORM-155","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12314820","id":"12314820","key":"STORM","name":"Apache Storm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12314820&avatarId=21667","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12314820&avatarId=21667","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12314820&avatarId=21667","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12314820&avatarId=21667"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/13260","id":"13260","description":"Apache Storm Related","name":"Storm"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327112","id":"12327112","name":"0.9.3","archived":false,"released":true,"releaseDate":"2014-11-25"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-07-16T06:58:07.061+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jul 25 21:37:58 UTC 2014","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_19233945763_*|*_5_*:*_1_*:*_0","customfield_12310420":"363854","customfield_12312321":null,"resolutiondate":"2014-07-25T21:37:58.774+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-155/watchers","watchCount":5,"isWatching":false},"created":"2013-12-15T06:52:13.050+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"customfield_12312339":null,"issuelinks":[{"id":"12406095","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12406095","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12684673","key":"STORM-99","self":"https://issues.apache.org/jira/rest/api/2/issue/12684673","fields":{"summary":"Multitple topologies assigned to one port","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-10-09T00:52:49.630+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12327950","id":"12327950","name":"storm-core","description":"Core storm daemons and APIs including trident"}],"timeoriginalestimate":null,"description":"https://github.com/nathanmarz/storm/issues/551\n\nWe're seeing an issue when rebalancing topologies on the clusters causes workers being assigned to multiple topologies which causes supervisors to fail. This can be easily reproduced locally by starting a single supervisor with 4 workers and nimbus, running several topologies and rebalancing all of them to use 1 worker.\n\nI tracked the issue to the mk-assignments function in nimbus.clj. In this function, the \"existing-assignments\" binding is assigned a list of all topologies with assignments except the one being rebalanced. The comment implies this is done to treat all the workers of the topology being rebalanced as unused, and that's what actually happens. However, the lack of the topology being rebalanced in the \"existing-assignments\" list causes this topology being ignore completely by scheduler and other code, so as the result all workers assigned to that topology will be taken over by other topologies, but\nno changes to the topology being rebalanced will be made, effective making all it's workers\nassigned to 2 topologies.\n\nI think that was not the intended behavior. I made a small change to treat all the workers of the topology being rebalanced dead instead, causing them to be reassigned fairly between all the topologies. This seems to work well and reliably for us.\n\nLet me know what do you think.\n\n--- a/src/clj/backtype/storm/daemon/nimbus.clj\n+++ b/src/clj/backtype/storm/daemon/nimbus.clj\n@@ -437,8 +437,11 @@\n   (into {} (for [[tid assignment] existing-assignments\n                  :let [topology-details (.getById topologies tid)\n                        all-executors (topology->executors tid)\n+                       ;; for the topology which wants rebalance (specified by the scratch-topology-id)\n+                       ;; we consider all its execturors to be dead so they will be treated\n+                       ;; as free slots in the scheduler code.\n                        alive-executors (if (and scratch-topology-id (= scratch-topology-id tid))\n-                                         all-executors\n+                                         (set nil)\n                                          (set (alive-executors nimbus topology-details all-executors assignment)))]]\n              {tid alive-executors})))\n\n@@ -638,11 +641,7 @@\n         ;; read all the assignments\n         assigned-topology-ids (.assignments storm-cluster-state nil)\n         existing-assignments (into {} (for [tid assigned-topology-ids]\n-                                        ;; for the topology which wants rebalance (specified by the scratch-topology-id)\n-                                        ;; we exclude its assignment, meaning that all the slots occupied by its assignment\n-                                        ;; will be treated as free slot in the scheduler code.\n-                                        (when (or (nil? scratch-topology-id) (not= tid scratch-topology-id))\n-                                          {tid (.assignment-info storm-cluster-state tid nil)})))\n+                                        {tid (.assignment-info storm-cluster-state tid nil)}))\n         ;; make the new assignments for topologies\n         topology->executor->node+port (compute-new-topology->executor->node+port\n                                        nimbus\n\n----------\nxumingming: The following code needs to be synchonized(mk-assignments):\n\n(defn do-rebalance [nimbus storm-id status]\n  (.update-storm! (:storm-cluster-state nimbus)\n                  storm-id\n                  (assoc-non-nil\n                    {:component->executors (:executor-overrides status)}\n                    :num-workers\n                    (:num-workers status)))\n  (mk-assignments nimbus :scratch-topology-id storm-id))\notherwise it will cause race condition here: https://github.com/nathanmarz/storm/blob/master/storm-core/src/jvm/backtype/storm/scheduler/Cluster.java#L264\n\nthen one port will be assigned to multiple topologies.\n\n----------\nstass: That's not the issue here. I initially thought it was a race condition as well, but my problem with rebalancing was in the sequential part of the algorithm (as described in analysis). Needless to say, it fixed the issue for us and I have not seen any multiple assignments in months when running with the patch I submitted.\n\n----------\nd2r: We are also hitting this issue and would welcome a fix.\n\n----------\nnathanmarz: The problem with the proposed patch is that it doesn't treat the slots of the topology that's rebalancing as free. It will certainly consider its executors as dead, but it won't make use of its slots during re-scheduling.\n\n----------\nstass: Hi, Nathan, thanks for comment.\n\nIf my reading of the code is right, the workers of the topology being rebalanced will be treated as free since they will be marked as dead (that's the purpose of the top hunk of the diff), and the scheduling code only looks at free workers when assigning workers to topologies. That is also what I observed in practice with this patch running.\n\nAm I missing something?\n\n----------\nvinceyang: @nathanmarz , We are also hitting this issue , I read the nimbus code,it seems when do rebalance , in mk-assignment function,the rebalancing topolgy's assignment info has out of date , but supervisor not kown this information. when other topolgy's assignment has the same port with the out of date assignment the problem occur. if we remove the out of date assignment in ZK this problem will not occur. if my Idea is OKï¼ŒI will work on it to fix this issue.\n\n----------\nrevans2: We have hit this issue too, and so I have been looking into it. It seems that it can happen in two different situations.\n\nFirst a topology is not assigned anything after it previously had slots assigned to it.\n\nThis happens most commonly when re-balancing because the scheduler is not aware the rebalanced topology had anything assigned to it previously, but I have been able to reproduce this with other hacked up schedulers.\n\nWhen this happens the supervisor in question will crash continuously until one of the topologies is killed.\n\nThe fix seems to be that we should include assigned-topology-ids in topology->executor->node+port when missing but with the topology pointing to nil.\n\nSecond the supervisor uses partially written scheduling data from ZK.\n\n(.set-assignment! storm-cluster-state topology-id assignment) is atomic for a single topology, but not for multiple topologies. This means that the supervisor can read data from ZK that has had some topologies updated, but not all of them.\n\nWhen this happens the supervisor will crash and then come back up and recover because the rest of the scheduling data was written to ZK.\n\nThe fix for this seems to be that we need to \"lock\" zookeeper with a watch file during the update. The supervisors would not read the data until nimbus is done updating. I don't think this is as critical to fix because the supervisor recovers fairly quickly.\n\nDoes my analysis seem correct? I don't understand all of the code perfectly, so I want to be sure I am not missing something.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"attachment":[],"customfield_12312340":null,"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"364160","customfield_12312823":null,"summary":"Storm rebalancing code causes multiple topologies assigned to a single port","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xumingming","name":"xumingming","key":"xumingming","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xumingming&avatarId=18354","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xumingming&avatarId=18354","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xumingming&avatarId=18354","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xumingming&avatarId=18354"},"displayName":"James Xu","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xumingming","name":"xumingming","key":"xumingming","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xumingming&avatarId=18354","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xumingming&avatarId=18354","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xumingming&avatarId=18354","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xumingming&avatarId=18354"},"displayName":"James Xu","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310291":null,"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14063224","id":"14063224","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"body":"Recently I met this issue. Though supervisor crashed and the message \"Should not have multiple topologies assigned to one port\" was logged, the assignments of topologies logged by ninbus was consistent as a whole. The cause seems to be reading assigments while updating them as commented above. \nHow about retrying synchronize-supervisor some times before throwing RuntimeException? Restarting supervisor is possible workaround but it causes some loss.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"created":"2014-07-16T06:58:07.061+0000","updated":"2014-07-16T06:58:07.061+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14063315","id":"14063315","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"GitHub user iwasakims opened a pull request:\n\n    https://github.com/apache/incubator-storm/pull/194\n\n    STORM-155: Storm rebalancing code causes multiple topologies assigned to a single port\n\n    Retrying synchronize-supervisor if assignments read was inconsistent before throwing RuntimeException in order to avoid supervisor crash as possible.\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/iwasakims/incubator-storm STORM-155\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/incubator-storm/pull/194.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #194\n    \n----\ncommit 14bcc9b2155ab5be71ccffa43689ef6f51b153f4\nAuthor: iwasakims <iwasakims@example.com>\nDate:   2014-07-14T17:12:24Z\n\n    made read-assignment retry on reading inconsistent assignments.\n\n----\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-16T09:16:36.275+0000","updated":"2014-07-16T09:16:36.275+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14063522","id":"14063522","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user revans2 commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-49171218\n  \n    The retry seems OK to me. I only have two concerns.\n    \n    The first one is that we are retrying for all RuntimeExceptions.  I would prefer to have us restrict the retry to just the case of the conflict.  Curator is already doing a lot of retries and in my experience if curator returns with an error a retry is not going to help.\n    \n    My second concern is with how quickly we are retrying.  I suppose in the common case we just got unlucky and downloaded the assignments in the middle of nimbus updating.  But retrying in a tight loop also does not feel correct.  For this one I am more interested in your and others opinions.  I don't consider it something that would block this from going in.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-16T14:14:37.429+0000","updated":"2014-07-16T14:14:37.429+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14065893","id":"14065893","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user iwasakims commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-49387876\n  \n    The retry of this patch happens only if the assignments read by supervisor were inconsistent in supervisor's perspective (i.e. multiple topologies have the same node+port).\n    \n    In retrying case, supervisor does not launch/shutdown workers because read-assignments returns unmodified existing-assignment. Because synchronize-supervisor is called every 10 seconds, the retry interval is 10 seconds as a result. I think it is not too quick.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-18T01:55:55.966+0000","updated":"2014-07-18T01:55:55.966+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14066460","id":"14066460","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user revans2 commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-49447151\n  \n    You are right, I did not look at the code as closely as I should have, there is no loop in the method, just setting an atom for next time around.  I am +1. I'll give some more time for others to comment and try to check this in on Monday assuming everyone else is OK with it.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-18T15:54:02.926+0000","updated":"2014-07-18T15:54:02.926+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14068777","id":"14068777","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user d2r commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-49633625\n  \n    I am seeing two test failures in new test code that was added:\n    \n    >         <testcase name=\"test-retry-read-assignments\" classname=\"backtype.storm.supervisor-test\">\n    ...\n    expected: (= launched-supervisor-&gt;ports supervisor-&gt;ports)\n    >  actual: (not (= {&quot;sup1&quot; (3 4 2 1)} {&quot;sup1&quot; [1 2]}))\n    >      at: run-test4560008170147641657.clj:75</failure>\n    ...\n    expected: (= launched-supervisor-&gt;ports supervisor-&gt;ports)\n    >  actual: (not (= {&quot;sup1&quot; (3 4 2 1)} {&quot;sup1&quot; [3 4]}))\n    >      at: run-test4560008170147641657.clj:75</failure>\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-21T16:58:48.281+0000","updated":"2014-07-21T16:58:48.281+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14069393","id":"14069393","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user iwasakims commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-49672593\n  \n    The cause seems to be the bug in validate-launched-once. I filed [STORM-415](https://issues.apache.org/jira/browse/STORM-415) and sent pull request.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-21T22:03:43.900+0000","updated":"2014-07-21T22:03:43.900+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14070273","id":"14070273","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user d2r commented on a diff in the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#discussion_r15228640\n  \n    --- Diff: storm-core/src/clj/backtype/storm/daemon/supervisor.clj ---\n    @@ -67,12 +67,19 @@\n                    [(Integer. port) (LocalAssignment. storm-id (doall executors))]\n                    ))))\n     \n    -\n     (defn- read-assignments\n       \"Returns map from port to struct containing :storm-id and :executors\"\n    -  [assignments-snapshot assignment-id]\n    -  (->> (dofor [sid (keys assignments-snapshot)] (read-my-executors assignments-snapshot sid assignment-id))\n    -       (apply merge-with (fn [& ignored] (throw-runtime \"Should not have multiple topologies assigned to one port\")))))\n    +  ([assignments-snapshot assignment-id]\n    +     (->> (dofor [sid (keys assignments-snapshot)] (read-my-executors assignments-snapshot sid assignment-id))\n    +          (apply merge-with (fn [& ignored] (throw-runtime \"Should not have multiple topologies assigned to one port\")))))\n    +  ([assignments-snapshot assignment-id existing-assignment retries]\n    +     (try (let [assignments (read-assignments assignments-snapshot assignment-id)]\n    +            (reset! retries 0)\n    +            assignments)\n    +          (catch RuntimeException e\n    +            (if (> @retries 2) (throw e) (swap! retries inc))\n    +            (log-warn (.getMessage e))\n    --- End diff --\n    \n    It would be nice to include some text to the effect that we are retrying \"1 of 3\" times in addition to this stack trace, just to avoid confusing this with a more serious error.  But this is very, very minor.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-22T13:57:13.440+0000","updated":"2014-07-22T13:57:13.440+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14070275","id":"14070275","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user d2r commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-49742005\n  \n    > The cause seems to be the bug in validate-launched-once. I filed STORM-415 and sent pull request.\n    \n    Yes, that fixes it for me.\n    \n    +1 so long as STORM-415 also gets merged in.  I had one very minor comment about the new log message, but I am fine with this as-is.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-22T13:58:25.347+0000","updated":"2014-07-22T13:58:25.347+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14071378","id":"14071378","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user iwasakims commented on a diff in the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#discussion_r15271391\n  \n    --- Diff: storm-core/src/clj/backtype/storm/daemon/supervisor.clj ---\n    @@ -67,12 +67,19 @@\n                    [(Integer. port) (LocalAssignment. storm-id (doall executors))]\n                    ))))\n     \n    -\n     (defn- read-assignments\n       \"Returns map from port to struct containing :storm-id and :executors\"\n    -  [assignments-snapshot assignment-id]\n    -  (->> (dofor [sid (keys assignments-snapshot)] (read-my-executors assignments-snapshot sid assignment-id))\n    -       (apply merge-with (fn [& ignored] (throw-runtime \"Should not have multiple topologies assigned to one port\")))))\n    +  ([assignments-snapshot assignment-id]\n    +     (->> (dofor [sid (keys assignments-snapshot)] (read-my-executors assignments-snapshot sid assignment-id))\n    +          (apply merge-with (fn [& ignored] (throw-runtime \"Should not have multiple topologies assigned to one port\")))))\n    +  ([assignments-snapshot assignment-id existing-assignment retries]\n    +     (try (let [assignments (read-assignments assignments-snapshot assignment-id)]\n    +            (reset! retries 0)\n    +            assignments)\n    +          (catch RuntimeException e\n    +            (if (> @retries 2) (throw e) (swap! retries inc))\n    +            (log-warn (.getMessage e))\n    --- End diff --\n    \n    Thanks for the comment. I updated the code. It shows the message like below now:\n    ```\n    19102 [nREPL-worker-0] INFO  backtype.storm.daemon.nimbus - Setting new assignment for topology id topology2-2-0: #backtype.storm.daemon.common.Assignment{:master-code-dir \"/tmp/bd4c83e2-fcab-44e9-bfd9-678124f22a3f/nimbus/stormdist/topology2-2-0\", :node->host {\"sup1\" \"centos63\"}, :executor->node+port {[1] [\"sup1\" 1], [2] [\"sup1\" 2]}, :executor->start-time-secs {[1] 0, [2] 0}}\n    19196 [Thread-12] WARN  backtype.storm.daemon.supervisor - Should not have multiple topologies assigned to one port: retrying 1 of 3\n    19357 [nREPL-worker-0] INFO  backtype.storm.daemon.nimbus - Delaying event :do-rebalance for 0 secs for topology2-2-0\n    19372 [nREPL-worker-0] INFO  backtype.storm.daemon.nimbus - Updated topology2-2-0 with status {:type :rebalancing, :delay-secs 0, :old-status {:type :active}, :num-workers nil, :executor-overrides {}}\n    19398 [Thread-12] WARN  backtype.storm.daemon.supervisor - Should not have multiple topologies assigned to one port: retrying 2 of 3\n    ```\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-23T05:13:40.066+0000","updated":"2014-07-23T05:13:40.066+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14072515","id":"14072515","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user ptgoetz commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-49948145\n  \n    +1\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-23T23:05:23.927+0000","updated":"2014-07-23T23:05:23.927+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14074971","id":"14074971","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user revans2 commented on the pull request:\n\n    https://github.com/apache/incubator-storm/pull/194#issuecomment-50207583\n  \n    STORM-415 is in, the unit tests all pass, and the changes look good to me I am +1.  I'll merge this in.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-25T21:36:12.358+0000","updated":"2014-07-25T21:36:12.358+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14074974","id":"14074974","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user asfgit closed the pull request at:\n\n    https://github.com/apache/incubator-storm/pull/194\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-25T21:37:16.807+0000","updated":"2014-07-25T21:37:16.807+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12684782/comment/14074977","id":"14074977","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"Thanks for this fix Masatake.  This bug has bitten me for the last time.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2014-07-25T21:37:58.804+0000","updated":"2014-07-25T21:37:58.804+0000"}],"maxResults":14,"total":14,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/STORM-155/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1qpuv:"}}