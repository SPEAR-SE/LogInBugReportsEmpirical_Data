{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [{
            "description": "Storm HDFS Integration",
            "id": "12324395",
            "name": "storm-hdfs",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324395"
        }],
        "created": "2016-11-23T23:00:56.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Yoel Cabo Lopez",
            "key": "yoelcabo",
            "name": "yoelcabo",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=yoelcabo",
            "timeZone": "Etc/UTC"
        },
        "customfield_10010": null,
        "customfield_12310220": null,
        "customfield_12310222": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i36q27:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "2016-11-23 23:00:56.0",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "In AbstractHDFSBolt, the tuples are being acked after calling syncAllWriters(), that basically ends up calling doSync() in every writer. In the case of the SequenceFileWriter, that is the same as calling the hsync() method of SequenceFile.Writer:\n\nhttps://github.com/apache/storm/blob/master/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/common/SequenceFileWriter.java#L52\n\nThe problem in the case of the block compression is that if there is a compression block opened it is not flushed with hsync(), instead it is necessary to call the sync() method, that adds a sync marker, compresses the block and writes it to the output stream that is flushed with hsync(). This is also done automatically when a certain size is reached in the compression block, but we cannot have certainty of the data being flushed until we call sync() and then hsync():\n\nhttps://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/SequenceFile.java#L1549\n\nThe easy fix is just add a call to sync() in case the writer is using Block Compression. I'm concerned about the impact that would have in the block size, but I think it is the only way of writing the data reliably in this case.",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": ["newbie"],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
            "id": "4",
            "name": "Minor",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/4"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12314820&avatarId=21667",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12314820&avatarId=21667",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12314820&avatarId=21667",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12314820&avatarId=21667"
            },
            "id": "12314820",
            "key": "STORM",
            "name": "Apache Storm",
            "projectCategory": {
                "description": "Apache Storm Related",
                "id": "13260",
                "name": "Storm",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13260"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12314820"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Yoel Cabo Lopez",
            "key": "yoelcabo",
            "name": "yoelcabo",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=yoelcabo",
            "timeZone": "Etc/UTC"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "When using Block Compression in the SequenceFileBolt some Tuples may be acked before the data is flushed to HDFS",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2016-11-23T23:00:56.000+0000",
        "versions": [],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/STORM-2218/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/STORM-2218/watchers",
            "watchCount": 1
        },
        "workratio": -1
    },
    "id": "13023030",
    "key": "STORM-2218",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13023030"
}