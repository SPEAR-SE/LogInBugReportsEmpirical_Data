{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [{
            "id": "12310688",
            "name": "ipc",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12310688"
        }],
        "created": "2016-03-11T21:10:07.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ctubbsii&avatarId=15840",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ctubbsii&avatarId=15840",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ctubbsii&avatarId=15840",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=ctubbsii&avatarId=15840"
            },
            "displayName": "Christopher Tubbs",
            "key": "ctubbsii",
            "name": "ctubbsii",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ctubbsii",
            "timeZone": "America/New_York"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": null,
        "customfield_12310222": "1_*:*_1_*:*_4614442_*|*_5_*:*_1_*:*_0",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i2ujk7:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Fri Mar 11 22:27:01 UTC 2016",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "MiniDFSCluster seems to be registering the DataNode using the machine's internal IP address, rather than \"localhost/127.0.0.1\". It looks like the problem isn't MiniDFSCluster specific, but that's what's biting me right now and I can't figure out a workaround.\n\nMiniDFSCluster logs show roughly the following (jetty services ignored):\n\nNameNode starts org.apache.hadoop.ipc.Server listening on localhost/127.0.0.1:43023\nDataNode reports \"Configured hostname is 127.0.0.1\"\nDataNode reports \"Opened streaming server at /127.0.0.1:57310\"\nDataNode starts org.apache.hadoop.ipc.Server listening on localhost/127.0.0.1:53015\nDataNode registers with NN using storage id DS-XXXXXXXXX-172.31.3.214-57310-XXXXXXXXXXXXX with ipcPort=53015\nNameNode reports \"Adding a new node: /default-rack/172.31.3.214:57310\"\n\nThe storage id should have been derived from 127.0.0.1, and the so should all the other registered information.\n\nI've verified with netstat that all services were listening only on 127.0.0.1\nThis resulted in the client being unable to write blocks to the datanode, because it was not listening on the address given to it by the namenode (the address it was registered under).\n\nThe actual client error message is:\n\n{code:java}\n[IPC Server handler 0 on 43023} INFO  org.apache.hadoop.hdfs.StateChange  - BLOCK* allocateBlock: /test-dir/HelloWorld.jar. BP-460569874-172.31.3.214-1457727894640 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[172.31.3.214:57310|RBW]]}\n[Thread-61} INFO  org.apache.hadoop.hdfs.DFSClient  - Exception in createBlockOutputStream\njava.net.ConnectException: Connection refused\n  at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n  at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n  at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n  at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)\n  at org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1305)\n  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1128)\n  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1088)\n  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:514)\n[Thread-61} INFO  org.apache.hadoop.hdfs.DFSClient  - Abandoning BP-460569874-172.31.3.214-1457727894640:blk_1073741825_1001\n[Thread-61} INFO  org.apache.hadoop.hdfs.DFSClient  - Excluding datanode 172.31.3.214:57310\n[IPC Server handler 2 on 43023} WARN  org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy  - Not able to place enough replicas, still in need of 1 to reach 1\nFor more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger\n[IPC Server handler 2 on 43023} ERROR org.apache.hadoop.security.UserGroupInformation  - PriviledgedActionException as:christopher (auth:SIMPLE) cause:java.io.IOException: File /test-dir/HelloWorld.jar could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.\n[IPC Server handler 2 on 43023} INFO  org.apache.hadoop.ipc.Server  - IPC Server handler 2 on 43023, call org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 172.31.3.214:57395 Call#12 Retry#0: error: java.io.IOException: File /test-dir/HelloWorld.jar could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.\njava.io.IOException: File /test-dir/HelloWorld.jar could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.\n  at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)\n  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2477)\n  at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:555)\n  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)\n  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)\n  at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n  at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)\n  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at javax.security.auth.Subject.doAs(Subject.java:422)\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)\n  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)\n[Thread-61} WARN  org.apache.hadoop.hdfs.DFSClient  - DataStreamer Exception\norg.apache.hadoop.ipc.RemoteException(java.io.IOException): File /test-dir/HelloWorld.jar could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.\n  at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)\n  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2477)\n  at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:555)\n  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:387)\n  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59582)\n  at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n  at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)\n  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at javax.security.auth.Subject.doAs(Subject.java:422)\n  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)\n  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)\n\n  at org.apache.hadoop.ipc.Client.call(Client.java:1347)\n  at org.apache.hadoop.ipc.Client.call(Client.java:1300)\n  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n  at com.sun.proxy.$Proxy17.addBlock(Unknown Source)\n  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:497)\n  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)\n  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n  at com.sun.proxy.$Proxy17.addBlock(Unknown Source)\n  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:330)\n  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1226)\n  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1078)\n  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:514)\n{code}\n\nAdditional information:\n\nI've tried with Hadoop 2.2.0, 2.6.1, and 2.6.3 and same results. It probably affects other versions.\nI do not see this problem running locally, only in EC2, but I've yet to be able to find a relevant networking configuration difference which would have any effect. (no extra entries in /etc/hosts, no DNS issues, etc.)\n\nI can reproduce this easily by trying to build Accumulo's master branch (HEAD at db21315) with `mvn clean package -Dtest=VfsClassLoaderTest -DfailIfNoTests=false -Dhadoop.version=2.6.3`",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [{
            "id": "12460257",
            "outwardIssue": {
                "fields": {
                    "issuetype": {
                        "avatarId": 21133,
                        "description": "A problem which impairs or prevents the functions of the product.",
                        "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                        "id": "1",
                        "name": "Bug",
                        "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                        "subtask": false
                    },
                    "priority": {
                        "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                        "id": "3",
                        "name": "Major",
                        "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                    },
                    "status": {
                        "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                        "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                        "id": "5",
                        "name": "Resolved",
                        "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                        "statusCategory": {
                            "colorName": "green",
                            "id": 3,
                            "key": "done",
                            "name": "Done",
                            "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
                        }
                    },
                    "summary": "MiniDFSCluster uses wrong IP address"
                },
                "id": "12949305",
                "key": "HADOOP-12918",
                "self": "https://issues.apache.org/jira/rest/api/2/issue/12949305"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12460257",
            "type": {
                "id": "12310000",
                "inward": "is duplicated by",
                "name": "Duplicate",
                "outward": "duplicates",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
            }
        }],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
            },
            "id": "12310240",
            "key": "HADOOP",
            "name": "Hadoop Common",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310240"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ctubbsii&avatarId=15840",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ctubbsii&avatarId=15840",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ctubbsii&avatarId=15840",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=ctubbsii&avatarId=15840"
            },
            "displayName": "Christopher Tubbs",
            "key": "ctubbsii",
            "name": "ctubbsii",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ctubbsii",
            "timeZone": "America/New_York"
        },
        "resolution": {
            "description": "The problem is a duplicate of an existing issue.",
            "id": "3",
            "name": "Duplicate",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/3"
        },
        "resolutiondate": "2016-03-11T22:27:01.000+0000",
        "status": {
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "id": "5",
            "name": "Resolved",
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "MiniDFSCluster uses wrong IP address",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2016-03-11T22:27:01.000+0000",
        "versions": [
            {
                "archived": false,
                "description": "2.2.0 release",
                "id": "12325048",
                "name": "2.2.0",
                "releaseDate": "2013-10-15",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12325048"
            },
            {
                "archived": false,
                "description": "2.6.1 release",
                "id": "12329005",
                "name": "2.6.1",
                "releaseDate": "2015-09-23",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12329005"
            },
            {
                "archived": false,
                "description": "2.6.3 release",
                "id": "12334001",
                "name": "2.6.3",
                "releaseDate": "2015-12-17",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12334001"
            }
        ],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12919/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12919/watchers",
            "watchCount": 2
        },
        "workratio": -1
    },
    "id": "12949307",
    "key": "HADOOP-12919",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12949307"
}