{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "percent": 0,
            "progress": 0,
            "total": 86400
        },
        "aggregatetimeestimate": 86400,
        "aggregatetimeoriginalestimate": 86400,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [],
        "created": "2010-08-05T16:22:57.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Rick Weber",
            "key": "tsetem",
            "name": "tsetem",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=tsetem",
            "timeZone": "Etc/UTC"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": null,
        "customfield_12310222": null,
        "customfield_12310230": "HADOOP-1722 large compressed file AuotInputFormat",
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "77610",
        "customfield_12310920": "102901",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i0hyt3:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Aug 05 16:25:02 UTC 2010",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "This was originally discovered while using Dumbo to parse a very large (2G) compressed file.  By default, Dumbo will attempt to use the AutoInputFormat as the input format.  \n\nHere is my use case:\n\nI have a large (2Gb) compressed file.  It's compressed using the default method, which is Gzip based and is unsplittable.  Due to the size, the default implementation of AutoInputFormat says that this file is splittable. As a result, this file is split into about 35 parts, and each one is assigned to a Map job.\n\nHowever, since the file itself is unsplittable, each Map job winds up parsing the file again from the beginning.  This basically means my job has 35x the data, and takes 35x long to run.\n\nIf I set \"-inputformat text\", this problem does not appear in dumbo. If I manually call the streaming jar and use AutoInputFormat, this\nproblem appears.\n\nLooking at the code in AutoInputFormat, it appears that it uses the default isSplittable() method from InputFormat, which indicates everything is splittable.  I think that this class should define it's own isSplittable method similar to what is defined in the TextInputFormat class, which basically says it's splittable if it's not compressed.\n\n",
        "duedate": null,
        "environment": "Hadoop v0.20.2 + HADOOP-1722",
        "fixVersions": [],
        "issuelinks": [
            {
                "id": "12333260",
                "outwardIssue": {
                    "fields": {
                        "issuetype": {
                            "avatarId": 21140,
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "id": "4",
                            "name": "Improvement",
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "subtask": false
                        },
                        "priority": {
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "id": "3",
                            "name": "Major",
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                        },
                        "status": {
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "id": "6",
                            "name": "Closed",
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "statusCategory": {
                                "colorName": "green",
                                "id": 3,
                                "key": "done",
                                "name": "Done",
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
                            }
                        },
                        "summary": "Make streaming to handle non-utf8 byte array"
                    },
                    "id": "12376160",
                    "key": "HADOOP-1722",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/12376160"
                },
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12333260",
                "type": {
                    "id": "10030",
                    "inward": "is related to",
                    "name": "Reference",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                }
            },
            {
                "id": "12334110",
                "inwardIssue": {
                    "fields": {
                        "issuetype": {
                            "avatarId": 21133,
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "id": "1",
                            "name": "Bug",
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "subtask": false
                        },
                        "priority": {
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "id": "3",
                            "name": "Major",
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                        },
                        "status": {
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "id": "5",
                            "name": "Resolved",
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "statusCategory": {
                                "colorName": "green",
                                "id": 3,
                                "key": "done",
                                "name": "Done",
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
                            }
                        },
                        "summary": "LineRecordReader should not seek into non-splittable, compressed streams."
                    },
                    "id": "12475294",
                    "key": "MAPREDUCE-2094",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/12475294"
                },
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12334110",
                "type": {
                    "id": "10030",
                    "inward": "is related to",
                    "name": "Reference",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                }
            }
        ],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "percent": 0,
            "progress": 0,
            "total": 86400
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
            },
            "id": "12310240",
            "key": "HADOOP",
            "name": "Hadoop Common",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310240"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Rick Weber",
            "key": "tsetem",
            "name": "tsetem",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=tsetem",
            "timeZone": "Etc/UTC"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "Parsing large compressed files with HADOOP-1722 spawns multiple mappers per file",
        "timeestimate": 86400,
        "timeoriginalestimate": 86400,
        "timespent": null,
        "updated": "2010-09-28T09:42:00.000+0000",
        "versions": [{
            "archived": false,
            "description": "",
            "id": "12313563",
            "name": "0.21.0",
            "releaseDate": "2010-08-23",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12313563"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6901/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6901/watchers",
            "watchCount": 2
        },
        "workratio": 0
    },
    "id": "12470915",
    "key": "HADOOP-6901",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12470915"
}