{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203"
            },
            "displayName": "Mingliang Liu",
            "key": "liuml07",
            "name": "liuml07",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=liuml07",
            "timeZone": "America/Los_Angeles"
        },
        "components": [{
            "id": "12332432",
            "name": "hdfs-client",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332432"
        }],
        "created": "2017-03-22T20:08:44.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203"
            },
            "displayName": "Mingliang Liu",
            "key": "liuml07",
            "name": "liuml07",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=liuml07",
            "timeZone": "America/Los_Angeles"
        },
        "customfield_10010": null,
        "customfield_12310191": [{
            "id": "10343",
            "self": "https://issues.apache.org/jira/rest/api/2/customFieldOption/10343",
            "value": "Reviewed"
        }],
        "customfield_12310192": null,
        "customfield_12310220": "2017-03-23T01:27:41.478+0000",
        "customfield_12310222": "1_*:*_1_*:*_18671177_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_70083477",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "1.0",
        "customfield_12310320": [
            {
                "archived": false,
                "id": "12339167",
                "name": "2.8.1",
                "releaseDate": "2017-06-08",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12339167"
            },
            {
                "archived": false,
                "id": "12339180",
                "name": "3.0.0-alpha4",
                "releaseDate": "2017-07-07",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12339180"
            }
        ],
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i3cntz:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Jul 26 14:46:44 UTC 2017",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "\nOur hive team found a TPCDS job whose queries running on LLAP seem to be getting stuck. Dozens of threads were waiting for the {{DfsClientShmManager::lock}}, as following jstack:\n{code}\nThread 251 (IO-Elevator-Thread-5):\n  State: WAITING\n  Blocked count: 3871\n  Wtaited count: 4565\n  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@16ead198\n  Stack:\n    sun.misc.Unsafe.park(Native Method)\n    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitUninterruptibly(AbstractQueuedSynchronizer.java:1976)\n    org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DfsClientShmManager.java:255)\n    org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager.allocSlot(DfsClientShmManager.java:434)\n    org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.allocShmSlot(ShortCircuitCache.java:1017)\n    org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:476)\n    org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:784)\n    org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:718)\n    org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)\n    org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)\n    org.apache.hadoop.hdfs.DFSInputStream.actualGetFromOneDataNode(DFSInputStream.java:1181)\n    org.apache.hadoop.hdfs.DFSInputStream.fetchBlockByteRange(DFSInputStream.java:1118)\n    org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1478)\n    org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1441)\n    org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)\n    org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)\n    org.apache.orc.impl.RecordReaderUtils$DefaultDataReader.readStripeFooter(RecordReaderUtils.java:166)\n    org.apache.hadoop.hive.llap.io.metadata.OrcStripeMetadata.<init>(OrcStripeMetadata.java:64)\n    org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.readStripesMetadata(OrcEncodedDataReader.java:622)\n{code}\n\nThe thread that is expected to signal those threads is calling {{DomainSocketWatcher::add()}} method, but it gets stuck there dealing with InterruptedException infinitely. The jstack is like:\n{code}\nThread 44417 (TezTR-257387_2840_12_10_52_0):\n  State: RUNNABLE\n  Blocked count: 3\n  Wtaited count: 5\n  Stack:\n    java.lang.Throwable.fillInStackTrace(Native Method)\n    java.lang.Throwable.fillInStackTrace(Throwable.java:783)\n    java.lang.Throwable.<init>(Throwable.java:250)\n    java.lang.Exception.<init>(Exception.java:54)\n    java.lang.InterruptedException.<init>(InterruptedException.java:57)\n    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2034)\n    org.apache.hadoop.net.unix.DomainSocketWatcher.add(DomainSocketWatcher.java:325)\n    org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DfsClientShmManager.java:266)\n    org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager.allocSlot(DfsClientShmManager.java:434)\n    org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.allocShmSlot(ShortCircuitCache.java:1017)\n    org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:476)\n    org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:784)\n    org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:718)\n    org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)\n    org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)\n    org.apache.hadoop.hdfs.DFSInputStream.actualGetFromOneDataNode(DFSInputStream.java:1181)\n    org.apache.hadoop.hdfs.DFSInputStream.fetchBlockByteRange(DFSInputStream.java:1118)\n    org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1478)\n    org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1441)\n    org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)\n{code}\nThe whole job makes no progress because of this.\n\nThe thread in {{DomainSocketWatcher::add()}} is expected to eventually break the while loop where it waits for the newly added entry being deleted by another thread. However, if this thread is ever interrupted, chances are that it will hold the lock forever so {{if(!toAdd.contains(entry))}} always be false.\n{code:title=DomainSocketWatcher::add()}\n  public void add(DomainSocket sock, Handler handler) {\n    lock.lock();\n    try {\n      ......\n      toAdd.add(entry);\n      kick();\n      while (true) {\n        try {\n          processedCond.await();\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n        }\n        if (!toAdd.contains(entry)) {\n          break;\n        }\n      }\n    } finally {\n      lock.unlock();\n    }\n  }\n{code}\n\nThe reason here is that, this method catches the InterruptedException and self interrupts during await(). The await() method internally calls {{AbstractQueuedSynchronizer::await()}}, which will throw a new InterruptedException if it's interrupted.\n{code:title=AbstractQueuedSynchronizer::await()}\n        public final void await() throws InterruptedException {\n            if (Thread.interrupted())\n                throw new InterruptedException();\n            Node node = addConditionWaiter();\n            ...\n{code}\n\nOur code in {{DomainSocketWatcher::add()}} catches this exception (again) and self interrupt (again). Please note in this process, the associated lock is never released so that the other thread which is supposed to make {{if(!toAdd.contains(entry))}} be true is still pending on the lock.\n\n{{DomainSocketWatcher::delete()}} has similar code logic and should suffer from similar problems. \n\nThanks [~jdere] for testing and reporting this.",
        "duedate": null,
        "environment": null,
        "fixVersions": [
            {
                "archived": false,
                "description": "2.9.0 release",
                "id": "12334219",
                "name": "2.9.0",
                "releaseDate": "2017-11-17",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12334219"
            },
            {
                "archived": false,
                "description": "2.7.4 release",
                "id": "12335546",
                "name": "2.7.4",
                "releaseDate": "2017-08-04",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12335546"
            },
            {
                "archived": false,
                "id": "12339180",
                "name": "3.0.0-alpha4",
                "releaseDate": "2017-07-07",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12339180"
            },
            {
                "archived": false,
                "id": "12340354",
                "name": "2.8.2",
                "releaseDate": "2017-10-24",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12340354"
            }
        ],
        "issuelinks": [{
            "id": "12498726",
            "inwardIssue": {
                "fields": {
                    "issuetype": {
                        "avatarId": 21133,
                        "description": "A problem which impairs or prevents the functions of the product.",
                        "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                        "id": "1",
                        "name": "Bug",
                        "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                        "subtask": false
                    },
                    "priority": {
                        "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
                        "id": "1",
                        "name": "Blocker",
                        "self": "https://issues.apache.org/jira/rest/api/2/priority/1"
                    },
                    "status": {
                        "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                        "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                        "id": "6",
                        "name": "Closed",
                        "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                        "statusCategory": {
                            "colorName": "green",
                            "id": 3,
                            "key": "done",
                            "name": "Done",
                            "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
                        }
                    },
                    "summary": "Job might get stuck in restoreState() from HDFS due to interrupt"
                },
                "id": "12941069",
                "key": "FLINK-3466",
                "self": "https://issues.apache.org/jira/rest/api/2/issue/12941069"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12498726",
            "type": {
                "id": "10030",
                "inward": "is related to",
                "name": "Reference",
                "outward": "relates to",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
            }
        }],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
            "id": "2",
            "name": "Critical",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/2"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
            },
            "id": "12310240",
            "key": "HADOOP",
            "name": "Hadoop Common",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310240"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203"
            },
            "displayName": "Mingliang Liu",
            "key": "liuml07",
            "name": "liuml07",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=liuml07",
            "timeZone": "America/Los_Angeles"
        },
        "resolution": {
            "description": "A fix for this issue is checked into the tree and tested.",
            "id": "1",
            "name": "Fixed",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
        },
        "resolutiondate": "2017-03-23T20:47:58.000+0000",
        "status": {
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "id": "5",
            "name": "Resolved",
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "DomainSocketWatcher::add()/delete() should not self interrupt while looping await()",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2017-07-26T14:46:44.000+0000",
        "versions": [],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14214/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14214/watchers",
            "watchCount": 12
        },
        "workratio": -1
    },
    "id": "13058378",
    "key": "HADOOP-14214",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13058378"
}