{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636"
            },
            "displayName": "dhruba borthakur",
            "key": "dhruba",
            "name": "dhruba",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=dhruba",
            "timeZone": "America/Tijuana"
        },
        "components": [],
        "created": "2008-01-23T22:17:17.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Hairong Kuang",
            "key": "hairong",
            "name": "hairong",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hairong",
            "timeZone": "Etc/UTC"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2008-01-23T22:32:05.405+0000",
        "customfield_12310222": "10002_*:*_2_*:*_113550595_*|*_1_*:*_2_*:*_3125565_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_1270593764",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "8.0",
        "customfield_12310320": null,
        "customfield_12310420": "81250",
        "customfield_12310920": "105594",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i0iffj:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Fri Jan 25 13:56:15 UTC 2008",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Some junit tests fail with the following exception:\njava.io.IOException: All datanodes are bad. Aborting...\n\tat org.apache.hadoop.dfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:1831)\n\tat org.apache.hadoop.dfs.DFSClient$DFSOutputStream.access$1100(DFSClient.java:1479)\n\tat org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1571)\nThe log contains the following message:\n2008-01-19 23:00:25,557 INFO  dfs.StateChange (FSNamesystem.java:allocateBlock(1274)) - BLOCK* NameSystem.allocateBlock: /srcdat/three/3189919341591612220. blk_6989304691537873255\n2008-01-19 23:00:25,559 INFO  fs.DFSClient (DFSClient.java:createBlockOutputStream(1982)) - pipeline = 127.0.0.1:40678\n2008-01-19 23:00:25,559 INFO  fs.DFSClient (DFSClient.java:createBlockOutputStream(1982)) - pipeline = 127.0.0.1:40680\n2008-01-19 23:00:25,559 INFO  fs.DFSClient (DFSClient.java:createBlockOutputStream(1985)) - Connecting to 127.0.0.1:40678\n2008-01-19 23:00:25,570 INFO  dfs.DataNode (DataNode.java:writeBlock(1084)) - Receiving block blk_6989304691537873255 from /127.0.0.1\n2008-01-19 23:00:25,572 INFO  dfs.DataNode (DataNode.java:writeBlock(1084)) - Receiving block blk_6989304691537873255 from /127.0.0.1\n2008-01-19 23:00:25,573 INFO  dfs.DataNode (DataNode.java:writeBlock(1169)) - Datanode 0 forwarding connect ack to upstream firstbadlink is \n2008-01-19 23:00:25,573 INFO  dfs.DataNode (DataNode.java:writeBlock(1150)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as \n2008-01-19 23:00:25,573 INFO  dfs.DataNode (DataNode.java:writeBlock(1169)) - Datanode 1 forwarding connect ack to upstream firstbadlink is \n2008-01-19 23:00:25,574 INFO  dfs.DataNode (DataNode.java:lastDataNodeRun(1802)) - Received block blk_6989304691537873255 of size 34 from /127.0.0.1\n2008-01-19 23:00:25,575 INFO  dfs.DataNode (DataNode.java:lastDataNodeRun(1819)) - PacketResponder 0 for block blk_6989304691537873255 terminating\n2008-01-19 23:00:25,575 INFO  dfs.StateChange (FSNamesystem.java:addStoredBlock(2467)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:40680 is added to blk_6989304691537873255 size 34\n2008-01-19 23:00:25,575 INFO  dfs.DataNode (DataNode.java:close(2013)) - BlockReceiver for block blk_6989304691537873255 waiting for last write to drain.\n2008-01-19 23:01:31,577 WARN  fs.DFSClient (DFSClient.java:run(1764)) - DFSOutputStream ResponseProcessor exception  for block blk_6989304691537873255java.net.SocketTimeoutException: Read timed out\n\tat java.net.SocketInputStream.socketRead0(Native Method)\n\tat java.net.SocketInputStream.read(SocketInputStream.java:129)\n\tat java.io.DataInputStream.readFully(DataInputStream.java:176)\n\tat java.io.DataInputStream.readLong(DataInputStream.java:380)\n\tat org.apache.hadoop.dfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:1726)\n\n2008-01-19 23:01:31,578 INFO  fs.DFSClient (DFSClient.java:run(1653)) - Closing old block blk_6989304691537873255\n2008-01-19 23:01:31,579 WARN  fs.DFSClient (DFSClient.java:processDatanodeError(1803)) - Error Recovery for block blk_6989304691537873255 bad datanode[0] 127.0.0.1:40678\n2008-01-19 23:01:31,580 WARN  fs.DFSClient (DFSClient.java:processDatanodeError(1836)) - Error Recovery for block blk_6989304691537873255 bad datanode 127.0.0.1:40678\n2008-01-19 23:01:31,580 INFO  fs.DFSClient (DFSClient.java:createBlockOutputStream(1982)) - pipeline = 127.0.0.1:40680\n2008-01-19 23:01:31,580 INFO  fs.DFSClient (DFSClient.java:createBlockOutputStream(1985)) - Connecting to 127.0.0.1:40680\n2008-01-19 23:01:31,582 INFO  dfs.DataNode (DataNode.java:writeBlock(1084)) - Receiving block blk_6989304691537873255 from /127.0.0.1\n2008-01-19 23:01:31,584 INFO  dfs.DataNode (DataNode.java:writeBlock(1196)) - writeBlock blk_6989304691537873255 received exception java.io.IOException: Reopen Block blk_6989304691537873255 is valid, and cannot be written to.\n2008-01-19 23:01:31,584 ERROR dfs.DataNode (DataNode.java:run(997)) - 127.0.0.1:40680:DataXceiver: java.io.IOException: Reopen Block blk_6989304691537873255 is valid, and cannot be written to.\n\tat org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:613)\n\tat org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:1996)\n\tat org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1109)\n\tat org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:982)\n\tat java.lang.Thread.run(Thread.java:595)\n\n2008-01-19 23:01:31,585 INFO  fs.DFSClient (DFSClient.java:createBlockOutputStream(2024)) - Exception in createBlockOutputStream java.io.EOFException\n\nThe log shows that blk_6989304691537873255 was successfully written to two datanodes. But dfsclient timed out waiting for a response from the first datanode. It tried to recover from the failure by resending the data to the second datanode. However, the recovery failed because the second datanode threw an IOException when it detected that it already had the block. It would be nice that the second datanode does not throw an exception for a finalized block during a recovery.\n",
        "duedate": null,
        "environment": null,
        "fixVersions": [{
            "archived": false,
            "description": "",
            "id": "12312740",
            "name": "0.16.0",
            "releaseDate": "2008-02-07",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12312740"
        }],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
            },
            "id": "12310240",
            "key": "HADOOP",
            "name": "Hadoop Common",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310240"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Hairong Kuang",
            "key": "hairong",
            "name": "hairong",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hairong",
            "timeZone": "Etc/UTC"
        },
        "resolution": {
            "description": "A fix for this issue is checked into the tree and tested.",
            "id": "1",
            "name": "Fixed",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
        },
        "resolutiondate": "2008-01-25T06:41:54.000+0000",
        "status": {
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "id": "6",
            "name": "Closed",
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Some junit tests fail with the exception: All datanodes are bad. Aborting...",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2009-07-08T16:42:51.000+0000",
        "versions": [{
            "archived": false,
            "description": "",
            "id": "12312877",
            "name": "0.15.2",
            "releaseDate": "2008-01-08",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12312877"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2691/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2691/watchers",
            "watchCount": 1
        },
        "workratio": -1
    },
    "id": "12386978",
    "key": "HADOOP-2691",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12386978"
}