{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12438397","self":"https://issues.apache.org/jira/rest/api/2/issue/12438397","key":"HADOOP-6319","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2009-10-19T23:34:01.866+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Dec 29 09:39:04 UTC 2009","customfield_12310420":"77750","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_150772120849_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-07-29T18:50:00.536+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6319/watchers","watchCount":5,"isWatching":false},"created":"2009-10-18T17:41:19.717+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313866","id":"12313866","description":"","name":"0.20.1","archived":false,"released":true,"releaseDate":"2009-09-01"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-07-29T18:50:00.562+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310689","id":"12310689","name":"fs","description":"Generic FileSystem code"}],"timeoriginalestimate":null,"description":"When trying to get Hadoop up and running on Solaris on a ZFS filesystem, I encountered a problem where the capacity reported was zero:\n\nConfigured Capacity: 0 (0 KB)\n\nIt looks like the problem is with the 'df' output:\n\n$ df -k /data/hadoop \nFilesystem           1024-blocks        Used   Available Capacity  Mounted on\n/                              0     7186354    20490274    26%    /\n\nThe following patch (applied to trunk) fixes the problem.  Though the real problem is with 'df', I suspect the patch is harmless enough to include?\n\nIndex: src/java/org/apache/hadoop/fs/DF.java\n===================================================================\n--- src/java/org/apache/hadoop/fs/DF.java\t(revision 826471)\n+++ src/java/org/apache/hadoop/fs/DF.java\t(working copy)\n@@ -181,7 +181,11 @@\n         this.percentUsed = Integer.parseInt(tokens.nextToken());\n         this.mount = tokens.nextToken();\n         break;\n-   }\n+    }\n+\n+    if (this.capacity == 0)\n+\tthis.capacity = this.used + this.available;\n+    \n   }\n \n   public static void main(String[] args) throws Exception {\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12422490","id":"12422490","filename":"solaris-hadoop.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nuggetwheat","name":"nuggetwheat","key":"nuggetwheat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Judd","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-18T17:41:43.295+0000","size":539,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12422490/solaris-hadoop.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"103264","customfield_12312823":null,"summary":"Capacity reporting incorrect on Solaris","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nuggetwheat","name":"nuggetwheat","key":"nuggetwheat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Judd","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nuggetwheat","name":"nuggetwheat","key":"nuggetwheat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Judd","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438397/comment/12767614","id":"12767614","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"This is an edge-case that I discussed with Yahoo!'s HDFS team a long time back that lead me to the conclusion that one is still better off specifying a max size rather than trying to guess capacity and do negative math.  Needless to say, I lost.  \n\nIn this particular edge-case, I think the fix would work. I'd still rate it as risky since there are likely other filesystems (especially pool based) that have similar df outputs, however where capacity is not used+avail.\n\nAlthough I'm curious about one thing.\n\nWhy not just create another filesystem in this ZFS pool rather than using the root filesystem?  A  ZFS file system is significantly faster for Hadoop operations than using UFS. [... yes, I've tested it.] As an added bonus, you avoid this issue. :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2009-10-19T23:34:01.866+0000","updated":"2009-10-19T23:34:01.866+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438397/comment/12795031","id":"12795031","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=woopi","name":"woopi","key":"woopi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=woopi&avatarId=19625","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=woopi&avatarId=19625","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=woopi&avatarId=19625","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=woopi&avatarId=19625"},"displayName":"Dr. Martin Menzel","active":true,"timeZone":"Europe/Berlin"},"body":"I had the same problem on Solaris and I did exactly what Allen mentioned. More detailed informations what I did:\n\n1) Create a zfs filesystem in the global zone \n\nzfs create rpool/srv/hadoop \n\n2) set the mountpoint to legacy and set a quota\n\nzfs set mountpoint=legacy rpool/srv/hadoop\n\nzfs set quota=50G rpool/srv/hadoop\n\n3) Add the dataset to the hadoop zone \n\nzonecfg -z <hadoopzone>\nzonecfg:hadoopzone> add dataset\nzonecfg:hadoopzone:dataset> set name=rpool/srv/hadoop\nzonecfg:hadoopzone:dataset> end\nzonecfg:hadoopzone>verify\nzonecfg:hadoopzone>commit\nzonecfg:hadoopzone>exit\n\n4) login to your hadoop zone\n\nzlogin hadoopzone\n\n5) set mountpoint for the zfs filesystem\n\nzfs set mountpoint=/srv/hadoop rpool/srv/hadoop\n\nThan hadoop recognizes the 50G as capacity. Remember to configure hadoop so that it uses a data dir in /srv/hadoop\n\nI set in core-site.xml \n\n<configuration>\n  <property>\n    <name>fs.default.name</name>\n    <value>hdfs://localhost:9000</value>\n  </property>\n  <property>\n    <name>hadoop.tmp.dir</name>\n    <value>/srv/hadoop/tmp/hadoop-${user.name}</value>\n  </property>\n</configuration>\n\nI hope these informations may help other solaris users.\n\nMartin","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=woopi","name":"woopi","key":"woopi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=woopi&avatarId=19625","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=woopi&avatarId=19625","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=woopi&avatarId=19625","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=woopi&avatarId=19625"},"displayName":"Dr. Martin Menzel","active":true,"timeZone":"Europe/Berlin"},"created":"2009-12-29T09:39:04.280+0000","updated":"2009-12-29T09:39:04.280+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6319/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0i11r:"}}