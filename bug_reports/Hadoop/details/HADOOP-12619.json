{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12919730","self":"https://issues.apache.org/jira/rest/api/2/issue/12919730","key":"HADOOP-12619","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-04-13T18:50:02.475+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Dec 21 19:14:37 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12619/watchers","watchCount":8,"isWatching":false},"created":"2015-12-07T15:13:19.222+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326144","id":"12326144","description":"2.4.0 release","name":"2.4.0","archived":false,"released":true,"releaseDate":"2014-04-07"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-12-21T19:14:37.147+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"The constructor of org.apache.hadoop.io.compress.CompressorStream requires an org.apache.hadoop.io.compress.Compressor  object to compress bytes but it does not invoke the compressor's finish method when close method are called. This may causes the native memory leaks if the compressor is only used by this CompressorStream object.\n\nI found this when set up a flume agent with gzip compression, the native memory grows slowly and cannot fall back. \n\n{code}\n  @Override\n  public CompressionOutputStream createOutputStream(OutputStream out) \n    throws IOException {\n    return (ZlibFactory.isNativeZlibLoaded(conf)) ?\n               new CompressorStream(out, createCompressor(),\n                                    conf.getInt(\"io.file.buffer.size\", 4*1024)) :\n               new GzipOutputStream(out);\n  }\n\n  @Override\n  public Compressor createCompressor() {\n    return (ZlibFactory.isNativeZlibLoaded(conf))\n      ? new GzipZlibCompressor(conf)\n      : null;\n  }\n{code}\n\nThe method of CompressorStream is\n\n{code}\n  @Override\n  public void close() throws IOException {\n    if (!closed) {\n      finish();\n      out.close();\n      closed = true;\n    }\n  }\n\n  @Override\n  public void finish() throws IOException {\n    if (!compressor.finished()) {\n      compressor.finish();\n      while (!compressor.finished()) {\n        compress();\n      }\n    }\n  }\n{code}\n\nNo one will end the compressor.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Native memory leaks in CompressorStream","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lc_wangchao","name":"lc_wangchao","key":"lc_wangchao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangchao","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lc_wangchao","name":"lc_wangchao","key":"lc_wangchao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangchao","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12919730/comment/15045070","id":"15045070","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lc_wangchao","name":"lc_wangchao","key":"lc_wangchao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangchao","active":true,"timeZone":"Etc/UTC"},"body":"The code of hadoop 2.7.1 changes the implement of GzipCodec.createOutputStream as \n\n{code}\n  @Override\n  public CompressionOutputStream createOutputStream(OutputStream out) \n    throws IOException {\n    if (!ZlibFactory.isNativeZlibLoaded(conf)) {\n      return new GzipOutputStream(out);\n    }\n    return CompressionCodec.Util.\n        createOutputStreamWithCodecPool(this, conf, out);\n  }\n\n  @Override\n  public CompressionOutputStream createOutputStream(OutputStream out, \n                                                    Compressor compressor) \n  throws IOException {\n    return (compressor != null) ?\n               new CompressorStream(out, compressor,\n                                    conf.getInt(\"io.file.buffer.size\", \n                                                4*1024)) :\n               createOutputStream(out);\n  }\n\n    static CompressionOutputStream createOutputStreamWithCodecPool(\n        CompressionCodec codec, Configuration conf, OutputStream out)\n        throws IOException {\n      Compressor compressor = CodecPool.getCompressor(codec, conf);\n      CompressionOutputStream stream = null;\n      try {\n        stream = codec.createOutputStream(out, compressor);\n      } finally {\n        if (stream == null) {\n          CodecPool.returnCompressor(compressor);\n        } else {\n          stream.setTrackedCompressor(compressor);\n        }\n      }\n      return stream;\n    }\n \n{code}\n\nbut CompressorStream override the close method and still not return the compressor to pool\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lc_wangchao","name":"lc_wangchao","key":"lc_wangchao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangchao","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-07T15:19:03.546+0000","updated":"2015-12-07T15:19:03.546+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12919730/comment/15239818","id":"15239818","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ersatzjef","name":"ersatzjef","key":"ersatzjef","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Faust","active":true,"timeZone":"Etc/UTC"},"body":"Observed this behavior in 2.7.1 with org.apache.hadoop.io.compress.BZip2Codec::createOutputStream(OutputStream) - the process would eventually exhaust the native memory on the host and crash.  Here's the relevant code:\n{code}\n@Override\n  public CompressionOutputStream createOutputStream(OutputStream out)\n      throws IOException {\n    return CompressionCodec.Util.\n        createOutputStreamWithCodecPool(this, conf, out);\n  }\n{code}\ncreateOutputStreamWithCodecPool gets a compressor from the CodecPool, calls codec.createOutputStream (out, compressor), and then calls CompressionOutputStream::setTrackedCompressor(compressor) so that the compressor can be cleaned up later by the CompressionOutputStream  \n{code}\nstatic CompressionOutputStream createOutputStreamWithCodecPool(\n        CompressionCodec codec, Configuration conf, OutputStream out)\n        throws IOException {\n      Compressor compressor = CodecPool.getCompressor(codec, conf);\n      CompressionOutputStream stream = null;\n      try {\n        stream = codec.createOutputStream(out, compressor);\n      } finally {\n        if (stream == null) {\n          CodecPool.returnCompressor(compressor);\n        } else {\n          stream.setTrackedCompressor(compressor);\n        }\n      }\n      return stream;\n    }\n{code}\nCompressionOutputStream has a private trackedCompressor attribute that it returns to the CodecPool on close():\n{code}\n   private Compressor trackedCompressor;\n   \n   void setTrackedCompressor(Compressor compressor) {\n    trackedCompressor = compressor;\n  }\n\n    @Override\n  public void close() throws IOException {\n    finish();\n    out.close();\n    if (trackedCompressor != null) {\n      CodecPool.returnCompressor(trackedCompressor);\n      trackedCompressor = null;\n    }\n  }\n{code}\nThis would be great, but when CompressionCodec.Util.createOutputStreamWithCodecPool calls codec.createOutputStream(out, compressor), the BZip2Codec never actually creates a CompressionOutputStream.  It creates one of two subclasses:\n{code}\n @Override\n  public CompressionOutputStream createOutputStream(OutputStream out,\n      Compressor compressor) throws IOException {\n    return Bzip2Factory.isNativeBzip2Loaded(conf) ?\n      new CompressorStream(out, compressor, \n                           conf.getInt(\"io.file.buffer.size\", 4*1024)) :\n      new BZip2CompressionOutputStream(out);\n  }\n{code}\nEach of these subclasses (CompressorStream and BZip2CompressionOutputStream) in turn overrides the close() method, and it will be one of these two implementations that will be called when the returned stream is closed.  Neither implementation returns the compressor to the pool, so every time you ask the CodecPool for a compressor it creates a new one, allocating more native memory.  \n\nOne workaround is to deal directly with the CodecPool, and use the BZip2Codec::createOutputStream method that takes a compressor as a second argument - and of course to return the compressor to the CodecPool yourself as soon as you're finished with it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ersatzjef","name":"ersatzjef","key":"ersatzjef","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Faust","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-13T18:50:02.475+0000","updated":"2016-04-13T18:50:02.475+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12919730/comment/15767893","id":"15767893","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlmarion","name":"dlmarion","key":"dlmarion","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dave Marion","active":true,"timeZone":"America/New_York"},"body":"Related to HADOOP-12007?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlmarion","name":"dlmarion","key":"dlmarion","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dave Marion","active":true,"timeZone":"America/New_York"},"created":"2016-12-21T19:14:37.147+0000","updated":"2016-12-21T19:14:37.147+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12619/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2pjh3:"}}