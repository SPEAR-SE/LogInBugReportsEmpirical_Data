{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12352244","self":"https://issues.apache.org/jira/rest/api/2/issue/12352244","key":"HADOOP-572","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312098","id":"12312098","description":"","name":"0.8.0","archived":false,"released":true,"releaseDate":"2006-11-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2006-10-03T03:01:02.000+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jan 03 21:39:36 UTC 2007","customfield_12310420":"80669","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_8019945295_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_2612771949","customfield_12312321":null,"resolutiondate":"2007-01-03T21:40:47.295+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-572/watchers","watchCount":0,"isWatching":false},"created":"2006-10-03T01:55:02.000+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312058","id":"12312058","description":"","name":"0.6.2","archived":false,"released":true,"releaseDate":"2006-09-18"}],"issuelinks":[{"id":"12313934","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12313934","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12353991","key":"HADOOP-641","self":"https://issues.apache.org/jira/rest/api/2/issue/12353991","fields":{"summary":"Name-node should demand a block report from resurrected data-nodes.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12313933","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12313933","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12353994","key":"HADOOP-642","self":"https://issues.apache.org/jira/rest/api/2/issue/12353994","fields":{"summary":"Explicit timeout for ipc.Client","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12314603","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12314603","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12343533","key":"HADOOP-255","self":"https://issues.apache.org/jira/rest/api/2/issue/12343533","fields":{"summary":"Client Calls are not cancelled after a call timeout","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12314604","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12314604","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12355797","key":"HADOOP-725","self":"https://issues.apache.org/jira/rest/api/2/issue/12355797","fields":{"summary":"chooseTargets method in FSNamesystem is very inefficient","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:42:05.177+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"I've observed a cluster crash caused by simultaneous failure of only 3 data-nodes.\nThe crash is reproducable. In order to reproduce it you need a rather large cluster.\nTo simplify calculations I'll consider a 600 node cluster as an example.\nThe cluster should also contain a substantial amount of data.\nWe will need at least 3 data-nodes containing 10,000+ blocks each.\nNow suppose that these 3 data-nodes fail at the same time, and the name-node\nstarted replicating all missing blocks belonging to the nodes.\nThe name-node can replicate 50 blocks per second on average based on experimental data.\nMeaning, it will take more than 10 minutes, which is the heartbeat expiration interval,\nto replicates all 30,000+ blocks.\n\nWith the 3 second heartbeat interval there are 600 / 3 = 200 heartbeats hitting the name-node every second.\nUnder heavy replication load the name-node accepts about 50 heartbeats per second.\nSo at most 3/4 of all heartbeats remain unserved.\n\nEach node SHOULD send 200 heartbeats during the 10 minute interval, and every time the probability\nof the heartbeat being unserved is 3/4 or less.\nSo the probability of failing of all 200 heartbeats is (3/4) ** 200 = 0 from the practical standpoint.\n\nIN FACT since current implementation sets the rpc timeout to 1 minute, a failed heartbeat takes\n1 minute and 8 seconds to complete, and under this circumstances each data-node can send only\n9 heartbeats during the 10 minute interval. Thus, the probability of failing of all 9 of them is 0.075,\nwhich means that we will loose 45 nodes out of 600 at the end of the 10 minute interval.\nFrom this point the name-node will be constantly replicating blocks and loosing more nodes, and\nbecomes effectively dysfunctional.\n\nA map-reduce framework running on top of it makes things deteriorate even faster, because failing\ntasks and jobs are trying to remove files and re-create them again increasing the overall load on\nthe name-node.\n\nI see at least 2 problems that contribute to the chain reaction described above.\n1. A heartbeat failure takes too long (1'8\").\n2. Name-node synchronized operations should be fine-grained.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"106947","customfield_12312823":null,"summary":"Chain reaction in a big cluster caused by simultaneous failure of only a few data-nodes.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Large dfs cluster","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352244/comment/12439376","id":"12439376","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"A namenode that drops 75% of its requests for 10 minutes is a problem.  I think the first thing to do is to control the replication rate, so that fewer than 50 replications are attempted per second.  This is fairly simple to do, since the namenode controls the issuance of replication requests.  For example, it can limit the number of outstanding replications, which will effectively control the rate.\n\nThink of it this way, the namenode's observed current capacity is 200 heartbeats per second and 50 block replications per second.  We're attempting in excess of 50 replications and still attempting 200 heartbeats, and the many of the heartbeats are failing to arrive in a timely manner (as are probably many of the replication reports, but those are less critical).  Retrying heartbeats sooner will just increase the load on the namenode, aggravating the problem.\n\nThe other thing to do is limit the heartbeat traffic.  Currently, heartbeat traffic is proportional to cluster size, which is not scalable.  As a simple measure, we can make the heartbeat interval configurable.  Longer term we can make it adaptive.  Longer-yet, we could even consider inverting the control, so that the namenode pings datanodes to check if they're alive and hand them work.\n\nAnother long-term fix would of course be to improve the namenode's performance and lessen its bottlenecks, so that it can handle more requests per second.  But no matter how much we do this, we still need to make sure that all request rates are limited, and do not increase linearly with cluster size.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-03T03:01:02.000+0000","updated":"2006-10-03T03:01:02.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352244/comment/12439572","id":"12439572","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the main problem with the heartbeats right now is the 1 minute timeout before they fail.\nReducing the timeout to say 3 seconds (or may be 0 seconds we will need to experimant with that)\ncould be an easy short term solution.\nFirst of all, this will randomize data-nodes' access to the name-node, and give them equal chances to\nacknowledge their existence within the 10 minute interval.\nSecondly, we will let other requests, the most often of which are leases extensions, to go through\nand succeed, which eventually will reduce the failure rate of map-reduce tasks.\n\nIMO, this will not increase the load on the name-node, because the name-node does nothing to reject\ntimed out requests. I expect the name-node replication rate to drop automatically since it will be\nprocessing other requests between individual block replications, which is desirable. The data-nodes\nwill have to leave with higher rate of TimeoutExceptions, which is acceptable.\n\nI like the idea of self-adjusting heartbeats. Why not, if a data-node observes a consistent 30%\nrate of timed out heartbeats it should increase the heartbeat interval by 30%. And making the adjusted\nparameters persistent is a good alternative to configuring.\n\nI agree the request rates should not increase linearly with the cluster size. This makes self-adjustments\neven more important, since optimizing configurations for different cluster sizes becomes a non-trivial task.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-03T17:34:51.000+0000","updated":"2006-10-03T17:34:51.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352244/comment/12439593","id":"12439593","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> IMO, this will not increase the load on the name-node ...\n\nIt depends on where the bottlenecks are in the namenode.  For example, if heartbeats are already using 75% of its capacity, and we want replications to use the last 25%, then vastly increasing the heartbeat rate will starve the replications.  To my thinking, we should design things so that we don't see timeouts in normal operation (except when trying to contact nodes that are malfunctioning).  In particular, we shouldn't use timeouts as a primary control mechanism.\n\nAlso note that there are different kinds of timeouts.  There are connect timeouts, which mean that the server never saw the request.  Response timeouts, however, usually mean that the server has recieved the request and will eventually respond to it, but just not in the time you're willing to wait.  In the latter case, the server won't notice that the client has timed out until *after* the response has been computed.  So, if you're going to retry sooner, you should only do so after a connect timeout, and even then I'd argue that this is a poor solution.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-03T17:56:59.000+0000","updated":"2006-10-03T17:56:59.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352244/comment/12439923","id":"12439923","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"How about this approach:\n* The DataNodes register once with the NameNode after the latter comes up (and registers just once - no heartbeats).\n* Whenever the NameNode requires the services of a DataNode (to store/delete blocks), it pings the chosen DataNode to see whether it is indeed alive. As a response to the \"ping\", the DataNode sends its latest status (block report, free disk space, etc.). The response can also be controlled - if the DataNode sent its status once in the last 30 secs, it doesn't send it again.\n* For each DataNode, the NameNode maintains a list of the blocks it hosts.\n* A separate thread in the NameNode pings the set of known DataNodes and whenever it is not able to ping a particular DataNode, it issues the replication requests of the blocks that were there in that datanode (for this it takes the help of the inverse mapping from a \"block\" to the set of DataNodes containing that block).\n\nA directory walk may also be a thing to look at - the NameNode walks the file system hierarchy and for each file it pings the set of all DataNodes containing the blocks of that file but in this case, we will end up pinging the same DataNode multiple times. To avoid this, the (DataNode->{blocks}) mapping can be used.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2006-10-04T17:58:21.000+0000","updated":"2006-10-04T17:58:21.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352244/comment/12439925","id":"12439925","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Devaraj: I think your proposal is part of the long-term solution.  A short-term fix will simply be to control the rate of replication and increase the heartbeat interval.  Longer-term we should consider the sort of inverted control you propose.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-04T18:06:44.000+0000","updated":"2006-10-04T18:06:44.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352244/comment/12462059","id":"12462059","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"body":"This issue has been addressed by the following fixes:\n\nHADOOP-725\nHADOOP-641\nHADOOP-642\nHADOOP-255","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-01-03T21:39:36.563+0000","updated":"2007-01-03T21:39:36.563+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-572/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ins7:"}}