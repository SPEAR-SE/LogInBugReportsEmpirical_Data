{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12395882","self":"https://issues.apache.org/jira/rest/api/2/issue/12395882","key":"HADOOP-3376","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312972","id":"12312972","description":"","name":"0.18.0","archived":false,"released":true,"releaseDate":"2008-08-22"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-05-13T13:24:16.288+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jun 03 13:39:23 UTC 2008","customfield_12310420":"125921","customfield_12312320":null,"customfield_12310222":"10002_*:*_4_*:*_1557963916_*|*_1_*:*_4_*:*_287376369_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6934274148","customfield_12312321":null,"resolutiondate":"2008-06-03T13:39:23.503+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3376/watchers","watchCount":0,"isWatching":false},"created":"2008-05-13T05:03:43.218+0000","customfield_12310192":"Modified HOD client to look for specific messages related to resource limit overruns and take appropriate actions - such as either failing to allocate the cluster, or issuing a warning to the user. A tool is provided, specific to Maui and Torque, that will set these specific messages.","customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2008-08-22T19:50:37.651+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312090","id":"12312090","name":"contrib/hod"}],"timeoriginalestimate":null,"description":"Currently If we set up resource manager/scheduler limits on the jobs submitted, any HOD cluster that exceeds/violates these limits may 1) get blocked/queued indefinitely or 2) blocked till resources occupied by old clusters get freed. HOD should detect these scenarios and deal intelligently, instead of just waiting for a long time/ for ever. This means more and proper information to the submitter.\n\n(Internal) Use Case:\n     If there are no resource limits, users can flood the resource manager queue preventing other users from using the queue. To avoid this, we could have various types of limits setup in either resource manager or a scheduler - max node limit in torque(per job limit), maxproc limit in maui (per user/class), maxjob limit in maui(per user/class) etc. But there is one problem with the current setup - for e.g if we set up maxproc limit in maui to limit the aggregate number of nodes by any user over all jobs, 1) jobs get queued indefinitely if jobs exceed max limit and 2) blocked if it asks for nodes < max limit, but some of the resources are already used by jobs from the same user. This issue addresses how to deal with scenarios like these.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12381947","id":"12381947","filename":"checklimits.sh","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-13T11:04:58.783+0000","size":762,"mimeType":"application/x-sh","content":"https://issues.apache.org/jira/secure/attachment/12381947/checklimits.sh"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12381937","id":"12381937","filename":"HADOOP-3376","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-13T08:58:47.836+0000","size":7056,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12381937/HADOOP-3376"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12382301","id":"12382301","filename":"HADOOP-3376.1","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-19T13:46:42.251+0000","size":15490,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12382301/HADOOP-3376.1"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12382640","id":"12382640","filename":"HADOOP-3376.2","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-23T12:01:34.610+0000","size":16816,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12382640/HADOOP-3376.2"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"105070","customfield_12312823":null,"summary":"[HOD] HOD should have a way to detect and deal with clusters that violate/exceed resource manager limits","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12596330","id":"12596330","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Attaching a patch.\n\n - This implements changes required in HOD to deal better with clusters exceeding resource manager or scheduler limits.\n - After this, every time HOD detects that the cluster is still queued, HOD calls isJobFeasible method of resource manager interface (src/contrib/hod/hodlib/Hod/nodePool.py) to check if job can run if at all.\n - Torque implementation of isJobFeasible (src/contrib/hod/hodlib/NodePools/torque.py) uses the comment field in qstat output. When this comment field becomes equal to hodlib.Common.util.TORQUE_USER_LIMITS_COMMENT_FIELD, HOD deallocates the cluster with the error message \"Request execeeded maximum user limits. Cluster will not be allocated.\" . As it is, this is still only part of the solution - torque comment field has to be set to the above string either by a scheduler or by an external tool.\n - Also introducing a hod config parameter which will enable the above checking : check-job-feasibility. This defaults to false and specifies whether or not to check job feasibility - resource manager and/or scheduler limits.\n - This patches also replaces a few 'job' strings by the string 'cluster'.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-13T08:58:47.859+0000","updated":"2008-05-13T08:58:47.859+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12596354","id":"12596354","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Attaching checklimits.sh. This is the utility that would update torque comment field. Uploading for review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-13T11:04:58.803+0000","updated":"2008-05-13T11:04:58.803+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12596391","id":"12596391","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12381947/checklimits.sh\n  against trunk revision 655674.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no tests are needed for this patch.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2457/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-05-13T13:24:16.288+0000","updated":"2008-05-13T13:24:16.288+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12597448","id":"12597448","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Cancelling patch to incorporate Hemanth's comments. The following things need to be done:\n\n - Each time cluster is checked for feasibility, two qstats are run - reduce it to get required information within only one trip to resource manager.\n - There can be two ways in which user limits can be crossed - requesting for limits beyond the max limit, and cumulative usage crossing the max limits. These two scenarios should be dealt with separately - in the first case, cluster should be deallocated while in the second, cluster should not be deallocated but users should be appropriately informed.\n - Do away with the configuration variable check-job-feasibility. Instead have the variable job-feasibility-comment, which will 1)indicate whether user limits functionality has to used and 2) the comment field that will be set by checklimits.sh - currently checkjob(used by checklimits.sh) prints \"job [0-9]* violates active HARD MAXPROC limit of [0-9]* for user [a-z]*  (R: [0-9]*, U: [0-9]*])\"\n - This patch changes behavior of getJobState. It should only return True or False in all code paths.\n - Modify the error message TORQUE_USER_LIMITS_EXCEEDED_MSG so that it also prints the max limits so that user can modify his request.\n - checklimits.sh: 1) Submit this also with in  the patch as part of src/contrib/hod/support 2) checklimits.sh should only do only one iteration over all incomplete jobs and modify comment field according as the job crosses the user limits. It should be left to some outside mechanism (like cron) to run checklimits.sh repeatedly after every (some) interval of time.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-16T12:34:25.974+0000","updated":"2008-05-16T12:34:25.974+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12597955","id":"12597955","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Made the suggested changes. Also updated documentation.\n  - When asking for resources>max limits, it prints \"Request exceeded maximum user limits. CurentUsage:%s, Requested:%s, MaxLimit:%s\" at critical log level and deletes the cluster.\n  - When request is within limits but cumulative usage crosses limits, it prints \"Request exceeded maximum user limits. CurentUsage:%s, Requested:%s, MaxLimit:%s.  This cluster will remain queued till old clusters free resources\" at info level and stays in the queued state.\n  - Replaced job-feasibity config parameter with job-feasibility-attr : specifies whether to check job feasibility - resource manager and/or scheduler limits, also gives the attribute value. It defaults to TORQUE_USER_LIMITS_COMMENT_FIELD which is \"User-limits exceeded. Requested:([0-9]*) Used:([0-9]*) MaxLimit:([0-9]*). \n  - Made necessary changes in checklimits and putting it now in hod/support dir.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-19T13:46:42.286+0000","updated":"2008-05-19T13:46:42.286+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12597978","id":"12597978","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12382301/HADOOP-3376.1\n  against trunk revision 656939.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no tests are needed for this patch.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2498/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2498/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2498/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2498/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-05-19T15:31:19.762+0000","updated":"2008-05-19T15:31:19.762+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12598949","id":"12598949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"body":"Some comments:\n\n- I think job-feasibility-attr should be optional. Some code which depends on this attribute may need to check for it or change to handle it if it's not defined:\nIn torque.py.isJobFeasible, if the job-feasibility-attr is not defined, we would get an exception, where the info message being printed is not going to be very descriptive. I think it would just print 'job-feasibility-attr' and not information about what the error is.\n__check_job_state: doesn't handle case where job-feasibility-attr is not defined.\n\n- The messages now read as follows:\n(In case of req. resources > max resources):\nRequest exceeded maximum user limits. CurentUsage:%s, Requested:%s, MaxLimit:%s\n(In other case):\nRequest exceeded maximum user limits. CurentUsage:3, Requested:3, MaxLimit:3 This cluster will remain queued till old clusters free resources.\nThe message still does not clarify the resources being exceeded.\n\nI suggest the following:\nRequest number of nodes exceeded maximum user limits. Current Usage:%s, Requested:%s, Maximum Limit:%s. This cluster cannot be allocated now.\n\nand\n\nRequest number of nodes exceeded maximum user limits. Current Usage:%s, Requested:%s, Maximum Limit:%s. This cluster allocation will succeed only after other clusters are deallocated.\n(Note: I also corrected some typos in the message)\n\n- The executable bit is not being turned on for support/checklimits.sh. This is mostly due to a bug in the ant script. For code under the contrib projects, only files under the bin/ folder are made executable when packaged. As this is not a bug in HOD, I think we should leave this as it is, but update the usage documentation to make it executable.\n\n- In checklimits.sh - the sleep at the end is not required.\n\n- In case when current usage + requested usage exceeds limits, the critical message is printed every 10 seconds. It should be printed only once.\n\nOther than these, I tested checklimits and hod for both scenarios and it works fine.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-05-22T08:56:53.967+0000","updated":"2008-05-22T08:56:53.967+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12599337","id":"12599337","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Incorporated the above changes. Reattaching.\n\nThis cannot have really useful test cases - it is related to system testing and too integrated with Torque/maui.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-23T12:01:34.654+0000","updated":"2008-05-23T12:01:34.654+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12601476","id":"12601476","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12382640/HADOOP-3376.2\n  against trunk revision 661918.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no tests are needed for this patch.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2529/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2529/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2529/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2529/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-06-01T16:02:04.696+0000","updated":"2008-06-01T16:02:04.696+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12601616","id":"12601616","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=karams","name":"karams","key":"karams","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karam Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"To check this issue after setting MAXPROC limit (say 10) in maui.cfg did the following -:\n\nAdded line -: job-feasibility-attr = User-limits exceeded. Requested:([0-9]*) Used:([0-9]*) MaxLimit:([0-9]*) under section hod in hodrc. Hod requires exact string in hodrc\n\n1. When tried to use hod allocate with number of nodes greater then MAXPROC limit (say 11). Verified that hod exits with exit code 4 and proper error message saying -:  CRITICAL/50 hadoop:216 - Requested number of nodes  exceeded maximum user limits. Current Usage:0, Requested:11, Maximum Limit:10 This cluster cannot be allocated now.\n\n2. Tried a combination like first used hod allocate 5 nodes then again using hod allocate with 6 nodes. Verified that job got queued with message -:\nCRITICAL/50 hadoop:216 - Requested number of nodes  exceeded maximum user limits. Current Usage:5, Requested:6, Maximum  Limit:10 This cluster allocation will succeed only after other clusters are deallocated.\nAlso checked after first cluster got deallocated then second cluster got allocated\n\nRepeated with more hod allocate combinations\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=karams","name":"karams","key":"karams","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karam Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-06-02T12:30:53.442+0000","updated":"2008-06-02T12:30:53.442+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12395882/comment/12601936","id":"12601936","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"I just committed this. Thanks, Vinod!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2008-06-03T13:39:23.473+0000","updated":"2008-06-03T13:39:23.473+0000"}],"maxResults":11,"total":11,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3376/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ic73:"}}