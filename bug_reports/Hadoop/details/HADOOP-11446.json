{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12763568","self":"https://issues.apache.org/jira/rest/api/2/issue/12763568","key":"HADOOP-11446","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327583","id":"12327583","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-12-24T13:27:08.577+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jan 06 15:20:39 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_1001410394_*|*_1_*:*_1_*:*_88492166_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-01-05T13:00:25.774+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11446/watchers","watchCount":9,"isWatching":false},"created":"2014-12-23T22:15:23.262+0000","customfield_12310192":"The following parameters are introduced in this JIRA:\nfs.s3a.threads.max:    the maximum number of threads to allow in the pool used by TransferManager\nfs.s3a.threads.core:    the number of threads to keep in the pool used by TransferManager\nfs.s3a.threads.keepalivetime:  when the number of threads is greater than the core, this is the maximum time that excess idle threads will wait for new tasks before terminating\nfs.s3a.max.total.tasks:    the maximum number of tasks that the LinkedBlockingQueue can hold","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327179","id":"12327179","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[{"id":"12407736","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12407736","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"12773738","key":"HADOOP-11571","self":"https://issues.apache.org/jira/rest/api/2/issue/12773738","fields":{"summary":"Ãœber-jira: S3a stabilisation phase I","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-04-10T20:04:47.790+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"When working with Terry Padgett who used s3a for hbase snapshot, the following issue was uncovered.\nHere is part of the output including the OOME when hbase snapshot is exported to s3a (nofile ulimit was increased to 102400):\n{code}\n2014-12-19 13:15:03,895 INFO  [main] s3a.S3AFileSystem: OutputStream for key 'FastQueryPOC/2014-12-11/EVENT1-IDX-snapshot/.hbase-snapshot/.tmp/EVENT1_IDX_snapshot_2012_12_11/    650a5678810fbdaa91809668d11ccf09/.regioninfo' closed. Now beginning upload\n2014-12-19 13:15:03,895 INFO  [main] s3a.S3AFileSystem: Minimum upload part size: 16777216 threshold2147483647\nException in thread \"main\" java.lang.OutOfMemoryError: unable to create new native thread\n        at java.lang.Thread.start0(Native Method)\n        at java.lang.Thread.start(Thread.java:713)\n        at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:949)\n        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1360)\n        at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:132)\n        at com.amazonaws.services.s3.transfer.internal.UploadMonitor.<init>(UploadMonitor.java:129)\n        at com.amazonaws.services.s3.transfer.TransferManager.upload(TransferManager.java:449)\n        at com.amazonaws.services.s3.transfer.TransferManager.upload(TransferManager.java:382)\n        at org.apache.hadoop.fs.s3a.S3AOutputStream.close(S3AOutputStream.java:127)\n        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:54)\n        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:112)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:366)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:356)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:356)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:338)\n        at org.apache.hadoop.hbase.snapshot.ExportSnapshot.run(ExportSnapshot.java:791)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n        at org.apache.hadoop.hbase.snapshot.ExportSnapshot.innerMain(ExportSnapshot.java:882)\n        at org.apache.hadoop.hbase.snapshot.ExportSnapshot.main(ExportSnapshot.java:886)\n{code}\nIn S3AOutputStream#close():\n{code}\n      TransferManager transfers = new TransferManager(client);\n{code}\nThis results in each TransferManager creating its own thread pool, leading to the OOME.\nOne solution is to pass shared thread pool to TransferManager.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327583","id":"12327583","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12690088","id":"12690088","filename":"hadoop-11446.addendum","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-01-05T15:04:02.710+0000","size":1656,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12690088/hadoop-11446.addendum"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12689078","id":"12689078","filename":"hadoop-11446-001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-24T22:49:57.996+0000","size":7489,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12689078/hadoop-11446-001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12689269","id":"12689269","filename":"hadoop-11446-002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-28T22:58:06.550+0000","size":9585,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12689269/hadoop-11446-002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12689537","id":"12689537","filename":"hadoop-11446-003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-30T18:04:14.001+0000","size":9802,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12689537/hadoop-11446-003.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"S3AOutputStream should use shared thread pool to avoid OutOfMemoryError","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14258240","id":"14258240","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"body":"Maybe we can take it even further and share a single TransferManager (as advised by AWS) with a custom threadpool of tunable size (default is FixedThreadPool(10), which is probably too low). Thus, construct a final TransferManager in S3AFileSystem.initialize() and pass it around (to S3AOutputStream)?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"created":"2014-12-24T13:27:08.577+0000","updated":"2014-12-24T13:27:08.577+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14258579","id":"14258579","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the comment, Thomas.\nAmazonS3Client is used to construct TransferManager. I replaced it with TransferManager in S3AOutputStream ctor.\n\nIntroduced the following parameters which control threadpool used by TransferManager:\nfs.s3a.threads.max\nfs.s3a.threads.core\nfs.s3a.max.total.tasks\nfs.s3a.threads.keepalivetime","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-24T22:54:29.228+0000","updated":"2014-12-24T22:54:29.228+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14258590","id":"14258590","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12689078/hadoop-11446-001.patch\n  against trunk revision 4f18018.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-aws.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5341//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5341//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-12-24T23:32:34.287+0000","updated":"2014-12-24T23:32:34.287+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14259682","id":"14259682","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"body":"Hi Ted,\nLooks good to me. Some minor remarks:\n\n- The parameters should be defined (and documented) in Constants.java. Your default of fs.s3a.threads.core=256 means up to 256 parallel (part)Uploads. That should fill up your network pipe :p. However, the number of concurrent http connections opened by the underlying AmazonS3Client (fs.s3a.max.connections) is set to a much lower value by default (too low?). Could you elaborate on the default values? I think we should tweak these a bit to give a good \"out of the box\" experience and/or document some tuning guidelines for different network conditions (use cases).\n\n- Also use the shiny new single TransferManager for purging at the end of initialize() in S3AFileSystem, replacing the following code path\n{code}\nif (purgeExistingMultipart) {\n      TransferManager transferManager = new TransferManager(s3);\n{code}\n\n- I like that you went for a low-level implementation for the Executor instead of using Executors.newFixedThreadPool. The ability to block submitting threads by setting fs.s3a.max.total.tasks  is nice tool for limiting memory consumption. Out of curiosiity: can you envision use cases where setting different values for core.threads and max.threads would be important? \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"created":"2014-12-28T17:40:30.380+0000","updated":"2014-12-28T17:40:30.380+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14259740","id":"14259740","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"body":"w.r.t. comment #1 above:\n{code}\n    awsConf.setMaxConnections(conf.getInt(MAXIMUM_CONNECTIONS, \n      DEFAULT_MAXIMUM_CONNECTIONS));\n{code}\nThe default value is from current setting.\nDo you think setting max connections as value for fs.s3a.threads.core makes sense ?\n\nw.r.t. last comment, having different values for core.threads and max.threads would get the full potential out of ThreadPoolExecutor.\n\nNext patch would address remaining comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-28T22:45:43.990+0000","updated":"2014-12-28T22:45:43.990+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14259757","id":"14259757","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12689269/hadoop-11446-002.patch\n  against trunk revision 1454efe.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-aws.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5351//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5351//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-12-28T23:32:17.884+0000","updated":"2014-12-28T23:32:17.884+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14261298","id":"14261298","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Ted, could you pull \"fs.s3a.max.total.tasks\" & its default value into the constants class.\n\nI think we'll need the doc updated with the config options too.\n\ntest-wise, I can't see an easy way to test that this works, except by you repeating your experiment","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-12-30T17:49:49.052+0000","updated":"2014-12-30T17:49:49.052+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14261311","id":"14261311","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch v3 addresses Steve's comment.\n\nOnce the set of new parameters has been agreed upon, I will update release note.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-30T18:04:14.010+0000","updated":"2014-12-30T18:04:14.010+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14261344","id":"14261344","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12689537/hadoop-11446-003.patch\n  against trunk revision 6621c35.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-aws.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5352//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5352//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-12-30T18:42:38.799+0000","updated":"2014-12-30T18:42:38.799+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14263511","id":"14263511","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-01-03T11:58:02.928+0000","updated":"2015-01-03T11:58:02.928+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14264572","id":"14264572","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #6805 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6805/])\nHADOOP-11446 S3AOutputStream should use shared thread pool to avoid OutOfMemoryError (stevel: rev 27d8395867f665fea1360087325cda5ed70efd0c)\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AOutputStream.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-05T13:12:34.176+0000","updated":"2015-01-05T13:12:34.176+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14264582","id":"14264582","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"body":"Some remarks: \n- I guess that at the end of \"purging\" the TransferManager should not be shut down?\n- Which got me thinking: Should we override FileSystem.close() in S3AFileSystem to call TransferManager.shutDownNow(true)? This will shut down the thread pool and AmazonS3Client. Otherwise, these resources may still leak? \n\nRegarding my previous comments: I see no harm in giving users full control, although probably a linear relation between fs.s3a.max.connections and fs.s3a.threads.core (etc.) is suitable (at least that's what I derive from the aws-sdk source code, I haven't tested this yet). However, we should at least document their interplay as f.i. increasing threads while keeping connections fixed will likely not yield the (linear) performance improvement users might expect. \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"created":"2015-01-05T13:23:01.707+0000","updated":"2015-01-05T13:23:01.707+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14264649","id":"14264649","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"body":"Thomas:\nAddendum addresses your comment.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-01-05T15:04:02.716+0000","updated":"2015-01-05T15:04:02.716+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14265694","id":"14265694","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"body":"Relying on FileSystem.close() to be called would not always work - ExportSnapshot from hbase doesn't call close().\n\nFYI","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-01-06T04:57:58.119+0000","updated":"2015-01-06T04:57:58.119+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14265945","id":"14265945","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"is this addendum something you want to get in? If so, it's going to have to be another patch I'm afraid","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-01-06T10:35:53.327+0000","updated":"2015-01-06T10:35:53.327+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14265975","id":"14265975","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk #799 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/799/])\nHADOOP-11446 S3AOutputStream should use shared thread pool to avoid OutOfMemoryError (stevel: rev 27d8395867f665fea1360087325cda5ed70efd0c)\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AOutputStream.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-06T11:33:55.349+0000","updated":"2015-01-06T11:33:55.349+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14265990","id":"14265990","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #65 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/65/])\nHADOOP-11446 S3AOutputStream should use shared thread pool to avoid OutOfMemoryError (stevel: rev 27d8395867f665fea1360087325cda5ed70efd0c)\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AOutputStream.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-06T11:42:17.180+0000","updated":"2015-01-06T11:42:17.180+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14266025","id":"14266025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"body":"@ [~tedyu]: \n- I fear we have overlooked this: copyFile and copyLocalFile still use a method-local TransferManager transfers object (instead of the class member object aka this.transfers). The addendum removes the shutDown() calls to the local transfermanager there but we should entirely abolish the local objects and only use this.transfers.\n- concerning close():  I guess calling close is left to the end user. However, I think we do not leak memory as long as fs.s3a.threads.keepalivetime > 0. Because you set tpe.allowCoreThreadTimeOut(true), the TransferManager will be garbage collected after it goes out of scope AND all (core) threads have timed out. Correct?\n\n@[~stevel@apache.org]: I fear we should. Without the addendum: if the purge code is hit, the next fs command will throw an error as the TransferManager has been shut down. Furthermore,  my first remark above hints at an addendum-002 ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"created":"2015-01-06T12:10:13.504+0000","updated":"2015-01-06T12:10:13.504+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14266141","id":"14266141","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk #1997 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1997/])\nHADOOP-11446 S3AOutputStream should use shared thread pool to avoid OutOfMemoryError (stevel: rev 27d8395867f665fea1360087325cda5ed70efd0c)\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AOutputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-06T14:20:45.479+0000","updated":"2015-01-06T14:20:45.479+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14266164","id":"14266164","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Hdfs-trunk-Java8 #62 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/62/])\nHADOOP-11446 S3AOutputStream should use shared thread pool to avoid OutOfMemoryError (stevel: rev 27d8395867f665fea1360087325cda5ed70efd0c)\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AOutputStream.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-06T14:38:29.439+0000","updated":"2015-01-06T14:38:29.439+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14266205","id":"14266205","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #66 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/66/])\nHADOOP-11446 S3AOutputStream should use shared thread pool to avoid OutOfMemoryError (stevel: rev 27d8395867f665fea1360087325cda5ed70efd0c)\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AOutputStream.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-06T15:02:15.807+0000","updated":"2015-01-06T15:02:15.807+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12763568/comment/14266248","id":"14266248","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk #2016 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2016/])\nHADOOP-11446 S3AOutputStream should use shared thread pool to avoid OutOfMemoryError (stevel: rev 27d8395867f665fea1360087325cda5ed70efd0c)\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AOutputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-06T15:20:39.675+0000","updated":"2015-01-06T15:20:39.675+0000"}],"maxResults":22,"total":22,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11446/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i23qrb:"}}