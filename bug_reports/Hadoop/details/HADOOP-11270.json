{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12752902","self":"https://issues.apache.org/jira/rest/api/2/issue/12752902","key":"HADOOP-11270","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-11-05T09:40:36.669+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jul 01 11:32:59 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11270/watchers","watchCount":5,"isWatching":false},"created":"2014-11-04T23:27:48.839+0000","customfield_12310192":"Update NativeS3FsInputStream's seek(length(file)) behavior to be similar to DFSInputStream.","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327745","id":"12327745","description":"2.5.1 release","name":"2.5.1","archived":false,"released":true,"releaseDate":"2014-09-05"}],"issuelinks":[{"id":"12403743","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12403743","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12762238","key":"HADOOP-11417","self":"https://issues.apache.org/jira/rest/api/2/issue/12762238","fields":{"summary":"review filesystem seek logic, clarify/confirm spec, test & fix compliance","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/3","id":"3","description":"A task that needs to be done.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype","name":"Task","subtask":false,"avatarId":21148}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-07-01T11:32:59.837+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"There is a difference in behavior while seeking a given file present\nin S3 using NativeS3FileSystem$NativeS3FsInputStream and a file present in HDFS using DFSInputStream.\n\nIf we seek to the end of the file incase of NativeS3FsInputStream, it fails with exception \"java.io.EOFException: Attempted to seek or read past the end of the file\". That is because a getObject request is issued on the S3 object with range start as value of length of file.\n\nThis is the complete exception stack:-\nCaused by: java.io.EOFException: Attempted to seek or read past the end of the file\nat org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:462)\nat org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.handleException(Jets3tNativeFileSystemStore.java:411)\nat org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieve(Jets3tNativeFileSystemStore.java:234)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:601)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\nat org.apache.hadoop.fs.s3native.$Proxy17.retrieve(Unknown Source)\nat org.apache.hadoop.fs.s3native.NativeS3FileSystem$NativeS3FsInputStream.seek(NativeS3FileSystem.java:205)\nat org.apache.hadoop.fs.BufferedFSInputStream.seek(BufferedFSInputStream.java:96)\nat org.apache.hadoop.fs.BufferedFSInputStream.skip(BufferedFSInputStream.java:67)\nat java.io.DataInputStream.skipBytes(DataInputStream.java:220)\nat org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer.readFields(RCFile.java:739)\nat org.apache.hadoop.hive.ql.io.RCFile$Reader.currentValueBuffer(RCFile.java:1720)\nat org.apache.hadoop.hive.ql.io.RCFile$Reader.getCurrentRow(RCFile.java:1898)\nat org.apache.hadoop.hive.ql.io.RCFileRecordReader.next(RCFileRecordReader.java:149)\nat org.apache.hadoop.hive.ql.io.RCFileRecordReader.next(RCFileRecordReader.java:44)\nat org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:339)\n... 15 more","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12686743","id":"12686743","filename":"HADOOP-11270.02.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-12T01:51:43.481+0000","size":2809,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12686743/HADOOP-11270.02.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12686763","id":"12686763","filename":"HADOOP-11270.03.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-12T04:39:35.386+0000","size":3196,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12686763/HADOOP-11270.03.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12815674","id":"12815674","filename":"HADOOP-11270.04.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-07-01T04:03:30.126+0000","size":1602,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12815674/HADOOP-11270.04.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12681635","id":"12681635","filename":"HADOOP-11270.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-11-14T22:35:05.465+0000","size":1461,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12681635/HADOOP-11270.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Seek behavior difference between NativeS3FsInputStream and DFSInputStream","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14198024","id":"14198024","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"body":"Hi Venkata,\n\nThe behavior of different file systems has been documented (quite recently). Have a look at [http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/filesystem/index.html].\n\nIf you look at the contract for s3n (s3n.xml) you will find\n\n  <property>\n    <name>fs.contract.rejects-seek-past-eof</name>\n    <value>true</value>\n  </property>\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"created":"2014-11-05T09:40:36.669+0000","updated":"2014-11-05T09:40:36.669+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14198066","id":"14198066","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"# which version of Hadoop is this; Hadoop 2.4 had a broken seek\n# are you trying to do {{seek(len(file))}} or {{seek(len(file)-1)}}?\n# is the file 0 bytes long.\n\nI would recommend you test on Hadoop 2.5.1; the semantics of filesystem access has change, as Thomas pointed out. And {{seek()}} turned out to be the most inconsistent of them (exceptions, actions on a negative value, seeking on the current position, etc.)\n\nFinally, yes, filesystems are different and that's a WONTFIX. Example: a native fileystem doesn't raise any exception on the seek, only on the following read(). HDFS and others do fail fast on the seek. Which is why I'm surprised you are seeing a difference between HDFS and S3N; both are going to reject on the seek()","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-11-05T10:08:06.047+0000","updated":"2014-11-05T10:08:06.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14198868","id":"14198868","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for your inputs!\n\n[~stevel@apache.org], my responses:\n1. I am currently using Hadoop 2.5.1.\n2. I am trying seek(len(file)).\n3. No, the file size is more than 1MB.\n\nI understand that behavior across file systems can be different. But I believe seek(<length of file>) should be supported by s3n as well.\nI have noticed that seek() method in NativeS3FsInputStream creates a new input stream by performing a getObject() starting from seek position. This fails when seek position is length of file. Instead we could do this:-\na. If the new seek position is greater than the current position of the stream, skip the difference in the underlying input stream.\nb. If the new seek position is less than the current position of the stream, get a new input stream starting from this position.\nI tested this change and its working. Please let me know your thoughts on this.\n\nOne impact of current behavior is that Hive reads for RCFiles stored in S3 fail when it tries to skip columns by issuing skipBytes() on this input stream.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-11-05T19:00:34.622+0000","updated":"2014-11-05T19:00:34.622+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14200082","id":"14200082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"\nthe operation {{seek(len(file))}} is considered to be going one byte too far, according to [[our current filesystem specification|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/site/markdown/filesystem/fsdatainputstream.md#seekableseeks]]\n\nthat's because offsets begin at 0.\n\nregarding the forward skipping, that's what the swift:// fs client does, [[for short distances of forward seeks|https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeInputStream.java#L300]]. This is because its expensive to re-open an http connection â€”going forward is far more efficient for short blocks. Nobody has (yet) backported the feature to the s3 filesystems. On longer reads it becomes more efficient to close and re-open. (especially long haul, but even short haul as the IO bandwidth of a s3 read is ~constant irrespective of the #of readers. If you have lots of jobs reading the same s3 file, you want them closing and reopening the file).\n\nto summarise\n# yes, some forward seeking by chomping bytes is worth doing, but purely for efficiency.\n# I dont' consider raising an exception on {{seek(len(file))}} to be an error. It's what HDFS does too,","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-11-06T11:17:48.821+0000","updated":"2014-11-06T11:17:48.821+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14212977","id":"14212977","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"body":"[~stevel@apache.org], HDFS currently supports seek(len(file)), it doesn't throw an error. Code snippet from seek() in DFSInputStream.java:-\n\n{quote}\n    if (targetPos > getFileLength()) \\{\n      throw new EOFException(\"Cannot seek after EOF\");\n    \\}\n{quote}\n\nEOF exception is thrown only when the seek position crosses the length of file.\nSince our current filesystem spec doesn't mandate that an error should be thrown at seek(len(file)), I believe this is acceptable.\nWe would need similar behavior for NativeS3FileSystem so that the clients using FSDataInputStream will be able to seek irrespective of hdfs/s3n scheme.\nI have submitted a patch that will ensure same behavior for NativeS3FileSystem in-case of seek(len(file)).\n\nCan you please review?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-11-14T22:35:05.476+0000","updated":"2014-11-14T22:35:05.476+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14213051","id":"14213051","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12681635/HADOOP-11270.patch\n  against trunk revision 49c3889.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-aws.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5087//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5087//artifact/patchprocess/newPatchFindbugsWarningshadoop-aws.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5087//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-11-14T23:20:54.120+0000","updated":"2014-11-14T23:20:54.120+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14213080","id":"14213080","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"body":"I am working on writing the testcase.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-11-14T23:41:30.282+0000","updated":"2014-11-14T23:41:30.282+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14243577","id":"14243577","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"body":"Updated patch after adding test case and addressing findbugs warning.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-12T01:52:18.481+0000","updated":"2014-12-12T01:52:18.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14243606","id":"14243606","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12686743/HADOOP-11270.02.patch\n  against trunk revision 5b9fced.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.\n\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5250//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-12-12T02:21:15.505+0000","updated":"2014-12-12T02:21:15.505+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14243721","id":"14243721","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12686763/HADOOP-11270.03.patch\n  against trunk revision b437f5e.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-aws.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5251//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5251//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-12-12T05:12:16.050+0000","updated":"2014-12-12T05:12:16.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14245046","id":"14245046","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"body":"[~stevel@apache.org], I resubmitted the patch with testcase.\nCan you please review?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-13T00:28:56.514+0000","updated":"2014-12-13T00:28:56.514+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14249271","id":"14249271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"body":"[~stevel@apache.org], can you please review?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vravuri%40ea.com","name":"vravuri@ea.com","key":"vravuri@ea.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkata Puneet Ravuri","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-17T01:30:16.801+0000","updated":"2014-12-17T01:30:16.801+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14249672","id":"14249672","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Venkata, I've created a new issue, HADOOP-11417, to get me to work out exactly what HDFS does, correct the spec if needed, and add a test in the FS contract to see what the filesystems do.\n\nIf we have to change s3n/s3a, this will be the s3n patch, which should remap to s3a with relative ease.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-12-17T10:03:58.438+0000","updated":"2014-12-17T10:03:58.438+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14524997","id":"14524997","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12686763/HADOOP-11270.03.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / f1a152c |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6372/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T05:06:41.733+0000","updated":"2015-05-02T05:06:41.733+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/14525014","id":"14525014","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12686763/HADOOP-11270.03.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / f1a152c |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6376/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T05:10:53.041+0000","updated":"2015-05-02T05:10:53.041+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/15358360","id":"15358360","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 10s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 18s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 28s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 11s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 1 new + 30 unchanged - 5 fixed = 31 total (was 35) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 35s{color} | {color:red} hadoop-tools/hadoop-aws generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 13s{color} | {color:green} hadoop-aws in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 12m 47s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-tools/hadoop-aws |\n|  |  org.apache.hadoop.fs.s3native.NativeS3FileSystem$NativeS3FsInputStream.reopen(long) ignores result of java.io.InputStream.skip(long)  At NativeS3FileSystem.java: At NativeS3FileSystem.java:[line 207] |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:85209cc |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12815674/HADOOP-11270.04.patch |\n| JIRA Issue | HADOOP-11270 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 4e0a6688e24b 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 846ada2 |\n| Default Java | 1.8.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/9912/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/9912/artifact/patchprocess/new-findbugs-hadoop-tools_hadoop-aws.html |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9912/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9912/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-01T04:21:33.638+0000","updated":"2016-07-01T04:21:33.638+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/15358813","id":"15358813","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Usual S3x patch question: which S3 installation have you run the full hadoop-aws test suite against? Jenkins doesn't test that bit, see.\n\nAlso: is there a seek test that we need? I've done a lot of extra work on seek tests on S3A, and actually hoped that I'd fixed this issue there. If S3n still has it, then the other S3 and object store clients may still have it too. \n\nCould you see what you can add to {{AbstractContractSeekTest}} in branch-2 or trunk to create the problem before your patch goes in, make it go away after. And, if s3a, s3, swift and azure have the issue, have their subclasses skip that test for now ... that'd be extra patches","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-07-01T11:15:17.791+0000","updated":"2016-07-01T11:15:17.791+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12752902/comment/15358829","id":"15358829","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"+findbugs warning isn't to be ignored. Skip result should be used to check range skipped, consider some policy if != desired. Warn? repeat seek? {{S3AInputStream}} does a warning","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-07-01T11:32:59.837+0000","updated":"2016-07-01T11:32:59.837+0000"}],"maxResults":18,"total":18,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11270/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i21z3b:"}}