{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13102863","self":"https://issues.apache.org/jira/rest/api/2/issue/13102863","key":"HADOOP-14877","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-12-20T16:13:23.142+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jan 03 13:51:33 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14877/watchers","watchCount":3,"isWatching":false},"created":"2017-09-18T03:38:05.824+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341432","id":"12341432","description":"3.1.0 release","name":"3.1.0","archived":false,"released":true,"releaseDate":"2018-04-06"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-03-20T18:17:31.697+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311543","id":"12311543","name":"build","description":"Build scripts"}],"timeoriginalestimate":null,"description":"{noformat}\n[INFO] Dependencies classpath:\nD:\\trunk\\hadoop\\hadoop-client-modules\\hadoop-client-runtime\\target\\hadoop-client-runtime-3.1.0-SNAPSHOT.jar;D:\\trunk\\had\noop\\hadoop-client-modules\\hadoop-client-api\\target\\hadoop-client-api-3.1.0-SNAPSHOT.jar\n[INFO]\n[INFO] --- exec-maven-plugin:1.3.1:exec (check-jar-contents) @ hadoop-client-check-invariants ---\njava.io.FileNotFoundException: D (The system cannot find the file specified)\n        at java.util.zip.ZipFile.open(Native Method)\n        at java.util.zip.ZipFile.<init>(ZipFile.java:219)\n        at java.util.zip.ZipFile.<init>(ZipFile.java:149)\n        at java.util.zip.ZipFile.<init>(ZipFile.java:120)\n        at sun.tools.jar.Main.list(Main.java:1115)\n        at sun.tools.jar.Main.run(Main.java:293)\n        at sun.tools.jar.Main.main(Main.java:1288)\njava.io.FileNotFoundException: \\trunk\\hadoop\\hadoop-client-modules\\hadoop-client-runtime\\target\\hadoop-client-runtime-3.\n1.0-SNAPSHOT.jar;D (The system cannot find the file specified)\n        at java.util.zip.ZipFile.open(Native Method)\n        at java.util.zip.ZipFile.<init>(ZipFile.java:219)\n        at java.util.zip.ZipFile.<init>(ZipFile.java:149)\n        at java.util.zip.ZipFile.<init>(ZipFile.java:120)\n        at sun.tools.jar.Main.list(Main.java:1115)\n        at sun.tools.jar.Main.run(Main.java:293)\n        at sun.tools.jar.Main.main(Main.java:1288)\n[INFO] Artifact looks correct: 'D'\n[INFO] Artifact looks correct: 'hadoop-client-runtime-3.1.0-SNAPSHOT.jar;D'\n[ERROR] Found artifact with unexpected contents: '\\trunk\\hadoop\\hadoop-client-modules\\hadoop-client-api\\target\\hadoop-cl\nient-api-3.1.0-SNAPSHOT.jar'\n    Please check the following and either correct the build or update\n    the allowed list with reasoning.\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12342324","id":"12342324","description":"3.2 release","name":"3.2.0","archived":false,"released":false}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12903076","id":"12903076","filename":"HADOOP-14877-001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-12-20T16:56:59.696+0000","size":1696,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12903076/HADOOP-14877-001.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Trunk compilation fails in windows","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"windows","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13102863/comment/16298678","id":"16298678","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I'm getting different failures\r\n\r\nIssue 1: command line for javah too big. Fix: build local maven-native-plugin java 1.0.9-SNAPSHOT and set the <useenv> option. This gets hadoop-common to build.\r\nIssue 2: hadoop-hdfs not compiling with xref issues. Not seen this before. protoc? Paths? Case logic? \r\n\r\nOddly enough, it's imports of inner enums which aren't being found.\r\n{code}\r\n[ERROR] /C:/Work/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java:[77,72] cannot find symbol\r\n[ERROR] symbol:   class AccessMode\r\n[ERROR] location: class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier\r\n{code}\r\n\r\nThis file is in hadoop-client, and I've verified that the file BlockTokenIdentified$AccessMode.class is in the compiled directory tree. Not getting into JAR, wrong JAR version, CP setup for javac?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-12-20T16:13:23.142+0000","updated":"2017-12-20T16:13:23.142+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13102863/comment/16298738","id":"16298738","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"patch 001: On windows builds, use the 1.0-alpha-9-SNAPSHOT native maven plugin, and so switch to the CLASSPATH env var, avoiding command line length problems.\r\n\r\nI was  having problems with my build because the maven clean wasn't taking until the hadoop maven plugin was built; there's a bootstrap problem. Until have done a full clean, old cruft can hang around, creating problems.\r\n\r\n\r\n# run mvn clean to purge old bits, and make sure that it had completed\r\n# run mvn install -DskipTests -DskipShade to do the install, making sure that the hadoop-maven-plugin had been built.\r\n# rerun mvn clean\r\n# rerun mvn install\r\n# do the mvn package -Pdist -DskipTests -Dmaven.javadoc.skip=true -DskipShade \r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-12-20T17:00:40.015+0000","updated":"2017-12-20T17:00:40.015+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13102863/comment/16298879","id":"16298879","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  8s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 35s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m  9s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 43m 27s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 41s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 41s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  6s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 19s{color} | {color:green} hadoop-project in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 15s{color} | {color:red} hadoop-common in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 80m 44s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HADOOP-14877 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12903076/HADOOP-14877-001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  xml  |\r\n| uname | Linux 1e20b9784012 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 13ad747 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13862/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13862/testReport/ |\r\n| Max. process+thread count | 1766 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-project hadoop-common-project/hadoop-common U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13862/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2017-12-20T18:31:41.702+0000","updated":"2017-12-20T18:31:41.702+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13102863/comment/16301561","id":"16301561","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"bq.Issue 1: command line for javah too big. Fix: build local maven-native-plugin java 1.0.9-SNAPSHOT and set the <useenv> option. This gets hadoop-common to build.\r\nThis I fixed by setting the repo path shorter (i.e -Dmaven.repo.local=D:/repo).Same I have suggested in user [mailing list|https://mail-archives.apache.org/mod_mbox/hadoop-common-dev/201702.mbox/%3CDM3PR18MB079583B2B7578530E7657FDDE14C0@DM3PR18MB0795.namprd18.prod.outlook.com%3E].Hope you also getting the same. Your patch make sense to me,as we can't retrict. \r\nbq.Issue 2: hadoop-hdfs not compiling with xref issues. Not seen this before. protoc? Paths? Case logic?\r\nI didn't face this issue.and {{mvn package -Pdist -DskipTests -Dmaven.javadoc.skip=true -DskipShade}} will success in my PC.\r\n\r\nComing to this jira, this will come always,if we execute without \"{{-DskipShade}}\"(i.e {{mvn clean install -DskipTests}}) since winddows path seperator is not handled in [ensure-jars-have-correct-contents.sh|https://github.com/apache/hadoop/blob/trunk/hadoop-client-modules/hadoop-client-check-invariants/src/test/resources/ensure-jars-have-correct-contents.sh#L63]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-12-22T15:26:59.738+0000","updated":"2017-12-22T15:26:59.738+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13102863/comment/16306791","id":"16306791","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"{{ -Dmaven.repo.local=D:/repo).}} should do, & better than using snapshot plugins. \r\n\r\nNeeds a doc update","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-12-30T14:33:58.248+0000","updated":"2017-12-30T14:33:58.248+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13102863/comment/16307692","id":"16307692","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"bq.Needs a doc update\r\nOk,this can be handle in seperate jira.? Since this jira is for different..?\r\n\r\nand better to update [TroubleShooting|https://wiki.apache.org/hadoop/TroubleShooting]..?\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2018-01-02T04:59:31.194+0000","updated":"2018-01-02T04:59:31.194+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13102863/comment/16309669","id":"16309669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"* we need to move the old wiki entries to confluent\r\n* given this JIRA exists, I think the docs can go in here","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-01-03T13:51:33.902+0000","updated":"2018-01-03T13:51:33.902+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14877/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3k67b:"}}