{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12504033","self":"https://issues.apache.org/jira/rest/api/2/issue/12504033","key":"HADOOP-7488","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2011-05-03T05:33:16.396+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 22 21:02:29 UTC 2012","customfield_12310420":"35483","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_3632933985_*|*_1_*:*_2_*:*_39431814727_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-08-22T21:03:06.440+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-7488/watchers","watchCount":11,"isWatching":false},"created":"2011-04-12T10:37:17.786+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12356894","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12356894","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12470466","key":"HADOOP-6889","self":"https://issues.apache.org/jira/rest/api/2/issue/12470466","fields":{"summary":"Make RPC to have an option to timeout","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-08-22T21:04:15.541+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310688","id":"12310688","name":"ipc","description":""}],"timeoriginalestimate":null,"description":"When NN/DN is shutdown gracefully, the DFSClient operations which are waiting for a response from NN/DN, will throw exception & come out quickly\n\nBut when the NN/DN network is unplugged, the DFSClient operations which are waiting for a response from NN/DN, waits for ever.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12488095","id":"12488095","filename":"HADOOP-7488.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-28T13:16:48.598+0000","size":6462,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12488095/HADOOP-7488.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"46524","customfield_12312823":null,"summary":"When Namenode network is unplugged, DFSClient operations waits for ever","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13028030","id":"13028030","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"body":"The problem was whenever network was unplugged the read operation was getting a timedout exception and it was trying again. This continued for almost 15 times and only then some connectionloss exception came and could come out.\nBy this time it was taking around 45 mins.\nHence we have done something like, configure the parameter \n\"max.ping.retries.on.socket.timeout\" to a value where you can configure a value after which it should come out after getting a socket time.  So while retrying chk for this configured value and once reached come out.\n\nThis problem comes only in unplug scenarios.  So based on the scenario this value can be configured as to when how much time it should chk to get a connection.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-05-03T05:33:16.396+0000","updated":"2011-05-03T05:33:16.396+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13028262","id":"13028262","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"# which version are you seeing this on?\n# when you say unplugged, do you mean the ethernet port of your local machine came unplugged, or the connection to the remote server failed?\n# Can you add the stack trace you see in the exceptions, to show where the problem is?\n\nThis is an HDFS problem, so re-assigning there\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2011-05-03T15:18:30.431+0000","updated":"2011-05-03T15:18:30.431+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13029904","id":"13029904","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi pls find the logs below\n\n2010-06-06 19:56:45,406 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null\n2010-06-06 19:56:45,426 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020\n2010-06-06 19:56:45,428 INFO org.apache.hadoop.ipc.metrics.RpcDetailedMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020\n2010-06-06 19:56:45,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnRegistration = DatanodeRegistration(linux112:50010, storageID=, infoPort=50075, ipcPort=50020)\n2010-06-06 19:56:45,437 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020\n2010-06-06 19:56:47,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: New storage id DS-1238806821-10.18.52.112-50010-1275834407685 is assigned to data-node 10.18.52.112:50010\n2010-06-06 19:56:47,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.18.52.112:50010, storageID=DS-1238806821-10.18.52.112-50010-1275834407685, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ramkrishna/opensrchadoop/hadoop-common-0.23.0-SNAPSHOT/hadoop-root/dfs/data/current/finalized'}\n2010-06-06 19:56:47,806 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting\n2010-06-06 19:56:47,808 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting\n2010-06-06 19:56:47,808 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting\n2010-06-06 19:56:47,809 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting\n2010-06-06 19:56:47,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: using BLOCKREPORT_INTERVAL of 60000msec Initial delay: 0msec\n2010-06-06 19:56:47,810 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting\n2010-06-06 19:56:47,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 2 msec to generate and 17 msecs for RPC and NN processing\n2010-06-06 19:56:47,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting Periodic block scanner.\n2010-06-06 19:57:32,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 4 msecs for RPC and NN processing\n2010-06-06 19:58:32,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 3 msecs for RPC and NN processing\n2010-06-06 20:14:40,742 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to /10.18.52.181:9000 failed on local exception: java.io.IOException: No route to host\n\tat org.apache.hadoop.ipc.Client.wrapException(Client.java:1087)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1055)\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:251)\n\tat $Proxy4.sendHeartbeat(Unknown Source)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:933)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1489)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.io.IOException: No route to host\n\tat sun.nio.ch.FileDispatcher.read0(Native Method)\n\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)\n\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:233)\n\tat sun.nio.ch.IOUtil.read(IOUtil.java:206)\n\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:236)\n\tat org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:59)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:159)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:132)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:116)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:371)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:237)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:370)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:784)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:722)\n\n2010-06-06 20:14:44,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 0 time(s).\n2010-06-06 20:14:48,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 1 time(s).\n2010-06-06 20:14:52,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 2 time(s).\n2010-06-06 20:14:56,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 3 time(s).\n2010-06-06 20:15:00,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 4 time(s).\n2010-06-06 20:15:04,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 5 time(s).\n2010-06-06 20:15:08,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 6 time(s).\n2010-06-06 20:15:12,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 7 time(s).\n2010-06-06 20:15:16,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 8 time(s).\n2010-06-06 20:15:20,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 9 time(s).\n2010-06-06 20:15:23,827 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to /10.18.52.181:9000 failed on local exception: java.net.NoRouteToHostException: No route to host\n\tat org.apache.hadoop.ipc.Client.wrapException(Client.java:1087)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1055)\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:251)\n\tat $Proxy4.sendHeartbeat(Unknown Source)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:933)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1489)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.net.NoRouteToHostException: No route to host\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:375)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:440)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:528)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:209)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1188)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1032)\n\t... 5 more\n\n2010-06-06 20:15:27,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 0 time(s).\n2010-06-06 20:15:31,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 1 time(s).\n2010-06-06 20:15:35,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 2 time(s).\n2010-06-06 20:15:39,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 3 time(s).\n2010-06-06 20:15:43,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 4 time(s).\n2010-06-06 20:15:47,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 5 time(s).\n2010-06-06 20:15:51,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 6 time(s).\n2010-06-06 20:15:55,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 7 time(s).\n2010-06-06 20:15:59,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 8 time(s).\n2010-06-06 20:16:03,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 9 time(s).\n2010-06-06 20:16:06,914 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to /10.18.52.181:9000 failed on local exception: java.net.NoRouteToHostException: No route to host\n\tat org.apache.hadoop.ipc.Client.wrapException(Client.java:1087)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1055)\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:251)\n\tat $Proxy4.sendHeartbeat(Unknown Source)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:933)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1489)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.net.NoRouteToHostException: No route to host\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:375)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:440)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:528)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:209)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1188)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1032)\n\t... 5 more\n\n2010-06-06 20:16:10,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 0 time(s).\n2010-06-06 20:16:14,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 1 time(s).\n2010-06-06 20:16:18,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 2 time(s).\n2010-06-06 20:16:22,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 3 time(s).\n2010-06-06 20:16:26,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 4 time(s).\n2010-06-06 20:16:30,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 5 time(s).\n2010-06-06 20:16:34,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 6 time(s).\n2010-06-06 20:16:38,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 7 time(s).\n2010-06-06 20:16:42,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 8 time(s).\n2010-06-06 20:16:46,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 9 time(s).\n2010-06-06 20:16:50,001 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to /10.18.52.181:9000 failed on local exception: java.net.NoRouteToHostException: No route to host\n\tat org.apache.hadoop.ipc.Client.wrapException(Client.java:1087)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1055)\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:251)\n\tat $Proxy4.sendHeartbeat(Unknown Source)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:933)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1489)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.net.NoRouteToHostException: No route to host\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:375)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:440)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:528)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:209)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1188)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1032)\n\t... 5 more\n\n2010-06-06 20:16:54,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 0 time(s).\n2010-06-06 20:16:58,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 1 time(s).\n2010-06-06 20:17:02,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 2 time(s).\n2010-06-06 20:17:06,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 3 time(s).\n2010-06-06 20:17:10,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 4 time(s).\n2010-06-06 20:17:14,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 5 time(s).\n2010-06-06 20:17:18,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 6 time(s).\n2010-06-06 20:17:22,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 7 time(s).\n2010-06-06 20:17:26,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 8 time(s).\n2010-06-06 20:17:30,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 9 time(s).\n2010-06-06 20:17:33,088 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to /10.18.52.181:9000 failed on local exception: java.net.NoRouteToHostException: No route to host\n\tat org.apache.hadoop.ipc.Client.wrapException(Client.java:1087)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1055)\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:251)\n\tat $Proxy4.sendHeartbeat(Unknown Source)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:933)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1489)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.net.NoRouteToHostException: No route to host\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:375)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:440)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:528)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:209)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1188)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1032)\n\t... 5 more\n\n2010-06-06 20:17:37,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 0 time(s).\n2010-06-06 20:17:41,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 1 time(s).\n2010-06-06 20:17:45,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 2 time(s).\n2010-06-06 20:17:49,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 3 time(s).\n2010-06-06 20:17:53,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 4 time(s).\n2010-06-06 20:17:57,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 5 time(s).\n2010-06-06 20:18:01,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.181:9000. Already tried 6 time(s).\n2010-06-06 20:18:04,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeCommand action: DNA_REGISTER\n2010-06-06 20:18:04,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 8 msecs for RPC and NN processing\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-05-06T11:59:15.097+0000","updated":"2011-05-06T11:59:15.097+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13029909","id":"13029909","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"body":"The problem that we are facing is\n\nIf we have to switch the namenode using some OM then as the DN is not going down after few retries, though the namenode switch may happen but this DN still continues to connect to the old NN.\n\nSo we suggest like we can add retry mechanism for a specified interval (this can be configured) and throw exception so that the DN goes down.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-05-06T12:03:07.118+0000","updated":"2011-05-06T12:03:07.118+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13034043","id":"13034043","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"these are all in the Datanode? This is designed to spin forever waiting for the Namenode to come back up. Are you also seeing the problem in other clients?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2011-05-16T15:01:11.717+0000","updated":"2011-05-16T15:01:11.717+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13034598","id":"13034598","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks for checking the defect.\n\nYes, these are in datanode.\n\nThe same problem will exist for any client that is using ipc.Client.\n\nSo I feel we can add some configuration to retry for that specific interval so that as per the need.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ram_krish","name":"ram_krish","key":"ram_krish","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ramkrishna.s.vasudevan","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-05-17T06:10:54.407+0000","updated":"2011-05-17T06:10:54.407+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13058525","id":"13058525","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Since we are moving towards HA implementations, this issue will create many problems.\n We were observing the same in our HA clusters.\n \nHere the actual problem is at:\n {code}\n     \n    public int read(byte[] buf, int off, int len) throws IOException {\n        do {\n          try {\n            return super.read(buf, off, len);\n          } catch (SocketTimeoutException e) {\n            handleTimeout(e);\n          }\n        } while (true);\n      }\n \n {code}\n\nWhen we unplug the network cable, this super.read will throw SocketTimeoutException.\nIt is handled the SocketTimeoutException and again it will trying to send the ping request.\n\nSO, this loop is getting repeated.\n\nbq. So I feel we can add some configuration to retry for that specific interval so that as per the need.\n\nYes , we may need to control this retries, so that it can break this loop after some number of retries.Because continusly getting timeout exception also can be consider as some problem in cluster environment.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-01T12:36:39.347+0000","updated":"2011-07-01T12:36:39.347+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13059349","id":"13059349","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Yes , we may need to control this retries, so that it can break this loop after some number of retries.Because continusly getting timeout exception also can be consider as some problem in cluster environment.\n\nThere's a fair amount of code to support automatic retries with configurable policies for IPC calls. Perhaps this could be adapted slightly and reused in the case of failures during data transfer. The relevant code is all in \"{{common/src/java/org/apache/hadoop/(io|ipc)}}\".","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-04T07:50:13.787+0000","updated":"2011-07-04T07:50:13.787+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13066848","id":"13066848","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Aaron,\nI have seen similar issue HADOOP-6889.\n\n That issue introduces rpcTimeOut, But from waitForProxy apis that values has been passed as 0 (hard coded value).\n\nI am just checking , whether i can use rpcTimeOut itself to control. ( since this change already committed). But in current code, i could not see the way to configure rpcTimeOut.\n\nsee https://issues.apache.org/jira/browse/HADOOP-6889","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-18T08:20:24.250+0000","updated":"2011-07-18T08:20:24.250+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13069574","id":"13069574","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\n> Uma Maheswara Rao G commented on HADOOP-6889:\n> ---------------------------------------------\n>\n> Hi John,\n>\n> I have seen waitForProxy is passing 0 as rpcTimeOut. It is hardcoded value.\n>\n> {code}\n> return waitForProtocolProxy(protocol, clientVersion, addr, conf, 0,\n> connTimeout);\n> {code}\n{quote}\n\nIf you want to control this value, you could use the waitForProtocolProxy() that accepts \"rpcTimeout\" as an argument. You could pass in any value\n(eg: \"DFS_CLIENT_SOCKET_TIMEOUT_KEY\") as rpcTimeout (though that means that it will timeout within that time instead of retrying.\n{code}\n  public static <T> ProtocolProxy<T> waitForProtocolProxy(Class<T> protocol,\n                               long clientVersion,\n                               InetSocketAddress addr, Configuration conf,\n                               int rpcTimeout,\n                               long timeout) throws IOException {\n{code}\n\n{quote}\n> If user wants to control this value then , how can he configure?\n{quote}\n\nHADOOP-6889 ensures that any communication to/from DN (DFSclient->DN & DN->DN), times out within rpcTimeout. If a user wants to control this value from configuration, it can be done like it is used today. For example, both these use the \"DFS_CLIENT_SOCKET_TIMEOUT_KEY\" configuration value to timeout. Like you said, this change does not change any timeout mechanisms to NN communication.\n\n{quote}\n>\n> Here we have a situation, where clients are waiting for long time.HDFS-1880.\n{quote}\n\nBased on the attached trace, I can see that DN is trying to reconnect to NN because it wants to send heartbeats to NN. When you say client, do you mean DFSClient is waiting to also doing the same thing trying to communicate with NN. For \"connection timeouts\" The maximum number of times a client should wait during each time is close to 15 minutes (45 retries with each \"connect() taking 20 seconds). For IOExceptions, it should not try more than 4 minutes or so.\nIn the trace that is attached here, you can see that it is an \"IOException\" and not a \"SocketTimeoutException\". Whenever an IOException is encountered, it tries \"ipc.client.connect.max.retries\" before it gives up, which can be controlled by conf. As you can see, it does give up after 10 retries, but since DN keeps trying to send heartbeats, it keeps doing it even after it fails.\n\n{code}\nconf.getInt(\"ipc.client.connect.max.retries\", 10)\n{code}\n\n\n{quote}\n>\n> I thought, HADOOP-6889 can solve that problem. But how this can be controlled\n> by the user in Hadoop (looks no configuration parameters available).\n>\n\n> I plan to add a new configuration ipc.client.max.pings that specifies the max\n> number of pings that a client could try. If a response can not be received\n> after the specified max number of pings, a SocketTimeoutException is thrown.\n> If this configuration property is not set, a client maintains the current\n> semantics, waiting forever.\n\n>\n> We have choosen this implementation for our cluster.\n>\n> I am just checking , whether i can use rpcTimeOut itself to control. ( since\n> this change already committed).\n>\n> Can you please clarify more?\n{quote}\n\nIf you just want to fail the call after a certain number of pings, introducing this new value \"max.pings\" might be a good idea. By using rpcTimeout, all it is doing is setting the socket timeout to be \"rpcTimeout\". There are no pings sent at all.\n\n{quote}\n>\n> Can you just check HDFS-1880.\n>\n>\n> @Hairong\n> I thought about introducing a configuration parameter. But clients or\n> DataNodes want to have timeout for RPCs to DataNodes but no timeout for RPCs\n> to NameNodes. Adding a rpcTimeout parameter makes this easy.\n>  I think considering HA, clients and NameNode also requires some timeout.\n>  If Active goes down, then clients should not wait in timeouts right?\n{quote}\nI do not know enough about HA to comment about this.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-22T14:56:42.856+0000","updated":"2011-07-22T14:56:42.856+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13072350","id":"13072350","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Jhon for taking alook on this issue.\nUpdated a patch for review!.\n\nThis patch introduces a property( max.ping.retries.on.socket.timeout ). Default value will be -1, represents that disabling of this property.\n\nIn this scenario, if we unplug the network cable between the nodes, this ping reads will get timeouts continuosly . SocketTimeOuts was handled and retried infinitely.So, it was waiting for long time.....\n\nNow , to avoid this problem, we can configure the number of ping retries.\nAnyway continuos timeouts means , somthing wrong in network/cluster, we can restrict this retries by configuring the above property.\n\nBydefault this property will be disabled.\n\n\n--Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-28T13:43:17.067+0000","updated":"2011-07-28T13:43:17.067+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13076044","id":"13076044","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"\nupdated a patch for review!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-08-02T05:35:54.660+0000","updated":"2011-08-02T05:35:54.660+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13080491","id":"13080491","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"If {{rpcTimeout > 0}} then {{ handleTimeout()}} will throw {{SocketTimeoutException}} instead of going into ping loop. Can you control the required behavior by setting {{rpcTimeout > 0}} rather introducing the # of pings limit.\n\nDataNodes and TaskTrackers are designed to ping NN and JT infinitely, because during startup you cannot predict when NN will come online as it depends on the size of the image and edits. Also when NN becomes busy it is important for DNs to keep retrying rather than assuming the NN is dead.\n\nFor DFSClient this may make sense, but I think they already timeout. At list DFSShell ls does. And even if they don't this should be an HDFS change not generic IPC change, which affects many Hadoop components.\n \nAs for HA I don't know what you did for HA and therefore cannot understand what problem you are trying to solve here. I can guess that you want DNs switch to another NN when they timeout rather than retrying. In this case you should be able to use rpcTimeout.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-08-07T00:25:05.152+0000","updated":"2011-08-07T00:25:05.152+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13085760","id":"13085760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Konstantin,\n\nThanks alot for taking a look on this issue.\n\n\n{quote}\nIf rpcTimeout > 0 then {{ handleTimeout()}} will throw SocketTimeoutException instead of going into ping loop. Can you control the required behavior by setting rpcTimeout > 0 rather introducing the # of pings limit.\n{quote}\n Yes, with this parameter also, we can control.\n\n I am planning to add below code in DataNode when gettng the proxy.\n\n {code}\n        // get NN proxy\n      DatanodeProtocol dnp = \n        (DatanodeProtocol)RPC.waitForProxy(DatanodeProtocol.class,\n            DatanodeProtocol.versionID, nnAddr, conf, socketTimeout,\n       Long.MAX_VALUE);\n {code}\n\n  Here the sockettimeout is rpcTimeOut. \n this property already used for createInterDataNodeProtocolProxy as rpcTimeOut.\n this.socketTimeout =  conf.getInt(DFS_CLIENT_SOCKET_TIMEOUT_KEY,\n                                      HdfsConstants.READ_TIMEOUT);\n\nBut my question is, if i use socketTimeout (default 60*1000 ms) as rpcTimeOut, default behaviour will be changed. I dont want to change the default behavior here.\n any suggestion for this? \n\n{quote}\nDataNodes and TaskTrackers are designed to ping NN and JT infinitely, because during startup you cannot predict when NN will come online as it depends on the size of the image and edits. Also when NN becomes busy it is important for DNs to keep retrying rather than assuming the NN is dead.\n{quote}\n\nYes. But there are some scenarios like network unplug may thorugh tomeouts and because of the timeout handlings, unneccerily system will be blocked for long time.\nAs i know, even if we through that timeout exception out to JT or DN, they will handle it and retry again in their offerService methods.\nexcept in below condition\n{code}\n catch(RemoteException re) {\n          String reClass = re.getClassName();\n          if (UnregisteredNodeException.class.getName().equals(reClass) ||\n              DisallowedDatanodeException.class.getName().equals(reClass) ||\n              IncorrectVersionException.class.getName().equals(reClass)) {\n            LOG.warn(\"blockpool \" + blockPoolId + \" is shutting down\", re);\n            shouldServiceRun = false;\n            return;\n          }\n{code}\n\n\n{quote}\nAnd even if they don't this should be an HDFS change not generic IPC change, which affects many Hadoop components\n{quote}\n  \n What i felt is, this particular issue will be applicable for all the components who is using Hadoop IPC. And also planned to retain the default behaviour as it is to not effect the other componenets. and if user really required then he will tune the configuration parameter based on his requirement.\n\nAnyway we decided to use rcpTimeOut right, IPC user code only should pass this value. In that case this will come under HDFS specific chnage. Also need to check the for MapReduce as well ( same situation for JT) \n\n\n{quote}\nAs for HA I don't know what you did for HA and therefore cannot understand what problem you are trying to solve here. I can guess that you want DNs switch to another NN when they timeout rather than retrying. In this case you should be able to use rpcTimeout\n{quote}\n Yes, your guess is correct :-)\n In our HA solution, we are using *BackupNode* and Switching framework is *Zookeeper based* LeaderElection. DNs will contain both the active and standby node addresses configured. On any failure, DNs will try to switch to other NN. \n Here the scenario is, We unplugged the active NN network card, then all DN are blocked for long time.\n\n\n--Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-08-16T14:55:46.707+0000","updated":"2011-08-16T14:55:46.707+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13100366","id":"13100366","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Konstantin,\n\n  I want your opinion on this. Can you have a look?\n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-09-08T14:51:55.039+0000","updated":"2011-09-08T14:51:55.039+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12504033/comment/13439844","id":"13439844","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Can make use of HADOOP-6889. marking it as duplicate to it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-08-22T21:02:29.632+0000","updated":"2012-08-22T21:02:29.632+0000"}],"maxResults":16,"total":16,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-7488/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i08bvr:"}}