{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13155057","self":"https://issues.apache.org/jira/rest/api/2/issue/13155057","key":"HADOOP-15412","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2018-04-25T10:27:26.273+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Apr 25 22:04:29 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_50490850_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2018-04-25T22:05:16.746+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15412/watchers","watchCount":4,"isWatching":false},"created":"2018-04-25T08:03:45.924+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332809","id":"12332809","description":"2.7.2 release","name":"2.7.2","archived":false,"released":true,"releaseDate":"2016-01-25"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334219","id":"12334219","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"}],"issuelinks":[{"id":"12532647","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12532647","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13155261","key":"HADOOP-15413","self":"https://issues.apache.org/jira/rest/api/2/issue/13155261","fields":{"summary":"Document that KMS should not store keystore on HDFS","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-04-25T22:05:16.770+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12324364","id":"12324364","name":"kms"}],"timeoriginalestimate":null,"description":"I have been trying to configure the Hadoop kms to use hdfs as the key provider but it seems that this functionality is failing. \r\n\r\nI followed the Hadoop docs for that matter, and I added the following field to my kms-site.xml:\r\n{code:java}\r\n<property> \r\n   <name>hadoop.kms.key.provider.uri</name>\r\n   <value>jceks://hdfs@nn1.example.com/kms/test.jceks</value> \r\n   <description> \r\n      URI of the backing KeyProvider for the KMS. \r\n   </description> \r\n</property>{code}\r\nThat route exists in hdfs, and I expect the kms to create the file test.jceks for its keystore. However, the kms failed to start due to this error:\r\n{code:java}\r\nERROR: Hadoop KMS could not be started REASON: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"hdfs\" Stacktrace: --------------------------------------------------- org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"hdfs\" at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3220) at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3240) at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:121) at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3291) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3259) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:470) at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356) at org.apache.hadoop.crypto.key.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:132) at org.apache.hadoop.crypto.key.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:88) at org.apache.hadoop.crypto.key.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:660) at org.apache.hadoop.crypto.key.KeyProviderFactory.get(KeyProviderFactory.java:96) at org.apache.hadoop.crypto.key.kms.server.KMSWebApp.contextInitialized(KMSWebApp.java:187) at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4276) at org.apache.catalina.core.StandardContext.start(StandardContext.java:4779) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:803) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:780) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:583) at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1080) at org.apache.catalina.startup.HostConfig.deployDirectories(HostConfig.java:1003) at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:507) at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1322) at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:325) at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:142) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1069) at org.apache.catalina.core.StandardHost.start(StandardHost.java:822) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1061) at org.apache.catalina.core.StandardEngine.start(StandardEngine.java:463) at org.apache.catalina.core.StandardService.start(StandardService.java:525) at org.apache.catalina.core.StandardServer.start(StandardServer.java:761) at org.apache.catalina.startup.Catalina.start(Catalina.java:595) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:289) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:414){code}\r\n \r\nFor what I could manage to understand, it seems that this error is because there is no FileSystem implemented for HDFS. I have looked up this error but it always refers to a lack of jars for the hdfs-client when upgrading, which I have not done (it is a fresh installation). I have tested it using Hadoop 2.7.2 and 2.9.0\r\n\r\nThank you in advance.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Hadoop KMS with HDFS keystore: No FileSystem for scheme \"hdfs\"","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pablosjv","name":"pablosjv","key":"pablosjv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34055","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"},"displayName":"Pablo San José","active":true,"timeZone":"Europe/Madrid"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pablosjv","name":"pablosjv","key":"pablosjv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34055","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"},"displayName":"Pablo San José","active":true,"timeZone":"Europe/Madrid"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"RHEL 7.3\r\n\r\nHadoop 2.7.2 and 2.7.9\r\n\r\n ","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13155057/comment/16452021","id":"16452021","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Pablo, thanks for filing the issue.\r\n\r\nWhat you mention is not a valid use case. KMS can't use HDFS as the backing storage. As you could imagine, if HDFS is used for KMS, then each HDFS client file access would go through HDFS NameNode --> KMS --> HDFS NameNode --> KMS ....\r\n\r\nThe file based KMS can use keystore files on the local file system. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-25T10:27:26.273+0000","updated":"2018-04-25T10:27:26.273+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13155057/comment/16452056","id":"16452056","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pablosjv","name":"pablosjv","key":"pablosjv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34055","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"},"displayName":"Pablo San José","active":true,"timeZone":"Europe/Madrid"},"body":"Hi Wei-Chiu,\r\n\r\nThank you very much for your quick response. So I have misunderstood the documentation. I thought the KMS could use any of the providers present in the provider type section of the Credential Provider API docs: [https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/CredentialProviderAPI.html#Provider_Types]\r\n\r\nI understood that the HDFS NameNode was only consulted when an access to an encryption zone was requested because the metadata stored in the NameNode only contains the EDEK for the files in an encryption zone. I thought that, because the key provider is already encrypted by the KMS, it could be in a non-encrypted zone of HDFS. \r\n\r\nThis case was great to have the KMS in HA  because they could share the key provider and be configured very easily.\r\n\r\nThank you again for your help.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pablosjv","name":"pablosjv","key":"pablosjv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34055","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"},"displayName":"Pablo San José","active":true,"timeZone":"Europe/Madrid"},"created":"2018-04-25T10:58:30.616+0000","updated":"2018-04-25T10:58:30.616+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13155057/comment/16452084","id":"16452084","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"If I understand it correctly, you wanted to implement KMS-HA using HDFS for storing keystore?\r\n\r\nWhile I can conceive that as a simple & quick solution, it makes little sense to store keystore in an unencrypted HDFS cluster. It also violates the initial design principal – separation of duty. With the keystore in non-EZ, A hdfs admin can easily decrypt anything in the cluster, voiding the need of KMS.\r\n\r\n \r\n\r\nKMS HA is not a trivial task. Please consult this doc for reference: https://hadoop.apache.org/docs/current/hadoop-kms/index.html#High_Availability","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-25T11:32:05.021+0000","updated":"2018-04-25T11:32:05.021+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13155057/comment/16452123","id":"16452123","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pablosjv","name":"pablosjv","key":"pablosjv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34055","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"},"displayName":"Pablo San José","active":true,"timeZone":"Europe/Madrid"},"body":"Yes, I want to implement KMS-HA using HDFS for storing keystore.\r\n\r\nAs you said, this solution may be confronting the separation of duty design principle. However, If I understand how the KMS works correctly, an HDFS admin could access the keystore but, because the key provider is encrypted by the KMS and only KMS could decrypt the contents of it, the admin wouldn't be able to decrypt anything in the cluster.\r\n\r\nThe problem I am facing trying to configure KMS in HA is that the KMS doesn't manage the replication of the data in the keystore. So, for example, if two instances of KMS are deployed, the client could be configured so if a request to a KMS instance fails, clients retry with the next instance, but the data of the two KMS keystore would be different if you use a local filesystem. The only solution I could think is using a shared filesystem for the KMS instances, which may be fine enough, but if the HA algorithm is something like round robin, there could be locking problems in the concurrency trying if the instances try to access the keystore at the same time.\r\n\r\nAs you said, KMS HA is not an easy task at all.\r\n\r\nThank you very much for your comments and your help.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pablosjv","name":"pablosjv","key":"pablosjv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34055","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"},"displayName":"Pablo San José","active":true,"timeZone":"Europe/Madrid"},"created":"2018-04-25T12:03:39.371+0000","updated":"2018-04-25T12:03:39.371+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13155057/comment/16453096","id":"16453096","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Yeah... that's a problem. Even if you use a shared file system (like NFS?) you still need to make sure the network communication is authentication and encrypted.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-25T21:11:19.006+0000","updated":"2018-04-25T21:11:19.006+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13155057/comment/16453169","id":"16453169","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Filed HADOOP-15413 to get this documented. I'll close this Jira then.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-25T22:04:29.403+0000","updated":"2018-04-25T22:05:01.791+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15412/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3szx3:"}}