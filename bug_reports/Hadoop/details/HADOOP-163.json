{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12332617","self":"https://issues.apache.org/jira/rest/api/2/issue/12332617","key":"HADOOP-163","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12310930","id":"12310930","description":"","name":"0.3.0","archived":false,"released":true,"releaseDate":"2006-06-02"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2006-04-25T04:56:30.000+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat May 27 05:42:26 UTC 2006","customfield_12310420":"80568","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_2767824000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_865463000","customfield_12312321":null,"resolutiondate":"2006-05-27T05:42:26.000+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-163/watchers","watchCount":0,"isWatching":false},"created":"2006-04-25T04:52:02.000+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12310813","id":"12310813","description":"","name":"0.2.0","archived":false,"released":true,"releaseDate":"2006-05-05"}],"issuelinks":[{"id":"12315639","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12315639","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12366500","key":"HADOOP-1200","self":"https://issues.apache.org/jira/rest/api/2/issue/12366500","fields":{"summary":"Datanode should periodically do a disk check","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:41:53.381+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"I observed that sometime, if a file of a data node is not mounted properly, it may not be writable. In this case, any data writes will fail. The name node should stop assigning new blocks to that data node. The webpage should show that node is in an abnormal state.\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12334638","id":"12334638","filename":"disk.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-27T05:22:39.000+0000","size":19316,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12334638/disk.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107308","customfield_12312823":null,"summary":"If a DFS datanode cannot write onto its file system. it should tell the name node not to assign new blocks to it.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12376118","id":"12376118","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Alternately, the datanode daemon should simply exit if it cannot write to its configured data directories.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-04-25T04:56:30.000+0000","updated":"2006-04-25T04:56:30.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12376120","id":"12376120","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"\nExiting is an option. However, the datanode may still be able to read, thus to serve the existing blocks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2006-04-25T05:19:21.000+0000","updated":"2006-04-25T05:19:21.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12376124","id":"12376124","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Good point.  So perhaps a read-only node should report itself at 100% of capacity?  Then the namenode should never allocate blocks to it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-04-25T05:52:15.000+0000","updated":"2006-04-25T05:52:15.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12376292","id":"12376292","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"body":"I envision 24x7 systems where the datanode is automatically restarted upon failure by init or another HA component. When a partition/FS fails, it will likely remain in a failed state after restart, so reporting up and stopping to serve would be better than simply exitting, which would lead to thrashing. At the end of the day, outside intervention would be required, so the most important part is diagnosing the error and reporting it as such. reporting 100% full would not generate the same kind of attention by a correction system/person.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"created":"2006-04-25T23:51:04.000+0000","updated":"2006-04-25T23:51:04.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12376353","id":"12376353","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"But should a datanode with no disk or a read-only disk still send heartbeats to the namenode?  I think not.  So it should exit the datanode daemon loop.  I think more than that is hard to specify at this point.  You're talking about what we should do when we have a system that automatically restarts, and a system that monitors, etc.  We don't have those systems in Hadoop today, so they're hard to code to!  In the meantime, do you think it would be better to enter some zombie state, not sending heartbeats or otherwise participating in namenode network protocols, but looping sending out SOS over channels TBD?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-04-26T05:50:16.000+0000","updated":"2006-04-26T05:50:16.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12376374","id":"12376374","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"body":"what I'm suggesting is close to your suggestion:\nif you're read-only, behave as though you're 100% full, serve only read requests, but don't mislead: report you're read-only, not that you're 100% full. Namenode will avoid new block allocations to the node, but its log will contain an error that could trigger external corrective action.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"created":"2006-04-26T07:50:17.000+0000","updated":"2006-04-26T07:50:17.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12412547","id":"12412547","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"I plan to take a simple approach to this problem. If a data node finds out that it can not write to its disk. It reports to the name node and aborts. The name node logs the error and alerts it on the http UI.\n\nI will use the existing data node protocol \"errorReport\" for the error reporting but with a minor change. In addition to the parameter error message, the rpc will also send an error code so that the name node does not need to parse the error message to figure out which action to take.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-20T00:56:31.000+0000","updated":"2006-05-20T00:56:31.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12412565","id":"12412565","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bpendleton","name":"bpendleton","key":"bpendleton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bryan Pendleton","active":true,"timeZone":"Etc/UTC"},"body":"Sounds good - except, what \"aborts\"? The idea of the datanode staying operating, but reporting error and not accepting further blocks is probably better, but maybe you meant \"abort the block write\". The node's blocks should probably not be counted by the namenode, but still available as a source for replication. Also, staying up means that there are fewer timeouts - it used to be that, when writing large volumes into DFS, if one or more of your nodes was full, your writer would hit a periodic timeout as connections to the (full and constantly restarting) datanode were refused. Hitting a timeout because some fraction of all resources is overused is, of course, much *much* slower than continuing to stream. Further - if the datanode periodically re-tests if the error condition has lifted, it can more immediately begin contributing to the cluster productivity again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bpendleton","name":"bpendleton","key":"bpendleton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bryan Pendleton","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-20T01:04:46.000+0000","updated":"2006-05-20T01:04:46.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12412571","id":"12412571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"We are trying to deal with the case that the node is misconfigured / broken.  Trying to operate in these situations is hard.  Simpler to fail fast, IMO.  This leverages the designed strengths of HDFS.  Our goal is to get the information to the operator so they can diagnose and fix the problem and seal the problem off from the cluster.\n\nThis is distinct from the case that the node is simply full.  That would not trigger this condition.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-05-20T01:34:22.000+0000","updated":"2006-05-20T01:34:22.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12413543","id":"12413543","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"In this patch, if a data node finds that its data directory becomes not readable or writable, it logs the error and reports the problem to its namen ode and shut down itself. When the name node receives the error report, it lots the error and removes the data node info.\n\nA data node detects disk problem at startup time, when it receives a r/w request, after it receives a command from its name node, and before it sends out a block report. A data node will not start up if its data dir is not readable or writable. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-27T05:22:39.000+0000","updated":"2006-05-27T05:22:39.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12332617/comment/12413545","id":"12413545","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"This looks great!  I just committed it.  Thanks, Hairong!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-05-27T05:42:26.000+0000","updated":"2006-05-27T05:42:26.000+0000"}],"maxResults":11,"total":11,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-163/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0iq0f:"}}