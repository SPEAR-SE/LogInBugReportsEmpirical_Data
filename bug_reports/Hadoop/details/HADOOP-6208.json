{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12433961","self":"https://issues.apache.org/jira/rest/api/2/issue/12433961","key":"HADOOP-6208","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2009-08-25T19:28:06.314+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri May 13 09:32:33 UTC 2016","customfield_12310420":"77784","customfield_12312320":null,"customfield_12310222":"1_*:*_2_*:*_207256436418_*|*_3_*:*_1_*:*_82728236_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_2_*:*_4571860796","customfield_12312321":null,"resolutiondate":"2016-05-13T09:32:44.590+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6208/watchers","watchCount":11,"isWatching":false},"created":"2009-08-25T17:22:19.340+0000","customfield_12310192":"S3 Filesystem: Polling to verify each INode write; prevents possible data-loss issues","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":"s3 ec2 filesystem consistency","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313438","id":"12313438","description":"","name":"0.20.0","archived":false,"released":true,"releaseDate":"2009-04-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12313866","id":"12313866","description":"","name":"0.20.1","archived":false,"released":true,"releaseDate":"2009-09-01"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-05-13T09:32:44.781+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"Under certain S3 consistency scenarios, Hadoop's S3FileSystem can 'truncate' files, especially when writing reduce outputs.  We've noticed this at tracksimple where we use the S3FS as the direct input and output of our MapReduce jobs.  The symptom of this problem is a file in the filesystem that is an exact multiple of the FS block size - exactly 32MB, 64MB, 96MB, etc. in length.\n\nThe issue appears to be caused by renaming a file that has recently been written, and getting a stale INode read from S3.  When a reducer is writing job output to the S3FS, the normal series of S3 key writes for a 3-block file looks something like this:\n\nTask Output:\n1) Write the first block (block_99)\n2) Write an INode (/myjob/_temporary/_attempt_200907142159_0306_r_000133_0/part-00133.gz) containing [block_99]\n3) Write the second block (block_81)\n4) Rewrite the INode with new contents [block_99, block_81]\n5) Write the last block (block_-101)\n6) Rewrite the INode with the final contents [block_99, block_81, block_-101]\n\nCopy Output to Final Location (ReduceTask#copyOutput):\n1) Read the INode contents from /myjob/_temporary/_attempt_200907142159_0306_r_000133_0/part-00133.gz, which gives [block_99, block_81, block_-101]\n2) Write the data from #1 to the final location, /myjob/part-00133.gz\n3) Delete the old INode \n\nThe output file is truncated if S3 serves a stale copy of the temporary INode.  In copyOutput, step 1 above, it is possible for S3 to return a version of the temporary INode that contains just [block_99, block_81].  In this case, we write this new data to the final output location, and 'lose' block_-101 in the process.  Since we then delete the temporary INode, we've lost all references to the final block of this file and it's orphaned in the S3 bucket.\n\nThis type of consistency error is infrequent but not impossible. We've observed these failures about once a week for one of our large jobs which runs daily and has 200 reduce outputs; so we're seeing an error rate of something like 0.07% per reduce.\n\nThese kind of errors are generally difficult to handle in a system like S3.  We have a few ideas about how to fix this:\n1) HACK! Sleep during S3OutputStream#close or #flush to wait for S3 to catch up and make these less likely.\n2) Poll for updated MD5 or INode data in Jets3tFileSystemStore#storeINode until S3 says the INode contents are the same as our local copy.  This could be a config option - \"fs.s3.verifyInodeWrites\" or something like that.\n3) Cache INode contents in-process, so we don't have to go back to S3 to ask for the current version of an INode.\n4) Only write INodes once, when the output stream is closed.  This would basically make S3OutputStream#flush() a no-op.\n5) Modify the S3FS to somehow version INodes (unclear how we would do this, need some design work).\n6) Avoid using the S3FS for temporary task attempt files.\n7) Avoid using the S3FS completely.\n\nWe wanted to get some guidance from the community before we went down any of these paths.  Has anyone seen this issue?  Any other suggested workarounds?  We at tracksimple are willing to invest some time in fixing this and (of course) contributing our fix back, but we wanted to get an 'ack' from others before we try anything crazy :-).\n\nI've attached a test app if anyone wants to try and reproduce this themselves.  It takes a while to run (depending on the 'weather' in S3 right now), but should eventually detect a consistency 'error' that manifests itself as a truncated file.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12421042","id":"12421042","filename":"HADOOP-6208.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-01T18:24:58.320+0000","size":14145,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12421042/HADOOP-6208.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12420930","id":"12420930","filename":"S3FSConsistencyPollingTest.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-30T18:09:54.041+0000","size":2501,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12420930/S3FSConsistencyPollingTest.java"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12417636","id":"12417636","filename":"S3FSConsistencyTest.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-08-25T17:41:56.367+0000","size":2336,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12417636/S3FSConsistencyTest.java"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"103339","customfield_12312823":null,"summary":"Block loss in S3FS due to S3 inconsistency on file rename","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Ubuntu Linux 8.04 on EC2, Mac OS X 10.5, likely to affect any Hadoop environment","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12747510","id":"12747510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"Test app that can reproduce truncated files in S3FS","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-08-25T17:41:56.373+0000","updated":"2009-08-25T17:41:56.373+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12747591","id":"12747591","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"This is the first time I am looking at S3FS. It is essentially a thin client managed FS layer over S3.. it would pretty hard to avoid such inconsistencies especially S3 itself can return stale info. isn't there an option for S3 client to get the latest copy (thinking Dynamo-like key-value reads)?\n\nBetween options (1) to (5) : (2) is probably the best. It is a bit analogous to what HDFS does : when close() completes successfully, it implies all the blocks have at least one replica reported.\n\nRegd (6)-(7) :  a loosely managed FS will always such issues. I am not sure how much is S3FS is used in production, I would be curious to know.\n\nFor those familiar with HDFS: S3FS is a broadly similar where all the metadata is manipulated by S3FS client rather than a central server (e.g. rename moves metadata for each file under the tree to a new location). While writing, each block is written locally and stored as an S3Object when full.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-08-25T19:28:06.314+0000","updated":"2009-08-25T19:28:06.314+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12747616","id":"12747616","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"Thanks for the quick reply.  You're right; any use of S3FS is going to run into inconsistencies, no matter how clever the client is.  What I'm looking for is some way to make any failures due to inconsistency more visible, and less likely to lose data.  Of the ideas I threw out, I think I also like #2 the best - that way users like us who do a ton of S3 I/O can pay the extra performance hit to verify writes without impacting everyone.  I'll bounce this idea around with teammates and see if I can put together a patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-08-25T20:10:33.349+0000","updated":"2009-08-25T20:10:33.349+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12747646","id":"12747646","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Regd option #2 : If one client gets the latest value, does it imply all subsequent reads (from any client) will? Otherwise one read might provide latest value, but very next read might return older value since it might read from a different replica (I don't know much about S3 internals). The client needs to somehow make sure all the replicas got the update.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-08-25T21:11:53.345+0000","updated":"2009-08-25T21:11:53.345+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12747842","id":"12747842","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"Option 2 seems like a reasonable approach. Since there is a single writer, do we only need to poll for consistency on file close?\n\nAlso, do we need to make this configurable? Always doing the polling seems acceptable since it guarantees correctness (at least for a given client).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2009-08-26T08:54:51.146+0000","updated":"2009-08-26T08:54:51.146+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12760967","id":"12760967","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"To answer the question about subsequent reads, no, unfortunately, getting one read of the latest version of an object does not guarantee that that object is fully propagated and that you won't get any more stale reads.  I ran a quick test yesterday to see how likely this scenario is (stale read after fresh read from the same client) and I was able to find one instance of a good read followed by a bad read over ~10,000 file writes (about 420,000 total reads).  For comparison, I found 7 instances in the same test where the very first read after a write was stale, but subsequent reads were all of the newest version.  The end result here is that with the current behavior, we'd have 7 truncated files of 10,000 written; with a patch to verify writes, we'd only get 1 truncated file out of 10,000.  Since the patch is simple and the verification step is cheap, I think it's worth the tradeoff; I'll let my script run a little longer and see if I can gather more significant data.\n\nTom: I think the safest thing to do is to verify writes (poll for consistency) after each INode write.  Looking through the code, this happens in 4 places: on directory creation, on file close, on file flush, and on rename.  Verifying file close and flush prevents truncated files as in this issue; verifying renames prevents a situation where a file can be renamed, then data can be written to the old filename (which should no longer exist), resulting in two copies of the file pointing to the same blocks (sort of like a weird hard link).  Verifying directory creates just prevents errors where a newly created directory doesn't show up for a little while; I don't think there are any data-loss issues possible in that scenario.\n\nI have a patch and unit test for verifying in these places; I have a bit more testing to do, but I should be able to submit it to JIRA later today.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-30T17:59:20.520+0000","updated":"2009-09-30T17:59:20.520+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12760972","id":"12760972","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"Second iteration of consistency testing - this one keeps polling even after the file is consistent to see if it stays consistent","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-30T18:09:54.064+0000","updated":"2009-09-30T18:09:54.064+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761003","id":"12761003","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"First attempt at a fix in this patch","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-30T20:47:58.978+0000","updated":"2009-09-30T20:47:58.978+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761007","id":"12761007","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"Attempting to reupload patch - I don't think I hit the right sequence of buttons the first time around :-)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-30T21:07:35.959+0000","updated":"2009-09-30T21:07:35.959+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761008","id":"12761008","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12420945/HADOOP-6208.patch\n  against trunk revision 820094.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 9 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/68/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/68/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/68/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/68/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-30T21:07:40.638+0000","updated":"2009-09-30T21:07:40.638+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761207","id":"12761207","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"This looks great.\n\n> I was able to find one instance of a good read followed by a bad read over ~10,000 file writes (about 420,000 total reads).\n\nOne possibility is to strengthen the requirement to n consecutive good reads rather than just one, but that imposes extra S3 calls. Does the current patch bring the chance of a bad read down to an acceptable level for you?\n\n> note that there's no sleep between polls; this is to avoid slowing down the unit tests, and assuming that the round-trip network latency is enough of a delay\n\nDo you know how much of a delay this imposes in practice? I wonder whether we should have a delay in order to be nice to S3. You could do this by adding a private configuration parameter (e.g. fs.s3.verifyPollInterval) for the delay, which the tests set to zero.\n\nAlso, do you know about Jets3tS3FileSystemContractTest? It's a unit test that you run manually to test against S3, using your own credentials (in src/test/core-site.xml). It's worth running this as a regression test.\n\nA couple of minor nits:\n\n* I know some other classes in Hadoop use primes in their hash code calculations, but it isn't really necessary. Or-ing the id and length is probably sufficient. See HDFS-288.\n* We generally put single line blocks in curly braces (e.g. line 76 of EventuallyConsistentInMemoryFileSystemStore).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2009-10-01T13:16:57.341+0000","updated":"2009-10-01T13:16:57.341+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761292","id":"12761292","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"> One possibility is to strengthen the requirement to n consecutive good reads rather than just one, but that imposes extra S3 calls. Does the current patch bring the chance of a bad read down to an acceptable level for you?\n\nNot sure yet; it's definitely an improvement.  We're just about to push this patch to our own cluster; I'll update the ticket with any information we gather.\n\n> Do you know how much of a delay this imposes in practice? I wonder whether we should have a delay in order to be nice to S3. You could do this by adding a private configuration parameter (e.g. fs.s3.verifyPollInterval) for the delay, which the tests set to zero.\n\nDone\n\n> Also, do you know about Jets3tS3FileSystemContractTest? It's a unit test that you run manually to test against S3, using your own credentials (in src/test/core-site.xml). It's worth running this as a regression test.\n\nI had seen it before but didn't run it with this patch.  Just ran it, everything looks good.\n\n> I know some other classes in Hadoop use primes in their hash code calculations, but it isn't really necessary. Or-ing the id and length is probably sufficient. See HDFS-288.\n\nDone\n\n> We generally put single line blocks in curly braces (e.g. line 76 of EventuallyConsistentInMemoryFileSystemStore).\n\nDone.  Thanks for the very prompt review","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-01T18:24:58.326+0000","updated":"2009-10-01T18:24:58.326+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761305","id":"12761305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"I think I've confused JIRA - can anyone direct me to the magic button to submit my new patch to Hudson?  Thx...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-01T19:15:59.677+0000","updated":"2009-10-01T19:15:59.677+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761319","id":"12761319","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"It's because you weren't assigned the issue (I've just added you to the JIRA list of contributors and assigned it to you). You should be able to cancel the patch then submit again to get Hudson to run.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2009-10-01T19:57:30.579+0000","updated":"2009-10-01T19:57:30.579+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761320","id":"12761320","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"body":"submitting new patch","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tracksimple-brad","name":"tracksimple-brad","key":"tracksimple-brad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bradley Buda","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-01T20:01:55.881+0000","updated":"2009-10-01T20:01:55.881+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12761329","id":"12761329","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12421042/HADOOP-6208.patch\n  against trunk revision 820094.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 12 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/70/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/70/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/70/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/70/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-01T20:27:50.651+0000","updated":"2009-10-01T20:27:50.651+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/12781501","id":"12781501","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"Changing to open while waiting for an update from Bradley.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2009-11-23T17:44:28.029+0000","updated":"2009-11-23T17:44:28.029+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/13565597","id":"13565597","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"# what's the status of this?\n# which s3 endpoint was being used to observe the problem -and to test that the changes worked? US default or something else?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2013-01-29T17:59:21.119+0000","updated":"2013-01-29T17:59:21.119+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/14072432","id":"14072432","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Yes, an update would be good.\n\nI suspect this is actually close-able now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-23T21:56:38.102+0000","updated":"2014-07-23T21:56:38.102+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12433961/comment/15282565","id":"15282565","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I'm going to close this as a WONTFIX due to the imminent demise of the original S3FS","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-05-13T09:32:33.980+0000","updated":"2016-05-13T09:32:33.980+0000"}],"maxResults":20,"total":20,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6208/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0i1if:"}}