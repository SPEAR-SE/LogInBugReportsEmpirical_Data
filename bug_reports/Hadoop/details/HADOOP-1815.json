{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12377138","self":"https://issues.apache.org/jira/rest/api/2/issue/12377138","key":"HADOOP-1815","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2007-08-30T16:50:48.618+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jul 17 17:45:57 UTC 2014","customfield_12310420":"19143","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-1815/watchers","watchCount":6,"isWatching":false},"created":"2007-08-30T03:47:27.734+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312474","id":"12312474","description":"","name":"0.14.0","archived":false,"released":true,"releaseDate":"2007-08-20"}],"issuelinks":[{"id":"12319638","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12319638","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12391635","key":"MAPREDUCE-166","self":"https://issues.apache.org/jira/rest/api/2/issue/12391635","fields":{"summary":"Remove distcp from hadoop core libraries, and publish documentation","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12409442","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12409442","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12778594","key":"HADOOP-11656","self":"https://issues.apache.org/jira/rest/api/2/issue/12778594","fields":{"summary":"Classpath isolation for downstream clients","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12391738","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12391738","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12707059","key":"HDFS-6200","self":"https://issues.apache.org/jira/rest/api/2/issue/12707059","fields":{"summary":"Create a separate jar for hdfs-client","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-03-02T03:18:37.632+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311543","id":"12311543","name":"build","description":"Build scripts"}],"timeoriginalestimate":null,"description":"For the ease of deployment, one should not have to change the server jars, and restart clusters, when minor features on the client side are changed. This requireds separating client and server jars for hadoop. Version numbers appended to hadoop jars can reflect the compatibility. e.g. the server jar could be at 0.13.1, and the client jar could be at 0.13.2. In short, we can treat the part following 0. as the \"major\" version number for now.\n\nThis allows major client frameworks such as streaming and Pig happy. To my knowledge, Pig uses hadoop's default jobclient. Whereas streaming uses its own jobclient. I would love to change streaming to use the default hadoop jobclient, if I can make modifications to it (e.g. to print more stats that are available from TaskReport, for example), if I do not have to deploy the new version of the whole jar to the backend and restart the mapreduce cluster.\n\n(I thought there was already a bug filed for separating the client and server jar, but I could not find it. Hence the new Jira. Sorry about duplication, if any.)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"106013","customfield_12312823":null,"summary":"Separate client and server jars","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"All","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12523877","id":"12523877","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"There's lots of code that's used on both the client and the server.  Would that go in a third jar?\n\nAlso, you state that your goal is to be able to upgrade the client jar without updating the server jar.  Why isn't that possible today?  Our current versioning system should already permit this: we should not be making incompatible protocol changes in point releases.  So I'm not clear what this will facilitate that's not already possible.  We shouldn't have to restart clusters to update the client's jar today, so long as there have been no incompatible protocol changes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-08-30T16:50:48.618+0000","updated":"2007-08-30T16:50:48.618+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12523895","id":"12523895","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"body":"Actually, we faced this problem while using distcp also. (Sorry for not mentioning it in the original mail.) disctcp (i.e. o.a.h.util.CopyFiles) is a mapred and dfs client appplication. However, since it is part of THE hadoop jar, if we make modifications to it, and use the modified version as a client jar, it is not reflected on the server-side (i.e. the tasktrackers pick up the original version of CopyFiles, rather than from the client one.) This is also true for streaming, now that the contrib jars are on the class path and are searched before the user-supplied jar. So, in that case, there is a situation that the JobClient side changes in user-supplied jar work, but the Task-side changes are picked up from the deployed jars on tasktrackers.\n\nI do not claim to have a solution for this. But I am sure someone out there has come across this before and solved this problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-08-30T17:46:01.315+0000","updated":"2007-08-30T17:46:01.315+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12523902","id":"12523902","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> we faced this problem while using distcp [ ...]\n\nAh.  I think one could make a case for a hadoop-user jar, that includes standard, supported stuff, like distcp, aggregate, etc., that's not part of the kernel, and should hence not be included in the kernel's jar that's used on servers.  A clean way to do this would be to use a separate source tree.  So we might split src/java into src/sys and src/user, and replace hadoop-core.jar with hadoop-sys.jar and hadoop-user.jar.  Some client-side stuff, like DFSClient and JobClient, would still be in the kernel jar, so the split wouldn't be client/server but rather user/system.  Could that work?\n\nAlternately, we could move such things into src/contrib, which is already built as separate jars and only contains user code.  In any case, we should attempt to minimize what's in the system jar file to avoid problems like this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-08-30T18:04:30.193+0000","updated":"2007-08-30T18:04:30.193+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12523907","id":"12523907","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"body":"yes, that would be awesome ! Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-08-30T18:37:54.646+0000","updated":"2007-08-30T18:37:54.646+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12524426","id":"12524426","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Ah. I think one could make a case for a hadoop-user jar, that includes standard, supported stuff, like distcp, aggregate, etc.\n\nEssentially they are standard, supported tools/utilities for users... do we have a case for *hadoop-tools.jar* then?\nOne other nice tool would be one which converts a bunch on input formats (text, compressed text etc.) to sequence files (say txt2seq for now). We could encourage users to contribute more of these utils.\n\nAlong similar lines, it would nice to encourage people to contribute their actual mapper/reducer implementations and build up a comprehensive {{org.apache.hadoop.mapred.lib}}, clearly with riders about IP etc. I'm not clear whether it would help to have a hadoop-mapred-lib.jar though. What do others think, should I file a jira?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-09-03T03:50:42.353+0000","updated":"2007-09-03T03:50:42.353+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12524430","id":"12524430","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm not wild about splitting up the jar into a bunch of pieces. In particular, I think that making \"tweaks\" to some of the system tools like distcp and melding them into a release is a really bad idea for debugability and maintainability. I've seen far too many cases of someone making a \"minor\" fix to a tool that hoses a tool chain and with Hadoop, such a mess up can affect a lot of users very quickly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-09-03T04:31:58.666+0000","updated":"2007-09-03T04:31:58.666+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12524609","id":"12524609","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"body":"Just want to know other users' opinions.\n\nWould it be a good idea for building a hadoop ecosystem, to separate all these client codes into separate projects?\n\n(one project - one artifact is a good thing (tm). Doug agrees on this, based on his previous comments. For growing hadoop ecosystem, we need several artifacts, that can evolve separately, and faster.)\n\nFor example, how about separating distcp as a hadoop-dependent, but separate project to provide a high-bandwidth distributed copy ?\n\nHow about separating streaming into a separate projects as a mechanism for using time-tested ways (aka stdin, and stdout) for passing data between plugins and hadoop ?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-09-04T04:03:46.141+0000","updated":"2007-09-04T04:03:46.141+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12524877","id":"12524877","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> Would it be a good idea for building a hadoop ecosystem, to separate all these client codes into separate projects?\n\nI think you mean something different than 'project'.  At Apache, each project requires a diverse community, so code with a single contributor or with all contributors from the same employer aren't good candidates for Apache projects.  But separating client tools into separate jar files might be good.  The cleanest way to separate jar files is to use separate source trees.  Splitting tools into 'src/tool/' subdirectories would be fine with me.  For example, Nutch puts each of its plugins in a separate source tree:\n\nhttp://svn.apache.org/repos/asf/lucene/nutch/trunk/src/plugin/\n\nAnd we already have contrib structured this way.  Is that what you meant?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-09-04T21:23:34.885+0000","updated":"2007-09-04T21:23:34.885+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12524888","id":"12524888","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"body":"Indeed.\n\nsrc/tools is the right place to put such things. Is it required that all tools be released at the same frequency as the core hadoop system? I should probably take a look at nutch release processes, and see if they fit our requirements.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-09-04T21:48:07.828+0000","updated":"2007-09-04T21:48:07.828+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/12524892","id":"12524892","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> Is it required that all tools be released at the same frequency as the core hadoop system?\n\nPragmatically, yes.  We don't want to call separate release votes for each tool.  Bundling tools with the core simplifies compatibility: otherwise each tool would need to separately document which version of the core it is compatible with.  Etc.\n\nI'm still on the fence about whether we need separate jars for each logical tool, or whether we should just move all non-kernel code into a single hadoop-tool.jar.  In the case of Nutch, having all those plugins separate makes builds go slower, and makes browsing the sources more awkward.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-09-04T21:58:09.577+0000","updated":"2007-09-04T21:58:09.577+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12377138/comment/14065215","id":"14065215","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"With the move to protobuf, how close are we to closing this out?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-17T17:45:57.102+0000","updated":"2014-07-17T17:45:57.102+0000"}],"maxResults":11,"total":11,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-1815/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ii0n:"}}