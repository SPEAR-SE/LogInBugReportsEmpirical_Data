{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12466631","self":"https://issues.apache.org/jira/rest/api/2/issue/12466631","key":"HADOOP-6817","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2012-07-10T17:51:32.355+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jul 12 18:01:41 UTC 2012","customfield_12310420":"77635","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_65788431422_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-07-10T17:51:32.311+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6817/watchers","watchCount":8,"isWatching":false},"created":"2010-06-10T07:17:40.978+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":"SequenceFile.Reader,Gzip","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314203","id":"12314203","description":"","name":"0.20.2","archived":false,"released":true,"releaseDate":"2010-02-16"}],"issuelinks":[{"id":"12354966","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12354966","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12598178","key":"HADOOP-8582","self":"https://issues.apache.org/jira/rest/api/2/issue/12598178","fields":{"summary":"Improve error reporting for GZIP-compressed SequenceFiles with missing native libraries.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12355032","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12355032","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"inwardIssue":{"id":"12349994","key":"HADOOP-538","self":"https://issues.apache.org/jira/rest/api/2/issue/12349994","fields":{"summary":"Implement a nio's 'direct buffer' based wrapper over zlib to improve performance of java.util.zip.{De|In}flater as a 'custom codec'","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-07-12T18:32:26.651+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310687","id":"12310687","name":"io","description":""}],"timeoriginalestimate":null,"description":"An hadoop job output a gzip compressed sequence file(whether record compressed or block compressed).The client program use SequenceFile.Reader to read this sequence file,when reading the client program shows the following exceptions:\n\n2090 [main] WARN org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n2091 [main] INFO org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor\nException in thread \"main\" java.io.EOFException\n\tat java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:207)\n\tat java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:197)\n\tat java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:136)\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:58)\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:68)\n\tat org.apache.hadoop.io.compress.GzipCodec$GzipInputStream$ResetableGZIPInputStream.<init>(GzipCodec.java:92)\n\tat org.apache.hadoop.io.compress.GzipCodec$GzipInputStream.<init>(GzipCodec.java:101)\n\tat org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:170)\n\tat org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:180)\n\tat org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1520)\n\tat org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)\n\tat org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)\n\tat org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)\n\tat com.shiningware.intelligenceonline.taobao.mapreduce.HtmlContentSeqOutputView.main(HtmlContentSeqOutputView.java:28)\n\nI studied the code in org.apache.hadoop.io.SequenceFile.Reader.init method and read:\n      // Initialize... *not* if this we are constructing a temporary Reader\n      if (!tempReader) {\n        valBuffer = new DataInputBuffer();\n        if (decompress) {\n          valDecompressor = CodecPool.getDecompressor(codec);\n          valInFilter = codec.createInputStream(valBuffer, valDecompressor);\n          valIn = new DataInputStream(valInFilter);\n        } else {\n          valIn = valBuffer;\n        }\nthe problem seems to be caused by \"valBuffer = new DataInputBuffer();\" ,because GzipCodec.createInputStream creates an instance of GzipInputStream whose constructor creates an instance of ResetableGZIPInputStream class.When ResetableGZIPInputStream's constructor calls it base class java.util.zip.GZIPInputStream's constructor ,it trys to read the empty \"valBuffer = new DataInputBuffer();\" and get no content,so it throws an EOFException.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"46529","customfield_12312823":null,"summary":"SequenceFile.Reader can't read gzip format compressed sequence file, which produce by a mapreduce job, without native compression library","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenjun","name":"wenjun","key":"wenjun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wenjun Huang","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wenjun","name":"wenjun","key":"wenjun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wenjun Huang","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Cluster:CentOS 5,jdk1.6.0_20\nClient:Mac SnowLeopard,jdk1.6.0_20","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466631/comment/13410623","id":"13410623","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"This is being addressed via HADOOP-8582.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-07-10T17:51:32.355+0000","updated":"2012-07-10T17:51:32.355+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466631/comment/13412705","id":"13412705","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nielsbasjes","name":"nielsbasjes","key":"nielsbasjes","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=nielsbasjes&avatarId=26763","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=nielsbasjes&avatarId=26763","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=nielsbasjes&avatarId=26763","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=nielsbasjes&avatarId=26763"},"displayName":"Niels Basjes","active":true,"timeZone":"Europe/Amsterdam"},"body":"To me this seems NOT to be a duplicate of HADOOP-8582 .\nTo me this issue is essentially: Problem with Gzip in specific situation.  \nHADOOP-8582 effectively says \"Lets make the error message clear until we fix the real problem\".\n\nSo I propose we keep this open as an unsolved 'non-duplicate' bug\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nielsbasjes","name":"nielsbasjes","key":"nielsbasjes","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=nielsbasjes&avatarId=26763","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=nielsbasjes&avatarId=26763","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=nielsbasjes&avatarId=26763","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=nielsbasjes&avatarId=26763"},"displayName":"Niels Basjes","active":true,"timeZone":"Europe/Amsterdam"},"created":"2012-07-12T11:30:47.222+0000","updated":"2012-07-12T11:30:47.222+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466631/comment/13413009","id":"13413009","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi Niels,\n\nAm happy to reopen this, but the reason for this not to work is explained at HADOOP-538.\n\nI will add that as a link as well.\n\nDo you still wish to reopen?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-07-12T17:59:46.937+0000","updated":"2012-07-12T17:59:46.937+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12466631/comment/13413014","id":"13413014","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"Also Neils, If you notice the stack trace, the user ran into this cause his jobs did create it with the right codec, but his reader failed to enforce that the right codec is needed, which is what HADOOP-8582 wishes to fix. Or did I miss something?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-07-12T18:01:41.838+0000","updated":"2012-07-12T18:01:41.838+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6817/votes","votes":5,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i08bwv:"}}