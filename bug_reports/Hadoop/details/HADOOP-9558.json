{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12646999","self":"https://issues.apache.org/jira/rest/api/2/issue/12646999","key":"HADOOP-9558","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"2013-05-10 11:18:28.998","customfield_12310420":"327356","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9558/watchers","watchCount":5,"isWatching":false},"created":"2013-05-10T11:18:28.998+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313563","id":"12313563","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-05-10T11:18:28.998+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310687","id":"12310687","name":"io","description":""}],"timeoriginalestimate":null,"description":"When running a hive job that tries to combine many small files, ~20,000; tasks fail with an out of Memory Exception detailed below.   The job is trying to combine many small files of approximately 1KB each, the underlying Zlib native implementation allocates a byte buffer of 64Kb.  It is suspected that the problem resides in the ZlibCompressor and its defaults for the ByteBuffer that is created at construction time.  Under less extreme conditions the issue does not manifest itself, tests have been tried with 5000 files and it worked okay.\n\n\nFATAL org.apache.hadoop.mapred.Child: Error running child : java.lang.OutOfMemoryError: unable to create new native thread \nat java.lang.Thread.start0(Native Method) \nat java.lang.Thread.start(Thread.java:640) \nat org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.<init>(DFSClient.java:3372) \nat org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:705) \nat org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:219) \nat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:584) \nat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:565) \nat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:472) \nat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:464) \nat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat.getHiveRecordWriter(HiveIgnoreKeyTextOutputFormat.java:80) \nat org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getRecordWriter(HiveFileFormatUtils.java:247) \nat org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:235) \nat org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:458) \nat org.apache.hadoop.hive.ql.exec.FileSinkOperator.getDynOutWriters(FileSinkOperator.java:599) \nat org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:539) \nat org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471) \nat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:744) \nat org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84) \nat org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471) \nat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:744) \nat org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84) \nat org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471) \nat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:744) \nat org.apache.hadoop.hive.ql.exec.FilterOperator.processOp(FilterOperator.java:87) \nat org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471) \nat org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:744) \nat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:730) \nat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:733) \nat org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:841) \nat org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:263) \nat org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:198) \nat org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:469) \nat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:417) \nat org.apache.hadoop.mapred.Child$4.run(Child.java:270) \nat java.security.AccessController.doPrivileged(Native Method) \nat javax.security.auth.Subject.doAs(Subject.java:396) \nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177) \nat org.apache.hadoop.mapred.Child.main(Child.java:264)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"327700","customfield_12312823":null,"summary":"Opening many small files with Zlib compression results in Out of Memory Exception when using Combined Input File Format for many small files","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jhancock","name":"jhancock","key":"jhancock","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Hancock","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jhancock","name":"jhancock","key":"jhancock","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Justin Hancock","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Red Hat 5.X JDK 1.6.31","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[],"maxResults":0,"total":0,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9558/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1khcv:"}}