{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12768212","self":"https://issues.apache.org/jira/rest/api/2/issue/12768212","key":"HADOOP-11487","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329058","id":"12329058","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2015-01-17T17:40:35.681+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jun 16 10:34:01 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_76109140945_*|*_4_*:*_1_*:*_6468_*|*_5_*:*_2_*:*_7710","customfield_12312321":null,"resolutiondate":"2017-06-16T10:34:28.245+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11487/watchers","watchCount":15,"isWatching":false},"created":"2015-01-17T13:08:33.156+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332809","id":"12332809","description":"2.7.2 release","name":"2.7.2","archived":false,"released":true,"releaseDate":"2016-01-25"}],"issuelinks":[{"id":"12506757","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12506757","type":{"id":"12310060","name":"Container","inward":"Is contained by","outward":"contains","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310060"},"inwardIssue":{"id":"12969687","key":"HADOOP-13145","self":"https://issues.apache.org/jira/rest/api/2/issue/12969687","fields":{"summary":"In DistCp, prevent unnecessary getFileStatus call when not preserving metadata.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12475662","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12475662","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12987291","key":"HADOOP-13345","self":"https://issues.apache.org/jira/rest/api/2/issue/12987291","fields":{"summary":"S3Guard: Improved Consistency for S3A","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12466500","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12466500","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12969687","key":"HADOOP-13145","self":"https://issues.apache.org/jira/rest/api/2/issue/12969687","fields":{"summary":"In DistCp, prevent unnecessary getFileStatus call when not preserving metadata.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12490663","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12490663","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"13032222","key":"HADOOP-13950","self":"https://issues.apache.org/jira/rest/api/2/issue/13032222","fields":{"summary":"S3A create(path, overwrite=true) need only check for path being a dir, not a file","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12407447","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12407447","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12647860","key":"HADOOP-9565","self":"https://issues.apache.org/jira/rest/api/2/issue/12647860","fields":{"summary":"Add a Blobstore interface to add to blobstore FileSystems","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-06-16T10:34:28.277+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310689","id":"12310689","name":"fs","description":"Generic FileSystem code"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"I'm trying to copy a large amount of files from HDFS to S3 via distcp and I'm getting the following exception:\n\n{code:java}\n2015-01-16 20:53:18,187 ERROR [main] org.apache.hadoop.tools.mapred.CopyMapper: Failure in copying hdfs://10.165.35.216/hdfsFolder/file.gz to s3n://s3-bucket/file.gz\njava.io.FileNotFoundException: No such file or directory 's3n://s3-bucket/file.gz'\n\tat org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:445)\n\tat org.apache.hadoop.tools.util.DistCpUtils.preserve(DistCpUtils.java:187)\n\tat org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:233)\n\tat org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:45)\n\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)\n\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)\n2015-01-16 20:53:18,276 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.FileNotFoundException: No such file or directory 's3n://s3-bucket/file.gz'\n\tat org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:445)\n\tat org.apache.hadoop.tools.util.DistCpUtils.preserve(DistCpUtils.java:187)\n\tat org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:233)\n\tat org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:45)\n\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)\n\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)\n{code}\n\nHowever, when I try hadoop fs -ls s3n://s3-bucket/file.gz the file is there. So probably due to Amazon's S3 eventual consistency the job failure.\n\nIn my opinion, in order to fix this problem NativeS3FileSystem.getFileStatus must use fs.s3.maxRetries property in order to avoid failures like this.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"FileNotFound on distcp to s3n/s3a due to creation inconsistency ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pauloricardomg","name":"pauloricardomg","key":"pauloricardomg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Paulo Motta","active":true,"timeZone":"America/Sao_Paulo"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pauloricardomg","name":"pauloricardomg","key":"pauloricardomg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Paulo Motta","active":true,"timeZone":"America/Sao_Paulo"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/14281462","id":"14281462","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"# Which version of hadoop?\n# Which S3 zone? Only US-east lacks create consistency\n\nBlobstores are the bane of our lives. They aren't real filesystems...really code around it needs to recognise this and act on it, though as they all have standard expectations of files and their metadata, that's not easy\n\nIt's not enough to retry on FS status as there are other inconsistencies: directory renames and deletes, blob updates, etc. \n\nThere's a new FS client,  s3a, in hadoop 2.6 which is where all future fs/s3 work is going on. Try it to see if it is any better, though I doubt it.\n\nIf we were to fix it, the route would be to go with something derived off NetFlix S3mper. Retrying on a 404 is not sufficient.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-01-17T17:40:35.681+0000","updated":"2015-01-17T17:40:35.681+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/14307007","id":"14307007","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Looking at this stack trace a bit more, it's actually the logic where the mapper is trying to propagate use & group, ACL & extended permissions. None of which s3 has.\n\nonce HADOOP-9565 is in, this bit of distcp could be checking to see if there is create/update consistency at the destination, and if not, spinning a bit on failure. This would have it handle the problem of no-entry-to-update against s3 or other FS, without having to hide polling & waiting in the s3 clients themselves.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-02-05T10:42:44.434+0000","updated":"2015-02-05T10:42:44.434+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/14307512","id":"14307512","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"body":"Nice find (unfortunately for you). I think the most likely culprit is org.apache.hadoop.tools.mapred.RetriableFileCopyCommand#promoteTmpToTarget which uses rename():  another \"commiting by renaming\" operation identified which we might be able to resolve in HADOOP-9565.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thodemoor","name":"thodemoor","key":"thodemoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Europe/Berlin"},"created":"2015-02-05T16:36:38.827+0000","updated":"2015-02-05T16:36:38.827+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/14309440","id":"14309440","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"marking as a dependency on HADOOP-9565 and changing JIRA to problem, not (initial) proposed solution","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-02-06T17:09:02.713+0000","updated":"2015-02-06T17:09:02.713+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/14640362","id":"14640362","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dekken","name":"dekken","key":"dekken","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dekken&avatarId=32252","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dekken&avatarId=32252","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dekken&avatarId=32252","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dekken&avatarId=32252"},"displayName":"Philip Deegan","active":true,"timeZone":"Etc/UTC"},"body":"Is it possible DRILL-3546 is similar?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dekken","name":"dekken","key":"dekken","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dekken&avatarId=32252","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dekken&avatarId=32252","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dekken&avatarId=32252","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dekken&avatarId=32252"},"displayName":"Philip Deegan","active":true,"timeZone":"Etc/UTC"},"created":"2015-07-24T12:08:51.435+0000","updated":"2015-07-24T12:08:51.435+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/14640706","id":"14640706","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"no, that looks like creation inconsistency, which is an AWS architecture issue\n\nbq. Amazon S3 buckets in the US Standard Region only provide read-after-write consistency when accessed through the Northern Virginia endpoint (s3-external-1.amazonaws.com).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-07-24T16:29:09.178+0000","updated":"2015-07-24T16:29:09.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/14640743","id":"14640743","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dekken","name":"dekken","key":"dekken","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dekken&avatarId=32252","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dekken&avatarId=32252","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dekken&avatarId=32252","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dekken&avatarId=32252"},"displayName":"Philip Deegan","active":true,"timeZone":"Etc/UTC"},"body":"Are you sure? It's a read only op from the same region (eu-central)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dekken","name":"dekken","key":"dekken","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dekken&avatarId=32252","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dekken&avatarId=32252","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dekken&avatarId=32252","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dekken&avatarId=32252"},"displayName":"Philip Deegan","active":true,"timeZone":"Etc/UTC"},"created":"2015-07-24T17:04:17.391+0000","updated":"2015-07-24T17:04:17.391+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15281472","id":"15281472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"eu-central is consistent, so its not create inconsistency. But s3 everywhere lags in listing consistency: if you GET a file it should be there, but if you list the pattern, it may not","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-05-12T12:39:10.531+0000","updated":"2016-05-12T12:39:10.531+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15283275","id":"15283275","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I just attached a patch to HADOOP-13145 to prevent this {{getFileInfo}} call when DistCp is run without the {{-p}} option.  I suspect that patch can help us get past this problem with eventual consistency on DistCp to a destination on S3A, at least when DistCp is run without the {{-p}} option.\n\nI filed that patch on a new JIRA instead of here, because the discussion here indicates that it may expand to a larger scope for addressing a wider set of eventual consistency concerns.  HADOOP-13145 is more of a spot performance enhancement.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-13T22:59:52.609+0000","updated":"2016-05-13T22:59:52.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15388227","id":"15388227","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=%24iddhe%24h","name":"$iddhe$h","key":"$iddhe$h","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"$iddhe$h Divekar","active":true,"timeZone":"Etc/UTC"},"body":"Hi,\nWe are processing data on US west and still seeing consistency issue.\nAs per forums US west should not be having consistency issue but we\nare doing update of a table. Not sure if 'read-after-write' consistency \nwill take care of 'read-after-update' consistency also.\n\nWill 9565 help us here.\n\nBelow is the back trace of the issue we are seeing when we\nwrite some tables in parquet format from Apache Spark to S3n.\n{code}\norg.apache.spark.SparkException: Job aborted.\n        at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelation$$anonfun$run$1.apply$mcV$sp(InsertIntoHadoopFsRelation.scala:154)\n        at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelation$$anonfun$run$1.apply(InsertIntoHadoopFsRelation.scala:106)\n        at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelation$$anonfun$run$1.apply(InsertIntoHadoopFsRelation.scala:106)\n        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)\n        at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelation.run(InsertIntoHadoopFsRelation.scala:106)\n        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:58)\n        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:56)\n        at org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:70)\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:132)\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:130)\n        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:130)\n        at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)\n        at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)\n        at org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:189)\n        at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:239)\n        at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:221)\n        at com.foo.vAnalytics.xyz_load$.main(xyz_load.scala:130)\n        at com.foo.vAnalytics.xyz_load.main(xyz_load.scala)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\n        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)\n        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n        at org.apache.oozie.action.hadoop.SparkMain.runSpark(SparkMain.java:104)\n        at org.apache.oozie.action.hadoop.SparkMain.run(SparkMain.java:95)\n        at org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:47)\n        at org.apache.oozie.action.hadoop.SparkMain.main(SparkMain.java:38)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:236)\n        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)\n        at org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.runSubtask(LocalContainerLauncher.java:317)\n        at org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.run(LocalContainerLauncher.java:232)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.FileNotFoundException: File s3n://foo-hive/warehouse/fooabcxyz0719/_temporary/0/task_201607210010_0005_m_000041 does not exist.\n        at org.apache.hadoop.fs.s3native.NativeS3FileSystem.listStatus(NativeS3FileSystem.java:506)\n        at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:360)\n        at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:310)\n        at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:46)\n        at org.apache.spark.sql.execution.datasources.BaseWriterContainer.commitJob(WriterContainer.scala:230)\n        at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelation$$anonfun$run$1.apply$mcV$sp(InsertIntoHadoopFsRelation.scala:149)\n        ... 42 more\n\n2016-07-21 00:22:54,370  WARN ParameterVerifier:523 - SERVER[ip-10-0-0-136.us-west-2.compute.internal] USER[root] GROUP[-] TOKEN[] APP[spark-coord] JOB[0000096-160719225831887-oozie-root-C] ACTION[0000096-1607192\\\n25831887-oozie-root-C@3] The application does not define formal parameters in its XML definition\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-07-21T19:00:08.885+0000","updated":"2016-07-22T09:46:54.459+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15388286","id":"15388286","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~$iddhe$h].  The stack trace indicates a problem during a {{FileSystem#listStatus}} call.  The listing calls against S3 are subject to eventual consistency.  The goals of the S3Guard project, tracked in issue HADOOP-13345, would help address this scenario.  However, please note that this effort is targeted to the S3A file system, which is where our ongoing development effort on Hadoop S3 integration is happening.  (Your stack trace indicates you are currently using S3N.)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-07-21T19:41:39.923+0000","updated":"2016-07-21T19:41:39.923+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15388417","id":"15388417","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=%24iddhe%24h","name":"$iddhe$h","key":"$iddhe$h","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"$iddhe$h Divekar","active":true,"timeZone":"Etc/UTC"},"body":"Hi Chris,\nThanks for replying.\nAs per AWS forum all of the S3 regions now support read-after-write consistency for new objects added to Amazon s3.\nhttps://forums.aws.amazon.com/ann.jspa?annID=3112\nDoes listStatus falls outside above consistency ?\n\nFor Hadoop 2.7 we started using s3a as per spark recommendations but\nbut after moving to s3a we started using 3x degradation, hence moved backed to s3n.\n\nWhen will be the patch available for general use ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=%24iddhe%24h","name":"$iddhe$h","key":"$iddhe$h","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"$iddhe$h Divekar","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-21T21:00:11.287+0000","updated":"2016-07-21T21:00:11.287+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15388426","id":"15388426","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Does listStatus falls outside above consistency ?\n\nYes, it does.  {{FileSystem#listStatus}} maps to an operation listing the keys in an S3 bucket.  For that listing operation, the consistency model you quoted does not apply.  Instead, it follows an eventual consistency model.  There may be propagation delays between creating a key and that key becoming visible in listings.\n\nThere are more details on this behavior in the AWS S3 consistency model doc:\n\nhttp://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-07-21T21:05:47.654+0000","updated":"2016-07-21T21:05:47.654+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15388474","id":"15388474","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=%24iddhe%24h","name":"$iddhe$h","key":"$iddhe$h","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"$iddhe$h Divekar","active":true,"timeZone":"Etc/UTC"},"body":"Cool thanks, will take a look.\nIs patch for HADOOP-13345 available for general use ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=%24iddhe%24h","name":"$iddhe$h","key":"$iddhe$h","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"$iddhe$h Divekar","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-21T21:32:31.513+0000","updated":"2016-07-21T21:32:31.513+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15388497","id":"15388497","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Is patch for HADOOP-13345 available for general use ?\n\nNo, that's just a prototype right now.  It's still under development.  I can't recommend running it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-07-21T21:50:50.660+0000","updated":"2016-07-21T21:50:50.660+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15388499","id":"15388499","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=%24iddhe%24h","name":"$iddhe$h","key":"$iddhe$h","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"$iddhe$h Divekar","active":true,"timeZone":"Etc/UTC"},"body":"Np, will start watching it.\nThanks for the help.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=%24iddhe%24h","name":"$iddhe$h","key":"$iddhe$h","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"$iddhe$h Divekar","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-21T21:53:26.834+0000","updated":"2016-07-21T21:53:26.834+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/15811707","id":"15811707","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Linking to HADOOP-13950, as it may be a lower cost solution.\n\nAWS caches negative GETs on a path, and FS.create() does an existence check as part of its getFileStatus call, which is always done to look for the dest being a directory.\n\nif overwrite=true, we don't care if a dir exists, so only need the 2 directory probes, not the direct path HEAD, so will skip the possibility of a -ve HEAD result being cached. This *may* be all that is needed","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-09T12:55:36.964+0000","updated":"2017-01-09T12:55:36.964+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12768212/comment/16051749","id":"16051749","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"The specific codepath here is addressed by HADOOP-13145; other inconsistency issues are different and addresssed elsewhere (HADOOP-13345, HADOOP-13786). Closing as fixed","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-16T10:34:01.771+0000","updated":"2017-06-16T10:34:01.771+0000"}],"maxResults":18,"total":18,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11487/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i24hkf:"}}