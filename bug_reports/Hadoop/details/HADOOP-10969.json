{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12733859","self":"https://issues.apache.org/jira/rest/api/2/issue/12733859","key":"HADOOP-10969","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2014-08-14T09:05:14.486+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Feb 01 20:03:17 UTC 2016","customfield_12310420":"411887","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_47813808_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-08-14T09:05:47.143+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-10969/watchers","watchCount":4,"isWatching":false},"created":"2014-08-13T19:48:53.368+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12421784","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12421784","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12821532","key":"SPARK-6961","self":"https://issues.apache.org/jira/rest/api/2/issue/12821532","fields":{"summary":"Cannot save data to parquet files when executing from Windows from a Maven Project","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-02-01T20:03:17.198+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"I'm an application developer. We recently moved from CDH4.7 to CDH5.1. The hadoop version have been from 1.x to 2.x. In order to perform development on Eclipse (on WINDOWS), the following class was created \n\npublic class WindowsLocalFileSystem extends LocalFileSystem {\n\n\tpublic WindowsLocalFileSystem() {\n\t\tsuper();\n\t}\n\t@Override\n\tpublic boolean mkdirs(Path f, FsPermission permission) throws IOException {\n\t\tfinal boolean result = super.mkdirs(f);\n\t\tthis.setPermission(f, permission);\n\t\treturn result;\n\t\t\n\t}\n\n\t@Override\n\tpublic void setPermission(Path p, FsPermission permission)\n\t\t\tthrows IOException {\n\t\ttry {\n\t\tsuper.setPermission(p, permission);\n\t\t} catch (final IOException e) {\n\t\t\tSystem.err.println(\"Cant help it, hence ignoring IOException setting persmission for path \\\"\" + p +\n\t\t\t\t\t \"\\\": \" + e.getMessage());\n\t\t}\n\t}\n\n}\n\nThis class was used in MapReduce Job as\n\n\t\tif (RUN_LOCAL) {\n\t\t\tconf.set(\"fs.default.name\", \"file:///\");\n\t\t\tconf.set(\"mapred.job.tracker\", \"local\");\n\t\t\tconf.set(\"fs.file.impl\",\n\t\t\t\t\t\"org.scif.bdp.mrjobs.WindowsLocalFileSystem\");\n\t\t\tconf.set(\n\t\t\t\t\t\"io.serializations\",\n\t\t\t\t\t\"org.apache.hadoop.io.serializer.JavaSerialization,\"\n\t\t\t\t\t\t\t+ \"org.apache.hadoop.io.serializer.WritableSerialization\");\n\n\t\t}\nIt worked fine on CDH4.7. Now the same code when compiled on CDH5.1 works but when I try to execute it throws the following stacktrace\n\nException in thread \"main\" java.lang.NullPointerException\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1010)\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:451)\n\tat org.apache.hadoop.util.Shell.run(Shell.java:424)\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:656)\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:745)\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:728)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:633)\n\tat org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:467)\n\tat com.scif.bdp.common.WindowsLocalFileSystem.setPermission(WindowsLocalFileSystem.java:26)\n\tat com.scif.bdp.common.WindowsLocalFileSystem.mkdirs(WindowsLocalFileSystem.java:17)\n\tat org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:125)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:348)\n\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1295)\n\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1292)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)\n\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1292)\n\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1313)\n\tat com.scif.bdp.mrjobs.DeDup.run(DeDup.java:55)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)\n\tat com.scif.bdp.mrjobs.DeDup.main(DeDup.java:59)\n\n(Note DeDup is my MR class to remove duplicates)\n\nUpon investigation the only change I saw was the change in method .setPermission(). It invokes Native.POSIX.chmod as against Native.chmod\n\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"411878","customfield_12312823":null,"summary":"RawLocalFileSystem.setPermission throws Exception on windows","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=venbigdata","name":"venbigdata","key":"venbigdata","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkatesh","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=venbigdata","name":"venbigdata","key":"venbigdata","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkatesh","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"hadoop 2.3.0, Windows Environment, Development using Eclipse, Lenevo Laptop","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12733859/comment/14096767","id":"14096767","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Venkatesh, \n\nHadoop 2.3+ works on windows without needing to do tricks like this...so if there are problems here they should go away if you get a native windows build (including the native libraries for performance, and {{winutils.exe}} for chmod. You should be able to submit jobs to a CDH5. x cluster running on Linux with it.\n\nIf you do want to stick with CDH client side, then this is going to have to be something to take up with them. From ASF side, I'm going to close as a INVALID. Sorry.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-08-14T09:05:14.486+0000","updated":"2014-08-14T09:05:14.486+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12733859/comment/14097544","id":"14097544","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=venbigdata","name":"venbigdata","key":"venbigdata","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkatesh","active":true,"timeZone":"Etc/UTC"},"body":"Hi Steve, I changed my Maven pom file to replace all dependencies having cdh with the apache version like. \n\t\t<!-- setup for CDH 5.x -->\n <!--  \n\t\t<jdk_version>1.7</jdk_version>\n\t\t<avro_version>1.7.5-cdh5.1.0</avro_version>\n\t\t<cdh_version>2.3.0-cdh5.1.0</cdh_version>\n\t\t<cdh_ZK_version>3.4.5-cdh5.1.0</cdh_ZK_version>\n\t\t<cdh_HB_version>0.96.1.1-cdh5.1.0</cdh_HB_version>\n --> \n \t\t<!-- setup for non-CDH 5.x but hadoop 2.3.0-->\n  \n\t\t<jdk_version>1.7</jdk_version>\n\t\t<avro_version>1.7.5</avro_version>\n\t\t<cdh_version>2.3.0</cdh_version>\n\t\t<cdh_ZK_version>3.3.1</cdh_ZK_version>\n\t\t<cdh_HB_version>0.96.1.1</cdh_HB_version>\n \n\nbut still get the same null pointer exception. I'm compiling and executing the MR job via eclipse as a simple Java Application (Right Click on Driver class --> Run--> run as Java Application).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=venbigdata","name":"venbigdata","key":"venbigdata","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Venkatesh","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-14T20:05:45.832+0000","updated":"2014-08-14T20:05:45.832+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12733859/comment/15126925","id":"15126925","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user velo commented on the pull request:\n\n    https://github.com/apache/incubator-tinkerpop/pull/207#issuecomment-178164276\n  \n    the windows profile is to work around\n    https://issues.apache.org/jira/browse/HADOOP-10969\n    and\n    https://issues.apache.org/jira/browse/SPARK-6961\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2016-02-01T20:03:17.198+0000","updated":"2016-02-01T20:03:17.198+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-10969/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1yuxz:"}}