{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12416724","self":"https://issues.apache.org/jira/rest/api/2/issue/12416724","key":"HADOOP-5474","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2009-03-12T08:31:30.586+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Mar 17 22:44:22 UTC 2009","customfield_12310420":"77974","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_483898795_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2009-03-17T22:44:22.795+0000","workratio":0,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-5474/watchers","watchCount":1,"isWatching":false},"created":"2009-03-12T08:19:24.599+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":345600,"aggregatetimeoriginalestimate":345600,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313211","id":"12313211","description":"","name":"0.19.0","archived":false,"released":true,"releaseDate":"2008-11-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:53:20.494+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":345600,"description":"When a tasktracker with a completed map task failed, the map task will be re-exectuted, and all reduce tasks that haven't read the data from that tasktracker should be re-executed. But the reduce task that have read the data from that tasktracker will not be re-executed. \n\nIn this situation, if the outputs of multi map tasks on the same dataset are different, for example outputting a random number, the outputs of maptask and the re-executed maptask will probably are different. Then the re-executed reduce tasks will read the new output of the re-executed maptask, but reduce tasks that have read the data from the failed tasktracker have read the old output. This probably will cause correctness of the result.\n\nA recommended solution is that all reduce tasks should be re-executed if one tasktracker with a completed map task failed.\n\nAny comments? thanks!\n\n\n","customfield_10010":null,"timetracking":{"originalEstimate":"96h","remainingEstimate":"96h","originalEstimateSeconds":345600,"remainingEstimateSeconds":345600},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":345600,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"103688","customfield_12312823":null,"summary":"All reduce tasks should be re-executed when tasktracker with a completed map task failed","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ltguo","name":"ltguo","key":"ltguo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Leitao Guo","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ltguo","name":"ltguo","key":"ltguo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Leitao Guo","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":345600,"percent":0},"customfield_12311024":null,"environment":"CentOS 5,\nhadoop-0.19.0","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":345600,"percent":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12416724/comment/12681215","id":"12681215","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. When a tasktracker with a completed map task failed, the map task will be re-exectuted, and all reduce tasks that haven't read the data from that tasktracker should be re-executed. \nReduce tasks are not re-executed, they will fail in fetching the map output and retry the fetch, will succeed once the reexecuted-map succeeds.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-03-12T08:31:30.586+0000","updated":"2009-03-12T08:31:30.586+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12416724/comment/12681219","id":"12681219","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"bq. In this situation, if the outputs of multi map tasks on the same dataset are different, for example outputting a random number, the outputs of maptask and the re-executed maptask will probably are different. Then the re-executed reduce tasks will read the new output of the re-executed maptask, but reduce tasks that have read the data from the failed tasktracker have read the old output. This probably will cause correctness of the result.\n\nI think your application should be tolerant to this happening and be written assuming that maps/reduces could fail or get killed, etc. We really don't want to do what you suggest.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2009-03-12T08:50:59.565+0000","updated":"2009-03-12T08:50:59.565+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12416724/comment/12681607","id":"12681607","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ltguo","name":"ltguo","key":"ltguo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Leitao Guo","active":true,"timeZone":"Etc/UTC"},"body":"I don't agree with you that the application should be tolerant to this situation. But the cost of re-execution of all reduce tasks is very high, do you have any suggestions to solve this issue?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ltguo","name":"ltguo","key":"ltguo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Leitao Guo","active":true,"timeZone":"Etc/UTC"},"created":"2009-03-13T05:10:02.510+0000","updated":"2009-03-13T05:10:02.510+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12416724/comment/12681610","id":"12681610","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"body":"Will seperating the job into two jobs resolve your problem? the first job only do the map, and if it is done, the outputs of map tasks are steady.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"created":"2009-03-13T05:20:01.013+0000","updated":"2009-03-13T05:20:01.013+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12416724/comment/12682842","id":"12682842","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"The cost of this change would be huge. Basically, any node going down or a crc failure in shuffle would cause you to kill all currently running reduces. That is unacceptable. Your application needs to be tolerant of reexecution of tasks. That is a fundamental constraint of map/reduce programming. In order to make your example work, the map could use the hash of the input split as the seed to the random number generator. That way, re-executions will have consistent behavior.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-03-17T22:44:22.781+0000","updated":"2009-03-17T22:44:22.781+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-5474/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0i3nz:"}}