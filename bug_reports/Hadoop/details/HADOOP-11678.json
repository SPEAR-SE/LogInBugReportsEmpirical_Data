{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12779778","self":"https://issues.apache.org/jira/rest/api/2/issue/12779778","key":"HADOOP-11678","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-07-29T19:48:53.152+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sun Jul 30 05:17:43 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11678/watchers","watchCount":5,"isWatching":false},"created":"2015-03-05T13:01:35.788+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327179","id":"12327179","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[{"id":"12510615","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12510615","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12719048","key":"HADOOP-10669","self":"https://issues.apache.org/jira/rest/api/2/issue/12719048","fields":{"summary":"Avro serialization does not flush buffered serialized values causing data lost","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12510612","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12510612","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12605001","key":"HADOOP-8730","self":"https://issues.apache.org/jira/rest/api/2/issue/12605001","fields":{"summary":"AvroSerialization may be broken","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12510613","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12510613","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12932875","key":"AVRO-1786","self":"https://issues.apache.org/jira/rest/api/2/issue/12932875","fields":{"summary":"Strange IndexOutofBoundException in GenericDatumReader.readString","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-07-30T05:17:43.209+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"We've had issues with the deserializer running into EOFException when using Cascading's TupleSerialization (which delegates to other hadoop serializers to serialize entries within its tuples) in combination with AvroSerialization.\n\nEventually tracked it down to the fact that AvroSerialization#AvroSerializer is buffering output (since it uses a buffering EncoderFactory#binaryEncoder rather than a non-buffering EncoderFactory#directBinaryEncoder):\n\nhttps://github.com/apache/hadoop/blob/e1109fb65608a668cd53dc324dadc6f63a74eeb9/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/serializer/avro/AvroSerialization.java#L105\n\nThe contract for Serializer explicitly states \"Serializers ... must not buffer the output since other producers may write to the output between calls to #serialize(Object).\" TupleSerialization does exactly that (write to the output between calls to #serialize), hence our problem.\n\nThere's a similar problem with the AvroDeserializer too -- it uses a buffering binaryDecoder, and this can consume the underlying InputStream beyond the end of the datum it's decoding, meaning that if a different Deserializer is used to read the next item, it'll start off in the wrong place and get confused.\n\nSwitching AvroSerializer and AvroDeserializer to use the non-buffering `EncoderFactory#directBinaryEncoder` and `DecoderFactory#directBinaryDecoder` fixes the issue for us.\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12879506","id":"12879506","filename":"HADOOP-11678.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"created":"2017-07-29T19:48:41.115+0000","size":849,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12879506/HADOOP-11678.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12879518","id":"12879518","filename":"HADOOP-11678.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"created":"2017-07-30T04:09:30.961+0000","size":1484,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12879518/HADOOP-11678.2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"AvroSerializer buffers output in violation of contract for Serializer","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=matthjw","name":"matthjw","key":"matthjw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matthew Willson","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=matthjw","name":"matthjw","key":"matthjw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matthew Willson","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779778/comment/14348936","id":"14348936","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=matthjw","name":"matthjw","key":"matthjw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matthew Willson","active":true,"timeZone":"Etc/UTC"},"body":"Updated to clarify that there's a similar problem with buffering in the deserializer too, and to describe a better fix via switching to directBinaryEncoder/Decoder.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=matthjw","name":"matthjw","key":"matthjw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matthew Willson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-05T15:38:28.822+0000","updated":"2015-03-05T15:38:28.822+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779778/comment/14348978","id":"14348978","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=matthjw","name":"matthjw","key":"matthjw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matthew Willson","active":true,"timeZone":"Etc/UTC"},"body":"Also note that this is not the same as the avro serialization in the separate avro-mapred library (org.apache.avro.mapred.AvroSerialization), which is implemented separately for AvroWrappers and is probably in more common usage.\n\nIn fact I'm not entirely clear why this code (org.apache.hadoop.io.serializer.avro.AvroSerialization) is in the hadoop project / why hadoop-common needs to have an avro dependency at all, given that there's a separate artifact in the avro project (avro-mapred) to get avro working in hadoop. Perhaps avro is used internally somewhere?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=matthjw","name":"matthjw","key":"matthjw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matthew Willson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-05T15:57:40.386+0000","updated":"2015-03-05T15:57:40.386+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779778/comment/16106227","id":"16106227","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"body":"Flush encoder after every object serialization","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"created":"2017-07-29T19:48:53.152+0000","updated":"2017-07-29T19:48:53.152+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779778/comment/16106244","id":"16106244","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"body":"In particular where I see this is with the Intermediate Files.  It works by serializing the key and value into a buffer then reading the buffer's length to determine how much data is about to be written to the intermediate file.  The problem here is that, for Avro serialization, the serialize method writes to a BufferedBinaryEncoder {{EncoderFactory.get().binaryEncoder}}.  The internal buffer is flushed to the underlying steam only when a certain number of bytes is written or if a single value of more than 512 bytes is written.  For smaller Avro objects, nothing is flushed.\n\n{code:title=org.apache.hadoop.mapred.IFile.Writer<K, V>)}\npublic void append(K key, V value) throws IOException {\n...\n      // Append the 'key'\n      keySerializer.serialize(key);\n      int keyLength = buffer.getLength();\n\n      // Append the 'value'\n      valueSerializer.serialize(value);\n      int valueLength = buffer.getLength() - keyLength;\n{code}\n\n{code:title=org.apache.avro.hadoop.io.AvroSerializer<T>}\n  /** {@inheritDoc} */\n  @Override\n  public void serialize(AvroWrapper<T> avroWrapper) throws IOException {\n    mAvroDatumWriter.write(avroWrapper.datum(), mAvroEncoder);\n    // This would be a lot faster if the Serializer interface had a flush() method and the\n    // Hadoop framework called it when needed.  For now, we'll have to flush on every record.\n    mAvroEncoder.flush();\n  }\n{code}\n\nAs is the contract of {{org.apache.hadoop.io.serializer.Serializer<T>}}, \n\n{quote}\nSerializers are stateful, but must not buffer the output since other producers may write to the output between calls to #serialize(Object).\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"created":"2017-07-29T21:11:16.277+0000","updated":"2017-07-29T21:11:16.277+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779778/comment/16106312","id":"16106312","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"body":"Submitted patch to flush the encoder buffer after each serialization and change the decoder to a non-buffering version so that it does not read (and then discard) extra bytes from the underlying stream.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=belugabehr","name":"belugabehr","key":"belugabehr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"BELUGA BEHR","active":true,"timeZone":"America/New_York"},"created":"2017-07-30T04:10:42.008+0000","updated":"2017-07-30T04:10:42.008+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779778/comment/16106326","id":"16106326","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  9s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 27s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 21s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 10s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 35s{color} | {color:orange} hadoop-common-project/hadoop-common: The patch generated 1 new + 1 unchanged - 0 fixed = 2 total (was 1) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 25s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 30s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  3s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 59m  0s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.security.TestKDiag |\n|   | hadoop.net.TestDNS |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HADOOP-11678 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12879518/HADOOP-11678.2.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 4e6ef28e86ca 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 890e14c |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/12895/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12895/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12895/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12895/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-30T05:17:43.209+0000","updated":"2017-07-30T05:17:43.209+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11678/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i26eev:"}}