{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13004243","self":"https://issues.apache.org/jira/rest/api/2/issue/13004243","key":"HADOOP-13593","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2016-09-12T09:01:29.158+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Sep 19 09:13:38 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_572346_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_608567624","customfield_12312321":null,"resolutiondate":"2016-09-19T09:12:28.036+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13593/watchers","watchCount":2,"isWatching":false},"created":"2016-09-12T08:00:09.181+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12480683","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12480683","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13005852","key":"HADOOP-13622","self":"https://issues.apache.org/jira/rest/api/2/issue/13005852","fields":{"summary":"`-atomic` should not be supported while using `distcp` command in object file system","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-09-19T09:13:38.775+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"While copying data from HDFS to Swift by using `hadoop distcp -atomic`, for example:\n{code}\nhadoop distcp -atomic /tmp/100M  swift://testhadoop.softlayer//tmp\n{code}\nit throws\n{code}\njava.lang.IllegalArgumentException: Work path swift://testhadoop.softlayer/._WIP_tmp546958075 and target path swift://testhadoop.softlayer/tmp are in different file system\n\tat org.apache.hadoop.tools.DistCp.configureOutputFormat(DistCp.java:351)\n.....\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12827988","id":"12827988","filename":"HADOOP-13593.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-09-12T08:08:36.908+0000","size":1021,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12827988/HADOOP-13593.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12828001","id":"12828001","filename":"HADOOP-13593.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-09-12T09:13:00.047+0000","size":1302,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12828001/HADOOP-13593.002.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"`hadoop distcp -atomic` invokes improper host check while copying data from HDFS to Swift","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483433","id":"15483433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"I find that in {{FileUtil#compareFs}}, it uses \"InetAddress.getByName(srcHost).getCanonicalHostName()\" to get the host name of Swift file system. In fact \"testhadoop.softlayer\" is an alias name of Swift, it's impossible to use \"getCanonicalHostName\" to get the real host name. I propose to delete it and upload v1 patch for this issue.\n\nSee the full stack info here:\n{code}\n16/09/08 20:59:36 WARN security.UserGroupInformation: Exception encountered while running the renewal command. Aborting renew thread. ExitCodeException exitCode=1: kinit: Ticket expired while renewing credentials\n\n16/09/08 20:59:37 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=true, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[/tmp/100M], targetPath=swift://testhadoop.softlayer/tmp, targetPathExists=true, preserveRawXattrs=false}\n16/09/08 20:59:38 INFO impl.TimelineClientImpl: Timeline service address: https://wangxjrhel672.fyre.ibm.com:8190/ws/v1/timeline/\n16/09/08 20:59:39 ERROR tools.DistCp: Exception encountered\njava.lang.IllegalArgumentException: Work path swift://testhadoop.softlayer/._WIP_tmp1072690165 and target path swift://testhadoop.softlayer/tmp are in different file system\n        at org.apache.hadoop.tools.DistCp.configureOutputFormat(DistCp.java:351)\n        at org.apache.hadoop.tools.DistCp.createJob(DistCp.java:237)\n        at org.apache.hadoop.tools.DistCp.createAndSubmitJob(DistCp.java:174)\n        at org.apache.hadoop.tools.DistCp.execute(DistCp.java:153)\n        at org.apache.hadoop.tools.DistCp.run(DistCp.java:126)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-09-12T08:06:05.649+0000","updated":"2016-09-12T09:39:01.155+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483562","id":"15483562","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  3s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m  2s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 30s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 23s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  7m 23s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 24s{color} | {color:orange} hadoop-common-project/hadoop-common: The patch generated 2 new + 59 unchanged - 0 fixed = 61 total (was 59) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 29s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 34s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 42m 44s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Issue | HADOOP-13593 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12827988/HADOOP-13593.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 5ee61cb8044b 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / cc01ed70 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10480/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10480/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10480/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-09-12T09:01:29.158+0000","updated":"2016-09-12T09:01:29.158+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483586","id":"15483586","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"uploaded v2 patch to address check style issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-09-12T09:13:00.051+0000","updated":"2016-09-12T09:13:00.051+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483594","id":"15483594","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"# please can you stick the full stack trace of the exception in as a comment; good for future searches of the same lines, & IDEs that navigate up the stack. Leaving out the bug description —as you did— is great, because it keeps out of all the emails, but having that stack in the comments is always useful\n# anything checking hostnames is going to be there for a reason. Presumably so that people can use URLs like hdfs://server:4040/ and hdfs://server.example.org:4040/ and have atomic operations. Changing this fairly fundamental behaviour is not going to happen, because it affects so much more than swift For that reason, it's going to have to be a -1 there, sorry.\n# none of the object stores support atomic renames, so an atomic distcp isn't going to work. in fact, maybe they should all reject the option outright to stop people thinking of it.\n\n\nIf there were to be a patch on this, it'd need tests. Here I'd recommend that (a) swift adds an implementation of {{AbstractContractDistCpTest}}, and that (b), that base test added a check for the atomic flag —one that every fs contract XML would have to declare whether or not it supported. The option. \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-09-12T09:17:10.185+0000","updated":"2016-09-12T09:17:10.185+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483686","id":"15483686","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"[~steve_l] Thanks a lot for your comments, that's really helpful.\n{quote}\n1. please can you stick the full stack trace of the exception in as a comment..\n{quote}\nSorry for omitting the stack info and I will edit my comment 1 to add the information.\n\n{quote}\n2. anything checking hostnames is going\n{quote}\nIn fact there is a code segment in {{FileUtils#compareFs}} as below:\n{code}\nString srcHost = srcUri.getHost();\nString dstHost = dstUri.getHost();\nif (!srcHost.equals(dstHost)) {\n        return false;\n}\n{code}\nand I think it can cover the case you mentioned above. Using \"getCanonicalHostName\" to double check whether hosts are equal seems good, but if the host name is an alias name, it may throw UnknownHostException here. If you don't agree to remove the check, at least we can do is to make the output info more accurate, \"Work path..in different file system\" is not right.\n\n{quote}\n3. none of the object stores support atomic renames...\n{quote}\nThanks for your info, yes you're right, if object store doesn't support atomic rename, it's not proper to use `distcp -atomic` here.\n\n{quote}\nIf there were to be a patch on this, it'd need tests. Here I'd recommend \n{quote}\nThanks for your suggestions. I will investigate them later.\nThanks again for your time!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-09-12T09:56:21.801+0000","updated":"2016-09-12T09:59:07.239+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483692","id":"15483692","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"one more thought: the code should be comparing FS schemas. If the filesystem is different, there's no point checking hostnames, is there? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-09-12T09:58:35.672+0000","updated":"2016-09-12T09:58:35.672+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483693","id":"15483693","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"one more thought: the code should be comparing FS schemas. If the filesystem is different, there's no point checking hostnames, is there? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-09-12T09:58:39.150+0000","updated":"2016-09-12T09:58:39.150+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483703","id":"15483703","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"[~stevel@apache.org] Yes there is a schema check in {{FileUtils#compareFs}}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-09-12T10:03:16.418+0000","updated":"2016-09-12T10:03:16.418+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15483704","id":"15483704","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 49s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 28s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 31s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 20s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  8m 20s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 57s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 44m 43s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.ha.TestZKFailoverController |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Issue | HADOOP-13593 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12828001/HADOOP-13593.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 648bffbe0d87 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / cc01ed70 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10481/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10481/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10481/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-09-12T10:03:28.258+0000","updated":"2016-09-12T10:03:28.258+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13004243/comment/15502810","id":"15502810","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"[~stevel@apache.org] I close this jira and hope to get your thoughts in HADOOP-13622. Thanks in advance.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuanbo","name":"yuanbo","key":"yuanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yuanbo&avatarId=25581","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yuanbo&avatarId=25581","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yuanbo&avatarId=25581","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yuanbo&avatarId=25581"},"displayName":"Yuanbo Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-09-19T09:13:38.775+0000","updated":"2016-09-19T09:13:38.775+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13593/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i33ic7:"}}