{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13166019","self":"https://issues.apache.org/jira/rest/api/2/issue/13166019","key":"HADOOP-15538","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-06-14T20:02:28.303+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Aug 14 17:40:49 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15538/watchers","watchCount":11,"isWatching":false},"created":"2018-06-14T06:52:17.861+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12536394","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12536394","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13165463","key":"HADOOP-15530","self":"https://issues.apache.org/jira/rest/api/2/issue/13165463","fields":{"summary":"RPC could stuck at senderFuture.get()","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12541644","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12541644","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13180851","key":"IMPALA-7482","self":"https://issues.apache.org/jira/rest/api/2/issue/13180851","fields":{"summary":"Deadlock with unknown lock holder in JVM in java.security.Provider.getService()","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-08-24T00:20:35.258+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12330961","id":"12330961","name":"common"}],"timeoriginalestimate":null,"description":"We have a jstack collection that spans 13 minutes. One frame per ~1.5 minutes. And for each of the frame, I observed the following:\r\n{code:java}\r\nFound one Java-level deadlock:\r\n=============================\r\n\"IPC Parameter Sending Thread #294\":\r\n  waiting to lock monitor 0x00007f68f21f3188 (object 0x0000000621745390, a java.lang.Object),\r\n  which is held by UNKNOWN_owner_addr=0x00007f68332e2800\r\n\r\nJava stack information for the threads listed above:\r\n===================================================\r\n\"IPC Parameter Sending Thread #294\":\r\n        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:268)\r\n        - waiting to lock <0x0000000621745390> (a java.lang.Object)\r\n        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)\r\n        - locked <0x0000000621745380> (a java.lang.Object)\r\n        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)\r\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\r\n        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)\r\n        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)\r\n        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\r\n        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\r\n        - locked <0x0000000621749850> (a java.io.BufferedOutputStream)\r\n        at java.io.DataOutputStream.flush(DataOutputStream.java:123)\r\n        at org.apache.hadoop.ipc.Client$Connection$3.run(Client.java:1072)\r\n        - locked <0x000000062174b878> (a java.io.DataOutputStream)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\nFound one Java-level deadlock:\r\n=============================\r\n\"IPC Client (297602875) connection to x.y.z.p:8020 from impala\":\r\n  waiting to lock monitor 0x00007f68f21f3188 (object 0x0000000621745390, a java.lang.Object),\r\n  which is held by UNKNOWN_owner_addr=0x00007f68332e2800\r\n\r\nJava stack information for the threads listed above:\r\n===================================================\r\n\"IPC Client (297602875) connection to x.y.z.p:8020 from impala\":\r\n        at sun.nio.ch.SocketChannelImpl.readerCleanup(SocketChannelImpl.java:279)\r\n        - waiting to lock <0x0000000621745390> (a java.lang.Object)\r\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:390)\r\n        - locked <0x0000000621745370> (a java.lang.Object)\r\n        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)\r\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\r\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\r\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\r\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\r\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\r\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:553)\r\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\r\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)\r\n        - locked <0x00000006217476f0> (a java.io.BufferedInputStream)\r\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\r\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1113)\r\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1006)\r\n\r\nFound 2 deadlocks.\r\n{code}\r\nThis happens with jdk1.8.0_162 on 2.6.32-696.18.7.el6.x86_64.\r\n\r\nThe code appears to match [https://insight.io/github.com/AdoptOpenJDK/openjdk-jdk8u/tree/dev/jdk/src/share/classes/sun/nio/ch/SocketChannelImpl.java].\r\n\r\nThe first thread is blocked at:\r\n\r\n[https://insight.io/github.com/AdoptOpenJDK/openjdk-jdk8u/blob/dev/jdk/src/share/classes/sun/nio/ch/SocketChannelImpl.java?line=268]\r\n\r\nThe second thread is blocked at:\r\n [https://insight.io/github.com/AdoptOpenJDK/openjdk-jdk8u/blob/dev/jdk/src/share/classes/sun/nio/ch/SocketChannelImpl.java?line=279]\r\n\r\nThere are two issues here:\r\n # There seems to be a real deadlock because the stacks remain the same even if the first an last jstack frames captured is 13 minutes apart.\r\n # Java deadlock report seems to be problematic, two threads that have deadlock should not be blocked on the same lock, but they appear to be in this case: the same SocketChannelImpl's stateLock.\r\n\r\nI found a relevant jdk jira [https://bugs.openjdk.java.net/browse/JDK-8007476], it explains where two deadlocks are reported and they are really for the same deadlock.\r\n\r\nI don't see a similar report about this issue in jdk jira database, and I'm thinking about filing a jdk jira for that, but would like to throw some discussion here before that.\r\n\r\nIssue#1 is important, because the client is hanging, which indicate a real problem; however, without a correct report before issue#2 is fixed, it's not clear how the deadlock really looks like.\r\n\r\nThanks.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12927903","id":"12927903","filename":"t1.jstack","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-15T00:23:16.886+0000","size":66932,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12927903/t1.jstack"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12927904","id":"12927904","filename":"t1+13min.jstack","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-15T00:23:16.893+0000","size":66932,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12927904/t1%2B13min.jstack"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Possible RPC deadlock in Client","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16512076","id":"16512076","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hm, I noticed that in [https://bugs.openjdk.java.net/browse/JDK-8007476], The \"which is held by UNKNOWN_owner_addr\" shows two different values for the two threads involved in the deadlock, one corresponds to each of these two threads.\r\n{code:java}\r\nFound one Java-level deadlock:\r\n=============================\r\n\"Worker-1\":\r\n  waiting to lock monitor 0x02f60e54 (object 0x1026ce00, a java.lang.Object),\r\n  which is held by UNKNOWN_owner_addr=0x0352fc54\r\n......\r\nFound one Java-level deadlock:\r\n=============================\r\n\"Worker-0\":\r\n  waiting to lock monitor 0x02f601bc (object 0x1026ce08, a java.lang.Object),\r\n  which is held by UNKNOWN_owner_addr=0x0357fbd4\r\n{code}\r\nHowever, in the case I reported here, they point to the same value:\r\n{code:java}\r\nFound one Java-level deadlock:\r\n=============================\r\n\"IPC Parameter Sending Thread #294\":\r\n  waiting to lock monitor 0x00007f68f21f3188 (object 0x0000000621745390, a java.lang.Object),\r\n  which is held by UNKNOWN_owner_addr=0x00007f68332e2800\r\n......\r\nFound one Java-level deadlock:\r\n=============================\r\n\"IPC Client (297602875) connection to x.y.z.p:8020 from impala\":\r\n  waiting to lock monitor 0x00007f68f21f3188 (object 0x0000000621745390, a java.lang.Object),\r\n  which is held by UNKNOWN_owner_addr=0x00007f68332e2800\r\n{code}\r\nand this value could just be a third thread, thus two deadlock pairs <thread1, thread3>, <thread2, thread3>. This explains issue#2. However, I wish java stack dump could be more clear about why UNKNOWN_owner_addr here, what thread this really is.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-14T07:29:38.436+0000","updated":"2018-06-14T07:39:39.192+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16512135","id":"16512135","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"All other 6 BLOCKED threads (there are 8 BLOCKED threads in total in each jstack frame) look like\r\n{code:java}\r\n\"Thread-52\" #82 prio=5 os_prio=0 tid=0x000000001a2c1000 nid=0xf189f waiting for monitor entry [0x00007f697a77f000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(Client.java:1053)\r\n        - waiting to lock <0x00000006215c1e08> (a java.lang.Object)\r\n        at org.apache.hadoop.ipc.Client.call(Client.java:1483)\r\n        at org.apache.hadoop.ipc.Client.call(Client.java:1441)\r\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\r\n        at com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\r\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:266)\r\n        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:258)\r\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)\r\n        at com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\r\n        at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1323)\r\n        at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1310)\r\n        at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1298)\r\n        at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:309)\r\n        at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:275)\r\n        - locked <0x0000000618947838> (a java.lang.Object)\r\n        at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:267)\r\n        at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1629)\r\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:338)\r\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:334)\r\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:334)\r\n{code}\r\nThese threads all blocked due to RPC serialization at\r\n{code:java}\r\n    public void sendRpcRequest(final Call call)\r\n        throws InterruptedException, IOException {\r\n      if (shouldCloseConnection.get()) {\r\n        return;\r\n      }\r\n\r\n      // Serialize the call to be sent. This is done from the actual\r\n      // caller thread, rather than the sendParamsExecutor thread,\r\n      \r\n      // so that if the serialization throws an error, it is reported\r\n      // properly. This also parallelizes the serialization.\r\n      //\r\n      // Format of a call on the wire:\r\n      // 0) Length of rest below (1 + 2)\r\n      // 1) RpcRequestHeader  - is serialized Delimited hence contains length\r\n      // 2) RpcRequest\r\n      //\r\n      // Items '1' and '2' are prepared here. \r\n      final DataOutputBuffer d = new DataOutputBuffer();\r\n      RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader(\r\n          call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry,\r\n          clientId);\r\n      header.writeDelimitedTo(d);\r\n      call.rpcRequest.write(d);\r\n\r\n      synchronized (sendRpcRequestLock) { <===================Client.java, line 1053\r\n        Future<?> senderFuture = sendParamsExecutor.submit(new Runnable() {\r\n{code}\r\n\r\nThese 6 threads are all blocked due to the single RPC thread holding the sendRpcRequestLock (\"IPC Parameter Sending Thread #294\" in the jira description), which is blocked due to the reported deadlock.\r\n\r\nSo what is the \"UNKNOWN_owner_addr=0x00007f68332e2800\" thread that caused the \"deadlock\" is hidden.\r\n\r\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-14T08:10:27.965+0000","updated":"2018-06-14T08:10:27.965+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16512923","id":"16512923","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"The JDK-8007476 bug appears to have simply obscured the threads in the deadlock output.  Notice that the stacktraces still include \"\\- waiting to lock <monitor>\" and \"\\- locked <monitor>\" which makes it easy to see the deadlock offenders despite the \"UNKNOWN_owner_addr\".\r\n\r\nDo you have the full stack trace that you can link as an attachment?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2018-06-14T20:02:28.303+0000","updated":"2018-06-14T20:02:51.036+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16512968","id":"16512968","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billyean","name":"billyean","key":"billyean","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billyean&avatarId=34501","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billyean&avatarId=34501","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billyean&avatarId=34501","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billyean&avatarId=34501"},"displayName":"Haibo Yan","active":true,"timeZone":"America/Los_Angeles"},"body":"[~yzhangal] It may be easier to use jhat to do analyze the heapdump. Since we object address like below. Can you get java heapdump?\r\n\r\n \r\n waiting to lock monitor 0x02f60e54 (object 0x1026ce00, a java.lang.Object),\r\n  which is held by UNKNOWN_owner_addr=0x0352fc54","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billyean","name":"billyean","key":"billyean","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billyean&avatarId=34501","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billyean&avatarId=34501","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billyean&avatarId=34501","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billyean&avatarId=34501"},"displayName":"Haibo Yan","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-14T20:51:43.207+0000","updated":"2018-06-14T20:51:43.207+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16513183","id":"16513183","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot [~daryn] and [~billyean].\r\n\r\nPlease see attached two jstack files, one is at the begining t1.jstack, the other is 13 minutes later: t1+13min.jstack.\r\n\r\nMy read is, JDK-8007476 fixed a jdk internal error that crash the jstack dump itself, by introducing \"which is held by UNKNOWN_owner_addr=\" to make it dump reasonable value of the other guy who hold the lock, so it can dump out the deadlock threads pair instead of crashing. In the example provided there, the two threads point to each other because they are the two threads involved in the same deadlock.\r\n\r\nI think the java version here has the JDK-8007476  fix, that's why we also have \"which is held by UNKNOWN_owner_addr=\" reported; However, the other party of deadlocks is not reported here.\r\n\r\nProblem here:\r\n # Did the deadlock finder miss some threads involved in the deadlock?\r\n # If it did not miss, why the two threads listed are blocked at the same lock (stateLock)? And these two threads point to the same culprit addr reported as \"which is held by UNKNOWN_owner_addr=\".\r\n # Who holds the stateLock?\r\n\r\nHaibo's suggestion of having heapdump seems a good direction to dive into. Unfortunately the problem is intermittent and it takes time to see it again. But I will look into.\r\n\r\nIf any of you have more comments and insight to share, I would really appreciate.\r\n\r\nThanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-15T00:44:25.486+0000","updated":"2018-06-15T00:45:27.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16513989","id":"16513989","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"The IPC client and parameter sending threads should be the only threads using the socket channel.  Note there's no other parameter sending threads other than the one reported in the deadlock.  This implies a dead thread is holding the monitor which would be an insidious jvm bug.\r\n\r\nHere's what produces the UNKNOWN_owner_addr output.  Note the comment \"blocked permanently\".\r\n{code:java}\r\n      currentThread = Threads::owning_thread_from_monitor_owner(\r\n                        (address)waitingToLockMonitor->owner(),\r\n                        false /* no locking needed */);\r\n      if (currentThread == NULL) {\r\n        // The deadlock was detected at a safepoint so the JavaThread\r\n        // that owns waitingToLockMonitor should be findable, but\r\n        // if it is not findable, then the previous currentThread is\r\n        // blocked permanently.\r\n        st->print(\"%s UNKNOWN_owner_addr=\" PTR_FORMAT, owner_desc,\r\n                  (address)waitingToLockMonitor->owner());\r\n        continue;\r\n      }\r\n{code}\r\n\r\nAre there any log lines indicating an OOM or other serious problem occurred?  Maybe native code somehow killed the thread directly or by mangling memory?\r\n\r\nNext time it happens, run pstack to check for {{SharedRuntime::handle_wrong_method}}.  There is a (supposedly) fixed jvm bug that causes a process to go into an infinite loop which eats 100% cpu.  That said, was the process idle or consuming cpu?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2018-06-15T15:42:27.219+0000","updated":"2018-06-15T15:42:27.219+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16514004","id":"16514004","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Just noticed a possible clue:\r\n{noformat}\r\n\"main\" #1 prio=5 os_prio=0 tid=0x0000000004cd8000 nid=0xf1491 runnable [0x0000000000000000]\r\n   java.lang.Thread.State: RUNNABLE\r\n\r\n\"VM Thread\" os_prio=0 tid=0x0000000004f39000 nid=0xf163e runnable\r\n{noformat}\r\n\r\nThe main thread has no stack trace.  Did you clip it out?  If no, that's indicative of the jvm trying to shutdown.  It may have detected a thread death or other nasty issue but is stuck waiting for all the non-daemon threads to exit.  Look for a hs_err_pid file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2018-06-15T15:55:10.876+0000","updated":"2018-06-15T15:55:10.876+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16514360","id":"16514360","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot [~daryn]! somehow I did not see your update in time. I did not clip anything out from the jstack logs I posted. I am not aware any OOM, good question about whether the process is idle or consuming cpu, not sure if we have that info but let me try. We do some have pstack too, I had been studying that and was not very successful. I will dig further with your hint.  Thanks again!\r\n\r\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-15T21:03:58.509+0000","updated":"2018-06-15T21:14:28.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16514402","id":"16514402","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"pstack for thread\r\n{code:java}\r\n\"IPC Parameter Sending Thread #294\" #142281 daemon prio=5 os_prio=0 tid=0x00007f676e2b7800 nid=0x1bfe75 waiting for monitor entry [0x00007f6920ed4000]\r\n{code}\r\nis\r\n{code:java}\r\nThread 6499 (Thread 0x7f6920ed5700 (LWP 1834613)):\r\n#0 0x000000396ce0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\r\n#1 0x00007f69f16c3c23 in os::PlatformEvent::park() () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#2 0x00007f69f16b2bad in ObjectMonitor::EnterI(Thread*) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#3 0x00007f69f16b4b81 in ObjectMonitor::enter(Thread*) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#4 0x00007f69f1769430 in SharedRuntime::complete_monitor_locking_C(oopDesc*, BasicLock*, JavaThread*) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#5 0x00007f69dedaadc8 in ?? ()\r\n#6 0x0000000630aa0dd0 in ?? ()\r\n#7 0x00007f69dfa61464 in ?? ()\r\n#8 0x00000006217452d0 in ?? ()\r\n#9 0xc42e8a70000294c8 in ?? ()\r\n#10 0x0000000621745380 in ?? ()\r\n#11 0x0000000621745390 in ?? ()\r\n#12 0x00007f676e2b7800 in ?? ()\r\n#13 0x00007f69f1d83790 in Universe::_heap_used_at_last_gc () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#14 0x00007f67c42e8a70 in ?? ()\r\n#15 0x00000000c42e8a72 in ?? ()\r\n#16 0x0000000630aa0dd0 in ?? ()\r\n#17 0x00007f69f17601b0 in OptoRuntime::new_instance_C(Klass*, JavaThread*) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n{code}\r\n \r\n The pstack for \r\n  \r\n{code:java}\r\n\"IPC Client (297602875) connection to x.y.z.p:8020 from impala\" #142248 daemon prio=5 os_prio=0 tid=0x00007f6920ed6000 nid=0x1bc4ee waiting for monitor entry [0x00007f6961246000]\r\n{code}\r\nis\r\n{code:java}\r\nThread 9778 (Thread 0x7f6961247700 (LWP 1819886)):\r\n#0  0x000000396ce0ba5e in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\r\n#1  0x00007f69f16c8dbf in os::PlatformEvent::park(long) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#2  0x00007f69f16b2a85 in ObjectMonitor::EnterI(Thread*) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#3  0x00007f69f16b4b81 in ObjectMonitor::enter(Thread*) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#4  0x00007f69f1769430 in SharedRuntime::complete_monitor_locking_C(oopDesc*, BasicLock*, JavaThread*) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n#5  0x00007f69dedaadc8 in ?? ()\r\n#6  0x00000006217452d0 in ?? ()\r\n#7  0x00007f69e010080c in ?? ()\r\n#8  0x0000060600000606 in ?? ()\r\n#9  0xc42e8a72c42e8a72 in ?? ()\r\n#10 0x0000000621745390 in ?? ()\r\n#11 0x0000000621745370 in ?? ()\r\n#12 0x0000000621745390 in ?? ()\r\n#13 0xc42e8a6e00000606 in ?? ()\r\n#14 0x0000000600000606 in ?? ()\r\n#15 0x000000062d2c5b80 in ?? ()\r\n#16 0x00000000806f8230 in ?? ()\r\n#17 0x0000000000000007 in ?? ()\r\n#18 0x0000000000000001 in ?? ()\r\n#19 0x0000000000000001 in ?? ()\r\n#20 0x0000000000000001 in ?? ()\r\n#21 0x0000000000000003 in ?? ()\r\n#22 0x0000000000000003 in ?? ()\r\n#23 0x0000000000045044 in ?? ()\r\n#24 0x00000006217455c0 in ?? ()\r\n#25 0x00007f69dfa7cd68 in ?? ()\r\n#26 0x00000006217455c0 in ?? ()\r\n#27 0x0000000100000001 in ?? ()\r\n#28 0x000000062d2c5b80 in ?? ()\r\n#29 0x00000001002a6c60 in ?? ()\r\n#30 0x000000062d2c5bb0 in ?? ()\r\n#31 0x00000001100df044 in ?? ()\r\n#32 0x00000000806f8220 in ?? ()\r\n#33 0x0000000000000007 in ?? ()\r\n#34 0x00000163ce93a3ba in ?? ()\r\n#35 0x00000006217452d0 in ?? ()\r\n#36 0x000000062d2c5bb0 in ?? ()\r\n#37 0x00007f69f122422a in CollectedHeap::fill_with_object(HeapWord*, unsigned long, bool) () from /usr/java/jdk1.8.0_162/jre/lib/amd64/server/libjvm.so\r\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-15T21:57:41.820+0000","updated":"2018-06-15T21:58:39.862+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16514425","id":"16514425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Only the two threads above refers to 0x0000000621745390 in the pthread dump. In LWP 1819886 it looks like\r\n{code}\r\n#10 0x0000000621745390 in ?? ()\r\n#11 0x0000000621745370 in ?? ()\r\n#12 0x0000000621745390 in ?? ()\r\n{code} \r\nand this one has deeper stack,\r\nvs \r\n{code}\r\n#11 0x0000000621745390 in ?? ()\r\n{code} \r\nin LWP 1834613, which has less deep stack.\r\n\r\n1819886 is in:\r\n{code}\r\n#0  0x000000396ce0ba5e in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\r\n{code}\r\n\r\n1834613 is in\r\n{code}\r\n#0  0x000000396ce0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\r\n{code}\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-15T22:09:44.904+0000","updated":"2018-06-15T22:21:11.210+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16514551","id":"16514551","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"FYI [~daryn], the CPU usage is pretty low.\r\n\r\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-16T00:07:48.438+0000","updated":"2018-06-16T00:07:48.438+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16514708","id":"16514708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Expanding the code snippet that [~daryn] shared, the following method searched all threads for the owner of the lock, and failed to find.\r\n{code}\r\n    // refer to Threads::owning_thread_from_monitor_owner\r\n    public JavaThread owningThreadFromMonitor(Address o) {\r\n        if (o == null) return null;\r\n        for (JavaThread thread = first(); thread != null; thread = thread.next()) {\r\n            if (o.equals(thread.threadObjectAddress())) {\r\n                return thread;\r\n            }\r\n        }\r\n\r\n        for (JavaThread thread = first(); thread != null; thread = thread.next()) {\r\n          if (thread.isLockOwned(o))\r\n            return thread;\r\n        }\r\n        return null;\r\n    }\r\n{code}\r\n\r\nThere are several possibilities:\r\n1. The thread the used to hold the lock was removed somehow\r\n2. The thread is still there, but the above method did not find.\r\n\r\nIt's more likely 1; It could be 2 if it were the threads that have empty dump in the logs I attached, but the chance seems low there.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-16T07:15:30.539+0000","updated":"2018-06-16T07:15:30.539+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16514846","id":"16514846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"There is also the other thread reported in HADOOP-15530 blocked at:\r\n\r\n[https://insight.io/github.com/AdoptOpenJDK/openjdk-jdk8u/blob/dev/jdk/src/share/classes/java/util/concurrent/FutureTask.java?line=396]\r\n\r\nThere is a chance that this thread is in play but I have not figured out how. \r\n\r\nI wish the comment here \r\n\r\n[https://insight.io/github.com/JetBrains/jdk8u_hotspot/blob/master/src/share/vm/services/threadService.cpp?line=906]\r\n\r\ncould give some explanation what are the possible scenarios that the lock owner is not findable. \r\n\r\nThis is likely a jdk bug: a lock has an associated owner thread address, but the thread can not be found. It seems to me that the only hope now is to  get heapdump and coredump to find clue. \r\n\r\nAny comment/insight is very much appreciated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-06-16T16:55:33.012+0000","updated":"2018-06-16T17:29:16.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16538911","id":"16538911","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=misha%40cloudera.com","name":"misha@cloudera.com","key":"misha@cloudera.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Misha Dmitriev","active":true,"timeZone":"America/Los_Angeles"},"body":"So, as far as I understand, we have two threads that try to grab the same lock (which is an instance of java.lang.Object referened by SocketChannelImpl.stateLock). When the JVM's deadlock detection mechanism tries to find who currently holds this lock, it cannot find any Java thread responsible for this. Such a situation is considered a variation of a deadlock, though it's not a classical one with two threads and two locks. Rather, it's a single lock, but it can never be grabbed by the waiting threads, because the only thread that can unlock it somehow disappeared. Note that the JVM's message, as well as the comments in the JVM code, are somewhat cryptic, and it took me some head-scratching and guessing before I understood what they try to say.\r\n\r\nI don't think that some normal Java thread threw an exception and exited, but didn't clean up one of the locks that it was holding. At least I've never seen such a situation in the past. Probably such a bug would be relatively easy to reproduce, and thus would have been fixed long ago. So I think here we have something really non-standard in play, and therefore the following exotic scenarios are more likely here:\r\n # The lock is still being held by some thread that the JVM doesn't know about, e.g. one started from native code.\r\n # The thread that was holding the lock exited in some non-standard, non-graceful way, perhaps because of a failure in native code. I am not sure what happens in such a case, and my theory is that if the thread is terminated by the OS and the JVM doesn't have a chance to interfere, all the Java locks that such a thread holds won't be unlocked. So we really have an \"orphaned\" lock.\r\n # Native code generally doing something bad. Note that in the JDK bug mentioned above, one of the JDK guys gave the following possible reason for running into this condition: \"My point is that the reason for the assert condition not holding (the owner of a monitor apparently not being in the Threadslist) may not be due to any inherent bug in deadlock detection or monitor management but may due to some other problem induced by the testcase - e.g. a memory stomp due to native code failing to check for errors after invoking JNI functions.\"\r\n\r\nThe bottom line is that I think we should really sniff for the native code in the app that runs this HDFS Client, and then check if that native code is doing something unusual.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=misha%40cloudera.com","name":"misha@cloudera.com","key":"misha@cloudera.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Misha Dmitriev","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-10T16:38:22.489+0000","updated":"2018-07-10T16:38:22.489+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16540322","id":"16540322","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot [~misha@cloudera.com]. Good inputs!\r\n\r\nThe java lock of interest here is a java object (stateLock in SocketChannelImpl), and it's used in synchronized block, example below. Assume the unknown thread is an external thread in the C++ world that reached java via JNI (should be in our case since it's impalad).\r\n\r\nThe lock is acquired/released looks like the following:\r\n{code:java}\r\n    private void ensureWriteOpen() throws ClosedChannelException {\r\n        synchronized (stateLock) {\r\n            if (!isOpen())\r\n                throw new ClosedChannelException();\r\n            if (!isOutputOpen)\r\n                throw new ClosedChannelException();\r\n            if (!isConnected())\r\n                throw new NotYetConnectedException();\r\n        }\r\n    }\r\n{code}\r\nso the speculated scenario is: an external thread unknown to java acquired the lock upon entering the synchronized block, then the thread disappeared abnormally without the lock being released.\r\n\r\nIn java synchronized block semantics, even if the execution of this thread is to exit, with or without exception being thrown inside the block, it would release the lock before getting out of the block;\r\n\r\nHowever, it doesn't release the lock in our case. This means the execution of the thread is essentially terminated inside the synchronized block, without handling any error, without even going out of the synchronized block, or the thread is \"frozen\" inside the synchronized block. Memory stomp might be a reason, but I wonder how.\r\n\r\nDiscussions in\r\n [https://bugs.openjdk.java.net/browse/JDK-8007476]\r\n\r\nstated\r\n{quote}The VM should never encounter a monitor with an owner thread that doesn't exist. Seems to me this may be a symptom rather than the actual problem.\r\n\r\nLooking at the NFC.c code it seems to me that the code is fragile because it has sequences of the form:\r\n\r\nclazz = (*env)->FindClass(env, \"cvm/jit/share/TestException\");\r\n mid = (*env)->GetMethodID(env, clazz, \"<init>\", \"()V\");\r\n throwObj = (jthrowable) (*env)->NewObject(env, clazz, mid);\r\n\r\nbut there is no checking to see if any exceptions occurred. Not saying that is the case here but if for some reason there is a problem who knows what the failure mode might be\r\n{quote}\r\nand\r\n{quote}My point is that the reason for the assert condition not holding (the owner of a monitor apparently not being in the Threadslist) may not be due to any inherent bug in deadlock detection or monitor management but may due to some other problem induced by the testcase - eg a memory stomp due to native code failing to check for errors after invoking JNI functions.\r\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-11T16:19:05.115+0000","updated":"2018-07-11T16:19:05.115+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16540325","id":"16540325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"BTW, I agree very much with \r\n{quote}\r\nThe bottom line is that I think we should really sniff for the native code in the app that runs this HDFS Client, and then check if that native code is doing something unusual.\r\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-11T16:20:14.917+0000","updated":"2018-07-11T16:20:41.354+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16579999","id":"16579999","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Did you ever look for an hs_err file per my earlier comment:\r\n\r\n\"The main thread has no stack trace. Did you clip it out? If no, that's indicative of the jvm trying to shutdown. It may have detected a thread death or other nasty issue but is stuck waiting for all the non-daemon threads to exit. Look for a hs_err_pid file.\"","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2018-08-14T16:02:39.325+0000","updated":"2018-08-14T16:02:39.325+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166019/comment/16580137","id":"16580137","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~daryn]\r\n\r\nAt this point we (+[~yzhangal]) think this symptom most likely pertains to OOM in a native + JVM hybrid process (such as an Impala Daemon). Somehow a thread exited without releasing the lock, and other threads had to wait for the lock and can't terminate. \r\n\r\n \r\n\r\nWe don't have a definite evidence to prove this theory, but after we bumped up the heap settings of the Impala daemons on the cluster, we've not observed the same issue for over a month (previously it was seen at least once per week).\r\n\r\nSo to conclude, it is likely a JVM bug rather than a Hadoop bug.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-08-14T17:40:49.242+0000","updated":"2018-08-14T17:40:49.242+0000"}],"maxResults":18,"total":18,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15538/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3uuj3:"}}