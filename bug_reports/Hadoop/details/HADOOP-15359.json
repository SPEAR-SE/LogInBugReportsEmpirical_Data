{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13149832","self":"https://issues.apache.org/jira/rest/api/2/issue/13149832","key":"HADOOP-15359","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-04-03T22:11:37.818+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jul 05 17:40:53 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15359/watchers","watchCount":10,"isWatching":false},"created":"2018-04-03T21:13:34.790+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327179","id":"12327179","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12329058","id":"12329058","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12341431","id":"12341431","description":"3.0.0 GA release","name":"3.0.0","archived":false,"released":true,"releaseDate":"2017-12-13"}],"issuelinks":[{"id":"12533392","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12533392","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12724659","key":"HADOOP-10768","self":"https://issues.apache.org/jira/rest/api/2/issue/12724659","fields":{"summary":"Optimize Hadoop RPC encryption performance","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-07-05T17:59:54.258+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310688","id":"12310688","name":"ipc","description":""}],"timeoriginalestimate":null,"description":"In a recent internal testing, we have found a DFS client hang. Further inspecting jstack shows the following:\r\n\r\n{noformat}\r\n\"IPC Client (552936351) connection toHOSTNAME:8020 from PRINCIPAL\" #7468 daemon prio=5 os_prio=0 tid=0x00007f6bb306c000 nid=0x1c76e waiting for monitor entry [0x00007f6bc2bd6000]\r\n   java.lang.Thread.State: BLOCKED (on object monitor)\r\n        at java.security.Provider.getService(Provider.java:1035)\r\n        - waiting to lock <0x0000000080277040> (a sun.security.provider.Sun)\r\n        at sun.security.jca.ProviderList$ServiceList.tryGet(ProviderList.java:444)\r\n        at sun.security.jca.ProviderList$ServiceList.access$200(ProviderList.java:376)\r\n        at sun.security.jca.ProviderList$ServiceList$1.hasNext(ProviderList.java:486)\r\n        at javax.crypto.Cipher.getInstance(Cipher.java:513)\r\n        at sun.security.krb5.internal.crypto.dk.Des3DkCrypto.getCipher(Des3DkCrypto.java:202)\r\n        at sun.security.krb5.internal.crypto.dk.DkCrypto.dr(DkCrypto.java:484)\r\n        at sun.security.krb5.internal.crypto.dk.DkCrypto.dk(DkCrypto.java:447)\r\n        at sun.security.krb5.internal.crypto.dk.DkCrypto.calculateChecksum(DkCrypto.java:413)\r\n        at sun.security.krb5.internal.crypto.Des3.calculateChecksum(Des3.java:59)\r\n        at sun.security.jgss.krb5.CipherHelper.calculateChecksum(CipherHelper.java:231)\r\n        at sun.security.jgss.krb5.MessageToken.getChecksum(MessageToken.java:466)\r\n        at sun.security.jgss.krb5.MessageToken.verifySignAndSeqNumber(MessageToken.java:374)\r\n        at sun.security.jgss.krb5.WrapToken.getDataFromBuffer(WrapToken.java:284)\r\n        at sun.security.jgss.krb5.WrapToken.getData(WrapToken.java:209)\r\n        at sun.security.jgss.krb5.WrapToken.getData(WrapToken.java:182)\r\n        at sun.security.jgss.krb5.Krb5Context.unwrap(Krb5Context.java:1053)\r\n        at sun.security.jgss.GSSContextImpl.unwrap(GSSContextImpl.java:403)\r\n        at com.sun.security.sasl.gsskerb.GssKrb5Base.unwrap(GssKrb5Base.java:77)\r\n        at org.apache.hadoop.security.SaslRpcClient$WrappedInputStream.readNextRpcPacket(SaslRpcClient.java:617)\r\n        at org.apache.hadoop.security.SaslRpcClient$WrappedInputStream.read(SaslRpcClient.java:583)\r\n        - locked <0x0000000083444878> (a java.nio.HeapByteBuffer)\r\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\r\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:553)\r\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\r\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)\r\n        - locked <0x00000000834448c0> (a java.io.BufferedInputStream)\r\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\r\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1113)\r\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1006)\r\n{noformat}\r\n\r\nand at the end of jstack:\r\n{noformat}\r\nFound one Java-level deadlock:\r\n=============================\r\n\"IPC Parameter Sending Thread #29\":\r\n  waiting to lock monitor 0x0000000017ff49f8 (object 0x0000000080277040, a sun.security.provider.Sun),\r\n  which is held by UNKNOWN_owner_addr=0x0000000050607000\r\n\r\nJava stack information for the threads listed above:\r\n===================================================\r\n\"IPC Parameter Sending Thread #29\":\r\n        at java.security.Provider.getService(Provider.java:1035)\r\n        - waiting to lock <0x0000000080277040> (a sun.security.provider.Sun)\r\n        at sun.security.jca.ProviderList$ServiceList.tryGet(ProviderList.java:437)\r\n        at sun.security.jca.ProviderList$ServiceList.access$200(ProviderList.java:376)\r\n        at sun.security.jca.ProviderList$ServiceList$1.hasNext(ProviderList.java:486)\r\n        at javax.crypto.SecretKeyFactory.nextSpi(SecretKeyFactory.java:293)\r\n        - locked <0x00000000834386b8> (a java.lang.Object)\r\n        at javax.crypto.SecretKeyFactory.<init>(SecretKeyFactory.java:121)\r\n        at javax.crypto.SecretKeyFactory.getInstance(SecretKeyFactory.java:160)\r\n        at sun.security.krb5.internal.crypto.dk.Des3DkCrypto.getCipher(Des3DkCrypto.java:187)\r\n        at sun.security.krb5.internal.crypto.dk.DkCrypto.dr(DkCrypto.java:484)\r\n        at sun.security.krb5.internal.crypto.dk.DkCrypto.dk(DkCrypto.java:447)\r\n        at sun.security.krb5.internal.crypto.dk.DkCrypto.calculateChecksum(DkCrypto.java:413)\r\n        at sun.security.krb5.internal.crypto.Des3.calculateChecksum(Des3.java:59)\r\n        at sun.security.jgss.krb5.CipherHelper.calculateChecksum(CipherHelper.java:231)\r\n        at sun.security.jgss.krb5.MessageToken.getChecksum(MessageToken.java:466)\r\n        at sun.security.jgss.krb5.MessageToken.genSignAndSeqNumber(MessageToken.java:315)\r\n        at sun.security.jgss.krb5.WrapToken.<init>(WrapToken.java:422)\r\n        at sun.security.jgss.krb5.Krb5Context.wrap(Krb5Context.java:922)\r\n        at sun.security.jgss.GSSContextImpl.wrap(GSSContextImpl.java:385)\r\n        at com.sun.security.sasl.gsskerb.GssKrb5Base.wrap(GssKrb5Base.java:103)\r\n        at org.apache.hadoop.security.SaslRpcClient$WrappedOutputStream.write(SaslRpcClient.java:636)\r\n        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\r\n        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\r\n        - locked <0x00000000834389a8> (a java.io.BufferedOutputStream)\r\n        at java.io.DataOutputStream.flush(DataOutputStream.java:123)\r\n        at org.apache.hadoop.ipc.Client$Connection$3.run(Client.java:1072)\r\n        - locked <0x00000000834389c0> (a java.io.DataOutputStream)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n{noformat}\r\n\r\nAfter some research, the closest I found is https://bugs.openjdk.java.net/browse/JDK-7092821 . \r\nFiling this jira for discussions.\r\n\r\nJDK version used was 1.8.0_144.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12917444","id":"12917444","filename":"1.jstack","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-03T21:36:15.054+0000","size":83765,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12917444/1.jstack"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12917445","id":"12917445","filename":"2.jstack","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-03T21:36:14.972+0000","size":83765,"mimeType":"application/octet-stream","content":"https://issues.apache.org/jira/secure/attachment/12917445/2.jstack"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"IPC client hang in kerberized cluster due to JDK deadlock","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16424643","id":"16424643","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Attached 2 sample jstacks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-03T21:36:27.775+0000","updated":"2018-04-03T21:36:27.775+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16424683","id":"16424683","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"JDK-7092821 mentioned it a scalability bottleneck rather than a deadlock. Not sure how JDK detetermines a deadlock though.\r\n HADOOP-13836 (Securing Hadoop RPC using SSL) should help with this in the long run, since it would not depend on JDK SASL eventually. And it improves RPC performance as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-03T22:11:37.818+0000","updated":"2018-04-03T22:11:37.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16424727","id":"16424727","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. JDK-7092821\r\nYes, I wasn't accurate, updated the description. That jira is the closest I can find. But if that's taken care of, (i.e. either the synchronized method isn't called any more, or the lock removed), then there is no deadlock in this case anyways.\r\n\r\nOne of its linked jiras also mentioned \" In order to alleviate this problem applications should cache the result of the Cipher.getInstance() call per thread and reinitialise (Cipher.init(...)) the cached copy instead of calling Cipher.getInstance() again. \" but the caller here would be krb5...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-03T23:11:43.014+0000","updated":"2018-04-03T23:11:43.014+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16530456","id":"16530456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm pretty sure I'm seeing the same bug, but this time it's more complex than what you reported, [~xiaochen]\r\n\r\nI saw an Impalad (a HDFS client) blocked on talking to NameNodes, and there are several threads involved. Posting them here so others may find it some day.\r\n\r\nThis cluster is on CDH5.15, Kerberized, Hadoop at-rest encryption, Hadoop RPC encryption, Hadoop data transport encryption. Somehow, all threads were in blocked state, and here are the most relevant threads:\r\n\r\nIt started with this thread:\r\n{noformat}\r\nThread 15180: (state = BLOCKED)\r\n - java.util.Hashtable.get(java.lang.Object) @bci=0, line=362 (Compiled frame)\r\n - java.util.Properties.getProperty(java.lang.String) @bci=2, line=969 (Compiled frame)\r\n - java.security.Provider.getProperty(java.lang.String) @bci=6, line=645 (Compiled frame)\r\n - java.security.Security.getProviderProperty(java.lang.String, java.security.Provider) @bci=2, line=264 (Compiled frame)\r\n - java.security.Security.isCriterionSatisfied(java.security.Provider, java.lang.String, java.lang.String, java.lang.String, java.lang.String) @bci=58, line=930 (Compiled frame)\r\n - java.security.Security.getProvidersNotUsingCache(java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.security.Provider[]) @bci=30, line=905 (Compiled frame)\r\n - java.security.Security.getAllQualifyingCandidates(java.lang.String, java.lang.String, java.security.Provider[]) @bci=29, line=893 (Compiled frame)\r\n - java.security.Security.getProviders(java.util.Map) @bci=81, line=623 (Compiled frame)\r\n - java.security.Security.getProviders(java.lang.String) @bci=59, line=547 (Compiled frame)\r\n - javax.security.sasl.Sasl.createSaslClient(java.lang.String[], java.lang.String, java.lang.String, java.lang.String, java.util.Map, javax.security.auth.callback.CallbackHandler) @bci=68, line=374 (Compiled frame)\r\n - org.apache.hadoop.hbase.security.HBaseSaslRpcClient.createKerberosSaslClient(java.lang.String[], java.lang.String, java.lang.String) @bci=9, line=148 (Compiled frame)\r\n - org.apache.hadoop.hbase.security.HBaseSaslRpcClient.<init>(org.apache.hadoop.hbase.security.AuthMethod, org.apache.hadoop.security.token.Token, java.lang.String, boolean, java.lang.String) @bci=277, line=128 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupSaslConnection(java.io.InputStream, java.io.OutputStream) @bci=48, line=615 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.access$700(org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection, java.io.InputStream, java.io.OutputStream) @bci=3, line=163 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection$2.run() @bci=12, line=744 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection$2.run() @bci=1, line=741 (Compiled frame)\r\n - java.security.AccessController.doPrivileged(java.security.PrivilegedExceptionAction, java.security.AccessControlContext) @bci=0 (Compiled frame)\r\n - javax.security.auth.Subject.doAs(javax.security.auth.Subject, java.security.PrivilegedExceptionAction) @bci=42, line=422 (Compiled frame)\r\n - org.apache.hadoop.security.UserGroupInformation.doAs(java.security.PrivilegedExceptionAction) @bci=14, line=1920 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams() @bci=305, line=741 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(org.apache.hadoop.hbase.ipc.Call, int, org.apache.htrace.Span) @bci=152, line=907 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(org.apache.hadoop.hbase.ipc.Call, int, org.apache.htrace.Span) @bci=10, line=874 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.RpcClientImpl.call(org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController, com.google.protobuf.Descriptors$MethodDescriptor, com.google.protobuf.Message, com.google.protobuf.Message, org.apache.hadoop.hbase.security.User, java.net.InetSocketAddress, org.apache.hadoop.hbase.client.MetricsConnection$CallStats) @bci=146, line=1246 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(com.google.protobuf.Descriptors$MethodDescriptor, org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController, com.google.protobuf.Message, com.google.protobuf.Message, org.apache.hadoop.hbase.security.User, java.net.InetSocketAddress) @bci=37, line=227 (Compiled frame)\r\n - org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(com.google.protobuf.Descriptors$MethodDescriptor, com.google.protobuf.RpcController, com.google.protobuf.Message, com.google.protobuf.Message) @bci=73, line=336 (Compiled frame)\r\n - org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ScanRequest) @bci=24, line=34094 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.ScannerCallable.openScanner() @bci=30, line=400 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.ScannerCallable.call(int) @bci=52, line=204 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.ScannerCallable.call(int) @bci=2, line=65 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(org.apache.hadoop.hbase.client.RetryingCallable, int) @bci=16, line=210 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(int) @bci=18, line=397 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(int) @bci=2, line=371 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(org.apache.hadoop.hbase.client.RetryingCallable, int) @bci=64, line=136 (Compiled frame)\r\n - org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run() @bci=20, line=80 (Compiled frame)\r\n - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1142 (Compiled frame)\r\n - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=617 (Compiled frame)\r\n - java.lang.Thread.run() @bci=11, line=745 (Compiled frame)\r\n{noformat}\r\n\r\nit blocked the following thread:\r\n\r\n{noformat}\r\nThread 24817: (state = BLOCKED)\r\n - java.security.Provider.getService(java.lang.String, java.lang.String) @bci=0, line=1035 (Compiled frame)\r\n - sun.security.jca.ProviderList$ServiceList.tryGet(int) @bci=159, line=444 (Compiled frame)\r\n - sun.security.jca.ProviderList$ServiceList.access$200(sun.security.jca.ProviderList$ServiceList, int) @bci=2, line=376 (Compiled frame)\r\n - sun.security.jca.ProviderList$ServiceList$1.hasNext() @bci=8, line=486 (Compiled frame)\r\n - javax.crypto.Cipher.getInstance(java.lang.String) @bci=88, line=513 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.AesDkCrypto.getCipher(byte[], byte[], int) @bci=22, line=148 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.DkCrypto.dr(byte[], byte[]) @bci=4, line=484 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.DkCrypto.dk(byte[], byte[]) @bci=4, line=447 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.AesDkCrypto.decryptCTS(byte[], int, byte[], byte[], int, int, boolean) @bci=70, line=394 (Compiled frame)\r\n - sun.security.jgss.krb5.WrapToken_v2.getData(byte[], int) @bci=57, line=141 (Compiled frame)\r\n - sun.security.jgss.krb5.WrapToken_v2.getData() @bci=10, line=105 (Compiled frame)\r\n - sun.security.jgss.krb5.Krb5Context.unwrap(byte[], int, int, org.ietf.jgss.MessageProp) @bci=136, line=1058 (Compiled frame)\r\n - sun.security.jgss.GSSContextImpl.unwrap(byte[], int, int, org.ietf.jgss.MessageProp) @bci=16, line=403 (Compiled frame)\r\n - com.sun.security.sasl.gsskerb.GssKrb5Base.unwrap(byte[], int, int) @bci=57, line=77 (Compiled frame)\r\n - org.apache.hadoop.security.SaslRpcClient$WrappedInputStream.readNextRpcPacket() @bci=166, line=617 (Compiled frame)\r\n - org.apache.hadoop.security.SaslRpcClient$WrappedInputStream.read(byte[], int, int) @bci=25, line=583 (Compiled frame)\r\n - java.io.FilterInputStream.read(byte[], int, int) @bci=7, line=133 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(byte[], int, int) @bci=7, line=553 (Compiled frame)\r\n - java.io.BufferedInputStream.fill() @bci=214, line=246 (Compiled frame)\r\n - java.io.BufferedInputStream.read() @bci=12, line=265 (Compiled frame)\r\n - java.io.DataInputStream.readInt() @bci=4, line=387 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse() @bci=19, line=1113 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client$Connection.run() @bci=62, line=1006 (Compiled frame)\r\n{noformat}\r\n\r\nand which blocked this thread, because socket writer must wait for reader (the above thread), according to [JDK-4509080\r\n(ch) Streams inhibit concurrent reading & writing|https://bugs.openjdk.java.net/browse/JDK-4509080]:\r\n\r\n{noformat}\r\nThread 32333: (state = BLOCKED)\r\n - java.security.Provider.getService(java.lang.String, java.lang.String) @bci=0, line=1035 (Compiled frame)\r\n - sun.security.jca.ProviderList$ServiceList.tryGet(int) @bci=159, line=444 (Compiled frame)\r\n - sun.security.jca.ProviderList$ServiceList.access$200(sun.security.jca.ProviderList$ServiceList, int) @bci=2, line=376 (Compiled frame)\r\n - sun.security.jca.ProviderList$ServiceList$1.hasNext() @bci=8, line=486 (Compiled frame)\r\n - javax.crypto.Cipher.getInstance(java.lang.String) @bci=88, line=513 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.AesDkCrypto.getCipher(byte[], byte[], int) @bci=22, line=148 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.DkCrypto.dr(byte[], byte[]) @bci=4, line=484 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.DkCrypto.dk(byte[], byte[]) @bci=4, line=447 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.AesDkCrypto.encryptCTS(byte[], int, byte[], byte[], byte[], int, int, boolean) @bci=70, line=324 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.dk.AesDkCrypto.encryptRaw(byte[], int, byte[], byte[], int, int) @bci=46, line=256 (Compiled frame)\r\n - sun.security.krb5.internal.crypto.Aes256.encryptRaw(byte[], int, byte[], byte[], int, int) @bci=11, line=70 (Compiled frame)\r\n - sun.security.jgss.krb5.CipherHelper.aes256Encrypt(byte[], byte[], byte[], int, int, int) @bci=63, line=1377 (Compiled frame)\r\n - sun.security.jgss.krb5.CipherHelper.encryptData(sun.security.jgss.krb5.WrapToken_v2, byte[], byte[], byte[], int, int, int) @bci=58, line=723 (Compiled frame)\r\n - sun.security.jgss.krb5.WrapToken_v2.<init>(sun.security.jgss.krb5.Krb5Context, org.ietf.jgss.MessageProp, byte[], int, int) @bci=131, line=200 (Compiled frame)\r\n - sun.security.jgss.krb5.Krb5Context.wrap(byte[], int, int, org.ietf.jgss.MessageProp) @bci=121, line=926 (Compiled frame)\r\n - sun.security.jgss.GSSContextImpl.wrap(byte[], int, int, org.ietf.jgss.MessageProp) @bci=16, line=385 (Compiled frame)\r\n - com.sun.security.sasl.gsskerb.GssKrb5Base.wrap(byte[], int, int) @bci=57, line=103 (Compiled frame)\r\n - org.apache.hadoop.security.SaslRpcClient$WrappedOutputStream.write(byte[], int, int) @bci=48, line=636 (Compiled frame)\r\n - java.io.BufferedOutputStream.flushBuffer() @bci=20, line=82 (Compiled frame)\r\n - java.io.BufferedOutputStream.flush() @bci=1, line=140 (Compiled frame)\r\n - java.io.DataOutputStream.flush() @bci=4, line=123 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client$Connection$3.run() @bci=149, line=1072 (Compiled frame)\r\n - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4, line=511 (Compiled frame)\r\n - java.util.concurrent.FutureTask.run() @bci=42, line=266 (Compiled frame)\r\n - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1142 (Compiled frame)\r\n - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=617 (Compiled frame)\r\n - java.lang.Thread.run() @bci=11, line=745 (Compiled frame)\r\n{noformat}\r\n\r\n{noformat}\r\nThread 17213: (state = BLOCKED)\r\n - sun.misc.Unsafe.park(boolean, long) @bci=0 (Compiled frame; information may be imprecise)\r\n - java.util.concurrent.locks.LockSupport.park(java.lang.Object) @bci=14, line=175 (Compiled frame)\r\n - java.util.concurrent.FutureTask.awaitDone(boolean, long) @bci=165, line=429 (Compiled frame)\r\n - java.util.concurrent.FutureTask.get() @bci=13, line=191 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(org.apache.hadoop.ipc.Client$Call) @bci=94, line=1088 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client.call(org.apache.hadoop.ipc.RPC$RpcKind, org.apache.hadoop.io.Writable, org.apache.hadoop.ipc.Client$ConnectionId, int, java.util.concurrent.atomic.AtomicBoolean) @bci=25, line=1483 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client.call(org.apache.hadoop.ipc.RPC$RpcKind, org.apache.hadoop.io.Writable, org.apache.hadoop.ipc.Client$ConnectionId, java.util.concurrent.atomic.AtomicBoolean) @bci=7, line=1441 (Compiled frame)\r\n - org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[]) @bci=260, line=230 (Compiled frame)\r\n - com.sun.proxy.$Proxy10.getBlockLocations(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto) @bci=20 (Compiled frame)\r\n - org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(java.lang.String, long, long) @bci=28, line=268 (Compiled frame)\r\n - sun.reflect.GeneratedMethodAccessor8.invoke(java.lang.Object, java.lang.Object[]) @bci=246 (Compiled frame)\r\n - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object, java.lang.Object[]) @bci=6, line=43 (Compiled frame)\r\n - java.lang.reflect.Method.invoke(java.lang.Object, java.lang.Object[]) @bci=56, line=498 (Compiled frame)\r\n - org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(java.lang.reflect.Method, java.lang.Object[]) @bci=21, line=258 (Compiled frame)\r\n - org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[]) @bci=105, line=104 (Compiled frame)\r\n - com.sun.proxy.$Proxy11.getBlockLocations(java.lang.String, long, long) @bci=31 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(org.apache.hadoop.hdfs.protocol.ClientProtocol, java.lang.String, long, long) @bci=5, line=1324 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(java.lang.String, long, long) @bci=18, line=1311 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(java.lang.String, long) @bci=10, line=1299 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength() @bci=9, line=315 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSInputStream.openInfo() @bci=9, line=280 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSInputStream.<init>(org.apache.hadoop.hdfs.DFSClient, java.lang.String, boolean) @bci=147, line=267 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.open(java.lang.String, int, boolean) @bci=21, line=1630 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(org.apache.hadoop.fs.Path) @bci=26, line=339 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(org.apache.hadoop.fs.Path) @bci=2, line=335 (Compiled frame)\r\n - org.apache.hadoop.fs.FileSystemLinkResolver.resolve(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path) @bci=22, line=81 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DistributedFileSystem.open(org.apache.hadoop.fs.Path, int) @bci=35, line=335 (Compiled frame)\r\n\r\n{noformat}\r\nand which blocked this thread:\r\n\r\n{noformat}\r\nThread 17212: (state = BLOCKED)\r\n - org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(org.apache.hadoop.ipc.Client$Call) @bci=67, line=1053 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client.call(org.apache.hadoop.ipc.RPC$RpcKind, org.apache.hadoop.io.Writable, org.apache.hadoop.ipc.Client$ConnectionId, int, java.util.concurrent.atomic.AtomicBoolean) @bci=25, line=1483 (Compiled frame)\r\n - org.apache.hadoop.ipc.Client.call(org.apache.hadoop.ipc.RPC$RpcKind, org.apache.hadoop.io.Writable, org.apache.hadoop.ipc.Client$ConnectionId, java.util.concurrent.atomic.AtomicBoolean) @bci=7, line=1441 (Compiled frame)\r\n - org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[]) @bci=260, line=230 (Compiled frame)\r\n - com.sun.proxy.$Proxy10.getBlockLocations(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto) @bci=20 (Compiled frame)\r\n - org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(java.lang.String, long, long) @bci=28, line=268 (Compiled frame)\r\n - sun.reflect.GeneratedMethodAccessor8.invoke(java.lang.Object, java.lang.Object[]) @bci=246 (Compiled frame)\r\n - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object, java.lang.Object[]) @bci=6, line=43 (Compiled frame)\r\n - java.lang.reflect.Method.invoke(java.lang.Object, java.lang.Object[]) @bci=56, line=498 (Compiled frame)\r\n - org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(java.lang.reflect.Method, java.lang.Object[]) @bci=21, line=258 (Compiled frame)\r\n - org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[]) @bci=105, line=104 (Compiled frame)\r\n - com.sun.proxy.$Proxy11.getBlockLocations(java.lang.String, long, long) @bci=31 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(org.apache.hadoop.hdfs.protocol.ClientProtocol, java.lang.String, long, long) @bci=5, line=1324 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(java.lang.String, long, long) @bci=18, line=1311 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(java.lang.String, long) @bci=10, line=1299 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength() @bci=9, line=315 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSInputStream.openInfo() @bci=9, line=280 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSInputStream.<init>(org.apache.hadoop.hdfs.DFSClient, java.lang.String, boolean) @bci=147, line=267 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DFSClient.open(java.lang.String, int, boolean) @bci=21, line=1630 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(org.apache.hadoop.fs.Path) @bci=26, line=339 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(org.apache.hadoop.fs.Path) @bci=2, line=335 (Compiled frame)\r\n - org.apache.hadoop.fs.FileSystemLinkResolver.resolve(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path) @bci=22, line=81 (Compiled frame)\r\n - org.apache.hadoop.hdfs.DistributedFileSystem.open(org.apache.hadoop.fs.Path, int) @bci=35, line=335 (Compiled frame)\r\n\r\n{noformat}\r\n\r\nIncidentally, I suspect this is related to HADOOP-15530 and HADOOP-15538.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-02T21:22:39.803+0000","updated":"2018-07-02T21:22:39.803+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16531458","id":"16531458","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Just curious. Where was the main thread at? Was it tearing down by any chance?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2018-07-03T14:05:46.994+0000","updated":"2018-07-03T14:05:46.994+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16531719","id":"16531719","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~kihwal] thanks for chiming in.\r\nImpalad is a C++ application that invokes Hadoop java libraries, so I don't see a Java main entrance.\r\n\r\nWe saw similar symptoms multiple times on a particular cluster, but sometimes the specific symptoms change from time to time (e.g. sometimes jstack detected deadlocks, but sometimes it didn't).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-03T17:28:28.946+0000","updated":"2018-07-03T17:28:28.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16531858","id":"16531858","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"bq.Incidentally, I suspect this is related to HADOOP-15530 and HADOOP-15538.\r\n\r\nLooks three are related. cc to [~yzhangal]\r\n\r\nAny chances of *CPU overloaded* *{color:#d04437}Or {color}OOM {color:#d04437}Or{color}* JVM busy with *garbage collection* *{color:#d04437}O{color}{color:#d04437}*r* {color}Remote debugging is enabled*( i.e -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=XXXXXXX).?.\r\n\r\n \r\n\r\nif it's reproducible, can we use \"jstack -m\" to take threaddump.?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2018-07-03T19:40:00.696+0000","updated":"2018-07-03T19:40:00.696+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16533936","id":"16533936","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~kihwal] actually, now I retrieved Xiao's jstack, there was actually a main thread, and the main thread didn't have a stack.\r\n\r\nSeems it was in some weird state\r\n\r\n\"main\" #1 prio=5 os_prio=0 tid=0x0000000004e22800 nid=0x1e9d runnable [0x0000000000000000]\r\n java.lang.Thread.State: RUNNABLE\r\n\r\n \r\n\r\nWhat's interesting is that, because the impalad is not a Java program, but a C++ program, typically you don't see a main thread in jstack. However, it seems when impalad crashes or something, the main thread appears in jstack.\r\n\r\n \r\n\r\nIn addition to main thread, I see also other threads with no stack. Like this one:\r\n{quote}\"Thread-478\" #8214 prio=5 os_prio=0 tid=0x00007f69a96b9000 nid=0xcfe0 runnable [0x0000000000000000]\r\n java.lang.Thread.State: RUNNABLE\r\n{quote}\r\nThe null address at the end looks suspicious to me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-05T17:34:11.607+0000","updated":"2018-07-05T17:59:54.251+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13149832/comment/16533948","id":"16533948","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~brahmareddy] thanks a lot for your thoughts.\r\n\r\nInitially, it appeared to be a moving target for me where each time the symptom appears the same (process hung) but the details were different, and not until a few days ago was I able to categorize them into two main different bugs.\r\n\r\nI do start to suspect OOM or GC crashed the process. We hit the similar issues a few times on a few clusters, but we don't collect the mixed mode jstack (the jstack -m option) every time.\r\n\r\nThat said, in the few occurrence where we were able to collect mixed mode jstack, I noticed the thread stack were \"boring\", whereas a \"live\" impalad mixed mode jstack is more \"interesting\" that there are clearly some activities going on.\r\n\r\nI'll try to grab one to compare.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-05T17:40:53.374+0000","updated":"2018-07-05T17:40:53.374+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15359/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3s3tz:"}}