{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12412519","self":"https://issues.apache.org/jira/rest/api/2/issue/12412519","key":"HADOOP-5059","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2009-01-15T21:22:16.988+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Jul 21 18:08:30 UTC 2014","customfield_12310420":"126903","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_173917946096_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-07-21T18:08:30.627+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-5059/watchers","watchCount":28,"isWatching":false},"created":"2009-01-15T19:36:04.561+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12327286","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12327286","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12411981","key":"HADOOP-4998","self":"https://issues.apache.org/jira/rest/api/2/issue/12411981","fields":{"summary":"Implement a native OS runtime for Hadoop","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-07-21T18:08:30.654+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310740","id":"12310740","name":"util","description":""}],"timeoriginalestimate":null,"description":"We've seen primary/secondary namenodes fail when calling whoami or topologyscripts.\n(Discussed as part of HADOOP-4998)\n\nSample stack traces.\n\nPrimary Namenode\n{noformat}\n2009-01-12 03:57:27,381 WARN org.apache.hadoop.net.ScriptBasedMapping: java.io.IOException: Cannot run program\n\"/path/topologyProgram\" (in directory \"/path\"):\njava.io.IOException: error=12, Cannot allocate memory\n        at java.lang.ProcessBuilder.start(ProcessBuilder.java:459)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:149)\n        at org.apache.hadoop.util.Shell.run(Shell.java:134)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)\n        at org.apache.hadoop.net.ScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:122)\n        at org.apache.hadoop.net.ScriptBasedMapping.resolve(ScriptBasedMapping.java:73)\n        at org.apache.hadoop.dfs.FSNamesystem$ResolutionMonitor.run(FSNamesystem.java:1869)\n        at java.lang.Thread.run(Thread.java:619)\nCaused by: java.io.IOException: java.io.IOException: error=12, Cannot allocate memory\n        at java.lang.UNIXProcess.<init>(UNIXProcess.java:148)\n        at java.lang.ProcessImpl.start(ProcessImpl.java:65)\n        at java.lang.ProcessBuilder.start(ProcessBuilder.java:452)\n        ... 7 more\n\n2009-01-12 03:57:27,381 ERROR org.apache.hadoop.fs.FSNamesystem: The resolve call returned null! Using /default-rack\nfor some hosts\n2009-01-12 03:57:27,381 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/55.5.55.55:50010\n\n{noformat}\n\nSecondary Namenode\n{noformat}\n\n2008-10-09 02:00:58,288 ERROR org.apache.hadoop.dfs.NameNode.Secondary: java.io.IOException:\njavax.security.auth.login.LoginException: Login failed: Cannot run program \"whoami\": java.io.IOException:\nerror=12, Cannot allocate memory\n        at org.apache.hadoop.security.UnixUserGroupInformation.login(UnixUserGroupInformation.java:250)\n        at org.apache.hadoop.security.UnixUserGroupInformation.login(UnixUserGroupInformation.java:275)\n        at org.apache.hadoop.security.UnixUserGroupInformation.login(UnixUserGroupInformation.java:257)\n        at org.apache.hadoop.dfs.FSNamesystem.setConfigurationParameters(FSNamesystem.java:370)\n        at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:359)\n        at org.apache.hadoop.dfs.SecondaryNameNode.doMerge(SecondaryNameNode.java:340)\n        at org.apache.hadoop.dfs.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:312)\n        at org.apache.hadoop.dfs.SecondaryNameNode.run(SecondaryNameNode.java:223)\n        at java.lang.Thread.run(Thread.java:619)\n\n        at org.apache.hadoop.dfs.FSNamesystem.setConfigurationParameters(FSNamesystem.java:372)\n        at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:359)\n        at org.apache.hadoop.dfs.SecondaryNameNode.doMerge(SecondaryNameNode.java:340)\n        at org.apache.hadoop.dfs.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:312)\n        at org.apache.hadoop.dfs.SecondaryNameNode.run(SecondaryNameNode.java:223)\n        at java.lang.Thread.run(Thread.java:619)\n\n{noformat}\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12398000","id":"12398000","filename":"TestSysCall.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2009-01-15T19:50:59.499+0000","size":1323,"mimeType":"text/x-java","content":"https://issues.apache.org/jira/secure/attachment/12398000/TestSysCall.java"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"74434","customfield_12312823":null,"summary":"'whoami', 'topologyscript' calls failing with java.io.IOException: error=12, Cannot allocate memory","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"On nodes with \nphysical memory 32G\nSwap 16G \n\nPrimary/Secondary Namenode using 25G of heap or more","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664228","id":"12664228","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"It's \"java.io.IOException: error=12, Cannot allocate memory\" but not OutOfMemoryException. Changing subject.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2009-01-15T19:37:23.550+0000","updated":"2009-01-15T19:37:23.550+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664232","id":"12664232","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"Wrote a simple test.\nOn node with physical memory of 32G and swap of 16G (we didn't bother to increase the swap when we added a memory), \n\ntop - 19:46:19 up 109 days,  5:02,  1 user,  load average: 0.37, 0.16, 0.09\nTasks: 188 total,   1 running, 187 sleeping,   0 stopped,   0 zombie\nCpu(s):  0.3% us,  0.1% sy,  0.2% ni, 99.3% id,  0.1% wa,  0.0% hi,  0.0% si\nMem:  32895200k total,  5766028k used, 27129172k free,   809300k buffers\nSwap: 16386160k total,    93612k used, 16292548k free,  4352600k cached\n\nbash-3.00$ cat /proc/sys/vm/overcommit_memory\n0\nbash-3.00$ /grid/0/java/jdk1.6.0_06_x64/bin/java -Xmx28000m -XX:NewSize=1G -XX:MaxNewSize=1G TestSysCall 260000000 100\nAllocating 26000000000Bytes\nAllocating done successfully\nCalling ls ===================\nException in thread \"main\" java.io.IOException: Cannot run program \"ls\": java.io.IOException: error=12, Cannot allocate memory\n        at java.lang.ProcessBuilder.start(ProcessBuilder.java:459)\n        at TestSysCall.main(TestSysCall.java:21)\nCaused by: java.io.IOException: java.io.IOException: error=12, Cannot allocate memory\n        at java.lang.UNIXProcess.<init>(UNIXProcess.java:148)\n        at java.lang.ProcessImpl.start(ProcessImpl.java:65)\n        at java.lang.ProcessBuilder.start(ProcessBuilder.java:452)\n        ... 1 more\n(root)\n# echo 1 > /proc/sys/vm/overcommit_memory\nexit\n\nbash-3.00$ cat /proc/sys/vm/overcommit_memory\n1\nbash-3.00$ /grid/0/java/jdk1.6.0_06_x64/bin/java -Xmx28000m -XX:NewSize=1G -XX:MaxNewSize=1G TestSysCall 260000000 100\nAllocating 26000000000Bytes\nAllocating done successfully\nCalling ls ===================\nTestSysCall.class\nTestSysCall.java\nhsperfdata_knoguchi\nreip_local\nls done ===================\nls has taken 2156 milliseconds\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2009-01-15T19:50:59.583+0000","updated":"2009-01-15T19:50:59.583+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664234","id":"12664234","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"Checking with strace, it was failing on \n{noformat}\nclone(child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x4133c9f0) = -1\nENOMEM (Cannot allocate memory)\n...\nwrite(2, \"Caused by: java.io.IOException: java.io.IOException: error=12, Cannot allocate memory\",\n85Caused by: java.io.IOException: java.io.IOException: error=12, Cannot allocate memory) = 85\n\n{noformat}\n\nThis clone call didn't have CLONE_VM flag.\nFrom clone manpage, \n  \"If  CLONE_VM  is not set, the child process runs in a separate copy of the memory space of the calling process\nat the time of clone.  Memory writes or file mappings/unmappings performed by one of the processes do not affect the \nother,  as with fork(2). \"\n\nSo it's probably using fork() and not vfork().\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2009-01-15T19:55:34.576+0000","updated":"2009-01-15T19:55:34.576+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664268","id":"12664268","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Based on the descriptions here:\n\nhttp://lists.uclibc.org/pipermail/busybox/2005-December/017513.html\n\nand here:\n\nhttp://www.unixguide.net/unix/programming/1.1.2.shtml\n\nIt seems like Java is correct to use fork()+exec(), not vfork()+exec().  But that with really big processes, if your swap space isn't huge and you don't have overcommit_memory=1, you'll inevitably see these problems when you fork.  The standard workaround seems to be to keep a subprocess around and re-use it, which has its own set of problems.\n\nIf you have either lots of swap space configured or have overcommit_memory=1overcommit_memory=1 then I don't think there's any performance penalty to using fork().  The new process has a huge address space that's nearly entirely shared with its parent for a short time, then it quickly shrinks down once the command is exec'd to something tiny, so it's harmless.  So these solutions (increased swap or overcommit_memory=1) seem reasonable to me.\n\nAt root this seems like a bug in Linux, that you cannot spawn a new subprocess without temporarily using as much address space as the parent process, but it does not seem like a bug that's likely to be fixed soon.\n\nDoes this analysis sound right to others?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-15T21:22:16.988+0000","updated":"2009-01-15T21:22:16.988+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664275","id":"12664275","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Based on:\n\nhttp://www.win.tue.nl/~aeb/linux/lk/lk-9.html\n\nIt sounds like maybe the safer thing to do is to increase swap to equal RAM and set overcommit_memory=2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-15T21:33:24.819+0000","updated":"2009-01-15T21:33:24.819+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664321","id":"12664321","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"That assumes you have an OS that supports overcommit.  Most don't, and rightfully so, as it causes memory management from an operations perspective to be wildly unpredictable.  Thus our issues.\n\nHadoop needs to do two things:\n\na) Move the topology program to be run as a completely separate daemon and open a socket to talk to it over the loopback interface.  This trick has been used by squid (unlinkd) and many other applications quite effectively to offload all of the forking.  \n\nb) Stop forking for things it should be doing via a native method rather than putting reliances upon external applications being in certain locations or, worse, using a completely untrusted path.  The output of programs are not guaranteed to be stable, even in POSIX-land.\n\nAs a sidenote to a, Owen has mentioned moving the topology program to be a Java loadable class.  AFAIK, this won't work in the real world, as it means that in order to change the topology on the fly, we have to restart the namenode.  Or worse, you'll need to get your admin team to learn Java. ;)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-15T23:34:26.896+0000","updated":"2009-01-15T23:34:26.896+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664336","id":"12664336","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"bq. or have overcommit_memory=1 then I don't think there's any performance penalty to using fork(). \n\nHaving a larger heap before fork()/exec() does slow down the calls.\n\n||Heap being used. || Time for a single 'ls' call ||\n|260000000    |  40 milliseconds   |\n|2600000000   |  360 milliseconds  |\n|5200000000   |  569 milliseconds  |\n|7800000000   |  758 milliseconds  |\n|10400000000  |  994 milliseconds  |\n|13000000000  |  1186 milliseconds |\n|15600000000  |  1417 milliseconds |\n|18200000000  |  1564 milliseconds |\n|20800000000  |  1792 milliseconds |\n|23400000000  |  1910 milliseconds |\n|26000000000  |  2094 milliseconds |","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2009-01-16T00:06:40.436+0000","updated":"2009-01-16T00:06:40.436+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664604","id":"12664604","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Allen> Stop forking for things it should be doing via a native method [ ... ]\n\nIf we wish to do this uniformly, we might adopt APR (http://apr.apache.org/) and Tomcat's libtcnative (JNI bindings for APR).\n\nAllen> in order to change the topology on the fly, we have to restart the namenode\n\nCouldn't we add an admin command that reloads the topology on demand?\n\nKoji> Having a larger heap before fork()/exec() does slow down the calls.\n\nI guess that's the cost of copying the page table.  Sigh.  So we should probably move to a model where we either:\n - 1. talk to a daemon\n - 2. cache the output of shell commands for long periods (i.e., topology, groups, etc.)\n - 3. implement these with native code.\n\n1 is fragile, since we have another daemon to manage.\n3 means we don't run well out of the box on non-linux (e.g., MacOS, Solaris, & Windows)\n2 may or may not be acceptable.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-16T18:38:50.440+0000","updated":"2009-01-16T18:38:50.440+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664625","id":"12664625","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Can we have a mixture of the three? We first try to load the jni lib. If we fail, then try to contact the daemon. If the daemon is not available, then we launch the process. Of course, if we succeed in loading the JNI lib, we are fine. However, for the external daemon case, we need to take care of a case where the daemon may go down anytime... If and when that happens we switch to the process launch model (if we couldn't load the jni earlier on startup).. Thoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2009-01-16T19:07:00.921+0000","updated":"2009-01-16T19:07:00.921+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664629","id":"12664629","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> Can we have a mixture of the three? \n\nYikes!  The same feature implemented three different ways?  Two is bad enough, since, when they don't operate identically, confusion can ensue.  Three is worse.  One option might be to always use a Java daemon, but have the daemon either run shell scripts or native code.  The daemon's heap would stay small, so forks would stay cheap and it we'd have a scalable portable solution, but for higher performance and/or security the native code could be used.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-16T19:17:37.389+0000","updated":"2009-01-16T19:17:37.389+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664734","id":"12664734","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":">... [from above links] It seems like Java is correct to use fork()+exec(), not vfork()+exec().  [...]\n\njust curious, why is it a bad idea for  Java to use vfork()? The code on child process from return of vfork() till excecv() it is still in JVM's control.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-16T23:24:40.227+0000","updated":"2009-01-16T23:24:40.227+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12664746","id":"12664746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> why is it a bad idea for Java to use vfork()?\n\nvfork() is very fragile, since, until a call to exec is made, the new process runs in the same memory as its parent, including the stack, etc.  The parent process is also suspended until exec() is called, but, still, the child can easily wreak havoc.\n\nhttps://www.securecoding.cert.org/confluence/display/seccode/POS33-C.+Do+not+use+vfork()\n\nThat said, it seems like folks do still use vfork() to get around this problem, e.g.:\n\nhttp://bugs.sun.com/view_bug.do?bug_id=5049299\nhttp://sources.redhat.com/ml/glibc-bugs/2004-09/msg00045.html\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-17T00:16:10.259+0000","updated":"2009-01-17T00:16:10.259+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12665101","id":"12665101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=steve_l","name":"steve_l","key":"steve_l","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Steve Loughran","active":true,"timeZone":"Etc/UTC"},"body":"A daemon would work, given that Hadoop RPC could be used as the protocol for talking to it, the alternative being (usually) something serialized over stdin and stdout. There are some serious security risks associated with having an OS-services daemon listening on a network port. By decoupling it you would even be able to deal with memory leak issues in any embedded libraries, just restart the daemon every few hours. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=steve_l","name":"steve_l","key":"steve_l","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Steve Loughran","active":true,"timeZone":"Etc/UTC"},"created":"2009-01-19T11:23:27.969+0000","updated":"2009-01-19T11:23:27.969+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/12988715","id":"12988715","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jukkaz","name":"jukkaz","key":"jukkaz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jukkaz&avatarId=15130","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jukkaz&avatarId=15130","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jukkaz&avatarId=15130","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jukkaz&avatarId=15130"},"displayName":"Jukka Zitting","active":true,"timeZone":"America/New_York"},"body":"See http://developers.sun.com/solaris/articles/subprocess/subprocess.html for relevant documentation. I'm working on a similar problem in TIKA-591and JCR-2864. Perhaps we could pool efforts for solving this in somewhere like Commons Exec?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jukkaz","name":"jukkaz","key":"jukkaz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jukkaz&avatarId=15130","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jukkaz&avatarId=15130","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jukkaz&avatarId=15130","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jukkaz&avatarId=15130"},"displayName":"Jukka Zitting","active":true,"timeZone":"America/New_York"},"created":"2011-01-31T10:03:56.408+0000","updated":"2011-01-31T10:03:56.408+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12412519/comment/14068941","id":"14068941","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"I'm going to close this as fixed.\n\nA bunch of things have happened:\n\na) On certain platforms, java now uses posix_spawn() instead of fork().\n\nb) Topology can now be provided by a class.\n\nc) The whoami call has been removed.\n\nSo there are definitely ways to mitigate/eliminate this issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-21T18:08:30.650+0000","updated":"2014-07-21T18:08:30.650+0000"}],"maxResults":15,"total":15,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-5059/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0d427:"}}