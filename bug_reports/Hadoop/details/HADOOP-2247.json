{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12383013","self":"https://issues.apache.org/jira/rest/api/2/issue/12383013","key":"HADOOP-2247","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312740","id":"12312740","description":"","name":"0.16.0","archived":false,"released":true,"releaseDate":"2008-02-07"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2007-11-21T22:29:11.446+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Dec 21 20:27:54 UTC 2007","customfield_12310420":"81112","customfield_12312320":null,"customfield_12310222":"10002_*:*_3_*:*_572933826_*|*_1_*:*_3_*:*_2010444966_*|*_6_*:*_1_*:*_0_*|*_5_*:*_2_*:*_4248907044_*|*_4_*:*_1_*:*_1485324","customfield_12312321":null,"resolutiondate":"2007-12-21T20:27:54.700+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2247/watchers","watchCount":1,"isWatching":false},"created":"2007-11-21T21:21:55.520+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312565","id":"12312565","description":"","name":"0.15.0","archived":false,"released":true,"releaseDate":"2007-10-19"}],"issuelinks":[{"id":"12318558","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12318558","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"outwardIssue":{"id":"12382701","key":"HADOOP-2220","self":"https://issues.apache.org/jira/rest/api/2/issue/12382701","fields":{"summary":"Reduce tasks fail too easily because of repeated fetch failures","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12318478","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12318478","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12382701","key":"HADOOP-2220","self":"https://issues.apache.org/jira/rest/api/2/issue/12382701","fields":{"summary":"Reduce tasks fail too easily because of repeated fetch failures","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2008-02-08T23:38:06.669+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Related to HADOOP-2220, problem introduced in HADOOP-1158\n\nAt this scale hardcoding the number of fetch failures to a static number: in this case 3 is never going to work. Although the jobs we are running are loading the systems 3 failures can randomly occur within the lifetime of a map. Even fetching the data can cause enough load for so many failures to occur.\n\nWe believe that number of tasks and size of cluster should be taken into account. Based on which we believe that a ratio between total fetch attempts and total failed attempts should be taken into consideration.\n\nGiven our experience with a task should be declared \"Too many fetch failures\" based on:\n\nfailures > n /*could be 3*/ && (failures/total attempts) > k% /*could be 30-40%*/\n\nBasically the first factor is to give some headstart to the second factor, second factor then takes into account the cluster size and the task size.\n\nAdditionally we could take recency into account, say failures and attempts in last one hour. We do not want to make it too small.\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12372075","id":"12372075","filename":"HADOOP-2220.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-21T11:31:21.546+0000","size":9567,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12372075/HADOOP-2220.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12371601","id":"12371601","filename":"HADOOP-2220.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-13T14:47:20.783+0000","size":14467,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12371601/HADOOP-2220.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12371591","id":"12371591","filename":"HADOOP-2220.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-13T11:50:06.979+0000","size":14451,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12371591/HADOOP-2220.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"102669","customfield_12312823":null,"summary":"Mappers fail easily due to repeated failures","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srikantk","name":"srikantk","key":"srikantk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Srikanth Kakani","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srikantk","name":"srikantk","key":"srikantk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Srikanth Kakani","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"1400 Node hadoop cluster","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12544618","id":"12544618","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Srikanth, as it stands today a mapper is failed when a minimum of 15 attempts to fetch is failed - it's basically {{MAX_FETCH_RETRIES_PER_MAP}} * {{MAX_FETCH_FAILURES_NOTIFICATIONS}}.\n\nBut yes, we've been debating ways to improve upto this, including tuning backoff period between fetches etc. (HADOOP-1894)\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-11-21T22:29:11.446+0000","updated":"2007-11-21T22:29:11.446+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12544666","id":"12544666","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srikantk","name":"srikantk","key":"srikantk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Srikanth Kakani","active":true,"timeZone":"Etc/UTC"},"body":"I think you are right 15 retries are being done but 5 of them fail in a bunch, really as one failure. Backoff should help in that. However the cluster size should also play a part as there will be lot more fetches and hence higher probability of failure. A ratio would help in considering that aspect. There may be better metrics for that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srikantk","name":"srikantk","key":"srikantk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Srikanth Kakani","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-22T00:58:23.931+0000","updated":"2007-11-22T00:58:23.931+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12546960","id":"12546960","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Changed this to blocker for 0.15.2, in concert with HADOOP-2220.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-30T01:41:11.476+0000","updated":"2007-11-30T01:41:11.476+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12549651","id":"12549651","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"_THE *WAIT-KILL* DILEMMA_\nFollowing are the issues to be considered while deciding whether a map should be killed or not. Earlier the backoff function used to backoff by a random amount between 1min-6min. Now after HADOOP-1984, the backoff function is exponential in nature. The total amount to time spent by a reducer on fetching a map output before giving up is {{max-backoff}} in total. In all ({{3* max-backoff}}) time is required to kill a map task by a reducer. So first thing to do is to adjust the {{mapred.reduce.max.backoff}} parameter so that the map is not killed early. Other parameters which we are working on is as follows\n* *Reducer-health* : There should a way to decide how is the reducer performing. One such parameter is ({{num-fail-fetches/num-fetches}}). Roughly this ratio > 50% conveys that the reducer is not performing well enough.\n* *Reducer-progress* : There should a way to decide how is the reducer progressing. One such parameter is ({{num-outputs-fetched/num-maps}}). Roughly this ratio > 50% conveys that the reducer has made considerable progress.\n* *Avg map completion time* : This time should determine when the fetch attempt should be considered as failed hence JT should be reported.\n* *Num-reducers* : The number of reducers in a particular job might provide some insight on how the contented the resources might be. (Low the number of reducers + failing output fetch a single map) indicate that the problem is map-sided. If the reducer is not able to fetch any map then the problem is reducer-sided. If there are many reducers and failures in map fetch then there is a high chance of congestion.\n\nOne thing to notice is that\n* it requires ({{max-backoff*3}}) amount of time to kill a map.\n* it requires 5 minutes (in worst case) to kill a reducer when there are 5 fetches fail simultaneously.\n\nA better strategy would be to make\n* *avg-map-completion-time* as a parameter in deciding the time to report failure. {{max-backoff}} should also be dependent on avg map completion time.\n* *num-reducers* as a parameter in deciding how much to backoff and whether the map should be killed or the reducer should backoff(wait).\n* *(num-maps - num-finished)* and *(num-fetch-fail / num-fetched)* as a parameter in deciding the time to kill the reducer. A good strategy would be to kill a reducer if it fails to fetch output of 50% of the maps and not many map output are fetched. It could be a case that the reducer has fetched the map outputs but with some failures. In that case the fetch-fail ratio will be higher but the progress will also be considerable. We don't want to penalize a reducer which has fetched many map outputs with lot of failures.\n* *ratio-based-map-killing* : JT should also kill a map based on some % along with the hard coded number 3. For example kill a map if 50% of the reducers report failures and num-reports >= 3. Also it might help the JT to have a global idea of what all map-outputs are being tried so that the scheduling of new tasks and killing of maps can be decided.\n* *fetch-success event notification* : JT should be informed by a reducer about a successful map-output-fetch event as a result of which the counters regarding the killing of that map should be reset. In a highly congested system finding 3 reducers that fail in the first attempt for a particular map is easy.\n ----\nComments ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-08T05:35:49.142+0000","updated":"2007-12-08T05:35:49.142+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12550320","id":"12550320","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"I think the max backoff should be set to a high value for apps where a high load on the cluster is expected. Apart from that, I think basing the decision whether to send a notification to the JT on a map should be based on the ratio of the number of failed attempts to the total number of attempts. The higher the ratio the lesser the probability that the map is faulty. It's highly probable that the reducer is faulty and/or the cluster is too busy ..\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-12-11T05:49:19.747+0000","updated":"2007-12-11T05:55:06.102+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12551491","id":"12551491","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"I am submitting a common patch for HADOOP-2220 and HADOOP-2247 since the combined effect of the strategy for map-kill and reducer-kill is what is desired. Following are the things that this patch proposes to change\n- _Map Killing_ : Following are the conditions that will now determine the killing of a map\n  1. {{num-fetch-fail-notifications >= 3}}\n  2. ({{num-fetch-fail-notifications/num-reducers) >= max-allowed}}, here {{max-allowed = 0.5}}\n- _Reducer Killing_ :  Following are the conditions that will now determine the killing of a reducer\n  1. {{num-unique-failures >= 5}}\n  2. {{num-failed-attempt/num-attempts >= max-allowed}}, {{max-allowed = 0.5}}\n  3. {{num-copied/num-maps <= min-required}}, {{num-required = 0.5}} _OR_  {{time-without-progress >= (min-shuffle-exec-time/2)}}\n\n\nHere are the details and insights for this design\n- In the map case, a vote is considered before killing the map. If more than 50% of the reducers fail to fetch the map output then the map should be re-executed. If some reducer continuously reports failure for a map causing the count to be >= num-reducers/2 also means that the map-host lately encountered a problem and had sufficient time to come out of it. This makes sure that the map is not killed too early and also that the map gets killed/re-executed sometime or the other.\n   *_CASE_* : Consider a case where the first 2 attempts by 2 reducers result into fetch-failures and subsequent attempts succeed. This can cause the map to be re-executed if the 3rd reducer fails for the first time. This addition overcomes this flaw. \n- In the reducer case, _num failed attempts_, _progress made_ and _stalled time_ are also taken into consideration. The reason for doing this is \n  1. _num failed attempts_ : It helps in cases where the reducer fails on unique maps but very few times and thus give some more time to the reducer. \n  2. _progress made_ : it helps to avoid reducer killing if the reducer has progressed a lot and killing it would be a big overhead. \n        *_CASE_* : Consider a case where the reducer has failed on every attempt once before being successful. In this case, the _failure rate_ is 50%, _unique failures_ is also more than 3 but the progress made is more than 50%. So _progress made_ balances _num failed attempts_ and _unique failures_ in some cases.  \n  3.  _stalled time_ : It helps in cases where the reducer has made a lot of progress but encountered a problem in the final steps. Now since the _progress made_ is more than 50% there should be a way to kill the reducer.  Stalled time is calculated based on the {{max-map-completion-time}} and {{duration of shuffle phase before stalling}}. So the reducer will have {{min-shuffle-exec-time}} as {{max(max-map-completion-time, duration-before-stall)}} and the reducer is considered stalled if it shows no progress for {{min-shuffle-exec-time/2}} amount of time.\n  In the above case {{uniq-fetch-failure}} gives the head start while the others help maintain the balance towards the rest of the shuffle phase.\n- {{max-backoff}} is now set to {{max(default-max-backoff, map-completion-time)}}. This allows a granular approach for map killing. So larger the map more the time required to kill it while faster maps will be killed faster. This parameter decides both the map killing and reducer killing (hence a common patch).\n ----\nSrikanth and  Christian could you plz try this out and comment? Any comments on the strategy and the default %?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-13T12:41:28.710+0000","updated":"2007-12-13T12:41:28.710+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12551499","id":"12551499","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12371591/HADOOP-2220.patch\nagainst trunk revision r603824.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new compiler warnings.\n\n    findbugs -1.  The patch appears to introduce 1 new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests -1.  The patch failed contrib unit tests.\n\nTest results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1335/testReport/\nFindbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1335/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1335/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1335/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-13T13:30:42.637+0000","updated":"2007-12-13T13:30:42.637+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12551543","id":"12551543","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12371601/HADOOP-2220.patch\nagainst trunk revision r603824.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new compiler warnings.\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1337/testReport/\nFindbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1337/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1337/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1337/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-13T15:53:13.880+0000","updated":"2007-12-13T15:53:13.880+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12551638","id":"12551638","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srikantk","name":"srikantk","key":"srikantk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Srikanth Kakani","active":true,"timeZone":"Etc/UTC"},"body":"> So the reducer will have min-shuffle-exec-time as max(max-map-completion-time, duration-before-stall) \nhow large is duration-before-stall\nshould min-shuffle-exec-time be max-map-completion-time + duration-before-stall\n\n>time-without-progress >= (min-shuffle-exec-time/2)\nis there any reason for the /2 factor?\n\nRest all seems good to me","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srikantk","name":"srikantk","key":"srikantk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Srikanth Kakani","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-13T23:02:26.352+0000","updated":"2007-12-13T23:02:26.352+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12551686","id":"12551686","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"- {{duration-before-stall}} is computed as \n{{shuffle-start-time - last-successful-map-output-copy-time}}. In most of the cases {{duration-before-stall}} should dominate but we also consider {{max-map-completion-time}} as to make sure that we wait at least {{max-map-completion-time}} amount of time and not kill the reducer to before that. \n- {{/2}} is just a measure to distinguish between the cases where  the reducer has developed some faults and network/jetty congestions. \n----\nComments? Any better measures? Any strong opinions on the usage of {{max}} or {{+}} operator in the {{min-shuffle-exec}} computation?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-14T04:30:38.004+0000","updated":"2007-12-14T04:30:38.004+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12553445","id":"12553445","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Couple of comments:\n\n1. To kill maps:\n\nbq. 2. (num-fetch-fail-notifications/num-reducers) >= max-allowed, here max-allowed = 0.5\n\nshould be (num-fetch-fail-notifications / *num-currently_running-reducers* ) >= max-allowed. This is to ensure that long-tails do not hold up the job. For e.g. if we had a lost TT and a bad map, we will need to wait too long for the last couple of reduces to finish; and hence the idea is to use *num-currently_running-reducers*. \nFor cases where the maps are long-lived and non-trivial the _max-completion-time_ of the mapper used to gate the notifications to the JT from the reducer should help.\n\n2. We don't need to maintain a mapping from mapId -> maxRetries, just a global variable should work i.e. we don't need to customize it per mapId.\n\n3. Please change all hard-coded factors (such as divide-by-two) to final variables. (I see at least one instance: *minShuffleRunDuration / 2*)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-19T19:35:16.222+0000","updated":"2007-12-19T19:35:16.222+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12553928","id":"12553928","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"Submitting a new patch incorporating Arun's comment.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-21T11:33:03.763+0000","updated":"2007-12-21T11:33:03.763+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12553941","id":"12553941","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12372075/HADOOP-2220.patch\nagainst trunk revision r606058.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new compiler warnings.\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1417/testReport/\nFindbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1417/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1417/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1417/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-21T13:14:12.055+0000","updated":"2007-12-21T13:14:12.055+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12553993","id":"12553993","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this. Thanks, Amar!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-21T18:58:14.292+0000","updated":"2007-12-21T18:58:14.292+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12554018","id":"12554018","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"I realised (a tad late) that this can't be scheduled for 0.15.2 unless we put in HADOOP-1984 into it too... either that or we schedule this for 0.16.0. \n\nThoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-21T20:03:09.361+0000","updated":"2007-12-21T20:03:09.361+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12554025","id":"12554025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Talked to Arun and agreed to move it to 0.16.0","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-21T20:22:59.497+0000","updated":"2007-12-21T20:22:59.497+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383013/comment/12554026","id":"12554026","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Ok, I've moved this to 0.16.0 after talking to Christian.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-21T20:27:54.684+0000","updated":"2007-12-21T20:27:54.684+0000"}],"maxResults":17,"total":17,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2247/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0hxdj:"}}