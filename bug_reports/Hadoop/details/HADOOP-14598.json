{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13082920","self":"https://issues.apache.org/jira/rest/api/2/issue/13082920","key":"HADOOP-14598","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334219","id":"12334219","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12338416","id":"12338416","description":"3.0.0-beta1 release","name":"3.0.0-beta1","archived":false,"released":true,"releaseDate":"2017-10-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-06-28T18:48:36.203+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Aug 11 09:12:43 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_4_*:*_78465096_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_4_*:*_3566619852","customfield_12312321":null,"resolutiondate":"2017-08-08T23:36:27.646+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14598/watchers","watchCount":6,"isWatching":false},"created":"2017-06-27T19:05:02.752+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334219","id":"12334219","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12339180","id":"12339180","name":"3.0.0-alpha4","archived":false,"released":true,"releaseDate":"2017-07-07"}],"issuelinks":[{"id":"12507969","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12507969","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12931808","key":"SPARK-12868","self":"https://issues.apache.org/jira/rest/api/2/issue/12931808","fields":{"summary":"ADD JAR via sparkSQL JDBC will fail when using a HDFS URL","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12507803","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12507803","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"inwardIssue":{"id":"13068993","key":"HADOOP-14383","self":"https://issues.apache.org/jira/rest/api/2/issue/13068993","fields":{"summary":"Implement FileSystem that reads from HTTP / HTTPS endpoints","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12507707","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12507707","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"13081078","key":"HADOOP-14552","self":"https://issues.apache.org/jira/rest/api/2/issue/13081078","fields":{"summary":"Ãœber-jira: WASB client phase II: performance and testing","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-08-11T09:12:43.769+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12328416","id":"12328416","name":"fs/azure","description":"Azure WASB filesystem client"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12311440","id":"12311440","name":"test","description":"Testing support software"}],"timeoriginalestimate":null,"description":"my downstream-of-spark cloud integration tests (where I haven't been running the azure ones for a while) now have a few of the tests failing\n\n{code}\n org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: org.apache.hadoop.fs.FsUrlConnection cannot be cast to java.net.HttpURLConnection\n{code}\n\nNo obvious cause, and it's only apparently happening in some of the (scalatest) tests.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334219","id":"12334219","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12338416","id":"12338416","description":"3.0.0-beta1 release","name":"3.0.0-beta1","archived":false,"released":true,"releaseDate":"2017-10-03"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12874910","id":"12874910","filename":"HADOOP-14598-002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-28T16:43:48.766+0000","size":6456,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12874910/HADOOP-14598-002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12875249","id":"12875249","filename":"HADOOP-14598-003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-30T12:51:34.578+0000","size":7013,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12875249/HADOOP-14598-003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12877054","id":"12877054","filename":"HADOOP-14598-004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-07-13T11:38:43.891+0000","size":6726,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12877054/HADOOP-14598-004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12880380","id":"12880380","filename":"HADOOP-14598-005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-08-04T10:29:06.073+0000","size":7237,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12880380/HADOOP-14598-005.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Blacklist Http/HttpsFileSystem in FsUrlStreamHandlerFactory","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16065318","id":"16065318","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"{code}\n- DataFrames *** FAILED ***\n  org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: org.apache.hadoop.fs.FsUrlConnection cannot be cast to java.net.HttpURLConnection\n  at org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.retrieveMetadata(AzureNativeFileSystemStore.java:2023)\n  at org.apache.hadoop.fs.azure.NativeAzureFileSystem.delete(NativeAzureFileSystem.java:1846)\n  at org.apache.hadoop.fs.azure.NativeAzureFileSystem.delete(NativeAzureFileSystem.java:1810)\n  at com.hortonworks.spark.cloud.ObjectStoreOperations$class.rm(ObjectStoreOperations.scala:409)\n  at com.hortonworks.spark.cloud.operations.CloudDataFrames.rm(CloudDataFrames.scala:36)\n  at com.hortonworks.spark.cloud.operations.CloudDataFrames.action(CloudDataFrames.scala:82)\n  at com.hortonworks.spark.cloud.ObjectStoreExample$class.action(ObjectStoreExample.scala:70)\n  at com.hortonworks.spark.cloud.operations.CloudDataFrames.action(CloudDataFrames.scala:36)\n  at com.hortonworks.spark.cloud.common.DataFrameTests$$anonfun$3.apply$mcV$sp(DataFrameTests.scala:45)\n  at com.hortonworks.spark.cloud.CloudSuiteTrait$$anonfun$ctest$1.apply$mcV$sp(CloudSuiteTrait.scala:69)\n  ...\n  Cause: com.microsoft.azure.storage.StorageException: org.apache.hadoop.fs.FsUrlConnection cannot be cast to java.net.HttpURLConnection\n  at com.microsoft.azure.storage.core.ExecutionEngine.setupStorageRequest(ExecutionEngine.java:332)\n  at com.microsoft.azure.storage.core.ExecutionEngine.executeWithRetry(ExecutionEngine.java:95)\n  at com.microsoft.azure.storage.blob.CloudBlob.exists(CloudBlob.java:1850)\n  at com.microsoft.azure.storage.blob.CloudBlob.exists(CloudBlob.java:1837)\n  at org.apache.hadoop.fs.azure.StorageInterfaceImpl$CloudBlobWrapperImpl.exists(StorageInterfaceImpl.java:333)\n  at org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.retrieveMetadata(AzureNativeFileSystemStore.java:1964)\n  at org.apache.hadoop.fs.azure.NativeAzureFileSystem.delete(NativeAzureFileSystem.java:1846)\n  at org.apache.hadoop.fs.azure.NativeAzureFileSystem.delete(NativeAzureFileSystem.java:1810)\n  at com.hortonworks.spark.cloud.ObjectStoreOperations$class.rm(ObjectStoreOperations.scala:409)\n  at com.hortonworks.spark.cloud.operations.CloudDataFrames.rm(CloudDataFrames.scala:36)\n  ...\n  Cause: java.lang.ClassCastException: org.apache.hadoop.fs.FsUrlConnection cannot be cast to java.net.HttpURLConnection\n  at com.microsoft.azure.storage.core.BaseRequest.createURLConnection(BaseRequest.java:185)\n  at com.microsoft.azure.storage.core.BaseRequest.getProperties(BaseRequest.java:299)\n  at com.microsoft.azure.storage.blob.BlobRequest.getProperties(BlobRequest.java:791)\n  at com.microsoft.azure.storage.blob.BlobRequest.getBlobProperties(BlobRequest.java:570)\n  at com.microsoft.azure.storage.blob.CloudBlob$10.buildRequest(CloudBlob.java:1867)\n  at com.microsoft.azure.storage.blob.CloudBlob$10.buildRequest(CloudBlob.java:1857)\n  at com.microsoft.azure.storage.core.ExecutionEngine.setupStorageRequest(ExecutionEngine.java:304)\n  at com.microsoft.azure.storage.core.ExecutionEngine.executeWithRetry(ExecutionEngine.java:95)\n  at com.microsoft.azure.storage.blob.CloudBlob.exists(CloudBlob.java:1850)\n  at com.microsoft.azure.storage.blob.CloudBlob.exists(CloudBlob.java:1837)\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-27T19:05:49.893+0000","updated":"2017-06-27T19:05:49.893+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16065397","id":"16065397","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"not related to the latest SDK update; happens if I switch to the  previous one.\n\nLooking @ the code, it comes down to this: the URI to use\n{code}\nbuilder = new UriQueryBuilder();\nfinal URL resourceUrl = builder.addToURI(uri).toURL();\nretConnection = (HttpURLConnection) resourceUrl.openConnection();   // *HERE*\n{code}\n\nThe implication is that (a) hadoop has patched in a URL factory and (b) its returning the wrong thing, or (c) I'm handing in the wrong URL to the FS. Which, if I instrument my code better, doesn't appear to be the case\n\n{code}\n FileGenerator *** FAILED ***\n  java.io.IOException: Failed to delete wasb://contract@contender.blob.core.windows.net/cloud-integration/DELAY_LISTING_ME/AzureFileGeneratorSuite/filegenerator on org.apache.hadoop.fs.azure.NativeAzureFileSystem@6fe77a97 org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: org.apache.hadoop.fs.FsUrlConnection cannot be cast to java.net.HttpURLConnection\n  at com.hortonworks.spark.cloud.ObjectStoreOperations$class.rm(ObjectStoreOperations.scala:415)\n  at com.hortonworks.spark.cloud.operations.CloudFileGenerator.rm(CloudFileGenerator.scala:33)\n  at com.hortonworks.spark.cloud.operations.CloudFileGenerator.action(CloudFileGenerator.scala:81)\n  at com.hortonworks.spark.cloud.ObjectStoreExample$class.action(ObjectStoreExample.scala:70)\n  at com.hortonworks.spark.cloud.operations.CloudFileGenerator.action(CloudFileGenerator.scala:33)\n  at com.hortonworks.spark.cloud.common.FileGeneratorTests.generate(FileGeneratorTests.scala:80)\n  at com.hortonworks.spark.cloud.common.FileGeneratorTests$$anonfun$2.apply$mcV$sp(FileGeneratorTests.scala:40)\n  at com.hortonworks.spark.cloud.CloudSuiteTrait$$anonfun$ctest$1.apply$mcV$sp(CloudSuiteTrait.scala:69)\n  at com.hortonworks.spark.cloud.CloudSuiteTrait$$anonfun$ctest$1.apply(CloudSuiteTrait.scala:67)\n  at com.hortonworks.spark.cloud.CloudSuiteTrait$$anonfun$ctest$1.apply(CloudSuiteTrait.scala:67)\n  ...\n  Cause: org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.st\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-27T20:10:20.755+0000","updated":"2017-06-28T11:20:55.872+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16065454","id":"16065454","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"In Spark's {{org.apache.spark.sql.internal.SharedState}}\n{code}\nURL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory())\n{code}\n\nThis is kicking in when Hive/ Spark SQLContext is being inited, which is why it only surfaces in some tests","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-27T20:59:00.826+0000","updated":"2017-06-27T20:59:00.826+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16066270","id":"16066270","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"trying to understand this some more. The Hadoop stream handler factory *should* be transparent for any URL Scheme which isn't from a supported FS. But of course, wasb is. Somehow a wasb URL is getting down into the Azure library when it tries to connect to azure storage...the fs factory returns a URL, which cannot be cast to an HTTP URL.\n\nthis should be isolatable into a local test","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-28T10:07:12.337+0000","updated":"2017-06-28T10:07:12.337+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16066763","id":"16066763","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"More details. Issue is that the {{HttpFileSystem}} connection is getting found when an http: URL comes in, so: disaster\n{code}\n2017-06-28 16:54:59,217 [ScalaTest-main-running-AzureDataFrameSuite] INFO  netty.NettyBlockTransferService (Logging.scala:logInfo(54)) - Server created on 192.168.1.38:57795\n2017-06-28 16:55:01,284 [ScalaTest-main-running-AzureDataFrameSuite] DEBUG fs.FsUrlStreamHandlerFactory (FsUrlStreamHandlerFactory.java:createURLStreamHandler(77)) - Creating handler for protocol http\n2017-06-28 16:55:01,285 [ScalaTest-main-running-AzureDataFrameSuite] DEBUG fs.FsUrlStreamHandlerFactory (FsUrlStreamHandlerFactory.java:createURLStreamHandler(77)) - Creating handler for protocol file\n2017-06-28 16:55:01,285 [ScalaTest-main-running-AzureDataFrameSuite] DEBUG fs.FsUrlStreamHandlerFactory (FsUrlStreamHandlerFactory.java:createURLStreamHandler(83)) - Found implementation of file: class org.apache.hadoop.fs.LocalFileSystem\n2017-06-28 16:55:01,285 [ScalaTest-main-running-AzureDataFrameSuite] DEBUG fs.FsUrlStreamHandlerFactory (FsUrlStreamHandlerFactory.java:createURLStreamHandler(91)) - Using handler for protocol file\n2017-06-28 16:55:01,291 [ScalaTest-main-running-AzureDataFrameSuite] DEBUG fs.FsUrlStreamHandlerFactory (FsUrlStreamHandlerFactory.java:createURLStreamHandler(83)) - Found implementation of http: class org.apache.hadoop.fs.http.HttpFileSystem\n2017-06-28 16:55:01,291 [ScalaTest-main-running-AzureDataFrameSuite] DEBUG fs.FsUrlStreamHandlerFactory (FsUrlStreamHandlerFactory.java:createURLStreamHandler(91)) - Using handler for protocol http\n2017-06-28 16:55:01,331 [ScalaTest-main-running-AzureDataFrameSuite] INFO  azure.AzureDataFrameSuite (Logging.scala:logInfo(54)) - Cleaning wasb://contract@contender.blob.core.windows.net/cloud-integration/DELAY_LISTING_ME/AzureDataFrameSuite\n2017-06-28 16:55:01,332 [ScalaTest-main-running-AzureDataFrameSuite] INFO  azure.AzureDataFrameSuite (Logging.scala:logInfo(54)) - During cleanup of filesystem: org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: org.apache.hadoop.fs.FsUrlConnection cannot be cast to java.net.HttpURLConnection\n- DataFrames *** FAILED ***\n  java.io.IOException: Failed to delete wasb://contract@contender.blob.core.windows.net/cloud-integration/DELAY_LISTING_ME/AzureDataFrameSuite/dataframes/generated on org.apache.hadoop.fs.azure.NativeAzureFileSystem@7b3cbe6e org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: org.apache.hadoop.fs.FsUrlConnection cannot be cast to java.net.HttpURLConnection\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-28T15:56:43.407+0000","updated":"2017-06-28T15:56:43.407+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16066841","id":"16066841","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Patch 002. This doesn't fix it, but provided me with enough debug level logging to confirm that the http schemas were resulting in connections via {{HttpFileSystem}}, not real HttpURLConnection instances.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-28T16:45:32.493+0000","updated":"2017-06-28T16:45:32.493+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16067044","id":"16067044","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  2m  5s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 52s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  9s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 26s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 26s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 15s{color} | {color:orange} root: The patch generated 3 new + 1 unchanged - 0 fixed = 4 total (was 1) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 31s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m 25s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 51s{color} | {color:green} hadoop-azure in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 42s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 93m 50s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.ha.TestZKFailoverController |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HADOOP-14598 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12874910/HADOOP-14598-002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 1749d1604419 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / ee243e5 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/12649/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12649/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12649/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-azure U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12649/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-06-28T18:48:36.203+0000","updated":"2017-06-28T18:48:36.203+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16070058","id":"16070058","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Patch 003 preregisters http and https as unsupported, so{{FsUrlStreamHandlerFactory}} doesn't look for any filesystems with those schemas, instead returning null. This will cause the JVM to fall back to the default handler.\n\n\nBefore that fix is in, the two new tests fail.\n\nNote also I patched the test class to set up the test {{TestUrlStreamHandler}} to set up the handler for the JVM in a before-class call. The existing code only worked provided the first test in the source, {{testDfsUrls}} was the first test executed; an ordering which hasn't been guaranteed since Java 7. It's possibly just been luck (or accidental sorting order of test names?) which has caused this to continue to work.\n\n{code}\n\njava.lang.AssertionError: Handler for HTTP is the Hadoop one expected null, but was:<org.apache.hadoop.fs.FsUrlStreamHandler@27ae2fd0>\n\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotNull(Assert.java:664)\n\tat org.junit.Assert.assertNull(Assert.java:646)\n\tat org.apache.hadoop.fs.TestUrlStreamHandler.testHttpDefaultHandler(TestUrlStreamHandler.java:170)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:160)\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\n\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\n\n\njava.lang.AssertionError: Handler for HTTPS is the Hadoop one expected null, but was:<org.apache.hadoop.fs.FsUrlStreamHandler@36c88a32>\n\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotNull(Assert.java:664)\n\tat org.junit.Assert.assertNull(Assert.java:646)\n\tat org.apache.hadoop.fs.TestUrlStreamHandler.testHttpsDefaultHandler(TestUrlStreamHandler.java:176)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:160)\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\n\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\n{code}\n\nAs well as this unit test, I have done a full integration test downstream. All is well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-06-30T13:03:09.146+0000","updated":"2017-06-30T13:03:09.146+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16070380","id":"16070380","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 32s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 20m 28s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 22s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 55s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 26s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 21s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 54s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 14s{color} | {color:orange} root: The patch generated 3 new + 9 unchanged - 0 fixed = 12 total (was 9) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 39s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 23s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 54s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 41s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 81m 59s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}194m 38s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.security.TestRaceWhenRelogin |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.web.TestWebHdfsTimeouts |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HADOOP-14598 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12875249/HADOOP-14598-003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux bf793a890bf7 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 3be2659 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12687/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/12687/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12687/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12687/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12687/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12687/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-06-30T16:39:25.419+0000","updated":"2017-06-30T16:39:25.419+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16085564","id":"16085564","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Test failures are unrelated. First is ordering of tgt tickets; the HDFS onea are all about network problems","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-07-13T11:34:23.923+0000","updated":"2017-07-13T11:34:23.923+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16085569","id":"16085569","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"patch 004; checkstyle warned of unused imports. fixed","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-07-13T11:39:00.360+0000","updated":"2017-07-13T11:39:00.360+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16085767","id":"16085767","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 14s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 26s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 48s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 46s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 31s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 45s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 64m 49s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 42s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}156m 20s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HADOOP-14598 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12877054/HADOOP-14598-004.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 176b6d59fd1d 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / cf0d084 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12772/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12772/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12772/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12772/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-13T14:35:13.841+0000","updated":"2017-07-13T14:35:13.841+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16112510","id":"16112510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Can I get a review of this? I do consider it a blocker for the next releases. Thx","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-08-03T09:52:11.951+0000","updated":"2017-08-03T09:52:11.951+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16113688","id":"16113688","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=esmanii","name":"esmanii","key":"esmanii","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Esfandiar Manii","active":true,"timeZone":"America/Los_Angeles"},"body":"FsUrlStreamHandlerFactory L73-74, Could you please add a few lines of comment on why the protocols are added there so the reason wont be forgotten in the future.\nFsUrlStreamHandlerFactory L73-74, I would create a util/private method which gets/(exists in) the factory and call put on all the list of protocols.\nTestUrlStreamHandler.java, do we also need to include a test for invalid protocols?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=esmanii","name":"esmanii","key":"esmanii","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Esfandiar Manii","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-03T23:23:13.327+0000","updated":"2017-08-03T23:23:13.327+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16114220","id":"16114220","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Patch 005: address Esfandiar Manii's comments by\n* moving list of protocols into a static string with a comment explaining importance\n* test handling of an unknown protocol (nobody will ever add a Gopher connector, right?)\n\nAlso, clean up the test suite slightly","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-08-04T10:29:19.946+0000","updated":"2017-08-04T10:29:19.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16114548","id":"16114548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 21s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 48s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 37s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 57s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 28s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 50s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 9 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 40s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 31s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 22s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 22s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  1s{color} | {color:green} root: The patch generated 0 new + 8 unchanged - 1 fixed = 8 total (was 9) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 31s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 37s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  9s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 65m  4s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}156m 27s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.security.TestKDiag |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\n|   | hadoop.hdfs.server.balancer.TestBalancer |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HADOOP-14598 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12880380/HADOOP-14598-005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux cd62903903a4 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 7fc324a |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12951/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12951/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12951/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12951/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12951/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-04T15:56:47.107+0000","updated":"2017-08-04T15:56:47.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16114683","id":"16114683","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=esmanii","name":"esmanii","key":"esmanii","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Esfandiar Manii","active":true,"timeZone":"America/Los_Angeles"},"body":"+1, thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=esmanii","name":"esmanii","key":"esmanii","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Esfandiar Manii","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-04T17:35:03.188+0000","updated":"2017-08-04T17:35:03.188+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16114801","id":"16114801","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"body":"If HADOOP-14383 is reverted or modified to use different schemes, this JIRA no longer needs to be fixed, right?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-04T18:44:16.390+0000","updated":"2017-08-04T18:44:16.390+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16118327","id":"16118327","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"HADOOP-14383 was designed to allow anyone to use an http or https URL as a source of data in anything which takes a filesystem for reading things. This is good, and changing the schema to anything other than http/https doesn't make sense.\n\nAll thats problematic is that the bit of code which exports every Hadoop FS client as a URL via the JVM mustn't register the core JVM HTTP/HTTPS clients, as those work very well and other bits of code (here: Azure SDK), have assumptions/requirements about the class returned when you try to open such URLs.\n\nThis patch stops the new schemas from being registered, sets things up for future schemas to go in too.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-08-08T13:20:08.951+0000","updated":"2017-08-08T13:20:08.951+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16119055","id":"16119055","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 LGTM. Wrap {{LOG.debug}} with {{if (LOG.isDebugEnabled())}} in fast paths?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-08T21:27:10.318+0000","updated":"2017-08-08T21:27:10.318+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16119124","id":"16119124","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"So essentially the downstream users assume that an {{URLConnection}} can be always casted to {{HttpConnection}} then. It's not ideal but yes, many people do that.\n\nThe patch looks good to me. +1. I'll commit it shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-08T22:25:57.109+0000","updated":"2017-08-08T22:25:57.109+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16119183","id":"16119183","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to trunk and branch-2. Thanks [~steve_l] for contribution.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-08T23:36:27.689+0000","updated":"2017-08-08T23:36:27.689+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16119641","id":"16119641","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"thanks for committing it. It's a funny one. FWIW the class cast wasn't downstream. it was in an external library. We will have to assume this is commonplace across the java codebase.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-08-09T09:56:25.005+0000","updated":"2017-08-09T09:56:25.005+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13082920/comment/16123066","id":"16123066","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"FYI., on a \"similar topic but not actually caused by the new work\" is the discovery that you get an NPE if you try to use an hdfs:// URL For a JAR in the classloader: SPARK-21697\n\nThat is: you cannot safely use *any* of the Hadoop filesystems as supported schemas for classloaders, due to a loop in commons-logging setup & use (at the very least, there may be other examples too). Not caused by the recent changes to {{FsUrlStreamHandlerFactory}} or the new schemas, just a new codepath that's not been looked at before","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-08-11T09:12:43.769+0000","updated":"2017-08-11T09:12:43.769+0000"}],"maxResults":24,"total":24,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14598/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3gswn:"}}