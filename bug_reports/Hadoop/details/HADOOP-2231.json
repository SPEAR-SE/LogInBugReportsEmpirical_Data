{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12382826","self":"https://issues.apache.org/jira/rest/api/2/issue/12382826","key":"HADOOP-2231","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2007-12-03T21:57:06.334+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Dec 07 10:12:29 UTC 2007","customfield_12310420":"125526","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_303720129_*|*_1_*:*_1_*:*_1207441713_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_2449288406","customfield_12312321":null,"resolutiondate":"2007-12-07T10:12:29.595+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2231/watchers","watchCount":0,"isWatching":false},"created":"2007-11-19T22:26:27.753+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312850","id":"12312850","description":"","name":"0.15.1","archived":false,"released":true,"releaseDate":"2007-11-27"}],"issuelinks":[{"id":"12318389","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12318389","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12383850","key":"HADOOP-2344","self":"https://issues.apache.org/jira/rest/api/2/issue/12383850","fields":{"summary":"Free up the buffers (input and error) while executing a shell command before waiting for it to finish.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2008-01-04T18:33:57.999+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310689","id":"12310689","name":"fs","description":"Generic FileSystem code"}],"timeoriginalestimate":null,"description":"We noticed that some pipes applications writing to dfs using libhdfs have about 6% chance of hanging when executing 'df -k' to find out whether there is enough space available on the local filesystem before opening a file for write.\n\nWhy not using File.getFreeSpace() or File.GetUsableSpace()?\n\nThe call stack is:\nException in thread \"main\" java.io.IOException\n         at org.apache.hadoop.fs.ShellCommand.runCommand\n(ShellCommand.java:52)\n         at org.apache.hadoop.fs.ShellCommand.run(ShellCommand.java:42)\n         at org.apache.hadoop.fs.DF.getAvailable(DF.java:72)\n         at org.apache.hadoop.fs.LocalDirAllocator\n$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:264)\n         at org.apache.hadoop.fs.LocalDirAllocator\n$AllocatorPerContext.createTmpFileForWrite(LocalDirAllocator.java:294)\n         at\norg.apache.hadoop.fs.LocalDirAllocator.createTmpFileForWrite\n(LocalDirAllocator.java:155)\n         at org.apache.hadoop.dfs.DFSClient\n$DFSOutputStream.newBackupFile(DFSClient.java:1470)\n         at org.apache.hadoop.dfs.DFSClient\n$DFSOutputStream.openBackupStream(DFSClient.java:1437)\n         at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.writeChunk\n(DFSClient.java:1579)\n         at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk\n(FSOutputSummer.java:140)\n         at org.apache.hadoop.fs.FSOutputSummer.write1\n(FSOutputSummer.java:100)\n         at org.apache.hadoop.fs.FSOutputSummer.write\n(FSOutputSummer.java:86)\n         at org.apache.hadoop.fs.FSDataOutputStream\n$PositionCache.write(FSDataOutputStream.java:39)\n         at java.io.DataOutputStream.write(DataOutputStream.java:90)\n         at java.io.FilterOutputStream.write(FilterOutputStream.java:80)\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12370878","id":"12370878","filename":"HADOOP-2231.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-03T21:48:46.466+0000","size":7282,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12370878/HADOOP-2231.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"105782","customfield_12312823":null,"summary":"ShellCommand, in particular 'df -k', sometimes hang","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12382826/comment/12548010","id":"12548010","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"There are many cases where {{df -k}} can hang like,\n1. If it encounters a faulty NFS mount. In this case {{df -k}} hangs for ever waiting for the NFS.\n2. If it encounters a faulty file system/block.\n3. Due to overflow of the inputStream/errorStream buffers leading to some kind of deadlock.\nAssuming the cause to be {{3}} I am uploading a patch. Similar bug was found in {{TaskRunner.java}}. Fixed that in this patch. \nComments ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-03T21:57:06.334+0000","updated":"2007-12-03T21:57:06.334+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12382826/comment/12548013","id":"12548013","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"Since we are going to Java 1.6 (ala HADOOP-2325), we can and should move to use java.io.File.getFreeSpace().","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-03T22:04:20.628+0000","updated":"2007-12-03T22:04:20.628+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12382826/comment/12548024","id":"12548024","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-03T22:26:15.685+0000","updated":"2007-12-03T22:26:15.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12382826/comment/12548120","id":"12548120","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12370878/HADOOP-2231.patch\nagainst trunk revision r600771.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    javadoc -1.  The javadoc tool appears to have generated  messages.\n\n    javac +1.  The applied patch does not generate any new compiler warnings.\n\n    findbugs -1.  The patch appears to introduce 1 new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests -1.  The patch failed contrib unit tests.\n\nTest results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1251/testReport/\nFindbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1251/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1251/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1251/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-04T04:30:06.290+0000","updated":"2007-12-04T04:30:06.290+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12382826/comment/12548237","id":"12548237","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"After some more thoughts we feel that \n1. The way free space is computed using {{DF.getAvailable()}} should now be done using {{File.getFreeSpace()}} and {{File.getUsableSpace()}} API available in java6. So as a part of this patch I will change the way {{df -k}} is used to compute the free space by making use of {{File.getUsableSpace()}}.\n2. There are some classes which still use the {{getMount()}} API of {{DF.java}}. Java 6 does not provide any API for this. So the only way out is to make use of shell commands like {{stat}} or {{df}} for calculating the mount points. As discussed in {{HADOOP-2344}}, there are issues with the way shell commands are executed in {{ShellUtil.java}} and {{ShellCommand.java}}. A patch is made available for {{HADOOP-2344}}. \n----\nComments ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-04T12:11:43.872+0000","updated":"2007-12-04T12:11:43.872+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12382826/comment/12548314","id":"12548314","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"I think we should fix HADOOP-2344 regardless.  We don't know for sure yet whether we'll upgrade to Java 6 in the 0.16 release, and, even if we do, we'll still need to invoke shell commands.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-04T17:25:12.909+0000","updated":"2007-12-04T17:25:12.909+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12382826/comment/12549358","id":"12549358","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"HADOOP-2344 addresses the problem in general.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2007-12-07T10:12:29.583+0000","updated":"2007-12-07T10:12:29.583+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2231/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0iglb:"}}