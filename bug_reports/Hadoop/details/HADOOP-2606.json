{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12386232","self":"https://issues.apache.org/jira/rest/api/2/issue/12386232","key":"HADOOP-2606","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312913","id":"12312913","description":"","name":"0.17.0","archived":false,"released":true,"releaseDate":"2008-05-20"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-01-15T00:27:26.367+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Mar 19 11:37:17 UTC 2008","customfield_12310420":"81052","customfield_12312320":null,"customfield_12310222":"10002_*:*_2_*:*_390150955_*|*_1_*:*_2_*:*_5140567605_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_5514551046","customfield_12312321":null,"resolutiondate":"2008-03-19T00:16:39.109+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2606/watchers","watchCount":3,"isWatching":false},"created":"2008-01-14T23:58:00.549+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312830","id":"12312830","description":"","name":"0.14.3","archived":false,"released":true,"releaseDate":"2007-10-19"}],"issuelinks":[{"id":"12391706","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12391706","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12383034","key":"HDFS-150","self":"https://issues.apache.org/jira/rest/api/2/issue/12383034","fields":{"summary":"Replication should be decoupled from heartbeat","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12319552","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12319552","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12383034","key":"HDFS-150","self":"https://issues.apache.org/jira/rest/api/2/issue/12383034","fields":{"summary":"Replication should be decoupled from heartbeat","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12318873","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12318873","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12386554","key":"HADOOP-2649","self":"https://issues.apache.org/jira/rest/api/2/issue/12386554","fields":{"summary":"The ReplicationMonitor sleep period should be configurable","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12318993","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12318993","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12387556","key":"HADOOP-2755","self":"https://issues.apache.org/jira/rest/api/2/issue/12387556","fields":{"summary":"dfs fsck extremely slow, dfs ls times out","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12320129","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12320129","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12394945","key":"HDFS-373","self":"https://issues.apache.org/jira/rest/api/2/issue/12394945","fields":{"summary":"Name node should notify administrator if when struggling with replication","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-07-17T18:37:13.019+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"We tried to decommission about 40 nodes at once, each containing 12k blocks. (about 500k total)\n(This also happened when we first tried to decommission 2 million blocks)\n\nClients started experiencing  \"java.lang.RuntimeException: java.net.SocketTimeoutException: timed out waiting for rpc\nresponse\" and namenode was in 100% cpu state. \n\nIt was spending most of its time on one thread, \n\n\"org.apache.hadoop.dfs.FSNamesystem$ReplicationMonitor@7f401d28\" daemon prio=10 tid=0x0000002e10702800 nid=0x6718\nrunnable [0x0000000041a42000..0x0000000041a42a30]\n   java.lang.Thread.State: RUNNABLE\n        at org.apache.hadoop.dfs.FSNamesystem.containingNodeList(FSNamesystem.java:2766)\n        at org.apache.hadoop.dfs.FSNamesystem.pendingTransfers(FSNamesystem.java:2870)\n        - locked <0x0000002aa3cef720> (a org.apache.hadoop.dfs.UnderReplicatedBlocks)\n        - locked <0x0000002aa3c42e28> (a org.apache.hadoop.dfs.FSNamesystem)\n        at org.apache.hadoop.dfs.FSNamesystem.computeDatanodeWork(FSNamesystem.java:1928)\n        at org.apache.hadoop.dfs.FSNamesystem$ReplicationMonitor.run(FSNamesystem.java:1868)\n        at java.lang.Thread.run(Thread.java:619)\n\n\nWe confirmed that Namenode was not in the fullGC states when these problem happened.\n\nAlso, dfsadmin -metasave was showing \"Blocks waiting for replication\" was decreasing very slowly.\n\nI believe this is not specific to decommission and same problem would happen if we lose one rack.\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12377892","id":"12377892","filename":"ReplicatorNew.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-14T11:49:00.256+0000","size":44495,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12377892/ReplicatorNew.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12378097","id":"12378097","filename":"ReplicatorNew1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-18T03:12:33.678+0000","size":48193,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12378097/ReplicatorNew1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12378188","id":"12378188","filename":"ReplicatorNew2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-18T23:33:29.953+0000","size":48546,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12378188/ReplicatorNew2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12377891","id":"12377891","filename":"ReplicatorTestOld.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-14T11:37:02.601+0000","size":38454,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12377891/ReplicatorTestOld.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"105632","customfield_12312823":null,"summary":"Namenode unstable when replicating 500k blocks at once","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12558871","id":"12558871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"It appears to me that the ReplicationMonitor thread wakes up every 3 seconds and does one iteration. Each iteration scans the neededReplication list once for every datanode. \n\nIf  a cluster has 2000 datanodes and 20K blocks per datanode, then decommissioning 40 nodes means that the size of the neededReplication list is almost 8 million. Thus, this list of 8 million is scanned 2000 times every 3 seconds. Heavy CPU consumption!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-01-15T00:27:26.367+0000","updated":"2008-01-15T00:27:26.367+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12576031","id":"12576031","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I spent some time investigating this issue.\nReplicationMonitor is definitely a problem when we have a lot of under-replicated blocks. Here is how it works.\nReplicationMonitor wakes up every 3 secs and selects 32% of data-nodes.\nFor each selected data-node the monitor scans the list of under-replicated blocks (called neededReplications)\nand selects two blocks from that list that the current node can replicate.\n\nIf we have 2000 nodes and 500,000 blocks each iteration of the monitor (the one that happens\nevery 3 seconds) consists of about 640 searches in the list of 500,000 blocks.\nEach search is a sequential scan of the list until 2 blocks are found.\nThis sure can take a lot of time on average, and is especially expensive if a data-node\ndoes not contain replicas of the blocks in the list.\n\nRather than optimizing this algorithm I propose to change it so that instead of choosing \ndata-nodes and then looking for related blocks the ReplicationMonitor selected \nunder replicated blocks and assigned for replication to one of the data-nodes it belongs to.\nWe of course should avoid the case when a lot of blocks (more than 4?) are assigned for replication to the same node.\nSo if all nodes a block belongs to have already been scheduled for a lot of replications, the block should be skipped.\nThe number of blocks to scan during one sweep should depend on the number of live data-nodes.\nI'd say double that number.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-07T04:12:54.289+0000","updated":"2008-03-07T04:12:54.289+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12577081","id":"12577081","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"This approach look good. It might make sense to create a \"replication benchmark\" so that the performance gain using the new algorithm can be measured. Also, it will help to ensure that we do not regress on replication performance in the future.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-03-10T17:29:00.016+0000","updated":"2008-03-10T17:29:00.016+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12578698","id":"12578698","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"ReplicatorTestOld.patch contains both the new and the old versions of the replication scheduling algorithms, as well as the benchmark to compare them. \nIt is not intended for committing, but if anybody wants to run and compare it is here.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-14T11:37:02.721+0000","updated":"2008-03-14T11:37:02.721+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12578700","id":"12578700","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"This patch implements the approach mentioned above.\nNamely, replication monitorscans the list of under-replicated blocks and schedules them for replication to and from appropriate data-nodes. This is in contrast to the current approach when we choose a node and then scan the list in order to choose a small number of blocks that the chosen node can replicate. The new algorithm tries to schedule more replications on nodes with ongoing decommission. It also does not schedule any replications on nodes that are already in decommissioned state, this part was not present in the previous algorithm.\n\nThe patch also presents a benchmark and a test.\nThe benchmark directly calls the replication scheduler until all blocks are replicated and measures how many blocks per second on average it can schedule. The test runs the benchmark with default parameters.\n\nI ran the test for the old version and for the new one.\nOn my machine the new replicator processes about 9700 blocks per second while the old one does only 640, which is about *15 times faster*.\nThis of course does not mean that blocks will be replicated 15 times faster in a real cluster. This just means that replication monitor will consume much less cpu and will let other name-node operations run faster.\n\nFor those who want to accelerate replication: you need to adjust an undocumented configuration parameter \"dfs.max-repl-streams\", which defines maximal number of replications a data-node is allowed to handle at one time. The default it is 2.\n\nTestReplication is supposed to fail with the new algorithm. The problem is that data-nodes do not report to the name-node crc exceptions obtained during replications. Previously another data-node (if exists) would be chosen as source for the block, and the replication will finally succeed. But now the same source node is deterministically chosen all the time. I think data-nodes should report crc-exceptions the same as clients do. I'll file a bug for discussion.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-14T11:49:00.314+0000","updated":"2008-03-14T11:49:00.314+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12578929","id":"12578929","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"If the namenode always deterministically choses the same datanode as the source of a replication request and the source machine has a problem (bad disk, crc error, read-only partition, etc.etc) then the replication request will never be successful. \n\nIt could also be the case that maybe there is a non-transient network failure between the source datanode and the target datanode. However, both the datanodes are successfully sending heartbeats to the namenode. No CRCs error occuring here. However, the replication request between these two datanodes will keep on failing permanently.\n\nIsn't it better if we can ensure that the namenodes tries different datanodes as the source of a replication request?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-03-14T21:08:07.117+0000","updated":"2008-03-14T21:08:07.117+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12579060","id":"12579060","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12377892/ReplicatorNew.patch\nagainst trunk revision 619744.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 3 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs -1.  The patch appears to introduce 1 new Findbugs warnings.\n\n    core tests -1.  The patch failed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1973/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1973/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1973/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1973/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-03-15T16:20:27.950+0000","updated":"2008-03-15T16:20:27.950+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12579711","id":"12579711","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"This fixes find bugs, and I also randomized target selection in order TestReplication could pass. \nI think another solution should be worked out as a part of HADOOP-3035.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-18T03:12:33.723+0000","updated":"2008-03-18T03:12:33.723+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12580005","id":"12580005","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"1. This patch exits the ReplicationMonitor thread when it receives Interruptedexception. This is nice, because it helps unit tests that restart namenode. Maybe we can make the same change for all other FSNamesystem deamons, e.g. DecommissionedMonitor, ResolutionMonitor, etc.\n\n2. A typo \"arleady reached replication limit\". Should be \"already ....\".\n\n3. If a block in neededReplication does not belong to any file, we silently remove it from neededreplication. This is a cannot happen case and we could log a message in the log.\n\n4. This patch prefers nodes-being-decommissioned to be source of replication requests. When a node changes to the decommmissioned state, the administrator is likely to shutdown that node. There is a higher probability that node is currently serving a replication request. That repliaction request will timeout because the machine was shutdown. This is probably acceptable.\n\n5. FSNamesystem.chooseSourceDatanode() should always return a node if possible. In the current code, this is not guaranteed because r.nextBoolean() may return false for many invocations at a stretch. It might be a good idea to do the following at the end of chooseSourceDatanode:\n\nif (srcNode == null) {\n  srcNode = first datanode in list that has not reached its limit\n}\n\n6. There used to be an important log message that described a replication request:\n     \" pending Transfer .... ask node ...  \".\n     This has changed to \n     \" computeReplicationWork .. ask node..\"\n   Maybe it is a better idea to not have the name of the method in the log messages. Otherwise, when the method name changes (in the future) that log message changes too and makes it harder for people accustomed to earlier log messages to debug the system.\n\n7, Typo in NNThroughOPutbenchmark.isInPorgress(). It should be isInProgress().\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-03-18T18:58:47.580+0000","updated":"2008-03-18T18:58:47.580+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12580164","id":"12580164","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12378097/ReplicatorNew1.patch\nagainst trunk revision 619744.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 3 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1988/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1988/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1988/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1988/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-03-18T23:06:43.766+0000","updated":"2008-03-18T23:06:43.766+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12580170","id":"12580170","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> 1. Interruptedexception or all other FSNamesystem deamons, e.g. DecommissionedMonitor, ResolutionMonitor, etc.\nYes, we should do that. And probably not only name system daemons. I'll file a jira.\n\n> 2. A typo\n> 3. If a block in neededReplication\nDone\n\n> 4. This patch prefers nodes-being-decommissioned to be source of replication requests.\nMy understanding is that the node in decommission-in-progress state SHOULD not be shutdown until its state changes to decommissioned.\nAnd the state can be changed to decommissioned only if all its blocks are replicated no matter who performs replications.\nIf the machine is shutdown anyway then the block will eventually be replicated by another machine.\n\n> 5. FSNamesystem.chooseSourceDatanode() should always return a node if possible.\nThis is a good catch thanks I corrected it.\n\n> 6.\nRemoved method names from the state change logs. We should not use method names in the future because \nNameNode.stateChangeLog() prints the name automatically.\n\n> 7.\nDone.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-18T23:33:29.983+0000","updated":"2008-03-18T23:33:29.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12580174","id":"12580174","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"+1 Code look good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-03-18T23:49:15.961+0000","updated":"2008-03-18T23:49:15.961+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12580187","id":"12580187","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-19T00:16:39.091+0000","updated":"2008-03-19T00:16:39.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12386232/comment/12580325","id":"12580325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk #433 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/433/])","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2008-03-19T11:37:17.045+0000","updated":"2008-03-19T11:37:17.045+0000"}],"maxResults":14,"total":14,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2606/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ifnz:"}}