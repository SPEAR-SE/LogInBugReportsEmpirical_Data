{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13204489","self":"https://issues.apache.org/jira/rest/api/2/issue/13204489","key":"HADOOP-16005","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-12-16T23:56:29.896+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Dec 22 19:25:18 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-16005/watchers","watchCount":5,"isWatching":false},"created":"2018-12-14T14:53:55.301+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2019-01-10T17:10:39.477+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12328416","id":"12328416","name":"fs/azure","description":"Azure WASB filesystem client"}],"timeoriginalestimate":null,"description":"When interacting with Azure Blob Storage via the Hadoop FileSystem client, it's currently (as of [a8bbd81|https://github.com/apache/hadoop/commit/a8bbd818d5bc4762324bcdb7cf1fdd5c2f93891b]) not possible to set custom metadata attributes.\r\n\r\nHere is a snippet that demonstrates the missing behavior (throws an UnsupportedOperationException):\r\n{code:java}\r\nval blobAccount = \"SET ME\"\r\nval blobKey = \"SET ME\"\r\nval blobContainer = \"SET ME\"\r\nval blobFile = \"SET ME\"\r\n\r\nimport org.apache.hadoop.conf.Configuration\r\nimport org.apache.hadoop.fs.{FileSystem, Path}\r\n\r\nval conf = new Configuration()\r\nconf.set(\"fs.wasbs.impl\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\r\nconf.set(s\"fs.azure.account.key.$blobAccount.blob.core.windows.net\", blobKey)\r\n\r\nval path = new Path(s\"wasbs://$blobContainer@$blobAccount.blob.core.windows.net/$blobFile\")\r\n\r\nval fs = FileSystem.get(path, conf)\r\nfs.setXAttr(path, \"somekey\", \"somevalue\".getBytes)\r\n{code}\r\nLooking at the code in hadoop-tools/hadoop-azure, NativeAzureFileSystem inherits the default setXAttr from FileSystem which throws the UnsupportedOperationException.\r\n\r\nThe underlying Azure Blob Storage service does support custom metadata ([service docs|https://docs.microsoft.com/en-us/azure/storage/blobs/storage-properties-metadata]) as does the azure-storage SDK that's being used by NativeAzureFileSystem ([SDK docs|http://javadox.com/com.microsoft.azure/azure-storage/2.0.0/com/microsoft/azure/storage/blob/CloudBlob.html#setMetadata(java.util.HashMap)]).\r\n\r\nIs there another way that I should be setting custom metadata on Azure Blob Storage files? Is there a specific reason why setXAttr hasn't been implemented on NativeAzureFileSystem? If not, I can take a shot at implementing it.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"NativeAzureFileSystem does not support setXAttr","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13204489/comment/16722609","id":"16722609","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Now that Azure Datalake Gen 2 is public, abfs is the connector getting active development of new features & performance. That'd be the one to work on ... I don't see it there either.\r\n\r\nNote the strict test policy for object store patches...it's in the documentation for that tools/hadoop-azure module. Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-12-16T23:56:29.896+0000","updated":"2018-12-16T23:56:29.896+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13204489/comment/16722876","id":"16722876","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I should add: serving up the etag as the file checksum would be nice —lets you do backups which use a change in the etag as the sign of a file being out of date\r\n\r\n Look at\r\n\r\n* class to describe the etag hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/store/EtagChecksum.java\r\n * HADOOP-13282 is the change to S3A to add this; HADOOP-15287 the discovery we'd better make it optional to stop distcp backups from HDFS failing, as too many jobs weren't using {{-skipCrc}} on the command line, it ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-12-17T11:01:36.129+0000","updated":"2018-12-17T11:01:48.977+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13204489/comment/16725285","id":"16725285","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"body":"Thanks for the pointers, [~stevel@apache.org]. I'll take a stab at implementing this over the next couple of weeks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"created":"2018-12-19T19:19:28.609+0000","updated":"2018-12-19T19:19:28.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13204489/comment/16726239","id":"16726239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"body":"I started working on a branch here: [CatalystCode/hadoop-16005|https://github.com/apache/hadoop/compare/trunk...CatalystCode:hadoop-16005].\r\n\r\nNote that for now I'm implementing {{getXAttr}} and {{setXAttr}} on the old wasb connector. This is because I'm familiar with the Azure Blob Storage SDK but not with the new Azure Datalake Gen 2 API -- implementing {{getXAttr}} and {{setXAttr}} in terms of the SDKs that's more familiar for me will let me better focus on understanding the hadoop-azure codebase itself instead of also having to learn about the new Azure Datalake Gen 2 API at the same time. I'll port the changes required for {{getXAttr}} and {{setXAttr}} to abfs once I have a better understanding of what's going on in the hadoop-azure codebase overall. Hope that's okay, [~stevel@apache.org].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"created":"2018-12-20T21:42:52.884+0000","updated":"2018-12-20T21:42:52.884+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13204489/comment/16726243","id":"16726243","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"body":"It looks like {{getXAttr}} and {{setXAttr}} now work for the wasb connector ([screenshot of the attributes set by the unit test|https://user-images.githubusercontent.com/1086421/50312485-7b222c80-0476-11e9-8c8f-4595aedd115c.png]).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=c-w","name":"c-w","key":"c-w","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=c-w&avatarId=31494","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=c-w&avatarId=31494","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=c-w&avatarId=31494","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=c-w&avatarId=31494"},"displayName":"Clemens Wolff","active":true,"timeZone":"America/New_York"},"created":"2018-12-20T21:47:07.102+0000","updated":"2018-12-20T21:47:07.102+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13204489/comment/16727540","id":"16727540","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"GitHub user c-w opened a pull request:\n\n    https://github.com/apache/hadoop/pull/452\n\n    HADOOP-16005: Add XAttr support to WASB and ABFS\n\n    As discussed in [HADOOP-16005](https://issues.apache.org/jira/browse/HADOOP-16005), this pull request implements `getXAttr` and `setXAttr` on hadoop-azure's WASB and ABFS file-systems.\r\n    \r\n    The changes were tested against the following Azure storage account configurations:\r\n    \r\n    - WASB: StorageV2, RA-GRS replication in East US (primary) West US (secondary). [WASB test session screenshot](https://user-images.githubusercontent.com/1086421/50362109-699f5a00-0534-11e9-97c9-e8a7cee6e6c6.png). All tests pass and the ABFS tests are skipped as expected.\r\n    \r\n    - ABFS: StorageV2 with Data Lake Storage Gen2 preview enabled, RA-GRS replication in East US (primary) West US (secondary). [ABFS test session screenshot](https://user-images.githubusercontent.com/1086421/50361278-fea05400-0530-11e9-9cb4-cc23dec87cfc.png). All ABFS tests pass but the WASB tests fail since the storage account hasn't implemented the blob endpoints yet.\r\n    \r\n    The test-patch script passed: [test-patch output](https://user-images.githubusercontent.com/1086421/50377952-50aaad80-05f5-11e9-8ea2-b7bf99fc7509.png).\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/CatalystCode/hadoop hadoop-16005\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/hadoop/pull/452.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #452\n    \n----\ncommit 1c8303a5af1016455d23ce78508f911a10af4e77\nAuthor: Clemens Wolff <clewolff@...>\nDate:   2018-12-20T21:30:56Z\n\n    Add setXAttr and getXAttr to WASB and ABFS\n\n----\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-12-22T19:25:18.231+0000","updated":"2018-12-22T19:25:18.231+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-16005/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|s01j28:"}}