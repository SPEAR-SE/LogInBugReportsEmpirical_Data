{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12408827","self":"https://issues.apache.org/jira/rest/api/2/issue/12408827","key":"HADOOP-4684","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2008-11-21T15:54:10.379+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Nov 21 15:54:10 UTC 2008","customfield_12310420":"87681","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_168906062_*|*_1_*:*_1_*:*_1034384_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2008-11-21T15:54:10.446+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4684/watchers","watchCount":1,"isWatching":false},"created":"2008-11-19T16:41:50.797+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313211","id":"12313211","description":"","name":"0.19.0","archived":false,"released":true,"releaseDate":"2008-11-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-04-23T19:25:00.762+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"I'm running two types of workflow. The first is a set of map jobs that read from S3 using s3n://ID:SECRET@bucket/ as input and HDFS as output. The other is using distcp as a backup tool to copy the outputs of other jobs using distcp.\n\n\nbq. hadoop distcp hdfs://host:50001/user/root/from/ s3n://ID:SECRET@backup-bucket/\n\nUnfortunately, I'm getting too many failures of this kind:\n\n{code}\n08/11/19 16:08:27 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.\norg.apache.hadoop.fs.s3.S3Exception: org.jets3t.service.S3ServiceException: S3 PUT failed for '/' XML Error Message: <?xml version=\"1.0\" encoding=\"UTF-8\"?><Error><Code>OperationAborted</Code><Message>A conflicting conditional operation is currently in progress against this resource. Please try again.</Message><RequestId>324E696A4BCA8731</RequestId><HostId>{REMOVED}</HostId></Error>\n\tat org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.createBucket(Jets3tNativeFileSystemStore.java:74)\n\tat org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.initialize(Jets3tNativeFileSystemStore.java:63)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)\n\tat org.apache.hadoop.fs.s3native.$Proxy2.initialize(Unknown Source)\n\tat org.apache.hadoop.fs.s3native.NativeS3FileSystem.initialize(NativeS3FileSystem.java:215)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1339)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:56)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1351)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:213)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:158)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:210)\n\tat org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:742)\n\tat org.apache.hadoop.streaming.StreamJob.submitAndMonitorJob(StreamJob.java:925)\n\tat org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:115)\n\tat org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:33)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:155)\n\tat org.apache.hadoop.mapred.JobShell.run(JobShell.java:54)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)\n\tat org.apache.hadoop.mapred.JobShell.main(JobShell.java:68)\nCaused by: org.jets3t.service.S3ServiceException: S3 PUT failed for '/' XML Error Message: <?xml version=\"1.0\" encoding=\"UTF-8\"?><Error><Code>OperationAborted</Code><Message>A conflicting conditional operation is currently in progress against this resource. Please try again.</Message><RequestId>{REMOVED}</RequestId><HostId>{REMOVED}</HostId></Error>\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.performRequest(RestS3Service.java:424)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.performRestPut(RestS3Service.java:734)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.createObjectImpl(RestS3Service.java:1357)\n\tat org.jets3t.service.impl.rest.httpclient.RestS3Service.createBucketImpl(RestS3Service.java:1234)\n\tat org.jets3t.service.S3Service.createBucket(S3Service.java:1390)\n\tat org.jets3t.service.S3Service.createBucket(S3Service.java:1158)\n\tat org.jets3t.service.S3Service.createBucket(S3Service.java:1177)\n\tat org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.createBucket(Jets3tNativeFileSystemStore.java:69)\n\t... 29 more\n{code}\n\nThe issue is that Jets3tNativeFileSystemStore always tries to create a bucket during initialization. I'm sure that's a good thing for when s3n is used to write output, but for read operations, it'd be best if it checked for existence first. IMHO.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12394253","id":"12394253","filename":"HADOOP-4684.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliast","name":"eliast","key":"eliast","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Elias Torres","active":true,"timeZone":"Etc/UTC"},"created":"2008-11-19T16:59:52.501+0000","size":1298,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12394253/HADOOP-4684.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"104181","customfield_12312823":null,"summary":"NativeS3FileSystem always tries to create a bucket, even when used for read-only workflows.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliast","name":"eliast","key":"eliast","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Elias Torres","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliast","name":"eliast","key":"eliast","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Elias Torres","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"I tried this in Mac OSX Leopard and Ubuntu Linux on EC2","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408827/comment/12649093","id":"12649093","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliast","name":"eliast","key":"eliast","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Elias Torres","active":true,"timeZone":"Etc/UTC"},"body":"Modified Jets3tNativeFileSystemStore to check for bucket existence.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eliast","name":"eliast","key":"eliast","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Elias Torres","active":true,"timeZone":"Etc/UTC"},"created":"2008-11-19T16:59:04.380+0000","updated":"2008-11-19T16:59:04.380+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408827/comment/12649691","id":"12649691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"Duplicate of HADOOP-4422","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2008-11-21T15:54:10.379+0000","updated":"2008-11-21T15:54:10.379+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4684/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0i6pj:"}}