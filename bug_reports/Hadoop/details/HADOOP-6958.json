{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12474513","self":"https://issues.apache.org/jira/rest/api/2/issue/12474513","key":"HADOOP-6958","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2011-11-01T13:12:13.334+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sun Sep 28 19:53:28 UTC 2014","customfield_12310420":"77593","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_127067745064_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-09-28T19:53:28.154+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6958/watchers","watchCount":8,"isWatching":false},"created":"2010-09-19T03:17:43.152+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":"org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314203","id":"12314203","description":"","name":"0.20.2","archived":false,"released":true,"releaseDate":"2010-02-16"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-09-28T19:53:28.202+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"hello,\n  I am using hadoop-0.20.2 and hadoop semi-cluster run in a server and the datas only 800M .\n  The problem is when the hadoop running a period of time (more than 1 hours),it not work. I am look up the log and find the exception: \"INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_201009161411_0368/attempt_201009161411_0368_m_000002_0/output/file.out in any of the configured local directories\"\n\tI googled many blogs and web pages but I could neither understand why this happens nor found a solution to this. What does that error message mean and how can avoid it, any suggestions?\n\tI've confused the problem for a week already, Please sharing if you know what could be causing this, Thinks in advance!\n\nConfiguration File:\n<!--hadoop-site.xml-->\t\n\t<configuration>\n   <property>\n     <name>mapred.child.tmp</name>\n     <value>/data/hadoop-tmp</value>\n   </property>\n   <property>\n     <name>hadoop.tmp.dir</name>\n     <value>/data/hadoop-tmp</value>\n   </property>\n   <property>\n     <name>mapred.local.dir</name>\n     <value>/data/hadoop-tmp</value>\n   </property>\n </configuration>\n\t\n<!--core-site.xml-->\n\t<configuration>\n   <property>\n    <name>fs.default.name</name>\n    <value>hdfs://10.0.0.8:8020</value>\n   </property>\n  </configuration>\n \n<!--mapred-site.xml--> \n  <configuration>\n   <property>\n     <name>mapred.job.tracker</name>\n     <value>10.0.0.8:8021</value>\n   </property>\n </configuration>\n  \n<!--hdfs-site.xml-->\n  <configuration>\n   <property>\n    <name>dfs.name.dir</name>\n    <value>/data/name</value>\n   </property>\n   <property>\n    <name>dfs.data.dir</name>\n    <value>/data/data</value>  \n   </property>\n   <property>\n    <name>dfs.replication</name>\n    <value>1</value>\n   </property>\n  </configuration>\n\n\n\nERROR Logs:\nINFO org.apache.hadoop.mapred.TaskTracker: LaunchTaskAction (registerTask): attempt_201009161411_0368_r_000000_0 task's state:UNASSIGNED\nINFO org.apache.hadoop.mapred.TaskTracker: Trying to launch : attempt_201009161411_0368_r_000000_0\nINFO org.apache.hadoop.mapred.TaskTracker: In TaskLauncher, current free slots : 2 and trying to launch attempt_201009161411_0368_r_000000_0\nINFO org.apache.hadoop.mapred.JvmManager: In JvmRunner constructed JVM ID: jvm_201009161411_0368_r_1871094354\nINFO org.apache.hadoop.mapred.JvmManager: JVM Runner jvm_201009161411_0368_r_1871094354 spawned.\nINFO org.apache.hadoop.mapred.TaskTracker: JVM with ID: jvm_201009161411_0368_r_1871094354 given task: attempt_201009161411_0368_r_000000_0\nINFO org.apache.hadoop.mapred.TaskTracker: Sent out 381650 bytes for reduce: 0 from map: attempt_201009161411_0368_m_000000_0 given 381650/381646\nINFO org.apache.hadoop.mapred.TaskTracker.clienttrace: src: 10.0.0.8:50060, dest: 10.0.0.8:58884, bytes: 381650, op: MAPRED_SHUFFLE, cliID: attempt_201009161411_0368_m_000000_0\nINFO org.apache.hadoop.mapred.TaskTracker: Sent out 384812 bytes for reduce: 0 from map: attempt_201009161411_0368_m_000001_0 given 384812/384808\nINFO org.apache.hadoop.mapred.TaskTracker.clienttrace: src: 10.0.0.8:50060, dest: 10.0.0.8:58884, bytes: 384812, op: MAPRED_SHUFFLE, cliID: attempt_201009161411_0368_m_000001_0\nINFO org.apache.hadoop.mapred.TaskTracker: attempt_201009161411_0368_r_000000_0 0.16666667% reduce > copy (1 of 2 at 0.06 MB/s) > \nINFO org.apache.hadoop.mapred.TaskTracker: attempt_201009161411_0368_r_000000_0 0.16666667% reduce > copy (1 of 2 at 0.06 MB/s) > \nINFO org.apache.hadoop.mapred.TaskTracker: attempt_201009161411_0368_r_000000_0 0.16666667% reduce > copy (1 of 2 at 0.06 MB/s) > \nINFO org.apache.hadoop.mapred.TaskTracker: Task attempt_201009161411_0368_r_000000_0 is in commit-pending, task state:COMMIT_PENDING\nINFO org.apache.hadoop.mapred.TaskTracker: attempt_201009161411_0368_r_000000_0 0.16666667% reduce > copy (1 of 2 at 0.06 MB/s) > \nINFO org.apache.hadoop.mapred.TaskTracker: Received commit task action for attempt_201009161411_0368_r_000000_0\nINFO org.apache.hadoop.mapred.TaskTracker: attempt_201009161411_0368_r_000000_0 1.0% reduce > reduce\nINFO org.apache.hadoop.mapred.TaskTracker: Task attempt_201009161411_0368_r_000000_0 is done.\nINFO org.apache.hadoop.mapred.TaskTracker: reported output size for attempt_201009161411_0368_r_000000_0  was 0\nINFO org.apache.hadoop.mapred.TaskTracker: addFreeSlot : current free slots : 2\nINFO org.apache.hadoop.mapred.JvmManager: JVM : jvm_201009161411_0368_r_1871094354 exited. Number of tasks it ran: 1\nINFO org.apache.hadoop.mapred.TaskTracker: LaunchTaskAction (registerTask): attempt_201009161411_0368_m_000002_0 task's state:UNASSIGNED\nINFO org.apache.hadoop.mapred.TaskTracker: Trying to launch : attempt_201009161411_0368_m_000002_0\nINFO org.apache.hadoop.mapred.TaskTracker: Received KillTaskAction for task: attempt_201009161411_0368_r_000000_0\nINFO org.apache.hadoop.mapred.TaskTracker: In TaskLauncher, current free slots : 2 and trying to launch attempt_201009161411_0368_m_000002_0\nINFO org.apache.hadoop.mapred.TaskTracker: About to purge task: attempt_201009161411_0368_r_000000_0\nINFO org.apache.hadoop.mapred.TaskRunner: attempt_201009161411_0368_r_000000_0 done; removing files.\nINFO org.apache.hadoop.mapred.JvmManager: In JvmRunner constructed JVM ID: jvm_201009161411_0368_m_2026394863\nINFO org.apache.hadoop.mapred.JvmManager: JVM Runner jvm_201009161411_0368_m_2026394863 spawned.\nINFO org.apache.hadoop.mapred.TaskTracker: JVM with ID: jvm_201009161411_0368_m_2026394863 given task: attempt_201009161411_0368_m_000002_0\nINFO org.apache.hadoop.mapred.TaskTracker: attempt_201009161411_0368_m_000002_0 0.0% \nINFO org.apache.hadoop.mapred.TaskTracker: attempt_201009161411_0368_m_000002_0 0.0% cleanup\nINFO org.apache.hadoop.mapred.TaskTracker: Task attempt_201009161411_0368_m_000002_0 is done.\nINFO org.apache.hadoop.mapred.TaskTracker: reported output size for attempt_201009161411_0368_m_000002_0  was 0\nINFO org.apache.hadoop.mapred.TaskTracker: addFreeSlot : current free slots : 2\nINFO org.apache.hadoop.mapred.JvmManager: JVM : jvm_201009161411_0368_m_2026394863 exited. Number of tasks it ran: 1\nINFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_201009161411_0368/attempt_201009161411_0368_m_000002_0/output/file.out in any of the configured local directories\nINFO org.apache.hadoop.mapred.TaskTracker: Received 'KillJobAction' for job: job_201009161411_0368\nINFO org.apache.hadoop.mapred.TaskRunner: attempt_201009161411_0368_m_000000_0 done; removing files.\nINFO org.apache.hadoop.mapred.TaskRunner: attempt_201009161411_0368_m_000002_0 done; removing files.\nINFO org.apache.hadoop.mapred.IndexCache: Map ID attempt_201009161411_0368_m_000002_0 not found in cache\nINFO org.apache.hadoop.mapred.TaskRunner: attempt_201009161411_0368_m_000001_0 done; removing files.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"102870","customfield_12312823":null,"summary":"org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phenixmzy","name":"phenixmzy","key":"phenixmzy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"mazhiyong","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phenixmzy","name":"phenixmzy","key":"phenixmzy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"mazhiyong","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"linux\njdk1.6.0_20\nhadoop 0.20.2","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12474513/comment/13141146","id":"13141146","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hungrytom","name":"hungrytom","key":"hungrytom","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom Wilcox","active":true,"timeZone":"Etc/UTC"},"body":"We are experiencing the same problem.\n\nWe have a cluster of HyperV VM's running Scientific Linux and Hadoop 0.20.2.\n\n1 VM for Namenode & SecondaryNamenode\n1 VM for Jobtracker\n3 VMs for DN/TT each\n\nEach machine shares the same configuration with:\n\nmapred.local.dir=/mapred\nmapred.system.dir=/hadoop/mapred/system\ndfs.name.dir=/hdfs/namespace,/hdfs_dupe/namespace\ndfs.data.dir=/hdfs/data\nhadoop.tmp.dir=/tmp\n\nWhen running the example provided in the Getting Started tutorials we are getting this error in the tasktracker (TT) running the single reduce task\n\n2011-11-01 13:07:24,310 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(attempt_201110312140_0003_m_000010_0,0) failed :\norg.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_201110312140_0003/attempt_201110312140_0003_m_000010_0/output/f\nile.out.index in any of the configured local directories\n        at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:389)\n        at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:138)\n        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:2887)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n        at org.mortbay.jetty.Server.handle(Server.java:324)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)\n        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)\n\n2011-11-01 13:07:24,310 WARN org.apache.hadoop.mapred.TaskTracker: Unknown child with bad map output: attempt_201110312140_0003_m_000010_0. Ignored.\n2011-11-01 13:07:24,310 INFO org.apache.hadoop.mapred.TaskTracker.clienttrace: src: 127.0.0.1:50060, dest: 127.0.0.1:38338, bytes: 0, op: MAPRED_SHUFFLE, cliI\nD: attempt_201110312140_0003_m_000010_0\n2011-11-01 13:07:24,310 WARN org.mortbay.log: /mapOutput: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_20111\n0312140_0003/attempt_201110312140_0003_m_000010_0/output/file.out.index in any of the configured local directories\n2011-11-01 13:07:25,237 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) >\n2011-11-01 13:07:28,238 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) >\n2011-11-01 13:07:29,328 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(attempt_201110312140_0003_m_000010_0,0) failed :\norg.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_201110312140_0003/attempt_201110312140_0003_m_000010_0/output/f\nile.out.index in any of the configured local directories\n        at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:389)\n        at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:138)\n        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:2887)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)\n:\n\n\n\nAny and all help will be much appreciated.\n\nCheers,\nTom","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hungrytom","name":"hungrytom","key":"hungrytom","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom Wilcox","active":true,"timeZone":"Etc/UTC"},"created":"2011-11-01T13:12:13.334+0000","updated":"2011-11-01T13:12:13.334+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12474513/comment/13141148","id":"13141148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hungrytom","name":"hungrytom","key":"hungrytom","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom Wilcox","active":true,"timeZone":"Etc/UTC"},"body":"Bit more log in case it helps:\n\n2011-11-01 13:09:55,298 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:09:58,299 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:04,301 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:09,349 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(attempt_201110312140_0003_m_000010_0,0) failed :\norg.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_201110312140_0003/attempt_201110312140_0003_m_000010_0/output/file.out.index in any of the configured local directories\n\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:389)\n\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:138)\n\tat org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:2887)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:324)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)\n\n2011-11-01 13:10:09,350 WARN org.apache.hadoop.mapred.TaskTracker: Unknown child with bad map output: attempt_201110312140_0003_m_000010_0. Ignored.\n2011-11-01 13:10:09,354 INFO org.apache.hadoop.mapred.TaskTracker.clienttrace: src: 127.0.0.1:50060, dest: 127.0.0.1:38341, bytes: 0, op: MAPRED_SHUFFLE, cliID: attempt_201110312140_0003_m_000010_0\n2011-11-01 13:10:09,354 WARN org.mortbay.log: /mapOutput: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_201110312140_0003/attempt_201110312140_0003_m_000010_0/output/file.out.index in any of the configured local directories\n2011-11-01 13:10:10,303 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:13,304 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:19,306 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:25,308 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:28,309 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:34,312 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:40,314 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:43,315 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:49,317 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:55,319 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:10:58,320 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:11:04,322 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:11:10,326 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:11:13,327 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:11:19,329 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:11:25,331 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) > \n2011-11-01 13:11:28,332 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201110312140_0003_r_000000_1 0.051282056% reduce > copy (2 of 13 at 0.00 MB/s) >","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hungrytom","name":"hungrytom","key":"hungrytom","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom Wilcox","active":true,"timeZone":"Etc/UTC"},"created":"2011-11-01T13:16:05.050+0000","updated":"2011-11-01T13:16:05.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12474513/comment/13141221","id":"13141221","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hungrytom","name":"hungrytom","key":"hungrytom","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom Wilcox","active":true,"timeZone":"Etc/UTC"},"body":"The answer to this problem (for me at least) was that the contents of the /etc/hosts file..\n\nAfter reading this:\n\nhttp://www.mail-archive.com/core-user@hadoop.apache.org/msg03635.html\n\nI did this:\n\nAdded lines to my /etc/hosts file so it looked like this:\n\n\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n\n10.0.0.235      namenode secondarynamenode\n10.0.0.236      jobtracker\n10.0.0.237      slave0\n10.0.0.238      slave1\n10.0.0.239      slave2\n\nThen on each machine I overwrote the /etc/hosts file with that above and then executed the following:\n\nsudo hostname namenode (on 10.0.0.235)\nOR \nsudo hostname jobtracker (on 10.0.0.236)\nOR \nsudo hostname slave0 (on 10.0.0.237)\nOR \nsudo hostname slave1 (on 10.0.0.238)\nOR \nsudo hostname slave2 (on 10.0.0.239)\n\nThen I rebooted all machines in the cluster, disabled the firewalls on all and reran the job successfully!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hungrytom","name":"hungrytom","key":"hungrytom","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom Wilcox","active":true,"timeZone":"Etc/UTC"},"created":"2011-11-01T15:04:06.186+0000","updated":"2011-11-01T15:04:06.186+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12474513/comment/13206683","id":"13206683","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prajor","name":"prajor","key":"prajor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"R Patrao","active":true,"timeZone":"Etc/UTC"},"body":"I followed the steps on naming the hosts etc, unfortunately I have only two servers. I named one as namenode and another as slave. but I have put all ip entries (jobtracker, tasktracker etc) in /etc/hosts. It is not solving the problem. Is there a patch or solution that we should wait for ? is it fixed in 1.0 beta ? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=prajor","name":"prajor","key":"prajor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"R Patrao","active":true,"timeZone":"Etc/UTC"},"created":"2012-02-13T05:15:40.504+0000","updated":"2012-02-13T05:15:40.504+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12474513/comment/14151024","id":"14151024","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dobromyslov","name":"dobromyslov","key":"dobromyslov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Dobromyslov","active":true,"timeZone":"Asia/Vladivostok"},"body":"I solved it by editing the /etc/hosts.\nAll your nodes MUST have real net IP addresses instead of 127.0.0.1 or localhost.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dobromyslov","name":"dobromyslov","key":"dobromyslov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Viacheslav Dobromyslov","active":true,"timeZone":"Asia/Vladivostok"},"created":"2014-09-28T08:51:01.902+0000","updated":"2014-09-28T08:51:01.902+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12474513/comment/14151194","id":"14151194","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Hadoop requires working host name resolution.  Closing as won't fix.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-09-28T19:53:28.191+0000","updated":"2014-09-28T19:53:28.191+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-6958/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0hym7:"}}