{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13187158","self":"https://issues.apache.org/jira/rest/api/2/issue/13187158","key":"HADOOP-15782","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-09-25T11:43:24.286+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Oct 29 19:50:08 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15782/watchers","watchCount":2,"isWatching":false},"created":"2018-09-24T23:57:45.443+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341432","id":"12341432","description":"3.1.0 release","name":"3.1.0","archived":false,"released":true,"releaseDate":"2018-04-06"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12342984","id":"12342984","description":"3.1.1 release","name":"3.1.1","archived":false,"released":true,"releaseDate":"2018-08-07"}],"issuelinks":[{"id":"12543951","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12543951","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13124028","key":"HADOOP-15107","self":"https://issues.apache.org/jira/rest/api/2/issue/13124028","fields":{"summary":"Stabilize/tune S3A committers; review correctness & docs","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-10-29T19:50:08.166+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311160","id":"12311160","name":"documentation"}],"timeoriginalestimate":null,"description":"The doc file {{hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/committers.md}} refers to the default file output committer (v2) as not supporting job and task recovery throughout the doc:\r\n{quote}or just by rerunning everything (The \"v2\" algorithm and Spark).\r\n{quote}\r\nThis is incorrect.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Clarify committers.md around v2 failure handling","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira.shegalov","name":"jira.shegalov","key":"jira.shegalov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gera Shegalov","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira.shegalov","name":"jira.shegalov","key":"jira.shegalov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gera Shegalov","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13187158/comment/16626583","id":"16626583","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira.shegalov","name":"jira.shegalov","key":"jira.shegalov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gera Shegalov","active":true,"timeZone":"America/Los_Angeles"},"body":"cc [~stevel@apache.org]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira.shegalov","name":"jira.shegalov","key":"jira.shegalov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gera Shegalov","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-09-24T23:58:40.187+0000","updated":"2018-09-24T23:58:40.187+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13187158/comment/16627203","id":"16627203","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"how about this \"not sure that v2 task recovery is correct\"\r\n\r\nSpecifically: v2 task commit renames from attempt dir into destination. If that fails partway through, then both MR and spark assume that the entire task can be retried. Which has the following flaws\r\n\r\n* a rerun task may generate files with different names. If this holds, those files from the first attempt which are copied into place will still be there. Outcome: output of two attempts may be in the destination.\r\n* if the created filenames are the same, if the first attempt hasn't actually failed, but instead paused for some time, but then resumes (GC pauses, VM hangs etc), then the first attempt will continue its rename, and potentially then overwriting 1+ file of the previous attempts output. Outcome: the data may be a mix of two attempts.\r\n\r\nIf each attempt creates precisely one file, and the name of the file is the same on both, then these problems don't arise. There's no partial commit of files; the second attempt will overwrite the first completely, and, if a paused attempt resumes, then it will completely overwrite the output of the latter. Provided that doesn't happen partway through ongoing work (deletion of task attempt dirs will cause the rename to fail, obviously), then the requirement for speculative/retriable tasks \"output from either attempt is valid\" will be met  —downstream code will have to deal with it.\r\n\r\nThat said, happy to be wrong, if I've misunderstood something —that commit code is complex enough that I had to step through with a debugger taking notes to understand what was going on.\r\n\r\nRight now I don't trust v2. it's worse on object stores as time-to-rename is potentially much longer, so probability of task failure during rename is higher.\r\n\r\nSee also [a zero rename committer|https://github.com/steveloughran/zero-rename-committer/releases/download/tag_draft_003/a_zero_rename_committer.pdf]; review & corrections welcome there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-09-25T11:43:24.286+0000","updated":"2018-09-25T11:43:24.286+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13187158/comment/16627206","id":"16627206","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"BTW, HADOOP-15107 updated that committer docs a lot; if you haven't looked at the 3.1.2+ version of the docs, start there","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-09-25T11:45:48.080+0000","updated":"2018-09-25T11:45:48.080+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13187158/comment/16627210","id":"16627210","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"PS: spark recovery is, AFAIK, always by rerunning entire job; it's only task recovery it attempts —and there it assumes that task attempts can always be retried. I now believe that in the absence of atomic/recoverable task commits, it & MR need to treat failures during task commit as special from failures during task execution.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-09-25T11:49:47.550+0000","updated":"2018-09-25T11:49:47.550+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13187158/comment/16630524","id":"16630524","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira.shegalov","name":"jira.shegalov","key":"jira.shegalov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gera Shegalov","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the comments [~stevel@apache.org]. I was looking at committers.md in trunk.  I mostly agree. v2 was designed with atomic rename semantics in mind, and any FileSystem implementation that does not provide it will be vulnerable to inconsistencies. However, the section on hadoop committers is called \"Background\" which is the good old atomic rename world on HDFS executed by MapReduce . \r\n{quote}a rerun task may generate files with different names. If this holds, those files from the first attempt which are copied into place will still be there. Outcome: output of two attempts may be in the destination.\r\n{quote}\r\nCorrect, but this is a user error to have any kind non-determinism between task attempts. I always remind my coworkers to set seeds for Random based on a hash of something repeatable like task id excluding attempt Id  and not use anything like the default currentTimeMillis. Let alone generate files with different names. Rereading this a few times I realize that you might also include the case of multi-file outputs which makes even the task commit non-atomic.  \r\n{quote}if the created filenames are the same, if the first attempt hasn't actually failed, but instead paused for some time, but then resumes (GC pauses, VM hangs etc), then the first attempt will continue its rename, and potentially then overwriting 1+ file of the previous attempts output. Outcome: the data may be a mix of two attempts.\r\n{quote}\r\nOnly one attempt is allowed to commit via canCommit and with deterministic output + atomic rename works anyway.\r\n{quote}Right now I don't trust v2. it's worse on object stores as time-to-rename is potentially much longer, so probability of task failure during rename is higher.\r\n{quote}\r\nI understand, but for previously typical cases (HDFS, single output file per attempt) it is robust. Once you realize that even on HDFS v1 was noticeably non-atomic for large jobs and you need to check for _SUCCESS or have another service recording completion, v2 was a big improvement for Twitter.\r\n\r\nI am just about to familiarize myself with Spark's use of FOC ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jira.shegalov","name":"jira.shegalov","key":"jira.shegalov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Gera Shegalov","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-09-27T14:30:52.130+0000","updated":"2018-09-27T14:30:52.130+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13187158/comment/16631607","id":"16631607","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"bq. Only one attempt is allowed to commit via canCommit and with deterministic output + atomic rename works anyway.\r\n\r\nyes, but if that attempt is considered to have failed, an alternative attempt may commit. At least, that's my reading of the code in Hadoop and spark. Now, provided that only one file is generated by a task attempt, and the output of any attempt can be accepted, then a long-delayed task commit *shouldnt* be harmful, at least if it happens while the job is in progress. If it happens after the job has completed, well, that's \"unusual\"\r\n\r\nI've never seen that happening, it is a failure mode to be considered if you want to be able to show that your algorithm is robust. The MR job committer explicitly checks before job commit that it's had a recent heartbeat with the YARN RM to avoid this and cluster partition problems at the job level; nothing worries about it for individual tasks.\r\n\r\nbq. even on HDFS v1 was noticeably non-atomic for large jobs and you need to check for _SUCCESS or have another service recording completion, v2 was a big improvement for Twitter.\r\n\r\nYes: neither committer is fully atomic at some phases in its operation\r\n\r\nThe S3A ones don't have atomic job commit either; just O(files) POST requests which can be done in parallel. They do at least deliver atomic task commit (at least I believe so...).\r\n\r\n\r\nbq. I am just about to familiarize myself with Spark's use of FOC \r\n\r\nit doesn't need to worry about job restart, so life is simpler. Still uses the MRv1 APIs though, which they should be weaned off (And in Hadoop MR: deprecated)\r\n\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-09-28T09:35:24.675+0000","updated":"2018-09-28T09:35:24.675+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13187158/comment/16667656","id":"16667656","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"BTW, do you have a patch for this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-10-29T19:50:08.166+0000","updated":"2018-10-29T19:50:08.166+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15782/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3yfyv:"}}