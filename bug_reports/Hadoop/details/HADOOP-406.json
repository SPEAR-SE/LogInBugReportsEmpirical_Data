{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12347075","self":"https://issues.apache.org/jira/rest/api/2/issue/12347075","key":"HADOOP-406","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2006-08-24T12:59:23.000+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu May 24 06:37:01 UTC 2007","customfield_12310420":"124786","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_25539269373_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_4718731061","customfield_12312321":null,"resolutiondate":"2007-05-24T06:37:01.373+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-406/watchers","watchCount":2,"isWatching":false},"created":"2006-08-01T16:22:32.000+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12311021","id":"12311021","description":"","name":"0.4.0","archived":false,"released":true,"releaseDate":"2006-06-28"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:51:52.149+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Child JVM's don't have access to logging config system properties. When the child JVM gets launched, it doesn't inherit the Java system properties hadoop.log.dir and hadoop.log.file (which are actually based on the Bash environment variables $HADOOP_LOG_DIR and $HADOOP_LOGFILE). This means that you get no log messages from the actual map/reduce tasks that are executing.\n\nStefan Groschupf reported this problem a while back:\n\n-------------------------------------------------------------------------\nTo: hadoop-dev@lucene.apache.org\nFrom: Stefan Groschupf <sg@media-style.com>\nSubject: tasks can't log bug?\nDate: Tue, 25 Jul 2006 19:26:17 -0700\nX-Virus-Checked: Checked by ClamAV on apache.org\n\nHi Hadoop developers,\n\nI'm confused about the way logging works within map or reduce tasks.\nSince tasks are launched in a new JVM  the java system properties \"hadoop.log.dir\" and \"hadoop.log.file\" are not passed to the new JVM.\nThis prevents the child process from logging properly. In fact you get:\n\n java.io.FileNotFoundException: / (Is a directory)\n  at java.io.FileOutputStream.openAppend(Native Method)\n  at java.io.FileOutputStream.<init>(FileOutputStream.java:177)\n  at java.io.FileOutputStream.<init>(FileOutputStream.java:102)\n  at org.apache.log4j.FileAppender.setFile(FileAppender.java:289)\n  at org.apache.log4j.RollingFileAppender.setFile(RollingFileAppender.java:165)\n  at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:163)\n  at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:256)\n  at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:132)\n  at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:96)\n  at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:654)\n  at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:612)\n  at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.j\n2006-07-25 15:59:07,553 INFO  mapred.TaskTracker (TaskTracker.java:main(993)) - Child\n  at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:415)\n  at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:441)\n  at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:4\n  at org.apache.log4j.LogManager.<clinit>(LogManager.java:122)\n  at org.apache.log4j.Logger.getLogger(Logger.java:104)\n  at org.apache.commons.logging.impl.Log4JLogger.getLogger(Log4JLogger.java:229)\n  at org.apache.commons.logging.impl.Log4JLogger.<init>(Log4JLogger.java:65)\n  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImp\n  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAcc\n  at java.lang.reflect.Constructor.newInstance(Constructor.java:494)\n  at org.apache.commons.logging.impl.LogFactoryImpl.newInstance(LogFactoryImpl.java:529\n  at org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:235\n  at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:370)\n  at org.apache.hadoop.mapred.TaskTracker.<clinit>(TaskTracker.java:44)\n  at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:993)\n\nWe see several ways to solve this problem. First retrieve the properties \"hadoop.log.dir\" and \"hadoop.log.file\" from the mother JVM and then pass them to the child JVM as within the args parameter.\nSecond would be to  access the environment variables \"$HADOOP_LOG_DIR\" and \"$HADOOP_LOGFILE\" using System.getEnv (java 1.5).\nThird there would be a more general solution. Taskrunner would resolve any environment variables it found in \"mapred.child.java.opts\" by lookup the value using System.getEnv().\nEg:\nunix:\nexport MAX_MEMORY = 200\nhadoop-site.xml:\n<name>mapred.child.java.opts</name>\n<value>-Xmx${MAX_MEMORY}</value>\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12337915","id":"12337915","filename":"HADOOP-406.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=schmed","name":"schmed","key":"schmed","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Schneider","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-08-01T16:46:25.000+0000","size":3587,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12337915/HADOOP-406.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107094","customfield_12312823":null,"summary":"Tasks launched by tasktracker in separate JVM can't generate log output","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=schmed","name":"schmed","key":"schmed","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Schneider","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=schmed","name":"schmed","key":"schmed","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Schneider","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12424926","id":"12424926","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=schmed","name":"schmed","key":"schmed","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Schneider","active":true,"timeZone":"America/Los_Angeles"},"body":"Here's a patch that provides one solution to the problem.\n\nI modified TaskRunner.java so that it supports elements like -Dhadoop.log.dir=@property[hadoop.log.dir]@ within the mapred.child.java.opts Hadoop configuration property (replacing @property[hadoop.log.dir]@ with this property value).\n\nIf others agree that this is the appropriate way to solve the problem, then we should probably modify mapred.child.java.opts in hadoop-default.xml to include all 5 of the items in the default $HADOOP_OPTS (hadoop.log.dir, hadoop.log.file, hadoop.home.dir, hadoop.id.str, and hadoop.root.logger), using this method. A few notes, though:\n\n1) This creates yet another dependency on the contents of $HADOOP_OPTS (i.e., anyone that adds items to this should probably add them to mapred.child.java.opts as well.) This is less than elegant.\n\n2) It doesn't seem like hadoop.home.dir, hadoop.id.str, and hadoop.root.logger are actually being used currently by the code. Both hadoop.home.dir and hadoop.id.str are loaded by LogFormatter.initFileHandler(), but that method doesn't seem to be used by anyone. It doesn't seem like anyone is loading hadoop.root.logger at all.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=schmed","name":"schmed","key":"schmed","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Schneider","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-08-01T16:46:25.000+0000","updated":"2006-08-01T16:46:25.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12430233","id":"12430233","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dougcook","name":"dougcook","key":"dougcook","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cook","active":true,"timeZone":"Etc/UTC"},"body":"This issue bit me as well, and it took me some time to unravel the mystery. It would be nice to fix it in the main distribution!\n\nI'm agnostic about what the long-term \"right\" solution is, but Chris's patch certainly works for me. (Thanks, Chris!)\n\nDoug","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dougcook","name":"dougcook","key":"dougcook","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cook","active":true,"timeZone":"Etc/UTC"},"created":"2006-08-24T12:59:23.000+0000","updated":"2006-08-24T12:59:23.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12431047","id":"12431047","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"The way this is currently supposed to work is that child processes log to standard output, and standard output is logged by the parent process (the task tracker).  Is that not working for you?\n\nLonger-term, we probably do not want child processes opening log files directly.  Rather, they should be configured with a logger that, for each line logged, makes an RPC to the parent process, passing the level and log message.  Then the tasktracker can log things accordingly.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-08-28T19:48:10.000+0000","updated":"2006-08-28T19:48:10.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12431080","id":"12431080","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dougcook","name":"dougcook","key":"dougcook","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cook","active":true,"timeZone":"Etc/UTC"},"body":"Hi, Doug.\n\nThe task trackers were definitely not logging the fetcher output until I applied and enabled this patch. Perhaps there is another bug, or something I simply misconfigured (I am rather new at this). I am running on a single MP machine; don't know if that makes any difference.\n\nAs I said, I'm agnostic about the solution, but given discussions about this on the Nutch forum,  there seem to be others who see the same problem.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dougcook","name":"dougcook","key":"dougcook","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cook","active":true,"timeZone":"Etc/UTC"},"created":"2006-08-28T21:37:38.000+0000","updated":"2006-08-28T21:37:38.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12431083","id":"12431083","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Since I don't see this, it is hard for me to guess what's going on.  Perhaps you can tell more about your installation: OS, JVM, config, etc.  Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-08-28T21:48:25.000+0000","updated":"2006-08-28T21:48:25.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12439994","id":"12439994","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=schmed","name":"schmed","key":"schmed","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Schneider","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry it took me so long to get back to this. I have just integrated Hadoop 0.5 and was about to back out my changes and install a more standard configuration when I noticed what I believe is the problem. The log4j.properties file we use doesn't default to the console logger like the standard log4j.properties does.\n\nOur log4j.properties file:\n\n  # RootLogger - DailyRollingFileAppender\n  log4j.rootLogger=INFO,DRFA\n\nVanilla log4j.properties file:\n\n  hadoop.root.logger=INFO,console\n\nThus, when the child JVM is launched, it's going to try to use our DRFA logger, not send its log output to standard output. Note that before Owen fixed HADOOP-279, running without the hadoop script broke logging (probably in a similar way), and the child JVM is launched without the hadoop script.\n\nOwen should probably comment on this, but it seems that the \"child processes log to standard output, and standard output is logged by the parent process\" design requires that every log4j.properties file must have console in its hadoop.root.logger.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=schmed","name":"schmed","key":"schmed","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Schneider","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-04T23:07:40.000+0000","updated":"2006-10-04T23:07:40.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12461934","id":"12461934","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=positron","name":"positron","key":"positron","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dominik Friedrich","active":true,"timeZone":"Etc/UTC"},"body":"I ran into this problem with hadoop 0.9.2, too. Upgrading log4j to version 1.2.14 seems to have solved the problem.\n\nrlog4j:ERROR setFile(null,true) call failed.\njava.io.FileNotFoundException: / (Invalid argument)\n\tat java.io.FileOutputStream.openAppend(Native Method)\n\tat java.io.FileOutputStream.(FileOutputStream.java:177)\n\tat java.io.FileOutputStream.(FileOutputStream.java:102)\n\tat org.apache.log4j.FileAppender.setFile(FileAppender.java:289)\n\tat org.apache.log4j.FileAppender.activateOptions(FileAppender.java:163)\n\tat org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:215)\n\tat org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:256)\n\tat org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:132)\n\tat org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:96)\n\tat org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:654)\n\tat org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:612)\n\tat org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:509)\n\tat org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:415)\n\tat org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:441)\n\tat org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:468)\n\tat org.apache.log4j.LogManager.(LogManager.java:122)\n\tat org.apache.log4j.Logger.getLogger(Logger.java:104)\n\tat org.apache.commons.logging.impl.Log4JLogger.getLogger(Log4JLogger.java:229)\n\tat org.apache.commons.logging.impl.Log4JLogger.(Log4JLogger.java:65)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:494)\n\tat org.apache.commons.logging.impl.LogFactoryImpl.newInstance(LogFactoryImpl.java:529)\n\tat org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:235)\n\tat org.apache.commons.logging.LogFactory.getLog(LogFactory.java:370)\n\tat org.apache.hadoop.mapred.TaskTracker.(TaskTracker.java:57)\n\tat org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1367)\nlog4j:ERROR Either File or DatePattern options are not set for appender [DRFA].\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=positron","name":"positron","key":"positron","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dominik Friedrich","active":true,"timeZone":"Etc/UTC"},"created":"2007-01-03T10:39:06.373+0000","updated":"2007-01-03T10:39:06.373+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12461953","id":"12461953","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=positron","name":"positron","key":"positron","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dominik Friedrich","active":true,"timeZone":"Etc/UTC"},"body":"Please ignore my previous comment. It worked after the upgrade only because there were no mapred errors that had to be logged. I should have read the all comments to figure out that the log appender causes this problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=positron","name":"positron","key":"positron","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dominik Friedrich","active":true,"timeZone":"Etc/UTC"},"created":"2007-01-03T13:43:37.103+0000","updated":"2007-01-03T13:43:37.103+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347075/comment/12498505","id":"12498505","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"This was resolved by giving the child jvm a special logger that captures it as part of the job and provides it via http.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-05-24T06:37:01.355+0000","updated":"2007-05-24T06:37:01.355+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-406/votes","votes":4,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ioov:"}}