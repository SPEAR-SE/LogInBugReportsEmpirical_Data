{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12702252","self":"https://issues.apache.org/jira/rest/api/2/issue/12702252","key":"HADOOP-10412","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-06-23T12:11:51.092+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Jun 23 12:11:51 UTC 2014","customfield_12310420":"380592","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-10412/watchers","watchCount":4,"isWatching":false},"created":"2014-03-18T21:10:41.592+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12325048","id":"12325048","description":"2.2.0 release","name":"2.2.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-06-23T12:11:51.092+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310688","id":"12310688","name":"ipc","description":""}],"timeoriginalestimate":null,"description":"This seems to happen only for ProtobufRpc based services. Could not reproduce using simple WritableRpc.\n\nSteps to reproduce :\nConsider the case of namenode HA failover. nn1 and nn2 are both namenodes, nn1 is 'active' and nn2 is 'standby'\n1) Bring down nn1 process. Now nn2 is active\n2) Bring nn1 process back up. Now nn1 is standby and nn2 is active.\n3) Manually issue failover using command :\n{quote}\n$ hdfs haadmin -failover nn2 nn1\n{quote}\n\nIt is observed that the first call always fails with the Following exception :\n{quote}\nOperation failed: Failed to become active. Couldn't make NameNode at centos62-2/192.168.2.202:8020 active\njava.io.IOException: Failed on local exception: java.io.EOFException; Host Details : local host is: \"centos62-2/192.168.2.202\"; destination host is: \"centos62-2\":8020;\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1351)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1300)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n\tat com.sun.proxy.$Proxy8.transitionToActive(Unknown Source)\n\tat org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB.transitionToActive(HAServiceProtocolClientSideTranslatorPB.java:100)\n\tat org.apache.hadoop.ha.HAServiceProtocolHelper.transitionToActive(HAServiceProtocolHelper.java:48)\n\tat org.apache.hadoop.ha.ZKFailoverController.becomeActive(ZKFailoverController.java:373)\n\tat org.apache.hadoop.ha.ZKFailoverController.access$900(ZKFailoverController.java:59)\n\tat org.apache.hadoop.ha.ZKFailoverController$ElectorCallbacks.becomeActive(ZKFailoverController.java:818)\n\tat org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:803)\n\tat org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:415)\n\tat org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:596)\n\tat org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:495)\nCaused by: java.io.EOFException\n\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:995)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:891)\n\n\tat org.apache.hadoop.ha.ZKFailoverController.doGracefulFailover(ZKFailoverController.java:673)\n\tat org.apache.hadoop.ha.ZKFailoverController.access$400(ZKFailoverController.java:59)\n\tat org.apache.hadoop.ha.ZKFailoverController$3.run(ZKFailoverController.java:592)\n\tat org.apache.hadoop.ha.ZKFailoverController$3.run(ZKFailoverController.java:589)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)\n\tat org.apache.hadoop.ha.ZKFailoverController.gracefulFailoverToYou(ZKFailoverController.java:589)\n\tat org.apache.hadoop.ha.ZKFCRpcServer.gracefulFailover(ZKFCRpcServer.java:94)\n\tat org.apache.hadoop.ha.protocolPB.ZKFCProtocolServerSideTranslatorPB.gracefulFailover(ZKFCProtocolServerSideTranslatorPB.java:61)\n\tat org.apache.hadoop.ha.proto.ZKFCProtocolProtos$ZKFCProtocolService$2.callBlockingMethod(ZKFCProtocolProtos.java:1548)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)\n{quote}\n\nThe calls succeeds if I issue the same command subsequently","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"380871","customfield_12312823":null,"summary":"First call from Client fails after Server restart","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Linux : centos62-2 2.6.32-220.el6.x86_64,\njdk : 1.7.0_15","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12702252/comment/14040669","id":"14040669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rnitzan","name":"rnitzan","key":"rnitzan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"raanan","active":true,"timeZone":"Etc/UTC"},"body":"Happened for me also when HDFS Client try to get block location from NN after NN restart\n\nOS: Red Hat Enterprise Linux Server release 6.4 (Santiago)\nJava: 1.7.0_15\n\n2014-06-23 03:35:40.0532 DEBUG IPC Client (1936601988) connection to nnhost:8020 from org.apache.hadoop.ipc.Client - closing ipc connection to nnhost:8020:\n null\njava.io.EOFException\n        at java.io.DataInputStream.readInt(DataInputStream.java:392)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:995)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:891)\n\n2014-06-23 03:35:40.0536 ERROR ...  Exception thrown when streaming\njava.io.IOException: Failed on local exception: java.io.EOFException; Host Details : local host is: \"dnhost\"; destination host is:  nnhost\":8020; \n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1351)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1300)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n        at com.sun.proxy.$Proxy56.getBlockLocations(Unknown Source)\n        ....\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rnitzan","name":"rnitzan","key":"rnitzan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"raanan","active":true,"timeZone":"Etc/UTC"},"created":"2014-06-23T12:11:51.092+0000","updated":"2014-06-23T12:11:51.092+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-10412/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1tkov:"}}