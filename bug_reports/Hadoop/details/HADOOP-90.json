{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12330364","self":"https://issues.apache.org/jira/rest/api/2/issue/12330364","key":"HADOOP-90","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312098","id":"12312098","description":"","name":"0.8.0","archived":false,"released":true,"releaseDate":"2006-11-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2006-03-17T12:05:38.000+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Oct 31 22:14:05 UTC 2006","customfield_12310420":"80708","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_170573000_*|*_1_*:*_1_*:*_19569679000_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_260765000","customfield_12312321":null,"resolutiondate":"2006-10-31T22:14:05.000+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-90/watchers","watchCount":2,"isWatching":false},"created":"2006-03-17T10:49:53.000+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312118","id":"12312118","description":"","name":"0.7.2","archived":false,"released":true,"releaseDate":"2006-10-18"}],"issuelinks":[{"id":"12313249","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12313249","type":{"id":"10020","name":"Cloners","inward":"is cloned by","outward":"is a clone of","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10020"},"inwardIssue":{"id":"12345183","key":"HADOOP-332","self":"https://issues.apache.org/jira/rest/api/2/issue/12345183","fields":{"summary":"Implement remote replication of dfs namespace images and transaction logs","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:41:49.792+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Currently, DFS name node stores its log and state in local files.\nThis has the disadvantage that a hardware failure of the name node causes a total data loss. \nSeveral approaches may be used to address this flaw:\n1. replicate the name server state files using copy or rsync once in a while, either manually or using a cron job.\n2. set up secondary name servers and a protocol whereby the primary updates the secondaries. In case of failure, a secondary can take over.\n3. store the state files as distributed, replicated files in the DFS itself. The difficulty is that it becomes a bootstrap problem, where the name node needs some information, typically stored in its state files, in order to read those same state files.\n\nsolution 1 is fine for non critical systems, but for systems that need to guarantee no data loss it's insufficient.\nSolutions 2 and 3 both seem valid; 3 seems more elegant in that it doesn't require an extra protocol, it leverages the DFS and allows any level of replication for robustness. Below is a proposition for  solution 3.\n\n1.\tThe name node, when it starts up, needs some basic information. That information is not large and can easily be stored in a single block of DFS. We hard code the block location, using block id 0. Block 0 will contain the list of blocks that contain the name node metadata - not the metadata itself (file names, servers, blocks etc), just the list of blocks that contain it. With a block identified by 8 bytes, and 32 MB blocks, we can fit 256K block id's in block 0. 256K blocks of 32MB each can hold 8TB of metadata, which can map a large enough file system, so a single block of block_ids is sufficient.\n2.\tThe name node writes his state basically the same way as now: log file plus occasional full state. DFS needs to change to commit changes to open files while allowing continued writing to them, or else the log file wouldn't be valid on name server failure, before the file is closed. \n3.\tThe name node will use double buffering for its state, using blocks 0 and 1. Starting with block 0, it writes its state, then a log of changes. When it's time to write a new state it writes it to node 1. The state includes a generation number, a single byte starting at 0, to enable the name server to identify the valid state. A CRC is written at the end of the block to mark its validity and completeness. The log file is identified by the same generation number as the state it relates to. \n4.\tThe log file will be limited to a single block as well. When that block fills up a new state is written. 32MB of transaction logs should suffice. If not, we could set aside a set of blocks, and set aside a few locations in the super-block (block 0/1) to store that set of block ids.\n5.\tThe super-block, the log and the metadata blocks may be exposed as read only files in reserved files in the DFS: /.metadata/* or something.\n6.\tWhen a name nodes starts, it waits for data nodes to connect to it to report their blocks. It waits until it gets a report about blocks 0 and 1, from which it can continue to read its entire state. After that it continues normally.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12343850","id":"12343850","filename":"backup.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-29T22:50:46.000+0000","size":21608,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12343850/backup.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12334580","id":"12334580","filename":"multipleEditsDest.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-26T06:22:12.000+0000","size":2515,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12334580/multipleEditsDest.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"79362","customfield_12312823":null,"summary":"DFS is succeptible to data loss in case of name node failure","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12370780","id":"12370780","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"I like the idea.  We have something very similar running in some of our other apps.\n\nI'm a bit concerned about using two blocks.  What if the name server only finds one of them?  I'd use block one to stage new versions and then support an operation to make it block zero \"atomically\".  Then there should be no confusion.  You still need to worry about generations of block zero though.\n\nInteresting problem space.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-03-17T12:05:38.000+0000","updated":"2006-03-17T12:05:38.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12370845","id":"12370845","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"body":"adding functionality for atomic transfers of blocks is non trivial, and unnecessary in this case.\nboth block 0 and 1 are replicated as many times as required to achieve any desired level of reliability.\nthe generations part is straightforward - read both blocks, verify they're valid via their CRC. If just one is valid - select it, the other one hasn't been written successfully; if they're both valid, they'll have consecutive generation numbers (with rollover, so 0 follows 255), so select the larger one. Noteworty is the fact that a state file with its corresponding log file are completely equivalent to the next generation state file at the time it's created, so the name node is safe in any type of failure while writing the new state: until it's valid and safe the old state+log are there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"created":"2006-03-18T01:18:01.000+0000","updated":"2006-03-18T01:18:01.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12378532","id":"12378532","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"body":"\nSince we have virtually no 'metadata' for a file we could have a complete description of the filesystem by adding a couple of fields to org.apache.hadoop.dfs.Block and then have the DataNodes write small block info files to the same directory as the actual block data.\n\nI actually did this one day as an experiment.\n\nclass Block ...\n\n    long blkid;\n    long len;\n    UTF8 path;// the full path name of this block in the NameNode  \n    long position;// the starting position of this block in the file  \n\nThe NameNode can recover it's state by just waiting for the DataNodes to report the blocks they have.\n\nThe ugly part is what happens during a directory rename. Every DataNode needs to know that the blocks have changed and then re-write it. It could be a LOT of blocks.\n\nOne adds this (below) to FSNamesystem:\n\n   //\n    // Keeps a Vector for every named machine.  The Vector contains\n    // blocks that have recently been part of a rename and are thought to live\n    // on the machine in question.\n    //\n    TreeMap recentRenameSets = new TreeMap();\n\nThen NameNode.getBlockWork has this code at it's beginning:\n\n        // check to see of there are blocks that need to be renamed.\n        //\n        Block blocks[] = namesystem.blocksToRename(new UTF8(sender));\n        if (blocks != null) {\n        \tBlockCommand cmd = new BlockCommand(blocks);\n        \tcmd.setRenameBlocks();\n        \treturn cmd;\n        }\n\nI don't think I'm formally proposing this scheme, but I'd like to talk about it before I go off half cocked and write the wrong thing.\n\nWe are very concerned here about losing our DFS if something ever happens to the NameNode. I have the assignment to fix it, somehow, in the next couple of weeks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-09T06:13:48.000+0000","updated":"2006-05-09T06:13:48.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12412591","id":"12412591","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"body":"I thought about this for a while, and I think this is how I would attack the problem.\n\nFirst, I introduce the concept of a 'precious file' in dfs. A precious file is a file that can be recovered even if all NameNode state is lost. This is probably not a new object but just a boolean in FSDirectory.INode to indicate that the file is precious (and a boolean in FileUnderConstruction). \n\nA precious file is composed of PreciousBlock's, instead of Block's like a normal dfs file: \n\npublic class PreciousBlock extends Block {\n\t\n\tUTF8   pathName; // absolute dfs path\n\tlong   timestamp;// milliseconds since last change\n\tint    sequence; // which block this is. ie 0th, first, etc.\n\tint    total;    // count of blocks for the file\n\tshort  replication; \n\n\tpublic void write(DataOutput out) ...\n      public void readFields(DataInput in) ... etc.\n}\n\nWhenever a DataNode creates, or replicates, a block for a file that is precious it also serializes the PreciousBlock to a file in it's data directory(s).\n\nYou would see something like this in a datanode directory;\n\nblk_2241143806243395050\nblk_385073589724654571\nblk_8416156569406441156\nprecious_385073589724654571\n\nThis would mean that block #385073589724654571 is part of a precious file. The file precious_385073589724654571 contains a serialization of PreciousBlock.\n\nFiles stored this way can be recovered with out any NameNode state at all. The NameNode could simply wait until the DataNodes report their blocks and reconstruct all the precious files. If a precious file is widely replicated it becomes almost impossible to ever lose. The purpose of the timestamp is for the case where a file is renamed, or deleted and recreated, and a datanode didn't get the message.\n\nThe next part is easy. The NameNode just writes its image and edits to precious files in the dfs. The NameNode can easily keep several old versions of its state, or any other good tricks. Old NameNode images could be rotated like log files, etc. \n\nRecovery from loss, or corruption, of NameNode state is relatively simple. The NameNode recovers the precious files and then just reads the latest reliable image/edits. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-20T03:39:42.000+0000","updated":"2006-05-20T03:39:42.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12413315","id":"12413315","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"body":"\nI changed my mind. Now I'm looking for the smallest possible solution.\n\nI just want a config to enable writing the edits to more than one place. The default config works exactly the same way as the existin code.\n\nAll the other details of backing up the NameNode image and edits can be handled outside of the code.\n\nHere's the patch. \n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-26T06:21:24.000+0000","updated":"2006-05-26T06:21:24.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12413532","id":"12413532","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"body":"seems like all the extra copies will be on the same node, right?\nso if it dies, so does the filesystem...\nperhaps the bug should be cloned, with the patch resolving a bug, but leaving the current bug open until it's more fully addressed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-27T04:10:26.000+0000","updated":"2006-05-27T04:10:26.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12413533","id":"12413533","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"The low-tech thing I've done that's saved me when the namenode dies is simply to have a cron entry that rsyncs the namenode's files to another node every few minutes.  If the namenode dies, you lose at most a few minutes of computation.  It's not perfect, and its not a long-term solution, but it is a pretty effective workaround in my experience.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-05-27T04:16:55.000+0000","updated":"2006-05-27T04:16:55.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12413534","id":"12413534","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"body":"I've done the same, alternating between two backup nodes.\nit's band-aid, until a real solution is devised.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-27T04:30:04.000+0000","updated":"2006-05-27T04:30:04.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12413885","id":"12413885","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"body":"What we plan is to securely backup the 'snapshot' (the image file) after the NameNode is started. So that takes care of that part.  Now it's all about saving the edit log in a safe way. I don't like the idea of the backup being even one minute old.\n\nThe failure mode is the loss of a hard drive on the NameNode server. Simply writing, ALL the time, the edit log to more than one path, and therefore to more than one drive, goes a long way towards making the data secure. If the node dies you would still have to retreive one of the edit files from one of the drives, but at least one of the drives should still work (there are 3 on our namenode). Someone needs to pull the drives and mount them on another machine before recovery can happen, but hey, it's going to be a rare event.\n\nIf you are using Solaris, as we are, then sun nfs is available (or so they tell me). We mount an nfs drive, and write the edit log to that drive also. In this case recovery can happen by copying the image, and the edits, from nfs to another node, changing DNS for the name of the namenode, and starting a new namenode. \n\nI feel, at least for us, that this IS a real solution, and not just a band-aid. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=awootton","name":"awootton","key":"awootton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"alan wootton","active":true,"timeZone":"Etc/UTC"},"created":"2006-05-31T02:10:10.000+0000","updated":"2006-05-31T02:10:10.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12413887","id":"12413887","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Alan,  I didn't mean to argue that cron+rsync was an ideal solution.  Yes, streaming the edits to multiple locations is the plan.  I personally don't think we should rely on NFS, but rather we should develop our own network protocol and service by which edits are sync'd, but I might be convinced otherwise.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-05-31T02:29:06.000+0000","updated":"2006-05-31T02:29:06.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12445471","id":"12445471","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"body":"Attached a patch that allows multiple locations to store the filesystem image and the edits log. Thus, dfs.name.dir can now contain multiple directories separated by comma.\nUpon startup, the namenode scans all provided locations, and determines the most recent image and the most recent edits log. Recents all images, and writes the new image in all the locations, alongwith a timestamp file.\nNamenode format command allows one to selectively format among all the specified locations.\nOne could use a more reliable disks (including NFS mounted disk) to store namesystem state.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-29T22:50:46.000+0000","updated":"2006-10-29T22:50:46.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12445472","id":"12445472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch submitted.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=milindb","name":"milindb","key":"milindb","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Milind Bhandarkar","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-29T22:51:12.000+0000","updated":"2006-10-29T22:51:12.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12330364/comment/12446084","id":"12446084","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this.  Thanks, Milind!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-31T22:14:05.000+0000","updated":"2006-10-31T22:14:05.000+0000"}],"maxResults":13,"total":13,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-90/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0dxj3:"}}