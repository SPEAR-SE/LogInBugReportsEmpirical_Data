{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12407619","self":"https://issues.apache.org/jira/rest/api/2/issue/12407619","key":"HADOOP-4562","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2008-10-31T20:46:29.473+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Oct 31 22:12:01 UTC 2008","customfield_12310420":"126601","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_11349065_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_1732105839","customfield_12312321":null,"resolutiondate":"2008-10-31T22:12:01.109+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4562/watchers","watchCount":1,"isWatching":false},"created":"2008-10-31T19:02:52.044+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313211","id":"12313211","description":"","name":"0.19.0","archived":false,"released":true,"releaseDate":"2008-11-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:43:23.575+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Updating hbase to use 0.19.0RC0 or latest from branch-0.19, I see reams of this in logs:\n\n{code}\n2008-10-31 18:33:41,296 INFO org.apache.hadoop.fs.FSInputChecker: java.io.IOException: Checksum ok was sent and should not be sent again\n        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1064)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1613)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1590)\n        at java.io.DataInputStream.readByte(DataInputStream.java:248)\n        at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:325)\n        at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:346)\n        at org.apache.hadoop.io.Text.readString(Text.java:400)\n        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1471)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)\n        at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:293)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$HbaseMapFile$HbaseReader.<init>(HStoreFile.java:632)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader.<init>(HStoreFile.java:714)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:413)\n        at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:262)\n        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1729)\n        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:469)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1004)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:976)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:901)\n        at java.lang.Thread.run(Thread.java:619)\n\n2008-10-31 18:33:41,272 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbasetrunk/-ROOT-/70236052/info/info/1689673398714621203, isReference=false, sequence id=1\n2008-10-31 18:33:41,274 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 1 file(s) in hstore 70236052/info, max sequence id 1\n2008-10-31 18:33:41,296 INFO org.apache.hadoop.fs.FSInputChecker: java.io.IOException: Checksum ok was sent and should not be sent again\n        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1064)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1613)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1590)\n        at java.io.DataInputStream.readByte(DataInputStream.java:248)\n        at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:325)\n        at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:346)\n        at org.apache.hadoop.io.Text.readString(Text.java:400)\n        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1471)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)\n        at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:293)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$HbaseMapFile$HbaseReader.<init>(HStoreFile.java:632)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader.<init>(HStoreFile.java:714)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:413)\n        at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:262)\n        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1729)\n        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:469)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1004)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:976)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:901)\n        at java.lang.Thread.run(Thread.java:619)\n\n2008-10-31 18:33:41,298 INFO org.apache.hadoop.fs.FSInputChecker: java.io.IOException: Checksum ok was sent and should not be sent again\n        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1064)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1613)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)\n        at java.io.DataInputStream.readFully(DataInputStream.java:178)\n        at org.apache.hadoop.io.Text.readString(Text.java:402)\n        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1471)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)\n        at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:293)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$HbaseMapFile$HbaseReader.<init>(HStoreFile.java:632)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader.<init>(HStoreFile.java:714)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:413)\n        at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:262)\n        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1729)\n        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:469)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1004)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:976)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:901)\n        at java.lang.Thread.run(Thread.java:619)\n{code}\n\nHBase is just opening a mapfile.\n\nHere is from svn blame and history:\n\n{code}\n706798    hairong         if (sentChecksumOk) {\n706798    hairong            // this should not happen; log the error for the debugging purpose\n706798    hairong            LOG.info(StringUtils.stringifyException(new IOException(\n708724    rangadi              \"Checksum ok was sent and should not be sent again\")));\n\n\nr708724 | rangadi | 2008-10-28 16:33:40 -0700 (Tue, 28 Oct 2008) | 1 line\n\nHADOOP-4499. DFSClient should invoke checksumOk only once. (Raghu Angadi)\n------------------------------------------------------------------------\nr706798 | hairong | 2008-10-21 15:19:07 -0700 (Tue, 21 Oct 2008) | 1 line\n\nMerge -r 706795:706796 from trunk to main to move the change log of HADOOP-3914.\n{code}\n\nCode comment says this condition should never happen.\n\nLooking at code, IIUC, we get this exception if we reread inside a block.\n\nFor now, I've marked it a blocker.  HBase can't use 0.19.0 if this is the carry-on.\n\nI'll dig in some more.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"104249","customfield_12312823":null,"summary":"Logs filled with \"IOException: Checksum ok was sent and should not be sent again\"","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12407619/comment/12644404","id":"12644404","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm running with r709534 so HADOOP-4499 is in place but I still see the above exceptions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-10-31T19:15:58.531+0000","updated":"2008-10-31T19:15:58.531+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12407619/comment/12644428","id":"12644428","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"The line number in the stacktrace does not match the latest 0.19 branch.. could you verify if you have HADOOP-4499? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-10-31T20:46:29.473+0000","updated":"2008-10-31T20:46:29.473+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12407619/comment/12644442","id":"12644442","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks. I confirmed that the debug message no longer shows (My bad, HBase was using DFSClient out of RC0 when I made above stacktraces).  Resolving as fixed by HADOOP-4499.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-10-31T22:12:01.091+0000","updated":"2008-10-31T22:12:01.091+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4562/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0i74n:"}}