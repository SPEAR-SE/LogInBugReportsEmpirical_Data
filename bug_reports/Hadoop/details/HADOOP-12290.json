{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12850428","self":"https://issues.apache.org/jira/rest/api/2/issue/12850428","key":"HADOOP-12290","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2015-07-30T22:44:38.272+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jul 30 23:54:01 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_3429194_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-07-30T22:44:38.251+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12290/watchers","watchCount":2,"isWatching":false},"created":"2015-07-30T21:47:29.085+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-07-30T23:54:01.931+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"I cannot find any document for wildcard support for \"hadoop fs -ls\" cmd and the expected behavior. So I did some experiments and got inconsistent results below. This looks like a bug to me. But if we don't support wildcard for \"hadoop fs -ls\", we should at least document it.\n\nOn a single node cluster with \"fs.default.name\" configured as hdfs://localhost:9000. \n\nRoot without wildcard: HDFS only.\n{code}\n$ hdfs dfs -ls /\nFound 11 items\ndrwxrwxrwx   - xyao hadoop          0 2015-07-28 15:27 /data\ndrwxr-xr-x   - xyao hadoop          0 2015-07-26 23:05 /noez\ndrwxr-xr-x   - xyao hadoop          0 2015-07-29 17:33 /path3\ndrwxrwxrwx   - xyao hadoop          0 2015-07-26 23:04 /tmp\ndrwx------   - xyao hadoop          0 2015-07-26 23:03 /user\ndrwxr-xr-x   - xyao hadoop          0 2015-07-29 17:34 /uu\ndrwxr-xr-x   - xyao hadoop          0 2015-07-26 23:08 /z1_1\ndrwxr-xr-x   - xyao hadoop          0 2015-07-26 21:43 /z1_2new\ndrwxr-xr-x   - xyao hadoop          0 2015-07-26 22:00 /z2_0\ndrwxr-xr-x   - xyao hadoop          0 2015-07-26 21:43 /z2_1\ndrwxr-xr-x   - xyao hadoop          0 2015-07-26 21:55 /z2_2\n{code}\n\nRoot with wildcard: HDFS and local. \n{code}\n$ hadoop fs -ls /*\nls: `/Applications': No such file or directory\nls: `/Library': No such file or directory\nls: `/Network': No such file or directory\nls: `/System': No such file or directory\nls: `/User Information': No such file or directory\nls: `/Users': No such file or directory\nls: `/Volumes': No such file or directory\nls: `/bin': No such file or directory\nls: `/dev': No such file or directory\nls: `/etc': No such file or directory\nls: `/home': No such file or directory\nls: `/mach_kernel': No such file or directory\nls: `/net': No such file or directory\nls: `/opt': No such file or directory\nls: `/private': No such file or directory\nls: `/proc': No such file or directory\nls: `/sbin': No such file or directory\nls: `/test.jks': No such file or directory\nFound 3 items\ndrwxrwxrwx   - xyao hadoop          0 2015-07-22 10:48 /tmp/test\ndrwxrwxrwx   - xyao hadoop          0 2015-07-22 10:50 /tmp/test\n\ndrwxrwxrwx   - xyao hadoop          0 2015-07-22 10:49 /tmp/test\nhello\nls: `/usr': No such file or directory\nls: `/var': No such file or directory\n{code}\n\nWildcard with prefix 1: HDFS and Local. But HDFS goes one level down.\n{code}\nHW11217:hadoop-hdfs-project xyao$ hadoop fs -ls /t*\nls: `/test.jks': No such file or directory\nFound 3 items\ndrwxrwxrwx   - xyao hadoop          0 2015-07-22 10:48 /tmp/test\ndrwxrwxrwx   - xyao hadoop          0 2015-07-22 10:50 /tmp/test\n\ndrwxrwxrwx   - xyao hadoop          0 2015-07-22 10:49 /tmp/test\nhello\n{code}\n\nWildcard and prefix 2: Empty result even though HDFS does have a few directories starts with \"z\" as shown above. \n{code}\nhadoop fs -ls /z*\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"hadoop fs -ls command returns inconsistent results with wildcards","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12850428/comment/14648425","id":"14648425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"This appears to be pilot error rather than a bug in Hadoop.  The wildcards are not quoted and therefore the shell is expanding them _before_ Hadoop even sees the wildcard.  You must be running on a Mac, which would explain why it's trying to lookup things like /Applications, /Library, /System, etc.  This needs to be something like:\n{noformat}\nhadoop fs -ls '/*'\n{noformat}\nto keep the shell from expanding it.\n\nThe same thing is occurring for the /t* case.\n\nFor the last case, the shell is not finding anything for /z* and therefore is passing it unexpanded to Hadoop, and Hadoop is expanding it to the various z* directories.  However I suspect all of those directories are empty, so it lists nothing as a result.\n\nClosing as invalid.  Please reopen if there's a real issue here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2015-07-30T22:44:38.272+0000","updated":"2015-07-30T22:44:38.272+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12850428/comment/14648525","id":"14648525","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~jlowe] for the detailed information! That makes sense to me after I understand the shell expanding. \n\nbq. For the last case, the shell is not finding anything for /z* and therefore is passing it unexpanded to Hadoop, and Hadoop is expanding it to the various z* directories. However I suspect all of those directories are empty, so it lists nothing as a result.\n\nYou are right, all the z* directories are empty. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-07-30T23:54:01.931+0000","updated":"2015-07-30T23:54:01.931+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-12290/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2i5in:"}}