{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12608251","self":"https://issues.apache.org/jira/rest/api/2/issue/12608251","key":"HADOOP-8825","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2012-09-19T15:11:08.206+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Sep 21 19:59:46 UTC 2012","customfield_12310420":"246642","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_72385937_*|*_1_*:*_1_*:*_925242_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-09-20T11:12:54.200+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-8825/watchers","watchCount":5,"isWatching":false},"created":"2012-09-19T14:51:03.036+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12322467","id":"12322467","description":"2.0.1-alpha release","name":"2.0.1-alpha","archived":false,"released":true,"releaseDate":"2012-07-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-09-21T19:59:46.444+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310687","id":"12310687","name":"io","description":""}],"timeoriginalestimate":null,"description":"Two constructors were removed in Hadoop 2 which causes a problem for Avro being able to support Hadoop 1 and Hadoop 2. See AVRO-1170.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12545738","id":"12545738","filename":"HADOOP-8825.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2012-09-19T14:56:55.730+0000","size":3430,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12545738/HADOOP-8825.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"43340","customfield_12312823":null,"summary":"Reinstate constructors in SequenceFile.BlockCompressWriter and SequenceFile.RecordCompressWriter for compatibility with Hadoop 1","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13458732","id":"13458732","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"This patch reinstates the constructors. I tested this by running Avro tests using Hadoop JARs built with the patch applied.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2012-09-19T14:56:55.732+0000","updated":"2012-09-19T14:56:55.732+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13458742","id":"13458742","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"Just out of curiosity how is Avro accessing these classes?  They are package private classes, and even though SequenceFile is @Public and @Stable being package private seems to indicate to me that they are not intended for general consumption.  If Avro is going to use them could we please mark them @LimitedPrivate for Avro, and perhaps even open them up more so they are public instead.  So Avro does not have to put their classes in an org.apache.hadoop.io package to use them.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-09-19T15:11:08.206+0000","updated":"2012-09-19T15:11:08.206+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13458749","id":"13458749","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"Avro is using the constructors via a class called SequenceFileBase in org.apache.hadoop.io to provide access. However, I agree that this is a poor way to do things, so making them public would be a lot better.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2012-09-19T15:22:29.697+0000","updated":"2012-09-19T15:22:29.697+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13458760","id":"13458760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"I am not an expert on sequence files so I perhaps am not the best person to make that choice to open them up.  From a quick read through the code it look like they were not intended to be extension points.  Why does avro need access to the compression writers, and does not just rely on the key and value serializers as the extension points?  At a minimum they need to be @LimitedPrivate for Avro so we don't break Avro again in the future.  But before marking them public I want to understand the reasons why Avro needs access to them, and if there is some cleaner way we can provide an extension point so others can do the same thing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-09-19T15:39:16.722+0000","updated":"2012-09-19T15:39:16.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13458763","id":"13458763","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12545738/HADOOP-8825.patch\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.\n\n    -1 findbugs.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed unit tests in hadoop-common-project/hadoop-common.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1485//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/1485//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1485//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-09-19T15:41:47.404+0000","updated":"2012-09-19T15:41:47.404+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13458774","id":"13458774","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"It's to support a wrapper around SequenceFile for Avro types: http://avro.apache.org/docs/1.7.1/api/java/org/apache/avro/hadoop/io/AvroSequenceFile.html. But it would be preferable to use the existing constructors or createWriter methods. I'll take a look to see if that's possible. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2012-09-19T15:57:25.763+0000","updated":"2012-09-19T15:57:25.763+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13459516","id":"13459516","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"body":"I managed to change AvroSequenceFile so it doesn't need to use the BlockCompressWriter or RecordCompressWriter constructors. Thanks for the help Bobby! ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tomwhite","name":"tomwhite","key":"tomwhite","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tom White","active":true,"timeZone":"Europe/London"},"created":"2012-09-20T11:12:54.211+0000","updated":"2012-09-20T11:12:54.211+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12608251/comment/13460784","id":"13460784","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"Glad I could help.  I don't think I did much, you actually wrote the code, so thanks should mostly go to you.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-09-21T19:59:46.444+0000","updated":"2012-09-21T19:59:46.444+0000"}],"maxResults":8,"total":8,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-8825/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i07s87:"}}