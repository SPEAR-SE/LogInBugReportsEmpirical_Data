{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12779927","self":"https://issues.apache.org/jira/rest/api/2/issue/12779927","key":"HADOOP-11693","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327583","id":"12327583","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-03-05T23:26:42.948+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jun 05 02:44:27 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"3_*:*_1_*:*_250881590_*|*_10002_*:*_1_*:*_175583792_*|*_1_*:*_1_*:*_86336727_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-03-11T21:45:55.793+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11693/watchers","watchCount":9,"isWatching":false},"created":"2015-03-05T23:19:13.728+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-07-01T23:02:42.679+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319643","id":"12319643","name":"tools","description":"Hadoop tools"}],"timeoriginalestimate":null,"description":"One of our customers' production HBase clusters was periodically throttled by Azure storage, when HBase was archiving old WALs. HMaster aborted the region server and tried to restart it.\n\nHowever, since the cluster was still being throttled by Azure storage, the upcoming distributed log splitting also failed. Sometimes hbase:meta table was on this region server and finally showed offline, which cause the whole cluster in bad state.\n\n{code}\n2015-03-01 18:36:45,623 ERROR org.apache.hadoop.hbase.master.HMaster: Region server workernode4.hbaseproddb4001.f5.internal.cloudapp.net,60020,1424845421044 reported a fatal error:\nABORTING region server workernode4.hbaseproddb4001.f5.internal.cloudapp.net,60020,1424845421044: IOE in log roller\nCause:\norg.apache.hadoop.fs.azure.AzureException: com.microsoft.windowsazure.storage.StorageException: The server is busy.\n\tat org.apache.hadoop.fs.azurenative.AzureNativeFileSystemStore.rename(AzureNativeFileSystemStore.java:2446)\n\tat org.apache.hadoop.fs.azurenative.AzureNativeFileSystemStore.rename(AzureNativeFileSystemStore.java:2367)\n\tat org.apache.hadoop.fs.azurenative.NativeAzureFileSystem.rename(NativeAzureFileSystem.java:1960)\n\tat org.apache.hadoop.hbase.util.FSUtils.renameAndSetModifyTime(FSUtils.java:1719)\n\tat org.apache.hadoop.hbase.regionserver.wal.FSHLog.archiveLogFile(FSHLog.java:798)\n\tat org.apache.hadoop.hbase.regionserver.wal.FSHLog.cleanOldLogs(FSHLog.java:656)\n\tat org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:593)\n\tat org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:97)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: com.microsoft.windowsazure.storage.StorageException: The server is busy.\n\tat com.microsoft.windowsazure.storage.StorageException.translateException(StorageException.java:163)\n\tat com.microsoft.windowsazure.storage.core.StorageRequest.materializeException(StorageRequest.java:306)\n\tat com.microsoft.windowsazure.storage.core.ExecutionEngine.executeWithRetry(ExecutionEngine.java:229)\n\tat com.microsoft.windowsazure.storage.blob.CloudBlob.startCopyFromBlob(CloudBlob.java:762)\n\tat org.apache.hadoop.fs.azurenative.StorageInterfaceImpl$CloudBlobWrapperImpl.startCopyFromBlob(StorageInterfaceImpl.java:350)\n\tat org.apache.hadoop.fs.azurenative.AzureNativeFileSystemStore.rename(AzureNativeFileSystemStore.java:2439)\n\t... 8 more\n\n2015-03-01 18:43:29,072 ERROR org.apache.hadoop.hbase.executor.EventHandler: Caught throwable while processing event M_META_SERVER_SHUTDOWN\njava.io.IOException: failed log splitting for workernode13.hbaseproddb4001.f5.internal.cloudapp.net,60020,1424845307901, will retry\n\tat org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.process(MetaServerShutdownHandler.java:71)\n\tat org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.fs.azure.AzureException: com.microsoft.windowsazure.storage.StorageException: The server is busy.\n\tat org.apache.hadoop.fs.azurenative.AzureNativeFileSystemStore.rename(AzureNativeFileSystemStore.java:2446)\n\tat org.apache.hadoop.fs.azurenative.NativeAzureFileSystem$FolderRenamePending.execute(NativeAzureFileSystem.java:393)\n\tat org.apache.hadoop.fs.azurenative.NativeAzureFileSystem.rename(NativeAzureFileSystem.java:1973)\n\tat org.apache.hadoop.hbase.master.MasterFileSystem.getLogDirs(MasterFileSystem.java:319)\n\tat org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:406)\n\tat org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(MasterFileSystem.java:302)\n\tat org.apache.hadoop.hbase.master.MasterFileSystem.splitMetaLog(MasterFileSystem.java:293)\n\tat org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler.process(MetaServerShutdownHandler.java:64)\n\t... 4 more\nCaused by: com.microsoft.windowsazure.storage.StorageException: The server is busy.\n\tat com.microsoft.windowsazure.storage.StorageException.translateException(StorageException.java:163)\n\tat com.microsoft.windowsazure.storage.core.StorageRequest.materializeException(StorageRequest.java:306)\n\tat com.microsoft.windowsazure.storage.core.ExecutionEngine.executeWithRetry(ExecutionEngine.java:229)\n\tat com.microsoft.windowsazure.storage.blob.CloudBlob.startCopyFromBlob(CloudBlob.java:762)\n\tat org.apache.hadoop.fs.azurenative.StorageInterfaceImpl$CloudBlobWrapperImpl.startCopyFromBlob(StorageInterfaceImpl.java:350)\n\tat org.apache.hadoop.fs.azurenative.AzureNativeFileSystemStore.rename(AzureNativeFileSystemStore.java:2439)\n\t... 11 more\n\nSun Mar 01 18:59:51 GMT 2015, org.apache.hadoop.hbase.client.RpcRetryingCaller@aa93ac7, org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on workernode13.hbaseproddb4001.f5.internal.cloudapp.net,60020,1425235081338\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2676)\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4095)\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3076)\n\tat org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:28861)\n\tat org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2008)\n\tat org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:92)\n\tat org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:160)\n\tat org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:38)\n\tat org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:110)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}\n\nWhen archiving old WALs, WASB will do rename operation by copying src blob to destination blob and deleting the src blob. Copy blob is very costly in Azure storage and during Azure storage gc, it will be highly likely throttled. The throttling by Azure storage usually ends within 15mins. Current WASB retry policy is exponential retry, but only last at most for 2min. Short term fix will be adding a more intensive exponential retry when copy blob is throttled.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327583","id":"12327583","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12702958","id":"12702958","filename":"HADOOP-11681.01.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-06T02:15:14.178+0000","size":7222,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12702958/HADOOP-11681.01.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12703803","id":"12703803","filename":"HADOOP-11681.02.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-11T01:06:08.006+0000","size":7225,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12703803/HADOOP-11681.02.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12704005","id":"12704005","filename":"HADOOP-11681.03.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-11T20:19:03.218+0000","size":7544,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12704005/HADOOP-11681.03.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14349612","id":"14349612","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thomas.jungblut","name":"thomas.jungblut","key":"thomas.jungblut","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thomas.jungblut&avatarId=13645","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thomas.jungblut&avatarId=13645","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thomas.jungblut&avatarId=13645","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thomas.jungblut&avatarId=13645"},"displayName":"Thomas Jungblut","active":true,"timeZone":"Europe/London"},"body":"Good find Duo, this explains some throttling I've seen already!\n\n| Copy blob is very costly in Azure storage and during Azure storage gc, it will be highly likely throttled.\n\nWhy can't we just \"move\" (CopyFromBlob) it to a different container? If I'm not mistaken it is a pretty cheap linkage operation, O(1) so to say.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thomas.jungblut","name":"thomas.jungblut","key":"thomas.jungblut","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thomas.jungblut&avatarId=13645","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thomas.jungblut&avatarId=13645","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thomas.jungblut&avatarId=13645","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thomas.jungblut&avatarId=13645"},"displayName":"Thomas Jungblut","active":true,"timeZone":"Europe/London"},"created":"2015-03-05T23:26:42.948+0000","updated":"2015-03-05T23:26:42.948+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14349625","id":"14349625","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~thomas.jungblut]\n\nWe discussed with Azure storage team.\n\nThe problem here is during copying blob, temp tables will be created. Azure storage has cleaner threads to clean these temp tables. When the number of temp tables reaches a certain number, Azure storage will throtte the copy blob operation so that no more temp tables will be created.\n\nHowever, during Azure storage gc, cleaner is blocked, which restricts the number of copy blob operations meanwhile.\n\nIt seems not simply a linkage operation. I do not fully know the details though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-05T23:36:53.381+0000","updated":"2015-03-05T23:36:53.381+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14349800","id":"14349800","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~cnauroth] Please take a look.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-06T02:15:14.185+0000","updated":"2015-03-06T02:15:14.185+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14350588","id":"14350588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thomas.jungblut","name":"thomas.jungblut","key":"thomas.jungblut","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thomas.jungblut&avatarId=13645","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thomas.jungblut&avatarId=13645","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thomas.jungblut&avatarId=13645","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thomas.jungblut&avatarId=13645"},"displayName":"Thomas Jungblut","active":true,"timeZone":"Europe/London"},"body":"[~onpduo] you are right- I was mistaking it with deletes of containers vs. blobs. \n\nCan you please shed some light on why we archive old WALs? I would assume we can just queue them up for deletion and delete them at a rate that doesn't cause throttling while it was splitting logs. \n\nI know this might be a very \"localized\" solution to HBase, do you see any better fix than just changing the retry backoffs?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thomas.jungblut","name":"thomas.jungblut","key":"thomas.jungblut","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thomas.jungblut&avatarId=13645","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thomas.jungblut&avatarId=13645","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thomas.jungblut&avatarId=13645","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thomas.jungblut&avatarId=13645"},"displayName":"Thomas Jungblut","active":true,"timeZone":"Europe/London"},"created":"2015-03-06T17:13:18.753+0000","updated":"2015-03-06T17:13:18.753+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14351084","id":"14351084","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~thomas.jungblut]\n\nHere's some words from [~enis],\n{code}\n\"There is currently two services which may keep the files in the archive dir. First is a TTL process, which ensures that the WAL files are kept at least for 10 min. This is mainly for debugging.  The other one is replication. If you have replication setup, the replication processes will hang on to the WAL files until they are replicated.\n\nThere was some related discussion about directly deleting those files, but that was not implemented AFAIK. HBase assumes that rename() is a cheap operation, and uses rename for not only WAL files but for data files as well.\"\n{code}\n\nHowever, in cloud, especially in Azure storage, rename() is not a cheap operation. Currently Azure storage gc only happens on page blobs and not as frequently as you imagined. So changing retry backoffs on copyblob operation seems the only short term fix here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-06T22:53:37.731+0000","updated":"2015-03-06T22:53:37.731+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14353141","id":"14353141","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~apurtell], although the issue title mentions HBase, the root cause for this problem actually resides in Hadoop Common, specifically the Azure Storage {{FileSystem}} implementation.  I have updated the issue title to try to make this clearer.  It looks like I don't have access to move HBASE issues, so would you mind moving this back to HADOOP?  Thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-09T15:56:29.931+0000","updated":"2015-03-09T15:56:29.931+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14353180","id":"14353180","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apurtell","name":"apurtell","key":"apurtell","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apurtell&avatarId=20553","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apurtell&avatarId=20553","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apurtell&avatarId=20553","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apurtell&avatarId=20553"},"displayName":"Andrew Purtell","active":true,"timeZone":"America/Los_Angeles"},"body":"Sure, moving it back! Thanks [~cnauroth]\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=apurtell","name":"apurtell","key":"apurtell","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=apurtell&avatarId=20553","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=apurtell&avatarId=20553","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=apurtell&avatarId=20553","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=apurtell&avatarId=20553"},"displayName":"Andrew Purtell","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-09T16:38:52.350+0000","updated":"2015-03-09T16:38:52.350+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14353635","id":"14353635","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=enis","name":"enis","key":"enis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Enis Soztutar","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch looks good to me. Is copyBlob the only operation that may get ServerBusy ? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=enis","name":"enis","key":"enis","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Enis Soztutar","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-09T21:22:48.545+0000","updated":"2015-03-09T21:22:48.545+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14353644","id":"14353644","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~enis]\n\nCurrently yes. Since our WASB driver is slow due to the synchronized hsync() method when writing WALs to Azure storage, we have not seen other operations being throttled.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-09T21:28:33.307+0000","updated":"2015-03-09T21:28:33.307+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14353661","id":"14353661","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12702958/HADOOP-11681.01.patch\n  against trunk revision d6e05c5.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-azure.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5896//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5896//artifact/patchprocess/newPatchFindbugsWarningshadoop-azure.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5896//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-09T21:34:43.993+0000","updated":"2015-03-09T21:34:43.993+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14355491","id":"14355491","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~cnauroth] Could you take a look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-10T19:08:15.630+0000","updated":"2015-03-10T19:08:15.630+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14355736","id":"14355736","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi, [~onpduo].  I have just one question.  Right now, the patch waits to see if it encounters a {{SERVER_BUSY}} error, and then restarts the operation with the redefined retry policy.  Is there any reason not to just use this retry policy right from the beginning on the initial call to {{startCopyFromBlob}}?\n\nThe patch will need to be reformatted to fit Hadoop coding conventions.  We indent by 2 spaces, and we wrap lines that exceed 80 characters.\n\nThanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-10T21:14:19.042+0000","updated":"2015-03-10T21:14:19.042+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14356054","id":"14356054","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~cnauroth]\nThere is a default retry policy for all the Azure storage calls, and it is initialized with the Azure storage client.\n{code}\n  private static final int DEFAULT_MIN_BACKOFF_INTERVAL = 1 * 1000; // 1s\n  private static final int DEFAULT_MAX_BACKOFF_INTERVAL = 30 * 1000; // 30s\n  private static final int DEFAULT_BACKOFF_INTERVAL = 1 * 1000; // 1s\n  private static final int DEFAULT_MAX_RETRY_ATTEMPTS = 15;\n{code}\n\nThe backoff interval is 1s. Azure storage throttling issue caused by Azure storage GC happens very rarely. Until now only one customer met this issue and only last 10-15 mins every day. \n\nBelow is the retry policy for copyblob,\n{code}\n  private static final int DEFAULT_COPYBLOB_MIN_BACKOFF_INTERVAL   = 3  * 1000; // 3s\n  private static final int DEFAULT_COPYBLOB_MAX_BACKOFF_INTERVAL   = 90 * 1000; // 90s\n  private static final int DEFAULT_COPYBLOB_BACKOFF_INTERVAL       = 30 * 1000;  // 30s\n  private static final int DEFAULT_COPYBLOB_MAX_RETRY_ATTEMPTS     = 15;  \n{code}\n\nThe backoff is longer, 15s. We set these values in order to let it retry as much as 15min. We only apply this to the rare Azure storage GC case so we do not lose performance in the normal cases.\n\nI have changed the format.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-11T01:06:08.013+0000","updated":"2015-03-11T01:06:08.013+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14356087","id":"14356087","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12703803/HADOOP-11681.02.patch\n  against trunk revision a5cf985.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-azure.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5913//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5913//artifact/patchprocess/newPatchFindbugsWarningshadoop-azure.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5913//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-11T01:44:43.811+0000","updated":"2015-03-11T01:44:43.811+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14357332","id":"14357332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the explanation about normal case vs. the new backoff policy.  That makes sense.\n\nThe eclipse:eclipse failure looks unrelated.  I couldn't reproduce it locally.\n\nSorry to nitpick, but there are still some lines in {{AzureNativeFileSystemStore}} that exceed the 80 character limit.  I know there are some existing lines in this file that already break the rule.  Don't worry about cleaning up all of the existing code, but please make sure all lines touched in the patch adhere to the 80 character limit.\n\nThe findbugs warning is legitimate.  I'm not sure why it's triggering now with this patch, as it appears the problem existed before the patch.  We can fix this by changing the {{catch (Exception e)}} so that there are 2 separate catch clauses for {{catch (StorageException e)}} and {{catch (URISyntaxException e)}}.  Each one can be rethrown wrapped as an {{AzureException}}.\n\nWe're almost there.  Thanks, Duo!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-11T18:21:56.373+0000","updated":"2015-03-11T18:21:56.373+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14357350","id":"14357350","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Please disregard the mention of an eclipse:eclipse failure in my last comment.  That comment was meant for a different patch.  Sorry about that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-11T18:30:31.717+0000","updated":"2015-03-11T18:30:31.717+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14357517","id":"14357517","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"[~cnauroth]\n\nI have wrapped those lines execeeding 80 characters, and indent by 2 characters. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-11T20:19:03.225+0000","updated":"2015-03-11T20:19:03.225+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14357590","id":"14357590","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12704005/HADOOP-11681.03.patch\n  against trunk revision 344d7cb.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-azure.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5919//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5919//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-11T20:59:23.295+0000","updated":"2015-03-11T20:59:23.295+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14357674","id":"14357674","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I have committed this to trunk, branch-2 and branch-2.7.  Duo, thank you for contributing the patch and incorporating the feedback.  Thomas and Enis, thank you for helping with code review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-11T21:45:55.823+0000","updated":"2015-03-11T21:45:55.823+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14357688","id":"14357688","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #7306 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7306/])\nHADOOP-11693. Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving. Contributed by Duo Xu. (cnauroth: rev 7a346bcb4fa5b56191ed00a39e72e51c9bdf1b56)\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/MockStorageInterface.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterface.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-11T21:54:53.033+0000","updated":"2015-03-11T21:54:53.033+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14358535","id":"14358535","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk #864 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/864/])\nHADOOP-11693. Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving. Contributed by Duo Xu. (cnauroth: rev 7a346bcb4fa5b56191ed00a39e72e51c9bdf1b56)\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/MockStorageInterface.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterface.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-12T11:36:55.604+0000","updated":"2015-03-12T11:36:55.604+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14358541","id":"14358541","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #130 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/130/])\nHADOOP-11693. Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving. Contributed by Duo Xu. (cnauroth: rev 7a346bcb4fa5b56191ed00a39e72e51c9bdf1b56)\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/MockStorageInterface.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterface.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-12T11:37:43.602+0000","updated":"2015-03-12T11:37:43.602+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14358734","id":"14358734","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk #2062 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2062/])\nHADOOP-11693. Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving. Contributed by Duo Xu. (cnauroth: rev 7a346bcb4fa5b56191ed00a39e72e51c9bdf1b56)\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/MockStorageInterface.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterface.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-12T14:36:41.417+0000","updated":"2015-03-12T14:36:41.417+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14358752","id":"14358752","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #121 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/121/])\nHADOOP-11693. Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving. Contributed by Duo Xu. (cnauroth: rev 7a346bcb4fa5b56191ed00a39e72e51c9bdf1b56)\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterface.java\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/MockStorageInterface.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-12T14:49:02.759+0000","updated":"2015-03-12T14:49:02.759+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14358830","id":"14358830","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #130 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/130/])\nHADOOP-11693. Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving. Contributed by Duo Xu. (cnauroth: rev 7a346bcb4fa5b56191ed00a39e72e51c9bdf1b56)\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterface.java\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/MockStorageInterface.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-12T15:35:18.894+0000","updated":"2015-03-12T15:35:18.894+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14358883","id":"14358883","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk #2080 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2080/])\nHADOOP-11693. Azure Storage FileSystem rename operations are throttled too aggressively to complete HBase WAL archiving. Contributed by Duo Xu. (cnauroth: rev 7a346bcb4fa5b56191ed00a39e72e51c9bdf1b56)\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/MockStorageInterface.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterfaceImpl.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/StorageInterface.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-12T16:12:50.132+0000","updated":"2015-03-12T16:12:50.132+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14573880","id":"14573880","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~cnauroth]\n\nI have submitted a new patch, which does the retries in WASB rather than rely on Azure Storage SDK. As I looked into the source code this week, Azure Storage SDK regards storage exception as non-retryable, so when throttling happens, the current code might still not work.\n\nCould you reopen this JIRA and review it ASAP?\n\nThanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=onpduo","name":"onpduo","key":"onpduo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=onpduo&avatarId=24246","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=onpduo&avatarId=24246","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=onpduo&avatarId=24246","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=onpduo&avatarId=24246"},"displayName":"Duo Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-05T00:38:55.089+0000","updated":"2015-06-05T00:38:55.089+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12779927/comment/14573965","id":"14573965","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~onpduo].  The HADOOP-11693 patch already shipped in Apache Hadoop 2.7.0.  At this point, please create a new jira to track the new change instead of attaching new patches here.\n\nBTW, I noticed that this new patch appears to be in a multi-byte character encoding (UTF-16 with BOM?).  When you create the new jira, please attach an ASCII patch file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-05T02:44:27.229+0000","updated":"2015-06-05T02:44:27.229+0000"}],"maxResults":28,"total":28,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-11693/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i26fbj:"}}