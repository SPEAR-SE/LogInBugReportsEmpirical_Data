{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12398951","self":"https://issues.apache.org/jira/rest/api/2/issue/12398951","key":"HADOOP-3633","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313296","id":"12313296","description":"","name":"0.17.2","archived":false,"released":true,"releaseDate":"2008-08-11"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-06-24T23:55:59.069+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Aug 22 12:34:09 UTC 2008","customfield_12310420":"81720","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_427168918_*|*_1_*:*_1_*:*_682457458_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_3641007640","customfield_12312321":null,"resolutiondate":"2008-07-07T19:56:29.221+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3633/watchers","watchCount":2,"isWatching":false},"created":"2008-06-24T23:42:42.845+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"5.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312913","id":"12312913","description":"","name":"0.17.0","archived":false,"released":true,"releaseDate":"2008-05-20"}],"issuelinks":[{"id":"12320822","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12320822","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12399489","key":"HADOOP-3685","self":"https://issues.apache.org/jira/rest/api/2/issue/12399489","fields":{"summary":"Unbalanced replication target ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:43:10.838+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Observed dfsclients timing out to some datanodes.\nDatanode's  '.out' file had \n{noformat}\nException in thread \"org.apache.hadoop.dfs.DataNode$DataXceiveServer@82d37\" java.lang.OutOfMemoryError: unable to create new native thread\n  at java.lang.Thread.start0(Native Method)\n  at java.lang.Thread.start(Thread.java:597)\n  at org.apache.hadoop.dfs.DataNode$DataXceiveServer.run(DataNode.java:906)\n  at java.lang.Thread.run(Thread.java:619)\n{noformat}\n\nDatanode was still running but not much activity besides verification.\nJstack showed no DataXceiveServer running.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12385261","id":"12385261","filename":"DataXceivr.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-04T01:51:02.949+0000","size":7367,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12385261/DataXceivr.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12385146","id":"12385146","filename":"DataXceivr.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-02T21:16:12.131+0000","size":7317,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12385146/DataXceivr.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12385435","id":"12385435","filename":"DataXceivr-017.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-07T19:50:59.966+0000","size":7728,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12385435/DataXceivr-017.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12385434","id":"12385434","filename":"DataXceivr-018.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-07T19:38:01.394+0000","size":7799,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12385434/DataXceivr-018.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12384636","id":"12384636","filename":"jstack-H3633.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2008-06-24T23:45:08.736+0000","size":8418,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12384636/jstack-H3633.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"104865","customfield_12312823":null,"summary":"Uncaught exception in DataXceiveServer","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"17.0 + H1979-H2159-H3442","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12607807","id":"12607807","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"Datanode's stack trace. \nIt doesn't show DataXceiveServer running","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2008-06-24T23:45:08.777+0000","updated":"2008-06-24T23:45:08.777+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12607808","id":"12607808","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"Tasks were failing with these error messages.\n{noformat}\n2008-06-24 21:51:38,389 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException:\n69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/99.88.77.66:45481 remote=/99.88.77.66:98765]\n2008-06-24 21:51:38,389 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_8837990207306721973\n2008-06-24 21:51:38,421 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 99.88.77.66:98765\n2008-06-24 21:52:54,093 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException:\n69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/99.88.77.66:45519 remote=/99.88.77.66:98765]\n2008-06-24 21:52:54,093 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_802858319825475456\n2008-06-24 21:52:54,094 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 99.88.77.66:98765\n2008-06-24 21:54:09,097 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException:\n69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/99.88.77.66:45553 remote=/99.88.77.66:98765]\n2008-06-24 21:54:09,097 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_-4807850860721655539\n2008-06-24 21:54:09,098 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 99.88.77.66:98765\n2008-06-24 21:55:24,315 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException:\n69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/99.88.77.66:45587 remote=/99.88.77.66:98765]\n2008-06-24 21:55:24,315 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_-2804036762457133352\n2008-06-24 21:55:24,322 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 99.88.77.66:98765\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2008-06-24T23:54:48.598+0000","updated":"2008-06-24T23:54:48.598+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12607809","id":"12607809","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"There are 2 issues here, imo\n# why there is OutOfMemoryError, probably memory leak.\n# DataXceiveServer.run() should catch all exceptions as any server, not only IOExceptions, and shutdown the data-node. \nOtherwise it is not clear that there is a problem with this node, it appears to happily sending heartbeats, but in fact cannot\ndo any data processing because the server thread is dead.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-24T23:55:59.069+0000","updated":"2008-06-24T23:55:59.069+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12608217","id":"12608217","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> 1. why there is OutOfMemoryError, probably memory leak.\n\nAccording to http://forum.java.sun.com/thread.jspa?threadID=605782&messageID=3360044, \"OutOfMemoryError: unable to create new native thread\" is due to too many threads, but not out-of-memory.\n\nDataXceiveServer creates a thread for each block receiving/sending request.  It might create too many thread if there are many block requests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-25T22:22:54.325+0000","updated":"2008-06-25T22:22:54.325+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12608254","id":"12608254","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"True. It looks like that one data-node received ~2000 blocks in one second.\nThis is a destination node during block replication, so many data-nodes were sending blocks to this destination.\nDon't know why, but it happened. May be there is a flaw in the random number generator in ChooseTargets() or it could be that most of \nother nodes on the cluster are pretty much full.\nThis occurred between two heartbeats, when the name-node has not yet received the information that this particular data-node is too busy.\n\nI propose to introduce a parameter in the Datanode that would limit the number of concurrent BlockReceives the data-node can handle.\nThis means that if D1 sends a block to D2 and D2 is already receiving enough blocks then D2 sends back to D1 a BusyException, and the \ntransfer fails. The name-node will later reschedule the block to to be replicated another node.\nWhich happens now anyway because D2 is too slow and D1 gets SocketTimeoutException (after 8 minutes).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-26T02:39:18.965+0000","updated":"2008-06-26T02:39:18.965+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12608640","id":"12608640","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Should be fixed in 0.18. We see this rather regularly when many cluster nodes get full. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-27T02:10:32.999+0000","updated":"2008-06-27T02:10:32.999+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12608902","id":"12608902","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"bq. True. It looks like that one data-node received ~2000 blocks in one second.\nIn the case we looked at, it was 2000 blocks in one *minute*.\n\nbq. or it could be that most of other nodes on the cluster are pretty much full.\nConfirmed that this is happening on cluster with plenty of space.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2008-06-27T20:10:30.005+0000","updated":"2008-06-27T20:10:30.005+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610049","id":"12610049","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"The patch includes:\n# Exception handling in DataXceiveServer, which warns in case of IOException and keeps running, \nbut shuts down the entire data-node in case of other throwables. That way we will not have zombie\ndata-nodes that pretend they are alive by heartbeating but in fact are unable to do any data \nprocessing because the DataXceiveServer is dead.\n# Throttling of the number of concurrent data-processing thread. We should not allow infinite\nnumber of threads to avoid data-nodes running out of space. I set the limit to 256 for now,\nlet me know if it too low/high or should be configurable.\n# I removed the xceiverCount member and related class Count and replaced it by getXceiverCount()\nmethod, which returns the number of current xceiver threads, which can be obtained from the \nthreadGroup. I  noticed that block scanner transfers were not counting the xceiver count.\nNow it is done automatically.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-02T21:16:12.148+0000","updated":"2008-07-02T21:16:12.148+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610072","id":"12610072","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"Opened a Jira for the namenode scheduling side which was assigning too many blocks to small number of datanodes causing this bug.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2008-07-02T22:22:06.947+0000","updated":"2008-07-02T22:22:06.947+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610080","id":"12610080","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nIf HADOOP-3685 fixes the root cause of this jira, can we we postpone #2 above and just have #1 for this jira?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-02T23:08:31.121+0000","updated":"2008-07-02T23:08:31.121+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610087","id":"12610087","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"No, I think #2 is a must. It should be fixed independently on fixing replication targets. Two reasons:\n# In general, I think any limited resources in the system particularly the number of threads like in this case should have explicit limitations in the code.\nHandling such limits by waiting for OutOfMemoryError is incorrect.\nMy 256 limit is based on observations on a cluster, which had problems handling 400 replications at once.\n# Exception handling #1 alone will not help 0.17 since the nodes will shut down instead of becoming zombie, which on a full cluster\ncan lead to cascading effects (more replications cause more failures) if administrators will not urgently restart the nodes.\n\nScheduling 2000 targets to the same node just revealed the problem of uncontrolled thread reproduction on data-nodes. \nThe same can happen if many clients will read from or write to the same data-node at the same time.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-02T23:39:49.577+0000","updated":"2008-07-02T23:39:49.577+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610089","id":"12610089","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":">Scheduling 2000 targets to the same node just revealed the problem of uncontrolled thread reproduction on data-nodes.\nThe same can happen if many clients will read from or write to the same data-node at the same time.\n\nYes. There many more DOS situations with Hadoop.\n\nThe question is not if we should handle these cases, but rather how. I think 256 is too low for some clusters and rejections of connection is a blunt shortcut to handling the situation. I am pretty certain this will lead to problems and will limit Hadoop functionality.\n\nThe situation here is similar to how a server (Hadoop RPC server for e.g.) should handle the excess connections. \n\nIMHO, we will have to visit this issue and again and I want to register my opinion now :).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-02T23:52:52.946+0000","updated":"2008-07-02T23:52:52.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610091","id":"12610091","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12385146/DataXceivr.patch\n  against trunk revision 673517.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no tests are needed for this patch.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2785/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2785/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2785/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2785/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-07-02T23:56:50.557+0000","updated":"2008-07-02T23:56:50.557+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610100","id":"12610100","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> The question is not if we should handle these cases, but rather how.\n\nThe first thing is that we should handle limitations. Current code does not, the patch does. I am glad we agree on that.\nOn \"how\", as I said before 256 comes from practical observations. I have seen cases when nodes were struggling to handle\nmore than that, and I'd rather be conservative here than leaving the problem unsolved by setting the limit too high.\n\n> this will lead to problems and will limit Hadoop functionality.\n\nOn the contrary, currently the functionality of hadoop is bounded by the lack of thread limitation because nodes become dysfunctional.\nIntroducing the limit will make it functional again.\nThe 256 limit does not look low if you look at it from the point of view of how many clients can simultaneously do transfers.\nOn a 2000 node cluster it is about 500,000 of them. It is pretty big even if you divide it by the replication factor of 3 for writes.\n\nAlthough I agree it would be better to have a method of calculating the limit based on some natural criteria like hardware \nconfiguration or heap size. I would be glad to hear ideas in this direction.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-03T01:12:27.902+0000","updated":"2008-07-03T01:12:27.902+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610134","id":"12610134","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 patch looks good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-03T05:44:51.203+0000","updated":"2008-07-03T05:44:51.203+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610313","id":"12610313","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chansler","name":"chansler","key":"chansler","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Chansler","active":true,"timeZone":"America/Los_Angeles"},"body":"Need patches for both 17 and 18, if different.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chansler","name":"chansler","key":"chansler","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Chansler","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-03T18:32:49.115+0000","updated":"2008-07-03T18:32:49.115+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610324","id":"12610324","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"body":"bq. If HADOOP-3685 fixes the root cause of this jira, can we we postpone #2 above and just have #1 for this jira?\n\nI think even with HADOOP-3685 fix, we still have this over-assignment issue when dfs is almost full. \nIt'll be nice to have the throttling set.   \n\nCan we have this limit(256) configurable?  For different OS/hardware/clusters, we might want to change this value.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=knoguchi","name":"knoguchi","key":"knoguchi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Koji Noguchi","active":true,"timeZone":"America/New_York"},"created":"2008-07-03T19:25:37.327+0000","updated":"2008-07-03T19:25:37.327+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610367","id":"12610367","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"body":"We should start with a reasonable default and make it configurable iff we encounter situations where it would help.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-03T23:16:55.860+0000","updated":"2008-07-03T23:16:55.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12610410","id":"12610410","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Updated the patch with new packaging.\n\nI agree with Sameer, lets do it without configuration parameters, and revisit this if there will ever be a need to modify \nthe the hard limit. As we have seen in the past parameters like that can be very confusing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-04T01:51:03.445+0000","updated":"2008-07-04T01:51:03.445+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12611304","id":"12611304","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Needs separate patches for 0.18 and 0.17 because of the directory and package restructuring.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-07T19:38:01.459+0000","updated":"2008-07-07T19:38:01.459+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12611313","id":"12611313","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-07T19:56:29.185+0000","updated":"2008-07-07T19:56:29.185+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398951/comment/12624669","id":"12624669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk #581 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/581/])","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2008-08-22T12:34:09.675+0000","updated":"2008-08-22T12:34:09.675+0000"}],"maxResults":22,"total":22,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3633/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0iaxj:"}}