{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12398252","self":"https://issues.apache.org/jira/rest/api/2/issue/12398252","key":"HADOOP-3559","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312972","id":"12312972","description":"","name":"0.18.0","archived":false,"released":true,"releaseDate":"2008-08-22"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-06-13T23:56:14.650+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jun 24 12:25:26 UTC 2008","customfield_12310420":"126030","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_15877993_*|*_1_*:*_1_*:*_868733616_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_5172169386","customfield_12312321":null,"resolutiondate":"2008-06-23T23:07:53.103+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3559/watchers","watchCount":0,"isWatching":false},"created":"2008-06-13T17:24:21.494+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312972","id":"12312972","description":"","name":"0.18.0","archived":false,"released":true,"releaseDate":"2008-08-22"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T17:05:58.275+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"test-libhdfs fails on linux\n\ntest-libhdfs:\n    [mkdir] Created dir: /workspace/trunk/build/test/libhdfs\n    [mkdir] Created dir: /workspace/trunk/build/test/libhdfs/logs\n    [mkdir] Created dir: /workspace/trunk/build/test/libhdfs/dfs/name\n     [exec] ./tests/test-libhdfs.sh\t\n     [exec] 08/06/13 03:25:15 INFO dfs.NameNode: STARTUP_MSG: \n     [exec] /************************************************************\n     [exec] STARTUP_MSG: Starting NameNode\n     [exec] STARTUP_MSG:   host = hudson/NNN.NNN.NNN.NNN\n     [exec] STARTUP_MSG:   args = [-format]\n     [exec] STARTUP_MSG:   version = 0.18.0\n     [exec] STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/trunk -r 667040; compiled by 'hudsonqa' on Fri Jun 13 03:24:28 UTC 2008\n     [exec] ************************************************************/\n     [exec] Re-format filesystem in ../../../build/test/libhdfs/dfs/name ? (Y or N) 08/06/13 03:25:15 INFO fs.FSNamesystem: fsOwner=hudsonqa,users\n     [exec] 08/06/13 03:25:15 INFO fs.FSNamesystem: supergroup=supergroup\n     [exec] 08/06/13 03:25:15 INFO fs.FSNamesystem: isPermissionEnabled=true\n     [exec] 08/06/13 03:25:15 INFO dfs.FSNamesystemMetrics: Initializing FSNamesystemMeterics using context object:org.apache.hadoop.metrics.spi.NullContext\n     [exec] 08/06/13 03:25:16 INFO fs.FSNamesystem: Registered FSNamesystemStatusMBean\n     [exec] 08/06/13 03:25:16 INFO dfs.Storage: Image file of size 82 saved in 0 seconds.\n     [exec] 08/06/13 03:25:16 INFO dfs.Storage: Storage directory ../../../build/test/libhdfs/dfs/name has been successfully formatted.\n     [exec] 08/06/13 03:25:16 INFO dfs.NameNode: SHUTDOWN_MSG: \n     [exec] /************************************************************\n     [exec] SHUTDOWN_MSG: Shutting down NameNode at hudson/NNN.NNN.NNN.NNN\n     [exec] ************************************************************/\n     [exec] starting namenode, logging to /workspace/trunk/build/test/libhdfs/logs/hadoop-hudsonqa-namenode-hudsonqa.out\n     [exec] starting datanode, logging to /workspace/trunk/build/test/libhdfs/logs/hadoop-hudsonqa-datanode-hudsonqa.out\n     [exec] CLASSPATH=/workspace/trunk/src/c++/libhdfs/tests/conf:/workspace/trunk/conf:/workspace/trunk/src/c++/libhdfs/tests/conf:/workspace/trunk/conf:/home/hudsonqa/tools/java/jdk1.5.0_11-32bit/lib/tools.jar:/workspace/trunk/build/classes:/workspace/trunk/build:/workspace/trunk/build/test/classes:/workspace/trunk/lib/commons-cli-2.0-SNAPSHOT.jar:/workspace/trunk/lib/commons-codec-1.3.jar:/workspace/trunk/lib/commons-httpclient-3.0.1.jar:/workspace/trunk/lib/commons-logging-1.0.4.jar:/workspace/trunk/lib/commons-logging-api-1.0.4.jar:/workspace/trunk/lib/commons-net-1.4.1.jar:/workspace/trunk/lib/jets3t-0.6.0.jar:/workspace/trunk/lib/jetty-5.1.4.jar:/workspace/trunk/lib/junit-3.8.1.jar:/workspace/trunk/lib/kfs-0.1.3.jar:/workspace/trunk/lib/log4j-1.2.13.jar:/workspace/trunk/lib/oro-2.0.8.jar:/workspace/trunk/lib/servlet-api.jar:/workspace/trunk/lib/slf4j-api-1.4.3.jar:/workspace/trunk/lib/slf4j-log4j12-1.4.3.jar:/workspace/trunk/lib/xmlenc-0.52.jar:/workspace/trunk/lib/jsp-2.0/*.jar LD_PRELOAD=/workspace/trunk/build/libhdfs/libhdfs.so /workspace/trunk/build/libhdfs/hdfs_test\n     [exec] 08/06/13 03:25:22 WARN fs.FileSystem: \"localhost:23000\" is a deprecated filesystem name. Use \"hdfs://localhost:23000/\" instead.\n     [exec] 08/06/13 03:25:24 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 0 time(s).\n     [exec] 08/06/13 03:25:25 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 1 time(s).\n     [exec] 08/06/13 03:25:26 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 2 time(s).\n     [exec] 08/06/13 03:25:27 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 3 time(s).\n     [exec] 08/06/13 03:25:28 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 4 time(s).\n     [exec] 08/06/13 03:25:29 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 5 time(s).\n     [exec] 08/06/13 03:25:30 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 6 time(s).\n     [exec] 08/06/13 03:25:31 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 7 time(s).\n     [exec] 08/06/13 03:25:32 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 8 time(s).\n     [exec] 08/06/13 03:25:33 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:23000. Already tried 9 time(s).\n     [exec] Exception in thread \"main\" java.io.IOException: Call failed on local exception\n     [exec] \tat org.apache.hadoop.ipc.Client.call(Client.java:710)\n     [exec] \tat org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)\n     [exec] \tat org.apache.hadoop.dfs.$Proxy0.getProtocolVersion(Unknown Source)\n     [exec] \tat org.apache.hadoop.ipc.RPC.getProxy(RPC.java:319)\n     [exec] \tat org.apache.hadoop.dfs.DFSClient.createRPCNamenode(DFSClient.java:103)\n     [exec] \tat org.apache.hadoop.dfs.DFSClient.<init>(DFSClient.java:173)\n     [exec] \tat org.apache.hadoop.dfs.DistributedFileSystem.initialize(DistributedFileSystem.java:67)\n     [exec] \tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1335)\n     [exec] \tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:56)\n     [exec] \tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)\n     [exec] \tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:209)\n     [exec] \tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:114)\n     [exec] Caused by: java.net.ConnectException: Connection refused\n     [exec] \tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n     [exec] \tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:527)\n     [exec] \tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:100)\n     [exec] \tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:300)\n     [exec] \tat org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:177)\n     [exec] \tat org.apache.hadoop.ipc.Client.getConnection(Client.java:781)\n     [exec] \tat org.apache.hadoop.ipc.Client.call(Client.java:696)\n     [exec] \t... 11 more\n     [exec] Call to org.apache.hadoop.fs.FileSystem::get failed!\n     [exec] Oops! Failed to connect to hdfs!\n     [exec] no datanode to stop\n     [exec] no namenode to stop\n     [exec] exiting with 255\n     [exec] make: *** [test] Error 255","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12384522","id":"12384522","filename":"HADOOP-3559-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-23T18:43:04.665+0000","size":1022,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12384522/HADOOP-3559-1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"104921","customfield_12312823":null,"summary":"test-libhdfs fails on linux","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mukundm","name":"mukundm","key":"mukundm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukund Madhugiri","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mukundm","name":"mukundm","key":"mukundm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukund Madhugiri","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"linux","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398252/comment/12605011","id":"12605011","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks like namenode did not start up. namenode log shows this stack trace\n{noformat}\n2008-06-13 23:51:11,611 INFO org.apache.hadoop.dfs.Storage: Storage directory /home/build/test/libhdfs/dfs/name does not exist.\n2008-06-13 23:51:11,631 ERROR org.apache.hadoop.fs.FSNamesystem: FSNamesystem initialization failed.\norg.apache.hadoop.dfs.InconsistentFSStateException: Directory /home/build/test/libhdfs/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.\n  at org.apache.hadoop.dfs.FSImage.recoverTransitionRead(FSImage.java:211)\n  at org.apache.hadoop.dfs.FSDirectory.loadFSImage(FSDirectory.java:80)\n  at org.apache.hadoop.dfs.FSNamesystem.initialize(FSNamesystem.java:273)\n  at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:252)\n  at org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:148)\n  at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:193)\n  at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:179)\n  at org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:825)\n  at org.apache.hadoop.dfs.NameNode.main(NameNode.java:834)\n{noformat}\n\nclearly,  /home/build/test/libhdfs/dfs/name is invalid directory.\n\nI think, this has to do with some fixes needed as a result of code source directory refactoring we did before branching. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-13T23:56:14.650+0000","updated":"2008-06-13T23:56:14.650+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398252/comment/12607338","id":"12607338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks like hadoop-daemon.sh used to cd to $HADOOP_HOME and libhdfs test uses a custom hadoop-site.xml. Fixing them to get the tests working as before.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-23T18:43:04.690+0000","updated":"2008-06-23T18:43:04.690+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398252/comment/12607366","id":"12607366","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12384522/HADOOP-3559-1.patch\n  against trunk revision 670709.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 8 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2720/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2720/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2720/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2720/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-06-23T20:22:35.102+0000","updated":"2008-06-23T20:22:35.102+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398252/comment/12607406","id":"12607406","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"+1\n\nI just committed this. Thanks, Lohit","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-23T23:07:53.085+0000","updated":"2008-06-23T23:07:53.085+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12398252/comment/12607597","id":"12607597","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk #528 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/528/])","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2008-06-24T12:25:26.228+0000","updated":"2008-06-24T12:25:26.228+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-3559/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ib9z:"}}