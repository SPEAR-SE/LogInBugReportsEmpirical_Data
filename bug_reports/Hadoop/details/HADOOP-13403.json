{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12991646","self":"https://issues.apache.org/jira/rest/api/2/issue/12991646","key":"HADOOP-13403","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334219","id":"12334219","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335733","id":"12335733","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-07-21T23:15:38.812+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Aug 08 20:01:27 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_2_*:*_990653038_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_2_*:*_552107756","customfield_12312321":null,"resolutiondate":"2016-08-08T19:34:08.338+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13403/watchers","watchCount":4,"isWatching":false},"created":"2016-07-21T23:01:28.021+0000","customfield_12310192":"WASB has added an optional capability to execute certain FileSystem operations in parallel on multiple threads for improved performance.  Please refer to the Azure Blob Storage documentation page for more information on how to enable and control the feature.","customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332809","id":"12332809","description":"2.7.2 release","name":"2.7.2","archived":false,"released":true,"releaseDate":"2016-01-25"}],"issuelinks":[{"id":"12478686","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12478686","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"outwardIssue":{"id":"13000464","key":"HADOOP-13550","self":"https://issues.apache.org/jira/rest/api/2/issue/13000464","fields":{"summary":"Azure threaded deleter logs too much at info","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/5","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/trivial.svg","name":"Trivial","id":"5"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12476705","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12476705","type":{"id":"12310040","name":"Required","inward":"is required by","outward":"requires","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310040"},"outwardIssue":{"id":"12994421","key":"HADOOP-13459","self":"https://issues.apache.org/jira/rest/api/2/issue/12994421","fields":{"summary":"hadoop-azure runs several test cases repeatedly, causing unnecessarily long running time.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-01-03T11:15:54.711+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12328416","id":"12328416","name":"fs/azure","description":"Azure WASB filesystem client"}],"timeoriginalestimate":null,"description":"WASB Performance Improvements\n\nProblem\n-----------\nAzure Native File system operations like rename/delete which has large number of directories and/or files in the source directory are experiencing performance issues. Here are possible reasons\na)\tWe first list all files under source directory hierarchically. This is a serial operation. \nb)\tAfter collecting the entire list of files under a folder, we delete or rename files one by one serially.\nc)\tThere is no logging information available for these costly operations even in DEBUG mode leading to difficulty in understanding wasb performance issues.\n\nProposal\n-------------\nStep 1: Rename and delete operations will generate a list all files under the source folder. We need to use azure flat listing option to get list with single request to azure store. We have introduced config fs.azure.flatlist.enable to enable this option. The default value is 'false' which means flat listing is disabled.\n\nStep 2: Create thread pool and threads dynamically based on user configuration. These thread pools will be deleted after operation is over.  We are introducing introducing two new configs\n\ta)\tfs.azure.rename.threads : Config to set number of rename threads. Default value is 0 which means no threading.\n\tb)\tfs.azure.delete.threads: Config to set number of delete threads. Default value is 0 which means no threading.\n\n\tWe have provided debug log information on number of threads not used for the operation which can be useful .\n\n\tFailure Scenarios:\n\tIf we fail to create thread pool due to ANY reason (for example trying create with thread count with large value such as 1000000), we fall back to serialization operation. \n\nStep 3: Bob operations can be done in parallel using multiple threads executing following snippet\n\twhile ((currentIndex = fileIndex.getAndIncrement()) < files.length) {\n\t\tFileMetadata file = files[currentIndex];\n\t\tRename/delete(file);\n\t}\n\n\tThe above strategy depends on the fact that all files are stored in a final array and each thread has to determine synchronized next index to do the job. The advantage of this strategy is that even if user configures large number of unusable threads, we always ensure that work doesn’t get serialized due to lagging threads. \n\n\tWe are logging following information which can be useful for tuning number of threads\n\n\ta) Number of unusable threads\n\tb) Time taken by each thread\n\tc) Number of files processed by each thread\n\td) Total time taken for the operation\n\n\tFailure Scenarios:\n\n\tFailure to queue a thread execute request shouldn’t be an issue if we can ensure at least one thread has completed execution successfully. If we couldn't schedule one thread then we should take serialization path. Exceptions raised while executing threads are still considered regular exceptions and returned to client as operation failed. Exceptions raised while stopping threads and deleting thread pool shouldn't can be ignored if operation all files are done with out any issue.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12819518","id":"12819518","filename":"HADOOP-13403-001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-21T23:58:09.898+0000","size":41375,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12819518/HADOOP-13403-001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12820673","id":"12820673","filename":"HADOOP-13403-002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-28T07:43:25.975+0000","size":59352,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12820673/HADOOP-13403-002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12821152","id":"12821152","filename":"HADOOP-13403-003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-30T07:44:50.948+0000","size":67803,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12821152/HADOOP-13403-003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12821543","id":"12821543","filename":"HADOOP-13403-004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-02T08:24:01.602+0000","size":68802,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12821543/HADOOP-13403-004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12822369","id":"12822369","filename":"HADOOP-13403-005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-05T20:32:16.587+0000","size":68938,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12822369/HADOOP-13403-005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12822628","id":"12822628","filename":"HADOOP-13403-006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-08T18:33:47.324+0000","size":69022,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12822628/HADOOP-13403-006.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"AzureNativeFileSystem rename/delete performance improvements","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10430","value":"Patch","id":"10430"}],"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15388594","id":"15388594","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~pattipaka].  This sounds interesting.  I won't be certain until I see the code changes, but some of it (particularly the \"flat listing\" option) sounds similar to optimizations done for S3A listings in HADOOP-13208.  Cc'ing [~stevel@apache.org] who authored that patch, just FYI.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-07-21T23:15:38.812+0000","updated":"2016-07-21T23:15:38.812+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15388654","id":"15388654","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"[~cnauroth], I have submitted initial patch for review. HADOOP-13208 seems to generic implementation. Still going through details. My changes are specific to Native Azure FileSystem. I am using the flat listing option provided by Azure Storage client which returns all files and directories.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-22T00:11:04.637+0000","updated":"2016-07-22T00:11:04.637+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15389243","id":"15389243","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"HADOOP-13208 is for S3a; this does sound similar, at least for listing.\n\nWhat you are proposing here is async rename/delete, which is somewhat akin to HDFS-9924: the caller issues a command and doesn't wait for a response.\n\nI'm worried here at out the fact you propose radically changing the semantics of rename and delete, so that they are now async. A lot of code expects rename(), a the very least, to be synchronous. (They also assume its atomic O(1),....). If the application can explicitly enable this, or sets up its own async thread, we'll know that the app is compatible with async mv/rm. Otherwise, I'm doubtful.\n\nListing wise, yes, I'm trying to speed that up. FWIW, speeding up globStatus() looks even more promising, though I have to tread carefully to avoid making performance worse for real-world directory structures","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-07-22T09:54:18.667+0000","updated":"2016-07-22T09:54:18.667+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15389877","id":"15389877","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"Adding [~kiran.kolli]\n\n[~stevel@apache.org], This change doesn't introduce async rename/delete. The current proposal is still a blocking operation at delete/rename File System call level. This performance issue is specific Azure Native File System. This change shouldn't affect any API contracts at File System level.\n\nIf a folder has large number of files and directories then we are deleting one file or directory at a time with current code serially. Delete/rename on multiple individual files can be done in parallel and we are using multiple threads to do these operations on individual files or directories. I have already attached path which has code level details. Please let me know if you have any more concerns.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-22T17:30:30.878+0000","updated":"2016-07-22T17:30:30.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15390002","id":"15390002","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I see -no worries. I was thinking of the next step —to do it fully asynchronously. I do think I'd like that, but we will need to extend the API or add it to applications","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-07-22T18:29:50.533+0000","updated":"2016-07-22T18:29:50.533+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15397192","id":"15397192","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"Uploaded new patch. I have refactored code and added extra unit tests for failure scenarios.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-28T07:43:25.980+0000","updated":"2016-07-28T07:43:25.980+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15398117","id":"15398117","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 33s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 11s{color} | {color:orange} hadoop-tools/hadoop-azure: The patch generated 39 new + 43 unchanged - 1 fixed = 82 total (was 44) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 55 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  2s{color} | {color:red} The patch 4 line(s) with tabs. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 39s{color} | {color:red} hadoop-tools/hadoop-azure generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 31s{color} | {color:green} hadoop-azure in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 13m 27s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-tools/hadoop-azure |\n|  |  Redundant nullcheck of ioThreadPool, which is known to be non-null in org.apache.hadoop.fs.azure.NativeAzureFileSystem.executeParallel(NativeAzureFileSystem$AzureFileSystemOperation, String, FileMetadata[], String, int, Configuration, String, NativeAzureFileSystem$AzureFileSystemThreadOperation)  Redundant null check at NativeAzureFileSystem.java:is known to be non-null in org.apache.hadoop.fs.azure.NativeAzureFileSystem.executeParallel(NativeAzureFileSystem$AzureFileSystemOperation, String, FileMetadata[], String, int, Configuration, String, NativeAzureFileSystem$AzureFileSystemThreadOperation)  Redundant null check at NativeAzureFileSystem.java:[line 910] |\n|  |  Should org.apache.hadoop.fs.azure.NativeAzureFileSystem$AzureFileSystemThreadFactory be a _static_ inner class?  At NativeAzureFileSystem.java:inner class?  At NativeAzureFileSystem.java:[lines 717-737] |\n|  |  new org.apache.hadoop.fs.azure.NativeAzureFileSystem$AzureFileSystemThreadRunnable(NativeAzureFileSystem, NativeAzureFileSystem$AzureFileSystemOperation, String, FileMetadata[], NativeAzureFileSystem$AzureFileSystemThreadOperation) may expose internal representation by storing an externally mutable object into NativeAzureFileSystem$AzureFileSystemThreadRunnable.files  At NativeAzureFileSystem.java:NativeAzureFileSystem$AzureFileSystemThreadOperation) may expose internal representation by storing an externally mutable object into NativeAzureFileSystem$AzureFileSystemThreadRunnable.files  At NativeAzureFileSystem.java:[line 796] |\n|  |  Should org.apache.hadoop.fs.azure.NativeAzureFileSystem$AzureFileSystemThreadRunnable be a _static_ inner class?  At NativeAzureFileSystem.java:inner class?  At NativeAzureFileSystem.java:[lines 766-841] |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12820673/HADOOP-13403-002.patch |\n| JIRA Issue | HADOOP-13403 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 52faf7262ecd 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 26de4f0 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10108/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-azure.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/10108/artifact/patchprocess/whitespace-eol.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/10108/artifact/patchprocess/whitespace-tabs.txt |\n| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/10108/artifact/patchprocess/new-findbugs-hadoop-tools_hadoop-azure.html |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10108/testReport/ |\n| modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10108/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-28T20:02:05.403+0000","updated":"2016-07-28T20:02:05.403+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15398461","id":"15398461","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~pattipaka].  Thank you for the patch.\n\nI started code reviewing this while doing a full test run with the patch against my Azure Storage account.  I saw these failures:\n\n{code}\nTests run: 67, Failures: 1, Errors: 2, Skipped: 0, Time elapsed: 591.899 sec <<< FAILURE! - in org.apache.hadoop.fs.azure.TestFileSystemOperationsWithThreads\ntestRenameSigleRenameException(org.apache.hadoop.fs.azure.TestFileSystemOperationsWithThreads)  Time elapsed: 7.062 sec  <<< ERROR!\njava.lang.Exception: Unexpected exception, expected<java.io.IOException> but was<java.lang.AssertionError>\n\tat org.junit.Assert.fail(Assert.java:86)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.junit.Assert.assertTrue(Assert.java:52)\n\tat org.apache.hadoop.fs.azure.TestFileSystemOperationsWithThreads.testRenameSigleRenameException(TestFileSystemOperationsWithThreads.java:630)\n\ntestDeleteSigleDeleteException(org.apache.hadoop.fs.azure.TestFileSystemOperationsWithThreads)  Time elapsed: 4.289 sec  <<< ERROR!\njava.lang.Exception: Unexpected exception, expected<java.io.IOException> but was<java.lang.AssertionError>\n\tat org.junit.Assert.fail(Assert.java:86)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.junit.Assert.assertTrue(Assert.java:52)\n\tat org.apache.hadoop.fs.azure.TestFileSystemOperationsWithThreads.testDeleteSigleDeleteException(TestFileSystemOperationsWithThreads.java:479)\n\ntestDeleteSigleDeleteFailure(org.apache.hadoop.fs.azure.TestFileSystemOperationsWithThreads)  Time elapsed: 4.403 sec  <<< FAILURE!\njava.lang.AssertionError: null\n\tat org.junit.Assert.fail(Assert.java:86)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.junit.Assert.assertFalse(Assert.java:64)\n\tat org.junit.Assert.assertFalse(Assert.java:74)\n\tat org.apache.hadoop.fs.azure.TestFileSystemOperationsWithThreads.testDeleteSigleDeleteFailure(TestFileSystemOperationsWithThreads.java:455)\n{code}\n\nI'll halt my code review at this point so that you can investigate the test failures.  Here is my feedback so far, based on what I've read of the patch.\n\n{code}\n      threadCount = conf.getInt(config, defaultThreadCount);\n{code}\n\nI recommend restructuring this so that the thread count for delete and rename are read just once in {{NativeAzureFileSystem#initialize}} and stored to member variables.  Accessing {{Configuration}} can be expensive, and contributors reading the code generally expect to find all config access in {{initialize}}, not throughout other methods.\n\n{code}\n      // Enable flat listing option only if depth is unboubded and config \n{code}\n\nTypo: \"unbounded\".\n\n{code}\nDate start = new Date();\n// Do something.\nDate end = new Date();\nlong duration = end.getTime() - start.getTime();\n{code}\n\nFor all occurrences of logic like the above, please switch to using {{org.apache.hadoop.util.Time#monotonicNow()}}, which is a wrapper over the JDK [{{java.lang.System#nanoTime()}}|http://docs.oracle.com/javase/7/docs/api/java/lang/System.html#nanoTime()].  By switching to this, the logic won't be prone to issues caused by clock drift or resetting time on the host.\n\n{code}\n    private String threadIdPrefix = \"AzureFileSytemThread\";\n{code}\n\nTypo: \"AzureFileSystemThread\".\n\n{code}\n  enum AzureFileSystemOperation{\n    Unkown,\n    Delete,\n    Rename\n  }\n{code}\n\nTypo: \"Unknown\".\n\n{code}\n  class AzureFileSystemThreadFactory implements ThreadFactory {\n{code}\n\n{code}\n  public class AzureFileSystemThreadRunnable implements Runnable {\n{code}\n\n{{NativeAzureFileSystem}} is a pretty long class already.  I propose refactoring {{AzureFileSystemThreadFactory}} and {{AzureFileSystemThreadRunnable}} to top-level classes with package-private visibility in separate files.\n\n{code}\n        if ((ioThreadPool = getThreadPool(threadCount, threadNamePrefix)) != null) {\n{code}\n\nI don't understand the null check.  {{getThreadPool}} cannot return {{null}}, because it simply calls the {{ThreadPoolExecutor}} constructor and returns the new object.  I see some tests mock it to return {{null}}, but since this condition cannot really happen, why do we need test coverage for it?  The same feedback applies to the exception handling.  I do not see any checked exceptions thrown from {{getThreadPool}}.  The {{ThreadPoolExecutor}} constructor can throw unchecked exceptions if the arguments don't make sense (e.g. negative thread pool size), but we can validate the sanity of those configuration parameters during {{initialize}} after following the feedback above about configuration handling.\n\n{code}\n          lastException = new IOException(operation + \" failed as operation on subfolers and files failed.\");\n{code}\n\nTypo: \"subfolders\".\n\n{code}\n  @Test(expected=IOException.class)\n{code}\n\nPlease don't use this technique for writing tests that expect a certain exception.  The problem with this is that it's very coarse-grained.  It allows the test to pass if an {{IOException}} is thrown from any point in the method.  There are multiple points in these test methods where the exception can be thrown.  Even if it's thrown from the wrong place, JUnit will still think the test passed.  Instead, I recommend using the JUnit {{ExpectedException}} rule, which gives you fine-grained control of declaring exactly where you expect the exception to be thrown.  See {{TestS3AAWSCredentialsProvider}} for an example of an existing test suite that uses {{ExpectedException}}.\n\n{code}\n  public void testDeleteSigleDeleteFailure() throws Exception {\n{code}\n\n{code}\n  public void testDeleteSigleDeleteException() throws Exception {\n{code}\n\n{code}\n  public void testRenameSigleRenameException() throws Exception {\n{code}\n\nSame typo on all 3: \"Single\".\n\nThe FindBugs and Checkstyle warnings from the last pre-commit run look legitimate, so please fix those.  You can check these reports locally by running {{mvn -o findbugs:findbugs}} and {{mvn -o checkstyle:checkstyle}}.\n\nI recommend updating the documentation at src/site/markdown/index.md to describe this new feature and its configuration properties.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-07-29T00:00:09.194+0000","updated":"2016-07-29T00:00:09.194+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15399707","id":"15399707","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~pattipaka], in addition to the earlier code review feedback, I have a higher-level question about the implementation of the {{executeParallel}} method.\n\nTypical usage of a {{ThreadPoolExecutor}} is to configure it with a certain thread count and then submit multiple tasks, with each task performing a single isolated action.  When tasks are submitted, they get added to an internal queue (the {{LinkedBlockingQueue}} in your code).  Then, the number of threads all independently pull and execute tasks from the queue.\n\nThe {{executeParallel}} method in your current patch does not follow this typical usage of {{ThreadPoolExecutor}}.  Instead, it submits a number of tasks identical to the thread count, and the code in each task iterates through an array of work items ({{FileMetadata[]}}) tracked manually.  The array is shared state across all of those tasks/threads, so safe access requires additional synchronization code.\n\nIt appears the current {{executeParallel}} reimplements functionality already built into the {{ThreadPoolExecutor}}.  Switching this code to more idiomatic usage of {{ThreadPoolExecutor}} would make it easier for maintainers to understand, and it would remove the need for extra cross-thread synchronization, which is always tricky to get right.  For example, assuming 10 threads configured for {{fs.azure.delete.threads}} and a deletion of 100 blobs, I recommend using a {{ThreadPoolExecutor}} configured with 10 threads and submitting 100 task instances to it, each task deleting a single blob, with no shared state across the tasks/threads.\n\nI also see the current logic carefully tracks the last exception that happened on a thread.  Maybe that's why you implemented {{executeParallel}} this way?  However, there is also a more idiomatic way to look for exceptions: call {{ThreadPoolExecutor#submit}} for all tasks, track every returned {{Future}} in a list, and then iterate through that list calling {{Future#get}} on each one.  If any task encountered an exception, it would propagate as an {{ExecutionException}}, and then you can unwrap it to get the underlying exception that was thrown on the thread.\n\nI also see logic for handling {{RejectedExecutionException}}.  In practice, I expect this won't happen, because the {{LinkedBlockingQueue}} will cause the caller submitting the task to block instead of failing if it runs out of capacity.  If you're concerned about this, then another way to approach this is to look into [{{ThreadPoolExecutor.CallerRunsPolicy}}|http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadPoolExecutor.CallerRunsPolicy.html], which would fall back to running the task in the main submitting thread.\n\nIf there is some other reason I'm missing that requires the current unusual implementation of {{executeParallel}}, please let me know.  Thank you.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-07-29T17:15:20.819+0000","updated":"2016-07-29T17:15:20.819+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15400516","id":"15400516","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"[~cnauroth], thanks for your comments. I have incorporated your comments. I have fixed issues showed by findbugs and also fixed new errors shown with checkstyle.\n\nRegarding you questions on thread pools, I have removed null check for thread pool. I have retained other checks. getThreadPool may be called with very large value. It could be a naive mistake from user application. Hive script may pass this user configuration dynamically and the current thread may fail to allocate memory for thread pool. We don't want to fail the operation in this case. Instead we want to do serial processing which could go through and operation can be success. I have added unit tests to verify the behavior in case of any exception raised while creating thread pool.\n\nNot sure why you are seeing this assertion while running tests. I have modified these test cases as per your recommendation. If you still see the issue then I can take a look. I have verified that test cases are passing with latest changes (patch 003).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-30T07:30:25.433+0000","updated":"2016-07-30T07:30:25.433+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15400523","id":"15400523","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"[~cnauroth],\n\nRegarding your question on synchronization and idiomatic usage of ThreadPoolExecutor\n\nYes. But, it is very simple one and worth using it due to its benefits as explained below.\n1. The input data set is final and doesn't change. To ensure this, I have changed input parameter to be final. Further, we don't have a code paths which can change this input list.\n2. As the input array is final, each thread starts from index 0 and walks through till the end of the array. The synchronization is done through generating \"next index\" ATOMICALLY. This efficient way due to following reasons\n\ta) As the input set doesn't change, its overhead to convert array to synchronized queue. If number of files are in millions then having double memory is overkill.\n\tb) Each thread has to spend extra CPU to dequeue from synchronized queue which is costly compared to simple atomic increment.\n3. With above benefits, this method still ensures that work doesn't get delayed even if some threads got stuck due to some reasons.\n\n\nRegarding your question on use of futures\n\nThe reason for tracking lastException or operationStatus is to ensure\na) Failure of operation on single file means overall operation is failed anyway. No point in processing further by anyt threads. bail them out right away.\nb) In case if threads are still yet to be submitted then bail out there is well. A probable case in case we use large number of threads like 128 and the very first file processing encountered issue.\n\nIs there any way to achieve this through futures?\n\n\nRegarding your question on RejectedExecutionException,\n\nAfter thinking deep, may be this exception will not be raised as threadPool.shutdown happens on the same thread inline after submit calls are done. All submit requests must be accepted. But, having this code will ensure that operation is completed cleanly even if this exception occurs due to any reason. I have unit tests to validate the behavior as well. Please let me know if you find any issues in keeping this code.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-30T07:40:26.066+0000","updated":"2016-07-30T07:40:26.066+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15400524","id":"15400524","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"Uploading latest patch after fixing review comments, findbugs and checkstyle errors.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-30T07:44:50.952+0000","updated":"2016-07-30T07:44:50.952+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15400530","id":"15400530","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 33s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 11s{color} | {color:orange} hadoop-tools/hadoop-azure: The patch generated 2 new + 43 unchanged - 1 fixed = 45 total (was 44) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 19s{color} | {color:green} hadoop-azure in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 14m 22s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12821152/HADOOP-13403-003.patch |\n| JIRA Issue | HADOOP-13403 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 1d2583fec78d 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 8d32bd8 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10128/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-azure.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/10128/artifact/patchprocess/whitespace-eol.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10128/testReport/ |\n| modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10128/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-30T08:03:01.277+0000","updated":"2016-07-30T08:03:01.277+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15402836","id":"15402836","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you for sharing patch 003.\n\nIf the reason for the unusual executor logic is optimization, then I suggest adding more comments in the {{executeParallel}} JavaDocs to explain that.  I'm not sure that the memory optimization argument is true for the {{delete}} code path, where it still does a conversion from {{ArrayList}} to array.\n\nbq. Is there any way to achieve this through futures?\n\nIf the code had followed idiomatic usage, then the typical solution is to call {{ThreadPoolExecutor#submit}} for each task, track every returned {{Future}} in a list, and then iterate through the list and call {{Future#get}} on each one.  If any individual task threw an exception, then the call to {{Future#get}} would propagate that exception.  Then, that would give you an opportunity to call {{ThreadPoolExecutor#shutdownNow}} to cancel or interrupt all remaining tasks.  With the current logic though, I don't really see a way to adapt this pattern.\n\nRepeating an earlier comment, I don't see any exceptions thrown from {{getThreadPool}}, so coding exception handling around it and tests for it looks unnecessary.  If you check validity of {{deleteThreadCount}} and {{renameThreadCount}} in {{initialize}} (e.g. check for values <= 0) and fail fast by throwing an exception during initialization, then even unchecked exceptions will be impossible during calls to {{getThreadPool}}.\n\nI still see numerous test failures in {{TestFileSystemOperationsWithThreads}}.  For the next patch revision, would you please ensure all tests pass?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-01T21:15:17.547+0000","updated":"2016-08-01T21:15:17.547+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15403181","id":"15403181","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"[~cnauroth], Thanks for your comments.\n\nI will update with more comments on executeParallel and generate another patch.\n\nI had refactored code for both delete and rename operations to use single interface. Rename already has array and the array is already used at other locations. If we use ConcurrentLinkedQueue and remove contents from it then after executeParallel call, there won't be any entries in the queue. In future, if we need this array contents for reuse then we have to regenerate the list of files. If use array, we do the job with out loosing entries and can be useful for other cases in future.\n\nRegarding futures, I hope you agree to keep current pattern and not to use futures. \n\nRegarding getThreadPool, we are doing new operation. This can potentially result in OutOfMemoryException if we give very large value as input. This could especially happen even for little big number if the current thread has already reached the maximum heap size due to object object allocations like fileMeataData array[]. Even if we think of restricting this to a max value like 1024 then still OutOfmemory can cause with remote possibility. Currently, I couldn't think of other scenario, but don't want to realize it later which can make operation fail. Instead, for any kind of exceptions raised as part of new ThreadPoolExecutor() operation, we want to take serial path. I have already included checks for basic cases like check for threadCount > 1 after going through user configurations etc.. This is extra safety check on top of that.\n\nI ran tests and all of them are passing. Can you please provide details on what errors you are seeing?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-02T01:26:47.272+0000","updated":"2016-08-02T01:26:47.272+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15403276","id":"15403276","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"[~cnauroth], I have reproduced the test issue on Linux machines. On windows machines, these tests are passing. I will fix these tests on Linux machine in next patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-02T02:59:24.921+0000","updated":"2016-08-02T02:59:24.921+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15403402","id":"15403402","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, I agree about not using futures.\n\nIf available memory is so constrained that the JVM can't run the {{ThreadPoolExecutor}} constructor, then it's really already a lost cause.  At that point, the {{OutOfMemoryError}} could come from just about any line of code.  Even if we manage to fall back to serial execution after that, we'll likely either get another {{OutOfMemoryError}} or the JVM will be unresponsive due to GC churn.  {{OutOfMemoryError}} generally is not something recoverable, no matter how hard you try.\n\nI cannot think of any possible error condition from the {{getThreadPoolExecutor}} method that can be recovered reasonably.  If you really think it's important to keep this, then please comment that this is defensive coding despite the fact that there are no possible known recoverable error conditions right now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-02T05:44:09.836+0000","updated":"2016-08-02T05:44:09.836+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15403598","id":"15403598","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"[~cnauroth], I have included comment. Also, I have fixed unit tests to run by any user. fixed white space issue as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-02T08:22:47.167+0000","updated":"2016-08-02T08:22:47.167+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15403599","id":"15403599","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"Fixed white space issues, unit test issues added details for executeParallel method.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-02T08:24:01.607+0000","updated":"2016-08-02T08:24:01.607+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15403632","id":"15403632","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 38s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  0s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 24s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 10s{color} | {color:green} hadoop-tools/hadoop-azure: The patch generated 0 new + 43 unchanged - 1 fixed = 43 total (was 44) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 18s{color} | {color:green} hadoop-azure in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 13m 50s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12821543/HADOOP-13403-004.patch |\n| JIRA Issue | HADOOP-13403 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux e987e0228780 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / a5fb298 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10150/testReport/ |\n| modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10150/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-02T08:42:37.766+0000","updated":"2016-08-02T08:42:37.766+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15405074","id":"15405074","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~pattipaka], patch 004 looks good.  Thank you for incorporating the feedback.  My only other suggestion is to add a link to the new documentation section in the table of contents at the top of the index.md file.\n\nI'm also marking HADOOP-13459 as a pre-requisite for this patch.  While testing, I noticed that hadoop-azure test runs were taking a really long time.  The root cause is that we are accidentally re-running some of the test cases multiple times.  See my patch on HADOOP-13459 for full details.  For the next patch revision, please change {{TestFileSystemOperationsWithThreads}} to subclass {{AbstractWasbTestBase}} instead of {{NativeAzureFileSystemBaseTest}}.  You can test locally by applying my HADOOP-13459 patch.\n\nI'm going to click Cancel Patch now, because your next revision of the patch won't work against trunk until after HADOOP-13459 gets committed.  I'll click Submit Patch again after HADOOP-13459 gets committed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-03T00:19:32.038+0000","updated":"2016-08-03T00:19:32.038+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15405361","id":"15405361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~pattipaka], I have committed the HADOOP-13459 patch.  You can pull the latest trunk and pick up the {{AbstractWasbTestCase}} class to use in your patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-03T05:46:54.656+0000","updated":"2016-08-03T05:46:54.656+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15410029","id":"15410029","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"New patch after using using new base class for tests. Also fixed your latest comments. I have observed now that new test case execution takes only 30 sec.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-05T20:32:16.601+0000","updated":"2016-08-05T20:32:16.601+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15410961","id":"15410961","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 23s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 18s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 20s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 10s{color} | {color:green} hadoop-tools/hadoop-azure: The patch generated 0 new + 43 unchanged - 1 fixed = 43 total (was 44) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 18s{color} | {color:green} hadoop-azure in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 14m  1s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12822369/HADOOP-13403-005.patch |\n| JIRA Issue | HADOOP-13403 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 700d6849b033 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 131d58a |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10198/testReport/ |\n| modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10198/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-07T15:12:54.776+0000","updated":"2016-08-07T15:12:54.776+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15410971","id":"15410971","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~pattipaka], patch 005 looks great.  Thank you for the update.\n\nUnfortunately, it looks like we'll need one more patch revision.  I'll want to commit this to both trunk and branch-2.  The patch works fine on trunk, but the test code fails to compile when applied to branch-2.  (See below.)\n\nA potential explanation for this difference is that we build trunk with Java 8 and branch-2 with Java 7.  You might need to put explicit type bounds on the Mockito calls to fix this.\n\n{code}\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hadoop-azure: Compilation failure: Compilation failure:\n[ERROR] /Users/chris/git/hadoop/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestFileSystemOperationsWithThreads.java:[376,99] incompatible types: java.lang.Object cannot be converted to java.lang.Runnable\n[ERROR] /Users/chris/git/hadoop/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestFileSystemOperationsWithThreads.java:[424,118] incompatible types: java.lang.Object cannot be converted to java.lang.Runnable\n[ERROR] /Users/chris/git/hadoop/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestFileSystemOperationsWithThreads.java:[452,69] incompatible types: java.lang.Object cannot be converted to java.lang.Runnable\n[ERROR] /Users/chris/git/hadoop/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestFileSystemOperationsWithThreads.java:[571,99] incompatible types: java.lang.Object cannot be converted to java.lang.Runnable\n[ERROR] /Users/chris/git/hadoop/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestFileSystemOperationsWithThreads.java:[618,118] incompatible types: java.lang.Object cannot be converted to java.lang.Runnable\n[ERROR] /Users/chris/git/hadoop/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestFileSystemOperationsWithThreads.java:[649,69] incompatible types: java.lang.Object cannot be converted to java.lang.Runnable\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-07T15:52:24.820+0000","updated":"2016-08-07T15:52:24.820+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15412182","id":"15412182","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"[~cnauroth], Thanks. I will upload another path after fixing this issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-08T18:05:41.169+0000","updated":"2016-08-08T18:05:41.169+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15412229","id":"15412229","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"body":"Latest patch tested on both trunk and branch-2. Verified all tests are passing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=pattipaka","name":"pattipaka","key":"pattipaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Subramanyam Pattipaka","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-08T18:33:47.329+0000","updated":"2016-08-08T18:33:47.329+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15412269","id":"15412269","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  9m 18s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} hadoop-tools/hadoop-azure: The patch generated 0 new + 43 unchanged - 1 fixed = 43 total (was 44) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 29s{color} | {color:green} hadoop-azure in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 17m 42s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12822628/HADOOP-13403-006.patch |\n| JIRA Issue | HADOOP-13403 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 8be9946d46ca 3.13.0-92-generic #139-Ubuntu SMP Tue Jun 28 20:42:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 6255859 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10201/testReport/ |\n| modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10201/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-08T18:56:37.933+0000","updated":"2016-08-08T18:56:37.933+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15412325","id":"15412325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~pattipaka], thank you again for revising the patch.  +1 for patch 006.  I have committed this to trunk and branch-2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-08T19:34:08.649+0000","updated":"2016-08-08T19:34:08.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12991646/comment/15412361","id":"15412361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-trunk-Commit #10236 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10236/])\nHADOOP-13403. AzureNativeFileSystem rename/delete performance (cnauroth: rev 2ed58c40e5dcbf5c5303c00e85096085b1055f85)\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureFileSystemThreadPoolExecutor.java\n* hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestFileSystemOperationsWithThreads.java\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureFileSystemThreadTask.java\n* hadoop-tools/hadoop-azure/src/site/markdown/index.md\n* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java\n* hadoop-tools/hadoop-azure/src/test/resources/log4j.properties\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-08T20:01:27.695+0000","updated":"2016-08-08T20:01:27.695+0000"}],"maxResults":30,"total":30,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13403/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i31cnj:"}}