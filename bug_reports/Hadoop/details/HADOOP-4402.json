{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12406310","self":"https://issues.apache.org/jira/rest/api/2/issue/12406310","key":"HADOOP-4402","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Oct 20 21:37:54 UTC 2008","customfield_12310420":"126521","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_626792032_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_2684533701","customfield_12312321":null,"resolutiondate":"2008-10-20T21:38:12.773+0000","workratio":0,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4402/watchers","watchCount":2,"isWatching":false},"created":"2008-10-13T15:31:40.741+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":345600,"aggregatetimeoriginalestimate":345600,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313357","id":"12313357","description":"","name":"0.18.1","archived":false,"released":true,"releaseDate":"2008-09-17"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:43:21.470+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":345600,"description":"I think the name node is not told when there is block corruption.\n\nI found a huge number of files corrupted when I restarted my namenode.  Digging through the datanode logs, I saw the following:\n\n2008-10-13 03:30:44,266 INFO org.apache.hadoop.dfs.DataBlockScanner: Reporting bad block blk_-54103619973430645_3038 to namenode.\n2008-10-13 03:57:11,447 WARN org.apache.hadoop.dfs.DataBlockScanner: First Verification failed for blk_7657563767222456337_3165. Exception : java.io.IOException: Block blk_7657563767222456337_3165 is not valid.\n\tat org.apache.hadoop.dfs.FSDataset.getBlockFile(FSDataset.java:716)\n\tat org.apache.hadoop.dfs.FSDataset.getLength(FSDataset.java:704)\n\tat org.apache.hadoop.dfs.DataNode$BlockSender.<init>(DataNode.java:1678)\n\tat org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:408)\n\tat org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)\n\tat org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)\n\tat java.lang.Thread.run(Thread.java:595)\n\n2008-10-13 03:57:11,448 WARN org.apache.hadoop.dfs.DataBlockScanner: Second Verification failed for blk_7657563767222456337_3165. Exception : java.io.IOException: Block blk_7657563767222456337_3165 is not valid.\n\tat org.apache.hadoop.dfs.FSDataset.getBlockFile(FSDataset.java:716)\n\tat org.apache.hadoop.dfs.FSDataset.getLength(FSDataset.java:704)\n\tat org.apache.hadoop.dfs.DataNode$BlockSender.<init>(DataNode.java:1678)\n\tat org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:408)\n\tat org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)\n\tat org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)\n\tat java.lang.Thread.run(Thread.java:595)\n\n2008-10-13 03:57:11,448 INFO org.apache.hadoop.dfs.DataBlockScanner: Reporting bad block blk_7657563767222456337_3165 to namenode.\n\nSo, node099 found a bad block.  However, if I grep the namenode information for that block:\n\n/scratch/hadoop/logs/hadoop-root-namenode-hadoop-name.log.2008-10-10:2008-10-10 20:21:20,002 INFO org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/uscms01/LoadTestDownload/LoadTest07_FNAL_01_MyQXiu5a22TJQlcB_508. blk_7657563767222456337_3165\n/scratch/hadoop/logs/hadoop-root-namenode-hadoop-name.log.2008-10-10:2008-10-10 20:21:32,150 INFO org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 172.16.1.110:50010 is added to blk_7657563767222456337_3165 size 67108864\n/scratch/hadoop/logs/hadoop-root-namenode-hadoop-name.log.2008-10-10:2008-10-10 20:21:32,151 INFO org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 172.16.1.99:50010 is added to blk_7657563767222456337_3165 size 67108864\n/scratch/hadoop/logs/hadoop-root-namenode-hadoop-name.log.2008-10-12:2008-10-12 05:05:26,898 INFO org.apache.hadoop.dfs.StateChange: BLOCK* ask 172.16.1.99:50010 to replicate blk_7657563767222456337_3165 to datanode(s) 172.16.1.18:50010\n/scratch/hadoop/logs/hadoop-root-namenode-hadoop-name.log.2008-10-12:2008-10-12 05:05:40,742 INFO org.apache.hadoop.dfs.NameNode: Error report from 172.16.1.99:50010: Can't send invalid block blk_7657563767222456337_3165\n/scratch/hadoop/logs/hadoop-root-namenode-hadoop-name.log.2008-10-12:2008-10-12 05:12:43,759 WARN org.apache.hadoop.fs.FSNamesystem: PendingReplicationMonitor timed out block blk_7657563767222456337_3165\n\nTo summarize:\n- Block is allocated and written successfully to node100, then replicated to node099.\n- Name node asks node099 to replicate block to node018\n- Name node is told it can't send invalid block to node018!  A few minutes later, the PendingReplicationMonitor times out\n- No new replications are launched!!!\n- Block is found to be corrupted on node099 a few days later.  Data node claims to inform the namenode of this, but nothing is listed in the namenode logs.\n- Block is suspiciously missing on node110 as well\n\nPerhaps there are a few bugs here?\n1) Name node doesn't get notified of the corrupted blocks - even though the datanode claims to!\n2) On replication failure, no new replicas are created.\n3) Corruption events are much, much too common.  We have a specific dataset which the namenode now claims is mostly-corrupted (100/167 files); before I restarted the namenode, we had jobs run against it continuously for the entire weekend.  The jobs were all successful, and the binary data format does internal integrity checks as it reads the files.  If the corruption was real, jobs would have failed.\n\nI'm concerned that the corruption-detection systems of Hadoop are seriously busted for me. \n\n\n","customfield_10010":null,"timetracking":{"originalEstimate":"96h","remainingEstimate":"96h","originalEstimateSeconds":345600,"remainingEstimateSeconds":345600},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":345600,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"104338","customfield_12312823":null,"summary":"Namenode is unaware of FS corruption","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bockelman","name":"bockelman","key":"bockelman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brian Bockelman","active":true,"timeZone":"America/Chicago"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bockelman","name":"bockelman","key":"bockelman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brian Bockelman","active":true,"timeZone":"America/Chicago"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":345600,"percent":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":345600,"percent":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12406310/comment/12641166","id":"12641166","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bockelman","name":"bockelman","key":"bockelman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brian Bockelman","active":true,"timeZone":"America/Chicago"},"body":"Ah - mystery solved.  It turns out that there actually was a large-scale corruption event that took out half the hadoop data nodes, but no one realized it until the above recurred.\n\nWe have a \"scratch cleanup\" script which did a \"rm\" on all of the hadoop data directories for about 100 nodes.  So, starting at midnight, all the block verification attempts started failing because there were no blocks to read; when I restarted the namenode, the data nodes suddenly had new block reports saying they all had no blocks.\n\nPlease close.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bockelman","name":"bockelman","key":"bockelman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brian Bockelman","active":true,"timeZone":"America/Chicago"},"created":"2008-10-20T21:37:54.834+0000","updated":"2008-10-20T21:37:54.834+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4402/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0i7of:"}}