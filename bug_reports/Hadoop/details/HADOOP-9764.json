{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12659280","self":"https://issues.apache.org/jira/rest/api/2/issue/12659280","key":"HADOOP-9764","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2013-07-23T14:20:10.743+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jul 23 14:20:10 UTC 2013","customfield_12310420":"339473","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_20990347_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-07-23T14:20:42.765+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9764/watchers","watchCount":3,"isWatching":false},"created":"2013-07-23T08:30:52.439+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320248","id":"12320248","description":"maintenance release on branch-1.0","name":"1.0.3","archived":false,"released":true,"releaseDate":"2012-05-07"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-07-23T14:20:42.783+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Hi,\n\nI am new to Hadoop concepts. \nWhile practicing with one custom MapReduce program, I found the result is not as expected after executing the code on HDFS based file. Please note that when I execute the same program using Unix based file,getting expected result.\nBelow are the details of my code.\n\nMapReduce in java\n==================\n\nimport java.io.IOException;\nimport java.util.*;\n\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.conf.*;\nimport org.apache.hadoop.io.*;\nimport org.apache.hadoop.mapred.*;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.util.*;\n\npublic class WordCount1 {\n\n    public static class Map extends MapReduceBase implements Mapper {\n      private final static IntWritable one = new IntWritable(1);\n      private Text word = new Text();\n\n      public void map(LongWritable key, Text value, OutputCollector output, Reporter reporter) throws IOException {\n        String line = value.toString();\n        String tokenedZone=null;\n        StringTokenizer tokenizer = new StringTokenizer(line);\n        while (tokenizer.hasMoreTokens()) {\n          tokenedZone=tokenizer.nextToken();\n          word.set(tokenedZone);\n          output.collect(word, one);\n        }\n      }\n    }\n\n    public static class Reduce extends MapReduceBase implements Reducer {\n      public void reduce(Text key, Iterator values, OutputCollector output, Reporter reporter) throws IOException {\n        int sum = 0;\n        int val = 0;\n        while (values.hasNext()) {\n        \tval = values.next().get();\n        \tsum += val;\n        }\n        if(sum&gt;1)\n        \toutput.collect(key, new IntWritable(sum));\n      }\n    }\n\n    public static void main(String[] args) throws Exception {\n      JobConf conf = new JobConf();\n      conf.setJarByClass(WordCount1.class);\n      conf.setJobName(\"wordcount1\");\n      \n      conf.setOutputKeyClass(Text.class);\n      conf.setOutputValueClass(IntWritable.class);\n\n      conf.setMapperClass(Map.class);\n      conf.setCombinerClass(Reduce.class);\n      conf.setReducerClass(Reduce.class);\n\n      conf.setInputFormat(TextInputFormat.class);\n      conf.setOutputFormat(TextOutputFormat.class);\n      \n      Path inPath = new Path(args[0]);\n      Path outPath = new Path(args[0]);\n\n      FileInputFormat.setInputPaths(conf,inPath );\n      FileOutputFormat.setOutputPath(conf, outPath);\n\n      JobClient.runJob(conf);\n    }\n  \n}\n\n\ninput File\n===========\ntest my program\nduring test and my hadoop \nyour during\nget program\n\n\nhadoop generated output file on HDFS file system\n=======================================\nduring\t2\nmy\t2\ntest\t2\n\nhadoop generated output file on local file system\n=======================================\nduring\t2\nmy\t2\nprogram\t2\ntest\t2\n\nPlease help me on this issue\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"339793","customfield_12312823":null,"summary":"MapReduce output issue","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mullangi13","name":"mullangi13","key":"mullangi13","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mullangi","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mullangi13","name":"mullangi13","key":"mullangi13","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mullangi","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"ubuntu","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12659280/comment/13716415","id":"13716415","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Please use hadoop user mailing list to ask these type of questions. Jira is for reporting bugs. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-23T14:20:10.743+0000","updated":"2013-07-23T14:20:10.743+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9764/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1mjvb:"}}