{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12383903","self":"https://issues.apache.org/jira/rest/api/2/issue/12383903","key":"HADOOP-2346","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312913","id":"12312913","description":"","name":"0.17.0","archived":false,"released":true,"releaseDate":"2008-05-20"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2007-12-04T19:21:14.054+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Mar 06 12:27:33 UTC 2008","customfield_12310420":"42087","customfield_12312320":null,"customfield_12310222":"10002_*:*_3_*:*_182707792_*|*_1_*:*_3_*:*_7801116038_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6621881603","customfield_12312321":null,"resolutiondate":"2008-03-06T04:41:08.040+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2346/watchers","watchCount":5,"isWatching":false},"created":"2007-12-04T18:57:24.210+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"16.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312850","id":"12312850","description":"","name":"0.15.1","archived":false,"released":true,"releaseDate":"2007-11-27"}],"issuelinks":[{"id":"12318792","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12318792","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12383842","key":"HADOOP-2341","self":"https://issues.apache.org/jira/rest/api/2/issue/12383842","fields":{"summary":"Datanode active connections never returns to 0","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:42:45.338+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"If a client opens a file and stops reading in the middle, DataNode thread writing the data could be stuck forever. For DataNode sockets we set read timeout but not write timeout. I think we should add a write(data, timeout) method in IOUtils that assumes it the underlying FileChannel is non-blocking.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12377217","id":"12377217","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-06T02:11:39.012+0000","size":49448,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12377217/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12377113","id":"12377113","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-04T19:53:28.037+0000","size":49455,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12377113/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12377022","id":"12377022","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-03T23:35:41.157+0000","size":48761,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12377022/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12377010","id":"12377010","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-03T21:10:38.825+0000","size":48657,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12377010/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12376883","id":"12376883","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-01T00:41:56.137+0000","size":48097,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12376883/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12376761","id":"12376761","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-28T20:23:27.209+0000","size":47455,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12376761/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12376562","id":"12376562","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-26T22:31:18.808+0000","size":47549,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12376562/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12376558","id":"12376558","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-26T22:25:55.630+0000","size":46500,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12376558/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12376449","id":"12376449","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-25T21:42:57.836+0000","size":46500,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12376449/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12375863","id":"12375863","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-18T21:45:01.592+0000","size":45584,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12375863/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12375740","id":"12375740","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-16T01:48:01.779+0000","size":45846,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12375740/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12374914","id":"12374914","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-06T21:32:11.554+0000","size":37000,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12374914/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12374835","id":"12374835","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-06T00:22:49.440+0000","size":36660,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12374835/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12374817","id":"12374817","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-05T20:50:17.238+0000","size":37318,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12374817/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12373118","id":"12373118","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-14T19:48:44.141+0000","size":11406,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12373118/HADOOP-2346.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12373024","id":"12373024","filename":"HADOOP-2346.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-12T03:10:32.437+0000","size":11559,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12373024/HADOOP-2346.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"105743","customfield_12312823":null,"summary":"DataNode should have timeout on socket writes.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12548366","id":"12548366","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Write timeouts are only possible by using async i/o.  So would you have each thread to create its own selector and loop on it?  Is that wise?  Otherwise, implementing this would require converting the entire datanode to use async i/o, which is probably a good idea, but not a short-term one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-04T19:21:14.054+0000","updated":"2007-12-04T19:21:14.054+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12548372","id":"12548372","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"A new FilterInputStream would poll only when read or write fails with EAGAIN (some Java equivalent). So it does not slow down fast clients. I don't think a poll() costs much.. especially when we are polling when required. If there are a lot of clients reading from DataNode, bottleneck is most certainly going to be disk.\n\nWe don't strictly need this for 16.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-12-04T19:32:28.480+0000","updated":"2007-12-04T19:32:28.480+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12558190","id":"12558190","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nThis patch implements write timeout on datanodes for block reads.  Currently only client reads have write timeout. Once the fix looks good , we can write timeout in other places (while writing mirror for e.g.).\n\nThis adds two classes SocketInputStream and SocketOutputStream in IOUtils. Please suggest better names.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-12T03:10:32.611+0000","updated":"2008-01-12T03:10:32.611+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12558709","id":"12558709","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"This looks nice!  How well does it work?\n\nSocketInputStream and SocketOutputStream seem like fine names, but should they be nested classes in IOUtils, or perhaps independent classes in the 'net' package?\n\nAlso, we might make the error messages in the exceptions a bit more informative, e.g., including the address the socket is connected to, the timeout, etc.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-14T18:25:27.174+0000","updated":"2008-01-14T18:25:27.174+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12558755","id":"12558755","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> How well does it work?\n\nAll the unit tests pass and I tested with (artificially) slow clients. Performance wise, I don't expect any change. JRE has to do something like this anyway. select() is invoked only when we need to wait. We will surely run benchmarks before this goes, may be after 0.16 branch is cut. \n\n> SocketInputStream and SocketOutputStream seem like fine names, but should they be nested classes in IOUtils, or perhaps independent classes in the 'net' package?\n\nYes, these can be independent classes in io or net package. Currently there is a ipc.SocketOutputStream (not currently used in Hadoop), which is just a special case of SocketOutputStream here. ipc.SocketOutputStream will be removed.\n\n> Also, we might make the error messages in the exceptions a bit more informative, e.g., including the address the socket is connected to, the timeout, etc.\nshould do this.\n\nWhen I prepare more complete patch for 0.17, I think we should replace all socket input/output streams in Datanode with these.\n\nAlso WRITE_TIMEOUT of 1 minute might be too short.\n\nThe patch attached does not have above changes, it just has some minor changes from previous patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-14T19:48:44.840+0000","updated":"2008-01-14T19:48:44.840+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12564295","id":"12564295","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=menicosia","name":"menicosia","key":"menicosia","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marco Nicosia","active":true,"timeZone":"Etc/UTC"},"body":"If you're preparing a more complete patch for Hadoop 0.17, can we apply this patch for Hadoop 0.16.1?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=menicosia","name":"menicosia","key":"menicosia","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marco Nicosia","active":true,"timeZone":"Etc/UTC"},"created":"2008-01-31T04:57:00.261+0000","updated":"2008-01-31T04:57:00.261+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12564446","id":"12564446","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Marco, is this bug causing real problems for your users?  If so, it might merit becoming a blocker for 0.16.1.\n\nThe patch introduces new public APIs, and thus we must be certain that these are APIs we wish to support long-term.  Since the new classes are network-specific, they belong in org.apache.hadoop.net, not org.apache.hadoop.io, where they are in the current patch.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-31T18:31:32.432+0000","updated":"2008-01-31T18:31:32.432+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12564543","id":"12564543","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"If remember correctly many cases that Koji noticed had DFSClient and one or more datanodes were stuck on socket writes (while writing new blocks). What happens is that when a datanode is writing block data to local disk, disk write gets stuck forever (due to various kernel problems... that mount might have spontaneously become read-only), this blocked write to disk essentially stalls write pipeline from that datanode up to DFSClient.\n\nThis is pre HADOOP-1707. I am not sure same condition still stalls the write pipeline in trunk, it might.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-31T23:13:44.523+0000","updated":"2008-01-31T23:14:05.247+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12564557","id":"12564557","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> I am not sure same condition still stalls the write pipeline in trunk\nLooks like trunk would be affected in the same way.\n\nWhat should the write timeouts be? (my recommendation in the braces) : \n\n# Read : when datanode is serving data to client (10 min)\n# Write : When client is writing data to DFS. Unlike read, this timeout is more 'disruptive' and thus needs to be more conservative. (10 min).\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-01-31T23:53:28.568+0000","updated":"2008-01-31T23:53:28.568+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12565886","id":"12565886","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nPatch for trunk is attached. All of DataNode and DFSClient sockets have write timeouts. The read timeout remains the same as before. The new streams are in hadoop.net package (strictly, they work one any socket with a selectable channel).\n\nThere are multiple public APIs. Doug, please take a look. The static methods in NetUtils are required to support flexible SocketFactory implementations where the sockets might not have a channel. Since the default socket factory returns a socket with a channel, regular streams from Socket.getInput/OutputStream methods seem to have a [problem|http://www.nabble.com/blocking-read-on-a-socket-blocks-write-too--tt15294234.html]. \n\n3 files are added under hadoop/net and one file is removed from hadoop/ipc.\n\ntest-core passes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-05T20:50:17.383+0000","updated":"2008-02-05T20:50:17.383+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12566002","id":"12566002","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nidaley","name":"nidaley","key":"nidaley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nigel Daley","active":true,"timeZone":"Etc/UTC"},"body":"-1.  No regression test and new unit test(s) for new api's.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nidaley","name":"nidaley","key":"nidaley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nigel Daley","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-06T03:36:21.727+0000","updated":"2008-02-06T03:36:21.727+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12566250","id":"12566250","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nJava Selector creation seems pretty heavy for a single filedescriptor polling. The current patch creates one selector for each stream. Looks like each selector takes up 3 fds: 2 for a pipe (used for {{wakeup()}, I guess) and for epoll().\n\nEven if we are ok with these extra fds for each stream, it still requires users to close the stream explicitly (to close the selector). Opening and closing new selector each time we wait might be costly be because of this extra pipe it uses.\n\nIf these streams aim to be drop in replacements for Socket's own streams, they should either clean up  automatically when the channel is closed, or better, should not require a {{close()}}.\n\nAnyone aware of a bare-bones selector or an alternate to a selector? Some thing that is a thin wrapper over {{poll()}}, without extra set up and extra fds for pipe and epoll?\n\nI think it is still possible to implement these streams with a single global Selector, without an extra thread. Registering and deregistering a channel each time we want to wait won't be costly. This way, stream does not need a close().\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-06T18:17:12.249+0000","updated":"2008-02-06T18:17:12.249+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12566264","id":"12566264","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Given the above issues, this is probably not a 0.16.1 jira. I would like to implement these with single selector if there are no better alternatives. But it might not be suitable for 0.16.1.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-06T18:43:59.611+0000","updated":"2008-02-06T18:43:59.611+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12566350","id":"12566350","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nUpdated patch that works well. SocketInputStream and SocketOutputStream are true drop in replacements for socket.getInputStream() and socket.getOutputStream() (i.e. they don't need to be closed).\n\nOf course this takes easy route around for the issues mentioned above: it creates new Selector for each time the IO needs to wait.\n\nAlso this does not have unit tests. Review of rest of patch, especially the public API would be very useful.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-06T21:32:11.718+0000","updated":"2008-02-06T21:32:11.718+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12569061","id":"12569061","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"My recommendation for committing this patch :\n\n- This is a change for low level streams and thus not appropriate for mostly stable 0.16. \n- This can go in to 0.17 sooner than later. Once it gets tested there, we can always back port it to 0.16 if we really need it.\n- The current patch is pretty OK. I will have an improved implementation of {{SocketIOWithTimout}} when I get some more time in next couple of weeks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-14T19:39:27.297+0000","updated":"2008-02-14T19:39:27.297+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12569071","id":"12569071","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"This looks reasonable to me.  +1 for 0.17.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-14T20:01:24.444+0000","updated":"2008-02-14T20:01:24.444+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12569483","id":"12569483","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nUpdate patch that I think is complete is attached.\n\nThis uses a pool of Selectors. This pool grows and shrinks with the number of threads blocked on these sockets. No extra thread is used. Selector is closed if it stays inactive for 30 sec (next time some thread blocks or wakes up). This should not have any perf penalty.\n\nEarlier I was thinking of using just one selector all threads waiting on read and one for all threads waiting on write.. I don't think that complexity is required.\n\nThese streams can be used with other channels like pipes and UDP sockets. The unit test uses pipes.\n\nI don't think this patch needs to wait till performance evaluation. \n\nUnit test: a new test is added to test timeout and read and write. Note that pretty much every DFS unit test test these streams.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-16T01:48:01.921+0000","updated":"2008-02-16T01:48:01.921+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12570016","id":"12570016","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"minor changes : mostly JavaDoc fixes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-18T21:45:02.971+0000","updated":"2008-02-18T21:45:02.971+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12572253","id":"12572253","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nUpdated patch. Added JavaDoc for private class SelectorPool in SocketIOWithTimeout.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-25T21:42:58.898+0000","updated":"2008-02-25T21:42:58.898+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12572695","id":"12572695","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"more comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-26T22:25:55.663+0000","updated":"2008-02-26T22:25:55.663+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12572780","id":"12572780","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"The ideas are really good.  Not able to finish reading the patch yet.  Got some comments:\n- SocketIOWithTimeout.read is not needed.  It might be a local variable in doIO(ByteBuffer buf), i.e.\n{code}\nsynchronized int doIO(ByteBuffer buf) throws IOException {\n  boolean read = channel instanceof ReadableByteChannel;\n  ...\n}\n{code}\n\n- The class SocketIOWithTimeout serves both ReadableByteChannel and WritableByteChannel.  It might be better to make SocketIOWithTimeout abstract and create two sub-classes for ReadableByteChannel and WritableByteChannel.  Then, the runtime checking can be eliminated\n\n- SocketIOWithTimeout.isClosed() should check channel.isOpen() and update SocketIOWithTimeout.closed if necessary.  Then SocketInputStream.isOpen() should just return !socketIO.isClosed().\n\n- Instead of implementing a linked list by ProviderInfo.next, it is better to use a list class provided in java.util.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-27T04:21:43.962+0000","updated":"2008-02-27T04:21:43.962+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12572793","id":"12572793","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"- > [...] {{boolean read = channel instanceof ReadableByteChannel;}}\n-- This won't work because most channels are both Readable and Writable.\n\n- >[...] Then, the runtime checking can be eliminated\n-- Can't really eliminate runtime checking. For e.g. SocketInputStream's channel should be both SelectableChannel and a ReadableByteChannel. How do we enforce that without runtime check?\n\n- > SocketIOWithTimeout.isClosed() should check [...]\n-- sure. Not much different but will  make the change.\n\n- > Instead of implementing a linked list by ProviderInfo.next [...]\n-- :) reminds of earlier days. I implemented only because we don't remove from the list. If we want an advantage, we iterate on the list (mostly has just one elemement) twice everytime we wait.. so avoids allocation of iterator twice. I think this is ok.. let me know if we should. Using java.util.LinkedList does not make number of lines less, with all the generics stuff, it surely takes more bytes :).\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-27T05:19:16.005+0000","updated":"2008-02-27T05:19:16.005+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12572794","id":"12572794","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"more on LinkedList: I also needed a list that compares references. With LinkedList it calls equals. For this I can have a own small class that wraps a provider. But that implies we create a new object each time to search in the list and the code for the new class, etc.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-27T05:26:12.338+0000","updated":"2008-02-27T05:26:12.338+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12573431","id":"12573431","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nUpdated patch attached.\n- fixed couple of conflicts HADOOP-1985\n- SocketIOWithTimeout.isOpen() checks channel.isOpen() as Nicholas suggested.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-28T20:23:27.236+0000","updated":"2008-02-28T20:23:27.236+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12573932","id":"12573932","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"- For ProviderInfo.next, I agreed that your implementation is more efficient and use less memory.  +1 since this class is a low level class.\n\n- >This won't work because most channels are both Readable and Writable.\nActually, I think the boolean variable read can be eliminated.  See below.\n\n- > Can't really eliminate runtime checking. For e.g. SocketInputStream's channel should be both SelectableChannel and a ReadableByteChannel. How do we enforce that without runtime check?\n\nIn the constructor of SocketIOWithTimeout, you already enforce if read is true, channel must be a ReadableByteChannel, otherwise, channel must be a WritableByteChannel.  I do not see a good reason to put ReadableByteChannel and WritableByteChannel in the same class and use a boolean to remember whether it is doing read or write.\n\nI suggest to add two classes, say ReadableSocketIOWithTimeout and WritableSocketIOWithTimeout, both extending SocketIOWithTimeout.  Then, the fields layout will become:\n{code}\nabstract class SocketIOWithTimeout {\n  private long timeout;\n  private boolean closed = false;\n}\n\nclass ReadableSocketIOWithTimeout extends SocketIOWithTimeout {\n  private ReadableByteChannel in;\n}\n\nclass WritableSocketIOWithTimeout extends SocketIOWithTimeout {\n  private WritableByteChannel out;\n}\n{code}\n\n- Also found some typs in SocketIOWithTimeout.java \nline 59, /* => /**\nline 119, mutliple => multiple\nline 247, canceled => canceled\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T20:13:38.693+0000","updated":"2008-02-29T20:13:38.693+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12573961","id":"12573961","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> Actually, I think the boolean variable read can be eliminated.\n:) one variable can always be 'eliminated' using one or more different variables. \n\nWhat is the problem you want to fix? Is it that we don't want a boolean? Or we should not do runtime cast in doIO()?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T21:04:54.757+0000","updated":"2008-02-29T21:04:54.757+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12574003","id":"12574003","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> What is the problem you want to fix?\n\nThe class SocketIOWithTimeout has two different uses, reading and writing.  Why not create two classes?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T23:07:54.475+0000","updated":"2008-02-29T23:07:54.475+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12574034","id":"12574034","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> The class SocketIOWithTimeout has two different uses, reading and writing. Why not create two classes?\n\nThat's why we have SocketInputStream and SocketOutputStream, right? I don't know advantage of two more classes on top of 3 we already have.\n\nSocketIOWithTimeout is just a helper class for reading and writing with a timeout. Its is not user facing. I still don't follow the problem completely. It will be best if you could modify the patch to how you wanted it to be.. that way I understand what you mean.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-01T00:40:50.863+0000","updated":"2008-03-01T00:40:50.863+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12574035","id":"12574035","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"My latest attempt at working around boolean and not do runtime check in doIO().","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-01T00:41:56.171+0000","updated":"2008-03-01T00:41:56.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12574735","id":"12574735","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nUpdated patch makes SocketIOWithTimeout an abstract class.\n\nFixed typos except one. The comment above SocketIOWithTimeout  is not meant to be JavaDoc. \n\nNicholas, please take a look again if this matches the hierarchy. Thanks for the reviews.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-03T21:10:38.860+0000","updated":"2008-03-03T21:10:38.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12574765","id":"12574765","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"+1.  Codes look good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-03T22:22:48.259+0000","updated":"2008-03-03T22:22:48.259+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12574790","id":"12574790","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Resolved conflicts with HADOOP-2758.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-03T23:35:41.189+0000","updated":"2008-03-03T23:35:41.189+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12574825","id":"12574825","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12377022/HADOOP-2346.patch\nagainst trunk revision 619744.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 3 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs -1.  The patch appears to introduce 3 new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-03-04T03:19:54.191+0000","updated":"2008-03-04T03:19:54.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12575116","id":"12575116","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Fixed findbugs warnings. Findbugs is smart enough to know that socket.getOutputStream() does not need to be closed..  it does not know hadoop.net.SocketOutputStream() is a true drop in replacement.  I think eventually we will write a 'FilterSocket' and override getOutputStream() and getInputStream().\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-04T19:53:28.075+0000","updated":"2008-03-04T19:53:28.075+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12575189","id":"12575189","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12377113/HADOOP-2346.patch\nagainst trunk revision 619744.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 3 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-03-04T23:21:39.055+0000","updated":"2008-03-04T23:21:39.055+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12575535","id":"12575535","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Resolved conflict with the trunk.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-06T02:11:39.058+0000","updated":"2008-03-06T02:11:39.058+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12575556","id":"12575556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \nhttp://issues.apache.org/jira/secure/attachment/12377217/HADOOP-2346.patch\nagainst trunk revision 619744.\n\n    @author +1.  The patch does not contain any @author tags.\n\n    tests included +1.  The patch appears to include 3 new or modified tests.\n\n    javadoc +1.  The javadoc tool did not generate any warning messages.\n\n    javac +1.  The applied patch does not generate any new javac compiler warnings.\n\n    release audit +1.  The applied patch does not generate any new release audit warnings.\n\n    findbugs +1.  The patch does not introduce any new Findbugs warnings.\n\n    core tests +1.  The patch passed core unit tests.\n\n    contrib tests +1.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-03-06T04:06:17.672+0000","updated":"2008-03-06T04:06:17.672+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12575560","id":"12575560","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-03-06T04:41:07.960+0000","updated":"2008-03-06T04:41:07.960+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12383903/comment/12575666","id":"12575666","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk #421 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/421/])","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2008-03-06T12:27:33.498+0000","updated":"2008-03-06T12:27:33.498+0000"}],"maxResults":39,"total":39,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2346/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0igcn:"}}