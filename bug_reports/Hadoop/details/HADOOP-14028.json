{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13038288","self":"https://issues.apache.org/jira/rest/api/2/issue/13038288","key":"HADOOP-14028","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329058","id":"12329058","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12339180","id":"12339180","name":"3.0.0-alpha4","archived":false,"released":true,"releaseDate":"2017-07-07"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-01-26T22:35:18.728+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Feb 25 16:54:38 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_11_*:*_517444536_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_11_*:*_2053027187","customfield_12312321":null,"resolutiondate":"2017-02-25T16:17:08.160+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14028/watchers","watchCount":11,"isWatching":false},"created":"2017-01-26T22:15:56.516+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"11.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329058","id":"12329058","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"issuelinks":[{"id":"12494229","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12494229","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"outwardIssue":{"id":"13041953","key":"HADOOP-14071","self":"https://issues.apache.org/jira/rest/api/2/issue/13041953","fields":{"summary":"S3a: Failed to reset the request input stream","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12494459","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12494459","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13042881","key":"HADOOP-14081","self":"https://issues.apache.org/jira/rest/api/2/issue/13042881","fields":{"summary":"S3A: Consider avoiding array copy in S3ABlockOutputStream (ByteArrayBlock)","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12492620","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12492620","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"inwardIssue":{"id":"13001280","key":"HADOOP-13560","self":"https://issues.apache.org/jira/rest/api/2/issue/13001280","fields":{"summary":"S3ABlockOutputStream to support huge (many GB) file writes","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12495781","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12495781","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"12780618","key":"HADOOP-11694","self":"https://issues.apache.org/jira/rest/api/2/issue/12780618","fields":{"summary":"Ãœber-jira: S3a phase II: robustness, scale and performance","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-04-21T21:53:07.616+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"I have `fs.s3a.fast.upload` enabled with 3.0.0-alpha2 (it's exactly what I was looking for after running into the same OOM problems) and don't see it cleaning up the disk-cached blocks.\n\nI'm generating a ~50GB file on an instance with ~6GB free when the process starts. My expectation is that local copies of the blocks would be deleted after those parts finish uploading, but I'm seeing more than 15 blocks in /tmp (and none of them have been deleted thus far).\n\nI see that DiskBlock deletes temporary files when closed, but is it closed after individual blocks have finished uploading or when the entire file has been fully written to the FS (full upload completed, including all parts)?\n\nAs a temporary workaround to avoid running out of space, I'm listing files, sorting by atime, and deleting anything older than the first 20: `ls -ut | tail -n +21 | xargs rm`\n\nSteve Loughran says:\n\n> They should be deleted as soon as the upload completes; the close() call that the AWS httpclient makes on the input stream triggers the deletion. Though there aren't tests for it, as I recall.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329058","id":"12329058","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12853116","id":"12853116","filename":"HADOOP-14028-006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-16T19:27:16.199+0000","size":59571,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12853116/HADOOP-14028-006.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12853598","id":"12853598","filename":"HADOOP-14028-007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-20T18:46:05.854+0000","size":59535,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12853598/HADOOP-14028-007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12850437","id":"12850437","filename":"HADOOP-14028-branch-2.8-002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-01T15:08:46.062+0000","size":39551,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12850437/HADOOP-14028-branch-2.8-002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12850704","id":"12850704","filename":"HADOOP-14028-branch-2.8-003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-02T22:20:36.326+0000","size":43459,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12850704/HADOOP-14028-branch-2.8-003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12850887","id":"12850887","filename":"HADOOP-14028-branch-2.8-004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-03T20:22:43.515+0000","size":43449,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12850887/HADOOP-14028-branch-2.8-004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12852840","id":"12852840","filename":"HADOOP-14028-branch-2.8-005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-15T15:33:25.115+0000","size":54639,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12852840/HADOOP-14028-branch-2.8-005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12853765","id":"12853765","filename":"HADOOP-14028-branch-2.8-007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-21T15:33:02.738+0000","size":59535,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12853765/HADOOP-14028-branch-2.8-007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12854467","id":"12854467","filename":"HADOOP-14028-branch-2.8-008.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T13:23:31.250+0000","size":59543,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12854467/HADOOP-14028-branch-2.8-008.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12850274","id":"12850274","filename":"HADOOP-14028-branch-2-001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T17:45:42.085+0000","size":36701,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12850274/HADOOP-14028-branch-2-001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12854576","id":"12854576","filename":"HADOOP-14028-branch-2-008.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T21:29:10.086+0000","size":59538,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12854576/HADOOP-14028-branch-2-008.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12854597","id":"12854597","filename":"HADOOP-14028-branch-2-009.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T22:43:04.596+0000","size":59413,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12854597/HADOOP-14028-branch-2-009.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"S3A BlockOutputStreams doesn't delete temporary files in multipart uploads or handle part upload failures","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"JDK 8 + ORC 1.3.0 + hadoop-aws 3.0.0-alpha2","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15840574","id":"15840574","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"https://github.com/apache/hadoop/blob/6c348c56918973fd988b110e79231324a8befe12/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java#L490 suggests that it should.\n\nOnce I get this file created and uploaded, I'll try enabling debug logging for S3A to get a clearer idea of what's happening.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-26T22:24:36.742+0000","updated":"2017-01-26T22:24:36.742+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15840583","id":"15840583","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"that Block.close() doesn't delete the file, it's one in {{org.apache.hadoop.fs.s3a.S3ADataBlocks.DiskBlock.FileDeletingInputStream}}; the AWS transfer manager is doing the close\n\n\nWhat are your various queue options....I'd like to know how many blocks are going up in parallel, or at least being queued? It might be there's enough of a backlog that there is that much pending data. Or, as you suggest, we aren't deleting things.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-26T22:35:18.728+0000","updated":"2017-01-26T22:35:18.728+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15840605","id":"15840605","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"Reading through the AWS SDK code, it looks like this is the line ultimately responsible for closing the input stream: https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-core/src/main/java/com/amazonaws/internal/ReleasableInputStream.java#L85\n\nI'm using the default settings (other than {{fs.s3a.fast.upload=true}}).\n\nFrom watching the atimes, it looks like there's only 1 block going up at a time while the next one fills up. (My producer is relatively slow and I'm running in EC2, so it makes sense that the uploader can keep up).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-26T22:52:44.423+0000","updated":"2017-01-26T22:52:55.417+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15845882","id":"15845882","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"With logging enabled (and extra debug code added), I can confirm that {{FileDeletingInputStream}} isn't being closed as expected. Everything else is working as expected (on my slower uplink at home the producer blocks as hoped for).\n\nHere's the workaround I'm going to use for the time-being (tested and working):\n\n{code}\ndiff --git i/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java w/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java\nindex 0fe2af7943..3848ecc3f8 100644\n--- i/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java\n+++ w/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java\n@@ -758,7 +758,13 @@ protected void innerClose() throws IOException {\n         break;\n \n       case Closed:\n-        // no-op\n+        if (bufferFile.exists()) {\n+          LOG.debug(\"Deleting buffer file {} after completion\", bufferFile);\n+          boolean deleted = bufferFile.delete();\n+          if (!deleted && bufferFile.exists()) {\n+            LOG.warn(\"Failed to delete buffer file {}\", bufferFile);\n+          }\n+        }\n         break;\n \n       default:\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-30T20:45:12.439+0000","updated":"2017-01-30T20:45:12.439+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15845932","id":"15845932","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"OK, I'll look at this.\n\nOne issue I hit in the past is this: if the blocks aren't being deleted, the input stream is still open, which is wrong, and will lead to problems if the output is still ongoing. That's why the delete call is where it is right now\n\nI plan to add some metric tracking of #of outstanding blocks; then modify the scale tests to verify that for all output mechanisms the output is cleaned up. But I don't just want to do that clean up in that closed call without understanding what's happening.\n\nthanks for looking into this; we should be able to fix it fairly quickly","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-30T21:12:04.211+0000","updated":"2017-01-30T21:12:04.211+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15845961","id":"15845961","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"Yup, totally makes sense.\n\nThanks for diving in. If I can be of any more help, please let me know.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-01-30T21:24:08.860+0000","updated":"2017-01-30T21:24:08.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847023","id":"15847023","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I've added some instrumentation and can confirm that this appears to be the case on branch-2+ for multipart uploads\n\nIf you are doing single block PUTs, then the stream is being closed correctly. Which is presumably why I have memories of problems when I was deleting the input in the block.close(): because if the stream was still open then, problems\n\nPut differently: single block PUT: stream closes; multipart upload: stream stays open.\n\nsingle block put completion; look for \"close stream\" at debug to indicate stream was explicitly closed\n{code}\n2017-01-31 16:06:43,358 [JUnit-testBlocksClosed] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:startUpload(260)) - Start datablock[1] upload\n2017-01-31 16:06:43,358 [JUnit-testBlocksClosed] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:enterState(167)) - FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-2613007414198033258.tmp, state=Writing, dataSize=16, limit=5242880}: entering state Upload\n2017-01-31 16:06:43,359 [JUnit-testBlocksClosed] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:clearActiveBlock(209)) - Clearing active block\n2017-01-31 16:06:43,360 [s3a-transfer-shared-pool1-t2] DEBUG amazonaws.request (AmazonHttpClient.java:executeOneRequest(1046)) - Sending Request: PUT https://hwdev-steve-ireland-new.s3-eu-west-1.amazonaws.com /test/testBlocksClosed Headers: (User-Agent: Hadoop 2.9.0-SNAPSHOT, aws-sdk-java/1.11.45 Mac_OS_X/10.12.2 Java_HotSpot(TM)_64-Bit_Server_VM/25.102-b14/1.8.0_102, amz-sdk-invocation-id: 4596ee4b-a9bd-da45-6c8c-67b6c8ff18a2, Content-Length: 16, Content-Type: application/octet-stream, ) \n2017-01-31 16:06:43,361 [s3a-transfer-shared-pool1-t2] DEBUG auth.AWS4Signer (CommonsLog.java:debug(33)) - AWS4 Canonical Request: '\"PUT\n/test/testBlocksClosed\n\namz-sdk-invocation-id:4596ee4b-a9bd-da45-6c8c-67b6c8ff18a2\namz-sdk-retry:0/0/500\ncontent-length:16\ncontent-type:application/octet-stream\nhost:hwdev-steve-ireland-new.s3-eu-west-1.amazonaws.com\nuser-agent:Hadoop 2.9.0-SNAPSHOT, aws-sdk-java/1.11.45 Mac_OS_X/10.12.2 Java_HotSpot(TM)_64-Bit_Server_VM/25.102-b14/1.8.0_102\nx-amz-content-sha256:UNSIGNED-PAYLOAD\nx-amz-date:20170131T160643Z\n\namz-sdk-invocation-id;amz-sdk-retry;content-length;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\nUNSIGNED-PAYLOAD\"\n2017-01-31 16:06:43,361 [s3a-transfer-shared-pool1-t2] DEBUG auth.AWS4Signer (CommonsLog.java:debug(33)) - AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n20170131T160643Z\n20170131/eu-west-1/s3/aws4_request\n3d06bfd2a67d99075b7bda392543c0d537232b95f22e66457c87c2e1445aa166\"\n2017-01-31 16:06:43,417 [s3a-transfer-shared-pool1-t2] DEBUG amazonaws.request (AwsResponseHandlerAdapter.java:handle(87)) - Received successful response: 200, AWS Request ID: AC9D7DE63C4BA32D\n2017-01-31 16:06:43,417 [s3a-transfer-shared-pool1-t2] DEBUG amazonaws.requestId (AwsResponseHandlerAdapter.java:logHeaderRequestId(136)) - x-amzn-RequestId: not available\n2017-01-31 16:06:43,417 [s3a-transfer-shared-pool1-t2] DEBUG amazonaws.requestId (AwsResponseHandlerAdapter.java:logResponseRequestId(156)) - AWS Request ID: AC9D7DE63C4BA32D\n2017-01-31 16:06:43,417 [s3a-transfer-shared-pool1-t2] INFO  s3a.S3ADataBlocks (S3ADataBlocks.java:close(886)) - Block[1] closing stream of buffer file target/build/test/s3a/s3ablock-0001-2613007414198033258.tmp\n2017-01-31 16:06:43,418 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:closeBlock(860)) - block[1]: closeBlock()\n2017-01-31 16:06:43,418 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:enterState(167)) - FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-2613007414198033258.tmp, state=Upload, dataSize=16, limit=5242880}: entering state Closed\n2017-01-31 16:06:43,418 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:close(282)) - Closed FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-2613007414198033258.tmp, state=Closed, dataSize=16, limit=5242880}\n2017-01-31 16:06:43,418 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:innerClose(807)) - Closing FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-2613007414198033258.tmp, state=Closed, dataSize=16, limit=5242880}\n2017-01-31 16:06:43,419 [JUnit-testBlocksClosed] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:close(354)) - Upload complete for {bucket=hwdev-steve-ireland-new, key='test/testBlocksClosed'}\n2017-01-31 16:06:43,419 [JUnit-testBlocksClosed] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:close(359)) - Closing block and factory\n2017-01-31 16:06:43,419 [JUnit-testBlocksClosed] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:close(362)) - Statistics: OutputStreamStatistics{blocksSubmitted=1, blocksInQueue=1, blocksActive=0, blockUploadsCompleted=0, blockUploadsFailed=0, bytesPendingUpload=0, bytesUploaded=16, blocksAllocated=1, blocksReleased=1, blocksActivelyAllocated=0, exceptionsInMultipartFinalize=0, transferDuration=0 ms, queueDuration=0 ms, averageQueueTime=0 ms, totalUploadDuration=0 ms, effectiveBandwidth=0.0 bytes/s}\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T16:10:53.540+0000","updated":"2017-01-31T16:10:53.540+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847033","id":"15847033","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I'm not setting that close stream message in the logs for the huge file upload, and when I add an assert that the number of outstanding blocks == 0 in the upload tests, the assertion falls for the disk block upload\n\nimplication: the stream isn't being closed, either due to multipart put, or the progress callback (which does wrap the input stream, judging by the AWS source)\n\nExcept: the byte buffer and byte array test runs do pass: their stream.close() methods are being triggered enough for them to release blocks. Which means that I'm not seeing consistent behaviour here.\n\nI know I could simply trigger the cleanup in the Block.close() operation, but I want to understand why the stream closure hasn't happened yet before I rush to do that","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T16:20:51.408+0000","updated":"2017-01-31T16:20:51.408+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847095","id":"15847095","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"log of the multple disk block put, no stream closed events, \n{code}\n2017-01-31 16:36:50,459 [JUnit-test_010_CreateHugeFile] INFO  scale.AbstractSTestS3AHugeFiles (AbstractSTestS3AHugeFiles.java:test_010_CreateHugeFile(188)) - [100%] Buffered 10.00 MB out of 10 MB; PUT 0 bytes (8388608 pending) in 2 operations (1 active); elapsedTime=0.21s; write to buffer bandwidth=48.40 MB/s\n2017-01-31 16:36:50,459 [JUnit-test_010_CreateHugeFile] INFO  scale.AbstractSTestS3AHugeFiles (AbstractSTestS3AHugeFiles.java:test_010_CreateHugeFile(203)) - Closing stream org.apache.hadoop.fs.FSDataOutputStream@7067fa8a\n2017-01-31 16:36:50,460 [JUnit-test_010_CreateHugeFile] INFO  scale.AbstractSTestS3AHugeFiles (AbstractSTestS3AHugeFiles.java:test_010_CreateHugeFile(204)) - Statistics : OutputStreamStatistics{blocksSubmitted=1, blocksInQueue=0, blocksActive=1, blockUploadsCompleted=0, blockUploadsFailed=0, bytesPendingUpload=8388608, bytesUploaded=0, blocksAllocated=2, blocksReleased=0, blocksActivelyAllocated=2, exceptionsInMultipartFinalize=0, transferDuration=0 ms, queueDuration=3 ms, averageQueueTime=3 ms, totalUploadDuration=3 ms, effectiveBandwidth=0.0 bytes/s}\n2017-01-31 16:36:50,460 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:close(329)) - S3ABlockOutputStream{{bucket=hwdev-steve-ireland-new, key='tests3ascale/scale/hugefile'}, blockSize=8388608, activeBlock=FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Writing, dataSize=2097152, limit=8388608}}: Closing block #2: current block= FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Writing, dataSize=2097152, limit=8388608}\n2017-01-31 16:36:50,460 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:uploadCurrentBlock(298)) - Writing block # 2\n2017-01-31 16:36:50,460 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:uploadBlockAsync(469)) - Queueing upload of FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Writing, dataSize=2097152, limit=8388608}\n2017-01-31 16:36:50,460 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:startUpload(260)) - Start datablock[2] upload\n2017-01-31 16:36:50,460 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:enterState(167)) - FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Writing, dataSize=2097152, limit=8388608}: entering state Upload\n2017-01-31 16:36:50,461 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:clearActiveBlock(209)) - Clearing active block\n2017-01-31 16:36:50,461 [s3a-transfer-shared-pool1-t3] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(490)) - Uploading part 2 for id 'i8AV2cnBFI5JymBdObYinUZh9Fl.JF.DN9w91B9UtOq08Y02Jj1W3uNGyBYLUg5VmNscz3xzMr5naAh6R.O.Ew--'\n2017-01-31 16:36:50,461 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:waitForAllPartUploads(511)) - Waiting for 2 uploads to complete\n2017-01-31 16:36:50,462 [s3a-transfer-shared-pool1-t3] DEBUG amazonaws.request (AmazonHttpClient.java:executeOneRequest(1046)) - Sending Request: PUT https://hwdev-steve-ireland-new.s3-eu-west-1.amazonaws.com /tests3ascale/scale/hugefile Parameters: ({\"uploadId\":[\"i8AV2cnBFI5JymBdObYinUZh9Fl.JF.DN9w91B9UtOq08Y02Jj1W3uNGyBYLUg5VmNscz3xzMr5naAh6R.O.Ew--\"],\"partNumber\":[\"2\"]}Headers: (User-Agent: STestS3AHugeFileCreate, Hadoop 2.9.0-SNAPSHOT, aws-sdk-java/1.11.45 Mac_OS_X/10.12.2 Java_HotSpot(TM)_64-Bit_Server_VM/25.102-b14/1.8.0_102, amz-sdk-invocation-id: 94996caa-80e5-a609-d1e8-edf313bc06a2, Content-Length: 2097152, Content-Type: application/octet-stream, ) \n2017-01-31 16:36:50,462 [s3a-transfer-shared-pool1-t3] DEBUG auth.AWS4Signer (CommonsLog.java:debug(33)) - AWS4 Canonical Request: '\"PUT\n/tests3ascale/scale/hugefile\npartNumber=2&uploadId=i8AV2cnBFI5JymBdObYinUZh9Fl.JF.DN9w91B9UtOq08Y02Jj1W3uNGyBYLUg5VmNscz3xzMr5naAh6R.O.Ew--\namz-sdk-invocation-id:94996caa-80e5-a609-d1e8-edf313bc06a2\namz-sdk-retry:0/0/500\ncontent-length:2097152\ncontent-type:application/octet-stream\nhost:hwdev-steve-ireland-new.s3-eu-west-1.amazonaws.com\nuser-agent:STestS3AHugeFileCreate, Hadoop 2.9.0-SNAPSHOT, aws-sdk-java/1.11.45 Mac_OS_X/10.12.2 Java_HotSpot(TM)_64-Bit_Server_VM/25.102-b14/1.8.0_102\nx-amz-content-sha256:UNSIGNED-PAYLOAD\nx-amz-date:20170131T163650Z\n\namz-sdk-invocation-id;amz-sdk-retry;content-length;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\nUNSIGNED-PAYLOAD\"\n2017-01-31 16:36:50,463 [s3a-transfer-shared-pool1-t3] DEBUG auth.AWS4Signer (CommonsLog.java:debug(33)) - AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n20170131T163650Z\n20170131/eu-west-1/s3/aws4_request\ndf85cf8cefd073de4a259d0eb4a5d22242ede33b3b402ccf73e7a43c81ac9f31\"\n2017-01-31 16:36:53,370 [s3a-transfer-shared-pool1-t3] DEBUG amazonaws.request (AwsResponseHandlerAdapter.java:handle(87)) - Received successful response: 200, AWS Request ID: 1B4A1673E51E1FE9\n2017-01-31 16:36:53,370 [s3a-transfer-shared-pool1-t3] DEBUG amazonaws.requestId (AwsResponseHandlerAdapter.java:logHeaderRequestId(136)) - x-amzn-RequestId: not available\n2017-01-31 16:36:53,370 [s3a-transfer-shared-pool1-t3] DEBUG amazonaws.requestId (AwsResponseHandlerAdapter.java:logResponseRequestId(156)) - AWS Request ID: 1B4A1673E51E1FE9\n2017-01-31 16:36:53,372 [s3a-transfer-shared-pool1-t3] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(494)) - Completed upload of FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Upload, dataSize=2097152, limit=8388608}\n2017-01-31 16:36:53,372 [s3a-transfer-shared-pool1-t3] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(495)) - Stream statistics of OutputStreamStatistics{blocksSubmitted=2, blocksInQueue=0, blocksActive=1, blockUploadsCompleted=1, blockUploadsFailed=0, bytesPendingUpload=5242880, bytesUploaded=5242880, blocksAllocated=2, blocksReleased=0, blocksActivelyAllocated=2, exceptionsInMultipartFinalize=0, transferDuration=2909 ms, queueDuration=4 ms, averageQueueTime=2 ms, totalUploadDuration=2913 ms, effectiveBandwidth=1799821.4898729832 bytes/s}\n2017-01-31 16:36:53,372 [s3a-transfer-shared-pool1-t3] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:enterState(167)) - FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Upload, dataSize=2097152, limit=8388608}: entering state Closed\n2017-01-31 16:36:53,372 [s3a-transfer-shared-pool1-t3] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:close(282)) - Closed FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Closed, dataSize=2097152, limit=8388608}\n2017-01-31 16:36:53,372 [s3a-transfer-shared-pool1-t3] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:innerClose(811)) - Closing FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-2667023026802684004.tmp, state=Closed, dataSize=2097152, limit=8388608}\n2017-01-31 16:36:57,131 [s3a-transfer-shared-pool1-t2] DEBUG amazonaws.request (AwsResponseHandlerAdapter.java:handle(87)) - Received successful response: 200, AWS Request ID: 9D1707B157420F81\n2017-01-31 16:36:57,132 [s3a-transfer-shared-pool1-t2] DEBUG amazonaws.requestId (AwsResponseHandlerAdapter.java:logHeaderRequestId(136)) - x-amzn-RequestId: not available\n2017-01-31 16:36:57,132 [s3a-transfer-shared-pool1-t2] DEBUG amazonaws.requestId (AwsResponseHandlerAdapter.java:logResponseRequestId(156)) - AWS Request ID: 9D1707B157420F81\n2017-01-31 16:36:57,132 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(494)) - Completed upload of FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-8866456036483591474.tmp, state=Upload, dataSize=8388608, limit=8388608}\n2017-01-31 16:36:57,132 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(495)) - Stream statistics of OutputStreamStatistics{blocksSubmitted=2, blocksInQueue=0, blocksActive=0, blockUploadsCompleted=2, blockUploadsFailed=0, bytesPendingUpload=0, bytesUploaded=10485760, blocksAllocated=2, blocksReleased=0, blocksActivelyAllocated=2, exceptionsInMultipartFinalize=0, transferDuration=9587 ms, queueDuration=4 ms, averageQueueTime=2 ms, totalUploadDuration=9591 ms, effectiveBandwidth=1093291.6275675113 bytes/s}\n2017-01-31 16:36:57,132 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:enterState(167)) - FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-8866456036483591474.tmp, state=Upload, dataSize=8388608, limit=8388608}: entering state Closed\n2017-01-31 16:36:57,132 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:close(282)) - Closed FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-8866456036483591474.tmp, state=Closed, dataSize=8388608, limit=8388608}\n\n// ** This is where the owner block is being closed **\n\n2017-01-31 16:36:57,132 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:innerClose(811)) - Closing FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-8866456036483591474.tmp, state=Closed, dataSize=8388608, limit=8388608}\n2017-01-31 16:36:57,133 [JUnit-test_010_CreateHugeFile] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:complete(550)) - Completing multi-part upload for key 'tests3ascale/scale/hugefile', id 'i8AV2cnBFI5JymBdObYinUZh9Fl.JF.DN9w91B9UtOq08Y02Jj1W3uNGyBYLUg5VmNscz3xzMr5naAh6R.O.Ew--' with 2 partitions \n2017-01-31 16:36:57,135 [JUnit-test_010_CreateHugeFile] DEBUG amazonaws.request (AmazonHttpClient.java:executeOneRequest(1046)) - Sending Request: POST https://hwdev-steve-ireland-new.s3-eu-west-1.amazonaws.com /tests3ascale/scale/hugefile Parameters: ({\"uploadId\":[\"i8AV2cnBFI5JymBdObYinUZh9Fl.JF.DN9w91B9UtOq08Y02Jj1W3uNGyBYLUg5VmNscz3xzMr5naAh6R.O.Ew--\"]}Headers: (User-Agent: STestS3AHugeFileCreate, Hadoop 2.9.0-SNAPSHOT, aws-sdk-java/1.11.45 Mac_OS_X/10.12.2 Java_HotSpot(TM)_64-Bit_Server_VM/25.102-b14/1.8.0_102, amz-sdk-invocation-id: aa9cda11-857e-fbe5-86b4-05640be1e7b0, Content-Length: 219, Content-Type: application/xml, ) \n2017-01-31 16:36:57,136 [JUnit-test_010_CreateHugeFile] DEBUG auth.AWS4Signer (CommonsLog.java:debug(33)) - AWS4 Canonical Request: '\"POST\n/tests3ascale/scale/hugefile\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T16:40:19.407+0000","updated":"2017-01-31T16:40:19.407+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847200","id":"15847200","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Patch 001\n\n# cleanup takes place in the block close() call\n# pass down index (for logging) and stream statistics (for counting and tests)\n# {{ITestS3AHugeFiles* }} tests verify that uploads do release all blocks by way of the statistics counters\n# the callables on the uploads always call Block.close() in a finally clause. This would have leaked buffers/files otherwise.\n# probably some log at info that could be cut back on\n\nI can't replicate the problem which I referred to in HADOOP-13560 about stream being active after block closure. I think if we used the transfer manager and didn''t block for the uploads to complete this would happen (as the original S3aOutputStream does), but as single part puts are put direct, &multiparts  block for the end tag, all uploads appear to be synchronous.\n\nAs noted, I'm not seeing the multipart uploads closing the output streams *at all*, not from the logs.\n\nI want to apply this to branch-2,8 to see what happens on the older SDK","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T17:45:42.091+0000","updated":"2017-01-31T17:45:42.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847221","id":"15847221","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"testing, s3a ireland","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T18:01:47.987+0000","updated":"2017-01-31T18:01:47.987+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847243","id":"15847243","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"backported to branch-2.8 and tested against s3a ireland there, no problems.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T18:09:55.154+0000","updated":"2017-01-31T18:09:55.154+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847253","id":"15847253","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 23s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} branch-2 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 24s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 35s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} branch-2 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 13s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 11 new + 31 unchanged - 0 fixed = 42 total (was 31) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 20s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 14m 27s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:b59b8b7 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12850274/HADOOP-14028-branch-2-001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux eee18554bd74 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / ccf33bc |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11545/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11545/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11545/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-01-31T18:23:08.064+0000","updated":"2017-01-31T18:23:08.064+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15847272","id":"15847272","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"BTW, on branch-2.8 the logs of the test also showed that on the multipart upload there, the stream *was not* being saved. That is: the problem exists on that branch-2. Because the temp files were all allocated on deleteOnExit(), clean process exits will clean up files anyway\n\n{code}\n2017-01-31 18:33:43,148 [s3a-transfer-shared-pool1-t4] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(501)) - Completed upload of FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-4995600247628610940.tmp, state=Upload, dataSize=2097152, limit=8388608} to part db1f7d786f6e0317456fac1628349973\n2017-01-31 18:33:43,148 [s3a-transfer-shared-pool1-t4] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(503)) - Stream statistics of OutputStreamStatistics{blocksSubmitted=2, blocksInQueue=0, blocksActive=1, blockUploadsCompleted=1, blockUploadsFailed=0, bytesPendingUpload=5734400, bytesUploaded=4751360, blocksAllocated=2, blocksReleased=0, blocksActivelyAllocated=2, exceptionsInMultipartFinalize=0, transferDuration=3028 ms, queueDuration=5 ms, averageQueueTime=2 ms, totalUploadDuration=3033 ms, effectiveBandwidth=1566554.566435872 bytes/s}\n2017-01-31 18:33:43,148 [s3a-transfer-shared-pool1-t4] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(506)) - Closing block at end of multipart PUT FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-4995600247628610940.tmp, state=Upload, dataSize=2097152, limit=8388608}\n2017-01-31 18:33:43,148 [s3a-transfer-shared-pool1-t4] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:enterState(167)) - FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-4995600247628610940.tmp, state=Upload, dataSize=2097152, limit=8388608}: entering state Closed\n2017-01-31 18:33:43,148 [s3a-transfer-shared-pool1-t4] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:close(282)) - Closed FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-4995600247628610940.tmp, state=Closed, dataSize=2097152, limit=8388608}\n2017-01-31 18:33:43,148 [s3a-transfer-shared-pool1-t4] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:innerClose(805)) - Closing FileBlock{index=2, destFile=target/build/test/s3a/s3ablock-0002-4995600247628610940.tmp, state=Closed, dataSize=2097152, limit=8388608}\n2017-01-31 18:33:43,149 [s3a-transfer-shared-pool1-t4] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:closeBlock(857)) - block[2]: closeBlock()\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-01-31T18:39:21.586+0000","updated":"2017-01-31T18:39:21.586+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15848373","id":"15848373","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Although we have that cleanup patch, I'm still worried about streams not being closed when sent up with the xfer manager. I think we should be explicitly closing them ourselves just to make sure.\n\nI've tweaked the code so that the disk output stream logs a full stack trace at debug in close(), which makes it easier to spot in the logs, and shows where closure kicks in\n\nsingle blob PUT\n{code}\n2017-02-01 13:28:51,451 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:close(884)) - Block[1] closing stream of buffer file target/build/test/s3a/s3ablock-0001-8454965610295305282.tmp\n2017-02-01 13:28:51,452 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:close(889)) - stack: \njava.io.IOException: Output stream closed\n\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlock$DiskBlockInputStream.close(S3ADataBlocks.java:888)\n\tat com.amazonaws.internal.ReleasableInputStream.doRelease(ReleasableInputStream.java:84)\n\tat com.amazonaws.internal.ReleasableInputStream.close(ReleasableInputStream.java:68)\n\tat com.amazonaws.internal.SdkFilterInputStream.close(SdkFilterInputStream.java:89)\n\tat com.amazonaws.internal.SdkFilterInputStream.close(SdkFilterInputStream.java:89)\n\tat java.io.BufferedInputStream.close(BufferedInputStream.java:483)\n\tat com.amazonaws.internal.SdkBufferedInputStream.close(SdkBufferedInputStream.java:93)\n\tat com.amazonaws.internal.SdkFilterInputStream.close(SdkFilterInputStream.java:89)\n\tat com.amazonaws.event.ProgressInputStream.close(ProgressInputStream.java:182)\n\tat com.amazonaws.util.IOUtils.closeQuietly(IOUtils.java:71)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:322)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3785)\n\tat com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1472)\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.putObjectDirect(S3AFileSystem.java:1090)\n\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream$1.call(S3ABlockOutputStream.java:397)\n\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream$1.call(S3ABlockOutputStream.java:392)\n\tat org.apache.hadoop.fs.s3a.SemaphoredDelegatingExecutor$CallableWithPermitRelease.call(SemaphoredDelegatingExecutor.java:222)\n\tat org.apache.hadoop.fs.s3a.SemaphoredDelegatingExecutor$CallableWithPermitRelease.call(SemaphoredDelegatingExecutor.java:222)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n2017-02-01 13:28:51,455 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ABlockOutputStream (S3ABlockOutputStream.java:call(399)) - Closing block {} after put operation\n2017-02-01 13:28:51,455 [s3a-transfer-shared-pool1-t2] DEBUG s3a.S3ADataBlocks (S3ADataBlocks.java:enterState(167)) - FileBlock{index=1, destFile=target/build/test/s3a/s3ablock-0001-8454965610295305282.tmp, state=Upload, dataSize=16, limit=5242880}: entering state Closed\n{code}\n\nThere is no stack trace in the multipart upload via {{S3client.uploadPart()}} anywhere in the test run. It's streams are not being closed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-01T13:34:27.827+0000","updated":"2017-02-01T13:46:57.448+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15848395","id":"15848395","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"..looking into {{com.amazonaws.services.s3.model.S3DataSource}}, the cleanup code call at the end of the multipart put doesn't \n\n{code}\n// restore the original input stream so the caller could close                   \n// it if necessary                                                               \nreq.setInputStream(inputStreamOrig);                                             \nreq.setFile(fileOrig);                                                           \n{code}\n\nConclusion: uploadPart really doesn't close input streams, we need to do it ourselves. As putObject *does*, I'm going to leave it alone, and rely on our new tests to pick up regressions in future","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-01T14:01:06.608+0000","updated":"2017-02-01T14:01:06.608+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15848472","id":"15848472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Patch 002\n\nexplicitly closes the stream on the multipart put. Still now only doing the close/buffer release &c in the actual block.close, but being consistent and closing the stream to guarantee file handles aren't leaked until the GC.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-01T15:08:46.067+0000","updated":"2017-02-01T15:08:46.067+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15848497","id":"15848497","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"patch 002 is for 2.8+; tested on 2.8, branch-2 and trunk, all against s3a ireland","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-01T15:20:41.131+0000","updated":"2017-02-01T15:20:41.131+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15848564","id":"15848564","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 18m  3s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  9m 34s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 26s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m  3s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 36s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 14s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 11s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 11 new + 27 unchanged - 1 fixed = 38 total (was 28) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 20s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 36m 30s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5af2af1 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12850437/HADOOP-14028-branch-2.8-002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux b951db0510f5 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2.8 / 4f13564 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11553/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11553/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11553/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-01T16:05:24.600+0000","updated":"2017-02-01T16:05:24.600+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15850389","id":"15850389","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"It's confirmed that the multipart part upload does not close streams; the docs will make it clearer in future. So yes, we do need to close it on a multipart commit, and no, not on a single part one.\n\ncode will be updated accordingly","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-02T19:59:21.672+0000","updated":"2017-02-02T19:59:21.672+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15850607","id":"15850607","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"HADOOP-14028 Patch 003\npulls in some of the changes coming in to HADOOP-13786 just to move the put/multipart put operations into the right place, and to do more diagnostics on block operations, plus the various checkstyle complaints.\n\nBased on some feedback from the SDK team, we must explicitly close the blocks on multipart, releasing the files. We do not need to do this for the putObject call. The disk block is now modified to delete the file in its close() as well as the stream: whichever closes first wins.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-02T22:20:36.333+0000","updated":"2017-02-02T22:20:36.333+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15850746","id":"15850746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 16s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 20s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 22s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 26s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 39s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 14s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 17s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 15s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 12s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 5 new + 26 unchanged - 2 fixed = 31 total (was 28) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 21s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 15m 52s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5af2af1 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12850704/HADOOP-14028-branch-2.8-003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux ae17cd972161 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2.8 / 4e423ed |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11565/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11565/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11565/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-02T23:38:30.154+0000","updated":"2017-02-02T23:38:30.154+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15852060","id":"15852060","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Patch 004; fix those bits of the checkstyle warnings I agreed with.\n\ntesting: s3a ireland, all well","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-03T20:22:43.524+0000","updated":"2017-02-03T20:22:43.524+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15852061","id":"15852061","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I'd like to get this into 2.8.0 if [~cnauroth] , [~jnp] or others could look @ this. [~Thomas Demoor] and [~ehiggs] should care about this too","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-03T20:25:17.758+0000","updated":"2017-02-03T20:25:17.758+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15852194","id":"15852194","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 25s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 18s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 24s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m  2s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 35s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 11s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 3 new + 26 unchanged - 2 fixed = 29 total (was 28) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 20s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 16m 28s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5af2af1 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12850887/HADOOP-14028-branch-2.8-004.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 738c7a6cb3e4 3.13.0-103-generic #150-Ubuntu SMP Thu Nov 24 10:34:17 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2.8 / 2bbcaa8 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11578/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11578/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11578/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-03T22:04:40.414+0000","updated":"2017-02-03T22:04:40.414+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15852800","id":"15852800","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"the two checkstyles are about having final read-only fields marked as protected rather than private+accessors, which, if the class in question were part of a public API would matter. As it is, the classes in S3ADataBlocks are all package private, so all uses will exist in our codebase, and encapsulating them would only be obsessive","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-04T14:08:52.608+0000","updated":"2017-02-04T14:08:52.608+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15854824","id":"15854824","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Thomas+Demoor","name":"Thomas Demoor","key":"thomas demoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Etc/UTC"},"body":"I'll do some testing tomorrow.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Thomas+Demoor","name":"Thomas Demoor","key":"thomas demoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-06T21:57:26.530+0000","updated":"2017-02-06T21:57:26.530+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15854968","id":"15854968","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fabbri","name":"fabbri","key":"fabbri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fabbri&avatarId=24131","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fabbri&avatarId=24131","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fabbri&avatarId=24131","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fabbri&avatarId=24131"},"displayName":"Aaron Fabbri","active":true,"timeZone":"America/Los_Angeles"},"body":"Quick review of v4 patch\n\n{noformat}\n@@ -392,8 +391,15 @@ private void putObject() throws IOException {\n         executorService.submit(new Callable<PutObjectResult>() {\n           @Override\n           public PutObjectResult call() throws Exception {\n-            PutObjectResult result = fs.putObjectDirect(putObjectRequest);\n-            block.close();\n+            PutObjectResult result;\n+            try {\n+              // the put object call automatically closes the input\n+              // stream afterwards.\n+              result = writeOperationHelper.putObject(putObjectRequest);\n+              block.close();\n+            } finally {\n+              closeCloseables(LOG, block);\n+            }\n             return\n{noformat}\n\nDo you still need block.close() above finally block?\n\n{noformat}\n-      /**\n-       * Return the buffer to the pool after the stream is closed.\n-       */\n-      @Override\n-      public synchronized void close() {\n-        if (byteBuffer != null) {\n-          LOG.debug(\"releasing buffer\");\n-          releaseBuffer(byteBuffer);\n+        /**\n+         * Return the buffer to the pool after the stream is closed.\n+         */\n+        @Override\n+        public synchronized void close() {\n+          LOG.debug(\"ByteBufferInputStream.close() for {}\",\n+              ByteBufferBlock.super.toString());\n           byteBuffer = null;\n         }\n-      }\n  \n-      /**\n-       * Verify that the stream is open.\n-       * @throws IOException if the stream is closed\n-       */\n-      private void verifyOpen() throws IOException {\n-        if (byteBuffer == null) {\n-          throw new IOException(FSExceptionMessages.STREAM_IS_CLOSED);\n{noformat}\n\nThis part of diff was hard to read due to indent change, but did you eliminate the call to releaseBuffer(byteBuffer)?\nIf so can you explain that a bit?\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fabbri","name":"fabbri","key":"fabbri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fabbri&avatarId=24131","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fabbri&avatarId=24131","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fabbri&avatarId=24131","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fabbri&avatarId=24131"},"displayName":"Aaron Fabbri","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-06T23:35:52.590+0000","updated":"2017-02-06T23:35:52.590+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15860725","id":"15860725","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm running into HADOOP-14071 when using {{HADOOP-14028-branch-2.8-003.patch}}.\n\nIt manages to complete intermittently and usually takes a few hours to fail.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-10T05:11:24.036+0000","updated":"2017-02-10T05:11:24.036+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15866263","id":"15866263","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Regarding marker/stream rollback, Thomas [~Thomas Demoor] has suggested calling {{getRequestClientOptions().setReadLimit()}} for the memory block streams, to say \"rollback as far as you want\". Thomas: is this what you are thinking: set the limit to the block size to indicate that you can go back to the end\n\n{code}\nputObjectRequest.getRequestClientOptions().setReadLimit(size);\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-14T18:00:06.863+0000","updated":"2017-02-14T18:00:06.863+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15868034","id":"15868034","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"patch 005.\n\nFile references are passed in direct to s3 multipart puts, leaving it to deal with the reset on failure logic. This isn't done for single part puts, as that can only apparently be done at the expense of creating custom metadata, which we need so as to set encryption keys &c. Essentially, {{DataBlock.startUpload()}} moves from returning a stream to a {{BlockUploadData}} structure containing a stream *or* a file. In a multipart put, the file is explicitly picked up. For a single put, {{BlockUploadData.asInputStream()}} is called either to return that input stream or to open one for the file.\n\n\n\n# been through the code, method names and javadocs in the {{S3ADataBlocks}} file to make it consistent with current behaviour.\n# addressed aaron's comments about duplicate close() calls; both single and multipart puts will close things in the finally clause\n# Tested: s3a ireland, 128MB scale, all well apart from that intermittent root delete consistency failure.\n\n(my laptop died last week and I'm only slowly recovering with a dev setup...testing has been someone complicated here, and more review & testing very much appreciated)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-15T15:33:25.126+0000","updated":"2017-02-15T15:33:25.126+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15868082","id":"15868082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  9m  2s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 30s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m  1s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 39s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 14s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 13s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 3 new + 26 unchanged - 2 fixed = 29 total (was 28) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 21s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 18m 42s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5af2af1 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12852840/HADOOP-14028-branch-2.8-005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 702889bc5280 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2.8 / 4c47cb6 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11633/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11633/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11633/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-15T15:57:03.244+0000","updated":"2017-02-15T15:57:03.244+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15868162","id":"15868162","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Thomas+Demoor","name":"Thomas Demoor","key":"thomas demoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Etc/UTC"},"body":"Not sure yet, looking at the aws sdk code but I'm still confused.\n\nThis is the comment for readlimit in {{com.amazonaws.RequestClientOptions}}\n{code}\n /**\n     * Used to enable mark-and-reset for\n     * non-mark-and-resettable non-file input stream for up to 128K memory\n     * buffering by default. Add 1 to get around an implementation quirk of\n     * BufferedInputStream.\n     *\n     * Retries after reading {@link #DEFAULT_STREAM_BUFFER_SIZE} bytes would\n     * fail to reset the underlying input stream as the mark position would\n     * have been invalidated.\n     *\n     */\n{code}\nThe upload / partupload code gets this from a legacy system property and puts it in awsreq variable but the awsreq variable doesn't seem to be used anymore.  \nCode is here {{com/amazonaws/services/s3/AmazonS3Client.java:1627}} and here \n{{com/amazonaws/services/s3/AmazonS3Client.java:3130}} (sdk 1.11.86)\n\nSo don't think it's set for our inputstreams. I guess we currently use the default 128K+1byte?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Thomas+Demoor","name":"Thomas Demoor","key":"thomas demoor","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Demoor","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-15T16:54:46.956+0000","updated":"2017-02-15T16:54:46.956+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15868425","id":"15868425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"it that case its not relevant, then mark  & reset should be doing the move, which is something that all the output streams we work with should support. So why the error message in HADOOP-14071 saying \"use the option\"\n\n\nmaybe we should a a test to TestBlocks which verifies that mark & reset works for a multi MB block; straightforward enough.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-15T19:25:16.989+0000","updated":"2017-02-15T19:25:16.989+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15870213","id":"15870213","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Looking at the latest code (the stuff we get with HADOOP-14040). The check is purely about mark supported and rollback\n{code}\n                if (requestInputStream.markSupported()) {\n                    try {\n                        requestInputStream.reset();\n                    } catch (IOException ex) {\n                        throw new ResetException(\"Failed to reset the request input stream\", ex);\n                    }\n                }\n{code}\nI will do a test to verify that all blocks are supporting reset of the full datablock","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-16T16:18:26.554+0000","updated":"2017-02-16T16:18:26.554+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15870545","id":"15870545","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"and that new test shows..file streams don't support mark/reset\n{code}\nTests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 6.235 sec <<< FAILURE! - in org.apache.hadoop.fs.s3a.ITestS3ABlockOutputDisk\ntestMarkReset(org.apache.hadoop.fs.s3a.ITestS3ABlockOutputDisk)  Time elapsed: 0.533 sec  <<< FAILURE!\njava.lang.AssertionError: Mark not supported in java.io.FileInputStream@7143d536\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.apache.hadoop.fs.s3a.ITestS3ABlockOutputArray.markAndResetDatablock(ITestS3ABlockOutputArray.java:134)\n\tat org.apache.hadoop.fs.s3a.ITestS3ABlockOutputArray.testMarkReset(ITestS3ABlockOutputArray.java:147)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\n\tat org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)\n\tat org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)\n{code}\n\nLooks like a valid complaint. \n\nLooking at the AWS code, they have a special class, {{com.amazonaws.internal.ResettableInputStream}} which does the mark/reset operation by using the FileChannel behind a File; we need to always pass it down for mark/reset to work with file sources\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-16T19:22:38.390+0000","updated":"2017-02-16T19:22:38.390+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15870560","id":"15870560","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"patch 006 pass file down to the put request, simplify blockUploadData and tune tests,\n\nI've been into the AWS SDK now, as well as testing what's happening in the java.io code\n\n# we MUST pass in the File instance for reliable uploads of file data.\n# cleanup must therefore always be in the block close() call.\n\ntested: s3 ireland, with scale tests at 128M","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-16T19:27:16.205+0000","updated":"2017-02-16T19:27:30.394+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15874908","id":"15874908","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"cancel patch to rebase onto latest branch-2.8","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-20T18:21:46.312+0000","updated":"2017-02-20T18:21:46.312+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15874942","id":"15874942","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Patch 007; patch 006 rebased to branch-2.8 after I put in rajesh's HADOOP-14081 patch\n\nTesting: s3a ireland with scale block size -> 128M","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-20T18:46:05.860+0000","updated":"2017-02-20T18:46:05.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15874945","id":"15874945","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  4s{color} | {color:red} HADOOP-14028 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12853598/HADOOP-14028-007.patch |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11660/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-20T18:48:34.307+0000","updated":"2017-02-20T18:48:34.307+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15876157","id":"15876157","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"patch 007 named to be applied to same branch. Not sure how trunk has diverged","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-21T15:33:02.744+0000","updated":"2017-02-21T15:33:02.744+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15876194","id":"15876194","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  7m 40s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 34s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 24s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 34s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 11s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 4 new + 27 unchanged - 2 fixed = 31 total (was 29) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 22s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 20s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 22m  4s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5af2af1 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12853765/HADOOP-14028-branch-2.8-007.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 80e2c0a596ee 3.13.0-103-generic #150-Ubuntu SMP Thu Nov 24 10:34:17 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2.8 / 2b3e8b7 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11676/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11676/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11676/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-21T16:00:43.593+0000","updated":"2017-02-21T16:00:43.593+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15878025","id":"15878025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Checkstyle complaints unimportant\n{code}\n./hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java:382:        : writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);: Line is longer than 80 characters (found 81).\n./hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java:212:    protected final long index;:26: Variable 'index' must be private and have accessor methods.\n./hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java:213:    protected final S3AInstrumentation.OutputStreamStatistics statistics;:63: Variable 'statistics' must be private and have accessor methods.\n./hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java:1:/*: File length is 2,374 lines (max allowed is 2,000)\n{Code}\n\n# 81 chars is acceptable for readability IMO\n# the visible fields are all final and for package private classes. We are in control of where these fields are referenced; wrapping them is needless.\n# File length is insurmountable (and getting worse). I've already moved stuff out of S3aFileSystem (e.g. all the listing stuff); not sure what else can be done. I worry more about class complexity, especially with the s3guard changes, than about overall length.\n\nThis patch is ready for review, and it is important. Volunteers?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-22T11:21:06.222+0000","updated":"2017-02-22T11:21:06.222+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15880323","id":"15880323","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Really, really need urgent review here. [~liuml07], [~eddyxu], [~cnauroth] , [~Thomas Demoor] â€” others?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-23T12:10:47.939+0000","updated":"2017-02-23T12:10:47.939+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15880770","id":"15880770","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"body":"Will do a review this week. Any more reviews will be appreciated as I've just started looking at the problem/solution here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-23T16:22:52.551+0000","updated":"2017-02-23T16:22:52.551+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15881168","id":"15881168","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"Functionality-wise, the patch has been working well for me on up to 70GB output files.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-23T20:16:05.858+0000","updated":"2017-02-23T20:16:05.858+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15881172","id":"15881172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"Err, actually, with one caveat: if the process is killed (OOM, typically), uploaded files are somehow still marked as complete (but not always), even though the write didn't actually complete successfully.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-23T20:19:35.042+0000","updated":"2017-02-23T20:19:35.042+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15881283","id":"15881283","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"That's interesting, because we don't issue the complete until the final close kicked in. When you say \"write didn't complete\" do you mean \"data hasn't been fully flushed?\"; maybe the upload stream is being closed before some flush() is called by the source","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-23T21:17:55.195+0000","updated":"2017-02-23T21:17:55.195+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15881311","id":"15881311","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"I mean \"data hasn't been fully created\" (because the producer gets killed before it finishes generating it), but what's there may have been fully flushed (the \"file\" hasn't ended yet).\n\nIt smelled like a {{finally}} block, but I'm not sure how the OOM killer ends up interacting with Java (specifically how much cleanup can be done).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-23T21:35:57.764+0000","updated":"2017-02-23T21:35:57.764+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15881336","id":"15881336","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi, Steve\n\nThe patch LGTM. +1 pending the following changes. \n \n{code}\npublic static void closeAll(Logger log,\n      java.io.Closeable... closeables) {\n    for (java.io.Closeable c : closeables) {\n      if (c != null) {\n        try {\n          LOG.debug(\"Closing {}\", c);\n          c.close();\n        } catch (Exception e) {\n          if (log != null && log.isDebugEnabled()) {\n            log.debug(\"Exception in closing {}\", c, e);\n          }\n        }\n      }\n    }\n  }\n{code}\n\nCan be  {{package-private}}?  And {{LOG.debug(\"Closing {}\", c);}} should be {{log.debug(...)}} to use the logger passed in.\n\n{code}\nstatic final class BlockUploadData implements Closeable {\n    public final File file;\n{code}\n\nIt should be {{private final File file}}.\n\nThanks a lot for the effort.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-23T21:45:30.174+0000","updated":"2017-02-23T21:45:49.093+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15881629","id":"15881629","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"body":"+1\n\nI learned a lot from the threads here: how to debug and identify the problem from logging/stats, how to evaluate direct idea to solve the problem and end up with a comprehensive one. I'd suggest we change the subject to \"not closing\" instead of \"don't delete temporary files\" to make the problem clearer.\n\nOne nit: can we use the {{IOUtilsClient#cleanup()}} instead of newly added {{closeAll()}}? Adding one more line of debug info to that method should just work fine.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-24T00:29:01.160+0000","updated":"2017-02-24T00:29:01.160+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15882504","id":"15882504","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Hadn't seen {{IOUtilsClient}}...it's in HDFS and we don't actually depend on it. Move those methods into hadoop common & I can use them","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T11:41:40.819+0000","updated":"2017-02-24T11:41:40.819+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15882653","id":"15882653","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"patch 008; patch feedback\n* make field private\n* use passed in log (with check for null first) in closeAll\nAlso: used xor in precondition check so its clearer; added comment too.\n\nI've not moved to the hdfs-client {{IOUtilsClient#cleanup()}} because its in the wrong package. Also, looking at it and the Hadoop client one, both are at risk of failing if a closeable raises an exception in close() and then throws an NPE in {{toString()}}. The one here relies on SLF4J to be more robust in its string evaluation. I'd have pulled it into hadoop-common, except then I'd have to write the test to create the failure conditions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T13:23:31.256+0000","updated":"2017-02-24T13:23:31.256+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15882691","id":"15882691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 34s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 24s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 16s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 34s{color} | {color:green} branch-2.8 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} branch-2.8 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} branch-2.8 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 11s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 4 new + 27 unchanged - 2 fixed = 31 total (was 29) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 22s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 20s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 14m 49s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5af2af1 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12854467/HADOOP-14028-branch-2.8-008.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux de828f17db34 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2.8 / ff87ca8 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11708/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11708/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11708/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-24T13:43:16.608+0000","updated":"2017-02-24T13:43:16.608+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15883395","id":"15883395","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nIOUtilsClient#cleanup() because its in the wrong package\n{quote}\nI missed that... sorry for the noise.\n\n+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-24T19:38:39.563+0000","updated":"2017-02-24T19:38:39.563+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15883553","id":"15883553","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Committed to branch-2.8. Here's the branch-2 patch for checkstyle to look at; it's slightly different due to some minor merge conflicts with the SSE code of HADOOP-13075","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T21:29:10.093+0000","updated":"2017-02-24T21:29:10.093+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15883571","id":"15883571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"body":"You can disregard my comments about prematurely / incorrectly closing the output file when the process terminates. It turns out that the input producer was the process being OOM killed, so I need to fix handling of premature end of inputs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mojodna","name":"mojodna","key":"mojodna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Seth Fitzsimmons","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-24T21:41:22.789+0000","updated":"2017-02-24T21:41:22.789+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15883580","id":"15883580","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Seth: thanks for that.\n\nregarding the branch-2 patch (which I consider +1'd in anyway, just the small diff going through yetus), tested s3 frankfurt with -Dscale & 32M files","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T21:44:52.191+0000","updated":"2017-02-24T21:44:52.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15883586","id":"15883586","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 37s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} branch-2 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 16s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 27s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 16s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 34s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} branch-2 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 12s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 11 new + 31 unchanged - 1 fixed = 42 total (was 32) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m  9s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 21s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 14m 51s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:b59b8b7 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12854576/HADOOP-14028-branch-2-008.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 08d517f49f19 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / 5c509f5 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11712/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11712/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11712/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-24T21:53:14.834+0000","updated":"2017-02-24T21:53:14.834+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15883663","id":"15883663","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Interesting: the branch-2 yetus checkstyle run complained about stuff that was in the -2.8 branch patch, but not picked up on.\n\npatch 009 shuts up checkstyle as far as makes sense; no other changes\n\ntested @ scale, s3a ireland, AES256 encryption turned on","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-24T22:43:04.609+0000","updated":"2017-02-24T22:43:04.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15883736","id":"15883736","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 35s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} branch-2 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 18s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 27s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 33s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} branch-2 passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 15s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 12s{color} | {color:orange} hadoop-tools/hadoop-aws: The patch generated 6 new + 31 unchanged - 1 fixed = 37 total (was 32) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed with JDK v1.8.0_121 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 20s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 14m 45s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:b59b8b7 |\n| JIRA Issue | HADOOP-14028 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12854597/HADOOP-14028-branch-2-009.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux c6458574a225 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / 5c509f5 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_121 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11713/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-aws.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11713/testReport/ |\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11713/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-24T23:23:02.603+0000","updated":"2017-02-24T23:23:02.603+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15884298","id":"15884298","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"OK, final patch is in to branch-2.8+. \n\n[~mojodna] â€”thank you for helping with the beta testing, finding this, and giving us the information we needed to track down and fix the problem. The next beta releases will have the patches. This is why participation in OSS beta releases is so important to users as well as us developers: the beta test phase is the best chance to get the bugs you see fixed within a few days to weeks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-02-25T16:21:26.932+0000","updated":"2017-02-25T16:21:26.932+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13038288/comment/15884305","id":"15884305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #11308 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/11308/])\nHADOOP-14028. S3A BlockOutputStreams doesn't delete temporary files in (stevel: rev dab00da19f25619ccc71c7f803a235b21766bf1e)\n* (edit) hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3ABlockOutputArray.java\n* (edit) hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java\n* (edit) hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3ABlockOutputByteBuffer.java\n* (edit) hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AUtils.java\n* (edit) hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3ABlockOutputDisk.java\n* (edit) hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/scale/AbstractSTestS3AHugeFiles.java\n* (edit) hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/S3ATestUtils.java\n* (edit) hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java\n* (edit) hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n* (edit) hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestDataBlocks.java\n* (edit) hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-02-25T16:54:38.252+0000","updated":"2017-02-25T16:54:38.252+0000"}],"maxResults":63,"total":63,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-14028/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i399u7:"}}