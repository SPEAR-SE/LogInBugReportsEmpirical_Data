{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12347662","self":"https://issues.apache.org/jira/rest/api/2/issue/12347662","key":"HADOOP-442","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312293","id":"12312293","description":"","name":"0.12.0","archived":false,"released":true,"releaseDate":"2007-03-02"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2006-08-10T19:55:38.000+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Feb 21 20:12:26 UTC 2007","customfield_12310420":"124810","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_420249366_*|*_1_*:*_1_*:*_16472756676_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_787772455","customfield_12312321":null,"resolutiondate":"2007-02-21T20:12:27.042+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-442/watchers","watchCount":0,"isWatching":false},"created":"2006-08-10T07:42:21.000+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12320337","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12320337","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12396455","key":"HDFS-134","self":"https://issues.apache.org/jira/rest/api/2/issue/12396455","fields":{"summary":"premature end-of-decommission of datanodes","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2008-05-20T22:32:39.965+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310711","id":"12310711","name":"conf","description":"Hadoop configuration mechanism."}],"timeoriginalestimate":null,"description":"I recently had a few nodes go bad, such that they were inaccessible to ssh, but were still running their java processes.\ntasks that executed on them were failing, causing jobs to fail.\nI couldn't stop the java processes, because of the ssh issue, so I was helpless until I could actually power down these nodes.\nrestarting the cluster doesn't help, even when removing the bad nodes from the slaves file - they just reconnect and are accepted.\nwhile we plan to avoid tasks from launching on the same nodes over and over, what I'd like is to be able to prevent rogue processes from connecting to the masters.\nIdeally, the slaves file will contain an 'exclude' section, which will list nodes that shouldn't be accessed, and should be ignored if they try to connect. That would also help in configuring the slaves file for a large cluster - I'd list the full range of machines in the cluster, then list the ones that are down in the 'exclude' section","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12351198","id":"12351198","filename":"hadoop-442-10.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-15T00:20:13.173+0000","size":46252,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12351198/hadoop-442-10.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12351403","id":"12351403","filename":"hadoop-442-11.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-16T21:25:53.444+0000","size":44225,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12351403/hadoop-442-11.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12350516","id":"12350516","filename":"hadoop-442-8.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-07T03:55:13.418+0000","size":36868,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12350516/hadoop-442-8.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107060","customfield_12312823":null,"summary":"slaves file should include an 'exclude' section, to prevent \"bad\" datanodes and tasktrackers from disrupting  a cluster","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12427334","id":"12427334","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bpendleton","name":"bpendleton","key":"bpendleton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bryan Pendleton","active":true,"timeZone":"Etc/UTC"},"body":"I too have had problems like this over time.\n\nAnother way to deal with this might be to hand out a new random ID to each instance on startup. The namenode/jobtracker would know the \"correct\" value, and treat as rogue any nodes which try to register but don't know the current \"correct\" value. This could be re-set at each full-cluster restart, to make sure that all nodes participating are \"up to date\" and correct.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bpendleton","name":"bpendleton","key":"bpendleton","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bryan Pendleton","active":true,"timeZone":"Etc/UTC"},"created":"2006-08-10T19:55:38.000+0000","updated":"2006-08-10T19:55:38.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12427609","id":"12427609","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"The slaves file is currently only used by the start/stop scripts, so it won't help here.\n\nPerhaps the jobtracker and namenode should have a public API that permits particular hosts to be banned.  Then the web ui could then use this to let adminstrators ban hosts.  We could initialize the list from a config file, in the case of persistently bad hosts.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-08-11T20:13:17.000+0000","updated":"2006-08-11T20:13:17.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12427632","id":"12427632","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=menicosia","name":"menicosia","key":"menicosia","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marco Nicosia","active":true,"timeZone":"Etc/UTC"},"body":"Would it be better to choose either one or the other to be authoritative for all operations?\n\n1] The namenode/jobtrackers maintain the slaves file. Membership and other administrative functions are made via API calls to the process, which modifies a file on disk. That file is used, but never modified, by slaves.sh, etc. If the file is still text, it can be modified between process restarts.\n\n2] The namenode/jobtrackers observe and respect the contents of a file on disk. Standard tools can modify it, but the processes would have to poll the file to see if it has been changed.\n\nI personally prefer #1, tho I'd hope that any API is open (XML-RPC, REST, SOAP...) instead of RMI so that any set of sysadmin automation can talk to it.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=menicosia","name":"menicosia","key":"menicosia","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marco Nicosia","active":true,"timeZone":"Etc/UTC"},"created":"2006-08-11T21:33:24.000+0000","updated":"2006-08-11T21:33:24.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12450506","id":"12450506","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"Current proposal:\n\n- Add config variables that points to file containing list of nodes HDFS should expect (slaves file) (optional config)\n- Add config variable that points to a file containing a list of excluded nodes (from previous list) (optional config)\n\n- The nameNode reads these files on startup (iff config).  It keeps a list of included nodes and another of excluded nodes.  If the include list is configured, it will be tested when a node registers or heartbeats.  If the node is not on the list, it will be told to shutdown on the response.  If the exclude list is configured, than a node will also be shutdown if listed.\n\n- We will add an admin command to re-read the inclusion and exclusion files\n\n- The job tracker will also read these lists and have a new admin command to reread the files\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-11-16T19:33:45.000+0000","updated":"2006-11-16T19:33:45.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12467944","id":"12467944","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"body":"Here is the latest design (pretty much the same as the previous proposal with a few more details)\n\n1. Adding two new config variables.  By default they will not be configured (commented out of hadoop-default).\n  a. hadoop.nodes.include -- file which contains nodes to include.  If this variable is configured, then only nodes on this list will be allowed to register with the namenode \n  b. hadoop.nodes.exclude -- file which contains nodes to exclude.  If this variable is configured, then any node appearing on this list will be denied communication (register, send heartbeats, send block reports, report received blocks, and send error reports) by the namenode, even if it appears in the include file.   \n\nIf neither is configured, then any node is allowed to connect.  We currently have a slaves file that is used for slaves.sh.  This file can be used as the file specified by hadoop.nodes.include, but there is no restriction that it needs to be. \n\n2. Adding a dfsadmin command (refreshNodes) to reread the inclusion/exclusion files.   \n\n3. The files will be read when the NameNode starts up and whenever it gets a refreshNodes command. \n\n4. JobTracker will use the same config variables to determine TaskTrackers to include/exclude.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-01-26T22:43:45.424+0000","updated":"2007-01-26T22:43:45.424+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12467961","id":"12467961","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"body":"Yes, right on! \n\nssian.jira.plugin.system.issuetabpanels:comment-tabpanel#action_12467944 ] \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"created":"2007-01-26T23:39:49.743+0000","updated":"2007-01-26T23:39:49.743+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12468848","id":"12468848","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"body":"Some changes:\n1. There are actually going to be 4 new config variables.  2 for dfs and 2 for mapred.  The current names are:\ndfs.client.include\ndfs.client.exclude\nmapred.client.include\nmapred.client.exclude\n\n-These variables are going to be commented out in hadoop-default, so by default they will not be configured.\n\n2. I created a generic gatekeeper class in hadoop.util which is used by dfs and mapred.\n\n3. Currently, the include list will only be looked at for registration.  It will not be used for heartbeats, block reports, etc..  The exclude list will be used for everything.  The reason for this is if a node can't register, then it can't send heartbeats, so we don't need to check it again.    \n \n4. The JobTracker will not have an admin command to refresh the nodes because such a mechanism does not yet exist.   \n\nComments welcome.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-01-31T01:15:54.098+0000","updated":"2007-01-31T01:15:54.098+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12469139","id":"12469139","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Nice and simple design. I have one comment. I would like to avoid every heartbeat checking the exclude list. We already know that heartbeat-processing should be very lightweight for the cluster to scale. Can we make the heartbeat check the exclude list only if it is the first heartbeat received after the last invocation of \"dfsadmin refreshNodes\" command?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2007-01-31T18:23:11.079+0000","updated":"2007-01-31T18:23:11.079+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12469272","id":"12469272","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"body":"A couple of points/questions:\n\n- The [dfs|mapred].client prefixes are a little confusing. They could be construed as lists of machines from which HDFS clients are permitted to connect, which is not the intent here. I'd also get rid of the 'include' suffix since that list is used to constrain the set of nodes that can participate. I propose calling them:\n[dfs|mapred].hosts and [dfs|mapred].hosts.exclude\n\n- What is the format of the include and exclude files, it needs to be specified here.\n\n- The variables should be set to reasonable default values in hadoop-default.xml, not excluded. Setting them to empty strings by default is probably fine.\n\n- What happens when a node is taken off the include list and not placed on the exclude list? Do heartbeats and block reports from it continue to get processed? Perhaps the 'refreshNodes' command should examine the collection of DatanodeDescriptors and update it to only include those that are on the new include list.\n\n- What are the semantics of exclude? How does it differ from decommission? Can we unify the two and have exclude mean decommission? What happens if all replicas of some blocks are excluded?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sameerp","name":"sameerp","key":"sameerp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34061","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34061","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34061","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34061"},"displayName":"Sameer Paranjpye","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-02-01T00:04:50.167+0000","updated":"2007-02-01T00:04:50.167+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12469320","id":"12469320","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"body":"so perhaps a simpler approach, more in line with the original request:\n\n* single slaves file\n* no new config variables, since the slaves file is configurable anyway via the hadoop script(s) and env vars\n* lines in the slaves file that start with the word 'exclude' imply that the nodes listed on that line are to be excluded\n\npros of this approach:\n* completely backwards compatible\n* very simple for the administrator (and implementor) - no config, no confusion, single slaves file to edit\n\nthe intent was to simplify the administrator's life. I'd list *all* the cluster in the slaves file, then list a handful of nodes under an 'exclude' section. The exclude statement is an override on whatever is listed elsewhere in the file.\nThe behavior is:\n* datanode/tasktracker on nodes that appear in the slaves file and are not excluded are launched on startup\n* any node may connect to the master, unless it is excluded (for backwards compatibility. I'd actually prefer to only allow included nodes to connect but that will wait, perhaps indefinitely)\n\nnodes are excluded for a reason, basically because they're dead and\n* their presence clutters up the startup/shutdown script output and error logs\n* if they are included in the cluster they may degrade its behavior or performance so they should be actively ignored\n- I wouldn't worry about the replicas of data they contain - they're long dead and re-replicated. If they're alive, I won't exclude them.\n\nI love the admin command to reread the file.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yarnon","name":"yarnon","key":"yarnon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yoram Arnon","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-01T03:03:28.819+0000","updated":"2007-02-01T03:03:28.819+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12469597","id":"12469597","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"body":"-I'll change the names to the ones Sameer proposed and make the default an empty string.\n\n-The exclude/hosts files expect full hostnames listed, separated by whitespace (similar to the slaves file).  I can refine this if it's too cumbersome. \n\n-Some of us had a discussion about exclude and decommission.  The conclusion is that they should be combined.   \n\nBelow is the new design:\n\n1. Namenode behavior in dealing with exclude/hosts lists.\n  a. When the namenode starts up, it reads the hosts and exclude files.  When a node on the exclude list registers with the namenode, we mark it to be decommissioned.  When nodes are done being decommissioned, they are shutdown.  Nodes not on the include list will not be allowed to register.   \n  b. When the namenode gets a refreshNodes command, it will update the hosts and exclude lists.  If a node is added to the hosts lists, then it will be allowed to register.  If a node is removed from the hosts list, then any further communication will be disallowed and it will be asked to shutdown.  If a node is added to the exclude list, then it will start to be decommissioned.  If a node is removed from the exlcude list, then the decommission process will be stopped.   \n\n2. Decommissioning a node behaves slightly differently from before. \n  a. When a node is being decommissioned, we do not want to use its copies to replicate unless no copies exist on non-decommissioned nodes. \n  b. A new thread will be used to periodically check if a node is done being decommissioned.  If it is, the next time the node heartbeats, it will be told to shut down. \n\nComments welcome (and please let me know if I forgot anything).  ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-01T22:16:05.442+0000","updated":"2007-02-01T22:16:05.442+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12470746","id":"12470746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"body":"To combine exclude and decommission, I've taken out the dsfadmin command decommission.  Starting and stopping decommission is now done through configured files.  The last option in the original decommission command was one to see the state of the decommission for a set of nodes.  Should this option be combined with refreshNodes or should it still have it's own command (especially if the decommission state is expanded to show progress or if we want to also show other states for the  nodes)?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-06T21:43:24.774+0000","updated":"2007-02-06T21:43:24.774+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12470803","id":"12470803","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"body":"I still need to make changes to TestDecommission, but I wanted to put up a patch for reviews.   ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-07T03:55:13.533+0000","updated":"2007-02-07T03:55:13.533+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12472390","id":"12472390","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"1. It would be nice if the description of dfs.hosts and dfs.hosts.exclude\n   says \"Full path name of file ...\"\n\n2. The FSNamesystem.close() function should have a dnthread.join() call.\n\n3. Can we make FSNamesystem.refreshNodes() package private? i.e. remove the\n   \"public\" keyword from its definition.\n\n4. The method FSNamesystem.refreshNodes migth need to be synchronized because\n   it traverses the datanodeMap. However, the first line in this method (that\n   invokes \"hostReader.refresh\" should preferably be outside this synchrnization.\n   It is good to read in contents from the hosts file outside the global\n   FSNamesystem lock.\n\n5. The methods inExcludedHostsList() and inHostsList() could be unified if we\n   pass in the specified list as a parameter to this unified method.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2007-02-12T19:21:56.072+0000","updated":"2007-02-12T19:21:56.072+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12473265","id":"12473265","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"body":"I've attached a new patch.  This one also has the changes for TestDecommission and incorporates Dhruba's comments. \n\n> 1. It would be nice if the description of dfs.hosts and dfs.hosts.exclude  says \"Full path name of file ...\" \nDone. \n\n> 2. The FSNamesystem.close() function should have a dnthread.join() call. \nDone.  \n\n> 3. Can we make FSNamesystem.refreshNodes() package private? i.e. remove the  \"public\" keyword from its definition. \nDone.\n\n> 4. The method FSNamesystem.refreshNodes migth need to be synchronized \nDone.\n\n> 5. The methods inExcludedHostsList() and inHostsList() could be unified \nThey are actually a little different because inHostsList returns true if the list is empty too.\n\n6. Dhruba and I also discussed removing the STOPPED state that I added from DatanodeInfo since it can be merged with DECOMMISSIONED.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-15T00:20:13.340+0000","updated":"2007-02-15T00:20:13.340+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12473491","id":"12473491","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"0. Nice work on removing the STOPPED state. Makes the system less complex.\n\n1. In TestDecommission.waitNodeState, we wait for half second per iteration.\n   If this setting causes many prints of the form \"Waiting for node to change..\"\n   then maybe we can change the wait period to 1 second instead of half second.\n\n2. In TestDecommission, we have the following logic:\n      a. decommissionNode()\n      b. waitNodeState(DECOMMISSION_INPROGRESS)\n      c. commissionNode()\n      d. waitNodeState(NORMAL)\n      e. decommissionNode()\n      f. waitNodeState(DECOMMISSIONED)\n      g. checkFile()\n\n  I guess b. should be  waitNodeState(DECOMMISSIONED)\n  Also, we can sneak in a call to checkFile() betwen steps b and c.\n\n3. Maybe ClientProtocol.refreshNodes can return a void instead of\n   \"boolean\".\n\n4. The original way to shutdown a datanode was to make the namenode send a\n   DNA_SHUTDOWN command in response to a heartbeat. You enahnced this logic\n   to make the datanode catch a UnregisteredDatanodeException and shut itself\n   down. Thus, we will now have two ways to shutdown a datanode. Do you think\n   that it is preferable to have only one way to shutdown a datanode?\n\n5. An earlier patch introduced an async thread called the ReplicationMonitor.\n   The ReplicationMonitor thread invokes checkDecommissionState(). This\n   probably means that the DecommissionedMonitor thread is not needed anymore.\n\n6. The FSNamesystem.verifyNodeRegistration needs to be synchronized since it\n   traverses hosts lists and datanode lists. Since\n   FSNamesystem.startDecommission and FSNamesystem.stopDecommission are private\n   and are always called from already-synchronized methods, we can remove\n   the \"synchronized\" keyword from their definitions.\n\n7. I am kind-of reluctant to put in added complexity to pendingTransfers\n   to handle the case that a decommissioned node should not be the\n   source of a replication request. Especially because the above rule is\n   not enforced if there is only one replica in the cluster. Is there any\n   way that we can avoid putting in this special purpose case? What bad\n   thing can occur if we select the decommissioned node as the source of\n   a replication request?\n\n8. Ideally, the FSNamesystem.verifyNodeShutdown needs to be synchronized\n   because it looks up the datanode descriptor. But this method is called\n   for every RPC request and a \"synchronized\" call just adds overhead.\n   Maybe we can make FSNamesystem.gotHeartBeat, FSNamesystem.processReport\n   and FSNamesystem.blockReceived call FSNamesystem.verifyNodeShutdown.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2007-02-15T20:05:18.674+0000","updated":"2007-02-15T20:05:18.674+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12473544","id":"12473544","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Regarding comment 5 above, it actually might make sense to have a separate thread to check whether a decommission is completed or not. It can run on its own schedule. The ReplicationMonitor thread periodically works every 3 seconds and this periodicity is \"too\" frequent to be checking decommissioned nodes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2007-02-15T22:48:02.812+0000","updated":"2007-02-15T22:48:02.812+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12473826","id":"12473826","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"body":"Thanks for looking over the patch, Dhruba!  I updated it to incorporate Dhruba's comments.\n\n1. TestDecommission.waitNodeState waits for 1 second now. \n2. I do mean to check for DECOMMISSION_INRPOGRESS to make sure the decommission began, but I want to stop it before it finishes so I can test commissioning a node works too.  \n3. refreshNodes now returns void.\n4. UnregisteredDatanodeException was already there, but I also added DisallowedDatanodeException to that clause.  I'm inclined to leave them together since they are similar.\n6. added synchronized to verifyNodeRegistration, and removed it from start/stopDecommission.\n7. removed the new code from pendingTransfers\n8. I moved verifyNodeShutdown to FSNamesystem.  \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchien","name":"wchien","key":"wchien","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wendy Chien","active":true,"timeZone":"Etc/UTC"},"created":"2007-02-16T21:25:53.580+0000","updated":"2007-02-16T21:25:53.580+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12347662/comment/12474815","id":"12474815","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this.  Thanks, Wendy!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-02-21T20:12:26.994+0000","updated":"2007-02-21T20:12:26.994+0000"}],"maxResults":19,"total":19,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-442/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0iohb:"}}