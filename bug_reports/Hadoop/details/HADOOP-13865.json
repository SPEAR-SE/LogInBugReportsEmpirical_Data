{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13025399","self":"https://issues.apache.org/jira/rest/api/2/issue/13025399","key":"HADOOP-13865","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2016-12-04T13:06:33.816+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jun 27 20:55:47 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_535023_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_98158789","customfield_12312321":null,"resolutiondate":"2016-12-05T15:50:49.998+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13865/watchers","watchCount":4,"isWatching":false},"created":"2016-12-04T12:25:56.438+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329058","id":"12329058","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334005","id":"12334005","description":"2.7.3 release","name":"2.7.3","archived":false,"released":true,"releaseDate":"2016-08-25"}],"issuelinks":[{"id":"12488264","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12488264","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12932096","key":"HADOOP-12721","self":"https://issues.apache.org/jira/rest/api/2/issue/12932096","fields":{"summary":"Hadoop-tools jars should be included in the classpath of hadoop command","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/5","id":"5","description":"General wishlist item.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Wish","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-06-27T20:55:47.850+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311393","id":"12311393","name":"scripts"}],"timeoriginalestimate":null,"description":"when i run hive queries, i get errors as follow\njava.lang.NoClassDefFoundError: org/apache/hadoop/tools/DistCpOptions\n...\n\nMaybe  run other hadoop apps which using hadoop tools classes, will get similar erros\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329058","id":"12329058","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12841667","id":"12841667","filename":"HADOOP-13865-branch-2.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-04T12:33:45.622+0000","size":4965,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12841667/HADOOP-13865-branch-2.001.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"add tools to classpath by default in branch-2","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15719875","id":"15719875","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"body":"patch uploaded for branch-2","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-04T12:33:45.628+0000","updated":"2016-12-04T12:33:45.628+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15719882","id":"15719882","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"body":"hi [~raviprak]\ncould you please give suggestions and review it ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-04T12:39:24.911+0000","updated":"2016-12-04T12:39:24.911+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15719918","id":"15719918","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 13m 41s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 52s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  7s{color} | {color:green} There were no new shellcheck issues. {color} |\n| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m  8s{color} | {color:green} There were no new shelldocs issues. {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 43s{color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 26m 53s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:b59b8b7 |\n| JIRA Issue | HADOOP-13865 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12841667/HADOOP-13865-branch-2.001.patch |\n| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  |\n| uname | Linux 95f6fe22ca4f 3.13.0-93-generic #140-Ubuntu SMP Mon Jul 18 21:21:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / d58fca0 |\n| shellcheck | v0.4.5 |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11195/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11195/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-04T13:06:33.816+0000","updated":"2016-12-04T13:06:33.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15720550","id":"15720550","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"-1\n\nThere is way too much stuff hanging out in tools to do this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2016-12-04T20:32:21.669+0000","updated":"2016-12-04T20:32:21.669+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15721032","id":"15721032","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"body":"hi [~aw]\nWill it cause any problmes for adding tool jars to classpath?\nMaybe many users encouner the problems when they run hadoop apps, if they use class in tools.And They will spend much time to resolve the problems.\nIn my opinion, it's meaningful for hadoop users","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-05T02:42:18.562+0000","updated":"2016-12-05T02:42:18.562+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15721974","id":"15721974","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I have mixed feelings here. I like bits on the CLI, and indeed think we (hortonworks) stick some more of the hadoop-aws and hadoop-azure stuff on our CP, albeit by copying them to somewhere on that path\n\nAt the same time, the fact that we bleed so much of our CP into downstream programs makes it a dangerous minefield about updating anything; the size of that CP means that it's inevitable that we break things whenever we do —so are trapped into shipping out of date stuff (Guava, Jackson) to minimise this pain (see HADOOP-9991).\n\nLooking at your specific problem: distcp runs on the `hadoop distcp` command. Why exactly were you trying to use it from hive?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-12-05T11:03:59.786+0000","updated":"2016-12-05T11:03:59.786+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15722174","id":"15722174","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"body":"hi [~stevel@apache.org]\nIn hive source code Hadoop23Shims.java, it calls DistCp like this\n\n  public boolean runDistCp(Path src, Path dst, Configuration conf) throws IOException {\n\n    DistCpOptions options = new DistCpOptions(Collections.singletonList(src), dst);\n    options.setSyncFolder(true);\n    options.setSkipCRC(true);\n    options.preserve(FileAttribute.BLOCKSIZE);\n    try {\n      conf.setBoolean(\"mapred.mapper.new-api\", true);\n      DistCp distcp = new DistCp(conf, options);\n      distcp.execute();\n      return true;\n    } catch (Exception e) {\n      throw new IOException(\"Cannot execute DistCp process: \" + e, e);\n    } finally {\n      conf.setBoolean(\"mapred.mapper.new-api\", false);\n    }\n  }\n\nSo i encounter the error 'java.lang.NoClassDefFoundError: org/apache/hadoop/tools/DistCpOptions'\nAnd i can solve the problem by setting HADOOP_CLASS\nBecause maybe many users encounter the problems, and maybe they spend much time to solve it, so i open the issue and submit patch \ni \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-05T12:40:25.047+0000","updated":"2016-12-05T12:40:25.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15722238","id":"15722238","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"body":"hi [~stevel@apache.org]\n\nNot only on the CLI, but also user applications using hadoop tools in their source code. Hadoop-aws ,hadoop-azure and other tools have been involved in hadoop, its meaningful for users using hadoop easily\n\nIf add tools to classpath, then CLASSPATH=${HADOOP_HOME}/share/hadoop/tools/*:${HADOOP_HOME}/share/hadoop/tools/lib/*:$CLASSPATH. Maybe CP is not so long. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-05T13:13:57.282+0000","updated":"2016-12-05T13:14:45.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15722586","id":"15722586","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Closing this as a duplicate of HADOOP-12721. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2016-12-05T15:50:50.157+0000","updated":"2016-12-05T15:50:50.157+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15722602","id":"15722602","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"bq.  Will it cause any problmes for adding tool jars to classpath?\n\nYes, it does.  There are reasons why this isn't being done already.  This is why in hadoop 3.x how the shell scripts handle hadoop tools is completely revamped (see HADOOP_OPTIONAL_TOOLS and associated code). There are no more \"add the entire directory to the classpath\" bits anymore.\n\nIn branch-2, users can add whatever jars they want in the default classpath by modifying various environment variables in hadoop-env.sh.  Rather than having us force this upon, they can inflict whatever level of pain they can tolerate.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2016-12-05T15:56:12.605+0000","updated":"2016-12-05T15:56:12.605+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15723025","id":"15723025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Really? That's very unexpected. Which version of Hive are you using?\n\nBecause I'm running spark code with Hive 1.2.1 on the CP, and I can confirm, there is no DistCP in there. Which means either it was in a much older version, or someone has gone and added it as a dependency.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-12-05T18:55:34.217+0000","updated":"2016-12-05T18:55:34.217+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15724117","id":"15724117","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"body":"I find the code with Hive 2.0.0","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-06T02:40:24.426+0000","updated":"2016-12-06T02:40:24.426+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15725170","id":"15725170","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Having checked with colleagues, \"Hive uses distcp when the copy has to happen across different filesystems (hdfs to s3 or across encryption zones) and when the data to be copied is large (hive.exec.copyfile.maxsize; defaults to 32M).\"\n\nI think an issue with Hive in 2.x is that even if you don't do that, it's been added to the shims so that unless distcp is on that CP, the shims don't load. I'd consider that a Hive problem, as it should only worry about distcp when the criteria are met. And, given it has a fallback, should be able to recover","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-12-06T11:02:46.897+0000","updated":"2016-12-06T11:02:46.897+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/15727447","id":"15727447","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"body":"thanks [~stevel@apache.org]\n\nI will open an issue related to this problem on hive jira, and try to fix it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ferhui","name":"ferhui","key":"ferhui","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fei Hui","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-07T02:27:58.409+0000","updated":"2016-12-07T02:27:58.409+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/16525460","id":"16525460","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"This is missing in trunk right now.\r\nI'm trying to list adl:// from Windows and it cannot find tools/lib.\r\n[~stevel@apache.org] should we add the Windows side to trunk?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2018-06-27T18:55:51.104+0000","updated":"2018-06-27T18:55:51.104+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/16525495","id":"16525495","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"My bad, it looks like based on the discussion in HADOOP-12721, this won't be done.\r\nThe solution was what is supported in HADOOP-12857.\r\nNone of this works for Windows though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2018-06-27T19:25:19.898+0000","updated":"2018-06-27T19:25:19.898+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/16525501","id":"16525501","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"[~elgoiri]: I don't see that adl: or abfs: integration happing on trunk with the FS shell, even though hadoop-aws has it (see HADOOP-15544 ). I don't know exactly what's meant to happen here\r\n\r\nw.r.t windows, no, it won't work. I think the solution there is something which will have to be different, won't it. If its just the cloud stores you want, we could have hadoop-cloud-storage's dependency set pulled into hadoop-common/lib, somehow","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-06-27T19:34:14.681+0000","updated":"2018-06-27T19:34:14.681+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/16525554","id":"16525554","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"bq. w.r.t windows, no, it won't work. I think the solution there is something which will have to be different, won't it. If its just the cloud stores you want, we could have hadoop-cloud-storage's dependency set pulled into hadoop-common/lib, somehow\r\n\r\nI'm guessing that the current trunk approach is working nicely on Linux, right?\r\nPulling the cloud libs into commons might be a little heavy.\r\nShould we just have a separate path for cloud storage?\r\n\r\nInternally, I can just append the tools/lib into my classpath but this is not working out of the box.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2018-06-27T20:14:48.394+0000","updated":"2018-06-27T20:14:48.394+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13025399/comment/16525602","id":"16525602","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"update: I know see whaI I do to get adl on the CP, but still unsure why hadoop-aws comes in automatically\r\n{code}\r\nexport HADOOP_OPTIONAL_TOOLS=\"hadoop-kafka,hadoop-aws,hadoop-aliyun,hadoop-openstack,hadoop-ozone,hadoop-azure,hadoop-azure-datalake\"\r\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-06-27T20:55:47.850+0000","updated":"2018-06-27T20:55:47.850+0000"}],"maxResults":19,"total":19,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13865/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i374on:"}}