{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13013240","self":"https://issues.apache.org/jira/rest/api/2/issue/13013240","key":"HADOOP-13730","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-10-18T17:12:33.196+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Oct 18 20:33:12 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13730/watchers","watchCount":6,"isWatching":false},"created":"2016-10-18T16:14:45.402+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332809","id":"12332809","description":"2.7.2 release","name":"2.7.2","archived":false,"released":true,"releaseDate":"2016-01-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-03-20T18:17:24.924+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12330961","id":"12330961","name":"common"}],"timeoriginalestimate":null,"description":"We've had issues in production where metrics stopped. We found the following in the log files:\n\n2016-09-02 21:44:32,493 WARN org.apache.hadoop.metrics2.sink.GraphiteSink: Error sending metrics to Graphite\njava.net.SocketException: Broken pipe\n        at java.net.SocketOutputStream.socketWrite0(Native Method)\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:120)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:164)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:233)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:294)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:137)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:147)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:270)\n        at java.io.Writer.write(Writer.java:154)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite.write(GraphiteSink.java:170)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink.putMetrics(GraphiteSink.java:98)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:186)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)\n        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:134)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)\n\n2016-09-03 00:03:04,335 WARN org.apache.hadoop.metrics2.sink.GraphiteSink: Error sending metrics to Graphite\njava.net.SocketException: Broken pipe\n        at java.net.SocketOutputStream.socketWrite0(Native Method)\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:120)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:164)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:233)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:294)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:137)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:147)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:270)\n        at java.io.Writer.write(Writer.java:154)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite.write(GraphiteSink.java:170)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink.putMetrics(GraphiteSink.java:98)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:186)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)\n        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:134)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)\n\n2016-09-03 00:20:35,436 WARN org.apache.hadoop.metrics2.sink.GraphiteSink: Error sending metrics to Graphite\njava.net.SocketException: Connection timed out\n        at java.net.SocketOutputStream.socketWrite0(Native Method)\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:120)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:164)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:233)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:294)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:137)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:147)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:270)\n        at java.io.Writer.write(Writer.java:154)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite.write(GraphiteSink.java:170)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink.putMetrics(GraphiteSink.java:98)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:186)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)\n        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:134)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)\n2016-09-03 00:22:48,862 WARN org.apache.hadoop.metrics2.sink.GraphiteSink: Error sending metrics to Graphite\njava.net.SocketException: Broken pipe\n        at java.net.SocketOutputStream.socketWrite0(Native Method)\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:120)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:164)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:233)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:294)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:137)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:147)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:270)\n        at java.io.Writer.write(Writer.java:154)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite.write(GraphiteSink.java:170)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink.putMetrics(GraphiteSink.java:98)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:186)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)\n        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:134)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)\n\n2016-09-03 00:24:00,270 WARN org.apache.hadoop.metrics2.sink.GraphiteSink: Error sending metrics to Graphite\njava.net.SocketException: Broken pipe\n        at java.net.SocketOutputStream.socketWrite0(Native Method)\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:120)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:164)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:233)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:294)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:137)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:147)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:270)\n        at java.io.Writer.write(Writer.java:154)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite.write(GraphiteSink.java:170)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink.putMetrics(GraphiteSink.java:98)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:186)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)\n        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:134)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)\n2016-09-03 00:24:41,987 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 482 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 3 Number of syncs: 355 SyncTimes(ms): 342\n2016-09-03 00:25:39,772 WARN org.apache.hadoop.metrics2.sink.GraphiteSink: Error sending metrics to Graphite\njava.net.SocketException: Connection reset\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:124)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:164)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:233)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:294)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:137)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:147)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:270)\n        at java.io.Writer.write(Writer.java:154)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite.write(GraphiteSink.java:170)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink.putMetrics(GraphiteSink.java:98)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:186)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)\n        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:134)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)\n\nThe last error was:\n2016-09-03 01:13:51,619 WARN org.apache.hadoop.metrics2.sink.GraphiteSink: Error sending metrics to Graphite\njava.net.SocketException: Broken pipe\n        at java.net.SocketOutputStream.socketWrite0(Native Method)\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:120)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:164)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:233)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:294)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:137)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:147)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:270)\n        at java.io.Writer.write(Writer.java:154)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite.write(GraphiteSink.java:170)\n        at org.apache.hadoop.metrics2.sink.GraphiteSink.putMetrics(GraphiteSink.java:98)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:186)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)\n        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:134)\n        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)\n2016-09-03 01:15:58,828 ERROR org.apache.hadoop.metrics2.sink.GraphiteSink: Too many connection failures, would not try to connect again.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12342324","id":"12342324","description":"3.2 release","name":"3.2.0","archived":false,"released":false}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12833976","id":"12833976","filename":"0001-Graphite-can-be-unreachable-for-some-time-and-come-b.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Sean+Young","name":"Sean Young","key":"sean young","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sean Young","active":true,"timeZone":"Etc/UTC"},"created":"2016-10-18T16:15:12.169+0000","size":2468,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12833976/0001-Graphite-can-be-unreachable-for-some-time-and-come-b.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"After 5 connection failures, yarn stops sending metrics graphite until restarted","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Sean+Young","name":"Sean Young","key":"sean young","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sean Young","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Sean+Young","name":"Sean Young","key":"sean young","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sean Young","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/15585876","id":"15585876","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Sean+Young","name":"Sean Young","key":"sean young","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sean Young","active":true,"timeZone":"Etc/UTC"},"body":"Keep on trying forever, graphite might come back.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Sean+Young","name":"Sean Young","key":"sean young","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sean Young","active":true,"timeZone":"Etc/UTC"},"created":"2016-10-18T16:17:15.465+0000","updated":"2016-10-18T16:17:15.465+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/15586015","id":"15586015","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 28s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 18s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  7m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 118 unchanged - 14 fixed = 118 total (was 132) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 31s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 21m 48s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 53m 56s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Issue | HADOOP-13730 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12833976/0001-Graphite-can-be-unreachable-for-some-time-and-come-b.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 9046dc25efc4 3.13.0-95-generic #142-Ubuntu SMP Fri Aug 12 17:00:09 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / d26a1bb |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10822/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10822/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10822/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-10-18T17:12:33.196+0000","updated":"2016-10-18T17:12:33.196+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/15588509","id":"15588509","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"It's good to have retries to deal with transient outages, and race conditions in cluster launch/teardown, but at the same time, retrying forever can have adverse consequences (including, if the stack is logged, log overflows. nothing like coming in to find a 20GB error log)\n\nI'd think about using the retry policies in {{org.apache.hadoop.io.retry.RetryPolicies}}; they are there for failures.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-10-19T11:39:44.751+0000","updated":"2016-10-19T11:39:44.751+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/15799361","id":"15799361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"body":"Drop 2.8 in fix version. We should only set this value when patch get committed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-01-04T21:12:29.906+0000","updated":"2017-01-04T21:12:29.906+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/15799611","id":"15799611","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 17s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 31s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 32s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 22s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 22s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 30s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 118 unchanged - 14 fixed = 118 total (was 132) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  9s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 23s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 54m 39s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.fs.viewfs.TestViewFsTrash |\n|   | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:a9ad5d6 |\n| JIRA Issue | HADOOP-13730 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12833976/0001-Graphite-can-be-unreachable-for-some-time-and-come-b.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux bfcbf2f2736b 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / a0a2761 |\n| Default Java | 1.8.0_111 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11364/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11364/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11364/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-01-04T22:53:27.232+0000","updated":"2017-01-04T22:53:27.232+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/16186478","id":"16186478","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"body":"Is this still on target for 2.9.0 ? If not, can we we push this out to the next major release ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-29T21:41:50.657+0000","updated":"2017-09-29T21:41:50.657+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/16201023","id":"16201023","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=subru","name":"subru","key":"subru","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=subru&avatarId=21709","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=subru&avatarId=21709","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=subru&avatarId=21709","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=subru&avatarId=21709"},"displayName":"Subru Krishnan","active":true,"timeZone":"America/Los_Angeles"},"body":"Pushing it out from 2.9.0 due to lack of activity. Feel free to revert if required.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=subru","name":"subru","key":"subru","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=subru&avatarId=21709","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=subru&avatarId=21709","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=subru&avatarId=21709","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=subru&avatarId=21709"},"displayName":"Subru Krishnan","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-11T21:45:57.367+0000","updated":"2017-10-11T21:45:57.367+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/16201183","id":"16201183","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 20s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 46s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 58s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 36s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 36s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 37s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 113 unchanged - 14 fixed = 113 total (was 127) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 44s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  5s{color} | {color:red} hadoop-common in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 83m 33s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.net.TestDNS |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:3d04c00 |\r\n| JIRA Issue | HADOOP-13730 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12833976/0001-Graphite-can-be-unreachable-for-some-time-and-come-b.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 3042faddcf14 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 8acdf5c |\r\n| Default Java | 1.8.0_144 |\r\n| findbugs | v3.1.0-RC1 |\r\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13489/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13489/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\r\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13489/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-11T23:22:57.308+0000","updated":"2017-10-11T23:22:57.308+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013240/comment/16209980","id":"16209980","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=subru","name":"subru","key":"subru","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=subru&avatarId=21709","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=subru&avatarId=21709","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=subru&avatarId=21709","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=subru&avatarId=21709"},"displayName":"Subru Krishnan","active":true,"timeZone":"America/Los_Angeles"},"body":"Pushing it out from 2.9.0 due to lack of recent activity. Feel free to revert if required.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=subru","name":"subru","key":"subru","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=subru&avatarId=21709","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=subru&avatarId=21709","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=subru&avatarId=21709","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=subru&avatarId=21709"},"displayName":"Subru Krishnan","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-18T20:33:12.956+0000","updated":"2017-10-18T20:33:12.956+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13730/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i351nz:"}}