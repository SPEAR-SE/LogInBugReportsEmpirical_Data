{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13026052","self":"https://issues.apache.org/jira/rest/api/2/issue/13026052","key":"HADOOP-13868","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-12-07T12:54:55.822+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Feb 14 17:01:46 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13868/watchers","watchCount":5,"isWatching":false},"created":"2016-12-06T17:18:09.011+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327583","id":"12327583","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335733","id":"12335733","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"issuelinks":[{"id":"12488385","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12488385","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12947129","key":"HADOOP-12891","self":"https://issues.apache.org/jira/rest/api/2/issue/12947129","fields":{"summary":"S3AFileSystem should configure Multipart Copy threshold and chunk size","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-02-14T17:01:46.214+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"I've been looking at a big performance regression when writing to S3 from Spark that appears to have been introduced with HADOOP-12891.\n\nIn the Amazon SDK, the default threshold for multi-part copies is 320x the threshold for multi-part uploads (and the block size is 20x bigger), so I don't think it's necessarily wise for us to have them be the same.\n\nI did some quick tests and it seems to me the sweet spot when multi-part copies start being faster is around 512MB. It wasn't as significant, but using 104857600 (Amazon's default) for the blocksize was also slightly better.\n\nI propose we do the following, although they're independent decisions:\n\n(1) Split the configuration. Ideally, I'd like to have fs.s3a.multipart.copy.threshold and fs.s3a.multipart.upload.threshold (and corresponding properties for the block size). But then there's the question of what to do with the existing fs.s3a.multipart.* properties. Deprecation? Leave it as a short-hand for configuring both (that's overridden by the more specific properties?).\n\n(2) Consider increasing the default values. In my tests, 256 MB seemed to be where multipart uploads came into their own, and 512 MB was where multipart copies started outperforming the alternative. Would be interested to hear what other people have seen.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12842433","id":"12842433","filename":"HADOOP-13868.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-08T22:50:23.138+0000","size":3191,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12842433/HADOOP-13868.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12842566","id":"12842566","filename":"HADOOP-13868.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-09T14:56:32.888+0000","size":3531,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12842566/HADOOP-13868.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12842434","id":"12842434","filename":"optimizing-multipart-s3a.sh","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-08T22:50:23.142+0000","size":2275,"mimeType":"application/x-shellscript","content":"https://issues.apache.org/jira/secure/attachment/12842434/optimizing-multipart-s3a.sh"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"New defaults for S3A multi-part configuration","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15727147","id":"15727147","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"[~stevel@apache.org] You've discussed reasons for not taking this route before: https://issues.apache.org/jira/browse/HADOOP-13826?focusedCommentId=15705101&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15705101. I'm wanting to investigate that a little further since I did see it have a significant impact on a Spark job. Regarding your comment there, do we not get much of the benefit of having everything == block size by ensuring that part sizes are at least multiples of that, so boundaries still line up nicely?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-07T00:05:31.722+0000","updated":"2016-12-07T00:05:31.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15727506","id":"15727506","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Just to add to the numbers above, 256 MB / 512 MB seemed to be the right spot when I was computing in us-west-2  and storing in us-west-1. If I do both in us-west-1, it would seem about 100 MB is where multipart uploads become faster for both upload and rename. Would be good to get more data on how that changes - I'll post the script I'm using in case other folks want to try it for their own set ups.\n\nGiven that I'm not seeing a huge discrepancy between upload and rename speeds (I was originally considering the 512 MB that was proving the right transition point for multipart renames vs. the 16 MB that is the default in core-default.xml), maybe the right thing to do here is indeed to keep the configuration together, but consider bumping the value in core-default.xml up (I definitely haven't seen performance fluctuations in S3 over time quite that large, so I'm reluctant to write it off as that). </thinking out loud>","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-07T02:59:59.902+0000","updated":"2016-12-07T02:59:59.902+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15728695","id":"15728695","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"always risky changing defaults, but as the fast output stuff hasn't shipped yet, that's something which could be played with.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-12-07T12:54:55.822+0000","updated":"2016-12-07T12:54:55.822+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15733602","id":"15733602","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"FYI, I was mistaken about the current defaults - looking at the wrong repo / branch. The default size is currently 100 MB and the threshold is 2 GB. I've done some more testing (I've covered all the US regions), and as long as I'm using a bucket in that region, I'm consistently seeing that around 128 MB or so is where multi-part uploads start being faster (even though that actual raw throughput can vary significantly). I also compared the time to upload 1GB using AWS CLI (24.8s), hadoop fs -cp with these settings (27.7s), and hadoop fs -cp with the current defaults (53.1s).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-08T22:35:38.455+0000","updated":"2016-12-08T22:35:38.455+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15733633","id":"15733633","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Attaching a patch with my proposed defaults, and a script I used to gather data (that assumes you've set BUCKET to the bucket to use and HADOOP to the path to the Hadoop executable to run) in case anyone wants to verify.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-08T22:50:23.146+0000","updated":"2016-12-08T22:50:23.146+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15735019","id":"15735019","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"128MB seems a reasonable increase. But could the patched values be of the form 128M, rather than the multiplied out number. That way it's easier for people reading it to see what the actual number means","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2016-12-09T11:14:30.987+0000","updated":"2016-12-09T11:14:30.987+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15735526","id":"15735526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Attaching a patch ising the M suffix where possible. I thought it would be cool to tweak things so the Constants.java values could also be in that format and they could be consistent everywhere, but that requires changing a bunch of functions used elsewhere to accept Strings. Probably not worth it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-09T14:56:32.896+0000","updated":"2016-12-09T14:56:32.896+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15735529","id":"15735529","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"{quote}128MB seems a reasonable increase{quote}\n\nJust to be clear, it's a decrease. I was mistaken about what the previous defaults were in trunk. But the current value is also significantly sub-optimal (at least in all the US regions I tested, despite significantly varying raw performance between them).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2016-12-09T14:57:47.316+0000","updated":"2016-12-09T14:57:47.316+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15735690","id":"15735690","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 40s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 26s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 34s{color} | {color:green} hadoop-aws in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 77m  9s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:a9ad5d6 |\n| JIRA Issue | HADOOP-13868 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12842566/HADOOP-13868.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  |\n| uname | Linux dfd8afad53d8 3.13.0-103-generic #150-Ubuntu SMP Thu Nov 24 10:34:17 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 80b8023 |\n| Default Java | 1.8.0_111 |\n| findbugs | v3.0.0 |\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11236/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11236/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-09T16:15:53.758+0000","updated":"2016-12-09T16:15:53.758+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13026052/comment/15866128","id":"15866128","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Just pinging on this - I'd like to resolve it soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2017-02-14T17:01:46.214+0000","updated":"2017-02-14T17:01:46.214+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-13868/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i378pr:"}}