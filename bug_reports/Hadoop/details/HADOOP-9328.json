{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12633695","self":"https://issues.apache.org/jira/rest/api/2/issue/12633695","key":"HADOOP-9328","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/5","id":"5","description":"All attempts at reproducing this issue failed, or not enough information was available to reproduce the issue. Reading the code produces no clues as to why this behavior would occur. If more information appears later, please reopen the issue.","name":"Cannot Reproduce"},"customfield_12312322":null,"customfield_12310220":"2013-02-23T13:07:35.965+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Aug 01 16:28:34 UTC 2013","customfield_12310420":"314190","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_157489651252_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2018-02-19T17:12:33.588+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9328/watchers","watchCount":4,"isWatching":false},"created":"2013-02-22T22:05:02.372+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12322473","id":"12322473","description":"2.0.2-alpha release","name":"2.0.2-alpha","archived":false,"released":true,"releaseDate":"2012-10-09"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-02-19T17:12:33.615+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"With Yarn and Hadoop 2.0.2-alpha, hive 0.9.0.\n\nThe destination is an S3 table, the source for the query is a small hive managed table.\n\nCREATE EXTERNAL TABLE payout_state_product (\n  state STRING,\n  product_id STRING,\n  element_id INT,\n  element_value DOUBLE,\n  number_of_fields INT)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nSTORED AS TEXTFILE\nLOCATION 's3://com.weatherbill.foo/bar/payout_state_product/';\n\nA simple query to copy the results from the hive managed table into a S3. \n\nhive> INSERT OVERWRITE TABLE payout_state_product \nSELECT * FROM payout_state_product_cached; \n\nTotal MapReduce jobs = 2 \nLaunching Job 1 out of 2 \nNumber of reduce tasks is set to 0 since there's no reduce operator \nStarting Job = job_1360884012490_0014, Tracking URL = http://i-9ff9e9ef.us-east-1.production.climatedna.net:8088/proxy/application_1360884012490_0014/ \nKill Command = /usr/lib/hadoop/bin/hadoop job -Dmapred.job.tracker=i-9ff9e9ef.us-east-1.production.climatedna.net:8032 -kill job_1360884012490_0014 \nHadoop job information for Stage-1: number of mappers: 100; number of reducers: 0 \n2013-02-22 19:15:46,709 Stage-1 map = 0%, reduce = 0% \n...snip... \n2013-02-22 19:17:02,374 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 427.13 sec \nMapReduce Total cumulative CPU time: 7 minutes 7 seconds 130 msec \nEnded Job = job_1360884012490_0014 \nEnded Job = -1776780875, job is filtered out (removed at runtime). \nLaunching Job 2 out of 2 \nNumber of reduce tasks is set to 0 since there's no reduce operator \njava.io.FileNotFoundException: File does not exist: /tmp/hive-marc/hive_2013-02-22_19-15-31_691_7365912335285010827/-ext-10002/000000_0 \nat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:782) \nat org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$OneFileInfo.<init>(CombineFileInputFormat.java:493) \nat org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getMoreSplits(CombineFileInputFormat.java:284) \nat org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:244) \nat org.apache.hadoop.mapred.lib.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:69) \nat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:386) \nat org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:352) \nat org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.processPaths(CombineHiveInputFormat.java:419) \nat org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:390) \nat org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:479) \nat org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:471) \nat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:366) \nat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1218) \nat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1215) \nat java.security.AccessController.doPrivileged(Native Method) \nat javax.security.auth.Subject.doAs(Subject.java:396) \nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367) \nat org.apache.hadoop.mapreduce.Job.submit(Job.java:1215) \nat org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:617) \nat org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:612) \nat java.security.AccessController.doPrivileged(Native Method) \nat javax.security.auth.Subject.doAs(Subject.java:396) \nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367) \nat org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:612) \nat org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:435) \nat org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:137) \nat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:134) \nat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57) \nat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1326) \nat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1118) \nat org.apache.hadoop.hive.ql.Driver.run(Driver.java:951) \nat org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258) \nat org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:215) \nat org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:406) \nat org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:689) \nat org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:557) \nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) \nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) \nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) \nat java.lang.reflect.Method.invoke(Method.java:597) \nat org.apache.hadoop.util.RunJar.main(RunJar.java:208) \nJob Submission failed with exception 'java.io.FileNotFoundException(File does not exist: /tmp/hive-marc/hive_2013-02-22_19-15-31_691_7365912335285010827/-ext-10002/000000_0)' \nFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MapRedTask ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"314535","customfield_12312823":null,"summary":"INSERT INTO a S3 external table with no reduce phase results in FileNotFoundException","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mlimotte","name":"mlimotte","key":"mlimotte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marc Limotte","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mlimotte","name":"mlimotte","key":"mlimotte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marc Limotte","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"YARN, Hadoop 2.0.2-alpha\nUbuntu","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12633695/comment/13584753","id":"13584753","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mlimotte","name":"mlimotte","key":"mlimotte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marc Limotte","active":true,"timeZone":"America/New_York"},"body":"I also tried explicitly listing the columns instead of '*', but that still failed:\nINSERT OVERWRITE TABLE payout_state_product \nSELECT * FROM payout_state_product_cached;\n--> FAILS\n\nI tried this multiple times, fails every time.  But I have a bunch of other queries that work and can write to S3.  The distinguishing factor for this query is that it has no reduce phase.\n\nFurther evidence... the following variation on the query works. It adds a simple reduce phase with a pointless group-by:\n\nINSERT OVERWRITE TABLE payout_state_product\nSELECT state, product_id, element_id, element_value, number_of_fields \nFROM payout_state_product_cached\nGROUP BY state, product_id, element_id, element_value, number_of_fields;\n\nThis group by is a feasible work-around, although for large jobs it could be a significant performance hit (luckily that's not the case for this particular query).\n\nAlso, I confirmed that the problem goes away when not writing to S3.  Using a variation of the query that writes to a hive managed, hdfs version of the destination.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mlimotte","name":"mlimotte","key":"mlimotte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marc Limotte","active":true,"timeZone":"America/New_York"},"created":"2013-02-22T22:08:19.176+0000","updated":"2013-02-22T22:08:19.176+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12633695/comment/13585113","id":"13585113","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Does this work on Hadoop 1.x?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2013-02-23T13:07:35.965+0000","updated":"2013-02-23T13:07:35.965+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12633695/comment/13726582","id":"13726582","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mlimotte","name":"mlimotte","key":"mlimotte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marc Limotte","active":true,"timeZone":"America/New_York"},"body":"This does work on hadoop 0.20.x.  Likely it's a YARN only problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mlimotte","name":"mlimotte","key":"mlimotte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marc Limotte","active":true,"timeZone":"America/New_York"},"created":"2013-08-01T16:28:34.315+0000","updated":"2013-08-01T16:28:34.315+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9328/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1i7vj:"}}