{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12655772","self":"https://issues.apache.org/jira/rest/api/2/issue/12655772","key":"HADOOP-9684","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-07-02T19:40:50.796+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Jul 15 20:52:08 UTC 2013","customfield_12310420":"336047","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9684/watchers","watchCount":3,"isWatching":false},"created":"2013-07-02T13:19:00.677+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12313563","id":"12313563","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12314296","id":"12314296","description":"","name":"0.22.0","archived":false,"released":true,"releaseDate":"2011-12-10"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-07-15T20:52:08.538+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12310688","id":"12310688","name":"ipc","description":""}],"timeoriginalestimate":null,"description":"Today, we see that a TaskTracer has keeped throwing the same exception in our production environment.it is that:\n\n2013-07-01 18:41:40,023 INFO org.apache.hadoop.mapred.TaskTracker: addFreeSlot : current free slots : 7\n2013-07-01 18:41:43,026 INFO org.apache.hadoop.mapred.TaskTracker: LaunchTaskAction (registerTask): attempt_201208241212_27521_m_000002_3 task's state:UNASSIGNED\n2013-07-01 18:41:43,026 INFO org.apache.hadoop.mapred.TaskTracker: Trying to launch : attempt_201208241212_27521_m_000002_3 which needs 1 slots\n2013-07-01 18:41:43,026 INFO org.apache.hadoop.mapred.TaskTracker: In TaskLauncher, current free slots : 7 and trying to launch attempt_201208241212_27521_m_000002_3 which needs 1 slots\n2013-07-01 18:41:43,026 INFO org.apache.hadoop.mapreduce.server.tasktracker.Localizer: User-directories for the user sds are already initialized on this TT. Not doing anything.\n2013-07-01 18:41:43,029 WARN org.apache.hadoop.mapred.TaskTracker: Error initializing attempt_201208241212_27521_m_000002_3:\njava.lang.NullPointerException\n\n2013-07-01 18:41:43,029 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201208241212_27521_m_000002_3 when no start time is set, stackTrace is : java.lang.Exception\n\tat org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:195)\n\tat org.apache.hadoop.mapred.MapTaskStatus.setFinishTime(MapTaskStatus.java:51)\n\tat org.apache.hadoop.mapred.TaskTracker$TaskInProgress.kill(TaskTracker.java:2937)\n\tat org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:2255)\n\tat org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:2212)\n\n  Then, we view the log files of the TaskTracker,and find that the TaskTracker throwed Several OutOfMemoryError: Java heap space about ten days ago. after that, the TaskTracker has still throws the exception:\n\n\n2013-06-22 12:39:42,296 INFO org.apache.hadoop.mapred.TaskTracker: LaunchTaskAction (registerTask): attempt_201208241212_26088_m_000043_1 task's state:UNASSIGNED\n2013-06-22 12:39:42,296 INFO org.apache.hadoop.mapred.TaskTracker: Trying to launch : attempt_201208241212_26088_m_000043_1 which needs 1 slots\n2013-06-22 12:39:42,296 INFO org.apache.hadoop.mapred.TaskTracker: In TaskLauncher, current free slots : 7 and trying to launch attempt_201208241212_26088_m_000043_1 which needs 1 slots\n2013-06-22 12:39:42,296 INFO org.apache.hadoop.mapreduce.server.tasktracker.Localizer: Initializing user sds on this TT.\n2013-06-22 12:39:42,300 WARN org.apache.hadoop.mapred.TaskTracker: Error initializing attempt_201208241212_26088_m_000043_1:\njava.lang.NullPointerException\n\tat org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:630)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:886)\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)\n\tat $Proxy5.getFileInfo(Unknown Source)\n\tat sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)\n\tat $Proxy5.getFileInfo(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:850)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:620)\n\tat org.apache.hadoop.mapred.TaskTracker.localizeJobTokenFile(TaskTracker.java:3984)\n\tat org.apache.hadoop.mapred.TaskTracker.localizeJobFiles(TaskTracker.java:1036)\n\tat org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:977)\n\tat org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:2247)\n\tat org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:2212)\n\n2013-06-22 12:39:42,300 ERROR org.apache.hadoop.mapred.TaskStatus: Trying to set finish time for task attempt_201208241212_26088_m_000043_1 when no start time is set, stackTrace is : java.lang.Exception\n\tat org.apache.hadoop.mapred.TaskStatus.setFinishTime(TaskStatus.java:195)\n\tat org.apache.hadoop.mapred.MapTaskStatus.setFinishTime(MapTaskStatus.java:51)\n\tat org.apache.hadoop.mapred.TaskTracker$TaskInProgress.kill(TaskTracker.java:2937)\n\tat org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:2255)\n\tat org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:2212)\n  \n  Since then, the TaskTracker has not completed any task.we can find the property of Connection -out is null from the above exeption,and it is caused by the failure of method setupIOstream() in the class org.apache.ipc.Client$Connection.anyway, the instance of Connection is not null and cached by the org.apache.ipc.Client.\n{code}\nprivate Connection getConnection(InetSocketAddress addr,\n                                   Class<?> protocol,\n                                   UserGroupInformation ticket,\n                                   Call call)\n                                   throws IOException, InterruptedException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    ConnectionId remoteId = new ConnectionId(addr, protocol, ticket);\n    do {\n      synchronized (connections) {\n        connection = connections.get(remoteId);\n        if (connection == null) {\n          connection = new Connection(remoteId);\n          connections.put(remoteId, connection);\n        }\n      }\n    } while (!connection.addCall(call));\n    \n    //we don't invoke the method below inside \"synchronized (connections)\"\n    //block above. The reason for that is if the server happens to be slow,\n    //it will take longer to establish a connection and that will slow the\n    //entire system down.\n    connection.setupIOstreams();\n    \n    \n    return connection;\n  }\n\n{code}\n  We guess that it throwed a OutOfMemoryError when a thread called the setupIOstream() because of RPC, so that some properties of the Connection are null, and throw NullPointerException when the Connection are accessed by other threads,which is fron the cache.It must be correct to make sure that the instance of Connection could only be access after initialized successfully. \n\n  On the other hand, we also simulate this scenario.Firstly, one thread create the Connection instance and throw OutOfMemoryError when it call connection.setupIOstreams().after that, the other thread start call RPC through by the instance and it keeps throwing the same exceptions\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320248","id":"12320248","description":"maintenance release on branch-1.0","name":"1.0.3","archived":false,"released":true,"releaseDate":"2012-05-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12313563","id":"12313563","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"336371","customfield_12312823":null,"summary":"The initialization may be missed for org.apache.ipc.Client$Connection","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12655772/comment/13698130","id":"13698130","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you please set the Affects Version/s field to the release where you observed this issue? Or did you observe this issue on both 1.0.3 and 0.21.0?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-02T19:40:50.796+0000","updated":"2013-07-02T19:40:50.796+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12655772/comment/13698135","id":"13698135","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"BTW 0.21.0 release never became stable. Are you using it? No 0.21.x releases are planned. So you may want to set the target version to 2.2.0 perhaps.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-02T19:42:22.134+0000","updated":"2013-07-02T19:42:22.134+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12655772/comment/13699995","id":"13699995","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"body":"However, I think that it should not be seen as the indicator of success for the setup or initialization of the Connection instance ,that property socket is not null!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"created":"2013-07-04T10:50:26.293+0000","updated":"2013-07-04T10:50:26.293+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12655772/comment/13700034","id":"13700034","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"body":"The source code about the initialization of the Connection instance:\n{code}\n private synchronized void setupIOstreams() throws InterruptedException {\n      \n-     if (socket != null || shouldCloseConnection.get()) {\n-       return;\n-     }\n      \n+     if(this.out != null || shouldCloseConnection.get()){\n+   \t  return;\n+     }\n      \n      short ioFailures = 0;\n      short timeoutFailures = 0;\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to \"+server);\n        }\n        while (true) {\n          try {\n            this.socket = socketFactory.createSocket();\n            this.socket.setTcpNoDelay(tcpNoDelay);\n            // connection time out is 20s\n            NetUtils.connect(this.socket, remoteId.getAddress(), 20000);\n            this.socket.setSoTimeout(pingInterval);\n            break;\n          } catch (SocketTimeoutException toe) {\n            /* The max number of retries is 45,\n             * which amounts to 20s*45 = 15 minutes retries.\n             */\n            handleConnectionFailure(timeoutFailures++, 45, toe);\n          } catch (IOException ie) {\n            handleConnectionFailure(ioFailures++, maxRetries, ie);\n          }\n        }\n        InputStream inStream = NetUtils.getInputStream(socket);\n        OutputStream outStream = NetUtils.getOutputStream(socket);\n        writeRpcHeader(outStream);\n        if (useSasl) {\n          final InputStream in2 = inStream;\n          final OutputStream out2 = outStream;\n          UserGroupInformation ticket = remoteId.getTicket();\n          if (authMethod == AuthMethod.KERBEROS) {\n            if (ticket.getRealUser() != null) {\n              ticket = ticket.getRealUser();\n            }\n          }\n          if (ticket.doAs(new PrivilegedExceptionAction<Boolean>() {\n            @Override\n            public Boolean run() throws IOException {\n              return setupSaslConnection(in2, out2);\n            }\n          })) {\n            // Sasl connect is successful. Let's set up Sasl i/o streams.\n            inStream = saslRpcClient.getInputStream(inStream);\n            outStream = saslRpcClient.getOutputStream(outStream);\n          } else {\n            // fall back to simple auth because server told us so.\n            authMethod = AuthMethod.SIMPLE;\n            header = new ConnectionHeader(header.getProtocol(),\n                header.getUgi(), authMethod);\n            useSasl = false;\n          }\n        }\n        if (doPing) {\n          this.in = new DataInputStream(new BufferedInputStream\n            (new PingInputStream(inStream)));\n        } else {\n          this.in = new DataInputStream(new BufferedInputStream\n            (inStream));\n        }\n        \n        \n        //byte[] data = new byte[1024*1024*5];\n        \n        this.out = new DataOutputStream(new BufferedOutputStream(outStream));\n        \n        writeHeader();\n\n        // update last activity time\n        touch();\n\n        // start the receiver thread after the socket connection has been set up\n        start();\n\n      } catch (IOException e) {\n        markClosed(e);\n        close();\n      }\n    }\n\n{code}\nOn the other hand,the program just olny catchs IOException, but does not catch and process any Errors, such as OutOfMemoryError.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"created":"2013-07-04T12:21:40.823+0000","updated":"2013-07-04T12:21:40.823+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12655772/comment/13700048","id":"13700048","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"body":"It May be better that:\n{code}\n private synchronized void setupIOstreams() throws InterruptedException {\n      \n-     if (socket != null || shouldCloseConnection.get()) {\n-       return;\n-     }\n      \n+     if(this.out != null || shouldCloseConnection.get()){\n+   \t  return;\n+     }\n      \n      short ioFailures = 0;\n      short timeoutFailures = 0;\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to \"+server);\n        }\n        while (true) {\n          try {\n            this.socket = socketFactory.createSocket();\n            this.socket.setTcpNoDelay(tcpNoDelay);\n            // connection time out is 20s\n            NetUtils.connect(this.socket, remoteId.getAddress(), 20000);\n            this.socket.setSoTimeout(pingInterval);\n            break;\n          } catch (SocketTimeoutException toe) {\n            /* The max number of retries is 45,\n             * which amounts to 20s*45 = 15 minutes retries.\n             */\n            handleConnectionFailure(timeoutFailures++, 45, toe);\n          } catch (IOException ie) {\n            handleConnectionFailure(ioFailures++, maxRetries, ie);\n          }\n        }\n        InputStream inStream = NetUtils.getInputStream(socket);\n        OutputStream outStream = NetUtils.getOutputStream(socket);\n        writeRpcHeader(outStream);\n        if (useSasl) {\n          final InputStream in2 = inStream;\n          final OutputStream out2 = outStream;\n          UserGroupInformation ticket = remoteId.getTicket();\n          if (authMethod == AuthMethod.KERBEROS) {\n            if (ticket.getRealUser() != null) {\n              ticket = ticket.getRealUser();\n            }\n          }\n          if (ticket.doAs(new PrivilegedExceptionAction<Boolean>() {\n            @Override\n            public Boolean run() throws IOException {\n              return setupSaslConnection(in2, out2);\n            }\n          })) {\n            // Sasl connect is successful. Let's set up Sasl i/o streams.\n            inStream = saslRpcClient.getInputStream(inStream);\n            outStream = saslRpcClient.getOutputStream(outStream);\n          } else {\n            // fall back to simple auth because server told us so.\n            authMethod = AuthMethod.SIMPLE;\n            header = new ConnectionHeader(header.getProtocol(),\n                header.getUgi(), authMethod);\n            useSasl = false;\n          }\n        }\n        if (doPing) {\n          this.in = new DataInputStream(new BufferedInputStream\n            (new PingInputStream(inStream)));\n        } else {\n          this.in = new DataInputStream(new BufferedInputStream\n            (inStream));\n        }\n        \n        \n        //byte[] data = new byte[1024*1024*5];\n        \n        this.out = new DataOutputStream(new BufferedOutputStream(outStream));\n        \n        writeHeader();\n\n        // update last activity time\n        touch();\n\n        // start the receiver thread after the socket connection has been set up\n        start();\n\n      } \n-\t  catch (IOException e) {\n-       markClosed(e);\n-       close();\n-      }\n+     catch (Throwable tb){\n+\t\tIOException ex = null;\n+\t\t\n+\t\tif(tb instanceof IOException) ex = (IOException) tb;\n+\t\t\n+\t\tmarkClosed(ex);\n+\t\tclose();\n+\t\t\n+\t\tif(tb instanceof Error) throw (Error)tb;\t\n\t  }\n    }\n\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dt_long","name":"dt_long","key":"dt_long","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hua xu","active":true,"timeZone":"Asia/Shanghai"},"created":"2013-07-04T12:59:13.143+0000","updated":"2013-07-04T12:59:13.143+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12655772/comment/13708962","id":"13708962","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"I asked couple of question. Could you please answer them?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-15T20:52:08.538+0000","updated":"2013-07-15T20:52:08.538+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-9684/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1lyrr:"}}