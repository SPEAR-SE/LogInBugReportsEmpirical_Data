{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13166199","self":"https://issues.apache.org/jira/rest/api/2/issue/13166199","key":"HADOOP-15541","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12342984","id":"12342984","description":"3.1.1 release","name":"3.1.1","archived":false,"released":true,"releaseDate":"2018-08-07"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2018-06-15T09:40:50.572+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jul 11 13:56:17 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_1910701291_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_399209842","customfield_12312321":null,"resolutiondate":"2018-07-11T13:56:28.394+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15541/watchers","watchCount":6,"isWatching":false},"created":"2018-06-14T20:17:57.301+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341760","id":"12341760","description":"2.9.1 release","name":"2.9.1","archived":false,"released":true,"releaseDate":"2018-05-03"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12342178","id":"12342178","description":"2.8.4 Release","name":"2.8.4","archived":false,"released":true,"releaseDate":"2018-05-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12342733","id":"12342733","description":"3.0.2 release","name":"3.0.2","archived":false,"released":true,"releaseDate":"2018-04-21"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12342984","id":"12342984","description":"3.1.1 release","name":"3.1.1","archived":false,"released":true,"releaseDate":"2018-08-07"}],"issuelinks":[{"id":"12536506","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12536506","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"13137852","key":"HADOOP-15220","self":"https://issues.apache.org/jira/rest/api/2/issue/13137852","fields":{"summary":"Über-jira: S3a phase V: Hadoop 3.2 features","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-07-11T13:56:28.421+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12311814","id":"12311814","name":"fs/s3","description":"S3A filesystem client and other S3 connectivity issues"}],"timeoriginalestimate":null,"description":"I've gotten a few reports of read timeouts not being handled properly in some Impala workloads. What happens is the following sequence of events (credit to Sailesh Mukil for figuring this out):\r\n * S3AInputStream.read() gets a SocketTimeoutException when it calls wrappedStream.read()\r\n * This is handled by onReadFailure -> reopen -> closeStream. When we try to drain the stream, SdkFilterInputStream.read() in the AWS SDK fails because of checkLength. The underlying Apache Commons stream returns -1 in the case of a timeout, and EOF.\r\n * The SDK assumes the -1 signifies an EOF, so assumes the bytes read must equal expected bytes, and because they don't (because it's a timeout and not an EOF) it throws an SdkClientException.\r\n\r\nThis is tricky to test for without a ton of mocking of AWS SDK internals, because you have to get into this conflicting state where the SDK has only read a subset of the expected bytes and gets a -1.\r\n\r\ncloseStream will abort the stream in the event of an IOException when draining. We could simply also abort in the event of an SdkClientException. I'm testing that this results in correct functionality in the workloads that seem to hit these timeouts a lot, but all the s3a tests continue to work with that change. I'm going to open an issue with the AWS SDK Github as well, but I'm not sure what the ideal outcome would be unless there's a good way to distinguish between a stream that has timed out and a stream that read all the data without huge rewrites.\r\n\r\n \r\n\r\n ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12930597","id":"12930597","filename":"HADOOP-15541.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2018-07-06T21:37:28.507+0000","size":3282,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12930597/HADOOP-15541.001.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"AWS SDK can mistake stream timeouts for EOF and throw SdkClientExceptions","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16512941","id":"16512941","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"There are a bunch of subtle bugs that have lead to use recovering the way we do. Pinging [~stevel@apache.org] who has worked on a few of these: do you know what benefit we gain from draining the stream instead of simply aborting and starting a new stream?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2018-06-14T20:26:25.712+0000","updated":"2018-06-14T20:26:25.712+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16512974","id":"16512974","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Also filed an issue with the SDK: [https://github.com/aws/aws-sdk-java/issues/1630.] But like I said, I'm not sure what the point is or if there's anything wrong with just aborting on SdkClientExceptions since we'll have to fail at some point anyway.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2018-06-14T20:55:58.062+0000","updated":"2018-06-14T20:55:58.062+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16513608","id":"16513608","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"I've worried about something related to this for a while, precisely because we are using close() not abort. Assuming the error on read() is due to a network problem, breaking that whole TCP connection is the only way to guarantee that your followup GET isn't on the same HTTP1.1 stream.\r\n\r\nI wasn't too worried, on the basis that nobody had complained...clearly that's not true any more. And my expectation of how things would fail was worse. \r\n\r\nHere's one possible strategy\r\n\r\n# {{S3AInputStream.reopen()}}  adds a {{boolean forceAbort}} param; passes it in to {{closeStream}}; \r\n# {{S3AInputStream.onReadFailure()}} forces that abort.\r\n\r\nLike you say, no real point in not aborting here.\r\n\r\nHappy for a patch, I don't think we can test this easily so not expecting any tests in the patch...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-06-15T09:40:50.572+0000","updated":"2018-06-15T09:40:50.572+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16516306","id":"16516306","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"{quote}Like you say, no real point in not aborting here.{quote}\r\n\r\nHelp me understand, though: when *do* we get a benefit from draining the stream instead of simply aborting?\r\n\r\n{quote}Happy for a patch, I don't think we can test this easily so not expecting any tests in the patch...{quote}\r\n\r\nYeah. This was (at the time anyway) happening pretty repeatedly with a particular workload - I'm hoping that keeps up so I can be fairly confident that the end result here is correct handling of timeouts.\r\n\r\nInstead of the forceAbort option, any objection to simple aborting when we catch IOExceptions AND SdkClientExceptions? If we're intended to close a previous stream and open a new one and draining the stream fails for any reason at all, I'd think we'd still want to force abort and proceed regardless of the option that led us to this point.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2018-06-18T20:19:43.639+0000","updated":"2018-06-18T20:27:41.264+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16517417","id":"16517417","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Stream draining means the http1.1 connection can be returned to the pool and so save setup costs, which is why we like to do it on close()\r\n\r\nBut here, if we can conclude that the connection is in trouble, should we return it it? \r\n\r\nNo objection to doing the abort for IOEs and SDKs, I was suggesting the arg because the reopen code already takes that param...requesting that forced abort after an exception on read() would be good.\r\n\r\nthough: are you suggesting for any IOE/SDK exception we don't try to reopen the call, just force the abort() before throwing up the exception? If so, yes, that also makes sense. We don't want a failing HTTP connection to be recycled\r\n\r\nMake sure any metrics on forced aborts are incremented though","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-06-19T18:41:34.220+0000","updated":"2018-06-19T18:41:34.220+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16535383","id":"16535383","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Thanks for the explanation [~stevel@apache.org]. Attaching a patch that uses the existing force-abort code in the event of a timeout. All tests continue to pass, and the workload that was consistently timing out before suddenly stopped upon applying this patch. I just saw your comment about incrementing metrics, though. Let me check for those and revise the patch if necessary.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2018-07-06T21:40:41.351+0000","updated":"2018-07-06T21:40:41.351+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16535386","id":"16535386","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Although on first glance, it certainly seems that calling streamStatistics.streamClose takes care of all that, and we're doing that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2018-07-06T21:47:35.980+0000","updated":"2018-07-06T21:47:35.980+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16535510","id":"16535510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m 47s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 30s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 19s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 20s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 31s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 27s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 59s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 31s{color} | {color:green} hadoop-aws in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 61m 33s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |\r\n| JIRA Issue | HADOOP-15541 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12930597/HADOOP-15541.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux e6408faeb955 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / ba68320 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_171 |\r\n| findbugs | v3.1.0-RC1 |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14864/testReport/ |\r\n| Max. process+thread count | 302 (vs. ulimit of 10000) |\r\n| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14864/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-07-07T00:14:48.580+0000","updated":"2018-07-07T00:14:48.580+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16538498","id":"16538498","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Looks good. \r\nOne issue: should we always force close on a read failure, rather than treat SocketTimeoutException as special? I guess there are some potential failure modes (source was deleted during the read) which could trigger IOEs during the GET (maybe? Do we test this with a large enough file to be sure there's no caching going on? If not, I could imagine adding it to the huge files test....). \r\n\r\nIF we say \"every IOE -> forced abort', then its a simpler path on read. What you have here though is the core fix: on socket errors, don't try and recycle things.\r\n\r\nWhat do you think? If you want this one as is, you've got my +1. I'm just wondering if the need to add a separate catch for SocketTimeoutException is needed","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-07-10T12:28:05.643+0000","updated":"2018-07-10T12:28:05.643+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16538842","id":"16538842","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"body":"Thanks Steve, commited. I'd like to commit this right now to address the known issue. I wanna do a bit of searching around and see if I can find any cases of IOExceptions where it would make sense to reuse the stream before taking it further. I'll a separate JIRA for that before resolving...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mackrorysd","name":"mackrorysd","key":"mackrorysd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mackrorysd&avatarId=18559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mackrorysd&avatarId=18559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mackrorysd&avatarId=18559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mackrorysd&avatarId=18559"},"displayName":"Sean Mackrory","active":true,"timeZone":"America/Denver"},"created":"2018-07-10T15:59:31.389+0000","updated":"2018-07-10T15:59:31.389+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16538888","id":"16538888","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14550 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14550/])\nHADOOP-15541. [s3a] Shouldn't try to drain stream before aborting (mackrorysd: rev d503f65b6689b19278ec2a0cf9da5a8762539de8)\n* (edit) hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2018-07-10T16:22:18.864+0000","updated":"2018-07-10T16:22:18.864+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13166199/comment/16540126","id":"16540126","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"OK. cherry picked to branch-3.1; lets close this one.\r\n\r\nThank you for finding a new failure mode :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-07-11T13:56:17.410+0000","updated":"2018-07-11T13:56:17.410+0000"}],"maxResults":12,"total":12,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-15541/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3uvx3:"}}