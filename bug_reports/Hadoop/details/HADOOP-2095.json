{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12381005","self":"https://issues.apache.org/jira/rest/api/2/issue/12381005","key":"HADOOP-2095","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310240","id":"12310240","key":"HADOOP","name":"Hadoop Common","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312972","id":"12312972","description":"","name":"0.18.0","archived":false,"released":true,"releaseDate":"2008-08-22"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2007-10-25T04:26:38.371+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jun 05 05:59:25 UTC 2008","customfield_12310420":"81135","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_25975656_*|*_1_*:*_1_*:*_19440970854_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_6795780743","customfield_12312321":null,"resolutiondate":"2008-06-05T04:07:25.019+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2095/watchers","watchCount":5,"isWatching":false},"created":"2007-10-23T20:38:18.509+0000","customfield_12310192":"Reduced in-memory copies of keys and values as they flow through the Map-Reduce framework. Changed the storage of intermediate map outputs to use new IFile instead of SequenceFile for better compression.","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"7.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12312565","id":"12312565","description":"","name":"0.15.0","archived":false,"released":true,"releaseDate":"2007-10-19"}],"issuelinks":[{"id":"12319310","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12319310","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12389392","key":"MAPREDUCE-99","self":"https://issues.apache.org/jira/rest/api/2/issue/12389392","fields":{"summary":"Reducers throw oom exceptions during fetching map outputs","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12320194","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12320194","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"12395589","key":"HADOOP-3366","self":"https://issues.apache.org/jira/rest/api/2/issue/12395589","fields":{"summary":"Shuffle/Merge improvements","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2009-07-08T16:52:30.385+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"One of the reducers of my job failed with the following exceptions.\nThe failure caused the whole job fail eventually.\nJava heapsize was 768MB and sort.io.mb was 140.\n\n\n2007-10-23 19:24:06,100 WARN org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Intermediate Merge of the inmemory files threw an exception: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.hadoop.io.compress.DecompressorStream.(DecompressorStream.java:43)\n\tat org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:71)\n\tat org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1345)\n\tat org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1231)\n\tat org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1154)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor.nextRawKey(SequenceFile.java:2726)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:2543)\n\tat org.apache.hadoop.io.SequenceFile$Sorter.merge(SequenceFile.java:2297)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$InMemFSMergeThread.run(ReduceTask.java:1311)\n2007-10-23 19:24:06,102 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 done copying task_200710231912_0001_m_001428_0 output .\n2007-10-23 19:24:06,185 INFO org.apache.hadoop.fs.FileSystem: Initialized InMemoryFileSystem: ramfs://mapoutput31952838/task_200710231912_0001_r_000020_2/map_1423.out-0 of size (in bytes): 209715200\n2007-10-23 19:24:06,193 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)\n\tat org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)\n\n2007-10-23 19:24:06,193 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001215_0 output from xxx\n2007-10-23 19:24:06,188 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001211_0 output from xxx\n2007-10-23 19:24:06,185 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryOutputStream.close(InMemoryFileSystem.java:161)\n\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:49)\n\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:64)\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.close(ChecksumFileSystem.java:312)\n\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:49)\n\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:64)\n\tat org.apache.hadoop.mapred.MapOutputLocation.getFile(MapOutputLocation.java:253)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:713)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)\n\n2007-10-23 19:24:06,199 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001247_0 output from .\n2007-10-23 19:24:06,200 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)\n\tat org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)\n\n2007-10-23 19:24:06,204 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001422_0 output from .\n2007-10-23 19:24:06,207 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)\n\tat org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)\n\n2007-10-23 19:24:06,209 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001278_0 output from .\n2007-10-23 19:24:06,198 WARN org.apache.hadoop.mapred.TaskTracker: Error running child\njava.io.IOException: task_200710231912_0001_r_000020_2The reduce copier failed\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:253)\n\tat org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1760)\n2007-10-23 19:24:06,198 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)\n\tat org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)\n\n2007-10-23 19:24:06,231 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001531_0 output from .\n2007-10-23 19:24:06,197 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)\n\tat org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)\n\n2007-10-23 19:24:06,237 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001227_0 output from .\n2007-10-23 19:24:06,196 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)\n\tat org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)\n\tat org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12383432","id":"12383432","filename":"HADOOP-2095_2_20080604.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-05T02:49:41.957+0000","size":165522,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12383432/HADOOP-2095_2_20080604.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12383426","id":"12383426","filename":"HADOOP-2095_2_20080604.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T23:56:00.014+0000","size":165492,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12383426/HADOOP-2095_2_20080604.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12383415","id":"12383415","filename":"HADOOP-2095_2_20080604.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T21:34:52.698+0000","size":165257,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12383415/HADOOP-2095_2_20080604.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12383412","id":"12383412","filename":"HADOOP-2095_2_20080604.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T20:54:14.808+0000","size":165292,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12383412/HADOOP-2095_2_20080604.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12383368","id":"12383368","filename":"HADOOP-2095_2_20080604.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T09:55:40.461+0000","size":164154,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12383368/HADOOP-2095_2_20080604.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12368782","id":"12368782","filename":"HADOOP-2095_CompressedBytesWithCodecPool.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-31T18:50:56.573+0000","size":4524,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12368782/HADOOP-2095_CompressedBytesWithCodecPool.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12368779","id":"12368779","filename":"HADOOP-2095_debug.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-31T18:34:33.353+0000","size":1753,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12368779/HADOOP-2095_debug.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"105852","customfield_12312823":null,"summary":"Reducer failed due to Out ofMemory","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12537162","id":"12537162","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"The problem was gone  after I set the compressMapOutput attribute to false.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2007-10-23T22:26:02.378+0000","updated":"2007-10-23T22:26:02.378+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12537491","id":"12537491","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Is it true that native compression was in use when you saw the problem?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-10-25T04:26:38.371+0000","updated":"2007-10-25T04:26:38.371+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12537492","id":"12537492","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"Yes.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2007-10-25T04:31:05.001+0000","updated":"2007-10-25T04:31:05.001+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12537499","id":"12537499","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"My hunch is this that we are ending up with too many files in the ramfs (the map outputs for the failing reduce are small in size). So when merge is initiated on those files, we end up creating too many codecs for decompressing the files, and since they are native, we encounter OOM. So one way to validate this is to decrease the value of mapred.inmem.merge.threshold (defaults to 1000) to something like 200 and then see whether the OOM goes away. The other alternative is to increase the heap size per task.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-10-25T05:41:05.460+0000","updated":"2007-10-25T05:41:05.460+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12538088","id":"12538088","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"FYI, I ran into the exactly same issue with massive failures (nearly all reduces), using a 0 value for mapred.inmem.merge.threshold (letting the framework select the threshold)\n\nusing native compression\n\n1GB of heap space, 1350 nodes\n\nmapred.inmem.merge.threshold\t0\nmapred.reduce.parallel.copies\t20\ntasktracker.http.threads\t30\nmapred.map.tasks\t13008\nmapred.reduce.tasks\t3600\nfs.inmemory.size.mb\t200\nio.seqfile.sorter.recordlimit\t1000000\nio.sort.mb\t200\nio.sort.factor\t300\nmapred.map.output.compression.type\tRECORD\nmapred.map.output.compression.codec\torg.apache.hadoop.io.compress.DefaultCodec\nmapred.compress.map.output\ttrue\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-10-26T20:07:57.212+0000","updated":"2007-10-26T20:07:57.212+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12538160","id":"12538160","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Christian, please don't use 0 for mapred.inmem.merge.threshold. It basically disables the threshold for initiating merge, and, in this case, merge on the ramfs files gets triggered only when the ramfs has collected enough bytes of data (actually 50% of fs.inmemory.size.mb). Depending on how big each map output is, we will accumulate that many files there. For each file, a native codec will be initialized, and I suspect that if we create too many codecs, we will encounter OOM (given a certain child heap size). So, I think it is worth trying the app with a reduced mapred.inmem.merge.threshold like 50/100, just to ensure that we keep a control on the number of codecs we create. Christian/Runping, could you please try this tweak and let us know? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-10-27T03:35:33.417+0000","updated":"2007-10-27T03:35:33.417+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12538161","id":"12538161","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Just to clarify, a codec-pool is maintained in the compression module. So, the number of codecs created will be in the order of mapred.inmem.merge.threshold.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-10-27T03:48:06.859+0000","updated":"2007-10-27T03:48:06.859+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12538292","id":"12538292","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"BTW, another thing that needs to be controlled is the io.sort.factor which would control the number of files that gets merged at once post the shuffle (the final merge of the on-disk files). The number of intermediate files opened would be as per the value of io.sort.factor and you might encounter OOM if that is large. So i would recommend that for working around this issue, the io.sort.factor value should be in the same order as the value of mapred.inmem.merge.threshold (that successfully does ramfs merges during the shuffle).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-10-28T08:42:36.055+0000","updated":"2007-10-28T08:42:36.055+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12538886","id":"12538886","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"Christian,\n   Can you generate a set of task files for the reduce with the failure with keep.failed.task.files set to true, so that we can run it in the isolation runner and a profiler?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-30T18:56:06.568+0000","updated":"2007-10-30T18:56:06.568+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12539003","id":"12539003","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Noticed that codec pool is not used in o.a.h.i.SequenceFile.CompressedBytes.writeUncompressedBytes. This needs to be fixed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-10-31T05:39:37.372+0000","updated":"2007-10-31T05:39:37.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12539148","id":"12539148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Christian/Runping - Could you please re-run your jobs using this debug patch? It just logs the no. of created native codecs and the stack trace to check where they are being created from. Thanks!\n\nMeanwhile I'll plug away and see how to fix SequenceFile.CompressedBytes as Devaraj pointed out...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-31T18:34:33.421+0000","updated":"2007-10-31T18:34:33.421+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12539151","id":"12539151","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Here is an early patch which fixed {{SequenceFile.CompressedBytes}} to use a {{CodecPool}} passed along by the {{SequenceFile.Reader}}... \n\nChristian/Runping -I'd appreciate if you could try this patch alongwith the previous debug patch while I try to test it at my end. Thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-31T18:46:34.239+0000","updated":"2007-10-31T18:46:34.239+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12539153","id":"12539153","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry, previous patch had the leading path wrong...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-31T18:49:25.882+0000","updated":"2007-10-31T18:49:25.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12539154","id":"12539154","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry, previous patch had the leading path wrong...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-31T18:50:56.717+0000","updated":"2007-10-31T18:50:56.717+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12569993","id":"12569993","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"I still see failures after shuffling during final sort:\n\njava.lang.OutOfMemoryError: Java heap space\n\tat org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:52)\n\tat org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:90)\n\tat org.apache.hadoop.io.SequenceFile$Reader.readBuffer(SequenceFile.java:1535)\n\tat org.apache.hadoop.io.SequenceFile$Reader.readBlock(SequenceFile.java:1574)\n\tat org.apache.hadoop.io.SequenceFile$Reader.nextRawKey(SequenceFile.java:1878)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor.nextRawKey(SequenceFile.java:2894)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:2694)\n\tat org.apache.hadoop.io.SequenceFile$Sorter.merge(SequenceFile.java:2478)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:298)\n\tat org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2049)\n\nor\n\njava.lang.OutOfMemoryError: Java heap space\n\tat org.apache.hadoop.io.compress.DecompressorStream.(DecompressorStream.java:43)\n\tat org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:71)\n\tat org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1480)\n\tat org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1379)\n\tat org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1302)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor.nextRawKey(SequenceFile.java:2877)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:2694)\n\tat org.apache.hadoop.io.SequenceFile$Sorter.merge(SequenceFile.java:2478)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:298)\n\tat org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2049)\n\nConfiguration:\n\nusing native compression\n1GB of heap space, 1350 nodes\nmapred.inmem.merge.threshold 1000\nmapred.reduce.parallel.copies 10\ntasktracker.http.threads 10\nmapred.map.tasks 2500\nmapred.reduce.tasks 2500\nfs.inmemory.size.mb 200\nio.seqfile.sorter.recordlimit 1000000\nio.sort.mb 200\nio.sort.factor 1000\nmapred.map.output.compression.type BLOCK\nmapred.map.output.compression.codec org.apache.hadoop.io.compress.DefaultCodec\nmapred.compress.map.output true\n\nI tried 2 runs:\n1) io.seqfile.compress.blocksize = 1000000 --> 1084 successful reduces, 935 failures\n2) io.seqfile.compress.blocksize = 131072 -->  2286 successful reduces, 1032 failures\n\nThe failures all seem to occur after shuffling, in the final merge-sort. Because the patch uses a pool of codecs I thought I should be able to keep a high sort.factor (to reduce the amount of multi-phasic merge-sort).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-18T19:45:14.013+0000","updated":"2008-02-18T19:45:14.013+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12569997","id":"12569997","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for trying this out Christian! Do you have the logs of the failed tasks somewhere i.e. the syslog file?\n\nClearly this needs more work... sigh.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-18T19:56:01.271+0000","updated":"2008-02-18T19:56:01.271+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12570002","id":"12570002","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Logs are available. I send you the pointers offline.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-18T20:16:39.024+0000","updated":"2008-02-18T20:16:39.024+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12570003","id":"12570003","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"\n1000 as merge factor seems very high.\nHow much data each reducer isexpected to process?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-18T20:17:23.761+0000","updated":"2008-02-18T20:17:23.761+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12570005","id":"12570005","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"With compression turned off we never had any problems with high merge factor (which reduces time spent in merging). Concerning the amount of data processed by reducers, the particular job has a few (imbalanced) reducers processing 100+ GB uncompressed. With block compression turned on we were hoping to reduce the merging even further.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-18T20:36:41.414+0000","updated":"2008-02-18T20:36:41.414+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12570395","id":"12570395","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"1000 is a much higher merge factor than is expected by the design.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-19T19:47:13.864+0000","updated":"2008-02-19T19:47:13.864+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12570944","id":"12570944","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm removing this as a blocker for 0.16.1 while we continue discussions...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-21T05:20:58.765+0000","updated":"2008-02-21T05:20:58.765+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12573169","id":"12573169","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"What is the RAM overhead of an active decompressor?  We can probably compute a reasonable merge size from that.  If we are seeing lots of very small files, maybe we should consider just working with the uncompressed data for small inputs?  That may use less total RAM and it should be easy to determine that on the fly.  \n\nYou could cap the number of compressed files in RAM and when you add a new file you could choose to uncompress the smallest file you have to allow you to stay under the limit.  You could also merge and recompress your small files, this obviously uses a lot more CPU.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-28T07:15:52.679+0000","updated":"2008-02-28T07:15:52.679+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12592198","id":"12592198","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"\nI'd like to elaborate a bit alone Eric's comment.\n\nThe root cause of the current problem is that when we merge too many small segments, \nwe need to allocate too many codecs, thus run out of memory.\nThe main point is to treat large segments and small segments differently.\nIt is intuitive that merging a lot of small segments incurrs too much overhead and may be inferior to quick sort.\n\nLet's say we have a fixed memory budget for in mem merge of fetched map output.\nWhen we fetch a small segment, we extract the records out of the segment and put in an area for future quick sort.\nWhen we fetch a big segment, we  leave it in the in mem file.\nWhen the number of in-mem file reach certain limit (say 100), or the total memory consumption reach the budget, we sort the extracted \nrecords, and merge them along with the inmem files.\n\nThis way, we can guarantee that we will not exceed the total memory budget.\n\nThoughts?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2008-04-24T23:24:33.975+0000","updated":"2008-04-24T23:24:33.975+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12592270","id":"12592270","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"I would like to suggest a very simple improvement.\n\n1) Compute the maximum number of usable decompressors.\n2) Download splits until ram is full, or we have reached the limit.\n3) If ram is not full\n    b) continue downloading splits, but now decompress them as they are loaded\n\n4) Now merge and dump all the splits, decompressing the first N on the fly\n\nThis is very simple and works in almost all cases.  A refinement would be to decompress the smallest split each time you load a new split beyond the merge limit.\n\n---\n\nThe above seems like it would be very simple to code and would work well in the face of large splits (the merge limit is not reached) and many small splits (many are merged in the first pass).  It would be ok in the face of medium splits, which seems like the worst case.\n\nA more optimal algorithm would presumably merge in ram, compressing on the fly and so on, but this is very complex and has many corner cases.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-04-25T04:57:43.528+0000","updated":"2008-04-25T04:57:43.528+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12592530","id":"12592530","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for Eric's proposal.\n\nA minor refinement to discuss:\n\n3) If ram is not full\nc) initiate the merge with the in-memory compressed files which fit the quota; continue downloading the compressed splits and stuff the compressed split as-is in the InMemoryFileSystem (on ram).\n\nThe next pass of the merge will pick it up and run with it. It has the advantage of saving ram and keeping the merge-code simple: each split is either compressed (compression enabled) or not (compression disabled).\n\nThoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-04-25T23:45:46.721+0000","updated":"2008-04-25T23:45:46.721+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12592846","id":"12592846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"I think that runs contrary to the goal of the exercise, which is to merge as many inputs at once as possible (with as little code complexity as possible).  We don't want to add extra passes in the case where the inputs are very small.\n\nPossible refinements from there might include:\n- merging and compressing back into ram (might be very good in some cases)\n- Releasing ram as inputs are merged to allow interleaving of the reads without wasting ram\n\nPS We should be sure to not have the merge factor considered in this code!  Merge factor if it should exist at all should be about the number of inputs from disk.  Even that is pretty awkward.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-04-28T17:05:38.542+0000","updated":"2008-04-28T17:05:38.542+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12592925","id":"12592925","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"It is worth noting that we'd need to reserve mapred.reduce.parallel.copies (default 5, but 20 on yahoo's clusters) extra codecs for decompressing on the fly. It isn't clear to me that it would be a win having the codec owned by the copier thread rather than the merger. \n\nYou would also need to add a header that gives the uncompressed size of the map outputs, so that the reducer knows how big the uncompressed file is.\n\nOf course getting rid of the 4 compression codecs using something like HADOOP-3315, would help a *lot*.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-04-28T23:13:42.637+0000","updated":"2008-04-28T23:13:42.637+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12595134","id":"12595134","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Somre refinements after further discusssions...\n\nPrologue: Use a compressed outputstream for the intermediate sequence files i.e. map-outputs, not {record|block}-compressed sequence files. This cuts down no. of decompressors required at the reducers. Add headers to ensure that the reducer can query each map to find out the exact compressed and uncompressed sizes _before_ it actually copies the data.\n\n1) Compute the maximum number of usable decompressors (this is going to get tricky with direct-buffers taking up non-heap space which is a fraction of the -Xmx of the jvm).\n2) Download map-outputs until ramfs is full; or we have reached the decompressors' limit.\n3) Trigger InMemFSMergeThread to start the merge. (Currently a new InMemFSMergeThread created for every triggered merge, I plan to fix it so that we use one and only one thread.)\n4) If ramfs is full, _suspend_ the shuffle; else keep shuffling into memory.\n\nEssentially the idea is that we pack as much into memory before we initiate the merge, this saves us trips to disk (the output of the merge) which, as Devaraj has shown (http://issues.apache.org/jira/browse/HADOOP-3297?focusedCommentId=12592816#action_12592816) leads to much better overall performance.\n\nOf course the above discussion is valid _iff_ we are dealing with small map-outputs.\n\nFor the contra-case where map-outputs are large, we need a threshold which says:\nIf a map-output > 10% of ramfs, then shuffle into memory if possible (i.e. space available in ramfs), else shuffle to disk. \nThis ensures that we do not needlessly throttle shuffle if map-outputs are too big to fit into ramfs. \n\nThoughts?\n\n----\n\nBefore I jump in and make changes I'm currently trying to simulate the above behaviour and publish some numbers... watch this space.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-08T07:04:48.326+0000","updated":"2008-05-08T07:07:37.803+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12595386","id":"12595386","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"To clarify some of the thinking above...  The short term goal is not to find the optimal solution.  It is to get something done that is clean, understandable and works acceptably well in all cases.  We can refine from there.\n\nto expand on the above suggestions:\n\nI suggest that for objects larger than 25% of RAM, we always just send them directly to disk.  A simple rule that let's us reason more easily about other case.  I don't think the 10% number above can be replaced with thiis.\n\nWe need to understand how we pause the copies without doing lots of polling.  Again, I suggest keeping it simple for now.  What about simply setting a global flag the first time a thread starts to read an input that is < 25% of buffer RAM (not piped directly to disk) and doesn't fit in the remaining space.  Other readers will then pause until this semaphore is cleared.  It is ok if races happen where a few threads try at the same time.  If copies fail, we will need to clear this semaphore too.\n\nWe want to be sure not to wait until RAM is totally full before starting the merge, because this might allow a single slow copy to brownout the system.  I suggest a simple rule, such as wait until the semaphore discussed above is set and copies filling at least 50% of RAM have completed.  Then merge.\n\nOnce all of the above is done, we can file new jiras to improve things.  Ideas include:\n- Freeing storage as we merge, so fetches can be interleaved\n- decompressing small segments as we read so we can increase the number of compressed objects merged\n- ...\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-08T20:53:28.171+0000","updated":"2008-05-08T20:53:28.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12596300","id":"12596300","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. To clarify some of the thinking above... The short term goal is not to find the optimal solution. It is to get something done that is clean, understandable and works acceptably well in all cases. We can refine from there.\n\n+1\n\nAlong a similar tangent, here is an even simpler proposal for a first-cut. Please bear in mind that these are a result of the fact that we have noticed that the merge code is actually a juicier target to fix; on large jobs we have noticed that reduces (which started _after_ all maps were completed) were spending way more time in merge rather than in shuffle: 13mins in shuffle, 17mins in merge and 15mins in reduce. So, the idea to fix the OOM to ensure better reliability in a reasonably straight-forward, simple manner and then go after merge in HADOOP-3366.\n\nHere goes:\n1. Use a compressed stream for map-outputs, not {record|block}-compressed sequence-files. Ensure both compressed and decompressed sizes are available for the reduce _before_ it actually shuffles the bytes.\n2. Decompress map-outputs as soon as they are shuffled into ramfs if there is enough space, else suspend shuffle as described above by Eric. This ensures that we never hit the #codecs limit, we just need as many codecs as the no. of threads doing the shuffle. The idea is that the merge-factor is anyway going to be limited by the #codecs, we might as well burn-up RAM. We could try and store the compressed outputs as a further refinement in a separate issue.\n3. If RAM is more than (say) 50% full, we start merging in-memory. Also, initially we should use up as much RAM as possible, allowing for some slack. Therefore I propose we do away with the *fs.inmemory.size.mb* config knob and use 3/4 or 2/3 of the heap-size available as the RAM limit.\n4. If the split is greater than 10% or 25% of available RAM limit, and there is on RAM available we shuffle directly to disk (compressed).\n5. The output of merge is compressed and written to disk, which potentially could be merged along with (4) above.\n\nHopefully this is reasonably simple and coherent. I'll put up more thoughts on HADOOP-3366 about merge improvements, current pitfalls etc.\n\nThoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-13T06:51:58.182+0000","updated":"2008-05-13T06:51:58.182+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12596380","id":"12596380","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"How would the case of multiple threads being suspended be handled? If we have a choice, we should place into ramfs the smaller files first.\nI am slightly concerned about the cpu cycles we will burn for compress/decompress the output of merges. What is the reason for compressing the output of merge?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2008-05-13T12:49:00.491+0000","updated":"2008-05-13T12:49:00.491+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12596400","id":"12596400","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. How would the case of multiple threads being suspended be handled? If we have a choice, we should place into ramfs the smaller files first.\nAll threads wait on a single semaphore and we could do a 'notifyAll' ...\n\nbq. I am slightly concerned about the cpu cycles we will burn for compress/decompress the output of merges. What is the reason for compressing the output of merge?\nThe compression of merge-outputs is to reduce temporary disk usage on the reducer node. Also it has the nice property of keeping all data on disk compressed, since compressed splits which can't fit in-memory go straight to disk. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-05-13T14:27:36.202+0000","updated":"2008-05-13T14:27:36.202+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12596425","id":"12596425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"\nWe can expect better performance if we use lz0 as the codec for compressing the map outputs and the merge outputs.\nSome more benchmarking may be required to confirm this, though.\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2008-05-13T16:23:03.719+0000","updated":"2008-05-13T16:23:03.719+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602230","id":"12602230","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Here is a nearly complete patch (I need fix a couple of failing test-cases). \n\nHighlights:\n1. Rework sort/merge to use the new IFile rather than SequenceFiles.\n2. Compression for intermediate map-outputs now implies that the entire file is compressed, no more record/block compression. This helps the codec cost.\n3. Rework intermediate merge to ensure there are no spurious copies of keys/values.\n\nBenchmarks:\nI ran this with a single reducer job where 2500 maps produced 5MB of data each. Trunk takes 45 mins for the job to complete with the on-disk merge taking nearly 25-30mins and the final merge (as records are fed to 'reduce') taking 12-13mins. With this patch the on-disk merge takes 20-22mins and the final merge takes around 7mins, an overall improvement of nearly 30%.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T09:55:40.474+0000","updated":"2008-06-04T09:55:40.474+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602421","id":"12602421","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"I looked at most of the patch except MapTask. +1 on the patch subject to unit tests passing and the sort benchmark running well. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2008-06-04T19:12:23.241+0000","updated":"2008-06-04T19:12:23.241+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602453","id":"12602453","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the review Devaraj!\n\nHere is an updated version of the patch with some minor changes...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T20:54:14.844+0000","updated":"2008-06-04T20:54:14.844+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602456","id":"12602456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"body":"just one comment:\n\n+        LOG.info(\"Sent out \" + totalRead + \" bytes (starting from offset: \" + startOffset + \" of outputFile: \" + mapOutputFileName + \" for reduce: \" + reduce + \" from map: \" + mapId + \" given \" + partLength + \"/\" + rawPartLength);\n\nyou might want to wrap this around!! :)\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"created":"2008-06-04T21:10:46.171+0000","updated":"2008-06-04T21:10:46.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602463","id":"12602463","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Fixed the log statement... thanks for the review Mahadev!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T21:34:52.733+0000","updated":"2008-06-04T21:34:52.733+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602505","id":"12602505","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Pretty-fied another log message...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-04T23:56:00.079+0000","updated":"2008-06-04T23:56:00.079+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602520","id":"12602520","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12383426/HADOOP-2095_2_20080604.patch\n  against trunk revision 663370.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 12 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    -1 javac.  The applied patch generated 449 javac compiler warnings (more than the trunk's current 447 warnings).\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    -1 release audit.  The applied patch generated 196 release audit warnings (more than the trunk's current 195 warnings).\n\n    +1 core tests.  The patch passed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2580/testReport/\nRelease audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2580/artifact/trunk/current/releaseAuditDiffWarnings.txt\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2580/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2580/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2580/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2008-06-05T02:20:03.170+0000","updated":"2008-06-05T02:20:03.170+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602523","id":"12602523","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"The javac warning was:\n{noformat}\n    [javac] /zonestorage/hudson/home/hudson/hudson/jobs/Hadoop-Patch/workspace/trunk/src/java/org/apache/hadoop/mapred/JobConf.java:467: warning: [dep-ann] deprecated name isnt annotated with @Deprecated\n    [javac]   public void setMapOutputCompressionType(CompressionType style) {\n    [javac]               ^\n    [javac] /zonestorage/hudson/home/hudson/hudson/jobs/Hadoop-Patch/workspace/trunk/src/java/org/apache/hadoop/mapred/JobConf.java:482: warning: [dep-ann] deprecated name isnt annotated with @Deprecated\n    [javac]   public CompressionType getMapOutputCompressionType() {\n    [javac]                          ^\n{noformat}\n\nFixed now.\n\nThe test-case failure seems unrelated and works on both Linux and Mac.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-05T02:49:41.975+0000","updated":"2008-06-05T02:49:41.975+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602528","id":"12602528","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"Why start the merge before the first fetcher thread is blocked due to  \nlack of RAM?  This seems like the wrong trade-off to me.  Especially  \nfor shuffles before the MAP is done.\n\nBe sure to account for brown-out / race conditions.  IE we may have a  \nfew really slow reads.  Hence we should only wait for the first  \nthread to block.  This should also influence the size of max element  \nwe will write to RAM.  EG I'd suggest the MAX object stored to RAM be  \nless than the (space used) / shuffle threads /2.  This will insure  \nyou have a full set of elements to merge when you start merging.  You  \nmight want to code an \"assertion\" for that.\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-05T04:02:46.629+0000","updated":"2008-06-05T04:02:46.629+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602531","id":"12602531","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this, many thanks to Devaraj, Chris & Mahadev for review it!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-05T04:07:24.966+0000","updated":"2008-06-05T04:07:24.966+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602538","id":"12602538","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Eric, doesn't it make sense to have a bit of buffer space free even during the merge? On machines where merge is quick (faster CPUs) it will allow shuffle to continue unimpeded... \nCurrently a merge is triggered when the buffer is half-full, which I plan to tweak a bit. \n\nMeanwhile I plan to use HADOOP-3366 to continue the 'stalled shuffle' rework.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-05T04:32:23.556+0000","updated":"2008-06-05T04:32:23.556+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12381005/comment/12602552","id":"12602552","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"body":"Let's get some numbers.  Producing the largest possible runs should be a long term goal.  It sounds like this will be an improvement over what we had.\n\nAn optimal solution would fill RAM (with compressed data) and then release that RAM as it merged, allowing the shuffle to be interleaved.\nMaybe you should create a new JIRA to track possible future improvements?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eric14","name":"eric14","key":"eric14","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"eric baldeschwieler","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-05T05:59:25.977+0000","updated":"2008-06-05T05:59:25.977+0000"}],"maxResults":45,"total":45,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HADOOP-2095/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ih0v:"}}