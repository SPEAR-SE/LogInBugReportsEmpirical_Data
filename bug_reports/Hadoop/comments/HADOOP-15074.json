[you mean after a flush/sync the length of the file from a listing/getFileStatus hasn't changed?, Hi [~stevel@apache.org], Yes, the length of the file wasn't updated after a hsync/hflush on the writer. This happens because the update length isn't passed as part of the flush/sync. Hence the length isn't updated as part of the sync request.

{code}
  @Override
  public void hsync() throws IOException {
    try (TraceScope ignored = dfsClient.newPathTraceScope("hsync", src)) {
      flushOrSync(true, EnumSet.noneOf(SyncFlag.class));
    }
  }
{code}, I propose the following change in the DFSOutputStream#hsync api to ensure the file size gets updated at the namenode when hsync completes.
{code:java}
@Override
public void hsync() throws IOException {
   try (TraceScope ignored = dfsClient.newPathTraceScope("hsync", src)) {
      flushOrSync(true, EnumSet.of(SyncFlag.UPDATE_LENGTH));
   }
}{code}
[~arpitagarwal]/others, please let me know your opinion on this., Hi Shashikant, I don't think we should change the default behavior of {{DFSOutputStream#hsync(void)}}. There is a {{DFSOutputStream#hsync(EnumSet<SyncFlag> syncFlags)}} overload that optionally takes sync flags. 

If the desired behavior is for {{Writer#hsync}} to update the length on the NameNode, then it should pass the UPDATE_LENGTH flag. i.e. make the change in SequenceFileWriter., [~arpitagarwal], SequenceFileWriter depends upon FSDataOutputStream object returned by FileSystem.create/append, which does not expose the hsync(EnumSet<SyncFlag> syncFlags). The DFSOutputStream gets wrapped into a FSDataOutputStream so it's not possible to fix in SequenceFile.

This bug makes it hard to implement producer / consumer using sequence files. We are a bit stuck on this. When would length get persisted, if hsync is never called with UPDATE_LENGTH? Is there like a periodic update of length or udpate when a block is full and written or only when close is called?, Hi [~harishjp], can you check whether the returned {{FSDataOutputStream}} is an instance of {{HdfsDataOutputStream}}. If so, then you can invoke _hsync(EnumSet<SyncFlag> syncFlags)_ on it. HdfsDataOutputStream is a public interface.

I don't usually like suggesting reflection, but in this case it may be the cleanest solution., I don't like that, HdfsDataOutputStream is in hdfs-client JAR; you can't loop in hadoop-common. 

In HADOOP-15229 we've discussed having an FS builder API to creating files; changing the hsync behaviour would be an option

, My mistake: the builder API is for creating files, its for opening on the todo list.

If HDFS added an option like "hdfs:update-length-on-hflush", it could be picked up and used by sequence file.

I'm a bit reluctant to go this way though, as there's a risk it gets used widely, and that may be bad for NN performance.

I've seen code in the timeline service which does this by remembering the last length of a file, then opening it, attempting to seek past, and, if it can do that, read in the new stuff. Ugly, but works today, bq. I don't like that, HdfsDataOutputStream is in hdfs-client JAR; you can't loop in hadoop-common.
[~stevel@apache.org], sorry I didn't get what you mean. The change I suggested doesn't need any jar dependency changes., Never mind, I think I understand what you mean now. There is no way to make this change without exposing update_length flag via FileSystem.]