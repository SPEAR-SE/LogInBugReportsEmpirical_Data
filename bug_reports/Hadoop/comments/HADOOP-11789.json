[[Jenkins|https://builds.apache.org/view/H-L/view/Hadoop/job/Hadoop-Common-2-Build/lastCompletedBuild/testReport/org.apache.hadoop.crypto/TestCryptoStreamsWithOpensslAesCtrCryptoCodec/org_apache_hadoop_crypto_TestCryptoStreamsWithOpensslAesCtrCryptoCodec/]

{code}
java.lang.NullPointerException: null
	at org.apache.hadoop.crypto.TestCryptoStreamsWithOpensslAesCtrCryptoCodec.init(TestCryptoStreamsWithOpensslAesCtrCryptoCodec.java:35)
{code}
, +1, I've seen this failure on our recently Windows run as well. , The failure is because openssl is not loaded or test is not run with -Pnative flag. Update the patch., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12709129/HADOOP-11789.001.patch
  against trunk revision bad070f.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6055//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6055//console

This message is automatically generated.,  The test is designed to catch cases where the openssl implementation is not loaded.  Perhaps we can avoid running the test when pnative is not set, but we should not pass the test when the openssl library can't be loaded., Colin, if {{-Pnative}} is set, but the os doesn't have a correct version of OpenSSL, then we should make the test failed? Could we test the crypto streams with OpensslAesCtrCryptoCodec only if correct Openssl is loaded? Otherwise people will still see the failure in the environment without correct OpenSSL., bq. Colin, if -Pnative is set, but the os doesn't have a correct version of OpenSSL, then we should make the test failed?

Yes.  Absolutely.

We've had some very subtle bugs earlier where we thought we were testing the openssl integration, but we actually were not. This is because there was a very subtle difference in the version of openssl installed on the jenkins machine and the one we needed.

I think the highest priority here is to make sure our Jenkins coverage doesn't regress again.  If people running tests locally want to skip the native tests, they can simply run the test suite without {{\-Pnative}}, or skip running the openssl test.

I think we should just close this as WONTFIX, what do you think?, Colin, I'm OK to close it as WONTFIX. 
[~steve_l] and [~xyao], do you have comments? If not, I will close it., I agree with Colin, this is very intentional behavior we introduced in HADOOP-11711. I'd also be amenable to a change that skips this if -Pnative is not specified, but the NPE on Jenkins needs to be fixed on the Jenkins side., Thanks Colin and Andrew for the comments, close it as WON'T FIX., If jenkins is failing with an NPE the
# jenkins needs to be fixed
# the message needs to be improved

Because at the very least we need a better message, i'm re-opening the JIRA, [~stevel@apache.org], good idea, we should have a better message, thanks.

Update the patch to give a better message.
, {quote}
but the NPE on Jenkins needs to be fixed on the Jenkins side.
{quote}
Sorry, I missed this comment from Andrew :)   The new patch addresses that, thanks., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12724221/HADOOP-11789.002.patch
  against trunk revision 6495940.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6086//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6086//console

This message is automatically generated., [~hitliuyi], the patch v2 looks good to me. I just have a few comments:
1. Is it possible to add additional check in the test for the specific openssl version or above that we want to test. for example, parse the 'openssl version -v' output.
{code}
$ openssl version -v
OpenSSL 0.9.8za 5 Jun 2014
{code}

2. Can you add an Assert.assertTrue(codec!=null, "codec instance should not be null!"); between the following two lines so that we will get meaningful failure message instead of NPE when codec.getClass() is called with a null instance.
 
{code}
codec = CryptoCodec.getInstance(conf);
Assert.assertEquals(OpensslAesCtrCryptoCodec.class.getCanonicalName(), 
        codec.getClass().getCanonicalName());
{code}, bq. 1. Xiaoyu Yao wrote: Is it possible to add additional check in the test for the specific openssl version or above that we want to test. for example, parse the 'openssl version -v' output.

Please, no.  Openssl versioning is a mess.  For example, Red Hat shipped a library labelled 1.0.0 that was actually version 1.0.1e in RHEL6.  With all the vendor patching that goes on, it's very difficult to say what the actual minimum version is for Hadoop, if it's even possible.  We already handle this correctly.  If the library is too old, the dlsym calls will fail and the user will get an informative message.  We will only get ourselves into trouble if we try to parse version IDs.  (Which aren't even always numeric for openssl, a WTF all its own.)

bq. 2. Can you add an Assert.assertTrue(codec!=null, "codec instance should not be null!"); between the following two lines so that we will get meaningful failure message instead of NPE when codec.getClass() is called with a null instance.

Good idea.  We should just use assertNotNull, though.

+1, I concur with the "avoid trying to be clever with openssl". There's windows to think about too.

regarding the code, any reason to go {{!"true".equalsIgnoreCase(System.getProperty("runningWithNative")}} instead of just {{Boolean.getBoolean()}}? If it's case-sensitivity, then it'll need to be a {{.toLower(LOCALE_EN).equals()}} for global reliability, I think the -Pnative is default one. Under Ubuntu also with openssl, I still get error:
{{
2015-05-12 12:10:33,662 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
}}, I think the -Pnative is default one. Under Ubuntu also with openssl, I still get error:
{{
2015-05-12 12:10:33,662 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
}}, I think the -Pnative is default one. Under Ubuntu also with openssl, I still get error:
{{
2015-05-12 12:10:33,662 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
}}, I think the -Pnative is default one. Under Ubuntu also with openssl, I still get error:
{{
2015-05-12 12:10:33,662 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
}}, I think the -Pnative is default one. Under Ubuntu also with openssl, I still get error:
{{
2015-05-12 12:10:33,662 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
}}, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HADOOP-11789 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12724221/HADOOP-11789.002.patch |
| JIRA Issue | HADOOP-11789 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9398/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]