[The changes in HDFS-6134 and HADOOP-10150 appear to have introduced this additional breakage for downstream users., Attached patch to CryptoUtils, [^0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch] for the 2.6.0-SNAPSHOT branch. (Bumps Guava dependency to version 14.0.1, which is the last version with both LimitInputStream and the alternative, in order to minimize impact with maximal benefit.), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667871/12667871_0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch
  against trunk revision 7d38ffc.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

      {color:red}-1 javac{color}.  The applied patch generated 1293 javac compiler warnings (more than the trunk's current 1264 warnings).

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//console

This message is automatically generated., Does this patch also remove the use of LimitInputStream in other parts of Hadoop? For example, in MiniDFSCluster?, version 2.5.1:

java.lang.NoClassDefFoundError: com/google/common/io/LimitInputStream
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at org.apache.hadoop.hdfs.server.namenode.FSImageFormat$LoaderDelegator.load(FSImageFormat.java:223)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:913)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:899)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:722)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:660)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:998)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:869)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:704)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:376)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:357)
	at de.mstier.hadoop.WordCountTest.setUp(WordCountTest.java:65)
, bq. Does this patch also remove the use of LimitInputStream in other parts of Hadoop? For example, in MiniDFSCluster?

No. See the referenced HDFS-7040. This only mitigates the new problem introduced in 2.6.0. HDFS-7040 addresses the issue introduced in 2.4.0, which is limited to MiniDFSCluster. This problem is worse, though, because it directly impacts many more users than the MiniDFSCluster one., Would this be more likely to be accepted for 2.6.0 if it were provided as a copied/re-implemented version of LimitInputStream instead of a dependency version change?, [~ctubbsii] - Apologies for the late response. Unfortunately, we can't change guava versions in 2.6 since it would be incompatible. , [~acmurthy]: I understand. What about my previous question, about whether a fix would be accepted if implemented as a copied/re-implemented version of LimitInputStream instead of a guava version change?, Yes, I'm cool with that. Tx!, Uploading a new patch ([^0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch]) which copies the HBase solution for the same issue. It also incidentally adds HDFS-7040, which is the other places where LimitInputStream is used (but only for version 2.6.0 and later)., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12680280/12680280_0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch
  against trunk revision 9a4e0d3.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5001//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5001//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12680280/12680280_0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch
  against trunk revision 6caa810.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5053//console

This message is automatically generated., FAILURE: Integrated in Hadoop-trunk-Commit #6493 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6493/])
HADOOP-11286. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java
* hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #738 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/738/])
HADOOP-11286. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java
* hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java
, I just committed this. Thanks [~ctubbsii]!, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1928 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1928/])
HADOOP-11286. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java
* hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1952 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1952/])
HADOOP-11286. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java
* hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java
* hadoop-common-project/hadoop-common/CHANGES.txt
]