[I think this is a valid concern. Most filesystems work poorly with thousands of files in a single directory. My recent tests on ext3 show that listing the data directory with 50,000 blocks takes several seconds.

FSDataset:80 contains a commented out section, which seems to address this issue. Anyone knows why it's not used?, Hi Andrzej,

I wrote this code and got it 90% working some time ago, but then had to abandon
it for a more important bug.  It is not ready to go in its current state, but shouldn't
be too hard.  I can bring this code back to life..

--Mike, That would be very useful. I've seen similar solutions in many places (e.g. squid, or Mozilla cache dir).

Currently, each time a block report is sent we need to list this huge dir. That's still ok, it's infrequent enough. However, each time we need to access a block, a correct file needs to be open. Inside the native code JVM uses an open(2) call, which causes the OS to perform a name-to-inode lookup. Even though OS is caching partial results of this lookup (in Linux this is known as dcache/dentries), still depending on the size of this LRU cache and the FS implementation details, doing real lookups for e.g. new blocks or newly requested blocks may take a long time.

Having said that, I'm not sure what would be the real performance benefit of this change, perhaps you could come up with a simpler test first...?, 
This fixes the multiple-directory storage problem.  It
lazily creates a single level of 512 subdirectories, into which
the blocks are allocated according to the lower 9 bits of the
block id.  If mankind ever needs more blocks than this, it is easy
to add an additional subdir layer and select on the lowest-but-9
bits of the blockid.

This change is backwards-compatible with the previous block
layout.  Old blocks in the single-layer dir will always be kept in
that format; we don't migrate them.  New blocks will always be added 
to the new hierarchy.

If both versions of the storage system are present, we always test
the new one first.  If that fails, we test the old one.  (The new test
should be faster, so we do it first.)

Please let me know if this patch works for you., +1
I didn't look at the patch, but I carefully read the commented out code. I vote yes. (is it already in? - close this issue)., This was done as part of HADOOP-64]