[I can see how that would really help, and what a pain it is to try to guess which stream we're dealing with.

Unfortunately, DecompressorStream doesn't have any way to know the name of the file or even if the InputStream is a file. If it is, it's more than likely to be buffered such that DecompressorStream never "sees" the actual FileInputStream. ...and even if he did have the FileInputStream I'm not aware of any way to retrieve the filename.

We could try to make each caller that creates a DecompressorStream from a file log debug information regarding which file is being used, but how would we correlate this message with a particular DecompressionStream?

The best solution I can think of - Perhaps creators of DecompressionStream's should catch EOFException and then print out detailed debug information., bq. The best solution I can think of - Perhaps creators of DecompressionStream's should catch EOFException and then print out detailed debug information.

I agree with this. IMO, this would be the right way to do it. What expects it, ought to log/print it properly.

Jeff/Tim - Any chances of a patch with the above approach? For the MR side though, I've added in MAPREDUCE-3678 to at least know what file you were dealing with., Harsh, I'm under some pretty Draconian schedule pressure right now. I did take a look at this none the less, and it doesn't look like a quick job. Some issues to consider:

 - Will all the codecs throw EOFException in this case, or will some throw IOException?
 - What if a decompressor gets a consistency check? Should it hit this same case? Certainly it should throw IOException rather than EOFException.
 - Clients include SequenceFile, TFile, offlineImageViewer, FSImageCompression, a few classes in mapred(uce), rumen, gridmix and various tests - no small patch.
 - Soon we should address compression stream usage in general to address reducing copies. Lots of places we buffer the stream when the CompressionInputStream is already buffering, resulting in still more copies. If we need to pick through these one by one, perhaps that would be a good time to touch up error handling as well?

Sorry to wimp out on you, but it seems like a little much right now., As the descriptions says, we need the file name in the exception printed.I think of a simple way to pass the filename to the constructor of the DecompressorStream. For this a new overloaded constructor is to be created. 
Then we can use the fileName in the exception message. As part of creating a new overloaded constructor, we would require to make a few changes also in some other files as well.

It worked for one of my implementations., I think I like thomastechs' idea. It has the advantage that it makes the codec figure out whether the problem is in the stream or not. It does mean patching every codec at once and then each client one by one. Really, in any scheme, we would need to be clear that the stream is the problem in any case, so touching the codecs seems unavoidable.

Are there issues for clients where they have problems knowing the stream source too? Does this ripple through a bunch of layers?, Thanks Tim for your comments. I am going ahead creating the patch for my suggestion.
, Please perform the code review, Created the patch based out of the latest code from git://git.apache.org/hadoop-common.git, This patch contains the fix as follows.As per the bug says, the EOFExceptions thrown in the DecompressorStream does not provide any information about the file at which the decompression fails. I have added overloaded constructor and necessary methods, which will have the file name also added as parameter. When the user uses this method and pass the filename, it would be printed in the EOF exception thrown, if any.So I believe the test cases may not be necessary. I was able to test it locally by forcefully creating an EOF Exception and verifying the new message as "java.io.EOFException: Unexpected end of input stream in the file = filename"
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12543497/HADOOP-8615.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 javac.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1397//console

This message is automatically generated., Please  do a code review , Hi, 
I have attached a new patch named:HADOOP-8615-release-0.20.2.patch
This is to be tested against only release 0.20.2, not in trunk.
The rest of the versions this may be incompatible., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545288/HADOOP-8615-release-0.20.2.patch
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1470//console

This message is automatically generated., The Hudson project again tests the patch against trunk.
Please let me know if there is any procedure for making this tested only on hadoop common
 release 0.20.2, Thomas,
Thank you for the patch!

bq. Please let me know if there is any procedure for making this tested only on hadoop common
release 0.20.2

Don't worry about the robots testing against the wrong branch, you're not doing anything wrong.

It seems to me this change would be a good thing on trunk as well. Can you port the patch to trunk?

bq. When the user uses this method and pass the filename, it would be printed in the EOF exception thrown, if any. So I believe the test cases may not be necessary. I was able to test it locally by forcefully creating an EOF Exception and verifying the new message as "java.io.EOFException: Unexpected end of input stream in the file = filename"

I think this should be fairly easy to test -- just write a compressed stream, truncate the compressed stream, then try to read it, catch the EOFException and verify that the filename shows up in the exception text.  Or am I missing something?

I'm a little worried about the places where your {{fileName}}-using methods add new default values, for example:
{code}
+  public CompressionInputStream createInputStream(InputStream in, 
+    Decompressor decompressor, String fileName) 
+  throws IOException {
+    return new DecompressorStream(in, decompressor, 
+               conf.getInt("io.file.buffer.size", 4*1024),fileName);
+  }
{code}
I'll have to think about it longer, but having a default value of 4k hidden in this method seems wrong to me at a first glance.  There are a few other instances of this as well., Thanks Andy for your valuable comments.
I will work on the patch in the trunk too.Also on the test case.
The methods having default values were already existing. I used the same methods and overloaded with an added parameter of fileName.This will not affect existing functionalities or the people who already used the existing methods without a fileName.The new methods with fileName , helps the user to use it, if the user faces the issue addressed in this bug.
Please let me know your comments., Cancelling PA status as there's some comments to address (and patch must target trunk).

You can look at http://wiki.apache.org/hadoop/QwertyManiac/BuildingHadoopTrunk for some easy commands to get trunk building., Given the target version as 2.0.0, latest patch for trunk, Please consider the HADOOP-8615 patch to be tested against the trunk., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12550195/HADOOP-8615.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1656//console

This message is automatically generated., Hi, 
Could anyone help me out, by reviewing what exactly is the reason for the build failure for my patch,named:
HADOOP-8615.patch
It is not producing any compile errors in my local.

Thanks, 
Thomas.
, With your patch I get the following compilation error:
{noformat}
[INFO] --- maven-compiler-plugin:2.5.1:testCompile (default-testCompile) @ hadoop-common ---
[INFO] Compiling 322 source files to /Users/suresh/Documents/workspace/hadoop.committer/hadoop-common-project/hadoop-common/target/test-classes
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /Users/suresh/Documents/workspace/hadoop.committer/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java:[32,17] org.apache.hadoop.io.compress.TestCodecFactory.BaseCodec is not abstract and does not override abstract method createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,java.lang.String) in org.apache.hadoop.io.compress.CompressionCodec
{noformat}, Thanks Suresh for taking a look. Your inputs helped me.
, Attaching the latest patch HADOOP-8615.Please review the same.This needs to be applied at the trunk, submitting the new patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12550994/HADOOP-8615.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1677//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/1677//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1677//console

This message is automatically generated., Thomas,

Thank you for working on this!  I've been annoyed by this unhelpful error message before.

The findbugs complaint seems legit:
{code}
Correctness Warnings
Code 	Warning
MF 	Field BlockDecompressorStream.fileName masks field in superclass org.apache.hadoop.io.compress.DecompressorStream
{code}
Please fix the coding style throughout the patch:
* you have leftover unused comments like ";//" at the end of lines
* always put a space after , in argument lists, for example {{decompress(buf,0,10);}} but there are many occurrences in the patch.
* in {{if}} tests, always put exactly space before ( and { and around operators.  For example {{if(null !=  this.fileName){ }} has one extra space after {{!=}} and is missing spaces before ( and {.
* properly indent continuation lines.  Use vim or emacs or eclipse for automatic indentation if necessary.
* exactly one space around {{else}}, you have }else{ in several places.
* in {{testBlockDecompress}} you want to {{fail("did not raise expected exception")}} after calling {{.decompress}}.
* please fill in javadoc {{\@param}} entries, or delete them.

The patch is looking good, almost all the above is just cosmetic.  Again, thanks for the code!, Thanks Andy for the comments.I have incorporated your comments and attaching a new patch.Please let me know any comments,, Attaching the patch named HADOOP-8615-ver2.patch, incorporating Andy's comments.Please review and let me know., New patch with the review comments, named HADOOP-8615-ver2.patch, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12551056/HADOOP-8615-ver2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1679//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1679//console

This message is automatically generated., Hi,
Please let me know for any feedback.
Requesting for further action.
Thanks, 
Thomas., bq. Please let me know for any feedback.

Sorry for the delay!

A few more whitespace fixups:
- make sure {{) throws}} has a space between the ) and "throws". (2 examples in this patch)
- still a few argument lists missing a space after "," for example {{return createInputStream(in, null,fileName);}}.
- also a few argument lists with extra spaces before "," for example {{Decompressor decompressor , String fileName}}
- extra space in {{protected  String fileName}}
- extra space in {{this.fileName =  fileName}}
- missing spaces in {{\+"file = "\+this.fileName}}, always put spaces on both sides of "\+" and other operators. also we generally put the "+" on the previous line for a string continuation like this one.
- missing space in {{if ((b1 | b2 | b3 | b4) < 0\)\{}} before "{"
- missing space in {{String fileName ="fileName";}} after "="

Thanks again for working on this enhancement!, Thanks Andy for the review. To incorporate these fixes, should I take the latest from the trunk again, since it is 1 week past now.? Or shall I edit these space fixes in the patch itself.? I am new to this JIRA process.So, please let me know any thoughts.
Thanks,
Thomas., bq. To incorporate these fixes, should I take the latest from the trunk again,

Good question.  Your patch will be applied against trunk when it's committed, so in some cases you will need to make changes to merge with trunk, and there's never a downside to refreshing your patch against trunk.

From the patch file formatting it looks like you're using svn, so you can probably just "svn up" and resolve any merge conflicts.  I use git, and use "git pull --rebase" to get a similar effect on my working branches., BTW, the wiki page http://wiki.apache.org/hadoop/HowToContribute is supposed to answer these questions, but it doesn't currently answer them very well I think.  If you're willing to contribute to the wiki, some improvements there would be helpful to everybody! :), Thanks Andy for the review. I am incorporating your review comments and attching the new patch., New patch incorporated with Andy's fix, Resolved coding standard issues mentioned in the Andy's review, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12552853/HADOOP-8615-ver3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1726//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1726//console

This message is automatically generated., Please let me know for any updates, The latest version of the patch looks great. +1., Hi, 
Please treat this as a gentle reminder on further procedures.
Thanks, 
Thomas., Hi,

I noted that this changes the CompressionCodec interface, which would make it an incompatible change for its users (as older code, downstream, would fail to compile as they now may be missing a few method implementations).

Is it absolutely necessary to break compatibility to have just some information over this exception?, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12552853/HADOOP-8615-ver3.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6267/console |


This message was automatically generated.]