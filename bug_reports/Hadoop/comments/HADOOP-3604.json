[
Those job completed after I failed those stuck reducers through web GUI.
, 
more info:

The jobs were all streaming jobs.
It seems to be reproducible.
Many copier threads were blocked at socket read:

Thread 6022: (state = BLOCKED)
 - java.net.SocketInputStream.socketRead0(java.io.FileDescriptor, byte[], int, int, int) @bci=0 (Interpreted frame)
 - java.net.SocketInputStream.read(byte[], int, int) @bci=84, line=129 (Interpreted frame)
 - java.io.BufferedInputStream.fill() @bci=175, line=218 (Interpreted frame)
 - java.io.BufferedInputStream.read1(byte[], int, int) @bci=44, line=258 (Interpreted frame)
 - java.io.BufferedInputStream.read(byte[], int, int) @bci=49, line=317 (Interpreted frame)
 - sun.net.www.http.HttpClient.parseHTTPHeader(sun.net.www.MessageHeader, sun.net.ProgressSource, sun.net.www.protocol.http.
HttpURLConnection) @bci=51, line=687 (Interpreted frame)
 - sun.net.www.http.HttpClient.parseHTTP(sun.net.www.MessageHeader, sun.net.ProgressSource, sun.net.www.protocol.http.HttpUR
LConnection) @bci=30, line=632 (Interpreted frame)
 - sun.net.www.protocol.http.HttpURLConnection.getInputStream() @bci=290, line=1000 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getInputStream(java.net.URLConnection, int, int) @bci=71
, line=1217 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceC
opier$MapOutputLocation, org.apache.hadoop.fs.Path) @bci=24, line=1067 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCop
ier$MapOutputLocation) @bci=181, line=976 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run() @bci=93, line=925 (Interpreted frame)


, Runping, did you see any timeouts? Or was that all of the reduce's logs?
I assume you are using the DefaultCodec.

I'm marking this as a blocker till we understand what is happening..., This patch fixes a potential problem in exception handling in ReduceTask.MapOutputCopier.getMapOutput, I'll test this further once I have access to a bigger cluster., Ok, this turned very murky indeed... 

Looks like lots of threads in JVM are hung in a call to Mutex::lock_without_safepoint_check; when I ran jstack over the hung reducer with

$ jstack -F -m <pid>

I saw:

{noformat}
----------------- 22175 -----------------
0xffffe410  ????????
0x00000002  ????????
0x064e5344  _ZN5Mutex28lock_without_safepoint_checkEv + 0x44
0x06557f57  _ZN20SafepointSynchronize5blockEP10JavaThread + 0xd7
0x064fc204  _ZN2os5sleepEP6Threadxb + 0x244
0x063d5d20  JVM_Sleep + 0x320
0xf4d863aa  * java.lang.Thread.sleep(long) bci:0 (Interpreted frame)
0xf4d7ef0d  * org.apache.hadoop.mapred.Task$1.run() bci:31 line:301 (Interpreted frame)
0xf4d7f3e9  * java.lang.Thread.run() bci:11 line:619 (Interpreted frame)
...
...


----------------- 22178 -----------------
0xffffe410  ????????
0x00000002  ????????
0x064e5344  _ZN5Mutex28lock_without_safepoint_checkEv + 0x44
0x06557f57  _ZN20SafepointSynchronize5blockEP10JavaThread + 0xd7
0x065b79f4  _ZN10JavaThread44check_safepoint_and_suspend_for_native_transEPS_ + 0x2b4
0x06398e9c  jni_SetByteArrayRegion + 0x7c
0xd034b55b  Java_java_net_SocketInputStream_socketRead0 + 0xfb
0xf4d863aa  * java.net.SocketInputStream.socketRead0(java.io.FileDescriptor, byte[], int, int, int) bci:0 (Interpreted frame)
0xf4d7ede9  * java.net.SocketInputStream.read(byte[], int, int) bci:84 line:129 (Interpreted frame)
0xf4d7ede9  * java.io.BufferedInputStream.fill() bci:175 line:218 (Interpreted frame)
0xf4d7ef0d  * java.io.BufferedInputStream.read1(byte[], int, int) bci:44 line:258 (Interpreted frame)
0xf4d7ede9  * java.io.BufferedInputStream.read(byte[], int, int) bci:49 line:317 (Interpreted frame)
0xf4d7ede9  * sun.net.www.http.HttpClient.parseHTTPHeader(sun.net.www.MessageHeader, sun.net.ProgressSource, sun.net.www.protocol.http.HttpURLConnection) bci:51 line:687 (Interpreted frame)
0xf4d7ece1  * sun.net.www.http.HttpClient.parseHTTP(sun.net.www.MessageHeader, sun.net.ProgressSource, sun.net.www.protocol.http.HttpURLConnection) bci:30 line:632 (Interpreted frame)
0xf4d7ece1  * sun.net.www.protocol.http.HttpURLConnection.getInputStream() bci:290 line:1000 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getInputStream(java.net.URLConnection, int, int) bci:71 line:1230 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation, org.apache.hadoop.fs.Path) bci:54 line:1068 (Interpreted frame)
...
...


----------------- 22182 -----------------
0xffffe410  ????????0x00000002  ????????
0x064e5344  _ZN5Mutex28lock_without_safepoint_checkEv + 0x440x06557f57  _ZN20SafepointSynchronize5blockEP10JavaThread + 0xd7
0x06594250  _ZN13ObjectMonitor5enterEP6Thread + 0x2a0
0x0659253a  _ZN18ObjectSynchronizer10slow_enterE6HandleP9BasicLockP6Thread + 0x6a
0x06365bde  _ZN18InterpreterRuntime12monitorenterEP10JavaThreadP15BasicObjectLock + 0x6e
0xf4d8f263  * org.apache.log4j.Category.callAppenders(org.apache.log4j.spi.LoggingEvent) bci:13 line:202 (Interpreted frame)
0xf4d7ef0d  * org.apache.log4j.Category.forcedLog(java.lang.String, org.apache.log4j.Priority, java.lang.Object, java.lang.Throwable) bci:14 line:388 (Interpreted frame)
0xf4d7ef0d  * org.apache.log4j.Category.log(java.lang.String, org.apache.log4j.Priority, java.lang.Object, java.lang.Throwable) bci:34 line:853 (Interpreted frame)
0xf4d7ef0d  * org.apache.commons.logging.impl.Log4JLogger.info(java.lang.Object) bci:21 line:133 (Interpreted frame)
0xf4d7f3e9  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation, org.apache.hadoop.fs.Path) bci:311 line:1114 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation) bci:181 line:976 (Interpreted frame)
...
...


----------------- 22185 -----------------
0xffffe410  ????????
0x00000002  ????????
0x064e5344  _ZN5Mutex28lock_without_safepoint_checkEv + 0x44
0x06557f57  _ZN20SafepointSynchronize5blockEP10JavaThread + 0xd7
0x063639cc  _ZN18InterpreterRuntime8newarrayEP10JavaThread9BasicTypei + 0xfc
0xf4d8eb97  * java.lang.AbstractStringBuilder.<init>(int) bci:6 line:45 (Interpreted frame)
0xf4d7ef0d  * java.lang.StringBuffer.<init>() bci:3 line:79 (Interpreted frame)
0xf4d7ef0d  * java.text.NumberFormat.format(long) bci:6 line:280 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.JobID.toStringWOPrefix() bci:30 line:107 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.TaskID.toStringWOPrefix() bci:13 line:135 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.TaskAttemptID.toStringWOPrefix() bci:13 line:124 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.TaskAttemptID.toString() bci:20 line:118 (Interpreted frame)
0xf4d7eda7  * java.lang.String.valueOf(java.lang.Object) bci:10 line:2827 (Interpreted frame)
0xf4d7eda7  * java.lang.StringBuilder.append(java.lang.Object) bci:2 line:115 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation, org.apache.hadoop.fs.Path) bci:372 line:1119 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation) bci:181 line:976 (Interpreted frame)
0xf4d7ee2b  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run() bci:93 line:925 (Interpreted frame)
...
...
{noformat}


Sigh! This could possibly mean that we are running into JVM bug - maybe I should upgrade to the latest, stable jvm and check.

Oh, the one other point to note is that the native codecs are compiled on a machine with 1.6.0 jvm and are run on nodes with 1.6.0_06..., I saw a couple of shuffle threads with:

{noformat}
----------------- 22176 -----------------0xffffe410  ????????
0x00000ffc  ????????
0x0639c149  jni_GetDirectBufferAddress + 0x79
0xcf9fdf90  Java_org_apache_hadoop_io_compress_lzo_LzoDecompressor_decompressBytesDirect + 0xd0
0xf4d863aa  * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompressBytesDirect(int) bci:0 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompress(byte[], int, int) bci:116 line:273 (Interpreted frame)
0xf4d7f2c5  * org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(byte[], int, int) bci:49 line:75 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.io.compress.DecompressorStream.read(byte[], int, int) bci:39 line:74 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation, org.apache.hadoop.fs.Path) bci:549 line:1141 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation) bci:181 line:976 (Interpreted frame)
0xf4d7ee2b  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run() bci:93 line:925 (Interpreted frame)
{noformat}, Complete output of "jstack -F -m" ...

Forgot to mention that the process does not respond to 'kill -3' at all., Some links to similar bugs wrt SafepointSynchronize::block -> Mutex::lock_without_safepoint_check:

http://bugs.sun.com/bugdatabase/view_bug.do;:WuuT?bug_id=4472904
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4639387
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4681171

and:

http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6601725
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6317397, A blog entry for a java process with similar characteristics i.e. hung jvm which doesn't respond to 'kill -3' etc. :
http://developers.sun.com/solaris/articles/debugjvm/, I'm hoping for some traction on http://forum.java.sun.com/thread.jspa?threadID=5308115 ..., The streaming tasks don't timeout since mapred.task.timeout is set to infinity..., > The streaming tasks don't timeout since mapred.task.timeout is set to infinity... 

That's a bug.  Fixing that should be the blocker, no?  We should not be forced to support such a configuration.

Arguably we should have two timeouts, one for user code and one for system code.  If user code hangs, and the user has set an infinite timeout, then the job will hang and that is not a bug.  But if system code hangs then the task would timeout no matter what the user timeout setting.  In general, however, that would be hard to implement, since user code can call system code and vice versa.  But in this particular case, during the shuffle, there's no user code running (except comparators when merging) so we could in theory somehow reset the task timeout during copies.  But even that may be difficult, if some threads are copying and some are merging.  Sigh.  I think we're better of just saying that setting an infinite timeout risks jobs hanging, that Hadoop cannot, e.g., guarantee that jvm's don't ever hang., 
It seems to me that there might be a lock contention condition in the jni code of the native compression library to access the direct buffers.
Once I limited the number of concurrent calls to the native decompression method to one by adding a lock around it, then the problem is gone.
{code}
--- src/core/org/apache/hadoop/io/compress/zlib/ZlibDecompressor.java   (revision 669236)
+++ src/core/org/apache/hadoop/io/compress/zlib/ZlibDecompressor.java   (working copy)
@@ -215,7 +215,9 @@
     uncompressedDirectBuf.limit(directBufferSize);
 
     // Decompress data
+    synchronized(ZlibDecompressor.class){
     n = inflateBytesDirect();
+    }
     uncompressedDirectBuf.limit(n);

--- src/core/org/apache/hadoop/io/compress/lzo/LzoDecompressor.java     (revision 669236)
+++ src/core/org/apache/hadoop/io/compress/lzo/LzoDecompressor.java     (working copy)
@@ -25,6 +25,7 @@
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.io.compress.Decompressor;
 import org.apache.hadoop.util.NativeCodeLoader;
 
 /**
@@ -270,7 +271,9 @@
     uncompressedDirectBuf.limit(directBufferSize);
 
     // Decompress data
+    synchronized(LzoDecompressor.class){
     n = decompressBytesDirect(strategy.getDecompressor());
+    }
     uncompressedDirectBuf.limit(n);

{code}
, Plausible patch which incorporates Runping's synchronization fix, we'll continue to test this., So it looks like a bug in the jvm causing a lock-up when 2 or more threads call 'JniEnv::GetDirectBufferAddress' to get the direct-buffer address in the JNI layer, especially when the first call is initializing the direct-buffer address... 

{noformat}
----------------- 22126 -----------------
22190 0xffffe410 ????????
0x00000002 ????????
0x064e5344 _ZN5Mutex28lock_without_safepoint_checkEv + 0x44
0x06557f57 _ZN20SafepointSynchronize5blockEP10JavaThread + 0xd7
0x0639bfd5 lookupDirectBufferClasses + 0x245
0x0639d5d2 _Z29initializeDirectBufferSupportP7JNIEnv_P10JavaThread + 0x192
0x0639c149 jni_GetDirectBufferAddress + 0x79
0xcf9fdf90 Java_org_apache_hadoop_io_compress_lzo_LzoDecompressor_decompressBytesDirect + 0xd0
0xf4d863aa * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompressBytesDirect(int) bci:0 (Interpreted frame)
0xf4d7ede9 * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompress(byte[], int, int) bci:116 line:273 (Interpreted frame)
0xf4d7f2c5 * org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(byte[], int, int) bci:49 line:75 (Interpreted frame)
0xf4d7ede9 * org.apache.hadoop.io.compress.DecompressorStream.read(byte[], int, int) bci:39 line:74 (Interpreted frame)
0xf4d7ede9 * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation, org.apache.hadoop.fs.Path) bci:549 line:1141 (Interpreted frame)
0xf4d7eda7 * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation) bci:181 line:976 (Interpreted frame)
0xf4d7ee2b * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run() bci:93 line:925 (Interpreted frame)

----------------- 22176 -----------------
0xffffe410  ????????
0x00000ffc  ????????
0x0639c149  jni_GetDirectBufferAddress + 0x79
0xcf9fdf90  Java_org_apache_hadoop_io_compress_lzo_LzoDecompressor_decompressBytesDirect + 0xd0
0xf4d863aa  * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompressBytesDirect(int) bci:0 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompress(byte[], int, int) bci:116 line:273 (Interpreted frame)
0xf4d7f2c5  * org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(byte[], int, int) bci:49 line:75 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.io.compress.DecompressorStream.read(byte[], int, int) bci:39 line:74 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation, org.apache.hadoop.fs.Path) bci:549 line:1141 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation) bci:181 line:976 (Interpreted frame)
0xf4d7ee2b  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run() bci:93 line:925 (Interpreted frame)

----------------- 22172 -----------------
0xffffe410  ????????
0x00000ffc  ????????
0x0639c149  jni_GetDirectBufferAddress + 0x79
0xcf9fdf90  Java_org_apache_hadoop_io_compress_lzo_LzoDecompressor_decompressBytesDirect + 0xd0
0xf4d863aa  * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompressBytesDirect(int) bci:0 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.io.compress.lzo.LzoDecompressor.decompress(byte[], int, int) bci:116 line:273 (Interpreted frame)
0xf4d7f2c5  * org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(byte[], int, int) bci:49 line:75 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.io.compress.DecompressorStream.read(byte[], int, int) bci:39 line:74 (Interpreted frame)
0xf4d7ede9  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation, org.apache.hadoop.fs.Path) bci:549 line:1141 (Interpreted frame)
0xf4d7eda7  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputLocation) bci:181 line:976 (Interpreted frame)
0xf4d7ee2b  * org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run() bci:93 line:925 (Interpreted frame)

{noformat}

We synchronized access to 'JniEnv::GetDirectBufferAddress'... voila!

Here is a patch which does fine-grained locking of just the call to JniEnv::GetDirectBufferAddress, it has minimal performance impact and we see a substantial improvement in GridMix with compression on for intermediate map-outputs and no more lockups, whee! *smile*

I'm hoping for a response from the post of the java forum..., Updated patch, gridmix works just fine! *smile*, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12384734/HADOOP-3604_2_20080625.patch
  against trunk revision 671563.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2742/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2742/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2742/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2742/console

This message is automatically generated., Some comments: 
1) In ReduceTask, shouldn't you call mapoutput.discard when there is an exception while reading/writing the map output.
2) Shouldn't the line {noformat} workmem = (*env)->GetDirectBufferAddress(env, working_memory_buf); {noformat} in LzoCompressor.java be within a LOCK & UNLOCK 
3) In the codec implementations, you lock on a per class level the call to GetDirectBufferAddress. I wonder whether it makes more sense to have all the calls to GetDirectBufferAddress synched on a single global lock. Wouldn't that be the safest thing to do (since we do use both the compression and decompression classes in the same JVM although maybe at different times always).
, Updated patch.

I don't think we need to bother about a global lock for now... so I haven't changed that.

We don't need to discard MapOutput for error during read since it hasn't been constructed yet., 
Agree.
I think this patch is ready for commit.
, Same patch, fixed some indentation issues., Although the MapOutput has not been created, we still need to delete the file on the localfs (when we shuffle the file directly to the disk). If you are convinced that the GetDirectBufferAddress calls don't require a global JVM lock, I am ok., My bad. I'll put the new patch after testing it..., Updated patch..., Hi arun, do you know whether this bug affects hadoop 0.15 as well? Thanks., Dhruba, this is a very different bug - looks like a bug in the jvm caused the child reduce's task's jvm to lockup - it wasn't responding to kill -3 too.

So, it could affect hadoop-0.15, but in a very different manner., sigh .. I still have one nit - in the methods shuffleToDisk and shuffleInMemory, there is some common code .. For readability/maintainability, could you pls move those out to independent methods. , I noticed that there are some differences in the code which i thought was duplicated in the methods... So +1 to the current patch, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12384999/HADOOP-3604_4_20080630.patch
  against trunk revision 673215.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2778/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2778/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2778/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2778/console

This message is automatically generated., I just committed this. Thanks, Arun, Integrated in Hadoop-trunk #536 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/536/])]