[
When HADOOP-940 is fixed, this issue becomes less critical.

Currently, DataNode picks a volume (disk) which satisfies 'volume.freespace >= blocksize()'. I think we can change that to two loops where first loop checks for 'volume.freespace >= 10*blockSize'. If no volume is found, next loop checks for 'freespace >= blocksize()'. This will reduce number of such exceptions. 10 might still be  too small.. may be 100?
, 
blockSize that datanode sees before writing is always 0. Will fix that.
, patch attached. Two fixes : 

DFSClient. : updates block size before sending to client.

DataNode : FSDataset : first looks for a volume with freespace larger than 10 times the block size.
                  (this is strictly not required but will handle almost full volumes better).
, > DataNode : FSDataset : first looks for a volume with freespace larger than 10 times the block size.
>                  (this is strictly not required but will handle almost full volumes better).

This is not required. Datanode already considers only 98% of total disk space (dfs.datanode.du.pct). Thanks Koji.

updated patch attached.

, +1, because http://issues.apache.org/jira/secure/attachment/12351200/HADOOP-990-2.patch applied and successfully tested against trunk revision r507276., > This is not required. Datanode already considers only 98% of total disk space (dfs.datanode.du.pct).

dfs.datanode.du.pct does not work as expected. Freespace is calculated as '0.98*disk_free_space'. I think it should be  'MAX(0.98*total_disk_space - disk_used, 0)', right?. I will add this to patch.
, finally I am able to write without errors to a datanode that has one of its volume filled.

three small fixes in 3.patch :
 
1) client should send block length to datanode
2) dfs.datanode.du.pct is used on properlry.
3) each volume has 'reserved' (initialized to dfs.datanode.du.reserved). But it was decremented with each block written. As a result volume's available space calculated never changed!

, +1. Code looks good.

One comment: I would rather dump a log message if the block returned from the namenode in locateFollowingBlock() returns anything other than 0.
, 
Thanks Dhruba.

Length of block is almost never enforced in DFS. I was thinking if I should add the 'if conidition' in DFSClient or not. But for now it is ok w.r.t our very loose enforcement of length. 
, I just committed this.  Thanks, Raghu!]