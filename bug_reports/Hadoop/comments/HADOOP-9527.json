[This test is exposing a Java 1.6 bug on Windows when trying to rename a symlink. Attached a minimal repro to demonstrate the JVM bug.

Here is the output on Windows using Java 1.7 and 1.6. 1.7 renames the symlink as expected, while 1.6 renames the target of the symlink.

{code}
C:\tmp\test>dir

 Directory of C:\tmp\test

05/02/2013  06:51 PM                 7 file.txt
05/02/2013  06:51 PM    <SYMLINK>      link1 [file.txt]

C:\tmp\test>c:\progra~1\java\jdk1.7.0_09\bin\java RenameLink link1 link2

C:\tmp\test>dir

 Directory of C:\tmp\test

05/02/2013  06:51 PM                 7 file.txt
05/02/2013  06:51 PM    <SYMLINK>      link2 [file.txt]

C:\tmp\test>c:\progra~1\java\jdk1.6.0_35\bin\java RenameLink link2 link3

C:\tmp\test>dir

 Directory of C:\tmp\test

05/02/2013  06:51 PM    <SYMLINK>      link2 [file.txt]
05/02/2013  06:51 PM                 7 link3

{code}

, Hi Arpit, the following Jira should help with the above JDK6 VS 7 problem you described: HADOOP-9061, Thanks for the pointer Ivan. I'll take a look., Fix symlink related tests on Windows. Multiple issues fixed here. 

# Hooked up readlink support added in winutils.
# Workaround Java6 symlink bug.
# Make sure relative symlinks are resolvable at creation time.
# Skipped tests verifying dangling symlink behavior.
# Fixed a few tests that did not need to create dangling links.
# Fixed a bad URI check.
# Few other path format changes., Cancelling patch. It seems that RawLocalFileStatus is still not working reliably on JDK6., Updated patch with another fix in RawLocalFileSystem#getFileLength., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12582186/HADOOP-9527.004.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2524//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2524//console

This message is automatically generated., I expect you don't need to add {{assumeTrue(!Shell.WINDOWS)}} to {{FileContextSymlinkBaseTest}} for the following methods: {{testCreateDanglingLink}}, {{testCreateFileViaDanglingLinkParent}}, {{testStatDanglingLink}}, {{testRecursiveLinks}}, and {{testRenameDirToDanglingSymlink}}.  These were addressed in HADOOP-9043 by overriding the methods in {{TestLocalFSFileContextSymlink}} and checking for Windows there.  It looks like I missed {{testRenameFileWithDestParentSymlink}} though, so thanks for picking that one up.  Could you please follow the same strategy of overriding it in {{TestLocalFSFileContextSymlink}}?

The reason for doing it this way is that by overriding it in the base class, we would skip the test even in the case of HDFS on Windows ({{TestFcHdfsSymlink}}).  It's only the combination of Windows and local file system that doesn't support dangling symlinks, so by overriding it in the subclass, we only skip the test in that very specific case.

{code}
+   * Returns the target of the given symlink. Returns the empty string if
+   * the given path does not refer to a symlink or there is an error
+   * acessing the symlink.
{code}
Minor nit: misspelling of accessing.

{code}
    RawLocalFileStatus(File f, long defaultBlockSize, FileSystem fs) {
      super(
          RawLocalFileSystem.getFileLength(f),
          f.isDirectory(),
          1,
          defaultBlockSize,
          f.lastModified(),
          0,
          null,
          null,
          null,
          null,
          new Path(f.getPath()).makeQualified(fs.getUri(),
            fs.getWorkingDirectory()));
    }
{code}

Was this change intended only for formatting, or was it intentional to switch to calling a different superclass constructor?  I think we could potentially remove the arguments 0, null, null, null, null, because even if you omit them, the base class constructors will chain to do the same thing.
, Thanks for the feedback. I have addressed it.

{quote}
Was this change intended only for formatting, or was it intentional to switch to calling a different superclass constructor? I think we could potentially remove the arguments 0, null, null, null, null, because even if you omit them, the base class constructors will chain to do the same thing.
{quote}
The FileStatus forwarding constructor has a comment indicating it needs to be deprecated.

There is a bug with RawLocalFileStatus (also on Linux) since it passes null for the symlink parameter even when the File might be a symlink. It should be addressed at some point in a separate Jira. I am fine with reverting the constructor change until then. Let me know what you think., Fixing a copy-paste error Chris just pointed out., Thanks Arpit for the patch here! Interesting approach overall. Please give me some time to think about this and review the patch. , {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12582323/HADOOP-9527.005.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2526//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2526//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12582329/HADOOP-9527.006.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2527//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2527//console

This message is automatically generated., +1 for the patch, pending review from Ivan too.  Thanks for correcting the misspelling (which was in the original code before the patch).  I didn't realize that constructor was deprecated, so please disregard my comment about that.  I verified that {{TestLocalFSFileContextSymlink}} and {{TestFcHdfsSymlink}} both pass on Mac and Windows.  It sure is exciting to see these tests pass after so long!, Thanks for the detailed review as always Chris!

Ivan - please let me know your concerns. It would be good to move forward while the context is still fresh., Sorry, Arpit.  I just thought of a potential issue.  {{RawLocalFileSystem}} is documented as {{@InterfaceAudience.Public}} and {{@InterfaceStability.Stable}}.  I wonder if it's best that we don't add the public static {{readLink}} methods here and inadvertently advertise them as something that any client can depend on.  Perhaps {{FileUtil}} is more appropriate, which is {{@InterfaceAudience.Public}} and {{@InterfaceStability.Evolving}}?  This would have nice symmetry with {{FileUtil#symLink}} too and centralize the Windows special-case logic for symlinks.

Let me know your thoughts on this., Good point and that came to my mind too.

https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/classification/InterfaceStability.Stable.html
{quote} Can evolve while retaining compatibility for minor release boundaries.; can break compatibility only at major release (ie. at m.0). {quote}

It doesn't sound like adding a new public method violates the contract. However if there is lack of clarity it would be fairly easy to move it to FileUtil.

Thanks., It's definitely not backwards-incompatible to add these new methods right now, but I'm wondering if we want to commit to maintaining that backwards-compatibility guarantee for these new methods in the future.  I defer to the opinion of a committer on this one.  If a committer asks, we can easily move those methods over to {{FileUtil}}., Chris, I've moved over the new methods to FileUtil to keep things simple.

Thanks!, Sounds good.  Thank you!, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12582351/HADOOP-9527.007.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2528//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2528//console

This message is automatically generated., Thanks Arpit for the patch and the patience! Sorry for not reviewing this earlier, I was not near my computer for a week.

1. Interestingly, you are going the similar route I initially took in branch-1-win :) (see HADOOP-8872) Unfortunately, I don't think this will work in all cases. See my comments from HADOOP-9061 for the reasons why. Quoting the branch-1-win approach below:
{quote}
 - If on Java6, do file copy instead of symlink. We've seen many problems with symlinks on files on Java6 and it is simply impossible to make all of them work. Recent examples include apps (like Oozie) built on top of MR that directly access symlinks using the Java File object (not thru RLFS), in which case things just don’t work.
 - If on Java7, symlinks work as expected.
{quote}
It took a few iterations to get symlink behavior to work properly across the Hadoop ecosystem with JDK6 on Windows, hence I’d stick with the approach. 

The downside would be that the readlink functionality would not work with the LFS on JDK6. Not sure if there are legit Hadoop scenarios that rely on this functionality, (I don’t know of any other than in tests). If not, I would be fine with just throwing the NOT_IMPL exception if readLink is invoked on JDK6 on Windows. Things are moving toward JDK7, so I don’t see this a big gap.

I am interested in hearing your thoughts on this direction.

2. FileUtil#readLink: My preference would be to expose a single {{File readLink(File)}} public API instead of FileUtil APIs that accept Paths or Strings. This makes the contract explicit such that the input path must be a valid cross-platform local file system path.

3. RawLocalFs#createSymlink: IMO this method should delegate to FileUtil#symlink(). Currently we have two inconsistent implementation for symlinks in FileUtil and RawLocalFs. 

, Ivan, thanks for reviewing and posting your feedback.

I think your suggestion is reasonable but I need to understand it better., Also seeing this failure in branch-2 on Windows., New patch. This is actually a simpler approach more in line with branch-1.

I tested with JDK6 and JDK7 on Windows, and JDK6 on OS X.

{quote}
2. FileUtil#readLink: My preference would be to expose a single File readLink(File) public API instead of FileUtil APIs that accept Paths or Strings. This makes the contract explicit such that the input path must be a valid cross-platform local file system path.
{quote}
Ivan, I've not addressed this. Other methods in FileUtil take String/Path and it complicates the calling code a bit.

Let me know what you think.

Arpit, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12586446/HADOOP-9527.008.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2606//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2606//console

This message is automatically generated., Ivan can you please review this and commit it to trunk and branch-2 when you get a chance., Thanks Arpit for the new patch! Will try to review tonight., bq. Ivan can you please review this and commit it to trunk and branch-2 when you get a chance.
Sure, will try to get this done tonight., Latest patch looks much better Arpit. Thanks for addressing the comments.

I still want to reiterate on above comment #2 and have one additional question:
 - We have already seen that miss use of Paths or Strings can cause problems because of different path semantics (for example, API consumers passing paths with forward slashes on Windows). File object makes it explicit that a local file system path is required. Let's please add a single public API {{String FileUtil.readLink(File)}} and work based off of that.
 - FileUtil.java: I am not able to understand this part
{code}
        // Relative links on Windows must be resolvable at the time of
        // creation. To ensure this we run the shell command in the directory
        // of the link.
{code}
Why would a parent directory of a link be the appropriate working directory?, Ivan, we use the parent directory of the symlink since the link needs to be resolvable at creation. Running the symlink command from the test's 'current directory' will not work.

Attached patch to fix the readLink signature.

Thanks for reviewing., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12587300/HADOOP-9527.009.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2634//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2634//console

This message is automatically generated., Thanks Arpit. This is almost good to go. Have two more minor comments, once you address those I am +1

 - RawLocalFs#createSymlink: Can you please include the exitCode in the exception message? 
 - RawLocalFs#createSymlink: Why do you need to catch IllegalArgumentException. This seems incorrect. Let’s please remove this catch block and address the underlying problem. Btw, you should be able to remove both catch blocks from RawLocalFs#createSymlink and just leave a throw if exitCode != 0. Right?

Big thanks again for taking time to thoroughly address this tricky Windows symlink problem! 
, Rollup fixes for TestSymlinkLocalFsFileSystem also into the same patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595515/HADOOP-9527.010.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestHDFSFileSystemContract

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2908//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2908//console

This message is automatically generated., The test failure looks unrelated to my patch. The exception indicates a NameNode bug.

{code}
java.util.ConcurrentModificationException
	at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
	at java.util.HashMap$EntryIterator.next(HashMap.java:834)
	at java.util.HashMap$EntryIterator.next(HashMap.java:832)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.shutdown(FsVolumeImpl.java:214)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.shutdown(FsVolumeList.java:215)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:1265)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:1293)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:1439)
{code}, Thanks Arpit for addressing the latest comments.

I re-reviewed the patch and it looks good. Had some minor comments (see below) which I went ahead and addressed in the v11 version of the patch. At this point I am +1 on the latest patch (if you’re fine with my modifications). I’ll give the latest patch a day before I commit, in case Chris or Chuan have something to add.

Comments addressed in v11:
 - We should reconcile FileUtil#getPathWithoutSchemeAndAuthority() with the new Path#getPathWithoutSchemeAndAuthority API recently added
 - RawLocalFileSystem#readLink is not used anymore and should be deleted
 - Let’s not modify TestSymlinkHdfs, instead we can leave the base implementation and just override as needed (otherwise, we’d have to split this in a separate HDFS jira)
 - IMO, it is better to leave TestSymlinkLocalFsFileSystem#testRenameSymlinkToItself to fail on Windows then to add a TODO in code. You have a tracking Jira what will suffice. 
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12596162/HADOOP-9527.011.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2922//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2922//console

This message is automatically generated., Hi Ivan,

Thanks for reviewing and your effort with the v11 patch. It is much appreciated.

As the test failure shows with your patch shows, this is kind of tricky to get right with multiple JDK+OS combinations that need to be verified.

The v10 patch is fixing a huge number of test cases (over 100) and moving the state of the Windows build forward quite significantly.

We have been spinning on this for quite some time. If there are no serious objections to the patch, can we get that in and handle the cleanup separately?
, I'm +1 for committing the v10 patch and submitting subsequent jiras to address any lingering clean-up activities, which appear to be minor at this point.

Regarding letting the test fail, I agree with the concept in general as a dev process.  Unfortunately, I don't think it interacts well with the established Apache patch workflow.  If we committed v11, then Jenkins would -1 every patch, and it could mask new failures introduced in later file system patches.  (Arpit stated earlier that it's not a Windows-specific problem.  It happens on Linux too.)  There are other examples in the code of leaving a TODO and mentioning a jira, so this appears to be acceptable if used in moderation.
, Sorry folks, I thought that the todo (HADOOP-9819) tracks the failure that is specific to Windows. I agree, no need to increase the scope of this Jira to fix HADOOP-9819. I attached v12 version of the patch that reverts back this part of the behavior from v10. Assuming that Jenkins comes back with +1 we can go ahead and commit the latest patch (since we did all the work already). If not, I agree, let's proceed with v10 and address the rest of the changes separately.

bq. As the test failure shows with your patch shows, this is kind of tricky to get right with multiple JDK+OS combinations that need to be verified
Yep, I did the testing with both JDK7 and JDK6., Thanks, Ivan.  I'd also be +1 for v12 if Jenkins passes it., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12596278/HADOOP-9527.012.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2930//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2930//console

This message is automatically generated., +1 if this runs clean on Windows with both JDK6 and JDK7., Thanks, Arpit and Ivan!  I plan to commit v12 later today.  I see a prior comment from Ivan stating that he tested using both JDK7 and JDK6., SUCCESS: Integrated in Hadoop-trunk-Commit #4222 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4222/])
HADOOP-9527. Add symlink support to LocalFileSystem on Windows. Contributed by Arpit Agarwal. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1511118)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Shell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSTestWrapper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFS.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileSystem.java
, I've committed this to trunk and branch-2.  I didn't commit to branch-2.1-beta, because the code is slightly different there, and this patch did not apply.  Based on that, I'm dropping 2.1.1-beta from the fix version and leaving it at 2.3.0.

Big thanks to Arpit for sticking through this tricky issue and incorporating the code review feedback.  Also thanks to Ivan for code reviews., Thanks Chris for the commit, and indeed, big thanks Arpit for jumping thru all the hoops to get issue fixed!, SUCCESS: Integrated in Hadoop-Yarn-trunk #294 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/294/])
HADOOP-9527. Add symlink support to LocalFileSystem on Windows. Contributed by Arpit Agarwal. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1511118)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Shell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSTestWrapper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFS.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileSystem.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1484 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1484/])
HADOOP-9527. Add symlink support to LocalFileSystem on Windows. Contributed by Arpit Agarwal. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1511118)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Shell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSTestWrapper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFS.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileSystem.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1511 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1511/])
HADOOP-9527. Add symlink support to LocalFileSystem on Windows. Contributed by Arpit Agarwal. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1511118)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Shell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSTestWrapper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFS.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestSymlinkLocalFSFileSystem.java
, Reopening the issue to commit to branch-2.1. Some refactoring from HADOOP-9355 did not make it to branch-2.1-beta. I will provide a rebased patch soon., v10 patch rebased to branch-2.1-beta. I verified this on OS X (JDK6) and Windows (JDK6+JDK7).
, v12 patch rebased to branch-2.1-beta. Missing changes to RawLocalFileSystem.java and TestSymlinkLoalFSFileSystem.java since we don't have HADOOP-9417.

[~cnauroth] This is the same patch you +1'ed earlier minus changes to those two files., +1 for the branch-2.1-beta patch.  Thanks again, Arpit!, Thanks Chris! I have committed this to branch-2.1-beta.]