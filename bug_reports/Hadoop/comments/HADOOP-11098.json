[Knowing the GUI is served from JMX, I looked into JMX and found this:
{code}
  {
  "beans" : [ {
    ...
    "MemNonHeapMaxM" : -9.536743E-7,
    ...
  },
{code}

which is getting set here:

{code:title=hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java}
  private void getMemoryUsage(MetricsRecordBuilder rb) {
    MemoryUsage memNonHeap = memoryMXBean.getNonHeapMemoryUsage();
    MemoryUsage memHeap = memoryMXBean.getHeapMemoryUsage();
    Runtime runtime = Runtime.getRuntime();
    rb.addGauge(MemNonHeapUsedM, memNonHeap.getUsed() / M)
      .addGauge(MemNonHeapCommittedM, memNonHeap.getCommitted() / M)
      .addGauge(MemNonHeapMaxM, memNonHeap.getMax() / M)
      .addGauge(MemHeapUsedM, memHeap.getUsed() / M)
      .addGauge(MemHeapCommittedM, memHeap.getCommitted() / M)
      .addGauge(MemHeapMaxM, memHeap.getMax() / M)
      .addGauge(MemMaxM, runtime.maxMemory() / M);
  }
{code}

According to [this | http://docs.oracle.com/javase/8/docs/api/java/lang/management/MemoryUsage.html#getMax--], getMax() returns -1 if the max is unlimited.
{quote}
public long getMax()
Returns the maximum amount of memory in bytes that can be used for memory management. This method returns -1 if the maximum memory size is undefined.
{quote}
And according to [this | http://docs.oracle.com/cd/E15289_01/doc.40/e15062/optionxx.htm#BABGCFFB], you set the non-heap max with {{-XX:MaxDirectMemorySize}}, but it claims it's unlimited by default.
{quote}
Default Value
The default value is zero, which means the maximum direct memory is unbounded.
{quote}
This is obviously the case in JDK8, but I haven't been able to find any references to the default changing between JDK7 and JDK8 yet., bq. And according to this , you set the non-heap max with -XX:MaxDirectMemorySize, but it claims it's unlimited by default.

According to the link, MaxDirectMemorySize sets the NIO buffer size. I wouldn't expect that to be the same thing as the non-heap max. , bq. According to the link, MaxDirectMemorySize sets the NIO buffer size. I wouldn't expect that to be the same thing as the non-heap max.

Yeah after reading more it looks like that's definitely the case, I don't remember what I initially read that lead me to believe that, it's been a while since I actually looked at this (this ticket is a copy of an internal ticket).

It looks like this is probably related to "PermGen" going away and now having "Metaspace", which is part of the heap now where PermGen was not (more [here | http://javaeesupportpatterns.blogspot.com/2013/02/java-8-from-permgen-to-metaspace.html]).  Anyways, I haven't actually found a way to cap non-heap yet and I'm not sure it's actually even necessary anymore?, The problem can be easily reproduced by running the following code in Java 7 and Java 8 respectively.
{code}
  public static void main(String[] args) {
    final String p = "java.version";
    System.out.println(p + " = " + System.getProperty(p));
        
    MemoryMXBean b = ManagementFactory.getMemoryMXBean();
    MemoryUsage memNonHeap = b.getNonHeapMemoryUsage();
    System.out.println("max = " + memNonHeap.getMax());
  }
{code}
- java 7
{code}
java.version = 1.7.0_60
max = 136314880
{code}
- java 8
{code}
java.version = 1.8.0_60
max = -1
{code}
, It looks like that this problem is closely related to the new Java 8 Metaspace.  By default the metaspace, which is a part of the non-heap memory, is unbounded.  As a result, the non-heap memory is unbounded, i.e. memNonHeap.getMax() returns -1 in the code above.  If we set a limit to the MaxMetaspaceSize, the non-heap memory becomes bounded; see output below

- java 8  with -XX:MaxMetaspaceSize=128M
{code}
java.version = 1.8.0_60
max = 1459617792
{code}
, [~szetszwo] thank you for taking a look at this issue. How about treating "-1" as a special value in the case on JDK8?, Sound good.  Let's show <unbounded> in the NameNode UI., bq. Let's show <unbounded> in the NameNode UI.
Sounds good for NameNode UI. By the way, how about JvmMetrics?
{code}
.addGauge(MemNonHeapMaxM, memNonHeap.getMax() / M)
{code}
If memNonHeap.getMax() is -1, can we set some other value such as 0 or remove the metric instead of displaying -9.536743E-7?, [~ajisakaa] good point. Zero or LONG_MAX looks fine to me. Let me implement this feature., I think LONG_MAX is more precise expression in the JVM's case., Either LONG_MAX or -1 is fine.  Thanks., On a second thought, Long.MAX_VALUE = 9223372036854775807 has too many digits.  It may lead to a display problem.  Also, other applications cannot easily tell whether it means unbounded or it is a valid setting.  They cannot show it as <unbounded> in their UI. So -1 may be better., bq. So -1 may be better.
+1, Attaching a screenshot after fixing., Attaching a patch., +1 patch looks good., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  19m 19s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:red}-1{color} | tests included |   0m  0s | The patch doesn't appear to include any new or modified tests.  Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. |
| {color:green}+1{color} | javac |   7m 44s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  10m  7s | There were no new javadoc warning messages. |
| {color:red}-1{color} | release audit |   0m 15s | The applied patch generated 1 release audit warnings. |
| {color:red}-1{color} | checkstyle |   1m 44s | The applied patch generated  5 new checkstyle issues (total was 19, now 24). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 28s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   4m 17s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:red}-1{color} | common tests |   7m 31s | Tests failed in hadoop-common. |
| {color:red}-1{color} | hdfs tests | 200m 11s | Tests failed in hadoop-hdfs. |
| | | 253m 52s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.hdfs.web.TestWebHdfsContentLength |
|   | hadoop.hdfs.web.TestWebHDFSOAuth2 |
|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |
|   | hadoop.hdfs.TestCrcCorruption |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12764941/HADOOP-11098.001.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 3b85bd7 |
| Release Audit | https://builds.apache.org/job/PreCommit-HADOOP-Build/7765/artifact/patchprocess/patchReleaseAuditProblems.txt |
| checkstyle |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7765/artifact/patchprocess/diffcheckstylehadoop-common.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7765/artifact/patchprocess/testrun_hadoop-common.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7765/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7765/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7765/console |


This message was automatically generated., All tests are not related to the patch.

Following tests are fails without patch - created HDFS-9195 and HDFS-9196 for addressing the problem:
{quote}
  TestDelegationTokenForProxyUser.testWebHdfsDoAs:163 expected:<...ocalhost:44528/user/[Proxy]User> but was:<...ocalhost:44528/user/[Real]User>
  TestWebHdfsContentLength.testPutOp:116 expected:<0> but was:<null>
  TestWebHdfsContentLength.testPutOpWithRedirect:130 expected:<[chunked]> but was:<[0]>
{quote}

The failures of TestCrcCorruption and TestGangliaMetrics are occasional one - ran all tests locally and confirmed that they passes. 

Thanks for the review, committing this shortly., Committed this to trunk and branch-2. Thanks [~szetszwo] for your review, [~ajisakaa] and [~aw] for your comment,  and [~tthompso] for your report., FAILURE: Integrated in Hadoop-trunk-Commit #8565 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8565/])
HADOOP-11098. [JDK8] Max Non Heap Memory default changed between JDK7 (ozawa: rev 30e2f836a26490a24c7ddea754dd19f95b24bbc8)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/dfshealth.html
* hadoop-common-project/hadoop-common/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #486 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/486/])
HADOOP-11098. [JDK8] Max Non Heap Memory default changed between JDK7 (ozawa: rev 30e2f836a26490a24c7ddea754dd19f95b24bbc8)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/dfshealth.html
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk #1217 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/1217/])
HADOOP-11098. [JDK8] Max Non Heap Memory default changed between JDK7 (ozawa: rev 30e2f836a26490a24c7ddea754dd19f95b24bbc8)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/dfshealth.html
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #2422 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2422/])
HADOOP-11098. [JDK8] Max Non Heap Memory default changed between JDK7 (ozawa: rev 30e2f836a26490a24c7ddea754dd19f95b24bbc8)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/dfshealth.html
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #478 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/478/])
HADOOP-11098. [JDK8] Max Non Heap Memory default changed between JDK7 (ozawa: rev 30e2f836a26490a24c7ddea754dd19f95b24bbc8)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/dfshealth.html
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk #2393 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2393/])
HADOOP-11098. [JDK8] Max Non Heap Memory default changed between JDK7 (ozawa: rev 30e2f836a26490a24c7ddea754dd19f95b24bbc8)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/dfshealth.html
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #453 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/453/])
HADOOP-11098. [JDK8] Max Non Heap Memory default changed between JDK7 (ozawa: rev 30e2f836a26490a24c7ddea754dd19f95b24bbc8)
* hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/dfshealth.html
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/source/JvmMetrics.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
]