[It may be unrelated, but do you have a speculative execution turned on?
, As a matter of fact, speculative execution was enabled before launching distcp. On the other hand, the actual job configuration had
mapred.map.tasks.speculative.execution=false,
i.e. distcp must turn it off before submiting the job., I think it is a good idea to verify file sizes after copying.

We probably should provide some way to verify the file content.  Computing a message digest of the entire file seems not practical.  Instead, we could compute message digests over the crc checksums.  It will be much more efficient since the crc checksums are relatively small., Verifying file sizes could have some implication when we support "appends". In that case, the source file could be appended to before the file-size check occurs. This is true for any kind of crc checking of the contents too., Verifying lengths is cheap and would catch many problems.  It could be done by the reducer, and the output could list any discrepancies.  Checking CRC's is more expensive and should be optional if implemented.

> Verifying file sizes could have some implication when we support "appends".

That's true, so we shouldn't have a discrepancy fail the job, but it should still be logged so that the user can see which files were modified after they were copied., > Verifying file sizes could have some implication when we support "appends".
Also, in this case the file time changes -- further, if the destination filesize is suspect (a multiple of blocksize inclueing 0) it would not hurt to copy such a file again (e.g. n the reducer), > it would not hurt to copy such a file again (e.g. n the reducer)

If a process is continually updating the source then such copying will never complete.

Perhaps we should have a distcp 'sync' mode where it first checks if each source and target have the same length and/or date and skips copying when they do.  Then one could choose to repeat distcp until it completes with no discrepancies.  Such looping could be built into the client., Maybe this is related to HADOOP-2891 when the dfsclient gets closed before the file is closed. In this case, the client used to call abandonFileInprogress. This code has been removed in 0.17 and later releases., My guess is that the file was read successfully from the source cluster but failed to write to the destination cluster.  And then the file/lease was deleted silently due to HADOOP-2891.

distcp currently check whether the number of bytes processed in the mapper is equal to the source size.  I will add some codes to check whether the destination size is equal to the source size., 3294_20080423.patch: check whether dst size == src size after copy and rename., 3294_20080423b.patch: throw IOException instead of logging., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12380810/3294_20080423b.patch
against trunk revision 645773.

    @author +1.  The patch does not contain any @author tags.

    tests included -1.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2315/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2315/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2315/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2315/console

This message is automatically generated., +1 This looks fine to me.  If a copy fails, then its map fails and it will be retried.  If another process is updating files while distcp is running, then the distcp job may fail.  Someday we may want to permit jobs to proceed even when individual copies fail due to updates (perhaps useful for, e.g., backing up a live filesystem) but that would be a new feature., bq. Perhaps we should have a distcp 'sync' mode where it first checks if each source and target have the same length and/or date and skips copying when they do.

This is already in distcp as \-update. Its semantics are a little odd- it assumes that the src tree matches the destination rather than the usual cp semantics- but it overwrites the destination file iff its size is different than the source file.

+1, I just committed this. Thanks, Nicholas, bq. As a matter of fact, speculative execution was enabled before launching distcp

Running distcp with speculative execution turned on is definitely not supported. It disables it before starting the job, but if it's somehow turned on during the copy, then its behavior- particularly with \-update or \-override- is undefined., distcp turns speculative execution off  before launching the map-reduce job -- how would you imagine to get it turned on again during the copy?, Integrated in Hadoop-trunk #470 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/470/]), If it were specified as a final param, then it could be turned on during the job., 3294_20080423b_0.16.patch: for 0.16, I committed this to 0.16.4. Thanks Nicholas.]