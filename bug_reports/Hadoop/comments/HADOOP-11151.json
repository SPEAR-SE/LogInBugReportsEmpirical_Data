[I think this is possibly related to HADOOP-11113, since it might be that the auth cookie expires after some time and then can't be refreshed.

[~zb161], maybe you could try out the patch there? If it doesn't work, we can keep hunting for the fix., Andrew, I think the environment here is for simple authentication, and the exception is because there is no auth parameter (user.name) when doing init request. 
Can you resolve it in HADOOP-11113 too? And also resolve the {{TestEncryptionZonesWithKMS}} issue recently in Jenkins report together.
Of course, if you want to resolve them separately using this JIRA, you can take this JIRA or I can do it :) , Hey Yi, I think the {{TestEncryptionZonesWithKMS}} issue is due to BUILDS-17. I guess we could make efforts to reduce the # of fds needed for each of these tests, but better would be to fix the build environment. The build team has been unsuccessful thus far though., Right, thanks Andrew., Uploading initial patch

[~hitliuyi], [~andrew.wang],
So HADOOP-11113 handles this for simple authentication. But it does not automatically retry the request. This patch adds automatic retry incase of authentication errors caused due to stale authToken, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672243/HADOOP-11151.1.patch
  against trunk revision 17d1202.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.crypto.random.TestOsSecureRandom
                  org.apache.hadoop.crypto.key.kms.server.TestKMS

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4842//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4842//console

This message is automatically generated., Fixing test case.., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672302/HADOOP-11151.2.patch
  against trunk revision 17d1202.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.crypto.random.TestOsSecureRandom
                  org.apache.hadoop.ha.TestZKFailoverControllerStress

                                      The test build failed in hadoop-common-project/hadoop-kms 

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4845//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4845//console

This message is automatically generated., The test failures are un-related, Cool patch, logic makes sense. Couple small comments though:

* Could we avoid doing getConf().getInt on each call? The Configuration hash lookup isn't free.
* Is there a reason why doing more than one retry would fix the issue? Seems if we get the same error even after one retry, then something else is wrong., Uploading updated patch addressing feedback suggestions

Thanks for the review [~andrew.wang]
agreed.. we don't really need to do more than 1 retry.. but thought it safer to just keep it configurable.. i've changed default to 1, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672444/HADOOP-11151.3.patch
  against trunk revision 52bbe0f.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.crypto.key.kms.server.TestKMS

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4848//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/4848//artifact/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4848//console

This message is automatically generated., Hi Arun, thanks for revving. Few more comments:

- Nit: can make authRetry final
- Could you comment on why authToken needs to be volatile?
- In the new if statement, I don't follow a few things. Why is the special case we need to handle a "success" error code rather than an error one? Also, we don't need to do another retry in this case? The operation succeeded even though we need to refresh the authToken?, I also ran apache-rat:check successfully with this patch applied, so not sure what's up with that., [~andrew.wang], thanks for the followup review

So, about the volatile authToken, the KMSClientProvider also starts background threads to fill the encryptedKeyCache when it goes below threshold, which is an HTTP call to the server using the authToken, so if in case the authToken gets flushed, I wanted to avoid a situation when the bg thread might use the older token

wrt the new if statement.. 
in kerberos mode, the first time the Client connects,  it initiates a SPNEGO handshake with the server. This involves first sending an {{OPTIONS}} request, to which the Server will respond with {{Set-Cookie:}} containing the correct {{hadoop.auth}} cookie. This cookie string is then *set* in the authToken. All subsequent requests {{GET / POST / DELETE etc.}} from the client would just send the {{hadoop.auth}} cookie. The issue is that the authToken can be *set* only during initialization, i.e. the response to the OPTIONS request (you can blame {{KerberosAuthenticator}} for that). Now, if the authToken is stale, the Server will send a 401 to the client with {{WWW-Authenticate : Negotiate}} Header. This is intercepted by the JDK SPNEGO implementing classes on the client side and it automatically responds (no control is returned to the call method in KMSClientProvider) with an {{Authorize : Negotiate <kerb token>}} header.  This will generally be accepted by the server and along with the 'success' response, the KMS server also sends back a {{Set-Cookie}} with the correct value of {{hadoop.auth}} cookie.. unfortunately, since this is not a response to a connection initialization call, and since the authToken is already *set*, the new {{hadoop.auth}} cookie is simply ignored.. Which mean for every subsequent request after the authToken has gone stale, the client will actually be sending 2 requests.. one with the old stale token which returns 401 and the second which is successful. The only way to know in the {{KMSClientProvider}} that there was an authentication failure and that the authToken needs to be flushed is to see if a SUCCESSFUL response has a {{hadoop.auth}} Set-Cookie. Also since I cannot just 'set' the authToken with the cookie, since the {{set()}} method is package protected.. only option I have is to create a new instance of the authToken.. so that the next request from the client will initialize the SPNEGO handshake and 'set' the authToken correctly.

Hope this made sense..


, Uploading new patch :

* addressing some of [~andrew.wang]'s suggestions
* Using {{AuthenticatedURL#extractToken}} to set the authToken on successful response if it contains a *hadoop.auth* cookie.. so subsequent requests need not initiate SPNEGO handshake, Updating patch again :

* Modified {{TestKMS#testKMSRestart}} to check case when kerb is both enabled and dissabled(simple auth), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672710/HADOOP-11151.4.patch
  against trunk revision 054f285.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.crypto.random.TestOsSecureRandom
                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4853//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4853//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672715/HADOOP-11151.5.patch
  against trunk revision 054f285.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl
                  org.apache.hadoop.ha.TestZKFailoverControllerStress
                  org.apache.hadoop.crypto.key.kms.server.TestKMS

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4854//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4854//console

This message is automatically generated., Looks real good. I like the revs you've made, and thanks for the very thorough explanations. +1, will commit shortly., Committed to the three branches, thanks much Arun for working on this!, SUCCESS: Integrated in Hadoop-trunk-Commit #6184 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6184/])
HADOOP-11151. Automatically refresh auth token and retry on auth failure. Contributed by Arun Suresh. (wang: rev 2d8e6e2c4a52a4ba815b23d6d1ac21be4df23d9e)
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/client/AuthenticatedURL.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
, Thanks [~asuresh] for the patch and [~andrew.wang] for review., SUCCESS: Integrated in Hadoop-Yarn-trunk #699 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/699/])
HADOOP-11151. Automatically refresh auth token and retry on auth failure. Contributed by Arun Suresh. (wang: rev 2d8e6e2c4a52a4ba815b23d6d1ac21be4df23d9e)
* hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/client/AuthenticatedURL.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1890 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1890/])
HADOOP-11151. Automatically refresh auth token and retry on auth failure. Contributed by Arun Suresh. (wang: rev 2d8e6e2c4a52a4ba815b23d6d1ac21be4df23d9e)
* hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/client/AuthenticatedURL.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1915 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1915/])
HADOOP-11151. Automatically refresh auth token and retry on auth failure. Contributed by Arun Suresh. (wang: rev 2d8e6e2c4a52a4ba815b23d6d1ac21be4df23d9e)
* hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/client/AuthenticatedURL.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
, Hi, I tried with the check-in of HADOOP-11113 and 1.patch here, it worked for the first 2 days, but failed again in the 3rd day, the same error message and exception in the log.

I'm using branch-2 and will try the latest code since already checked in., BTW, after restart namenode and kms service, it can get back to put file into the encryption zone., [~zb161], this patch should handle Token expirations without having to restart NN.. , Arun Suresh, I'm using branch-2 code and think the patch is already in, but get the same error I mentioned in 3 days, so far it will occasionally report java.util.concurrent.ExecutionException: java.io.IOException: HTTP status [403], message [Forbidden]
and get back to work after re-execute the command.

as a workaround, would it be better to add more than one retry by default? or add sleep or any other reason?, [~zb161] thanks for the additional testing, maybe we should file a new JIRA to track? You could also try increasing the retry count via configuration if you want to test it. Based on Arun's explanations though, I'd be surprised if it made a difference, barring network issues., [~zb161], we had identified another related issue, which I suspect is what you are facing : HADOOP-11187
The are a couple of workarounds you can try till the above bug is resolved :
# One may increase the KMS authentication token validity period to some very high number (default is 10 hours, so by default this bug will only be encountered after 20 hours of no communication between the NN and KMS) by putting the following in the {{kms-site.xml}} safety valve: 
{code} 
<property> 
  <name>hadoop.kms.authentication.token.validity</name> 
  <value>SOME VERY HIGH NUMBER</value> 
</property> 
{code} 
# You can switch the KMS signature secret provider to the string secret provider by putting the following in the {{kms-site.xml}} safety valve: 
{code} 
<property> 
  <name>hadoop.kms.authentication.signature.secret</name> 
  <value>SOME VERY SECRET STRING</value> 
</property> 
{code}

]