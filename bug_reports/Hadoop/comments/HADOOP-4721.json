[Stack trace 
, Stack Trace (resent)

    [junit] Exception in thread "Main Thread" java.lang.OutOfMemoryError: allocLargeObjectOrArray - Object size: 164626424, Num elements: 164626404
    [junit]     at java.util.Arrays.copyOf(Arrays.java:2786)
    [junit]     at java.io.ByteArrayOutputStream.toByteArray(ByteArrayOutputStream.java:133)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:448)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
    [junit] Running org.apache.hadoop.mapred.TestSetupAndCleanupFailure
    [junit] Tests run: 1, Failures: 0, Errors: 1, Time elapsed: 0 sec
    [junit] Test org.apache.hadoop.mapred.TestSetupAndCleanupFailure FAILED (timeout)

This is in ant,

            if (startTestSuiteSuccess) {
                sendOutAndErr(new String(outStrm.toByteArray()),
                              new String(errStrm.toByteArray()));
            }

And it is triggered by either of the streams being too big for junit to handle. This is something to x-file with Ant, but there is also a root cause somewhere to deal with -what is creating 164MB worth of stdout or stderr?, Patching Ant to handle this gracefully (by catching the OOM exception and skipping the conversion) shows the underlying cause, its Log4J that is running out of memory



java.lang.OutOfMemoryError: requested array is larger than heap
at java.util.Arrays.copyOf(Arrays.java:2786)
at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:94)
at java.io.PrintStream.write(PrintStream.java:430)
at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:202)
at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:272)
at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:276)
at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:122)
at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:212)
at org.apache.log4j.helpers.QuietWriter.flush(QuietWriter.java:58)
at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:316)
at org.apache.log4j.WriterAppender.append(WriterAppender.java:160)
at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
at org.apache.log4j.Category.callAppenders(Category.java:206)
at org.apache.log4j.Category.forcedLog(Category.java:391)
at org.apache.log4j.Category.log(Category.java:856)
at org.apache.commons.logging.impl.Log4JLogger.info(Log4JLogger.java:133)
at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:550)
at org.apache.hadoop.mapred.TestSetupAndCleanupFailure.testWithDFS(TestSetupAndCleanupFailure.java:107), This is in this line: 

LOG.info("Shutting down the Mini HDFS Cluster");

Could be something to discuss with Team Log4J. But the underlying cause is, presumably, that a few hundred MB of text are somehow being written out and neither Ant nor Log4J are happy with this. , Hello Steve,

Do you know the size of the buffer of FileAppender? Could you please provide your log4j.properties file?, Try setting the 'immediateFlush'  property of your FileAppender to true. 

If that is already the case, is it possible that the data being logged is very large?
, This is the log4J config file; its the hadoop log4j with the debug logger altered to not print the thread info -that was causing a deadlock on JRockit, Which one is the "debug logger"? , that's a point. Hang on, I'm not sure thats' the log4 properties file used in test runs, the properties file used in my test runs is 

# log4j configuration used during build and unit tests

log4j.rootLogger=info,stdout
log4j.threshhold=ALL
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} %x- %m%n

It's different from the one in SVN because of HADOOP-3654 

, There is nothing wrong with the above config file. Moreover, it is already configured for immediate flush which is the default. 

1) Which version of log4j is this? 
2) Are you really sure that the message being logged is not huge or somehow becomes huge? , Looking at the source code of MiniDFSCluster.java [1], I can't see any references to logging. 

What happens when you disable logging altogether? Maybe there is no memory because there is a leak somewhere unrelated to log4j.

[1] http://tinyurl.com/69soss

, I dont think there is a memory leak, I just fear that too much is being buffered -even on console output- though it could be hidden by Ant playing games underneath. If Ant is still buffering everything going to stdout and log4j is pushing to stdout, Ant could be the cause even though it is not in the stack trace. 

I will downgrade logging level to INFO and see if that is enough to make the problem go away., Ceki, we're running 1.1.15. 

If I set logging to ERROR then the test succeeds in <3 minutes and all is well. Things go wrong at DEBUG level. It could be there's too much stuff coming to stdout for ant, or there could be some looping going on. Or it could be a JRockit x64 problem. I'll try some more experiments (same code under a sun JVM, more selective log levels, etc), The trigger for this is my having the following line in src/test/log4.properties

log4j.logger.org.apache.hadoop.mapred=DEBUG

Does anyone else see the same problem if they add this to their log4 properties file?, I now think this is a problem with Ant setting up junit to log the output; at debug level this test just creates too much data. There's no solution to this within og4j or hadoop. Closing as WONTFIX. ]