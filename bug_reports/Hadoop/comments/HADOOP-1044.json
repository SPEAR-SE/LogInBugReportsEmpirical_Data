[This patch changes the test to keep track of the datanodes that have been decommissioned and keeps them in the exclude file.  The problem with the test before was that the exclude file was overwritten with only the latest node to be decommissioned.  The previously decommissioned node would then be marked as normal instead of decommissioned, making it a valid target for replication. , +1. Code reviewed.

One minor comment: there are 5 datanodes and in the second iteration two of the datanodes are in decommission state. Thus the  test file should get replicated on the remaining three datanodes. In this is correct, you might want to make numDatanodes = numIterations + 3., Thanks for reviewing the patch, Dhruba!  I changed numDatanodes to be numIterations+3.
, -1, because javac generated 772 warnings (more than the acceptable 768 warnings) when testing the latest attachment (http://issues.apache.org/jira/secure/attachment/12352145/hadoop-1044-2.patch) against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/512006. Please note that this message is automatically generated and may represent a problem with the automation system and not the patch. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, Removed use of generics.  Trying again..., I just committed this.  Thanks, Wendy!]