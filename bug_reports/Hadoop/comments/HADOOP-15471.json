[Cc: [~arpitagarwal], [~ajaysachdev] : Is this the same functionality which we are trying to achive?
https://issues.apache.org/jira/browse/HDFS-11786, Thanks for working on this [~ajaysachdev] and [~jcwik]. Please find my comments as following.

1) The current patch is not applying right now. Can you please rebase the patch over latest trunk ?
2) Also can you please upload the patch with filename as "HDFS-13398.001.patch". Please follow the guidelines for naming the patch as https://wiki.apache.org/hadoop/HowToContribute#Naming_your_patch.
3) Also can the config "fs.threads" can be replaced with a command line argument. I feel that will help in controlling the parallelization for each command. We can certainly have a default value in the case it is not specified.
4) Also it will be great if some unit tests can be added for the patch.
, Hi Mukul/Arpit,

Sorry for late response. We would like to get a formal review process for this patch before we deploy on customer site. I will work on items #3 and #4 above. Also I was unable to find trunk branch in 

[https://github.com/hortonworks/hadoop-release.] So we have used HDP tag -

HDP-2.6.2.0-205-tag

I have also attached the patch against this tag. I would appreciate if you could take a look at code and get a review as well.

 

Thanks

Ajay[^HDFS-13398.001.patch], Thanks for the updated patch [~ajaysachdev]. The Apache Hadoop trunk can be found at "git clone git://git.apache.org/hadoop.git". Please refer to https://wiki.apache.org/hadoop/GitAndHadoop for details.

Please rebase the patch over the latest Apache Hadoop trunk obtained from the above location., I have attached apache hadoop trunk multithreading diff. Please take a look at code review and provide comments.

 

Thanks

Ajay, Hi [~ajaysachdev], I cannot see a patch uploaded to the jira. Can you please upload the patch to the jira :)
, Thanks [~ajaysachdev].

I am still not able to see the "HDFS-13398.002.patch" patch in Attachments section of the jira.
I tried reviewing the HDFS-13398.001.patch but the patch does not apply on the latest trunk.

Please submit the patch by using the Attachment section of the jira. , Hi [~ajaysachdev], I just take a quick look for the v001 patch. One comment from me:

In the v001 patch, we introduced the ForkJoinPool to execute commands in an asyn way. Since we make this change in Command class that means this will also make sense for other fs sub-commands, not only -du, -ls commands. Will this be thread-safe to run in other fs commands?

In addition, looks like this JIRA should move into Hadoop Common., Hi Mukul,

I have attached the new patch to JIRA.

 

Cheers,

Ajay, Hi Yiqun,

Thanks for taking the time to take a look at the patch. I have also uploaded the 2nd version of the patch against apache trunk. I would appreciate if you could provide some feedback against that version as well. This patch is intended for our customer which is using ViPRFS interface and they only want to run -ls -R/-du and count commands of FsShell. I agree that if there is any mutable shared state that any of sub-commands such as usagesTable in FsUsage.java class then we will wrap synchronized block around it to make it thread-safe. As a long term solution we would like to optimize all FsShell commands to take use of this ForkJoin Pool Framework and then all sub-commands implementation can ensure that any shared state are thread-safe.

 

Thanks

Ajay, [~ajaysachdev]: Thanks for the patch.
Do you have performance numbers for {{ForkJoinPool}} approach. Sorry if I have missed that part.
Also for {{fs.threads}}, did you compare with different #threads and evaluate what #threads is recommended., Hi Rushabh,

Thats a good question. As you may know FJP is very critical for multi-core systems and it forks large tasks into smaller subtasks and then joins (waits) individual results to form final result (Divide and Conquer approach). We tried different number for parallelism (ie number of threads) in ForkJoinPool framework such as 8, 16, 32 and 64. The use case was a directory/file hierarchy structure of 40K+ and a nested tree-level. In this scenario we were able to demonstrate that a numberOfThreads=32 was ideal configuration. So our tests were based off these variables.

FsShell commands (single threaded approach) -

ls -R -> 12 mins

du -> 14 mins

count -> 14 mins

 

FsShell commands (FJP approach) -

ls -R -> 3 mins

du -> 2 mins

count -> 9 mins

 , Thanks for the  [^HDFS-13398.002.patch] [~ajaysachdev]. Some major comments on the patch.

1) The current recursion in Command@recursePath uses the depth variable to recurse down the tree. I feel we should synchronize and localize the modification to this variable.
2) Apache Hadoop uses, 2 spaces for indentation. Please use the same coding guidelines in the patch.
3) Lets also add a unit test for this patch, We can add a unit test where a multi level directory structure is parsed through both the current method as well as the new method in the patch and lets compare the results to verify the validity of the patch.
4) Also I feel in place of a config variable "fs.threads", number of threads should be made a command line argument, so that the user can control the number of threads for each invocation of the command., I have incorporated all items above. I am in process of putting some unit tests as well and testing these out. For number of threads option I have opted for -T <number of threads> in command line argument. The "du" command already had a lower -t option for storage type., Attaching the latest patch which has Count multithreaded optimization as well. Also added unit tests to diff. Let me know if there are any more comments.

 

Thanks

Ajay[^HDFS-13398.003.patch], Hello Mukul/Yiqun/Rishabh,

Please let me know if you have any comments on latest patch.

Appreciate your help!

Ajay, Submitting the patch to trigger jenkins., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 29m 10s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 29m 10s{color} | {color:red} root generated 1 new + 1489 unchanged - 0 fixed = 1490 total (was 1489) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 52s{color} | {color:orange} hadoop-common-project/hadoop-common: The patch generated 47 new + 101 unchanged - 0 fixed = 148 total (was 101) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  8s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 43s{color} | {color:red} hadoop-common-project/hadoop-common generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 20s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}124m 50s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-common-project/hadoop-common |
|  |  Boxing/unboxing to parse a primitive org.apache.hadoop.fs.shell.Count.processOptions(LinkedList)  At Count.java:org.apache.hadoop.fs.shell.Count.processOptions(LinkedList)  At Count.java:[line 140] |
|  |  Possible null pointer dereference of status in org.apache.hadoop.fs.shell.Count$ContentSummaryTask.compute() on exception path  Dereferenced at Count.java:status in org.apache.hadoop.fs.shell.Count$ContentSummaryTask.compute() on exception path  Dereferenced at Count.java:[line 277] |
|  |  Boxing/unboxing to parse a primitive org.apache.hadoop.fs.shell.FsUsage$Du.processOptions(LinkedList)  At FsUsage.java:org.apache.hadoop.fs.shell.FsUsage$Du.processOptions(LinkedList)  At FsUsage.java:[line 193] |
|  |  Boxing/unboxing to parse a primitive org.apache.hadoop.fs.shell.Ls.processOptions(LinkedList)  At Ls.java:org.apache.hadoop.fs.shell.Ls.processOptions(LinkedList)  At Ls.java:[line 155] |
| Failed junit tests | hadoop.fs.TestFsShellCopy |
|   | hadoop.cli.TestCLI |
|   | hadoop.fs.shell.TestLs |
|   | hadoop.fs.shell.TestCount |
|   | hadoop.fs.shell.find.TestFind |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15471 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12925175/HDFS-13398.003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 6956ede0deb0 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 7dd26d5 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/14713/artifact/out/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/14713/artifact/out/diff-checkstyle-hadoop-common-project_hadoop-common.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/14713/artifact/out/new-findbugs-hadoop-common-project_hadoop-common.html |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14713/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14713/testReport/ |
| Max. process+thread count | 1516 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14713/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, [~ajaysachdev], please review the javac/findbugs issues and test failures. Please fix them if they are related to this patch.]