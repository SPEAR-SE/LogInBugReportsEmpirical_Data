[I also tried explicitly listing the columns instead of '*', but that still failed:
INSERT OVERWRITE TABLE payout_state_product 
SELECT * FROM payout_state_product_cached;
--> FAILS

I tried this multiple times, fails every time.  But I have a bunch of other queries that work and can write to S3.  The distinguishing factor for this query is that it has no reduce phase.

Further evidence... the following variation on the query works. It adds a simple reduce phase with a pointless group-by:

INSERT OVERWRITE TABLE payout_state_product
SELECT state, product_id, element_id, element_value, number_of_fields 
FROM payout_state_product_cached
GROUP BY state, product_id, element_id, element_value, number_of_fields;

This group by is a feasible work-around, although for large jobs it could be a significant performance hit (luckily that's not the case for this particular query).

Also, I confirmed that the problem goes away when not writing to S3.  Using a variation of the query that writes to a hive managed, hdfs version of the destination.
, Does this work on Hadoop 1.x?, This does work on hadoop 0.20.x.  Likely it's a YARN only problem.]