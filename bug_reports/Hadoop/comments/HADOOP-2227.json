[I have to correct my previous comment, as the map output gets merged into a single file, i.e. free space should not be added up, but when one of the disks has enough space for a task, then TaskTracker.enoughFreeSpace should return true., bq. when one of the disks has enough space for a task, then TaskTracker.enoughFreeSpace should return true.

With current behaviour , if we do this, localizeJob() and localizeTask() can fail because they use getLocalPath() for localizing. In getLocalPath(), there is no space availability check. And local file names are hashed to determine which device to store the file on.
One solution could be to change getLocalPath to use localDirAllocator as proposed in HADOOP-1991 and then do this change.  But there would be some cases where we do not know size of files apriori, to check for disk space.

Thoughts?, The local directory handling of multiple directories has been an issue for a long time. *grin* How about a weighted selection based on how much free space there is? Once that is changed, then using the max of the freespace > minspacestart seems like it would be right., We have two options here. 
1.    The simple approach of just checking whether at least one of the disks has enough space. This will cover all the intermediate outputs generation/copy cases (for maps and reduces respectively). The bulk of the other operations that the tasktracker does to do with disks is copying the job jar file, and, localizing the tasks' cache. Both these are done before the task launch (process spawn) and the tasktracker won't even launch the process if it encounters a problem in this part (it will throw an exception). The tasktracker then marks that task as having "failed". This behavior should be okay since we haven't spent much time executing the task yet.

2.   The other option is to change things like localizeJob, localizeTask and localizeCache, to use the LocalDirAllocator but in order to do that, we have to know the sizes of the cache files. This is doable, but involves an RPC.

Thoughts?


, bq. This is doable, but involves an RPC
We anyway do an RPC to get the DFSFileInfo, right? Isn't the length always present? , In the attached patch,  when one of the disks has enough space for a task, then TaskTracker.enoughFreeSpace  returns true. The patch also changes localizeJob, localizeTask and localizeCache methods to use localDirAllocator. , +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371485/patch-2227.txt
against trunk revision r603428.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1324/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1324/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1324/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1324/console

This message is automatically generated., jobCacheDir has to use localDirAllocator, Fixed jobCacheDir. Tested on 100 node cluster, +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371660/patch-2227.txt
against trunk revision r604058.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1343/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1343/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1343/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1343/console

This message is automatically generated., Some comments:
1) In LocalDirAllocator.java, 
  1.1)  isExists should probably be renamed to ifExists
  1.2) The implementation of isExists returns 'false' when IOException is encountered. I think it should just catch the exception and continue looking.

2) In ReduceTask.java, shouldn't workDir be using the LocalDirAllocator.getLocalPathToRead (like jobCacheDir)?

3) DistributedCache.java is a public class and so the public APIs that were there earlier should still be there (maybe redirect the implementation to your new APIs).

4) In TaskTracker.java, getLocalPathForWrite is invoked for both jobfile and the jar file. Is the second one required since you already account for the sizes in the first call and you should probably use the same path that the first call returns., bq. 2) In ReduceTask.java, shouldn't workDir be using the LocalDirAllocator.getLocalPathToRead (like jobCacheDir)?

WorkDir is the taskdirectory here, which is created using getLocalPathForWrite and stored in task as taskfile's parent. It need not use getLocalPathToRead.

, Submiting patch after incorporating the review comments., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371787/patch-2227.txt
against trunk revision r604451.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs -1.  The patch appears to introduce 1 new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1364/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1364/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1364/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1364/console

This message is automatically generated., Submiting patch again after fixing findbugs warning., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371795/patch-2227.txt
against trunk revision r604451.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1368/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1368/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1368/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1368/console

This message is automatically generated., I just committed this. Thanks, Amareshwari!, Integrated in Hadoop-Nightly #338 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/338/])]