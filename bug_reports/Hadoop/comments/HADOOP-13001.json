[Quickly checked several existing retry policies (RetryUpToMaximumTimeWithFixedSleep, FailoverOnNetworkExceptionRetry, etc). Looks like we have not clearly defined the semantic for their sleep/delay intervals, nor written tests to cover the 0 interval case. We can use this jira to fix them., that would be good. What I wanted was to set the RM client up to have a policy of try once then fail —no retry—, but as the retry policy is hard coded, all I can do is change the timeouts. Setting interval=0 triggers this.

Setting maxwait=0 and interval=1 works, though you get warned that as maxwait < interval, you don't get any retries.

I think I'd like there special case of "maxwait=0" to be recognised as "you don't want retries". 
If you do have a maxwait >0, and an interval ==0, well, you do have a problem in your configuration, don't you? That could be be rejected more gracefully than a division by zero exception., FAILURE: Integrated in Hadoop-trunk-Commit #9651 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9651/])
HADOOP-13001 - Clearly Document the Password Details for Keystore-based (lmccay: rev 3ba490763e5dfcd6ee0def4c63405c20b2721c8c)
* hadoop-common-project/hadoop-common/src/site/markdown/CredentialProviderAPI.md
, Please ignore the above message. The related commit inadvertently referenced this JIRA instead of HADOOP-13011.]