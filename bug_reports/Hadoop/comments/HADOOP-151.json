[What's the problem with a static CLIENT?  What problems does this cause?  The client has the connection pool, so one potential problem is that, a large request or response will delay other requests or responses to/from the same host.  Is that the issue you're seeing?  If so, can you provide more details about the circumstances where this occurs?
, 
If thre is only one Client object, then you're right, its OK that its static. 

The fact that the object is also stored in the conf - combined with the comment - made it look like a coding error (since its not accessed by anything but those parts of the code).

, You're right, that code got uglified by the configuration stuff.  There should only need to be a single Client for RPC.  Each Client keeps a cache of TCP connections to other host:port pairs expecting the same Writable class for requests and responses.  All RPCs use Invocation as the request class and ObjectWritable as the response class, so they can generally share connections.

The problem is that there's no longer a global configuration.  So a global client could be lazily constructed the first time a call is made with the invoker's configuration.  Or we could create a new client for each configuration.  But, you're right, we shouldn't do both, as the current code does.  Changing the global CLIENT shouldn't break anything, but it's also silly and wasteful.  The only thing the client reads from the configuration is the RPC timeout.  It might almost be better to remove the configuration from Client altogether and always explicitly pass the timeout as a parameter to call().

I wonder if this could even be leading to socket leaks?  Hmm.  A client doesn't close it's connections until it's either explicitly closed (which these are not) or until the remote server dies.  So we should probably fix this somehow., I just fixed this.  I restored the original behaviour, where a single client is used for all calls, regardless of the configuration.  This results in the use of a single connection pool for all RPC calls, and hence closes a potential socket leak.  Long-term we might consider other approaches to pooling connections.  Today it seemed more important to close the leak than to, e.g., permit different ipc timeouts for different jobs.]