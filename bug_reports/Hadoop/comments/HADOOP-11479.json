[[~ranadip], can you paste the failure msg?  
Only super user is allowed to create an encryption zone. What key level ACL you have configured?, Test ACL config attached.

If hdfs is included in the sections key.acl.ranskey1.GENERATE_EEK and key.acl.ranskey1.READ, it works.

Without those changes, it just shows RemoteException on the shell with no error message:
<quote>
[ranadip@server ~]$ hdfs crypto -createZone -keyName ranskey1 -path /user/ranadip.dir/enc
RemoteException:
</quote>

On KMS log, it shows:
<quote>
2015-01-15 11:49:46,447 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hdfs/*masked*@*masked* (auth:KERBEROS) cause:org.apache.hadoop.security.authorize.AuthorizationException: User [hdfs] is not authorized to perform [READ] on key with ACL name [ranskey1]!!
</quote>
, Sorry, obviously the attempted markup with the quotes did not work :-(, Sorry, obviously the attempted markup with the quotes did not work :-(, [~ranadip],

Just to confirm, you are running the hdfs crypto command as user 'ranadip' (assuming your cli prompt is showing user@host) and you are running your namenode as hdfs (as indicated by the KMS message "User [hdfs] is not..."). Assuming the NN is running as user hdfs, then user 'hdfs' is the hdfs superuser and it must have (as you have noted) GENERATE_EEK and READ access to ranskey1. As [~hitliuyi] said, the hdfs crypto -createZone command can only be run by the superuser.

Charles
, Hi Charles,

Yes, you are right on the user setup and namenode process is started by "hdfs". This is a kerberos enabled environment, so the real user is obtained from the Kerberos ticket. The Kerberos user, though not "hdfs" is a member of the hdfs supergroup. So, Hadoop should see the user as a superuser when executing this command. Moreover, the encryption zone is being created inside the Kerberos user's home directory where the user executing the command is in fact the owner of the EZ being created.
However, providing key level access, specially READ access to an application user does ring some alarm bells. In effect, with this limitation that hdfs user needs those key accesses for all encryption zones, it means if the hdfs user credentials are compromised, the "baddie" can have access to the encrypted data as well (or am I missing something?) Should the process rather not use the real user (authenticated by Kerberos) from the UserGroupInformation  check key level authorisations with KMS?, [~ranadip],

I am pretty sure that the READ exception is being thrown when the NN is doing getMetadata. Here's the explanation:

There are KMS operation ACLs (hadoop.kms...) and KMS key ACLs (default.key.acl...). The KMS key ACLs are more coarse-grained (MANAGEMENT, GENERATE_EEK, DECRYPT_EEK, READ, ALL) than the KMS operation ACLs (which cover each public KMS method call individually).

So, by default, the HDFS user has READ permission on all keys (default.key.acl.READ=*). This gives that user access to the getKeyVersion, getKeyVersions, getMetadata, getKeysMetadata and getCurrentKey methods.

But, then, to lock down HDFS user access to key material, you also need to add the HDFS user to the blacklist for the following KMS operation ACLs:

CREATE, DELETE, ROLLOVER, GET, GET_KEYS, SET_KEY_MATERIAL, DECRYPT_EEK

(This is what setting the KMS Blacklist property in CM does: it is a shortcut to setting these seven KMS operation ACLs)
There is also a specific KMS operation ACL for GET_METADATA, but you don't want to set that in this case., [~ranadip],

I haven't heard back about whether the suggested KMS ACLs got you past this problem. I'm going to close this for now, but feel free to reopen it.
]