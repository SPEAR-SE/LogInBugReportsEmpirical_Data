[Looks like there might be a race in FsDatasetAsyncDiskService -> ReplicaFileDeleteTask.run

Scenario:

1) blockFile.delete()
2) DU thread runs setting disk usage number which (deleted block not included)
3) volume.decDfsUsed(...) decrements the block from the used amount, From a user perspective, I am not expecting a negative number and as such, a simple solution such as Math.max(used, 0) would be acceptable., The patch attached changes the DU class in common. I think making the change their is appropriate because a drive should never have a negative amount "used". Should I create a HADOOP jira for this? I wasn't able to detect based on (http://wiki.apache.org/hadoop/HowToContribute)


Details on the change:

The change to the DU class simply wraps the getUsed() return statement in a Math.max(used, 0L) to ensure that the getUsed method never returns negative. 

Another option would be when getUsed() would return negative to re-run the DU command. I do not feel that change is appropriate because there are still races mean we would have to loop until we obtain a positive value. The scenario where getUsed() can return negative occurs when there is a very small, possibly zero, amount actually used. As such reporting a perfectly correct number is of little value., Marking patch available., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12561135/HDFS-4229-0.patch.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3670//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3670//console

This message is automatically generated., The patch looks pretty good to me, Brock. I agree with you that this issue doesn't warrant as heavyweight a solution as the other one you proposed.

Can you comment on whether or not running with this patch addressed the actual issue you noticed? i.e. running with a near-empty HDFS instance, creating and deleting a single file very quickly?, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12561135/HDFS-4229-0.patch.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1902//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1902//console

This message is automatically generated., Yes, I was unable to reproduce with the patch applied!, Great, thanks for confirming that.

+1, the patch looks good to me. I'm going to commit this momentarily., I've just committed this to trunk and branch-2.

Thanks a lot for the contribution, Brock., Thank you!, Integrated in Hadoop-trunk-Commit #3137 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3137/])
    HADOOP-9152. HDFS can report negative DFS Used on clusters with very small amounts of data. Contributed by Brock Noland. (Revision 1423602)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1423602
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DU.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDU.java
, Integrated in Hadoop-Yarn-trunk #70 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/70/])
    HADOOP-9152. HDFS can report negative DFS Used on clusters with very small amounts of data. Contributed by Brock Noland. (Revision 1423602)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1423602
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DU.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDU.java
, Integrated in Hadoop-Hdfs-trunk #1259 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1259/])
    HADOOP-9152. HDFS can report negative DFS Used on clusters with very small amounts of data. Contributed by Brock Noland. (Revision 1423602)

     Result = FAILURE
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1423602
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DU.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDU.java
, Integrated in Hadoop-Mapreduce-trunk #1290 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1290/])
    HADOOP-9152. HDFS can report negative DFS Used on clusters with very small amounts of data. Contributed by Brock Noland. (Revision 1423602)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1423602
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DU.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDU.java
, Integrated in Hadoop-Hdfs-0.23-Build #471 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/471/])
    HADOOP-9152. HDFS can report negative DFS Used on clusters with very small amounts of data (Brock Noland via tgraves) (Revision 1425095)

     Result = UNSTABLE
tgraves : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1425095
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DU.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDU.java
]