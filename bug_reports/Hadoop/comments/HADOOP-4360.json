[It is disturbing that the JobTracker had duplicate events. I think we should focus on fixing that for a start...

Zheng what was the output of
$ bin/hadoop job -events -events <job-id> 0 10000000

, The array of completion events at the JobTracker is correct - there is no duplicate. I didn't try that -events but I have a web interface to view the completed events on the job tracker.

The problem is only at the TaskTracker.  However, different TaskTrackers have different patterns of duplicates.

A lot of them (but not all) are 100 duplicates at a time (1,2,3...,100, 1,2,3,...100), which also signals the problem is at the communication protocol (where we poll 100 events at a time).
, Ok, thanks for the clarification - it's good to know that the problem lies at the TaskTracker end.

Any idea _why_ the TaskTracker is getting messed up?, Arun, are there any changes to getCompletionEvents interface from 17 to trunk? Or are there any changes in the plan?

If not, I will be glad to work on a diff to add the starting index to the JobTracker's reply.
, The problem can easily happen if there are multiple requests to the job tracker at the same time:

Let's say TaskTracker's allMapEvents contains 5 elements now, and 2 requests to the JobTracker are started at the same time, so both requests bear a starting index of 5.
The 2 requests will get identical replies from JobTracker. Then they are added to the completion events separately, which caused the duplicates.


A simple "synchronized(fromEventId)" wrapper around the "jobClient.getTaskCompletionEvents" call will avoid the problem. In case we don't want to do that, we should at least check whether fromEventId has changed during the RPC call.
(let me withdraw the idea of adding starting index to the job tracker reply - that does not seem necessary)

TaskTracker.java:(from 0.17.2)
854:
  private List<TaskCompletionEvent> queryJobTracker(IntWritable fromEventId,
                                                    String jobId,
                                                    InterTrackerProtocol jobClient)
    throws IOException {

    TaskCompletionEvent t[] = jobClient.getTaskCompletionEvents(
                                                                jobId,
                                                                fromEventId.get(),
                                                                probe_sample_size);
    //we are interested in map task completion events only. So store
    //only those
    List <TaskCompletionEvent> recentMapEvents = 
      new ArrayList<TaskCompletionEvent>();
    for (int i = 0; i < t.length; i++) {
      if (t[i].isMap) {
        recentMapEvents.add(t[i]);
      }
    }
    fromEventId.set(fromEventId.get() + t.length);
    return recentMapEvents;

613:
    public void fetchMapCompletionEvents() throws IOException {
      List <TaskCompletionEvent> recentMapEvents = 
        queryJobTracker(fromEventId, jobId, jobClient);
      synchronized (allMapEvents) {
        allMapEvents.addAll(recentMapEvents);
      }
    }

, bq. The problem can easily happen if there are multiple requests to the job tracker at the same time: [...]

But that should not happen at all... each job has a single FetchStatus which maintains the fromEventId. 
I guess we should look closer if we are mucking up there... thoughts?, Yep I agree with your reasoning. I tried to find other reasons but I couldn't. Also it's not easy to reproduce the problem.

Let me put an assert in our in-house code, and try to dump some more information when duplicate events happens.

Will put up more details when I've got more information.
, Thanks Zheng, more details would really help!, This is related to HADOOP-3155. In addition to what you already have for debugging this, could you please apply the patch for the 0.17 release from HADOOP-3155 and deploy., this looks like a dup of 3155. we haven't applied the patch yet (I think) - but i did just now upload an attachment to 3155 with the output of hadoop job -events. please let us know if we need to run any additional commands., Duplicate of http://issues.apache.org/jira/browse/HADOOP-3155]