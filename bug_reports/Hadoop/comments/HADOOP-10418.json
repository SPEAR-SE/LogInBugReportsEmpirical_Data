[Straightforward patch attached to specify the correct name type for this principal, which will cause the JDK Kerberos library to use the domain_realm mapping to determine the correct realm.

No tests are included because of the difficulty of setting up an appropriate environment in the unit tests. I manually tested this and confirmed that it works as expected., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636163/HADOOP-10418.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3693//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3693//console

This message is automatically generated., +1 for the patch.  Thanks, Aaron!, +1 Looks ok to me.  I assumed kerberos was using the krb5.conf realm mapping since it works in our env., Thanks a lot for the reviews, gents. I've just committed this to trunk and branch-2., SUCCESS: Integrated in Hadoop-trunk-Commit #5385 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5385/])
HADOOP-10418. SaslRpcClient should not assume that remote principals are in the default_realm. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580666)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #519 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/519/])
HADOOP-10418. SaslRpcClient should not assume that remote principals are in the default_realm. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580666)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1711 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1711/])
HADOOP-10418. SaslRpcClient should not assume that remote principals are in the default_realm. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580666)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1736 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1736/])
HADOOP-10418. SaslRpcClient should not assume that remote principals are in the default_realm. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580666)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
, Closing old tickets that are already shipped in a release.]