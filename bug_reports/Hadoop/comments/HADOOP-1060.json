[Forgot to add that I ran into this while working on HADOOP-1050., Here is a patch which fixes the problem; basically the events-counter wasn't being manipulated correctly - also this fixes the JobClient to correctly handle lost trackers and fixes a synchronization issue in the JobTracker.

However there is an issue with this patch: With TASKTRACKER_EXPIRY_INTERVAL (set to the current default of 10mins) this patch works like a charm, I've tried manually bringing down trackers etc. and all unit-tests pass; however when I tried to test it with smaller expiry intervals (3m/5m) I see some weird behaviour; bringing this to everyone's attention while I dive deeper.

a) Set to 3mins i.e. ExpiryTrackerThread kicks in every minute
  The JT goes into a tizzy and seems to get overloaded e.g. all IPCs from the JobClient timeout and eventually it kills the job.

b)  Set to 3mins i.e. ExpiryTrackerThread kicks in every minute and a two-thirds
  I see that the reduces hang with infinite logs of this nature: 
2007-03-06 02:01:43,203 INFO org.apache.hadoop.mapred.TaskRunner: task_0002_r_000017_0 Need 4 map output(s)
2007-03-06 02:01:43,203 INFO org.apache.hadoop.mapred.TaskRunner: task_0002_r_000017_0 Need 4 map output location(s)
2007-03-06 02:01:43,204 INFO org.apache.hadoop.mapred.TaskRunner: task_0002_r_000017_0 Got 0 new map outputs from jobtracker and 0 map outputs from previous failures
2007-03-06 02:01:43,204 INFO org.apache.hadoop.mapred.TaskRunner: task_0002_r_000017_0 Got 4 known map output location(s); scheduling...
2007-03-06 02:01:43,204 INFO org.apache.hadoop.mapred.TaskRunner: task_0002_r_000017_0 Scheduled 0 of 4 known outputs (4 slow hosts and 0 dup hosts)
2007-03-06 02:01:44,084 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000017_0 0.3288889% reduce > copy (296 of 300 at 0.00 MB/s) > 
2007-03-06 02:01:45,085 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000017_0 0.3288889% reduce > copy (296 of 300 at 0.00 MB/s) > 
2007-03-06 02:01:46,087 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000017_0 0.3288889% reduce > copy (296 of 300 at 0.00 MB/s) > 
2007-03-06 02:01:47,089 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000017_0 0.3288889% reduce > copy (296 of 300 at 0.00 MB/s) > 
2007-03-06 02:01:48,092 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000017_0 0.3288889% reduce > copy (296 of 300 at 0.00 MB/s) > 


Appreciate any insights/reviews while I continue digging..., +1, Need to double check this patch; the 0.10.1 release works with TASKTRACKER_EXPIRY_INTERVAL set to 3min., -1, because 3 attempts failed to build and test the latest attachment http://issues.apache.org/jira/secure/attachment/12352698/HADOOP-1060_20070305_1.patch against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/515311. Please note that this message is automatically generated and may represent a problem with the automation system and not the patch. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, Could you please check whether the patch for HADOOP-1077 addresses the issue? Thanks., Resubmitting patch - this needs HADOOP-1077 of course!, Updated to reflect some changes to trunk..., I just committed this.  Thanks, Arun!]