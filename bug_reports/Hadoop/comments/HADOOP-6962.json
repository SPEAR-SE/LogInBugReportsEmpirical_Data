[Problem appears to be deeper than the related bugs.  The namenode appears to be the root cause of the incorrect permissions.  The client code is trying to spackle over the issue by changing the final directory's permissions to what they should be., Changed logic from: calling mkdirs with default perms, then applying the supplied perms to the last directory; to calling mkdirs with the supplied perms., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12477840/HADOOP-6962.patch
  against trunk revision 1097322.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://builds.apache.org/hudson/job/PreCommit-HADOOP-Build/389//testReport/
Findbugs warnings: https://builds.apache.org/hudson/job/PreCommit-HADOOP-Build/389//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/hudson/job/PreCommit-HADOOP-Build/389//console

This message is automatically generated., No tests are necessary because it's removing unnecessary behavior, and the hdfs tests in the linked bug will test it.
, This breaks compatibility. That's a big deal.

BTW are the semantics different for localfs and hdfs?, Hadoop's mkdirs used to follow posix and create dirs with correct permissions, but the semantics were broken sometime after 0.20.9.  Yes, currently the semantics differ for localfs (follows posix) and hdfs (does not).  This patch restores posix compliance for hdfs mkdirs.
, bq. the semantics were broken sometime after 0.20.9

What is 0.20.9?, 20.09 is internal yahoo release -- at least on the internal release the semantics appeared to have changed.  The internal Y! release does not matter to the larger Hadoop community except that he may have helped detect a problem.
Main questions are:
* Did the semantics change and if so  accidentally or on purpose.
* What is the right semantics?
* Are we breaking compatibility if we change the behavior.

I have always disliked the recursive mkdirs., Daryn. There are 2 mkdirs methods.
* The *static* FileSystem#mkdirs(fs, dir, permission) is very explicitly
creating the dirs with the default and changing the permissions of the new leaf. This is 
not accidental.
* the *non static* Filesystem#mkdirs is an abstract method. Raw local file system implements mkdirs as
{code}
  public boolean mkdirs(Path f, FsPermission permission) throws IOException {
    boolean b = mkdirs(f);
    if(b) {
      setPermission(f, permission);
    }
    return b;
  }
{code}
, Apologies, my comments were more about the patch on the linked HDFS-1869.  The FileSystem api for creating directories is somewhat confusing.  Here's my reading of the code:

For localfs:
1. *public boolean mkdirs(Path f)* uses the umask for dirs0..N.
2. *public boolean mkdirs(Path f, FsPermission permission)* uses umask for dir0..N-1, given perms for dirN.

For hdfs:  
1. *public boolean mkdirs(Path f)* uses the parent dir's permission for dir0..N-1, 0777 for dirN.
2. *public boolean mkdirs(Path f, FsPermission permission)* uses the parent dir's permission for dir0..N-1, given permission for dirN

In both cases, *public +static+ boolean mkdirs(FileSystem fs, Path dir, FsPermission permission)* calls #1 + setPermission which has the same effect as #2, hence this change.

The linked HDFS bug creates dir0..N with the given permissions which restores how it used to work, and restores posix compliance.  However, it now differs from localfs, but localfs is in contradiction to FileSystem:

{code}
  /**
   * Make the given file and all non-existent parents into
   * directories. Has the semantics of Unix 'mkdir -p'.
   * Existence of the directory hierarchy is not an error.
   */
  public abstract boolean mkdirs(Path f, FsPermission permission
      ) throws IOException;
{code}, +1 patch looks good., > +1 patch looks good.

On a second thought, the non static mkdirs(f, perm) should create all dirs with masked perm with automatic u+wx for dir0..N-1.  We should keep the static mkdirs(..) as-is.  Does it make sense?, I'm not sure I understand.  The static method created the parent dirs with default perms -- which was really translating to inheriting the parent dir's perms prior to the linked HDFS-1869 -- and then changing the last dir to have the requested perms.  After HDFS-1869, the parent dirs won't inherit and thus may unexpectedly be more permissive than the final directory.  This change brings the static method in line with the non-static method which will create all the dirs with the requested perms (with implicit u+wx for parents).  It also eliminates a RPC., The static mkdir was introduced for setting absolute permission, i.e. without umask.  That's why it first calls non-static mkdir(..) and then calls setPermission(..).  It is independent to whether the non-static mkdir(..) inherits perms or uses umask., There's a bit of a conundrum here.  Owen's description of this bug wants all the created dirs to have the same perms.  The current patch fulfills this requirement, but yes, subjects the perms to the umask.  To satisfy both requirements, the "easy" way to implement the change is to call {{primitiveMkdirs}} which is marked deprecated.  Advice?, Hey Daryn, I believe Owen was talking about the non-static mkdir(..) with two parameters since the static mkdir has three parameters., What is the resolution here?

The DistributedFileSystem#mkdirs (which is the func. that allows parent-dir creation):

{code}
 @Override
  public boolean mkdirs(Path f, FsPermission permission) throws IOException {
    statistics.incrementWriteOps(1);
    return dfs.mkdirs(getPathName(f), permission, true);
  }
{code}

Eventually reaches the FSDirectory#mkdirs call with the inheritPermission argument set to false, thereby making it use the supplied permission object itself as the parent permission object:

{code}
// default to creating parent dirs with the given perms
      PermissionStatus parentPermissions = permissions;
<And eventually similar after entering a condition if there's parent directories to make>
{code}

So this mkdirs(â€¦) at the client (FS.mkdirs(P, Perm) as the title goes) is already supporting parent dir permission setting, no? Only LocalFS doesn't implement it that way. Given that, must we be changing anything at all?

I may be wrong somewhere here, feel free to point out., My memory of this jira is very rusty.  I do think all filesystems should be consistent, include LocalFS.  We recently had debacles with permissions because LocalFS and hdfs don't play by the same rules., Is there any reason not to make this a blocker for 2.0 or even 1.2.0?  This is really causing us 'out here' a lot of pain and really needs to get fixed., I'm changing this to a blocker for 1.2.0.  This is a pretty major security hole, when one considers that HDFS does permission inheritance. 

The only real choices appear to be:
a) Use 0777 + applied umask (i.e., POSIX)
b) Use inherited perms + applied umask (what I remember from the testing we did in Hadoop 0.14/15-ish)

I don't view this as a backwards compatibility problem as much as I view this as a regression.  I'm fairly confident that at some point in time this was working as intended (option b), but somewhere along the way no one noticed that it was broken., [~aw]I have been meaning to look at this, but have been busy. I will try to get this done this week., My tests with the current patch did not work on 1.0.4 when running a MapReduce program., Allen, how did the patch fail to work as expected?  I don't have a 1.x cluster handy at the moment., Changed Target Version to 1.3.0 upon release of 1.2.0. Please change to 1.2.1 if you intend to submit a fix for branch-1.2., This appears to be working now on 2.x.  Closing as fixed.]