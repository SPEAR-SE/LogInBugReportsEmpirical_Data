[For example, the following code in MapReduce input split calculation expects null to mean the file doesn't exist but an empty array to mean it exists but doesn't match any filters:
{code}
  private List<FileStatus> singleThreadedListStatus(JobContext job, Path[] dirs,
      PathFilter inputFilter, boolean recursive) throws IOException {
    List<FileStatus> result = new ArrayList<FileStatus>();
    List<IOException> errors = new ArrayList<IOException>();
    for (int i=0; i < dirs.length; ++i) {
      Path p = dirs[i];
      FileSystem fs = p.getFileSystem(job.getConfiguration()); 
      FileStatus[] matches = fs.globStatus(p, inputFilter);
      if (matches == null) {
        errors.add(new IOException("Input path does not exist: " + p));
      } else if (matches.length == 0) {
        errors.add(new IOException("Input Pattern " + p + " matches 0 files"));
      } else {
{code}

There was a case where a user passed the path to a _SUCCESS file as one of the input paths to a job, and the hidden file filter in FileInputFormat suppressed the _SUCCESS file.  globStatus returning null instead of an empty array triggered the code to report a misleading error to the user.
, This sounds like your opportunity to define what globStatus is meant to do as part of HADOOP-12177 ; I've looked at it when doing HADOOP-13207, but decided I was scared.

We really need written down what globStatus is meant to do here, It's easy enough to implement this behavior if you want.  See patch 001.

It seems like the current behavior dates back to at least Hadoop 2.3 though.  It was introduced by HADOOP-9817.  At this point, changing the behavior to the pre-2.3 behavior may break existing applications.  Perhaps this is a change we should make in 3.0?, bq. This makes it impossible for the caller to discern the difference between the file not existing at all vs. being suppressed by the filter and is inconsistent with the way it handles globs for an existing dir but fail to match anything within the dir.

Sorry if this is a nitpick, but it's not impossible for the code to know that the filter is suppressing the file entry.  The filter object could set a boolean when it's asked to examine an entry, and the code could check this entry.

With that being said, maybe there is case for (re)adopting the behavior proposed here., Thanks for chiming in, [~stevel@apache.org] and [~cmccabe].  I filed it without knowing for sure what the "right" fix is.  As Colin points out, it may be dangerous to change this behavior since it's been this way for so long.  Someone may have intentionally or accidentally relied on the behavior.  So I could see this as simply updating the javadoc to explain how globbing and filtering interact without any semantic changes at all.  Or we decide to fix the semantics but only in 3.x, etc.

My personal preference would be to have it act consistent with globbing patterns failing to match when the base path does exist.  And I'm totally fine if we decide this is best done on a major-release boundary to minimize the surprises for users when upgrading., well, it is a regression. You could just be the first to notice. Which also shows limitations of test coverage.

we should be updating filesystem.md BTW, that's where the definition of what filesystems are meant to do live. The whole glob code is an undocumented bit of functionality there â€”and I know that as I have plans to subclass the globber and do profund things once I've got HADOOP-13208 checked off. I'd like that spec and the contract tests to go with.]