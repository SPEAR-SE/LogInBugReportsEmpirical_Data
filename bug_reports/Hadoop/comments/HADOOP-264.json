[This patch forces the namenode to load the DatanodeRegistration class so that the factory is setup before it is needed for RPC., I should comment that this is a total hack just to get us flying again..., There is an idiom for this hack.  See e.g., the static initializer blocks near the top of DataNode, DFSClient, DFSShell, JobTracker, TaskTracker, etc.  It's nice to keep these all uniform, with the same comment, so that, someday, we can easily remove them all at once., Ok, after considering it a few minutes, I propose that all objects passed through RPC should be public classes with public methods. That will help when we factor the different servers (jobtracker vs. tasktracker) into separate packages (org.apache.hadoop.mapred.job vs org.apache.hadoop.mapred.task ???) and fundamentally the RPC interfaces are _public_ with a capital P.

However, the WritableFactory factory is still very useful for serialization and such. I'd propose that classes that want to register do:

static void registerWritableFactory() {
  WritableFactories.setFactory(Foo.class, new WritableFactory () { ... });
}

static {
  registerWritableFactory();
}

Then when WritableFactory wants to create an instance of a class, if no factory is registered, it uses reflection to find a "registerWritableFactory" method and calls it, if such a method exists. (We can use setAccessable to make it callable, even if it is not public.), I agree with Owen that DatanodeRegistration as well as other classes passed through RPC should be public.
The counter-patch :-) with only one word added is attached.
Since it is related to HADOOP-124 making some classes non-public,
I would return public status to the exceptions as well.
Just speculating: if RPC would have to convert RemoteException to the real
exceptions like LeaseExpiredException then it would crash for the same reason.
We do not have that mechanism (for converting exceptions) yet, but one day we will., Here is a patch that matches the standard idiom., I just committed this.  Thanks, Owen.]