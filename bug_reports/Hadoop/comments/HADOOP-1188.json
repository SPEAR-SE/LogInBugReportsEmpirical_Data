[+1. Sounds great., It is possible that updating the fstime on the good directories could fail too. So, a namenode restart should pick all those directories that have the latest (and same) fstime and fail to restart if the sizes of the edit files in those directories are not exactly the same., Promoted for consideration in 16.
, This patch writes new time-stamp in fstime file if a directory becomes unavailable.
If writing of the time-stamp fails then this directory is going to be removed as well,
which makes checking of consistency of the edits files lengths on startup redundant.

Inequality of lengths of two edits files does necessarily mean inconsistency of the
storage directories. If one directory contains an image, which has already been
merged with the edits, and another has the image and the edits in the pre-merged
conditions, then the first edits file is empty, while the second is not, but the storage 
directories in fact define the same namespaces, that is they are equivalent., I am still reviewing this patch, but two preliminary comments:

1. If a directory becomes bad, then we increment the timestamp and write the new timestamp into all remaining good directories. If the write of this new timestamp to a good directory fails, then we *again* increment the timestamp and then write this new timestamp to *all* known good directories.

2. This is very crucial piece of namenode code. It would be nice to have a unit test., I was thinking about a unit test, but I cannot figure our how to make it work especially on windows.
I need to make a directory unaccessible while the name-node is still running, but ntfs does not
let you modify anything about open files.
When I debugged this patch on Win I had to mount a "network drive", start name-node with one of 
the directories on the mounted drive, then disconnect the drive and then perform a create or delete.
This works for debugging but I don't know how to make a unit test out of it.
Let me know if you have any ideas., +1. code looks good., I actually found a way to write the test on Windows.  
If I lock fsedits from the outside using FileChannel.lock() or tryLock() the name-node 
would not be able to log name-space operations and will stop using this directory. 
The real problem is to model this behavior on Unix.
Locking is advisory in Unix and the name-node will have to explicitely check for the lock in order to 
fail while synching fsedits. File.delete() or rename() does not help either because once opened the file 
is still accessible via its inode even though the link to the file is removed from the containing directory.
We should open a separate jira if want such a test., I just committed this., Assigning to the lowest version that this appears in.  "Fix Version" should only be a single value., Integrated in Hadoop-trunk #392 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/392/])]