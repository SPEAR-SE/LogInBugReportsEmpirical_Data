[Tests show this problem is harder than it appears, even with improved Interrupt support during the sleep(), you can't interrupt the client while it is actually waiting to connect, that gets swallowed somewhere too. The test case shows this; a thread that tries to wait for 20s for a connection, but which is interrupted in another thread never sees the interrupt, instead after 20s it times out and throws the ConnectionRefused fault. What I'd like would be the interrupt acknowledged with the inner exception nested, and for the operation to fail as soon as the thread is interrupted., Incidentally, this patch converts the InterruptedException to an InterruptedIOException, therefore the signature of the methods do not change, only their behaviour when interrupted. Programs not interrupting threads that were trying to connect to an unresponsive remote server will not see any change in method signature or behaviour., the interrupt is being swallowed in {{Client.call())}}, which blocks until a call completes or times out
{code}
     while (!call.done) {
        try {
          call.wait();                           // wait for the result
        } catch (InterruptedException ie) {
          // save the fact that we were interrupted
          interrupted = true;
        }
      }

      if (interrupted) {
        // set the interrupt flag now that we are done waiting
        Thread.currentThread().interrupt();
      }
{code}

This means that the client thread is blocked until whichever thread is actually doing the RPC. {{Client.waitForWork()}} also swallows interrupts.

This will get complex fast. I think a good tactic would be rather than trying to make the old RPC stack interruptible, focus on making Avro something that you can interrupt, so that going forward you can interrupt client programs trying to talk to unresponsive servers., Retitling this to cover the entire underlying problem: you cannot interrupt a Client if the far end isn't responding. , This issue benefits from the HADOOP-3457 patch, to the extent that to be able to interrupt RPC operations client-side properly, you need the HADOOP-3457 patch applied.

I propose merging, as this patch provides the test , Updated patch incorporating HADOOP-3457 with the tests passing. There are still no guarantees that the underlying IPC classes can be interrupted but now
# the sleeps between attempts to communicate can be interrupted
# InterruptedIOExceptions get passed up, so can be filtered on in client code (including tests), -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12431866/HADOOP-6221.patch
  against trunk revision 904339.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    -1 release audit.  The applied patch generated 2 release audit warnings (more than the trunk's current 1 warnings).

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/304/testReport/
Release audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/304/artifact/trunk/patchprocess/releaseAuditDiffWarnings.txt
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/304/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/304/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/304/console

This message is automatically generated., Updated patch with the ASF header in the test class, which is the probable cause of RAT being unhappy, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12434950/HADOOP-6221.patch
  against trunk revision 906388.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/330/console

This message is automatically generated., patch in sync w/ SVN_HEAD, +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12434971/HADOOP-6221.patch
  against trunk revision 906388.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/331/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/331/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/331/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/331/console

This message is automatically generated., sync up with HEAD, +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12468404/HADOOP-6221.patch
  against trunk revision 1058881.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 2 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/182//testReport/
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/182//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/182//console

This message is automatically generated., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12468404/HADOOP-6221.patch
  against trunk revision 1071364.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 2 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/288//testReport/
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/288//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/288//console

This message is automatically generated., reworking for the various svn structures, Attached the patch for trunk version., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12539301/HADOOP-6221.patch
  against trunk revision acf1e03.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5109//console

This message is automatically generated., -007 patch. In sync with trunk., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12694440/HADOOP-6221-007.patch
  against trunk revision 35f6496.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1206 javac compiler warnings (more than the trunk's current 1204 warnings).

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5475//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5475//artifact/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5475//console

This message is automatically generated., javac warnings about deprecation in junit. This patch is so old it isn't junit4 yet, Patch -008. Modernised test and cleaner checks for underlying exception, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12694520/HADOOP-6221-008.patch
  against trunk revision 7b82c4a.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5479//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5479//console

This message is automatically generated., * At RPC.java:415, won't the following call to {{Thread.sleep()}} check if the interrupt flag is set? Is the explicit check required?
* According to the [docs|http://docs.oracle.com/javase/7/docs/api/java/lang/Thread.html#interrupt%28%29], a thread blocked a a {{Selector}} should set the interrupt flag and return, rather than throwing {{InterruptedIOException}}, but I'm not sure the rest of the RPC stack is consistent. HDFS seems to use it this way, so this is arguably correct.

AFAIK, the only way to forcibly interrupt some IO operations is to close the channel from outside the thread, but implementing that would be more invasive.

+1 overall, FAILURE: Integrated in Hadoop-trunk-Commit #6935 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6935/])
HADOOP-6221 RPC Client operations cannot be interrupted (stevel) (stevel: rev 1f2b6956c2012a7d6ea7e7ba5116d3ad71c23d7e)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPCWaitForProxy.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/SocketIOWithTimeout.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
, Still curious about RPC.java:415. Is the check required?, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #86 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/86/])
HADOOP-6221 RPC Client operations cannot be interrupted (stevel) (stevel: rev 1f2b6956c2012a7d6ea7e7ba5116d3ad71c23d7e)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/SocketIOWithTimeout.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPCWaitForProxy.java
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk #820 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/820/])
HADOOP-6221 RPC Client operations cannot be interrupted (stevel) (stevel: rev 1f2b6956c2012a7d6ea7e7ba5116d3ad71c23d7e)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPCWaitForProxy.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/SocketIOWithTimeout.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #83 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/83/])
HADOOP-6221 RPC Client operations cannot be interrupted (stevel) (stevel: rev 1f2b6956c2012a7d6ea7e7ba5116d3ad71c23d7e)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPCWaitForProxy.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/SocketIOWithTimeout.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #2037 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2037/])
HADOOP-6221 RPC Client operations cannot be interrupted (stevel) (stevel: rev 1f2b6956c2012a7d6ea7e7ba5116d3ad71c23d7e)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/SocketIOWithTimeout.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPCWaitForProxy.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* hadoop-common-project/hadoop-common/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #2018 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2018/])
HADOOP-6221 RPC Client operations cannot be interrupted (stevel) (stevel: rev 1f2b6956c2012a7d6ea7e7ba5116d3ad71c23d7e)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPCWaitForProxy.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/SocketIOWithTimeout.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #87 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/87/])
HADOOP-6221 RPC Client operations cannot be interrupted (stevel) (stevel: rev 1f2b6956c2012a7d6ea7e7ba5116d3ad71c23d7e)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/SocketIOWithTimeout.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPCWaitForProxy.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java
, Bless you [~stevel@apache.org]]