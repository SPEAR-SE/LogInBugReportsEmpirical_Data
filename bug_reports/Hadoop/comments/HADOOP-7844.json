[flush and sync are mainly for DFS. not for local file-systems.
Currently you can invoke them on dfs streams.

so, closing this as invalid. If the issue intention is different, please feel free to reopen it., Uma, the reporter clearly said they expected flush/sync to work for local file systems. Why shouldn't those operations work for the local FS?, Misread the issue, I was thinking about DFS flush/sync. 
Verified it on local FS. Behaviour for flush and should flush the data. Looks only close is flushing the data. seems to be a bug. Let me dig into more.
Reopening it., Reason for not working is, ChecksumFSOutputSummer will hold the data and checksum streams.
 but did not implemented the flush. So, simply it delegates to OutPutStream. So, no data will be flushed., Hi Nathan, Even though we fix the above problem, we can not flush the bytes less than LOCAL_FS_BYTES_PER_CHECKSUM_KEY. Because LocalFileSystem is checksum file system. by default the value is 512 bytes. It maintains the data in internal buffers till then.

Thanks
Uma, Does HDFS have a similar issue with flush (Not flushing everything unless we are at a byte boundary)?  It being a checksum file system as well.  If so then I think we also need to update the documentation about when data is flushed and perhaps even provide an API so that a user can know how many bytes they may need to pad before the flush can happen as expected.  From reading the documentation on trunk for Syncable it does not indicate at all that this might happen.

{code}
  /**
   * @deprecated As of HADOOP 0.21.0, replaced by hflush
   * @see #hflush()
   */
  @Deprecated  public void sync() throws IOException;

  /** Flush out the data in client's user buffer. After the return of
   * this call, new readers will see the data.
   * @throws IOException if any error occurs
   */
  public void hflush() throws IOException;

  /** Similar to posix fsync, flush out the data in client's user buffer 
   * all the way to the disk device (but the disk may have it in its cache).
   * @throws IOException if error occurs
   */
  public void hsync() throws IOException;
{code}, With hsync/hflush at a checksum boundary, we re-write the last checksum into the checksum file at the same time as we append the new data. There is a race during which the new data is there but not the checksum info -- but during recovery operations I believe we deal with this situation by ignoring checksum errors on the last checksum-chunk if there are no replicas with a valid last-chunk., Great! Can we put something like that into LocalFileSystem too in addition to adding in Syncable support to the output streams as described previously?  I doubt there are many people wanting to run production H-Base on top of LocalFileSystem so I would not consider it critical but IMO for testing getting its behavior closer to HDFS would be very nice.  , Yep, something like this could be done, but it's probably low on most people's priority queues., Thanks Todd and Robert for taking a look.
Yes, as Todd explained this will work well for trunk. When i tested there were some issues in 20Append when we sync with <512 bytes multiple times.  leaving bytesperchecksum limitation, at least we can delegate the flush call to actual streams as i explained earlier.(would be low priority) 
, I agree that any changes like that to LocalFileSystem should be low priority.  My bigger concern was with HDFS and obviously Todd has been making sure that it works correctly so I should try harder to stop worrying about it., Somewhat similar to HADOOP-8861. That makes flush/sync work for RawLocalFileSystem but not LocalFileSystem., This issue appears fixed as of March, 2012 with the patches committed in HADOOP-8861, since LocalFileSystem wraps RawLocalFileSystem. When those fixes went in (and sync() came out of Syncable) it fixed this issue., Is this still live? Someone should write a test for it and see if has been fixed by now, This is still live. (Tested with Hadoop 2.5.1)

To reproduce:

{code:java}
public static void main(String[] args) throws IOException {
	FileSystem fs = FileSystem.getLocal(new Configuration());
	Path file = new Path("test.txt");
	try (FSDataOutputStream stream = fs.create(file)) {
		stream.write("foo\nbar\n".getBytes());
		stream.hflush();
		stream.hsync();
		stream.flush();

		new Thread() {
			@Override
			public void run() {
				while (true) {
					try {
						byte[] bytes = Files.readAllBytes(Paths.get("test.txt"));
						System.out.println("content = " + Arrays.toString(bytes));
						Thread.sleep(1000);

					} catch (InterruptedException | IOException e) {
						e.printStackTrace();
					}
				}
			}
		}.start();

		System.out.println("waiting");
		System.in.read();
		System.out.println("closing");
	}
}
{code}

This write some bytes to a local file and tries to get it to disc. The file is closed when pressing return.
Until the file is closed the written bytes are not present. Output is:

{noformat}
waiting
content = []
content = []
content = []
content = []

closing
content = [102, 111, 111, 10, 98, 97, 114, 10]
content = [102, 111, 111, 10, 98, 97, 114, 10]
content = [102, 111, 111, 10, 98, 97, 114, 10]
content = [102, 111, 111, 10, 98, 97, 114, 10]
content = [102, 111, 111, 10, 98, 97, 114, 10]
content = [102, 111, 111, 10, 98, 97, 114, 10]
{noformat}

Using *.getRaw()* solves it.

HADOOP-8861 did not solve the issue because it just added a call to *flush()* if the _wrappedStream_ is not _Syncable_. However _ChecksumFSOutputSummer_ inherits an empty *flush()* and therefore does nothing.

]