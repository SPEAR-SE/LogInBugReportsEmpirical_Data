[Here's the stack trace. It is actually being raised in the NameNode, when Server.call tries to change the access permissions on the local method that is about to be invoked

{code}
Caused by: RemoteException:: java.io.IOException: java.security.AccessControlException: access denied (java.lang.reflect.ReflectPermission suppressAccessChecks)
at java.security.AccessControlContext.checkPermission(AccessControlContext.java:323)
at java.security.AccessController.checkPermission(AccessController.java:546)
at java.lang.SecurityManager.checkPermission(SecurityManager.java:532)
at java.lang.reflect.AccessibleObject.setAccessible(AccessibleObject.java:107)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:505)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
, SmartFrog 3.17.007dev (2009-04-22 16:55:37 BST)
at org.apache.hadoop.ipc.Client.call(Client.java:732)
at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
at $Proxy0.getProtocolVersion(Unknown Source)
at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:346)
at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:383)
at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:314)
at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:291)
at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:306)
at org.apache.hadoop.hdfs.server.datanode.DataNode.innerStart(DataNode.java:232)
at org.apache.hadoop.hdfs.server.datanode.ExtDataNode.innerStart(ExtDataNode.java:79)
at org.apache.hadoop.util.Service.start(Service.java:186)
at org.smartfrog.services.hadoop.components.cluster.HadoopServiceImpl.innerDeploy(HadoopServiceImpl.java:504)
at org.smartfrog.services.hadoop.components.cluster.HadoopServiceImpl.access$000(HadoopServiceImpl.java:54)
at org.smartfrog.services.hadoop.components.cluster.HadoopServiceImpl$ServiceDeployerThread.execute(HadoopServiceImpl.java:760)
at org.smartfrog.sfcore.utils.SmartFrogThread.run(SmartFrogThread.java:279)
at org.smartfrog.sfcore.utils.WorkflowThread.run(WorkflowThread.java:117)
{code}, Incidentally, before anyone says "add that permission", this is the permissions file that I believe I'm using

{code}
grant {
  permission java.security.AllPermission;
};

// Standard extensions get all permissions by default
grant codeBase "file:${java.home}/lib/ext/*" {
	permission java.security.AllPermission;
};
{code}

That is: all rights should have been granted. 

People who aren't running hadoop services under a security manager won't encounter this problem, so I'm marking it as minor.
, catching and logging the setAccessible operation allows the method call to proceed, but other problems surface

1. I get some access control problems
{code}
[sf-startdaemon-debug] java.io.IOException: java.security.AccessControlException: access denied (javax.security.auth.AuthPermission getSubject)
[sf-startdaemon-debug] 	at java.security.AccessControlContext.checkPermission(AccessControlContext.java:323)
[sf-startdaemon-debug] 	at java.security.AccessController.checkPermission(AccessController.java:546)
[sf-startdaemon-debug] 	at java.lang.SecurityManager.checkPermission(SecurityManager.java:532)
[sf-startdaemon-debug] 	at javax.security.auth.Subject.getSubject(Subject.java:268)
[sf-startdaemon-debug] 	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:84)
[sf-startdaemon-debug] 	at org.apache.hadoop.security.UserGroupInformation.getCurrentUGI(UserGroupInformation.java:44)
[sf-startdaemon-debug] 	at org.apache.hadoop.hdfs.server.namenode.NameNode.mkdirs(NameNode.java:642)
[sf-startdaemon-debug] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[sf-startdaemon-debug] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
[sf-startdaemon-debug] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
[sf-startdaemon-debug] 	at java.lang.reflect.Method.invoke(Method.java:597)
[sf-startdaemon-debug] 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:516)
[sf-startdaemon-debug] 	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
[sf-startdaemon-debug] 	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
[sf-startdaemon-debug] 	at javax.security.auth.Subject.doAs(Subject.java:396)
[sf-startdaemon-debug] 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
{code}

2. RMI stops working
{code}
java.lang.SecurityException: attempt to add a Permission to a readonly Permissions object
at java.security.Permissions.add(Permissions.java:110)
at java.security.Policy$UnsupportedEmptyCollection.add(Policy.java:790)
at sun.rmi.server.LoaderHandler.getLoaderAccessControlContext(LoaderHandler.java:985)
at sun.rmi.server.LoaderHandler.lookupLoader(LoaderHandler.java:861)
at sun.rmi.server.LoaderHandler.loadClass(LoaderHandler.java:385)
at sun.rmi.server.LoaderHandler.loadClass(LoaderHandler.java:165)
at java.rmi.server.RMIClassLoader$2.loadClass(RMIClassLoader.java:620)
at org.smartfrog.sfcore.security.SFRMIClassLoaderSpi.loadClass(SFRMIClassLoaderSpi.java:90)
at java.rmi.server.RMIClassLoader.loadClass(RMIClassLoader.java:247)
at sun.rmi.server.MarshalInputStream.resolveClass(MarshalInputStream.java:197)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1575)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1496)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1732)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351)
at sun.rmi.server.UnicastRef.unmarshalValue(UnicastRef.java:306)
at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:290)
at sun.rmi.transport.Transport$1.run(Transport.java:159)
at sun.rmi.transport.Transport.serviceCall(Transport.java:155)
at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)
at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
at java.lang.Thread.run(Thread.java:619)
at sun.rmi.transport.StreamRemoteCall.exceptionReceivedFromServer(StreamRemoteCall.java:255)
at sun.rmi.transport.StreamRemoteCall.executeCall(StreamRemoteCall.java:233)
at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:142)
{code}

Now, this could be my fault for using RMI, but I think a trigger for a lot of this trouble is line 959 of hadoop.ipc.Server, which invokes things as the user who made the remote call. And that somehow switching to a new user for the call is causing problems when running under a security manager, because the user making the call isnt trusted enough., I think this was triggered by HADOOP-4348, which adds (needed) user level auth and the runAs() code to hadoop IPC; this appears to be an unexpected consequence of the tighter security.

I will bring my branch up to sync with SVN_HEAD next week, see if the problem is still there, and if it is, see if there is a way to fix it. It may also be useful to add some tests to Hadoop which run under a security manager, though that is tricky to set up inside junit., In the current design, it is not expected to run Hadoop with SecurityManager due to performance reason.  Of course, it would be great if we can fix this.

See also [Arun's comment|https://issues.apache.org/jira/browse/HADOOP-4348?focusedCommentId=12643117&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12643117]., HADOOP-6452 is the root cause of the RMI-related stack trace. With that patch in, there is one less reason why you can't run Hadoop under a security manager if you so desire., Reviewing this, the risk is if a client running under a security manager tries to talk over IPC then it will fail. There's an obvious test for this to see if it's a real issue. I'm not sure it would surface in a webapp, which is the place that it would matter the most. they tend to play classloader games more than anything else, Nobody else is seeing/complaining about this. WONTFIX]