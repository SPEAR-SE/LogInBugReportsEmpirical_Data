[it appears "owner" string is empty in your case - the code that threw this exception is below

    if (fs.exists(stagingArea)) {
      FileStatus fsStatus = fs.getFileStatus(stagingArea);
      String owner = fsStatus.getOwner();
      if (!(owner.equals(currentUser) || owner.equals(realUser)) || 
          !fsStatus.getPermission().equals(JOB_DIR_PERMISSION)) {
         throw new IOException("The ownership/permissions on the staging " +
                      "directory " + stagingArea + " is not as expected. " + 
                      "It is owned by " + owner + " and permissions are "+ 
                      fsStatus.getPermission() + ". The directory must " +
                      "be owned by the submitter " + currentUser + " or " +
                      "by " + realUser + " and permissions must be rwx------");
      }
    } else {

can you check who owns your stagingArea (example, /user/root/.staging)

if you clean the stagingarea can you submit successfully?
, The problem is that file metadata for the block-based S3 filesystem (org.apache.hadoop.fs.s3.S3FileSystem) does not store the file owner. This would need adding to INode to fix this issue.  , checked further

looks like the fsStatus.getOwner() returned an empty string for s3 file system(initialized to am empty string - "").  
The job/stagingarea group/user ownership checks are part of hadoop-22 secure job submission. 

It appears these checks won't work with existing s3 implementation 



, Doesn't seem a blocker for any release.  Downgrading to Critical., I've experienced the same error on 0.20.2 (cloudera's cdh3u0) when submitting a job and restarting the JobTracker. In both cases, the ownership of paths is checked.

For the quick and dirty solution, I've patched core/org/apache/hadoop/fs/s3/S3FileSystem.java and added the following method to the S3FileStatus inner class:

{noformat}
public String getOwner() {
  return System.getProperty("user.name");
}   
{noformat}

For my use case this works, but it probably should use proper acl stuff.
, I blocked the logic using FileStatus.getPath().getUri().getScheme().
if it is 's3' or 's3n' (case-insensitive), then skip the logic.
Eventually, I added a new boolean variable in FileStatus.Java; boolean iss3
and I added a new method which returns the iss3 value; boolean isS3()
and edit JobSubmissionFiles.java and JobTracker.java using isS3() method.
, Likely stale.]