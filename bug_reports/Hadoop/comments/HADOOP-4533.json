[This seems to have been caused by HADOOP-4116, based on Nicholas' testing., > ...  based on Nicholas' testing.

Reproduce this
- start a 0.18.1 cluster
- write a file by a 0.18.2 client, e.g. {{hadoop fs -put src dst}}
- It will fail with similar error messages shown in the description.

It won't fail if the patch in HADOOP-4116 is reverted., It looks like we need 2 patches here:
- for 0.18 the incompatible change in data transfer protocol should be removed.
- for 0.19 we need to provide a clear message saying that data transfer protocols are incompatible rather than "Could not read from stream", Ok, I reverted HADOOP-4116 in branch 18. This patch removes the incompatible change in the patch to HADOOP-4116 but keeps the critical code to prevent the Balancer from overusing network bandwidth and avoid the deadlock problem that was described in HADOOP-4116., +1
This looks reasonable for 0.18. It fixes the semaphore contention problem and retains the data transfer protocol compatible across 0.18
We need to run tests with this patch.
For 0.19 and 0.20 it is better to open another jira. , Konstantin, the junit tests have passed. I will test this patch on a real dfs cluster. For 0.19 and 0.20, we keep the patch to HADOOP-4116. We should open a jira on Could not read from stream" problem for 0.19 or 0.20., > We should open a jira on Could not read from stream" problem for 0.19 or 0.20.

Created HADOOP-4538, Unit test passed and here is the ant test-patch result:
     [exec] +1 overall.

     [exec]     +1 @author.  The patch does not contain any @author tags.

     [exec]     +1 tests included.  The patch appears to include 3 new or modified tests.

     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.

     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

     [exec]     +1 findbugs.  The patch does not introduce any new Findbugswarnings.

, I've committed this.]