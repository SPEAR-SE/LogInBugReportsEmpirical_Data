[According to our test on hadoop snappy on ppc64 platform, length of generated .snappy file is almost empty. After days of investigation we finally located the problem and below are the analysis:

size_t is defined as "unsigned long int" on 64 bit platform, and jint is defined as "signed 32bit int"(http://docs.oracle.com/javase/1.5.0/docs/guide/jni/spec/types.html for the jni spec), so if we cast size_t type pointer to jint, it will cut-off 32bit values in the higher adress and only reserve those in the lower address; If the platform is Big-Endian, and the value stored in the pointer is less than 0xffffffff, then value get through the post-cast pointer will be 0.

Here is a simple program can prove the above analysis:
{code:title=test.c|borderStyle=solid}
#include <stdio.h>
#include <jni.h>

void main(){
  jint x;
  size_t * p_x = &x;

  * p_x = 0x01;
  printf("****************************************\n");
  printf("Test-1: value less than 0x7fffffff\n");
  printf("Before pointer type cast: %ld\n",*p_x);
  printf("After pointer type cast: %ld\n",x);
  printf("After value type cast: %ld\n",(jint)*p_x);
  printf("****************************************\n");

  * p_x = 0x80000000;
  printf("Test-2: value larger than 0x7fffffff\n");
  printf("Before pointer type cast: %ld\n",*p_x);
  printf("After pointer type cast: %ld\n",x);
  printf("After value type cast: %ld\n",(jint)*p_x);
  printf("****************************************\n");

  * p_x = 0x1ffffffff;
  printf("Test-3: value larger than 0xffffffff\n");
  printf("Before pointer type cast: %ld\n",*p_x);
  printf("After pointer type cast: %ld\n",x);
  printf("****************************************\n");
}
{code}

And here is the test result:
{noformat}
****************************************
Test-1: value less than 0x7fffffff
Before pointer type cast: 1
After pointer type cast: 0
After value type cast: 1
****************************************
Test-2: value larger than 0x7fffffff
Before pointer type cast: 2147483648
After pointer type cast: 0
After value type cast: -2147483648
****************************************
Test-3: value larger than 0xffffffff
Before pointer type cast: 8589934591
After pointer type cast: 1
****************************************
{noformat}

Test-1 proves the data loss caused by pointer type cast (as we observed in snappy of branch-1 hadoop), Test-2 proves the necessarity to set JINT_MAX as done in HADOOP-8686, Test-3 proves the higher 32 bit(store in lower address as big-endian) will be preserved with lower 32 bit cut-off

The patch attached probably can help better understand this issue., In the attached patch I've only backported the changes made on SnappyCompressor.c in HADOOP-8686 to save some time because other parts are not that critical. Please let me know if you prefer me to backport the whole patch, thanks., JINT_MAX assumes a fixed size for 64bit signed integer. This may not always be the case for other platforms.  It would be good to use:

#include <limits.h>, and check with INT_MAX instead.
, Sorry, what I said in previous comment is not right, JINT_MAX is 32 bit signed int.  This is defined in jni type spec.  Hence, the patch is correct as it is.  +1 looks good., Thanks Eric for the review, have submitted the patch for Hadoop QA to test., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12597363/HADOOP-9863.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2962//console

This message is automatically generated., Since this is a branch-1 patch, seems Hadoop QA has some problem testing it.

Here is the result of test-patch on my local env:

  {color:red}-1 overall.{color}

      {color:green}+1 @author.{color}  The patch does not contain any @author tags.

      {color:red}-1 tests included.{color}  The patch doesn't appear to include any new or modified tests.
                          Please justify why no tests are needed for this patch.

      {color:green}+1 javadoc.{color}  The javadoc tool did not generate any warning messages.

      {color:green}+1 javac.{color}  The applied patch does not increase the total number of javac compiler warnings.

      {color:red}-1 findbugs.{color}  The patch appears to introduce 239 new Findbugs (version 2.0.1) warnings.
, Yu, can you port this patch to trunk or branch2?, Hi Tian Hong,

This is a partial backport of HADOOP-8686, which is already in trunk/branch2 but missing in branch1. , +1 looks good.  I just committed this.  Thank you, Yu Li., Thanks Eric!]