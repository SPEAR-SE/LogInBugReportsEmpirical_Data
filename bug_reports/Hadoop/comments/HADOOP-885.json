[
In addition, isn't RPC supposed to use persistent connections? From the stats above seem to using new connection for every RPC call., If the required time resolution is one second, a thread that calls gettimeofday, updating a global variable, and sleeps for a second would remove virtually all those system calls.

as for the RPC - it was agreed that the namenode would be hard pressed to maintain the number of connections, so connections are cached for a very short time to enable short sessions with clients and are then torn down. in the case of heartbeats the caching is much smaller than the delay between heartbeats.
reviving an old discussion, UDP will improve performance *a lot*. It would require a mechanism for delivering large messages that don't fit in a single packet, but in the overwhelming majority of cases message are small and the performance improvement will be significant. Seven overhead packets and a lot of kernel processing just to send a single packet for a single reply is a high price to pay., Regarding gettimeofday: I agree with you. In fact, it might be true that most places do not even need a 1 second precision. Maybe a 5 second precision or so. A code inspection will reveal this.

Regarding keeping RPC connections open: I had a 900 node cluster on which no jobs were running. In this case, there should have been only 900 connections to the namenode (one from each datanode). Also, the config value  ipc.client.maxidletime has been set to 120 seconds which means that a connection will be closed only after 120 seconds of inactivity. I  had observed (in the dfshealth.jsp page) that heartbeats from all datanodes were being processed within 3 seconds or so. There is another config parameter  ipc.client.idlethreshold that specifies the threshold number of connections that triggers connection reaping. The default is set to 4000 connections.

So, it is still a mystery to me why connections were getting reaped so aggressively?
, Regarding gettimeofday, even if you can get away with 5 second resolution I'd go with 1.
The overhead becomes totally negligible and for purposes of time stamping events such as file creation time we, as human users, like one-second resolution., Here is a class that returns the current time with a 1 second resolution. I have compared the performance of this class with that of calling System.currentTimeMillis(). Here are the results:

currentTimeMillis() invokes 1million times : 1661 second
WallClock.gettime() invokes 1 million times: 15 ms

I would like some review comments about this piece of code. Since none of the methods are synchronized, it needs careful review., The above should read:

currentTimeMillis() invokes 1million times : 1661 ms
WallClock.gettime() invokes 1 million times: 15 ms , 
Thread.sleep() not throwing an exception does not imply accuracy of sleep time. Most of the time it wont throw an exception: 

How about some extremely simple implementation like:

run() :  { while (true) {
                try { 
                    Thrread.sleep(sleepTime);
                catch ( InterruptedException ignored ) {}
                curTime = System.currentTimeMillis()/1000 // and round it.
            }
}
getTime () { rerurn curTime }.
, Dhruba,

WallClock works only when the timing thread gets a chance to execute, which in a heavily multithreaded app like namenode may not get any chance at all for a few seconds (especially if all threads are doing cpu intensive work). so, there is no way to guarantee that this resolution is maintained by the clock (one could play with thread priorities to achieve that.)

Also, your benchmark numbers are misleading because in 15 ms, WallClock gets only one call to currrentTimeMillis (assuming 10ms interval between context-switching). so, even when I change the 1 second resolution and make it 1 ms, I get the same timing, but without the 1ms resolution requested., Of course, we should not be depending on the fact that Thread.sleep() is accurate. Here is a modified patch, Please review.

Regarding benchmark numbers, I think the comparision that I am doing is fair. In fact, the design goal is such that the precision really does not matter. In fact, the earlier commentary in the issue describes that there should really be no difference whether the precision is 1 second or 5 seconds.  The quantity to measure is the time difference between System.curTime() vs WallClock.gettime(). This is precisely what my measurement shows.
, Another vresion of WallClock.java. This version uses a 'volatile long' member to store the latest time., +1

We should probably restrict precision to more than 100ms. In practice, we would  never set precision.
 , The default settings for ipc.client.connection.maxidletime is 1 second. Heartbeats are 3 seconds. This must be the reason why we see a large number of accept(0 and close() calls. I propose that we change the default value of ipc.client.connection.maxidletime from 1 to 4 seconds., Changed all calls to System.currentTimeMillis() to use WallClock.

Changed default value of ipc.client.connection.maxidletime from 1 to 4 seconds., 
Should we have different patch for maxIdleTime change?

The main cost of keeping connections longer is the cost of poll() and iterating in cleanupConnections(). This cost will become more significant with larger number of clients and datanode. I would suggest following changes

  1) cleanupConnections() should be called only once in few seconds. 
  2) we should start using epoll() added in JDK 1.5.10 (this is a java cmd line option)  http://java.sun.com/j2se/1.5.0/ReleaseNotes.html#150_10 

With these we can set timeout much higher, may be 1 minute.

, I included the change to maxIdleTime in that patch because this patch reduces CPU consumption on the namenode. Regarding epoll(), it appears to me that is could be very platform specific and currently implemented only on Linux 2.6. If this is true, then I would like to avoid using it at present. Please let me know if you concur.
, 
Sine we poll on idle connections, there is cpu cost even for idle connections. In that sense, increasing it to 4 sec would actually increase cpu cost on large clusters. Of course, I don't have much justification for 1 sec either :).

Using epoll() is not platform dependent since it does not change Java API. Its just a cmd line option. We could set this only on Linux in hadoop-env.sh. 

Also, we should call cleanupConnections()  only once or twice in maxIdleTime. 

Though changing it 4 sec is a very small change, it is different from getTime() change.  We could open another Jira on this.
, This issue arose because of the fact that java 1.5 was being used and the poll() for sockets consumed lots of CPU. The CPU consumption of an idle 900 node cluster came down to 4 to 5% when java 1.6 was used. gettimeofday is hardly consumes much CPU. 

I am going to close this JIRA as "Wont-fix"., This issue arose because of the fact that java 1.5 was being used and the poll() for sockets consumed lots of CPU. The CPU consumption of an idle 900 node cluster came down to 4 to 5% when java 1.6 was used. gettimeofday is hardly consumes much CPU.

I am closing his JIRA as "Wont-fix".]