[I figured the clearest way to explain this is to put the call stack:
{noformat}
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:461)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:331)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:322)
	at org.apache.hadoop.crypto.key.KeyProviderFactory.get(KeyProviderFactory.java:95)
	at org.apache.hadoop.util.KMSUtil.createKeyProvider(KMSUtil.java:65)
	at org.apache.hadoop.hdfs.DFSUtil.createKeyProvider(DFSUtil.java:1851)
	at org.apache.hadoop.hdfs.KeyProviderCache$2.call(KeyProviderCache.java:73)
	at org.apache.hadoop.hdfs.KeyProviderCache$2.call(KeyProviderCache.java:70)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4767)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3568)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2350)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2313)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2228)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3965)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4764)
	at org.apache.hadoop.hdfs.KeyProviderCache.get(KeyProviderCache.java:70)
	at org.apache.hadoop.hdfs.DFSClient.getKeyProvider(DFSClient.java:3570)
	at org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(DFSClient.java:1408)
	at org.apache.hadoop.hdfs.DFSClient.createWrappedOutputStream(DFSClient.java:1521)
	at org.apache.hadoop.fs.Hdfs.createInternal(Hdfs.java:108)
	at org.apache.hadoop.fs.Hdfs.createInternal(Hdfs.java:59)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:577)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:683)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:679)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:679)
	at org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter$1.run(AggregatedLogFormat.java:385)
	at org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter$1.run(AggregatedLogFormat.java:380)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1710)
	at org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.<init>(AggregatedLogFormat.java:379)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.uploadLogsForContainers(AppLogAggregatorImpl.java:246)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregation(AppLogAggregatorImpl.java:456)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.run(AppLogAggregatorImpl.java:421)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$2.run(LogAggregationService.java:386)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
{noformat}
So there's a {{KeyProviderCache}} which caches the KeyProvider object by the configured URI. Meanwhile, {{KMSClientProvider}} has this {{actualUGI}} cached for the creator UGI. This is fine for transient clients, but problematic for long-running processes like Node Manager. 
When NM impersonate the client and use client's delegation token to run MR job, {{KMSClientProvider}} should favor client's DT, not the cached ones which may have long been expired., The {{KeyProviderCache}} is necessary according to HDFS-7718.

To fix the issue, I can think of 2 options:
- Change the cache to recognize different clients.
- Update KMSClientProvider to favor new tokens.
I chose option #2 because #1 would increase {{KeyProvider}} object based on client number, and even so we still need to update the tokens since after a MR job, a token may be explicitly cancelled.


This is more of an end-to-end thing, but I tried to mimic it in TestKMS to keep it simple. Patch 1 attached.

Thanks [~rkanter] again for helping me understand Yarn log aggregation! Ping [~asuresh] / [~andrew.wang] for review, thank you in advance., [~asuresh] do you think you can review this one? The fix is a one-liner, but the discussion here is mostly about YARN, and it looks like you wrote the original cache code., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 33s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  6m 59s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 16s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 47m  5s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12818255/HADOOP-13381.01.patch |
| JIRA Issue | HADOOP-13381 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux c550c20e093f 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ea9f437 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10010/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10010/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Thanks for the opening this [~xiaochen]..
I think your approach is definitely simpler than modifying the cache to key with a composite key of URI + ugi current user.
But I think the bigger issue is that it looks like the {{ClientContext}} in which the {{KeyProviderCache}} is maintained is not a per user cache. Can you confirm [~cmccabe] / [~andrew.wang]? , Thanks [~asuresh] for the response.

Colin and Andrew can confirm on the {{ClientContext}}, but I think the problem here is the cached {{actualUgi}} inside the {{KMSClientProvier}}. Since the same client will get the provider from cache, the {{actualUgi}} in the cached provider is in turn cached, without updated credentials. Later, the DT is fetched out of the UGI's out-dated credentials ([code|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/web/DelegationTokenAuthenticatedURL.java#L290-L296])., I had an offline discussion with [~asuresh], and here's the minute:
- Arun brought up the point that there's {{authRetry}} in KMSCP, and when {{authToken}} is expired, a new {{DelegationTokenAuthenticatedURL.Token}} is created and the call is retried.
  This doesn't help in our case, since [(code inside the call)|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/web/DelegationTokenAuthenticatedURL.java#L290-L296] the UGI's credentials are used to get the kms-dt, which would be the same expired token.
- Regarding Yarn log aggregation, I explained that MR jobs will get tokens and run, and in the end NM will use that job's tokens to do Yarn log aggregation as a final MR job. So this part should be done as the MR user (as opposed to NM user: yarn), since this writes to the MR user's dir {{/tmp/logs/user/....}}. cc [~rkanter] in case anything I said is not accurate.
- To minimize impact, we should only update {{kms-dt}} in the call.
- Arun has a general concern on updating the actualUgi's token, since normal use case is doAs / proxy user. This could be enhanced in another jira.


(My thought after the discussion): to counter the race that multiple threads calling the same cached KMSCP, we should create a new UGI object and update the tokens.
Will update a patch with more details., bq. the race that multiple threads calling the same cached KMSCP
The problem becomes tougher when considering multi-thread.... The cached {{actualUgi}} is to handle proxy users, per HADOOP-10698 and HADOOP-11176, so we need that as initial UGI.

For the DT case, we want to pass in the latest credentials. However, the DT-fetching always happens inside {{actualUgi.doAs}}, which is cached and not updated. I can see the race where more than 1 thread in comment #1 reaching the same KMSCP, and what we do here would be troublesome.

Don't see a decent solution so far, need more thoughts... Feel free to speak up if any suggestions., So... I was thinking we should do the following:
# Ensure the NM creates the DFSclient on boot up, so that the acutalUgi is the yarn user
# Add a method in {{UserGroupInformation}} to remove credentials, so that you can remove the KMS-DT from the actualUgi.
# After the token has expired and when we get an authorization exception, we, in addition to flushing the authToken (line 592 in KMSClientProvider), we also call the new method I mentioned in the previous point to remove the KMS-DT.
# Then, we let the retry happen, at which point it will get a new delegation token.
makes sense ?
 , Thanks [~asuresh] for the quick response! The flow you mentioned would work, assuming we loosen the retry check of response message ([these lines|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java#L584-L587]), and add the remove token method to UGI.

On the multi-thread side, did I miss anything? If many threads running in {{LogAggregationService}} try to do log aggregation, and end up with the same cached KMSCP, would this cause a race? IMO this problem exists before this patch, but maybe I missed something... I don't think the cached {{authToken}} work under this scenario.
, bq. ..assuming we loosen the retry check of response message..
Agreed... I guess that should be fine..

With respect to the race condition, am not really worried.. the worst that can happen, if we follow the flow I specified in my earlier comment (when multiple threads call the same KMSClientProvider at  a time when the DT has expired), is that.. simultaneous refreshes of the UGI's credentials will happen, but dont think there would be any UGI state inconsistency. Besides, the UGI::addCredential is synchronized on the subject., Thank you for the continued discussion, Arun.

Sorry I missed 1 point in your proposal... it wouldn't work as we hoped.
bq. 4. Then, we let the retry happen, at which point it will get a new delegation token.
IIUC, the {{authToken}} was to cache past successful authentications (so we don't have to authenticate every time). It does not 'get a new delegation token'. Instead, it just gets the {{kms-dt}} from the UGI's current user inside {{DelegationTokenAuthenticatedURL#openConnection}}, which happens inside the {{actualUgi.doAs}} in {{KMSCP#createConnection}}. So retries will still see the same expired DT (or no DT at all if we remove it). We have to get the DT from UGI's current user before actualUgi.doAs... right?

Let me elaborate on the race I was thinking:
I did a test as follows:
# set {{/tmp}} as an EZ
# run a MR job (wordcount) as user {{mapred}}, over {{/tmp}}. Let's call this job1
# run a MR job (wordcount) as user {{impala}}, over {{/tmp}}. Let's call this job2.
# get below logs from my customized logging in {{KMSCP#createConnection}}

{noformat}
2016-07-19 14:35:18,306 INFO org.apache.hadoop.crypto.key.kms.KMSClientProvider: ==== currentUGI:impala (auth:SIMPLE) creds: [Kind: kms-dt, Service: 172.31.9.35:16000, Ident: 00 06 69 6d 70 61 6c 61 04 79 61 72 6e 00 8a 01 56 05 15 10 22 8a 01 56 05 17 cf 42 02 02, Kind: mapreduce.job, Service: job_1468963667277_0002, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@2e951fb5), Kind: HDFS_DELEGATION_TOKEN, Service: 172.31.9.72:8020, Ident: (token for impala: HDFS_DELEGATION_TOKEN owner=impala@GCE.CLOUDERA.COM, renewer=yarn, realUser=, issueDate=1468964081478, maxDate=1468964381478, sequenceNumber=216, masterKeyId=20)]
2016-07-19 14:35:18,307 INFO org.apache.hadoop.crypto.key.kms.KMSClientProvider: ==== actualUGI: mapred (auth:SIMPLE) creds: [Kind: kms-dt, Service: 172.31.9.35:16000, Ident: 00 06 6d 61 70 72 65 64 04 79 61 72 6e 00 8a 01 56 05 11 b5 db 8a 01 56 05 14 74 fb 01 02, Kind: mapreduce.job, Service: job_1468963667277_0001, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@7fdacda0), Kind: HDFS_DELEGATION_TOKEN, Service: 172.31.9.72:8020, Ident: (token for mapred: HDFS_DELEGATION_TOKEN owner=mapred@GCE.CLOUDERA.COM, renewer=yarn, realUser=, issueDate=1468963861782, maxDate=1468964161782, sequenceNumber=215, masterKeyId=20)]
{noformat}
Note here the actual UGI is entirely mapred's. If job1 is about to {{actualUgi.doAs}} while job2 updated the credentials in {{actualUgi}}, job1 will then see job2's dt when the invocation goes into DTAURL..... right?

My drive-home thinking is that we should doAs current ugi in this specific case (or retry with currentUGI).... Namely, when [this|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java#L535] is null., I extended my above thought further, and think that's the decent way to fix this.

Attaching patch 2 to demonstrate the idea, I can also verify from end-to-end if we agree on this approach.

Could you take a look, [~asuresh]? Thanks a lot!, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 35s{color} | {color:red} hadoop-common-project/hadoop-common generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 41s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 17s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 46m  9s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-common-project/hadoop-common |
|  |  Load of known null value in org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(URL, String)  At KMSClientProvider.java:in org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(URL, String)  At KMSClientProvider.java:[line 542] |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12819148/HADOOP-13381.02.patch |
| JIRA Issue | HADOOP-13381 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux dccc7992d7f2 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 38128ba |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/10039/artifact/patchprocess/new-findbugs-hadoop-common-project_hadoop-common.html |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10039/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10039/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Patch 3 to make findbugs happy.

[~asuresh],
Could you please take a look at this when you have a chance? I feel this is the better way to fix the issue: if there's a DT present, then underlying user doesn't matter, and we doAs the DT's UGI to use it. Otherwise, we keep existing behavior.
Thanks in advance., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 22s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m  9s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 17s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 46m 46s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12820067/HADOOP-13381.03.patch |
| JIRA Issue | HADOOP-13381 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 5427676dfd36 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d383bfd |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10081/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10081/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, I agree.. I also prefer what you've done in v03.

Minor nit:
You can maybe replace the huge if else with:

{noformat}
UserGroupInformation ugiToUse = (currentUgiContainsKmsDt() && doAsUser == null) ? currentUgi : actualUgi;
conn = ugiToUse.doAs(new PrivilegedExceptionAction<HttpURLConnection>() {
  @Override
  public HttpURLConnection run() throws Exception {
    DelegationTokenAuthenticatedURL authUrl =
        new DelegationTokenAuthenticatedURL(configurator);
    return authUrl.openConnection(url, authToken, doAsUser);
  }
});
{noformat}, Thank you for the nice suggestion, [~asuresh].
Patch 4 attached to address it., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m  1s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 12s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 47m 50s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12820780/HADOOP-13381.04.patch |
| JIRA Issue | HADOOP-13381 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 0389f1bd4d9b 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 26de4f0 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10110/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10110/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, +1, Thanks for taking care of this [~xiaochen], Thanks Arun, committing this., Committed to trunk and branch-2. There is a minor conflict (imports) when backporting to branch-2, compiled and made sure {{TestKMS}} pass before pushing.

Thanks a lot [~asuresh] for the thoughtful reviews, and [~andrew.wang] for chiming in!, SUCCESS: Integrated in Hadoop-trunk-Commit #10176 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10176/])
HADOOP-13381. KMS clients should use KMS Delegation Tokens from current (xiao: rev 8ebf2e95d2053cb94c6ff87ca018811fe8276f2b)
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
, This one is labelled with target version Hadoop-2.8 but somehow missed from branch-2.8.
Propose to backport this to branch-2.8, the cherrypick from branch-2 commit is clean and TestKMS passed successfully.  What do you think, [~xiaochen]., Sure [~xyao], just pushed this to branch-2.8., Thanks [~xiaochen] for the quick response. ]