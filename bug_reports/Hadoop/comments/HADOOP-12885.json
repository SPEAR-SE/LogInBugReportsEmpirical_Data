[Hello [~liushaohui].  There have been several recent bug fixes in this area.  Please see HADOOP-12634 and HADOOP-12780.  If it looks like these address the problem you saw, then would you please close this as a duplicate issue?  Thank you.

Cc [~gouravk], [~madhuch-ms], [~onpduo], [~dchickabasapa]., Thanks for your reminding~ [~cnauroth]
I think this problem is different from HADOOP-12634 and HADOOP-12780., [~liushaohui], interesting...  I think you're right that this one is different.  I have not seen cases of duplicates showing up in the rename pending list like you showed in the description.  Cc [~gouravk], [~madhuch-ms], [~onpduo], [~dchickabasapa] to check if any of them have seen something like this., I agree; [~madhuch-ms] since you worked on this specifically in the latest instance does this look like a case that can happen and we might have missed? 

Also is it possible this might be a regression due to latest fixes?, [~liushaohui] Could you please share the logs, a cluster where you are able to repro this issue and the storage account details of the cluster? And are you getting this error when the first rename happened, or after some crash happened, and we are trying to redo the pending renames?, [~liushaohui] Some more doubts
How often you are facing this? Are you seeing this frequently across many clusters in production?, bq. ...storage account details of the cluster...

Please do not share any passwords, ssh keys, or any other forms of private credentials over Apache JIRA.  This is a public forum, and you wouldn't want to let the whole Internet into your cluster.  :-)  I apologize if I misinterpreted this comment, but I wanted to make sure no one was compromised by mistake.

Sharing additional logs though would be fine to help troubleshoot root cause., [~madhuch-ms]
{quote}
Could you please share the logs, a cluster where you are able to repro this issue and the storage account details of the cluster?
{quote}
The storage account is xiaomitst2 in Central India and the container is named xiaomi. The state of container didn't be changed after this issue. The RenamePending.json(/hbase/azurtst-xiaomi/data/default/YCSBTest-RenamePending.json) is still there.

{quote}
And are you getting this error when the first rename happened, or after some crash happened, and we are trying to redo the pending renames?
{quote}
The exception when  the first rename happened
{code}
2016-02-29,05:58:57,780 ERROR org.apache.hadoop.hbase.master.handler.TableEventHandler: Error manipulating table YCSBTest
org.apache.hadoop.fs.azure.AzureException: Source blob hbase/azurtst-xiaomi/data/default/YCSBTest/5f882f5492c90b4c03a26561a2ee0a96/.regioninfo does not exist.
        at org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.rename(AzureNativeFileSystemStore.java:2405)
        at org.apache.hadoop.fs.azure.NativeAzureFileSystem$FolderRenamePending.execute(NativeAzureFileSystem.java:413)
        at org.apache.hadoop.fs.azure.NativeAzureFileSystem.rename(NativeAzureFileSystem.java:1997)
        at org.apache.hadoop.hbase.master.MasterFileSystem.moveTableToTemp(MasterFileSystem.java:586)
        at org.apache.hadoop.hbase.master.handler.DeleteTableHandler.handleTableOperation(DeleteTableHandler.java:105)
        at org.apache.hadoop.hbase.master.handler.TableEventHandler.process(TableEventHandler.java:129)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{code}
When we are trying to redo the pending renames,  it encounter the bug mentioned in HDFS-9897
{code}
java.io.IOException: Attempting to complete rename of file hbase/azurtst-xiaomi/data/default/YCSBTest/.tabledesc during folder rename redo, and file was not found in source or destination.
        at org.apache.hadoop.fs.azure.NativeAzureFileSystem$FolderRenamePending.finishSingleFileRename(NativeAzureFileSystem.java:561)
        at org.apache.hadoop.fs.azure.NativeAzureFileSystem$FolderRenamePending.redo(NativeAzureFileSystem.java:511)
        at org.apache.hadoop.fs.azure.NativeAzureFileSystem.conditionalRedoFolderRenames(NativeAzureFileSystem.java:1743)
        at org.apache.hadoop.fs.azure.NativeAzureFileSystem.listStatus(NativeAzureFileSystem.java:1689)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1515)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1555)
        at org.apache.hadoop.hbase.util.FSUtils.getLocalTableDirs(FSUtils.java:1333)
        at org.apache.hadoop.hbase.util.FSUtils.getTableDirs(FSUtils.java:1318)
        at org.apache.hadoop.hbase.util.FSTableDescriptors.getAll(FSTableDescriptors.java:206)
        at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:920)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:711)
        at java.lang.Thread.run(Thread.java:745)
{code}, [~madhuch-ms]
{quote}
How often you are facing this? Are you seeing this frequently across many clusters in production?
{quote}
No. Only once so far. I tried but failed to reproduce this problem for many times.
, Here is log from when the first rename happened. , [~liushaohui] I remember you reported a similar JIRA https://issues.apache.org/jira/browse/HADOOP-12884 and that was reported as dup and resolved. I understand the symptom here is slightly different but just checking did you retry with the appropriate versions that had the fix for the previous issue and were you able to repro it with appropriate updated versions? If not there is a possibility that the issue may be self-resolved with the latest versions. Just something to verify

[~onpduo], [~pravinmittal] for context]