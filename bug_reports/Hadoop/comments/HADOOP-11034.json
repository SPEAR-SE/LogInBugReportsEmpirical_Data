[{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12665540/HADOOP-11034-trunk-1.patch
  against trunk revision 0f34e6f.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1264 javac compiler warnings (more than the trunk's current 1263 warnings).

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.fs.TestEnhancedByteBufferAccess

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4608//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/4608//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4608//console

This message is automatically generated., The test failures here appear to be because of "java.lang.NoClassDefFoundError: org/apache/hadoop/util/DiskChecker$DiskOutOfSpaceException" which is unrelated to this patch. Will fix the javac warning and upload a new patch, hopefully the tests following will run correctly. 

Incidentally, HADOOP-11032 is also seeing unrelated NoClassDefFoundError., The javac warnings file wasn't available (link 404s) but I believe I found the additional warning I introduced and removed it. , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12665814/HADOOP-11034.2.patch
  against trunk revision 258c7d0.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDFSClientRetries

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4623//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4623//console

This message is automatically generated., Stack trace for test failure shows a MiniDFSCluster couldn't start up because it couldn't parse core-default.xml:

2014-09-01 22:04:41,695 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(440)) - starting cluster: numNameNodes=1, numDataNodes=3
2014-09-01 22:04:41,698 FATAL conf.Configuration (Configuration.java:loadResource(2492)) - error parsing conf core-default.xml
java.util.zip.ZipException: oversubscribed dynamic bit lengths tree, Reattaching patch 2 to trigger Jenkins build. , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667221/HADOOP-11034.2.patch
  against trunk revision 6a84f88.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4671//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4671//console

This message is automatically generated., Once again reattaching patch 2. The prior test failures don't appear to be related to this change., +1 Patch looks good to me. I am not sure why this was not part of ViewFileSystem to begin with. May be someone has history about it, otherwise, changes looks good to me., We have also discussed an option to have a recursive getStatus. I am not sure if you want to do it in a separate JIRA.
Recursion will will traverse internal viewfs dirs with mount points as base, and where each internal inode sums the results from its child nodes.

An edge case is when the user has the same fs mounted multiple times. This can be avoided by keeping track of resolved fs during recursion. Even more complex edge case than this is when the same FS is mounted via different abstractions, e.g., as WebHDFS, Hftp and HDFS at the same time.  One can have certain heuristics regarding identical authorities, etc. Initially we can have a boolean conf enabling collecting status recursively. It will be off by default. Then users who don't have multiple logically equivalent mount points will set it to true. , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12668851/HADOOP-11034.2.patch
  against trunk revision 88e329f.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4728//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4728//console

This message is automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12668851/HADOOP-11034.2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6367/console |


This message was automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12668851/HADOOP-11034.2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6375/console |


This message was automatically generated., This got fixed as part of HDFS-11058]