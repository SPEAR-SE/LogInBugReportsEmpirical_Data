[Submitted patch from HADOOP-11293 that demonstrated the problem earlier.

Thanks for looking into.
, *I think, there is no problem in any script.* 
*Precommit Build will be triggered everytime patch is submitted, even though it contains multiple projects. But its getting aborted due to timeout (5 hours)*
IMO Actually there is no such intelligence added anywhere to run only specific project's patches.

Since the patch which contains changes in almost all projects, like the one one which attached to this jira, all those project's test need to run sequentially in single build. it obviously takes more time, because of vast no. of hadoop tests.

Build for current patch taking more than 5 hours, But the build timeout set is 5 hours (300 min) in jenkins and after that jenkins is marking the build as aborted and its killing there itself before posting comments back to Jira. Check the abort message at the end of the build console text.
{noformat}Build timed out (after 300 minutes). Marking the build as aborted.
Build was aborted
Archiving artifacts
Description set: HADOOP-11293
Recording test results
Finished: ABORTED{noformat}

There are number of builds triggered and aborted for HADOOP-11293. Such build numbers are [5077|https://builds.apache.org/job/PreCommit-HADOOP-Build/5077/], [5079|https://builds.apache.org/job/PreCommit-HADOOP-Build/5079/] and [5081|https://builds.apache.org/job/PreCommit-HADOOP-Build/5077/]

So suggestion is to create separate patches for each of the project., Hi [~vinayrpet], thanks a lot for looking into and suggestion!

, Since there was no issue with the hadoop script to trigger jenkins, marking this jira as invalid., Thanks Vinayakumar.
, Based on the email discussion, it seems beneficial to allow the option of making changes that span sub-projects. Still, reviewer can decide whether the change need to be broken down to sub-patches. So we won't really lose much by having this option.

Thanks [~cnauroth], [~stevel@apache.org], [~cmccabe], [~vinayrpet], [~b.eckenfels] for the feedback.

I'm re-opening this jira for increasing the timeout. It would be nice to make the timeout adaptable to the patch, say, if a patch only spans a single sub-project, keep the original timeout, otherwise, adjust it accordingly.

{code}
On Tue, Nov 25, 2014 at 10:26 PM, Colin McCabe <cmccabe@alumni.cmu.edu> wrote:
+1 for increasing the test timeout for tests spanning multiple sub-projects.

I can see the value in what Steve L. suggested... if you make a major
change that touches a particular subproject, you should try to get the
approval of a committer who knows that subproject.  But I don't think that
forcing artificial patch splits is the way to do this...  There are also
some patches that are completely mechanical and don't really require the
involvement of YARN / HDFS committer, even if they change that project.
For example, fixing a misspelling in the name of a hadoop-common API.

Colin

On Tue, Nov 25, 2014 at 8:45 AM, Yongjun Zhang <yzhang@cloudera.com> wrote:

> Thanks all for the feedback. To summarize (and I have a suggestion at the
> end of this email), there are two scenarios:
>
>    1. A change that span multiple *bigger* projects. r.g. hadoop, hbase.
>    2. A change that span multiple *sub* projects* within hadoop, e.g.,
>    common, hdfs, yarn
>
> For 1, it's required for the change to be backward compatible, thus
> splitting change for multiple *bigger* projects is a must.
>
> For 2, there are two sub types,
>
>    - 2.1 those changes that can be made within hadoop sub-projects, and
>    there is no external impact
>    - 2.2 those changes that have external impact, that is, the changes
>    involve adding new APIs and marking old API deprecated, and
> corresponding
>    changes in other *bigger* projects will have to be made independently.
> *But
>    the changes within hadoop subjects can still be done altogether.*
>
> I think (Please correct me if I'm wrong):
>
>    - What Colin referred to is 2.1 and changes within hadoop sub-subjects
>    for 2.2;
>    - Steve's "not for changes across hadoop-common and hdfs, or
>    hadoop-common and yarn" means 2.1, Steve's  "changes that only
>    span hdfs-and-yarn would be fairly doubtful too." implies his doubt of
>    existence of 2.1.
>
> For changes of 2.1 (if any) and *hadoop* changes of 2.2, we do have an
> option of making the change across all hadoop sub-projects altogether, to
> save the multiple steps Colin referred to.
>
> If this option is feasible, should we consider increasing the jenkins
> timeout for this kind of changes (I mean making the timeout adjustable, if
> it's for single sub-project, use the old timeout; otherwise, increase
> accordingly)  so that we have at least this option when needed?
>
> Thanks.
>
> --Yongjun
>
>
> On Tue, Nov 25, 2014 at 2:28 AM, Steve Loughran <stevel@hortonworks.com>
> wrote:
>
> > On 25 November 2014 at 00:58, Bernd Eckenfels <ecki@zusammenkunft.net>
> > wrote:
> >
> > > Hello,
> > >
> > > Am Mon, 24 Nov 2014 16:16:00 -0800
> > > schrieb Colin McCabe <cmccabe@alumni.cmu.edu>:
> > >
> > > > Conceptually, I think it's important to support patches that modify
> > > > multiple sub-projects.  Otherwise refactoring things in common
> > > > becomes a multi-step process.
> > >
> > > This might be rather philosophical (and I dont want to argue the need
> > > to have the patch infrastructure work for the multi-project case),
> > > howevere if a multi-project change cannot be applied in multiple steps
> > > it is probably also not safe at runtime (unless the multiple projects
> > > belong to a single instance/artifact). And then beeing forced to
> > > commit/compile/test in multiple steps actually increases the
> > > dependencies topology.
> > >
> >
> > +1 for changes that span, say hadoop and hbase. but not for changes
> across
> > hadoop-common and hdfs, or hadoop-common and yarn. changes that only span
> > hdfs-and-yarn would be fairly doubtful too.
> >
> > there is a dependency graph in hadoop's own jars â€”and cross module (not
> > cross project) changes do need to happen.
> >
{code}
, Hi [~abayer] and [~vinayrpet],

Thanks for looking at this issue earlier. Seems the timeout is set in the jenkins job that calls test-patch.sh. Would you please suggest who would help fixin gthe timeout setting? Thanks.

, Someone on the project with Jenkins job modification rights. , Thanks [~abayer].

Hi [~cmccabe], I wonder if  you could help on this? I re-opened this jira based on our discussion in email. Thanks a lot.

, What should be the new timeout ?, Now 500 minutes

One flaw with having a test run which spans everything is that tests do now take 3+ hours to pass through, which now impacts the #of test patches that can be reviewed in a single day, even with some parallelism turned on. There's known issues with tests causing problems for each other if they run on the same machines (port conflict, maven conflict), so that's not good.

We've also started hitting some jenkins OOM limits parsing the aggregate test results of a full build.



, FYI, I bumped the slave memory settings on builds.a.o today - the H* slaves were at a mere -Xmx512m, now they'll be at 2g, bigger permgen, etc. It won't kick in til the slaves are disconnected/reconnected, but I'm gradually doing that when they free up., Thanks [~tedyu], [~stevel@apache.org] and [~andrew.wang]!

If we find issues with this change, we may need a solution later. E.g., if a test is not supposed to run for long but it does due to a bug, allowing it to run long will keep the computing resource not released. We will keep watching if this happens. The solution would be to somehow make the timeout set to different values based on whether the patch crosses sub-projects etc.

, Thanks  [~abayer]!
, Based upon the previous discussion, it looks as though this should get closed as fixed.]