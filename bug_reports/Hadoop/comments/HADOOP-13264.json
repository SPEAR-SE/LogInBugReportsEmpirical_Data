[Linked to the related ticket on which a sudden failure causes the JVM to die with OutOfMemory. In that test I was trying to migrate a couple of million files while the datanode ran out of diskspace. This caused the client to die, although I was calling close on the stream (using java8 close with resource), but since that failed, the mentioned map caused my JVM to die.

Created a simple test that attempts a write while the datanode is down. , Test code from [~sebyonthenet] (moving from description)

{code}

Here is a test program:

	public static void main(String args[]) throws Exception
	{
		final Configuration conf = new Configuration();
		conf.addResource(new FileInputStream(new File("core-site.xml")));
		conf.addResource(new FileInputStream(new File("hdfs-site.xml")));

		final DistributedFileSystem newFileSystem = (DistributedFileSystem)FileSystem.get(conf);
		OutputStream outputStream = null;
		try
		{
			outputStream = newFileSystem.create(new Path("/user/ssmogos", "test1"));
			outputStream.write("test".getBytes());
		}
		catch (IOException e)
		{
			e.printStackTrace();//don't care about this
		}
		finally
		{
			try
			{
				if (outputStream != null)
					outputStream.close();//now this one will fail to close the stream
			}
			catch (IOException e)
			{
				e.printStackTrace();//this will list the thrown exception from DFSOutputStream->flushInternal->checkClosed
				//TODO the DFSOutputStream#close->dfsClient.endFileLease(fileId) is never getting closed
			}
		}

		Field field = DFSClient.class.getDeclaredField("filesBeingWritten");
		field.setAccessible(true);
		System.out.print("THIS SHOULD BE EMPTY: " + field.get(newFileSystem.getClient()));
{code}, It looks like a dupe of HDFS-9812. , Thanks [~kihwal], but that fix does not seem to address this problem.

The DFSOutpuStream#close()->closeImlp()->flushInternal() ->checkClosed() call still throws the lastException.get(), so going back on the stack to the DFSOutputStream#close, the dfsClient.endFileLease(fileId) still does not get called due to the thrown exception in the checkClosed method.

Just to make sure, I've syned the 2.7 branch and built the latest 2.7.3 on my box and re-running my test still shows the problem being present, filesBeingWritten still keeps a reference to the stream that could not be closed. , Since it is closely related to HDFS-9812, [~linyiqun], can you take a look at this?  , I think this problem is different with HDFS-9812. HDFS-9812 solved the problem that {{datastreamer}} thread not closed when failures happened in flushing data, and these logic was done in {{closeImpl}}. In this probloem, if the method {{closeImpl}} threw the IOException, the dfsClient.endFileLease(fileId) will not be called. If we want to fix this, I suggest that we would be better  to keep the synchronized block code, like this:

{code}
  public void close() throws IOException {
    boolean threwException = false;
    synchronized (this) {
      try (TraceScope ignored =
          dfsClient.newPathTraceScope("DFSOutputStream#close", src)) {
        closeImpl();
      } catch (IOException ioe) {
        threwException = true;
      }
    }
    dfsClient.endFileLease(fileId);
    if (threwException) {
      throw new IOException("Exception happened in closing the output stream.");
    }
  }
{code}

Correct me if I am wrong, thanks., I have looked the code, there were some other places will not release resources associated with stream. Like in {{DFSOutputStream#abort}}, {{DFSStripedOutputStream#abort}}. We could make all fixed in this jira. Who can assign this to me, I'd like to post a patch for this. In addition, this jira seems better to transform to HDFS ranther Hadoop Common., I'm closing this as a dup of HDFS-10549, since [~linyiqun] is working on there and the change is in HDFS.

Thanks [~sebyonthenet] and all for the work here, let's follow up on HDFS-10549.]