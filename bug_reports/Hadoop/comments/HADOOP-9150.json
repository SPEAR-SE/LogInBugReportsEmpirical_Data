[To diagnose this, I wrote a wrapper implementation of the NameService SPI which logs all resolutions. Attached is the source for the tracing implementation along with a log I captured on a test cluster. Here you can see a DNS lookup coming from the path canonicalization code:

{code}
java.lang.Exception: looking up ha-nn-uri
        at MyNameservice.lookupAllHostAddr(MyNameservice.java:11)
...
        at org.apache.hadoop.security.SecurityUtil$StandardHostResolver.getByName(SecurityUtil.java:538)
        at org.apache.hadoop.security.SecurityUtil.getByName(SecurityUtil.java:526)
        at org.apache.hadoop.net.NetUtils.canonicalizeHost(NetUtils.java:283)
        at org.apache.hadoop.net.NetUtils.getCanonicalUri(NetUtils.java:255)
        at org.apache.hadoop.fs.FileSystem.getCanonicalUri(FileSystem.java:214)
        at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:524)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:170)
        at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:401)
...
{code}, Can think of a few options here:

First option: have DistributedFileSystem override getCanonicalUri, and check if the URI is a logical one (using {{HAUtil.isLogicalUri}}). If so, don't call through to canonicalizing the hostname

Or, since I think this also affects viewfs and other filesystems which don't strictly use hostnames (eg s3n://bucketname/), we can add an overridable {{isLogicalUri()}} in the FileSystem interface itself, and then have the affected filesystems return true as necessary., bq. Or, since I think this also affects viewfs and other filesystems which don't strictly use hostnames (eg s3n://bucketname/), we can add an overridable isLogicalUri() in the FileSystem interface itself, and then have the affected filesystems return true as necessary.

This one makes sense to me, given that this affects more than just HDFS proper., I'd assume this would impact not only FileSystems but MR/YARN as well. Wouldn't make sense, similar to what we do for UID-name caching, implement a short-lived NAME-IP caching in NetUtils., The problem here is that, on some DNS setups, even the first lookup takes a lot of time (>5sec) to come back for a host-not-found. A cache wouldn't solve that. Plus, Java already _has_ a cache here internally, so we'd be adding yet another layer of caching which has its downsides., I thought I had fixed this quite awhile ago...  ViewFS is just supposed to return its URI.  For HA, maybe I fixed this in a patch I lost in a laptop crash that greatly simplified all of its token handling., BTW, NetUtils already caches canonicalized hosts.  It doesn't do negative caching though., The problem we've seen is that this slows down MR tasks, even though they tend to only initialize the DFSClient once or twice. The timeout can be 5+ seconds, so even a negative cache would leave a lot of performance on the table., Attached patch should fix the issue.

I added an {{isLogicalUri(URI)}} protected hook for FileSystem, to be used in S3, viewfs, and HA HDFS. The new unit test spys on the java DNS infrastructure to verify that the logical hostname is never resolved. The test fails without the bugfix, passes with., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563378/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2021 javac compiler warnings (more than the trunk's current 2014 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.fs.viewfs.TestViewFsTrash
                  org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem
                  org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem
                  org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs
                  org.apache.hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1947//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/1947//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1947//console

This message is automatically generated., Looks like there is some bug introduced in viewfs. Canceling patch to fix it., Fixes a bug in the previous patch: when trying to canonicalize paths without hosts (eg "/foo"), I forgot to check for the null host., Did you mean to make viewfs mount tables case-insensitive?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563628/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2002//console

This message is automatically generated., bq. Did you mean to make viewfs mount tables case-insensitive?

I guess not -- but I did mean to make the HA logical name case-insensitive, since it shows up like a hostname to users. Do you think making viewfs's top level case-insensitive would be a feature or a bug? :), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563628/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2021 javac compiler warnings (more than the trunk's current 2014 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2003//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2003//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2003//console

This message is automatically generated., I'd lean towards case-sensitive.  If others lean the other way, I'm not sure how exactly you'll match up the mount table with the config unless you tell users "don't use uppercase or it's not going to work!" which feels a bit wrong., Hey Daryn. What do you think about changing {{canonicalizeLogicalUri}} to actually just remove the port? So far we've been canonicalizing these URIs by adding the default port, but in fact logical URIs don't really have ports. Would this have issues 'downstream' in stuff like the token code?, Here's a patch which takes the above attempt. I ran a couple tests by hand, let's see if all pass., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563826/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2021 javac compiler warnings (more than the trunk's current 2014 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2014//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2014//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2014//console

This message is automatically generated., The javac warning is due to the unit test, which spies on the JDK resolver. I used Assume checks so that it will just skip this on non-sun JDK., Hey Daryn. How's this patch look to you? Hoping to get this in for 2.0.3 since it can cause a big (and unfortunately silent) perf regression for HA on clusters with borked DNS., +1, patch looks good to me.

My only suggestion would be to add a test for the FileContext side of the house to make sure that that isn't affected by this issue as well, though you could also certainly do this in a separate JIRA if you wanted., Added a test for FileContext. It appears it wasn't affected by the issue (appears not to do canonicalization). But if someone adds canonicalization to FileContext later, this should catch a regression., Thanks for adding the test.

The latest patch looks good to me. +1 pending Jenkins., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565050/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2030 javac compiler warnings (more than the trunk's current 2022 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2053//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2053//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2053//console

This message is automatically generated., bq. Hey Daryn. What do you think about changing canonicalizeLogicalUri to actually just remove the port? So far we've been canonicalizing these URIs by adding the default port, but in fact logical URIs don't really have ports. Would this have issues 'downstream' in stuff like the token code?

Where are you proposing to remove the ports?  In general or just viewfs?, Skimming the patch, to reduce adding more methods and complexity, maybe we should consider either of the following:
# Default impl of {{getCanonicalUri()}} just returns {{getUri()}}.  Filesystem like DFS can specifically override {{getCanonicalUri}} to call {{NetUtils.getCanonicalUri}}.  The advantage is that it won't preclude other/future logical filesystems from utilizing a port.
# {{getCanonicalUri()}} continues to call {{NetUtils.getCanonicalUri}}.  Logical filesystems should have a default port of -1 (ie. URI considers this as no port), so perhaps {{NetUtils.getCanonicalUri}} can just return the given uri if there's no default port.

I lean towards #1., Hey Daryn.

I'm looking at implementing your #1 option above. Another issue, though, is that checkPath() hard-codes {{NetUtils.getCanonicalUri}}. I don't really want to have to make all of HDFS,HFTP,HSFTP,WebHDFS re-implement that code.

How does the following sound?
- Add {{protected FileSystem.canonicalizeUri(uri)}}. Default implementation would add getDefaultPort() if the given URI has no port set, and if getDefaultPort() > 0
- Make the default implementation of {{FileSystem.getCanonicalUri()}} call {{canonicalizeUri(getUri())}}
- Change {{checkPath}} to call {{canonicalizeUri}}
- In all of the FileSystems which use real hostnames as their authority, override {{canoncalizeUri}} to call {{NetUtils.canonicalizeUri}}, Attached patch implements something like what's described above.

Note that this changes behavior for those who are extending the FileSystem interface. It's marked as Public and Stable, so we should probably add a release note for this. I think we should allow it nonetheless -- it's not clear that the {{Stable}} marking there refers to "stable for FileSystem developers to inherit from" vs "stable for developers to code against". Since the changes are only to protected methods, we've only changed something for the former and not the latter., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565211/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2030 javac compiler warnings (more than the trunk's current 2022 warnings).

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.fs.TestFilterFileSystem

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2061//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2061//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2061//console

This message is automatically generated., Previous patch forgot to add a delegator method in FilterFileSystem. This patch adds the trivial delegation., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565269/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2030 javac compiler warnings (more than the trunk's current 2022 warnings).

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2062//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2062//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2062//console

This message is automatically generated., Fix javadoc warning, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565393/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2030 javac compiler warnings (more than the trunk's current 2022 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2067//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2067//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2067//console

This message is automatically generated., Daryn, can you take a look at this latest patch rev? We've seen users have a big perf impact due to this bug when their DNS infrastructure isn't well set up with nscd, etc. Would like to get it fixed ASAP. Thanks!, +1, the latest patch looks good to me. I agree that this seems a little easier to follow than the previous version., Looking at the patch, FileSystem has two methods that can be overridden. getCanonicalUri() and canonicalizeUri(). Overriding the first method would be sufficient. Is the reason for introducing the second method just to reduce the code or getCanonicalUri() should become final and no longer overridable?, Hey Suresh. Thanks for reviewing the patch.

The reason that we need to create {{canonicalizeUri}} and allow implementations to override it is that we have canonicalize the URI parameter in {{checkPath}}. Since we don't have a FileSystem instance corresponding to the URI parameter, we have to add this method which takes a URI for this to work out.

Certainly most systems can now use the default implementation of {{getCanonicalUri}} (which just calls {{canonicalizeUri(getUri())}}, but making it final seemed a little bit dictatorial. I'm generally not a fan of forcing users to not override things - seems better to just suggest that implementors use the default implementation unless they have good reason not to., I'm also kind of leaning towards a final on {{getCanonicalUri()}}.  If someone overrides it then there would be an inconsistency in calling {{getCanonicalUri()}} and {{getCanonicalUri(getUri())}}.

I think the comparison {{getDefaultPort() != 0}} should be {{getDefaultPort() > 0}} since -1 signifies no port to URI.  I find it very odd that the default impl returns 0 instead of -1.  Perhaps that should be changed?  If so, maybe it should be {{getDefaultPort() != -1}}.

Very minor, but I'd consider renaming {{canonicalizeUri(URI)}} to {{getCanonicalUri(URI)}}.  If you disagree, that's ok.
, Attached patch makes {{getCanonicalUri()}} final as suggested by Suresh and Daryn above. I had to change a couple unit tests which were relying on overriding the protected method in order to expose it at public visibility.

I also changed the if condition checking for default port, but I didn't change the default behavior to return -1 instead of 0. It seemed like this could have more far-reaching but subtle impact, so figured I'd prefer to avoid the scope creep on this JIRA., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566181/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2030 javac compiler warnings (more than the trunk's current 2022 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.fs.TestFilterFileSystem
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2080//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2080//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2080//console

This message is automatically generated., Had to modify TestFilterFileSystem so that it knows that FilterFileSystem doesn't need to override final methods., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566219/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2030 javac compiler warnings (more than the trunk's current 2022 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2081//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2081//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2081//console

This message is automatically generated., +1 If warnings and test failure are unrelated to patch, Sorry for the late reply. I was merely asking a question to understand the change and not suggesting a change, in my previous comment.

bq. The reason that we need to create canonicalizeUri and allow implementations to override it is that we have canonicalize the URI parameter in checkPath. Since we don't have a FileSystem instance corresponding to the URI parameter, we have to add this method which takes a URI for this to work out.
Now I understand the issue better.

Some obesvations/comments:
# With this patch, default FileSystem#getCanonicalUri() implementation changes. The host is no longer canonicalized for file systems that do not override the method. This is a change in behavior. However it is taking the behavior prior to changes from HADOOP-7510. So that should be okay.
# Making getCanonicalUri() final is an API incompatible change for the file system implementations. While in my pervious comment I asked you about making getCanonicalUri() final, thinking a bit more, it is not worth making incompatible change. There are two ways now in FileSystem to override the behavior. getCanoicalUri() and canonicalizeUri(). It is not clean, but may be worth doing to keep the API compatibility. Also adding a comment to getCanonicalUri() to say, most file system need to only override canonicalizeUri() and not this method, should add more clarity.
# It is worth making this change in branch-1, since some new implementations of file systems could start with that branch.


, Attached patch goes back to making the call not be declared {{final}}, for compatibility.

Otherwise it's the same as the prior patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12575612/hadoop-9150.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1371 javac compiler warnings (more than the trunk's current 1363 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2369//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2369//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2369//console

This message is automatically generated., Per above, the javac warnings are because the unit test spies on the DNS resolver., +1, the latest patch looks good to me., Suresh, any further comments or can I go ahead and commit?, +1 for the patch., Committed to trunk and branch-2. Thanks for reviewing everyone., Integrated in Hadoop-trunk-Commit #3537 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3537/])
    HADOOP-9150. Avoid unnecessary DNS resolution attempts for logical URIs. Contributed by Todd Lipcon. (Revision 1462303)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1462303
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemCanonicalization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/GenericTestUtils.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HftpFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java
, Integrated in Hadoop-Yarn-trunk #169 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/169/])
    HADOOP-9150. Avoid unnecessary DNS resolution attempts for logical URIs. Contributed by Todd Lipcon. (Revision 1462303)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1462303
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemCanonicalization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/GenericTestUtils.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HftpFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java
, Integrated in Hadoop-Hdfs-trunk #1358 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1358/])
    HADOOP-9150. Avoid unnecessary DNS resolution attempts for logical URIs. Contributed by Todd Lipcon. (Revision 1462303)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1462303
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemCanonicalization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/GenericTestUtils.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HftpFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java
, Integrated in Hadoop-Mapreduce-trunk #1386 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1386/])
    HADOOP-9150. Avoid unnecessary DNS resolution attempts for logical URIs. Contributed by Todd Lipcon. (Revision 1462303)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1462303
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemCanonicalization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/GenericTestUtils.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HftpFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java
]