[I too came across this problem the hard way (our weaker nodes started thrashing, because they were running too many jobs.  In my case I don't even see it reverting to the desired behavior after the first round of jobs is
finished, - it's always the jobtracker's config value.  Maybe I'm using a different version of Hadoop? (it's 0.15 devel from svn). 

If anyone knows a way to run different number of tasks on different boxes, please let me know, because from what I see, there is no way to do it, which makes our hadoop cluster as lame as the lamest node in it., I've also run into this, and came up with a patch that involved:

- adding a 'maxTasks' value to the TaskTrackerStatus (set by the local mapred.tasktracker.tasks.maximum)
- modifying JobTracker to track totalTaskCapacity instead of per-node maxTasks, and to use the particular task tracker's maxTasks value when deciding whether to assign it another task

If this seems like a reasonable approach, I can do more testing and provide a patch., Here's a patch implementing the approach described in the last comment. It also includes web UI updates to display the per tasktracker max-tasks setting., Patch looks reasonable.  +1, See what hudson thinks..., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12367239/tasktracker-max-tasks-1245.patch
against trunk revision r582867.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/903/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/903/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/903/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/903/console

This message is automatically generated., The patch is cool, I tested it on our hadoop cluster and it seems to be working. +1., Fixing issue description to reflect reality as reported by others, +1 This looks reasonable to me.

Note that this is potentially incompatible, since previously folks could set the number of tasks per node globally at the jobtracker, now it is determined by the configuration of the tasktracker nodes.  So we should probably either add a compatibility note (i.e., move this to the INCOMPATIBLE section of CHANGES.txt) or perhaps have a configuration parameter that enables the old behavior.  I think a compatibility note is probably sufficient.  Thoughts?, It might be enough to use the value at the jobtracker as a default, and override with the tasktracker value if it's present (along with the compatibility note).  

If a tasktracker is configured differently than the jobtracker, it's more likely the configurer intended the tasktracker's value to be used, as opposed to the configurer expecting the tasktracker value to be ignored.  So I doubt using the jobtracker as an overridable default will break anybody., Thanks. I can certainly modify the patch as Michael suggests, though there is a setting for mapred.tasktracker.tasks.maximum in hadoop-default.xml, so it seems like a user would really have to go out of her way to not have any setting present on the tasktracker., This looks fine., Rick, I forgot about that.  So my suggestion would be rather useless., I just committed this (twice!). Thanks, Michael., Integrated in Hadoop-Nightly #282 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/282/])]