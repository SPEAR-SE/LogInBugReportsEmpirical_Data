[Seems to affect 1.2.1, during normal 'hadoop fs -put', too.

from datanode.log:
{quote}
2013-10-08 08:20:27,288 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
org.apache.hadoop.util.Shell$ExitCodeException: du: cannot access `/..../hdfs/datanode/blocksBeingWritten/blk_2086885445451145306': No such file or directory

        at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
        at org.apache.hadoop.util.Shell.run(Shell.java:182)
        at org.apache.hadoop.fs.DU.access$200(DU.java:29)
        at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:84)
        at java.lang.Thread.run(Thread.java:662)
{quote}

output on the console:
{quote}
13/10/08 08:20:27 INFO hdfs.DFSClient: Exception in createBlockOutputStream 192.168.x.y:50010 java.io.EOFException
13/10/08 08:20:27 INFO hdfs.DFSClient: Abandoning blk_-605554355196703343_69209
13/10/08 08:20:27 INFO hdfs.DFSClient: Excluding datanode 192.168.x.y:50010
{quote}, Getting this in 2.6.0 too, during TestDFSIO
{quote}
2014-12-15 20:40:19,944 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver constructor. Cause is
org.apache.hadoop.util.Shell$ExitCodeException: du: cannot access `/data3/dfs/dn/current/BP-1172228382-36.0.0.112-1418564551057/current/rbw/blk_1073754273': No such file or directory
    at org.apache.hadoop.util.Shell.runCommand(Shell.java:511)
    at org.apache.hadoop.util.Shell.run(Shell.java:424)
    at org.apache.hadoop.fs.DU.run(DU.java:190)
    at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
    at java.lang.Thread.run(Thread.java:745)
{quote}, HADOOP-12973 unintentionally fixed this bug., Given that the refactor in HADOOP-12973 unintentionally eliminated this problem in 2.8.0 and above, I'll mark this as a won't fix.]