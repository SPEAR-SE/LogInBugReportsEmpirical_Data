[Attached patch removes checkDataDir() calls from DataXceiveServer.run() method., +1, because http://issues.apache.org/jira/secure/attachment/12354393/1170.patch applied and successfully tested against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/523072. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, 
It is invoked in two more places in Datanode.java.. though not this often. Should we remove those as well?  It is called once before sending block report and when a command is received from namenode (e.g. block invalidate cmd in response to heartBeat).

, I agree that it is too costly to call checkDirs on every I/O operation. A background thread that periodically does the sanity check would be nicer.

The patch should also clean up the code that does the error handling., I like the idea of a background thread that periodically checks the data directories. The idea is to detect bad/inaccessible data directories and shutdown the datanode if this occurs, right?, 
There is going to be a periodic checker for all the blocks. The same thread could check the some of these conditions too. For this jira, I vote for removing all calls to checkDirs in Datanode.java.
, Is there a consensus to commit this as-is, or is someone working on an improved version?, I'll prepare patch with all calls removed later today, This patch removes all FSDataset.checkDataDir() calls from DataNode as well as DiskErrorException handling in DataXceiveServer.run() method. I decided not to touch DiskErrorException handling in DataNode.offerService() - I just don't know whether or not it's possible to get it there.
 , +1, because http://issues.apache.org/jira/secure/attachment/12354634/1170-v2.patch applied and successfully tested against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/524205. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, I just committed this.  Thanks, Igor., Integrated in Hadoop-Nightly #43 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/43/), This patch improves the performance situation but removes all checkDirs from the datanode. This introduces the problem that disk's migt not get checked for a long time. This is dangerous for a cluster where disks go bad. I think we should either implement a background thread to call checkDirs() before this patch can be deployed on a real cluster., > we should either implement a background thread to call checkDirs() before this patch can be deployed on a real cluster

Please file a new issue to be fixed for 0.13 for this., There is another issue HADOOP-1200 that was open exactly for this, The thing to understand is that we can not upgrade our cluster to HEAD with this patch committed.  This patch breaks us.  We'll try to move forward in the new issue rather than advocating rolling this back, but this patch did not address the concerns we raised in this bug and so we have a problem.  I hope we can avoid this in the future.

I'm not advocating rolling back because I agree that these checks were not the appropriate solution to the disk problems they solved.

In case the context isn't clear, we frequently see individual drives go read only on our machines.  This check was inserted to allow this problem to be detected early and avoid failed jobs cause by write failures., Integrated in Hadoop-Nightly #82 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/82/)]