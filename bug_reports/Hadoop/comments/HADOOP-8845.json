[Here is a failing test case first, to demonstrate the issue.

Fix to follow., Here's a patch that fixes it up as well., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546608/HADOOP-8845.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1522//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/1522//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1522//console

This message is automatically generated., Patch fixes the findbugs warning (I had a @Nullable), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546641/HADOOP-8845.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.ha.TestZKFailoverController
                  org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics
                  org.apache.hadoop.hdfs.TestPersistBlocks

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1524//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1524//console

This message is automatically generated., {quote}
-1 core tests. The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:
org.apache.hadoop.ha.TestZKFailoverController
org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics
org.apache.hadoop.hdfs.TestPersistBlocks
{quote}

These tests do not rely on globbing at all, and hence the failures are unrelated to this patch on the core-side., Ping? Its a trivial fix to not lookup non-directories and I have tests attached (similar to pClosure5, but that mkdired everything and couldn't run into EXECUTE-less issues as described)., globPathsLevel is a generic method, and globStatus which calls it claims to return all matching path names, why is it OK to unconditionally filter out all files from its results?  Since * can match the empty string, in other contexts it could be appropriate to return ""/tmp/testdir/testfile" for "/tmp/testdir/*/testfile".

Ie is there a place where we know we should just be checking directory path elements? The comment in globStatusInternal ("// list parent directories and then glob the results") by one of the cases indicates is the intent but it's valid to pass both files and directories to listStatus.
, bq. Since * can match the empty string, in other contexts it could be appropriate to return ""/tmp/testdir/testfile" for "/tmp/testdir/*/testfile".

Nice catch. I will add a test for this to see if we aren't handling it already.

bq. Ie is there a place where we know we should just be checking directory path elements? The comment in globStatusInternal ("// list parent directories and then glob the results") by one of the cases indicates is the intent but it's valid to pass both files and directories to listStatus.

The parts I've changed this under, try to fetch "parents", which can't mean anything but directories AFAICT., bq. Since * can match the empty string, in other contexts it could be appropriate to return ""/tmp/testdir/testfile" for "/tmp/testdir/*/testfile".

That's not right for Posix-style path glob: /usr/*/bin does match /usr/X11/bin but does not match /usr/bin, even though /usr//bin is a valid synonym for /usr/bin, and this is an important feature that is commonly depended on in scripts. For example an admin might {{rm /var/www/user/*/.htaccess}} to remove all the user's htaccess files while leaving {{/var/www/user/.htaccess}} intact.

So unless there's a specific need for that kind of funky glob, I don't think we need to support it?, I would argue that even if there is a specific need for non-standard globbing we don't want to support it.  POSIX compliance is what most people would expect from HDFS, when we deviate from it users will get confused and angry. Especially if rm deletes more files then they want., (sorry for the markup messup in my last comment.)

The currently pending patch specifically checks in {{pTestClosure6}} that the case I mentioned is handled correctly, so I think we're all on the same page. :)

Code-wise, one minor comment:
{code}
+              public boolean apply(FileStatus input) {
+                return input.isDirectory() ? true : false;
+              }
{code}

This is an anti-pattern; {{foo() ? true : false}} is the same as {{foo()}}.

Other than that, LGTM on the code level. I haven't carefully read the GlobFilter implementation to see if there's a cleaner/simpler way to implement this bugfix., Harsh,

Per the discussion, my earlier comment was incorrect {{/tmp/testdir/\*/testfile}} should *not* match {{/tmp/testdir/testfile}}. Let's add a test for that if we don't have one.

bq. The parts I've changed this under, try to fetch "parents", which can't mean anything but directories AFAICT.

I took another look, and that appears to be true for FileSystem, however not FileContext which also needs to handle symlinks.  Unfortunately it looks like this glob handling code was duplicated, so the equivalent change needs to be made to the same code in FileContext, which file a jira for sharing it across FileSystem and FileContext? Can do that in a separate change., Thanks all. Am addressing all your comments. What ought to be the intended behavior when symlinks are thrown into the picture? To resolve or not to resolve?

It is quite unfortunate that we've the globbing code copied instead of shared. The FileContext copy does not even have tests for itself!

But I can't imagine sharing code if we begin trying to filter or resolve symlinks - given two implementations, one that handles it and the other that doesn't., I'll revise the patch here to include fixes for FileContext's globbing implementation as well, but for the reuse goal I have filed HADOOP-9068 for later., Are you sure this patch is still needed?  This should have already been fixed by HADOOP-8906., Hi Daryn,

Indeed, the UGI test in my pTestClosure6 passes on trunk now so HADOOP-8906 should have fixed this case completely. Thanks for the heads up!

Shall we retarget this JIRA for fixing the same on FileContext (sort of a clone of HADOOP-8906 for the new FC)?

Or would the UGI test be worth an addition anyway? Cause we couldn't catch this issue unless its a non super-user., The testing at HADOOP-8906 is sufficient. Resolving as dupe of HADOOP-8906 as it does address this.]