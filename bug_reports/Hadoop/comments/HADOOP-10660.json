[I have a question, [~tedyu]. I did not find GraphiteSink in hadoop source code but MetricsSystem. I am happy to help., You can find the file here:
hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12648346/HADOOP-10660.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.net.TestNetUtils

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4007//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4007//console

This message is automatically generated., The TestNetUtils fails on trunk without my patch., Should socket become a member of GraphiteSink and be closed in close() ?, The unit test failure is caused by hostname is null. NetUtils applies normalizeHostNames() to a list of string. For each string, NetUtils applies normalizeHostName() which actually return InetAddress.getByName(string).getHostAddress();

I did not find relationship between this error and my patch., The unit test failure is because of HADOOP-10664., A couple of colleagues and I contributed the GraphiteSink metric and it got into the trunk a couple of days ago. Thanks for the bug report. I see the problem, but was wondering why none of the other sinks (FileSink and GangliaSink) implement Closeable as well? I also would like to bring [~vicaya] and [~raviprak] attention to this issue., {code}
public class FileSink implements MetricsSink, Closeable {
{code}
I couldn't find GangliaSink in trunk.
There're GangliaSink30 and GangliaSink31., is this patch ok? :), Ted: I'm afraid I don't see where close() is being called either. AbstractGangliaSink->GangliaSink30->GangliaSink31 don't implement it either. I don't see a problem if it were added so if you can please point out where its being used, I have no objection. If its an external project, should we consider making MetricsSink implement Closeable (in a separate JIRA ofcourse)?

Chen: Thanks for the patch. However if we were to close the writer, I would expect to check during a putMetrics whether it was null, and perhaps log a message? Also a log message at close could be helpful in later debugging issues., See the following javadoc in MetricsSink.java :
{code}
 * {@link #putMetrics(MetricsRecord)} method.  If the implementing class also
 * implements {@link Closeable}, then the MetricsSystem will close the sink when
 * it is stopped.
{code}
See also MetricsSinkAdapter#stop():
{code}
    if (sink instanceof Closeable) {
      IOUtils.cleanup(LOG, (Closeable)sink);
    }
{code}
GraphiteSink uses OutputStreamWriter which wraps socket.getOutputStream().
The writer and socket should be closed when MetricsSystem stops., Is there probability that the GraphiteSink is closed but the writer is still needed? If so, we should just leave the GraphiteSink.close() empty., bq. the GraphiteSink is closed but the writer is still needed? 

I don't think so. See MetricsSystemImpl#stopSinks(), Thank you for the suggestions, [~raviprak] and [~ted_yu]. Patch updated., {code}
+            } else {
+              throw new Exception("Writer in GraphiteSink is null!");
+            }
         } catch (Exception e) {
             throw new MetricsException("Error sending metrics", e);
{code}
The Exception would be caught and converted to MetricsException - better throw MetricsException in the first place.
{code}
+        if(writer != null){
+          writer.close();
+          LOG.info("GraphiteSink "+this.toString()+" is closed!");
{code}
writer should be set to null after close() returns.
nit: .toString() is not needed.

Should socket become a member of GraphiteSink and be closed in close() ?, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12648655/HADOOP-10660-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4016//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4016//console

This message is automatically generated., Patch updated. Socket is closed since it is set to writer using setWriter(), right?, writer field of GraphiteSink points to OutputStreamWriter which wraps OutputStream of the underlying socket.
Closing writer wouldn't trigger socket.close() to be called., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12648669/HADOOP-10660-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.ha.TestZKFailoverControllerStress

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4018//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4018//console

This message is automatically generated., The failed unit test is because of HADOOP-10668, socket is closed in the GraphiteSink.close() method., The close of socket should be enclosed in finally block of the close of writer - otherwise the socket may not be closed when closing writer encounters problem., [~raviprak]:
Is there any question that I haven't answered ?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12649393/HADOOP-10660-v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4031//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12649389/HADOOP-10660-v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4030//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4030//console

This message is automatically generated., Thanks [~airbots] and [~ted_yu]. We have a system set up for using this and I will give this patch a test today. I will let you guys know about these experiments., Thanks Ted! That makes sense. Perhaps we should do the same from GangliaSink (in another JIRA)

In the latest patch, we are still not assigning writer = null after close()

bq. Should socket become a member of GraphiteSink and be closed in close() ?
http://docs.oracle.com/javase/7/docs/api/java/net/Socket.html#getOutputStream%28%29
{noformat}Closing the returned OutputStream will close the associated socket.{noformat}
So closing the socket is unnecessary and should be removed from the patch., I tried to find the source code for StreamEncoder.
But the ones I found don't have forOutputStreamWriter() method.

FYI, Socket has isClosed() which can be used to check the status., [~ babakbehzad]:
Is there anything Chen He and myself can do to help with validation ?, [~babakbehzad]:
Is there anything Chen He and myself can do to help with validation ?, No, thanks [~ted_yu], I am currently in the process of testing this. I will let you know soon., GitHub user babak-altiscale opened a pull request:

    https://github.com/apache/hadoop-common/pull/18

    Hadoop-9704, HADOOP-10660

    A metrics sink plugin for Hadoop to send metrics directly to Graphite in additional to the current ganglia and file ones.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/VertiPub/hadoop-common HADOOP-9704

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/hadoop-common/pull/18.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #18
    
----
commit 3522780c0fb73eb53394251d3b6d5bd3dd548b67
Author: Arun Murthy <acmurthy@apache.org>
Date:   2013-08-22T01:53:21Z

    Merge -c 1516358 from trunk to branch-2.1-beta to fix MAPREDUCE-5468. Fix MR AM recovery for map-only jobs. Contributed by Vinod K. V.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1516360 13f79535-47bb-0310-9956-ffa450edef68

commit 9b827d0c829d0b9447c9022ce78c4bcdfe0d4daa
Author: Arun Murthy <acmurthy@apache.org>
Date:   2013-08-22T02:00:33Z

    Merge -c 1516361 from trunk to branch-2.1-beta to fix MAPREDUCE-5475. Ensure MRClientService verifies ACLs for users. Contributed by Jason Lowe.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1516363 13f79535-47bb-0310-9956-ffa450edef68

commit eb31b999db0083c48ff5dcbef52c2a368908ca83
Author: Jason Darrell Lowe <jlowe@apache.org>
Date:   2013-08-22T20:39:12Z

    svn merge -c 1516594 FIXES: Revert MAPREDUCE-5475
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1516597 13f79535-47bb-0310-9956-ffa450edef68

commit dbbfdeed89023bb98f403fd56a3bdae2f6ccdf84
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-22T23:18:20Z

    MAPREDUCE-5476. Changed MR AM recovery code to cleanup staging-directory only after unregistering from the RM. Contributed by Jian He.
    svn merge --ignore-ancestry -c 1516660 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1516663 13f79535-47bb-0310-9956-ffa450edef68

commit 70db769b3826c9843a583cb57f84064af001de31
Author: Jing Zhao <jing9@apache.org>
Date:   2013-08-23T01:00:03Z

    HDFS-5124. Merge change r1516672 from branch-2.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1516673 13f79535-47bb-0310-9956-ffa450edef68

commit ba57f759656cc8e010580056cfd6a881ce1336c2
Author: Tsz-wo Sze <szetszwo@apache.org>
Date:   2013-08-23T08:43:28Z

    svn merge -c 1516745 from branch-2 for HADOOP-9899. Remove the debug message, added by HADOOP-8855, from KerberosAuthenticator. 
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1516749 13f79535-47bb-0310-9956-ffa450edef68

commit 252d7238f4b17e357e0fab70d1ca52715d033716
Author: Chris Nauroth <cnauroth@apache.org>
Date:   2013-08-23T17:04:57Z

    MAPREDUCE-5470. LocalJobRunner does not work on Windows. Contributed by Sandy Ryza.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1516933 13f79535-47bb-0310-9956-ffa450edef68

commit e369fbdc57d03a00a3cfe24491b7437522c690b5
Author: Sanford Ryza <sandy@apache.org>
Date:   2013-08-23T21:28:05Z

    MAPREDUCE-5478. TeraInputFormat unnecessarily defines its own FileSplit subclass (Sandy Ryza)
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517054 13f79535-47bb-0310-9956-ffa450edef68

commit e653508476626493bfaeef70bfc8a389d947c747
Author: Brandon Li <brandonli@apache.org>
Date:   2013-08-23T21:33:03Z

    HDFS-4947. Merging change r1517049 from branch-2
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517062 13f79535-47bb-0310-9956-ffa450edef68

commit 1ea776b191c5953eccfcc531f4a0263118c39a1c
Author: Jason Darrell Lowe <jlowe@apache.org>
Date:   2013-08-23T22:22:38Z

    svn merge -c 1517073 FIXES: YARN-707. Add user info in the YARN ClientToken. Contributed by Vinod Kumar Vavilapalli
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517078 13f79535-47bb-0310-9956-ffa450edef68

commit dc520091fd6a7cbc323e4086960ae9903f1be59c
Author: Jason Darrell Lowe <jlowe@apache.org>
Date:   2013-08-23T23:10:11Z

    svn merge -c 1517085 FIXES: MAPREDUCE-5475. MRClientService does not verify ACLs properly. Contributed by Jason Lowe
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517091 13f79535-47bb-0310-9956-ffa450edef68

commit 130ae47439842d4ae5da9e0895cdcffa06bb1635
Author: Jason Darrell Lowe <jlowe@apache.org>
Date:   2013-08-24T01:25:17Z

    svn merge -c 1517097 to revert MAPREDUCE-5475 and YARN-707
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517099 13f79535-47bb-0310-9956-ffa450edef68

commit b70af9224c736c5a38561ff25e25b878e6773b0c
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-24T02:49:13Z

    YARN-1085. Modified YARN and MR2 web-apps to do HTTP authentication in secure setup with kerberos. Contributed by Omkar Vinit Joshi.
    svn merge --ignore-ancestry -c 1517101 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517103 13f79535-47bb-0310-9956-ffa450edef68

commit ed7eb62d39f01a931922fd3e70e281cb98d8c7cd
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-24T21:17:33Z

    YARN-1074. Cleaned up YARN CLI application list to only display running applications by default. Contributed by Xuan Gong.
    svn merge --ignore-ancestry -c 1517196 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517198 13f79535-47bb-0310-9956-ffa450edef68

commit fca5712d35f08520c0b17cc6418afb8bc30ec7ae
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-24T23:33:46Z

    YARN-1094. Fixed a blocker with RM restart code because of which RM crashes when try to recover an existing app. Contributed by Vinod Kumar Vavilapalli.
    svn merge --ignore-ancestry -c 1517215 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517217 13f79535-47bb-0310-9956-ffa450edef68

commit a30e60d1fd038e518194a27320a8976b8bc1c2bf
Author: Alejandro Abdelnur <tucu@apache.org>
Date:   2013-08-26T15:47:05Z

    YARN-1008. MiniYARNCluster with multiple nodemanagers, all nodes have same key for allocations. (tucu)
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517567 13f79535-47bb-0310-9956-ffa450edef68

commit e46c61f7a7ae9cc3c981ec9a6a8b768826aed73c
Author: Sanford Ryza <sandy@apache.org>
Date:   2013-08-26T19:59:04Z

    YARN-1093. Corrections to Fair Scheduler documentation (Wing Yew Poon via Sandy Ryza)
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517668 13f79535-47bb-0310-9956-ffa450edef68

commit 45b8b5925486f7bb6026620bab56c7e26108a4ee
Author: Sanford Ryza <sandy@apache.org>
Date:   2013-08-26T20:49:02Z

    YARN-942. In Fair Scheduler documentation, inconsistency on which properties have prefix (Akira Ajisaka via Sandy Ryza)
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517693 13f79535-47bb-0310-9956-ffa450edef68

commit 9d7cbbc8d719d1c3ad2fdc74bff8a490b297720e
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-26T23:01:47Z

    YARN-1085. Addendum patch to address issues with the earlier patch.
    svn merge --ignore-ancestry -c 1517721 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517723 13f79535-47bb-0310-9956-ffa450edef68

commit 6452b863cb654466f4bb95571757fb2cd3971541
Author: Kihwal Lee <kihwal@apache.org>
Date:   2013-08-27T19:27:23Z

    svn merge -c 1517942 merging from branch-2 to branch-2.1-beta to fix HDFS-3245.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517943 13f79535-47bb-0310-9956-ffa450edef68

commit e3afbe8cd000bf7d3f33b1e70f5fdaca86a92591
Author: Kihwal Lee <kihwal@apache.org>
Date:   2013-08-27T20:59:20Z

    svn merge -c 1517982 merging from branch-2 to branch-2.1-beta to fix HDFS-5128.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517985 13f79535-47bb-0310-9956-ffa450edef68

commit f632839bfbef1dc037ce9f8fd79bf350e663c797
Author: Kihwal Lee <kihwal@apache.org>
Date:   2013-08-27T21:07:10Z

    svn merge -c 1517989 merging from trunk to branch-2.1-beta to fix HDFS-5132.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517991 13f79535-47bb-0310-9956-ffa450edef68

commit 2605f8dcd64530e45868150e86a94e712ecf0a5f
Author: Kihwal Lee <kihwal@apache.org>
Date:   2013-08-27T21:17:41Z

    svn merge -c 1517995 Merging from branch-2 to add the new test file for HDFS-3245 that was accidentally dropped.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1517997 13f79535-47bb-0310-9956-ffa450edef68

commit 578548353de0ab5c35c007ff3975fcbc9e514b47
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-27T23:39:56Z

    YARN-981. Fixed YARN webapp so that /logs servlet works like before. Contributed by Jian He.
    svn merge --ignore-ancestry -c 1518030 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1518032 13f79535-47bb-0310-9956-ffa450edef68

commit 90c48672f99b10d2000e9d654fbeebf2cc628a8c
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-27T23:54:51Z

    YARN-1083. Changed ResourceManager to fail when the expiry interval is less than the configured node-heartbeat interval. Contributed by Zhijie Shen.
    svn merge --ignore-ancestry -c 1518036 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1518038 13f79535-47bb-0310-9956-ffa450edef68

commit 34eefef554e7fb3b1124e6df356c2f95c6dc1c47
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-28T05:14:35Z

    YARN-602. Fixed NodeManager to not let users override some mandatory environmental variables. Contributed by Kenji Kikushima.
    svn merge --ignore-ancestry -c 1518077 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1518079 13f79535-47bb-0310-9956-ffa450edef68

commit 0e15d3546a2c6b96686311eb8ec74d13cdff6f3b
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-28T05:56:21Z

    YARN-905. Add state filters to nodes CLI (Wei Yan via Sandy Ryza)
    svn merge --ignore-ancestry -c 1517083 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1518082 13f79535-47bb-0310-9956-ffa450edef68

commit e70adee18ef3f6cbd1435598946ee63825d483e6
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   2013-08-28T05:58:25Z

    YARN-1081. Made a trivial change to YARN node CLI header to avoid potential confusion. Contributed by Akira AJISAKA.
    svn merge --ignore-ancestry -c 1518080 ../../trunk/
    
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1518084 13f79535-47bb-0310-9956-ffa450edef68

commit 3c153dd0684d048a53b8ae3bac30b51739d1648b
Author: Harsh J <harsh@apache.org>
Date:   2013-08-28T17:59:38Z

    HADOOP-9910. proxy server start and stop documentation wrong. Contributed by Andre Kelpe. (harsh)
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1518305 13f79535-47bb-0310-9956-ffa450edef68

commit f1c2a41f504d714d27afc0e0f1f3fba03c63aa94
Author: Sanford Ryza <sandy@apache.org>
Date:   2013-08-28T18:07:42Z

    HADOOP-9906. Move HAZKUtil to o.a.h.util.ZKUtil and make inner-classes public (Karthik Kambatla via Sandy Ryza)
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2.1-beta@1518310 13f79535-47bb-0310-9956-ffa450edef68

----
, I just finished testing this patch on my own local Hadoop environment. Everything seems to be working correctly. Did the pull request in order to deploy it. Thanks [~ted_yu] and [~airbots]., Github user babak-altiscale closed the pull request at:

    https://github.com/apache/hadoop-common/pull/18
, [~raviprak]:
What do you think of patch v3 ?, 1. I should have picked it up in HADOOP-9704, but shouldn't setWriter be private? I'm fine with doing that in a separate JIRA and assigning it to [~babakbehzad]
2. I wrote this test to check close(). Why does it not pass?
{noformat}
    @Test(expected=MetricsException.class)
    public void testCloseAndWrite() throws IOException {
      GraphiteSink sink = new GraphiteSink();
      List<MetricsTag> tags = new ArrayList<MetricsTag>();
      tags.add(new MetricsTag(MsInfo.Context, "all"));
      tags.add(new MetricsTag(MsInfo.Hostname, "host"));
      Set<AbstractMetric> metrics = new HashSet<AbstractMetric>();
      metrics.add(makeMetric("foo1", 1.25));
      metrics.add(makeMetric("foo2", 2.25));
      MetricsRecord record = new MetricsRecordImpl(MsInfo.Context, (long) 10000, tags, metrics);

      OutputStreamWriter writer = mock(OutputStreamWriter.class);
      ArgumentCaptor<String> argument = ArgumentCaptor.forClass(String.class);

      Log.info("Setting writer");
      sink.setWriter(writer);
      Log.info("Closing sink");
      sink.close();
      Log.info("Putting metrics");
      sink.putMetrics(record);
      Log.info("Put metrics successfully. This shouldn't have happened");
    }
{noformat}
3. [~Ted Yu] You are right. I couldn't find OutputStreamWriter making any guarantee about closing the underlying stream, so we are fine there., Hi [~raviprak], would you mind provide error message ? Then, I can figure out what is the problem., [~airbots]:
You can put Ravi's code in TestGraphiteMetrics.java
You should be able to see what failure the code produces., Hi  [~tedyu], I did. But I do not know his context to run this test case. For example, what type of "Log" he is using, etc; It will be great if [~raviprak] can provide more information. , I logged HADOOP-10715 for making GraphiteSink#setWriter() private., Patch v4 incorporates Ravi's test which passes., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12650825/hadoop-10660-v4.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4085//console

This message is automatically generated., Patch v5 fixes compilation issue w.r.t. closing socket., remove an unused variable "ArgumentCaptor<String> argument", {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12650831/hadoop-10660-v5.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4086//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4086//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12650835/HADOOP-10660-v6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4087//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4087//console

This message is automatically generated., +1. Will commit momentarily. Thanks [~airbots] and [~tedyu]], SUCCESS: Integrated in Hadoop-trunk-Commit #5722 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5722/])
HADOOP-10660. GraphiteSink should implement Closeable (Chen He and Ted Yu via raviprak) (raviprak: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1603379)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #587 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/587/])
HADOOP-10660. GraphiteSink should implement Closeable (Chen He and Ted Yu via raviprak) (raviprak: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1603379)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1778 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1778/])
HADOOP-10660. GraphiteSink should implement Closeable (Chen He and Ted Yu via raviprak) (raviprak: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1603379)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1805 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1805/])
HADOOP-10660. GraphiteSink should implement Closeable (Chen He and Ted Yu via raviprak) (raviprak: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1603379)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
]