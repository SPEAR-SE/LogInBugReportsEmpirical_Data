[Noticed an instance of this bug on an app whose pipes process ran for two complete hours after the parent java map task died.
I think we should introduce a ping mechanism, similar to the one we have for the task -> tasktracker communication, that periodically pings to check whether the java map/reduce process is up., Was the application generating progress messages? In other words, did the write on the command socket just block instead of reporting socket closed?, Application is not generating any progress messages.  

I reproduced the problem by putting an infinite loop in map method and killed Java map tasks when it is running. C++ processes does not die. 

I think  we need a ping mechanism from C++ process to Java task to solve this., As long as c++ process is communicating with the java application (like progress, emit etc.) , and if it is not able to communicate, then it is dieing. , I am downgrading the priority to Major since things work in the normal circumstances where the pipes process tries to communicate with its Java counterpart periodically (through progress reporting periodically, etc.). But, I still think that we need to handle the case where the pipes process is doing a long computation (without frequent progress reports) and the Java side gets killed during that time., +1

bq.But, I still think that we need to handle the case where the pipes process is doing a long computation (without frequent progress reports) and the Java side gets killed during that time.

The two options are:
   * Background thread which periodically pings the parent java map/reduce task to check if it is alive and kills the c++ process if not.
   * Use unix jobcontrol features i.e. make the java task the session the _process group leader_ (via setsid) and then send SIGTERM to the entire process group.

Being old-skool, I prefer jobcontrol. *smile*, > Being old-skool, I prefer jobcontrol. smile

Shouldn't we use the same solution we use for the child task process?  There we use a ping from a separate thread.  If we think jobcontrol is portable-enough and superior, then we should switch both to use that, no?  Or else we should just use a ping thread here., We see this a lot: pipes applications continuing as orphan processes after the parent task gets killed (e.g. speculatively executed task killed because of  'Already completed TIP') . When these applications sidestep the mapred framework and communicate to DFS directly using libhdfs, then lthe load to dfs sometimes becomes so high that the job eventually fails. , The attached patch adds background thread which pings the parent java map/reduce task every 30 seconds to check if it is alive.  If parent is not alive, it kills the c++ process after three retries.
Christian, Can you use this patch and let us know if you see improvement?, Sorry... forgot to add configurations changes to add pthread library., Submitting with configuration changes, -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12372284/patch-2092.txt
against trunk revision r607330.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs -1.  The patch appears to introduce 1 new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1432/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1432/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1432/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1432/console

This message is automatically generated., fixed findbugs warning., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12372353/patch-2092.txt
against trunk revision r608052.

    @author +1.  The patch does not contain any @author tags.

    javadoc -1.  The javadoc tool appears to have generated  messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1445/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1445/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1445/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1445/console

This message is automatically generated., The javadoc -1 is due to another jira that got committed., A couple of things bother me:
  1. There is no locking of the connection or context fields, so corruption will occur.
  2. ping should not be in Pipes.hh, since it should not be visible to the user., Added patch with locking for the upword protocol and writes to the variable 'done' in context. This will take care of the locking issues., The patch did not work for me. I tested the patch with a pipes application not emitting anything, just reading from DFS using libhdfs, and the application continued long after killing the task till it tried to shutdown the socket.

Another major headache of the current implementation is that the 'PING' enum value replaced the enum value for 'DONE' which increased by 1. This way the release process of applications needs to be sync'd up with Hadoop releases. It proved so inconvenient that I switched the two enums around in my patch.

On Unix checking for (getppid() == 1) works nicely. If there is need for pipes on Windows (is there?), there  might be no non-ugly way to retrieve the parent process, so I would suggest to use a ping from the parent to the child, and the child exits when there is no ping for a certain period., I tested this with a map having an infinite loop which has a sleep inside i.e. it does not do any emit or progress other than sleep. Then I killed java tasks and checked c++ processes dieing.  I also tried killing job and shutting down cluster, in all the cases I noticed c++ processes dieing. We cannnot see any fprintf messages once the java processes die. 
Christian, Can you check the behavior with the latest patch once again? , -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12372805/patch-2092.txt
against trunk revision r610910.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1537/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1537/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1537/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1537/console

This message is automatically generated., Canceling patch , it seems like flush() is platform dependent., This patch adds ping thread which connects to the java task and disconnects immediately. Ping is done every 5 seconds until the task is done. If ping fails, it retries 3 times and kills c++ process.

Thanks Christian for your inputs., Making this a blocker for 0.16 since people have seen significant performance issues due to these processes hanging around and using resources unnecessarily., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373502/patch-2092.1.txt
against trunk revision r613359.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1647/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1647/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1647/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1647/console

This message is automatically generated., Please add locking around the isDone method in the context and updating the done flag., bq. Please add locking around the isDone method in the context and updating the done flag.

Do we really need a lock here? Since, boolean is one byte memory and ping thread only reads it. Ping thread can read a stale value, since in the next iteration it will read the correct value.
Without doing a lock, we save the "lock" overhead., Never try to be tricky with threading, it is not worth the non-deterministic problems. The primary problem is that the optimizer and the multiple cpus all have caches and unless you use locking, bad things happen. Furthermore, this is not performance critical code. We have had to fix numerous problems like this in the Java code with EXACTLY this problem (with boolean done flags, even). Don't do this., Added locking around the isDone method in the context and updating the done flag., I modified Amareshwari's patch by pushing the mutex into the context object instead of a global variable., Resubmit to hadoop-qa., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12374075/2092.3.patch
against trunk revision 614721.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1680/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1680/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1680/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1680/console

This message is automatically generated., On Arun's suggestion, I put the pthreads check in a common m4 function., Looks good. +1, I just committed this. Thanks Amareshwari and Owen!, Integrated in Hadoop-trunk #380 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/380/])]