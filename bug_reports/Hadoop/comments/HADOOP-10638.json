[Setting target version to the next release since 2.4.0 is already out., Patch looks good to me, Mani. One question - can you please comment what testing of this patch you've done? I don't think our automated tests will actually exercise this change at all.

+1 pending Jenkins and an answer to the above question.

Also, no need to change it now, but for future reference we typically name the patch files just "<JIRA NUMBER>.patch", so "HDFS-6468.patch" in this case., Actually, given that this change is only to Hadoop Common code, I've moved the JIRA., Testing done:
Installed NFS and updated the hadoop-daemon.sh from under /usr/lib/hadoop/sbin with the patch included above. 
Set up the following environment variables in /etc/defaults/hadoop-hdfs-nfs3 
$HADOOP_PRIVILEGED_NFS_USER
$HADOOP_PRIVILEGED_NFS_LOG_DIR
$HADOOP_PRIVILEGED_NFS_PID_DIR

Then started and stopped NFS service successfully. The logs and pid file were pushed to the expected directories with the expected file names., Cool, good stuff. Will wait for Jenkins to come back and then go ahead and commit it if clean., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12647404/0001-Picking-the-right-pid-file-when-running-NFS-as-privi.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7006//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7006//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12647404/0001-Picking-the-right-pid-file-when-running-NFS-as-privi.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.ha.TestZKFailoverControllerStress

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3982//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3982//console

This message is automatically generated., Hey Aaron,

I see a bunch of comments from Hadoop QA and see two -1’s 
1. For not having new/modified tests. Its asks for a list of manual steps taken to verify the change - which I’ve already commented on.
2. One of the tests failed, and is marked as a regression with this call stack:

Test: org.apache.hadoop.ha.TestZKFailoverControllerStress.testExpireBackAndForth

org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode
	at org.apache.zookeeper.server.DataTree.getData(DataTree.java:648)
	at org.apache.zookeeper.server.ZKDatabase.getData(ZKDatabase.java:371)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireActiveLockHolder(MiniZKFCCluster.java:199)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireAndVerifyFailover(MiniZKFCCluster.java:234)
	at org.apache.hadoop.ha.TestZKFailoverControllerStress.testExpireBackAndForth(TestZKFailoverControllerStress.java:84)

Not sure if this related to the changes I made, but can you please take a look.

Thanks!





, It's fine to not include any tests in this case since it's a script-only change and we don't have any tests for those. That's why I asked you about what manual testing you did for this.

The test failure is surely unrelated - no way this change could affect that. It's probably just a flake.

Given this, I'm going to commit this momentarily., I've just committed this to trunk and branch-2.

Thanks a lot for the contribution, Mani., SUCCESS: Integrated in Hadoop-trunk-Commit #5630 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5630/])
HADOOP-10638. Updating hadoop-daemon.sh to work as expected when nfs is started as a privileged user. Contributed by Manikandan Narayanaswamy. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1598451)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemon.sh
, FAILURE: Integrated in Hadoop-Yarn-trunk #568 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/568/])
HADOOP-10638. Updating hadoop-daemon.sh to work as expected when nfs is started as a privileged user. Contributed by Manikandan Narayanaswamy. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1598451)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemon.sh
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1759 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1759/])
HADOOP-10638. Updating hadoop-daemon.sh to work as expected when nfs is started as a privileged user. Contributed by Manikandan Narayanaswamy. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1598451)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemon.sh
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1786 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1786/])
HADOOP-10638. Updating hadoop-daemon.sh to work as expected when nfs is started as a privileged user. Contributed by Manikandan Narayanaswamy. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1598451)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemon.sh
]