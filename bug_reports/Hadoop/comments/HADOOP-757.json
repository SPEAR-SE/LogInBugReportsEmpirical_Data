[
Nothing obvious in code to explain this. Please report if you see this again. Checked some large sort run, and not able to find any traces.
, 
Both this and HADOOP-758 could be cause if creation of a tmp file for a block fails., HADOOP-758 has a patch that handles exceptions better and ignores the exception show in the description above. It is not enough since we are actually trying to write a fd that we don't own, which could corrupt data if someone else gets that fd. Not sure why FileOutputStream does not detect that it is already closed. Fix is to set backupStream to null when it is closed and handle. , This is related to HADOOP-757 and not same., 
Attached patch sets backupStream to null when it is closed. I have taken care of backupStream being null before writing (it throws an IOException). I don't think there are other cases but in the worst case it would be null pointer exception and would be "safer" than writing to wrong fd.
, +1, because http://issues.apache.org/jira/secure/attachment/12348779/HADOOP-757.patch applied and successfully tested against trunk revision r495045., I just committed this.  Thanks, Raghu!, This fix has a bug. Needs patch in HADOOP-902 to fix.
]