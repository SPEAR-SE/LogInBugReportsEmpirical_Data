[Add a RetryProxy around the JobSubmissionProtocol so that time outs are retried., I forgot one of the control paths. Here is an updated patch., I'm concerned about retrying the submitJob() method.  All the others seem okay to retry.  The only other one with side-effects is killJob(), and it's okay to call that more than once.  But we really don't want to submit a job twice., I agree that submitJob needs to be more careful. But rather than not protect it against timeouts, the better solution is to have the server ignore the duplicate request., I'm okay with making submit safe against retries, and then retrying it.  That would indeed be better.  Perhaps the client can ask the server for a job-id, then submit the job with the id, and the server can ignore duplicate submissions.  We'd might want to make job ids a bit more unique too.  Otherwise, if the JobTracker restarts between submit retries then the same job-id could end up being used by a different client, and a submission would be ignored.

In the meantime, we'd probably get 90+% of the benefit of this patch by simply not retrying submits.  Then we can have a separate issue to make submits retryable., Ok, this patch has:
  1. Retry on timeouts for JobSubmissionProtocol.
  2. A new JobSubmissionProtocol getNewJobId method to assign a new job_id.
  3. Submit job now passes in the jobid.
  4. The submit directory is now $system/$jobid.
  5. Change some of the map/reduce classes to expect JobConf instead of Configurations, so that I can get the System directory using the method., +1

http://issues.apache.org/jira/secure/attachment/12359198/job-client-retry-4.patch applied and successfully tested against trunk revision r544740.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/256/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/256/console, I don't see how this handles the case I mentioned above, where:

1. Client A allocates job-id 1.
2. JobTracker restarts.
3. Client B allocates job-id 1.
4. Client B submits job 1.
5. Client A retries submtting job 1, and is returned B's job.

Did I miss something, or could this happen?  An easy fix is to make job-ids more unique.
, > An easy fix is to make job-ids more unique.

+1 to that: I don't really like the reuse of job_0001 across restarts.  It makes job automation more difficult.
, I think that my patch addresses the problem at hand. If the JobTracker bounces, they'll get a connection error, which will be propagated to the user. I can understand that there is a desire for persistent job ids, but that is a big enough feature with enough downsides that it should be addressed in a separate jira., So your contention is that only TimeoutException is retried, and that there's no way a server could deliver a TimeoutException near a bounce?  Can you elaborate this?, I filed the unique job id bug over in HADOOP-1473., We'll commit this after HADOOP-1473, right?, We'll re-submit this after HADOOP-1473., Ok, this patch is updated to the current head., I just committed this.  Thanks, Owen!, -1, could not apply patch.

The patch command could not apply the latest attachment http://issues.apache.org/jira/secure/attachment/12361916/1400.patch as a patch to trunk revision r556754.

Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/421/console

Please note that this message is automatically generated and may represent a problem with the automation system and not the patch.]