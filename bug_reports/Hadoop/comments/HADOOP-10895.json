[HI [~tucu00],

This jira is a blocker in the list http://s.apache.org/hadoop-2.6.0-blockers and it's currently owned by you. I wonder whether you will have time to work on. If not, would you mind reassigning it to me and I will spend time on it? Thanks.

, yongjun, go ahead, take it (cannot reassign from phone jira app). thanks, Thanks [~tucu00], I will work on.
, I just submitted patch rev 001. Hightlight of the changes:

* Since hadoop-auth doesn't have dependency on hadoop-common, we can't access the usual configuration object from within hadoop-auth.  I changed ConnectionConfigurator  from interface to class, and make it carry the info about whether fallback to pseudo authenticator is enabled. 
* I made it the client of this class' responsibility to pass the info to ConnectionConfiguration. 
* I used the same property used for HADOOP-9698 for enabling/disabling the fallback. The default is that the fallback is disabled.
* Changed many related tests to enable the fallback so the tests work the same way as before this fix.

Hi [~tucu00], wonder if you will have time to review, I would really appreciate if you can. Please let me know if not. Thanks.

BTW, Thanks [~rkanter] for some discussion and suggestion.
, The patch spans hadoop-comon-project (hadoop-auth, hadoop-common, hadoop-kms), hadoop-hdfs-project and hadoop-yarn-project, we can split the patch to multiple subtasks for each project when it's finalized.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12676211/HADOOP-10895.001.patch
  against trunk revision b294276.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 7 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.ha.TestZKFailoverControllerStress
                  org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4934//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/4934//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4934//console

This message is automatically generated., TestZKFailoverControllerStress failure was reported as HADOOP-10668, which is still open.
TestDNFencing was reported as HDFS-7226, for which I've already  provided patch, and it's close to commit.

, Thanks [~yzhangal] for working on this.

I don't like to change {{ConnectionConfigurator}} as a class and add {{allowFallbackToPseudoAuth}} in it.  It looks strange we modify _URLConnectionFactory_ and _SSLFactory_.
allow fallback is better to be in {{Authenticator}}? , HI [~hitliuyi], thanks for the review and comments, your point is well taken, I will look into alternatives.
, Hello [~hitliuyi],

I just uploaded a new rev (002). Many thanks for your valuable comments, and hopefully this version looks better. Would you please take a look again when you get chance? thanks.

, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12678132/HADOOP-10895.002.patch
  against trunk revision 0126cf1.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 7 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.security.authentication.client.TestPseudoAuthenticator
                  org.apache.hadoop.security.authentication.client.TestKerberosAuthenticator
                  org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken
                  org.apache.hadoop.crypto.key.kms.server.TestKMSWithZK

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4986//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4986//console

This message is automatically generated., Overall it looks fine to me (other than the failed unit tests).  
However, I'm still concerned about disabling this by default.  This is going to break other components that depend on the fallback behavior.  I think the default should be to allow fallback with the option of disabling it.  In fact, looking at HADOOP-9698, it looks like it allows falling back by default too., Hi [~rkanter],

Thanks for your review and comments. The fallback default introduced for HADOOP-9698 is false:

http://mail-archives.apache.org/mod_mbox/hadoop-common-commits/201307.mbox/%3C20130730181051.B71712388900@eris.apache.org%3E

I think the idea is to disable the fallback by default and enable it only when user set the config property to true. Right?

Sorry I overlooked some testcases when working on last rev. Just uploaded new rev (003) to address the failures.

Thanks.

, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12678402/HADOOP-10895.003.patch
  against trunk revision 4727064.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4993//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4993//console

This message is automatically generated., You're right, HADOOP-9698 sets the default to false.  In that case, I guess we should do the same here.  
Please set the "Incompatible change" flag in the JIRA and add a release note about this., Thanks Robert, I marked it as incompatible change. Thanks [~hitliuyi] who is helping the review. I will add release note when closing.
, Added release note too, I thought I could only add release note when closing the jira:-). Thanks [~andrew.wang].

, I took a closer look and had a few comments:
# In {{TestPseudoAuthenticator}}, you don't need to change the fallback to {{true}}.  The {{PseudoAuthenticator}} can't actually fallback (in fact, the setter doesn't do anything).
# It looks like most of the tests enable the fallback behavior.  If the default is going to be not to fallback, I think the tests should be updated to not require falling back (unless the test is specifically testing something that requires fallback to be enabled).
# Can you add a test that verifies that you can't fallback when it's disabled?
# Setting "ipc.client.fallback-to-simple-auth-allowed" is only going to work for the KMS.  If I want to create a {{KerberosAuthenticator}} that allows fallback, I have to call the {{setAllowDefaultAuthToFallbackToPseudo}} method.  However, once I add that call, if I also wanted to allow my code to be compiled against a previous version of Hadoop, it won't compile now.  The nice thing about having a property config to enable/disable this is that it doesn't breaking compiling.  In other words, it would be nice if I could set a property config to enable the fallback: this would allow the fallback going forward but still allow the code to work with earlier Hadoop versions (they would just ignore the property)., Thanks a lot [~rkanter], very good points. I got some idea how to make it better. Will address your comments in next rev. 
 , HI [~rkanter] and [~hitliuyi],

Thanks a lot for your earlier review and comments. I uploaded rev 004 to address them.

{quote}
In TestPseudoAuthenticator, you don't need to change the fallback to true. 
{quote}
Done. 

{quote}
It looks like most of the tests enable the fallback behavior. If the default is going to be not to fallback, I think the tests should be updated to not require falling back (unless the test is specifically testing something that requires fallback to be enabled).
{quote}
Indeed quite some existing testcases count on the fallback behaviour. Enabling the config property make them to pass. So this indicates that the old behaviour is not broken as long as we enable the config property. I agree that we should have some tests that don't count on the fallback, however, I expect there should be some tests like that already (those I don't have to fix because they succeeded without fallback), because the fallback is just a fallback after all. I will probably dig some more to find some of those tests out. 

{quote}
Can you add a test that verifies that you can't fallback when it's disabled?
{quote}
Added 
{code}
@Test(expected=AuthenticationException.class)
  public void testDisallowFallbacktoPseudoAuthenticatorFail()
{code}

{quote}
Setting "ipc.client.fallback-to-simple-auth-allowed"...
{quote}
In the new rev I made it a requirement to pass the default authenticator to the constructor of AuthenticatedURL, because it's not easy to pass the config property to the  old default authenticator implemented in AuthenicatedURL. I hope this can work better.

Thanks for taking further look at the new rev.












, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12678771/HADOOP-10895.004.patch
  against trunk revision 5c0381c.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 11 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-auth-examples hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5002//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5002//console

This message is automatically generated., {quote}
I will probably dig some more to find some of those tests out. 
{quote}
I updated rev 004 by separating out the testcases that need fallback and those don't, and only enable fallback for those need it.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12678829/HADOOP-10895.004.patch
  against trunk revision 5c0381c.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-auth-examples hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl

                                      The test build failed in hadoop-hdfs-project/hadoop-hdfs-httpfs 

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5004//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5004//console

This message is automatically generated., Hi [~yzhangal], your patch has a big impact, and my suggestion is to make it small. Also I would like to hear other committers' comments, since it looks simple, but trick.
* I see you remove existing APIs/Constructor from AuthenticatedURL.java and DelegationTokenAuthenticatedURL.java, it's not a good practice. It will break others who are using {{hadoop-auth}}
* we don't need get fallback for Authenticator, and only need set
{code}
public void setAllowFallback(boolean allowFallback);
{code}
* I suggest only add a simple method to AuthenticatedURL, and no need change for DelegationTokenAuthenticatedURL
{code}
public void setAllowAuthenticatorFallback(boolean allowFallback) {
  authenticator.setAllowFallback(allowFallback);
}
{code}
* Other places just need to call {{setAllowAuthenticatorFallback}} of AuthenticatedURL or {{setAllowFallback}} of Authenticator. Then it's more simpler. 


, 

i agree with Yi, in having a setFallback method, we could have a static and instance versions of it, to allow global and per conn setting , HI [~hitliuyi],

Thanks a lot for your review and comments!  I agree with you that though this jira looks simple but it's kind of tricky.

I think rev3 is quite close to what you suggested. When I tried to address Robert's comments (especially comment #4), I came up with the idea of enforcing user to pass an authenticator to AuthenticatedUR (in rev4), because I thought if a client need to solve the issue here, the client code need to be changed anyways. But I agree with you that keeping the old interface is likely better.

I think going with the approach in rev3 works with me too. Would you comment on rev3 if you have time? I will look into improving rev3 to address both Robert's and your comments.

Hi [~rkanter], thanks for your earlier comments. About your comment #4 of using property, the problem is that we need a way to communicate the property to AuthenticatedURL etc, which we don't have interface to do so. Thus it appears to me that it's unavoidable to add new interface (rev3) or enforcing user to pass an authenticator object (rev4). But I will discuss with you about it.

Thanks again!

, HI [~tucu00],

Thanks a lot for your comment/suggestion. I did not see it earlier until now. I guess both of us were writing last comments at the same time. I think your suggestion of creating a static object for global setting would help here. I will work on addressing the comments from  you /Yi/Robert in next rev. 

Many thanks to Yi for some side discussion.




, BTW [~tucu00],  

My interpretation of creating a static object is to replace
{code}
private static Class<? extends Authenticator> DEFAULT_AUTHENTICATOR = KerberosAuthenticator.class;
{quote}
in AuthenticatedURLwith a real authenticator object, and create the obecject when setAllowFallback() is called.

This means we need to remove the methods in AuthenticatedURL that set/get DEFAULT_AUTHENTICATOR. 

Would you please confirm whether my interpretation is correct? And if we have to make the interface change in AuthenticatedURL like this, is there any compatibility issue? 

Or you meant we will need to keep the pre-existing DEFAULT_AUTHENTICATOR, and don't touch its accessor interface, but introduce a new static authenticator object to co-exist with DEFAULT_AUTHENTICATOR?

Actually rev3 tries to solve the problem along this direction. However,  instead of creating an authenticator object, rev3  introduced a boolean variable in AuthenticatedURl to indicate whether the DEFAULT_AUTHENTICATOR to be created need to allow fallback. So the interface to set/get DEFAULT_AUTHENTICATOR is not touched in rev3.

Thanks a lot.


, A further thought, we are not removing pre-existing DEFAULT_AUTHENTICATOR related interface to be safe, 

* rev3 approach is to have a static boolean member in AuthenticatedURL to remember whether fallback is supported (set by method {{AuthenticatedURL#setAllowDefaultAuthToFallbackToPseudo}}), and apply it when creating an authenticator if the client doesn't pass one. The authenticator created here is dynamic instead of static.

*the suggested change is to create a static authenticator when {{AuthenticatedURL#setAllowDefaultAuthToFallbackToPseudo}} is called. A static authenticator of type DEFAULT_AUTHENTICATOR is created here. Notice that when {{AuthenticatedURL#setDefaultAuthenticator}} is called, the value of DEFAULT_AUTHENTICATOR is reset, so we need to create the static authenticator object again even if it was created  already.

So the new suggested change is essentially the same as rev3 from client side point of view.  The difference is when to create the object and whether we create dynamic or static default authenticator object, which is transparent to client. 

Thanks.

, IMO, the fallback is a concern of the {{KerberosAuthenticator}, not of the {{AuthenticatedURL}}.

I would add the methods, both static and instance versions, to the {{KerberosAuthenticator}}, and instance version to the {{DelegationTokenKerberosAuthenticator}} (the static version will feed from the {{KerberosAuthenticator}}.

Then, the {{AuthenticatedURL}} would simply have a method to get the authenticator that would allow disabling the fallback on the configured authenticator if a non-configured one has been provided., HI [~tucu00],

Thanks a lot for your input. The problem is that {{AuthenticatedURL}} creates authenticator when client code doesn't pass one, 
{code}
public AuthenticatedURL(Authenticator authenticator, ConnectionConfigurator connConfigurator) {
    try {
      if (authenticator != null) {
        this.authenticator = authenticator;
      } else {
        // use default authenticator
        this.authenticator = DEFAULT_AUTHENTICATOR.newInstance(); <== this is where the default authenticator is created
     }
  ...
{code}

we somehow need to let AuthenticatedURL know whether to create an authenticator that allows fallback or not. Certainly this is relevant only when the authenticator is KerberosAuthenticator. Since user is allowed to set the default authenticator type, and {{AuthenticatedURL}} doesn't really care what authenticator type it is creating.

Are you suggesting that we can change AuthenticatedURL to not create authenticator in the above code, and instead, to retrieve the static version from the corresponding authenticator class?  I can make this change to {{AuthenticatedURL}}, I wonder whether there is any compatibility concern of doing so?

Thanks.
 , Because the {{AuthenticatedURL}} creates the {{Authenticator}} with some constructor is that I was suggesting adding the {{getAuthenticator()}} method to the {{AuthenticatedURL}} so the {{Authenticator}} can be configured not do  fallback. Then we don't have to change any constructor. 

Makes sense?, Thanks [~tucu00], 

Rev3's AuthenticatedURL code is already very much like what you said:
{code}
  /*
   *  whether it's allowed to let DEFAULT_AUTHENTICATOR to fallback to PseudoAuthenticator
   */
  private static boolean allowDefaultAuthToFallbackToPseudo = false;
  
  /**
   * Set to allow/disallow the DEFAULT_AUTHENTICATOR to fallback to
   * PseudoAuthenticator. Notice that by default, the DEFAULT_AUTHENTICATOR
   * disallow the fallback.
   */
  public static void setAllowDefaultAuthToFallbackToPseudo(
      final boolean allowFallback) {
    allowDefaultAuthToFallbackToPseudo = allowFallback;
  }

  public AuthenticatedURL(Authenticator authenticator,
                          ConnectionConfigurator connConfigurator) {
    try {
      if (authenticator != null) {
        this.authenticator = authenticator;
      } else {
        // use default authenticator
        this.authenticator = DEFAULT_AUTHENTICATOR.newInstance();   
        this.authenticator.setAllowFallbackToPseudoAuthenticator(              <=== configure the authenticator
            allowDefaultAuthToFallbackToPseudo);
      }
    } catch (Exception ex) {
      throw new RuntimeException(ex);
    }
    ...
{code}
except it calls {{DEFAULT_AUTHENTICATOR.newInstance()}} to create an authenticator instance. So what you were suggesting is to replace this line with a {{getAuthenticator()}} call, that retrieves the static instance from the corresponding authenticator class (Per your earlier suggestion, each authenticator class is going to have a static instance member).  

Is my understanding correct? If so, a little change on top of rev3 would address your suggestions...

Thanks.
, [~tucu00], changing the default to not allow fallback will break anybody relying on that behavior.  For example, the Oozie client.  It would be okay if we had a config property to change it back, as this would allow the Oozie client to compile against this version of hadoop-auth and prior versions without any code changes.  However, it looks like we can't do that, and a method will have to be called.  This means that projects depending on this fallback behavior either have to stick to only an older version of hadoop-auth or only a newer version, which makes things more difficult.  
Why can't we keep the fallback enabled by default, and a method call to disable it?  This shouldn't be a security problem because if you only want Kerberos, the server should only use the KerberosAuthenticationHandler, which IIRC, won't allow pseudo auth, even if the client falls back and tries to use it, right?, Robert, I'm not suggesting changing the default, just how to wire the disabling capabilities., Hi @tucu,

Thanks for answering Robert's question. The fallback default introduced for HADOOP-9698 is false:
http://mail-archives.apache.org/mod_mbox/hadoop-common-commits/201307.mbox/%3C20130730181051.B71712388900@eris.apache.org%3E
Which means, if we are going to use the same config property, the default will be false (changing from the hardcoded default).
Do we need to introduce a different config property for this? It seems consistent to have same default for this one and hadoop-9698.

BTW, would you please also address  my questions to you in my last comment? I tried to address Robert's comment #4, that's what made me to move from rev3 to rev4. Sounds rev3 is close to what you are suggesting. Thanks a lot.






, By the way, if we don't change the default (i.e. if fallback is the default), then my 4th comment doesn't apply anymore, Hi [~rkanter] and [~tucu00],

Please see ATM's comments here:

https://issues.apache.org/jira/browse/HDFS-6776?focusedCommentId=14126388&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14126388

Thanks.
, I discussed this with [~yzhangal] and he showed me the security issue at that link from ATM's comment.  If my understanding is correct, the problem with allowing fallback is that a man-in-the-middle attack could trick the client into giving it information without needing Kerberos credentials.  For example, if a malicious fake NameNode somehow tricked a client into talking to it instead of the real NameNode, it normally would have a problem because it would have to get valid Kerberos credentials to actually talk to the client.  However, with the fallback enabled, it could trick the client into falling back to pseudo auth, where it could then continue talking to the client, and getting potentially sensitive information from it (e.g. you're trying to upload a file with social security numbers in it or something).

In that case, we should disable this and we'll just have to break compatibility.  Projects depending on the fallback behavior will have to update their code to enable it, or decide that they don't want to allow the fallback anymore., HI Guys,

Thanks a lot for the review/feedback/discussion so far.

HI [~tucu00],

To address yours comments, I uploaded a slightly modified version of rev3 (rev3v1) with a {{getDefaultAuthenticatorInstance}} method. 

About your suggestion,
{quote}
IMO, the fallback is a concern of the {{KerberosAuthenticator}}, not of the {{AuthenticatedURL}}.
I would add the methods, both static and instance versions, to the KerberosAuthenticator, and instance version to the DelegationTokenKerberosAuthenticator (the static version will feed from the KerberosAuthenticator.
{quote}

I agree that only {{KerberosAuthenticator}} and {{DelegationTokenKerberosAuthenticator}} are relevant here.  Please notice that in rev3 all the authenticator types have the instance interface (see Authenticator.java) in rev3.   The remaining thing that I would like to discuss a bit more is about where to put the static version interface. 

Assume that we put the static interface to the two classes {{KerberosAuthenticator}} and {{DelegationTokenKerberosAuthenticator}}. The type of the default authenticator in AuthenticatedURL (and DelegationTokenAuthenticatedURL) may or may not be these two
classes because the client code is allowed to set the default authenticator type. That means, when AuthenticatedURL create a default authenticator, it need to check the type of the authenticator and do things differently for different types, I'm worried that this may not be that clean.  So I haven't done this yet.

I intend to use patch rev3v1 for further discussion.  Many thanks for taking a look and comment again.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679175/HADOOP-10895.003v1.patch
  against trunk revision 2bb327e.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 9 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancer

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5011//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5011//console

This message is automatically generated., HI [~tucu00],

I uploaded v3rev2 which is closest to address your comments in my understanding. 

This version also illustrates the type checking needed when AuthenticatedURL (and DelegationTokenAuthenticatedURL) creates a default authenticator, as I described in my last comment. We can see the diff between rev3v1 and rev3v2.

Would you please help taking a look again? you can refer to both v3rev1 and v3rev2.

Thanks a lot.
, Uploaded v3rev2improved version.  Thanks.

, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679247/HADOOP-10895.003v2.patch
  against trunk revision 2bb327e.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 9 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5014//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5014//console

This message is automatically generated., Hi Guys, 

If we make the default constructor of KerberosAuthenticator and KerberosDelegationTokenAuthenticator to apply the static boolean allowDefaultAuthToFallbackToPseudo in KerberosAuthenticator, then we can continue to use the {{DEFAULT_AUTHENTICATOR.newInstance()}} call in class AuthenticatedURL and DelegationTokenAuthenticatedURL, and it would look cleaner.
E.g., change
{code}
 public KerberosAuthenticator() {
    this(false);
  }
{code}
to
{code}
 public KerberosAuthenticator() {
    this(allowDefaultAuthToFallbackToPseudo);
 }
{code}
The suggested {{getDefaultAuthenticatorInstance()}} method would simply be {{DEFAULT_AUTHENTICATOR.newInstance()}} .
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679279/HADOOP-10895.003v2improved.patch
  against trunk revision 1eed102.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 9 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5015//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5015//console

This message is automatically generated., Uploaded rev 005 per the last comment I made (I made the default constructor  to use the static setting of fallback).

The other revs I submitted earlier today were kind of for discussion purpose. I think the latest one (005) is cleaner. I'd appreciate that you guys can help with another round of review. 

Thanks a lot.

, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679308/HADOOP-10895.003v2improved.patch
  against trunk revision 1eed102.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 9 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The test build failed in hadoop-hdfs-project/hadoop-hdfs-httpfs 

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5017//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5017//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679388/HADOOP-10895.005.patch
  against trunk revision dbf30e3.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 9 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.
        See https://builds.apache.org/job/PreCommit-HADOOP-Build/5021//artifact/patchprocess/diffJavadocWarnings.txt for details.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5021//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5021//console

This message is automatically generated., Running the failed test locally succeeded. I also saw the same test failed in one run reported here and succeeded locally: 
https://issues.apache.org/jira/browse/HADOOP-10771?focusedCommentId=14077437&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14077437
It's likely a flaky one.

, Uploaded rev 006, with two improvements on top of 005:

* Added and improved some javadocs
* Separate testcases that need fallback from those don't, and config them separately.

Thanks.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679595/HADOOP-10895.006.patch
  against trunk revision b4c951a.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.
        See https://builds.apache.org/job/PreCommit-HADOOP-Build/5034//artifact/patchprocess/diffJavadocWarnings.txt for details.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.hdfs.server.namenode.TestCheckpoint

                                      The following test timeouts occurred in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

org.apache.hadoop.hdfs.server.namenode.TestBackupNode

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5034//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5034//console

This message is automatically generated., Modifying the {{Authenticator}} interface breaks backwards compatibility., Many thanks [~tucu00],  Very helpful input, I just uploaded new rev to address that. Would you please help to quickly browse again due to the 2.6 schedule? thanks again.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679693/HADOOP-10895.007.patch
  against trunk revision 8549fa5.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.hdfs.server.namenode.TestCheckpoint

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5038//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5038//console

This message is automatically generated., I saw that TestCheckpoint also failed in trunk run https://builds.apache.org/job/Hadoop-Hdfs-trunk/1924/, and created jira HDFS-7370, and provided a patch there. It turned out to be HDFS-7333 which is resolved now. Thanks.

, The name of the properties and methods {{allowFallbackToPseudoAuth}} and 
{{allowDefaultAuthToFallbackToPseudo}} is a bit odd, I would have 'Default' at the end.

In the {{KMSClientProvider}}, instead setting the default fallback, we should create the authenticator with the on/off setting and pass it to the authenticated URL. You don't want a global setting as some other place in the code could change the default and it will unknowingly impact the {{KMSCLientProvider}}. This should be the rule for all places where {{AuthenticatedURL}} is used.

Other than that, the patch seem OK.

Thx
, Hi [~tucu00],

Many thanks for your comments. Had to work on a critical internal issue for some time, so sorry for being late here.

About your second comment, I also think it's a good practice for all client code to create an authenticator with the expected on/off setting and pass it to AuthenticatedURL or DelegationTokenAuthenticatedURL's constructor. I actually tried to enforce that all client must pass a valid authenticator in rev004. But to be backward compatible, we moved on to rev007 now.

Currently KMSClientProvider uses constructor {{public DelegationTokenAuthenticatedURL(ConnectionConfigurator connConfigurator)}} and counts on DelegationTokenAuthenticatedURL to create a default authenticator of type {{DelegationTokenAuthenticatedURL#DEFAULT_AUTHENTICATOR}}.

To address your comment #2,  we need to create an authenticator in KMSClientProvider. We need to know what type of authenticator to create. To be backward compatible, it seems we should continue to use the type  {{DelegationTokenAuthenticatedURL#DEFAULT_AUTHENTICATOR}}, which is defaulted to {{KerberosDelegationTokenAuthenticator.class}} and is resettable by client code. 

So to address your comment#1, we can replace the following code in KMSClientProvider
{code}
public HttpURLConnection run() throws Exception {
     DelegationTokenAuthenticatedURL authUrl =
             new DelegationTokenAuthenticatedURL(configurator);
{code}
with
{code}
public HttpURLConnection run() throws Exception {
     Class<? extends DelegationTokenAuthenticator> authType = DelegationTokenAuthenticatedURL.getDefaultDelegationTokenAuthenticator();
     DelegationTokenAuthenticator auth = (authType == KerberosDelegationTokenAuthenticator.class)? 
           new KerberosDelegationTokenAuthenticator(allowFallback) : authType.newInstance();
     DelegationTokenAuthenticatedURL authUrl =
           new DelegationTokenAuthenticatedURL(auth, configurator);
{code}

Would you please confirm if this is what you are looking for? 

Thanks a lot.
, Hi [~tucu00],

The concern you raised in your comment #2  is that some code might mess with the default fallback setting in the KerberosAuthenticator and cause unwanted effect.  I came up an alternative solution that I think would address this concern without having to do the change described in my last comment. I just uploaded rev 008, with your comment #1 addressed too.

That is, let KMSClientProvider remember the value of allowFallback specified in the configuration file as a private boolean member when KMSClientProvider object is constructed, and then refresh the KerberosAuthenticator's default setting each time before KMSClientProvider object creates AuthenticatatedURL object.

After all, our intention is that the default setting should be the same as specified in the configuration file all the time after initialization. What we are adding here is a protection in case some code accidentally changed the setting.

BTW, as far as I can see, the only production code that has the need for this change is KMSClientProvider, other similar places are in testing code. I think it's ok for the other places to rely on setting the default fallback at initialization time without refreshing, which would even help us to find any culprit code that tries to mess with the default setting after initialization, if error happens.

Would you please help take a look at rev 008?

Thanks a lot.
, BTW, I'm flexible going with this new alternative, or have a solution toward the direction mentioned in
https://issues.apache.org/jira/browse/HADOOP-10895?focusedCommentId=14203225&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14203225

Thanks for the feedback.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12680395/HADOOP-10895.008.patch
  against trunk revision 9a4e0d3.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 1 warning messages.
        See https://builds.apache.org/job/PreCommit-HADOOP-Build/5052//artifact/patchprocess/diffJavadocWarnings.txt for details.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-auth-examples hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5052//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5052//console

This message is automatically generated., Updated rev008 to address the javadoc warning.
, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12680440/HADOOP-10895.008.patch
  against trunk revision 6caa810.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-auth-examples hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5054//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5054//console

This message is automatically generated., I'm worried about pulling this into 2.6 at the last minute... seems like this could come right after in 2.7?, Hi [~acmurthy], I'm very sorry for the delay here. I hoped we could resolve this sooner. There was some trickiness that we try both maintaining compatibility as much as possible and avoiding potential problems. We had forth and back discussions, but I think we are converging.

HI [~tucu00], do you think we should get this into 2.7 instead?   thanks.

, [~yzhangal] - there is no need to apologize at all... these things are very normal.

I just feel worried about pulling this in the last minute, let's commit it to trunk/branch-2 ASAP, this way we get bake time early for 2.7. I should be able create 2.7 very soon with primary reason being to drop JDK-1.6. Makes sense? Thanks., HI [~acmurthy], thanks a lot for your kind words. Your concern of pulling this in the last minute and the 2.7 planning makes sense to me. We will certainly try to get the fix in asap, pending review of the latest rev.


, Thanks for your patience and understanding [~yzhangal]... not to mention your contributions, please keep them coming., Hi [~acmurthy], thanks for your patience and understanding too

Hi [~tucu00], 
I hope rev008 addressed your comments, would you please help taking a look? if you think it's not yet, would you please answer my question in https://issues.apache.org/jira/browse/HADOOP-10895?focusedCommentId=14203225&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14203225
? thanks a lot.
, Hi [~tucu00],  [~hitliuyi], and [~rkanter],

Thank you guys a lot for the earlier reviews. Since we are talking about 2.7 and 2.8 now, I hope we can get this issue resolved as soon as possible.  Rev8 addressed (or attempted to address) all of your earlier comments. It might be out-of-date now, but if you could review it on top of  trunk revision 6caa810 (on which latest jenkins test was run), I will rebase it on latest while addressing your new comments if there are any. Appreciate your help very much!


, I've re-looked at rev 8 and it looks fine to me.  I'm going to try it out a bit in a cluster soon.  
In the meantime, any other comments from anyone?  [~tucu00]? [~hitliuyi]?

[~yzhangal], I'm not sure the release note covers all cases.  I don't think the "ipc.client.fallback-to-simple-auth-allowed" property covers the case of a 3rd-party program (i.e. a non-Hadoop program) using KerberosAuthenticator directly, as it doesn't use that config.  So while this release note is fine for Hadoop components, it doesn't look like it's accurate for non-Hadoop components.  You could just add something about setting it programmatically., Hi [~rkanter],

Thanks a lot for your review, and sorry for getting back late.

I just uploaded rev9 (rev8 rebased on latest trunk), and changed the release notes as you suggested. 
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12686796/HADOOP-10895.009.patch
  against trunk revision bda748a.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 34 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-auth-examples hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5253//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5253//artifact/patchprocess/newPatchFindbugsWarningshadoop-yarn-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5253//artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs-httpfs.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5253//artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5253//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5253//console

This message is automatically generated., I was helping [~yzhangal] test this out by deploying Oozie with the hadoop-auth changes in the patch.  The idea would be that Oozie uses {{KerberosAuthenticator}} even in a non-secure cluster, relying on the fallback behavior.  With the patch, that should now fail because the fallback is disabled by default.  

However, when we tried this, we saw that it still was able to connect with the {{KerberosAuthenticator}} (and also the {{PsuedoAuthenticator}}.  We attached a debugger and discovered that it wasn't even trying to use Kerberos and succeeding; it actually looks like the {{KerberosAuthenticator}} can be used to talk to a non-secure cluster, without falling back.  See this code here from {{KerberosAuthenticator}}:
{code:java}
      if (conn.getResponseCode() == HttpURLConnection.HTTP_OK) {    // <----- A
        LOG.debug("JDK performed authentication on our behalf.");
        // If the JDK already did the SPNEGO back-and-forth for
        // us, just pull out the token.
        AuthenticatedURL.extractToken(conn, token);
        return;
      } else if (isNegotiate()) {                                   // <----- B
        LOG.debug("Performing our own SPNEGO sequence.");
        doSpnegoSequence(token);
      } else {                                                      // <----- C
        LOG.debug("Using fallback authenticator sequence.");
        Authenticator auth = getFallBackAuthenticator();
        // Make sure that the fall back authenticator have the same
        // ConnectionConfigurator, since the method might be overridden.
        // Otherwise the fall back authenticator might not have the information
        // to make the connection (e.g., SSL certificates)
        auth.setConnectionConfigurator(connConfigurator);
        auth.authenticate(url, token);
      }
    }
{code}

In the case we were expecting it to fail, we get to Line A.  Because its a non-secure cluster, we get an HTTP_OK when we talk to the server, even without Kerberos credentials.  Because of that, it goes ahead normally.  As the comment suggests, Line A can also occur sometimes in a normal Kerberos case.

Line B occurs when were doing a Kerberos negotiation.  And Lince C occurs when were not doing Kerberos; which is what we were expecting to hit in our test but didnt.

We cant remove Line A; IIRC, weve tried that in the past and its caused problems.  So, Im not really sure what we should do here.  Regardless of fallback, it looks like the KerberosAuthenticator can talk to a non-secure cluster, which was the point of this JIRA.  Any ideas [~atm] or [~tucu00]?, As long planned for a real cluster test after the code review is settled, and I got [~rkanter]'s help on this. Thanks Robert a lot for walking me through with the oozie tests, and the comments here. Look forward to [~atm] and [~tucu00]'s comments (thanks guys!).


, Just to clarify one thing about Line A above: I don't remember the JIRA number, but at one point that if statement also checked the HTTP header for an AUTHORIZATION flag (or something like that), so that it would only pass when using Kerberos.  We had to remove that because Java hides that flag, so it wasn't working right.  I think one solution to this issue is to add a similar condition to the if statement on Line A to only pass when using security; I'm just not sure what check we can do for that., Hi [~rkanter], thanks a lot for following up.

Following what you stated, I found HADOOP-8883 added the checking 
{code}
-      if (conn.getResponseCode() == HttpURLConnection.HTTP_OK) {
+      if (conn.getRequestProperty(AUTHORIZATION) != null && conn.getResponseCode() == HttpURLConnection.HTTP_OK) {
{code}

and HADOOP-10078 removed it:
{code}
-      if (conn.getRequestProperty(AUTHORIZATION) != null && conn.getResponseCode() == HttpURLConnection.HTTP_OK) {
+      if (conn.getResponseCode() == HttpURLConnection.HTTP_OK) {
{code}
, HI [~rkanter],

About the test you helped with:
{quote}
The idea would be that Oozie uses KerberosAuthenticator even in a non-secure cluster, relying on the fallback behavior. With the patch, that should now fail because the fallback is disabled by default.
{quote}
What we observed is that Oozie uses KerberosAuthenticator in a non-secure cluster and succeeds, so it DOESN"T seem to need the fallback.

However, there are other use cases that count on the fallback. As an example, with the patch, I had to fix quite some tests that fail if not allowing fallback. Right now the problem is that we don't have a real use case that count on the fallback to test out the fix.

I wonder if it makes sense to commit the patch such that the cases that need the fallback has to enable the fallback first?

Thanks.




, Discussed with Robert, we agreed that "KerberosAuthenticator is (incorrectly) able to talk to a nonsecure server without falling back" is an orthogonal issue to this one. We will create a new jira for that. Thanks Robert.

, I've created HADOOP-11467 to fix that., Thanks Robert!
, Hi Folks watching this jira,

Thanks [~rkanter] for committing HADOOP-11467. This addressed Robert's comment in
https://issues.apache.org/jira/browse/HADOOP-10895?focusedCommentId=14247476&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14247476
such that KerberosAuthenticator will fallback when talking to insure cluster.

Now back to HADOOP-10895, if we apply the patch of HADOOP-10895, it means that the clients that depends on the existing automatic fallback feature need to be changed. This is why HADOOP-10895 is marked as "incompatible". Robert once shared his concern about this with me.

Would you please comment on whether we should proceed with HADOOP-10895 solution and fix the clients accordingly?

Thanks a lot.
, Hi [~yzhangal],

It's a great work. I read the patch and only have a few minor comments for your reference. Thanks.
1. The following piece of codes is repeated in quite many places. Could we put it in a good place like {{SecurityUtil}} in a function say {{isAuthAllowFallback()}}?
{code}
    boolean allowFallback = conf.getBoolean(      CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY,        CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_DEFAULT);
{code}
2. To be consistent (with HADOOP-9698), might it be better to have {{allowFallbackToSimpleAuth}} than {{allowFallbackToPseudoAuth}}, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12686796/HADOOP-10895.009.patch
  against trunk revision ca1c00b.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5811//console

This message is automatically generated., Hello [~drankye],

Thanks a a lot for reviewing and the nice comments! I will make the change accordingly once we decide to move forward with the solution.
, Hi [~tucu00], [~atm], [~zjshen], [~daryn],

This jira originates from the discussion in HADOOP-10771 you guys participated. I'd like to bring to your attention, to see if we want to move this one forward. Please see my comment at 
https://issues.apache.org/jira/browse/HADOOP-10895?focusedCommentId=14321823&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321823

Thanks for your time, and thanks [~vinodkv] for suggesting me in the email thread to collect feedback from you guys.
, [~yzhangal], haven't looked at the patch, but we cannot make incompatible changes in branch-2 line and this JIRA is already marked so. We need to address this., Hi [~vinodkv], thanks for looking,  yes, this will be an incompatible change. we can defer to later releases, if we decide 2.x is not a good fit. Thanks.




, Tx for the response [~yzhangal]. Moving this out to 2.8. while we discuss more.

I'll spend more time on this a bit later, but [~yzhangal], can you in the mean while work with others to see if it *needs* to be an incompatible change? Thanks., Hi [~vinodkv],

As the release notes stated, it has to be an incompatible change because relevant application code (oozie for example, and [~rkanter] has raised the concern before) need to be changed accordingly.

Thanks.
, Changing this to be a blocker for 3.0.0 since it is an incompatible change., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12686796/HADOOP-10895.009.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 5137b38 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7317/console |


This message was automatically generated., [~yzhangal] are you still interested in pursuing this change for 3.0? Was wondering if this is really a blocker., Hi [~andrew.wang],

Thanks for the pinging. Due to the incompatibility of this fix, 3.0 would be an opportunity to get it in. However, there is some related change to be done in other components, per earlier discussion in this jira. We'd need a consensus before we can spend time to move this forward (I may not have the bandwidth at this moment).  I wonder what other people think. Any comment [~tucu00], [~rkanter], [~atm] and [~hitliuyi]? thanks.



, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HADOOP-10895 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12686796/HADOOP-10895.009.patch |
| JIRA Issue | HADOOP-10895 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9255/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, I'm downgrading this to just "Critical" since it seems like there's no one actively working on it., Thanks [~andrew.wang] for the update. I have not got chance to look this further, I'm unassigning it so other people may work on it. ]