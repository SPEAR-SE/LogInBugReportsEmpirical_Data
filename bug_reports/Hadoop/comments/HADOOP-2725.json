[It is possible that a map task copied a few blocks on the file before it encountered an error. The map task failed and got restarted. Now, the destination file already exists in DFS. The re-run of the map task sees that the file already exists and skips it.

Maybe distcp should be copy a file into a temporary filename into the destination folder and then when the entire copy is successful, it should rename it to the real filename. The rename is atomic in DFS,, We have been using  '-update' to avoid this problem for now. (0.15)
, bq. Maybe distcp should be copy a file into a temporary filename into the destination folder and then when the entire copy is successful, it should rename it to the real filename.

This is a good idea. However, since distcp accepts multiple sources, it is possible for multiple sources to map to the same destination. In the default case, skipping present files prevents both accidental deletion of data at the destination and- now that files appear when created- map tasks overwriting a file copying/copied from another map. If one doesn't expect files to be skipped, searching the logs for skipped files is necessary.

Copying to a temporary dir and renaming can distinguish part of the latter case, since collisions at creation time are unambiguously part of the copy. The problem changes, however, because now we must distinguish between files copying from another map and files that were part of a failed attempt (in the temp dir). The distcp user still needs to review the log to determine what- if any- of the cruft left in the temp dir is relevant.

Running the task a second time with '-upgrade' seems easier, if less efficient., Shell we make "-update" a default option?  It is like cp in unix, i.e. cp overwrite files by default., > Shell we make "-update" a default option? It is like cp in unix, i.e. cp overwrite files by default.

I'd rather not make it the default. It's too easy to clobber vast amounts of data inadvertently.

From the discussion above, it seems like the problem is that partial copies aren't clearly distinguishable from successfully copied inputs. One has to compare the source and destination lists by name and size to determine the set of unsuccessful copies. The use to temporary filenames should make it easier find partial copies.

Another enhancement that would help is distcp deleting partially copied files at the destination.

, Chris and I have a better solution for this issue:
# verify source list to make sure there is no duplication since duplicated source files dose not make sense in copying.
# Then, use dhruba's idea to first copy a file into a temporary file and do rename.

Sounds good?, 2725_20080206.patch: check source duplication and then do atomic copy (i.e. copy to tmp and rename)., Only a few minor nits:
* Path::makeRelative should use String::split rather than StringTokenizer
* Path::makeRelative probably needs a new test case in o.a.h.fs.TestPath
* This uses SequenceFile.Sorter::sort, which has been unused in core for awhile. It might be worthwhile to add some noise into the duplication test case (i.e. more than 2 files) to ensure that any regressions introduced through changes to the sort code are detected.

In addition to its enhancements, this patch makes distcp much cleaner. +1, Thanks, Chris!  Here is a update

2725_20080208.patch: 
- the changes for makeRelative are reverted.  We properly should work on it in a separated issue.
- TestCopyFiles.testCopyDuplication() indeed initializes two 20-file sets and do sorting., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12375120/2725_20080208.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 3 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1764/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1764/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1764/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1764/console

This message is automatically generated., I just committed this. Thanks, Nicholas!, I reverted this patch, because its test case (TestCopyFiles) took nearly 400s (from 26s) on my machine, due to a silently failing local-to-local test case. All 20 files copy successfully, but fail in the rename:

{noformat}
2008-02-08 18:36:14,246 INFO  util.CopyFiles (CopyFiles.java:map(390)) - FAIL 2522487525519213817 : java.io.IOException: Fail to rename tmp file (=file:/path/build/test/data/destdat/_distcp_tmp_cq5yoa/25224875255192138
17) to destination file (=file:/path/build/test/data/destdat/2522487525519213817)
        at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.rename(CopyFiles.java:336)
        at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.copy(CopyFiles.java:317)
        at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.map(CopyFiles.java:382)
        at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.map(CopyFiles.java:202)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:208)
        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:132)
Caused by: java.io.IOException: Target file:/path/build/test/data/destdat/.2522487525519213817.crc already exists
        at org.apache.hadoop.fs.FileUtil.checkDest(FileUtil.java:269)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:142)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:133)
        at org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:211)
        at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:403)
        at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.rename(CopyFiles.java:333)
        ... 6 more
{noformat}

At a glance, this looks like a problem in LocalFileSystem, but I'm reverting this patch for now., This looks related to HADOOP-730. Since RawLocalFileSystem uses copy to rename, the .crc is already regenerated when ChecksumFileSystem::rename attempts to move it., Integrated in Hadoop-trunk #395 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/395/]), As it turns out, the observed failure is *not* related to HADOOP-730. Rather, the .crc files are included in the source file list, which causes the collision during rename. HADOOP-2754 has been merged into 0.16.1, so the source list should contain only "real" targets., 2725_20080212.patch: also fixed HADOOP-2807, +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12375405/2725_20080212.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 3 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1785/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1785/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1785/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1785/console

This message is automatically generated., I just committed this. Thanks, Nicholas!, Integrated in Hadoop-trunk #399 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/399/])]