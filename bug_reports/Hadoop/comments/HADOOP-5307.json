[Attaching patch. , -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12400765/h5307_v1.patch
  against trunk revision 746970.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 12 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3903/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3903/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3903/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3903/console

This message is automatically generated., I committed this. , I reverted this for two procedural reasons:
# The patch never received a +1 or review
# Committing it all the way back to 0.19 is arguably appropriate, particularly since it's an incompatible change

As for the content of the patch, adding a special value parsed as "null" without escaping literal instances of it in a utility class is not good. The use case is also unclear; where is this causing problems, configuration or otherwise?, The issue occurs in the context of storing/restoring an array(with possible null values) in the configuration. The specific use case arose after HADOOP-4955, in which we store the column names in the configuration for DB access, however the names of the columns are not always available to the job, thus are passed as null array. 

This issue fixes the issue introduced by HADOOP-4955(which wad committed to 0.19), I guess it is appropriate for this to be in 0.19. 

As for escaping literal instances of "__null__", we can introduce an escaping mechanism, however it will not be backwards compatible, since "any" form of escaping the value will result in some literal matching the value which was not set by StringUtils#arrayToStrings(). (For example setting the value by hand from the configuration). 

I believe that using a pragmatical value for representing nulls, which is extremely unlikely to occur, does not introduce a backward incompatibility at all. I think classifying this as an incompatible change would only introduce noise to the long list of incompatible changes. 

, # bq. I believe that *using a pragmatical value for representing nulls, [...], does not introduce a backward incompatibility at all*.
# bq. As for escaping literal instances of "\_\_null\_\_", *we can introduce an escaping mechanism, however it will not be backwards compatible*, since "any" form of escaping the value will result in some literal matching the value which was not set by StringUtils#arrayToStrings().

These read as mutually exclusive statements. If escaping "\_\_null\_\_" is backwards-incompatible, then escaping {{null}} is, too. That any escape sequence needs a way to represent itself literally isn't controversial. Further, the change is to a public utility class: even if we defined "incompatible" statistically, the frequency of either case is unknown since its domain is undefined.

I'm a little confused about why StringUtils needs its own escape for a null reference. Converting an array of String with a null reference to a String with a special symbol for null is odd. It's cleaner to throw from StringUtils if it gets {{null}} and require callers to handle escaping.

bq. The issue occurs in the context of storing/restoring an array(with possible null values) in the configuration. The specific use case arose after HADOOP-4955 [...]

HADOOP-4955 probably should not have been committed to 0.19.1. It reads as an improvement, not a fix to a regression.

That said, if HADOOP-4955 is the cause, then this _is_ a regression in 0.19.1. I'm not sure what to do about this. Since the regression is in DBOutputFormat, wouldn't it make sense to fix this there?

Other:
* What was committed didn't match the patch posted here. There was a conflict in the imports for StringUtils.
* One of the cases added in testArrayToStringToArray (nullArr3) doesn't have a corresponding test., bq. These read as mutually exclusive statements. If escaping "__null__" is backwards-incompatible, then escaping null is, too. bq. That any escape sequence needs a way to represent itself literally isn't controversial. Further, the change is to a public utility class: even if we defined "incompatible" statistically, the frequency of either case is unknown since its domain is undefined.
Of course the patch is technically backwards-incompatible, what I say is that, the frequency is expected to be so small that it is negligible.

bq. I'm a little confused about why StringUtils needs its own escape for a null reference. Converting an array of String with a null reference to a String with a special symbol for null is odd. It's cleaner to throw from StringUtils if it gets null and require callers to handle escaping.
passing an array, possibly containing null values seems to me generic enough to be introduced in StringUtils rather than a custom solution in the context(DBOutputFormat).

bq. HADOOP-4955 probably should not have been committed to 0.19.1. It reads as an improvement, not a fix to a regression.
The API indicates to use the supplied column names, when in fact it did not, so 4955 is a bug fix, fixing the expected behavior from the API, rather than an improvement, introducing a new API. 

bq. What was committed didn't match the patch posted here. There was a conflict in the imports for StringUtils.
The patch is committed w/o changes to import statements. Committing a patch with minor changes is not uncommon. However I should have stated that. 
bq. One of the cases added in testArrayToStringToArray (nullArr3) doesn't have a corresponding test.
Will fix

At this point I think we can continue with the patch in three ways : 
1. Introduce new String[] -> String, and String -> String[] array methods handling possible null values. 
2. Mark the patch incompatible and commit this one
3. introduce a new API to set only the number of columns(not the names) in the DBConfiguration. However this does not fix the passing null values in configuration problem, if there is such. 

What would you suggest? 
, Integrated in Hadoop-trunk #778 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/778/])
    , bq. Of course the patch is technically backwards-incompatible, what I say is that, the frequency is expected to be so small that it is negligible.

Neither of us has enough data to assert anything about the frequency of any case because it's a public class. While my intuition matches yours, "incompatible change" isn't a statistical definition, let alone one based on our expectations.

bq. passing an array, possibly containing null values seems to me generic enough to be introduced in StringUtils rather than a custom solution in the context(DBOutputFormat).

I disagree. By supporting an escape for null references, this is defining a serialization for arrays of String, rather than representing an array of String in a single String. For this, the Stringifier seems like a more appropriate choice than changing the semantics of a method on StringUtils.

bq. The API indicates to use the supplied column names, when in fact it did not, so 4955 is a bug fix, fixing the expected behavior from the API, rather than an improvement, introducing a new API.

I see. From the description, it sounded like this was adding functionality by using the fields provided. I don't think adding a new API is necessary to differentiate an improvement from a bug; it's sufficient to change functionality. If the intent was to use them, then OK.

bq. What would you suggest? 

Not sure. Since this seems to be serializing an array in and out of configs, I'm leaning towards the Stringifier work as a solution local to DBConfiguration. Would that work?, bq. Neither of us has enough data to assert anything about the frequency of any case because it's a public class. While my intuition matches yours, "incompatible change" isn't a statistical definition, let alone one based on our expectations.
Wish we had resolved HADOOP-5073, which will hopefully classify the "gray areas" in the code.
bq. Not sure. Since this seems to be serializing an array in and out of configs, I'm leaning towards the Stringifier work as a solution local to DBConfiguration. Would that work?
I have opened HADOOP-5500, to fix the issue in DB context. I will close this one as won't fix. If any other use case occurs for stringifying possible null object(s), we can reopen this one. 
, bq. Wish we had resolved HADOOP-5073, which will hopefully classify the "gray areas" in the code.

Agreed. HADOOP-5073 is a necessary prerequisite for moving to 1.0, particularly for any remaining Java-public APIs.

bq. I have opened HADOOP-5500, to fix the issue in DB context. I will close this one as won't fix. If any other use case occurs for stringifying possible null object(s), we can reopen this one.

Sounds fair.]