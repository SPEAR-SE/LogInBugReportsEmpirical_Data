[Note that the docs are being converted from XDOC to APT; see HADOOP-8427 and HADOOP-9190. So please convert {{single_node_setup.xml}} to APT before editing the content, if at all possible., I've converted the xdoc to SingleNodeSetup.apt.vm in HADOOP-9221., It doesn't look like this jira ticket is blocked anymore.  But the single node cluster setup instructions have not been updated yet.  This page is where the beginner goes to setup and configure a pseudo cluster, so in step two (Setting up the environment) you should not assume that anything has been configured yet.

The main questions are:
* What should HADOOP_COMMON_HOME be set to
* What should HADOOP_HDFS_HOME be set to
* If this is a single tar install, why does it say "Assuming you have installed hadoop-common/hadoop-hdfs" then say "untar hadoop mapreduce tarball".  Does that mean there are two tarballs, one for common/hdfs, and one for mapreduce/yarn?
* Again, if this is a single tar install, why does it say "The following instructions assume you have hdfs running".  This makes it sound like I have an hdfs tarball I have to install, configure, then start before I can install mapreduce/yarn
* The first mention of the HADOOP_CONF_DIR states that it should already be set.  Set to what?  I thought this was the "how to install a single node cluster page".  Is there some other page I need to go to first to install and config something else?  Where is it?

Lots of confusion going on in this page.]