[Below are the related logs that explain what happened to this block:
# INFO  dfs.StateChange (FSNamesystem.java:addStoredBlock(2839)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48092 is added to blk_6302924909504458109_1001 size 32
# INFO  dfs.StateChange (FSNamesystem.java:computeReplicationWork(2403)) - BLOCK* ask 127.0.0.1:48092 to replicate blk_6302924909504458109_1001 to datanode(s) 127.0.0.1:48095
# INFO  dfs.StateChange (FSNamesystem.java:computeReplicationWork(2403))- BLOCK* ask 127.0.0.1:48092 to replicate blk_6302924909504458109_1001 to datanode(s) 127.0.0.1:48095
# INFO  dfs.DataNode (DataNode.java:writeBlock(1205)) - Receiving block blk_6302924909504458109_1001 src: /127.0.0.1:48124 dest: /127.0.0.1:48095 
# INFO dfs.DataNode (DataNode.java:writeBlock(1205)) - Receiving block blk_6302924909504458109_1001 src: /127.0.0.1:48125 dest: /127.0.0.1:48095 
# INFO dfs.DataNode (DataNode.java:writeBlock(1340)) - Received block blk_6302924909504458109_1001 src: /127.0.0.1:48125 dest: /127.0.0.1:48095 of size 32  
# WARN dfs.DataNode (DataNode.java:receiveBlock(2804)) - Exception in receiveBlock for block blk_6302924909504458109_1001 java.io.IOException: Finalizing a block that has already been finalized6302924909504458109
# INFO  dfs.StateChange (FSNamesystem.java:addStoredBlock(2839)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48095 is added to blk_6302924909504458109_1001 size 32 
# INFO  dfs.StateChange (FSNamesystem.java:computeReplicationWork(2403)) - BLOCK* ask 127.0.0.1:48095 to replicate blk_6302924909504458109_1001 to datanode(s) 127.0.0.1:48101 127.0.0.1:48113
# INFO  dfs.DataNode (DataNode.java:transferBlocks(908)) - Can't send invalid block blk_6302924909504458109_1001, The problem was that a simulated DataNode allows two concurrent writes to the same block. In the above case, NN happened to schedule two concurrent replications of a block to the same datanode (127.0.0.1:48095). The first replication succeeded but the second one failed on the error: Finalizing a block that has already been finalized, which caused the block to be deleted on the datanode. Subsequent request to replicate the block on this datanode failed because the block was deleted. As a result, the block remained to stay under-replicated before the test timed out., The patch does the following:
1. Disallow a simulated datanode to write to a block if the block is being written;
2. In the test, make sure that all datanodes are up before injecting blocks. This could greatly reduce the chance that NN schedules two concurrent replications to the same datanode., I've run the test for 50 times back to back without hitting the infinite loop. Previously I saw the loop before the 20th run., This patch is for the trunk. The previous is for 0.18., +1. , ant test-patch succeeded:

     [exec] +1 overall.
     [exec]
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec]
     [exec]     +1 tests included.  The patch appears to include 6 new or modified tests.
     [exec]
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec]
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec]
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.
     [exec]
     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
     [exec]
     [exec]     +1 release audit.  The applied patch does not increase the total number of release audit warnings.
     [exec]

ant test-core passed too., I've committed this., Integrated in Hadoop-trunk #778 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/778/])
    ]