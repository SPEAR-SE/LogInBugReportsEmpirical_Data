[In this patch I used LoadingCache to replace ConcurrentHashMap. After this change the logic of canonicalizedHostCache is simplified. , [~gtCarrera9], can you provide performance measurements including runtime and memory usage of this function with perhaps 6000 hostnames over 10,000,000 lookups (significant lookup metrics). Typically Cache lookups can be 5 - 100 times worse performance and double or triple memory requirements., Hi [~jeagles], sorry I'm a little bit confused here: I think this cache is only used by hdfs clients. In this use case there won't be significant number of hostnames in this cache. Am I missing anything here? Thanks! , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12687307/HADOOP-11387-121514.patch
  against trunk revision e597249.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.crypto.random.TestOsSecureRandom

                                      The following test timeouts occurred in hadoop-common-project/hadoop-common:

org.apache.hadoop.http.TestHttpServerLifecycle

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5271//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5271//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5271//console

This message is automatically generated., {code}
-    String fqHost = canonicalizeHost(host);
+    String fqHost;
+    try {
+      fqHost = canonicalizedHostCache.get(host);
+    } catch (ExecutionException e) {
+      throw new RuntimeException(e);
+    }
{code}

{code}
+  private static final LoadingCache<String, String> canonicalizedHostCache =
+      CacheBuilder.newBuilder().maximumSize(CANONICAL_CACHE_SIZE).build(
+          new CacheLoader<String, String>() {
+            @Override public String load(String host) throws Exception {
+              return SecurityUtil.getByName(host).getHostName();
+            }
+          }
+      );
{code}

I think it diverges from that original behavior. It might make sense to catch the {{UnknownHostException}} when populating the cache., Thanks [~wheat9] for pointing this out. I fixed the overlooked exception handling in this patch. , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12687334/HADOOP-11387-121514-1.patch
  against trunk revision a095622.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.crypto.random.TestOsSecureRandom

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5272//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5272//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5272//console

This message is automatically generated., Move the catch ExecutionExection statement into the loader to make the overall load logic cleaner. , LGTM. +1 pending jenkins. [~jeagles], do you have any comments? I'd like to commit it sooner rather than later as if blocks a clean Jenkins run., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12687367/HADOOP-11387-121514-2.patch
  against trunk revision a095622.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.ha.TestZKFailoverController
                  org.apache.hadoop.crypto.random.TestOsSecureRandom

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5276//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5276//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5276//console

This message is automatically generated., A couple of things.

1) The performance of this CacheLoader is several orders of magnitude worse than the concurrent library for our use case. Have a look at TEZ-1526 to see my earlier concerns with the performance and memory concerns over using this guava library in Hadoop.

2) The purpose by looking at the summary and description of this change is to make something simpler, but you say that it blocks a clean jenkins run above. That is not documented in this jira. If there is truly a simplification jira then this shouldn't block a clean jenkins build. Can you please comment on this.
, The two unit test failures are both timeout-related. They appears to by unrelated to the changes in this JIRA and I could not reproduce them. From the report, the two findbugs warnings are completely orthogonal to this JIRA. I'm looking into the performance issues, though. , bq. Have a look at TEZ-1526 to see my earlier concerns with the performance and memory concerns over using this guava library in Hadoop.

As [~gtCarrera9] pointed out, the cache is only for caching the resolution of NN by the client-side {{FileSystem}} objects. In common cases there should be only one or two instances in the cache, thus in my opinion guava cache is good enough for this use case.

bq. That is not documented in this jira. If there is truly a simplification jira then this shouldn't block a clean jenkins build. Can you please comment on this.

I'll update the description accordingly., Please hold off on check this in until at least 24 hours so I can check the implications of the change. Also please update the title. This may have negative performance implications that I need to check on.

Jon, Can you post the findbugs warning. I prefer to fix the warning rather that switch the underlying cache implementation. For small number hosts, this change is overkill. For large number of hosts, this implementation under-performs.

 , bq. Can you post the findbugs warning. 

https://builds.apache.org/job/PreCommit-HADOOP-Build/5275//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html

bq.  For small number hosts, this change is overkill.

As mentioned earlier, there are at most one or two entries in the cache. I'm fine with removing the cache., Posting warnings before the build artifacts are deleted. 

{quote}
Multithreaded correctness Warnings
Code 	Warning
AT 	Sequence of calls to java.util.concurrent.ConcurrentHashMap may not be atomic in org.apache.hadoop.net.NetUtils.canonicalizeHost(String)

 AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION: Sequence of calls to concurrent abstraction may not be atomic

This code contains a sequence of calls to a concurrent abstraction (such as a concurrent hash map). These calls will not be executed atomically. 
{quote}

{quote}
Bug type AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION (click for details)
In class org.apache.hadoop.net.NetUtils
In method org.apache.hadoop.net.NetUtils.canonicalizeHost(String)
Type java.util.concurrent.ConcurrentHashMap
Called method java.util.concurrent.ConcurrentHashMap.put(Object, Object)
At NetUtils.java:[line 291]
{quote}, Oops, i filed HADOOP-11433 to track the findbugs warning and just find this one., [~jeagles] do you have any more comments? I plan to commit it next Monday if there is no objection., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12687367/HADOOP-11387-121514-2.patch
  against trunk revision 6fdef76.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5939//console

This message is automatically generated., This change is still overkill and makes it very difficult to maintain. The standard way to fix this findbugs warning is with a putIfAbsent call. That still seems like the best fix to me.]