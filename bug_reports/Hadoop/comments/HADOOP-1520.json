[It might be significant that the namenode is rolling the fsimage file right before the IndexOutOfBoundsException., NNBench on 100+ nodes alway hits this problem and hangs., The DFSClient retries the ClientProtocol.complete() call untill it is successful. I am assuming that a previous complete() call was successfully executed at the NameNode but the client decided to declare that call as "timedout" and retried. The retried call experiences this Exception over and over again.

One generic solution is a have a unique sequence number per RPC that identifies that RPC. The NameNode remembers the last few thousands RPCs that it executed. If a client sends a RPC with a sequence number that exists in the NameNode cache, the NameNode returns the results that were produced by the previous execution of the same RPC.

Can you pl send a pointer to a namenode log file that shows this problem?, I added appropriate synchronization to FSEditLog.java. can you pl see if you started seeing these problems since HADOOP-1003 was applied? Also, if possible, can you apply this patch and rerun the benchmark on the 100 node cluster to see if it fixes your problem? Thanks., +1.  This patch seems to fix the problem., +1 The patch looks good., Appropriate locking for the methods that the secondary namenode uses to roll the edit log and fsimage., +1

http://issues.apache.org/jira/secure/attachment/12360389/1520.patch applied and successfully tested against trunk revision r551725.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/347/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/347/console, I just commited this. Thanks Dhruba!, Integrated in Hadoop-Nightly #140 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/140/])]