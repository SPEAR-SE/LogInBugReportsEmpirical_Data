[We noticed the same when we upgraded to a very recent trunk build. Also lost some blocks. We were not sure whether it had to do with our upgrade procedure and, therefore, did not file a ticket yet., It usually happens with following steps:

# Start Cluster
# Creates some files (e.g. run a randomWriter job)
# Delete some files (e.g. run another randomWrite job, which deletes earlier files)
# Stop cluster (sooner the better).
# Start cluster again

My impression is that deleting the files in 3rd step somehow causes this.
, I saw this around June 28th. I am trying to reproduce., Someone please double check what I have found till now. It looks like it exists in 13 also.

Before HADOOP-702, FSEditLog.adjustReplication() used to take conf as argument before. Not it just relies on min/max Replication  variables set in FSNamesystem object. But secondary name node uses a bare minimum which does have these variables set. So whenever Secondary namenode rolls the FSImage, it resets replication to 0 and when Namenode reads it in the next restart, it sets it to 1.

In my developement, for some reason many times Secondary Namenode never finishes creating new Image or it has some other exception.. never checked secondary namenode log till now. So this problem didn't always show up.
, Seeing this on a cluster running a checkout of release-0.13.0. Haven't lost any blocks yet, but had some close calls....

Not sure where to mention it, but it exposes a limitation of the "when down replication happens, clear blocks from the fullest node first" working against the "try to distribute replications across racks"., HADOOP-1300 takes into account rack locality when deleting excess replicas., 
I am preparing a patch. All constructors of FSNamesystem will take configuration and common initialization will be moved to a separate private member.
, This patch moves initialization of common variables in to a common member function., 01.patch  applies only to branch-0.13. It conflicts with HADOOP-1562 on the trunk. Attaching trunk-01.patch.
, I cannot apply this patch to current trunk.
Looks like there is a conflict with committed patch HADOOP-1562, which already introduced a configuration parameter for the FSNamespace constructor.
Also this case should be a part of TestCheckpoint, in which currently we always check that file replication is 1.
I think TestCheckpoint should also test replication factors of 2 and 3., Thanks Konstantin. attached 02.patch :

Modified TestCheckpoint to use 3 datanodes. checkFile now checks file replication along with block replication. Test failed without the fix and passes after the fix.
, FileSystem.getReplication() method is deprecated. Use getFileStatus() instead.
I do not particularly like how you named the new method initializeFromConf().
I'd suggest get or setConfigurationParameters(), but I don't mind any other name as long 
as it doesn't contain abbreviations.
, Thanks Konstantin. 

# changed the new member name to setConfigurationParameters()
# patch for trunk uses getFileStatus() for replication. Yesterday I made the TestCheckpoint.java patch for 13 then applied it to trunk, otherwise I wouldn't have missed eclipse's loud screams about the use of deprecated functions.
, +1, -1, build or testing failed

2 attempts failed to build and test the latest attachment http://issues.apache.org/jira/secure/attachment/12362002/HADOOP-1603-trunk-02.patch against trunk revision r557050.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/429/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/429/console

Please note that this message is automatically generated and may represent a problem with the automation system and not the patch., This causes TestCheckpoint to fail for me.
 
junit.framework.AssertionFailedError: Number of replicas for block0 expected:<3> but was:<2>
	at org.apache.hadoop.dfs.TestCheckpoint.checkFile(TestCheckpoint.java:59)
	at org.apache.hadoop.dfs.TestCheckpoint.testCheckpoint(TestCheckpoint.java:289)

, hmm.. I think we should remove this perticular test. This tests how many datanodes reported the block, which is unrelated to what checkpoint does. Mostly in your case, this check was done before the third datanode reported its blocks. If you  still have it, could you attach build/test/TEST*Checkpoint.txt?
, I didn't save it, but it was easy enough to regenerate., I agree with Raghu that it should be ok to remove the check from checkFile., Submitting updated patches with the test for block replication removed. In the test log that Doug attached time between Namenode start and last datanode registration is around 500 millisec, which makes it more probably for client to check for for this between datanode registration and block report (client sleeps for 500 millisec between each check).
, I just committed this.  Thanks, Raghu!]