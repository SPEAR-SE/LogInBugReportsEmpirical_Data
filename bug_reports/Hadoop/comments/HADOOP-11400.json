[Thanks for the report Kamil! Do you plan on uploading a patch to fix the issue? I'd be happy to review and commit it promptly, I'll try to upload patch, do you have any guidelines for newcomers?, Hi Kamil! https://wiki.apache.org/hadoop/HowToContribute
Just follow the same code formatting and create a patch file to upload onto this JIRA., I've attached patch which should fix this issue. 

I've tried to follow codestyle used in GraphiteSink class, but since there is no one consisten style it was hard :), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12688856/HADOOP-11400.patch
  against trunk revision 5caebba.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 4 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5334//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5334//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5334//console

This message is automatically generated., Hmm, I am not sure if this findbugs report is correct, 4 new Findbugs?, [~kgs] DM_DEFAULT_ENCODING is a related warning. Could you fix it?, Thanks for the patch Kamil. Here are my thoughts:
# Please explicitly import all classes.
# Let's connect during init() rather than on first write.
# We can move the logic to check if graphite.isConnected() within the functions graphite.write() and graphite.flush() . Instead maybe check if graphite != null ?
# Should we also set a limit to the number of times a connection will be allowed to be retried?
# Any reason for class Graphite to be public?
# In Graphite.connect(), the condition should be isConnected() instead of socket != null
# In general let's try to move all the conditions and error checking related to the connection within the Graphite class., Thanks for your thoughts - I've uploaded fixed version. Here are my comments:

1. Done.
2. I've already done this in first version.
3. Logic moved to Graphite class. In my opinion graphite != null is not necessary.
4. I've created limit, setting it arbitrarily to 5 (after limit is reached, there is ERROR in logs and no more errors is raported and no further connection attempts are made)
5. Because of tests - I now this is ugly, but I have no better solution.
6. Fixed.
7. Done., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12691187/HADOOP-11400.patch
  against trunk revision ae91b13.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5386//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5386//console

This message is automatically generated., Thanks a lot Kamil! The latest patch looks good to me. +1 . I'll commit by end of day today if there are no objections., Thanks Kamil for your contribution! I've committed the patch to trunk and branch-2, FAILURE: Integrated in Hadoop-trunk-Commit #6840 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6840/])
HADOOP-11400. GraphiteSink does not reconnect to Graphite after 'broken pipe' (raviprak: rev 4d2914210053f28c95094aa59e48f8e84c55a2c7)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #70 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/70/])
HADOOP-11400. GraphiteSink does not reconnect to Graphite after 'broken pipe' (raviprak: rev 4d2914210053f28c95094aa59e48f8e84c55a2c7)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #804 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/804/])
HADOOP-11400. GraphiteSink does not reconnect to Graphite after 'broken pipe' (raviprak: rev 4d2914210053f28c95094aa59e48f8e84c55a2c7)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #2002 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2002/])
HADOOP-11400. GraphiteSink does not reconnect to Graphite after 'broken pipe' (raviprak: rev 4d2914210053f28c95094aa59e48f8e84c55a2c7)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk-Java8 #67 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/67/])
HADOOP-11400. GraphiteSink does not reconnect to Graphite after 'broken pipe' (raviprak: rev 4d2914210053f28c95094aa59e48f8e84c55a2c7)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
* hadoop-common-project/hadoop-common/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2021 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2021/])
HADOOP-11400. GraphiteSink does not reconnect to Graphite after 'broken pipe' (raviprak: rev 4d2914210053f28c95094aa59e48f8e84c55a2c7)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #72 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/72/])
HADOOP-11400. GraphiteSink does not reconnect to Graphite after 'broken pipe' (raviprak: rev 4d2914210053f28c95094aa59e48f8e84c55a2c7)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java
, Thanks Kamil for the patch !! 

Though I have few questions regarding MetricSystem in general (so may be someone can also please comment), and for GraphiteSink : 

1. Case, target Graphite Server is down, or not reachable: 

In case of putMetrics throws exception, client gets "broken pipe" exception which goes till MetricSinkAdapter. 
Then Hadoop MetricSystem in general has notion of retry and wait-time, but after retry it just stop using the errored Sink.
Even after few mins if the target server is up, it doesn't try to publish metric again. 

I tested this scenario with GraphiteSink.

My understanding of this flow, might be wrong :), but if not then I think best place to fix this in the MetricSystem framework, and it should check the sinks availability after every few secs / mins based on the config. 


2. GraphiteSink is using single TCP connection, should it uses a TCP connection pool? 

Regards,
Manish, " 1. Case, target Graphite Server is down, or not reachable:
In case of putMetrics throws exception, client gets "broken pipe" exception which goes till MetricSinkAdapter. 
Then Hadoop MetricSystem in general has notion of retry and wait-time, but after retry it just stop using the errored Sink.
Even after few mins if the target server is up, it doesn't try to publish metric again.
I tested this scenario with GraphiteSink.
My understanding of this flow, might be wrong , but if not then I think best place to fix this in the MetricSystem framework, and it should check the sinks availability after every few secs / mins based on the config. "

Looks like the MetricSinkAdapter just suppresses the log.error  but still keep trying the putMetrics(....) method in a while loop on the sink object. 
So, its bad on my part  :( , but then yes each sink needs to handle the reconnect etc. in case of failure which should hold true. 

Cheers,
Manish
]