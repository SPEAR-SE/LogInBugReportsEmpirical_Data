[I have seen unit tests fail with this message on recent trunk versions.  I don't think the bug is specific to JobControl, but is rather with LocalJobRunner., This should fix this.  Can you please try this, Johan?, +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12367971/HADOOP-1642.patch
against trunk revision r586003.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/967/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/967/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/967/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/967/console

This message is automatically generated., I applied the patch to the 0.15 branch and reran my program, this time it got a bit further. The above error didn't show up.
Instead i got this:

java.io.IOException: Target /tmp/hadoop-johan/mapred/local/map_0000/file.out already exists
        at org.apache.hadoop.fs.FileUtil.checkDest(FileUtil.java:246)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:125)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:116)
        at org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:180)
        at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:380)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:501)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:607)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:193)
        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:133)
, Here's another try.  Does this work for you, Johan?, -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12368036/HADOOP-1642-2.patch
against trunk revision r586264.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/971/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/971/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/971/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/971/console

This message is automatically generated., I just committed this. Thanks, Doug!, Integrated in Hadoop-Nightly #283 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/283/]), I just checked out the 0.15 branch and I don't see the code  mentioned in the patch commited there? 

Anyway, I applied the most recent patch, rebuilt hadoop and then put the new jar files in our project. I get the same behaviour as Johan:

11-01 10:57:02] Thread-1 (LocalJobRunner.java:186) - job_local_2
java.io.IOException: Target /tmp/hadoop-adrian/mapred/local/map_0000/file.out already exists
	at org.apache.hadoop.fs.FileUtil.checkDest(FileUtil.java:246)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:125)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:116)
	at org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:180)
	at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:394)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:501)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:607)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:193)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:132)

So I don't think this issue should be marked as resolved., Re-opening, since this does not yet appear to be fixed., Code Review please. 

The actual change to the source code is very small, just a one liner modification on line 117 of LocalJobRunner.java like so:

          String mapId = jobId + "_map_" + idFormat.format(i);

The problem was that in local MR and FS mode, the mapId wasn't unique enough and caused tasks to create .out files with the same name. Prepending the jobId as shown above fixes this. Maybe there is a better way to do this that is more consistent with how it is done in the distributed Job Runner? Or using a GUID of some sort? The above worked for me but if you have a preference for another way of generating the mapId I'm keen to hear it.

The bulk of the patch consists of adding a Unit test for this. What I have done is create a TestLocalJobControl which extends HadoopTestCase and sets up a mini-mr cluster in Local MR and File mode. I based the test on  TestJobControl (which is a bit of a weird unit test IMHO as it does no asserts, surely it should check the job results?) . Anyway, I factored out all the common functionality into a JobControlTestUtils class and changed both tests to use this. My test failed with the 

java.io.IOException: Target build/test/mapred/local/map_0000/file.out

message until the change to LocalJobRunner was made so I think it covers this issue., Patch containing fix and unit test added (HADOOP-1642-3.patch), Missing Apache license as comment at top of new unit test classes, Code review, see comments for previous patch (HADOOP-1642-3.patch), all that has changed here is that I have added Apache license in comments at top of new files in accordance with license., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12368990/HADOOP-1642-4.patch
against trunk revision r591880.

    @author +1.  The patch does not contain any @author tags.

    patch -1.  The patch command could not apply the patch.

Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1064/console

This message is automatically generated., Can anyone tell why hudson couldn't apply the patch? I generated it according to the hadoop wiki docs and can apply it just fine to the trunk myself..., bq. Can anyone tell why hudson couldn't apply the patch?

Here's what I see when I attempt to apply this to trunk:
{noformat}
 % patch -p 0 < ~/Desktop/HADOOP-1642-4.patch 
patching file src/test/org/apache/hadoop/mapred/jobcontrol/TestLocalJobControl.java
patching file src/test/org/apache/hadoop/mapred/jobcontrol/TestJobControl.java
Hunk #1 FAILED at 18.
Hunk #2 succeeded at 47 (offset 3 lines).
Hunk #3 succeeded at 90 (offset 3 lines).
Hunk #4 succeeded at 106 (offset 3 lines).
Hunk #5 succeeded at 125 (offset 3 lines).
1 out of 5 hunks FAILED -- saving rejects to file src/test/org/apache/hadoop/mapred/jobcontrol/TestJobControl.java.rej
patching file src/test/org/apache/hadoop/mapred/jobcontrol/JobControlTestUtils.java
patching file src/java/org/apache/hadoop/mapred/LocalJobRunner.java
Hunk #2 FAILED at 268.
1 out of 2 hunks FAILED -- saving rejects to file src/java/org/apache/hadoop/mapred/LocalJobRunner.java.rej
{noformat}, OK, I patched it using Eclipse and it worked. I just tried from command line and I get the same as you. Does it have to work from command line? If so I will look into it and try figure out what the issue is...., Have you recently updated your Eclipse workspace to the current trunk?

> Does it have to work from command line?

Yes.
, Attempting patch regeneration from trunk, Same patch as before, but this time generated against a fresh checkout of the trunk. Works for me from the command line. All comments above for HADOOP-1642-3.patch still apply., Should work from command line now., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12369042/HADOOP-1642-5.patch
against trunk revision r592324.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1070/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1070/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1070/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1070/console

This message is automatically generated., bq. I just checked out the 0.15 branch and I don't see the code mentioned in the patch commited there?

Adrian, the original fix went into 0.16.0 (trunk), could you check if it is fixed there? If not, please open another issue and attach your current patch, else we can debate about reverting Doug's original patch from 0.16.0. Thanks!, Yes, the original fix is indeed in the trunk, the patch I have submitted was also built against the trunk and requires Doug's original patch and should be applied in addition to it as it solves the second issue which arose after the original patch. Can someone please code review it and see if it is acceptable?, Resolving this and taking the issue forward in HADOOP-2245.]