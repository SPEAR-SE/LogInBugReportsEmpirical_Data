[Tim,

bq. Further investigation showed the were 200,000+ files in the job history folder - and every submission was creating a FileStatus for them all, then applying a regular expression to just the name
Hey. I think the regex is passed in the DFS call and the expected answer is just  *one* FileStatus object. I dont know how the regex based  search is implemented. But JobHistory doesnt create FileStatus objects for all the files.

bq. having Hadoop default to storing all the history files in a single directory is a Bad Idea
HADOOP-4670 is opened to address this. 

bq. doing expensive processing of every history file on every job submission is a Worse Idea
HADOOP-4372 should help as there will be no need to access history folder in job initialization. But I think the DFS should be efficient enough for regex based searches. 

bq. doing expensive processing of every history file on every job submission while holding a lock on the JobInProgress object and thereby blocking the jobtracker.jsp from rendering is a Terrible Idea (note: haven't confirmed this, but a cursory glance suggests that's what's going on)
The plan is to improve on JobTracker locking and improve on granularity. But I think HADOOP-4372 should eliminate this. 

bq. not being able to clean up the mess without taking down the job tracker is just Unfortunate
Look at HADOOP-4167., > Hey. I think the regex is passed in the DFS call and the expected answer is just one FileStatus object. I dont know how the regex based search is implemented. But JobHistory doesnt create FileStatus objects for all the files.

Regarding this, the code path is:
  JobHistory.getJobHistoryFileName(...) -> fs.listStatus(new Path(LOG_DIR), filter) --> listStatus(results, f, filter);
which has the following:
    FileStatus listing[] = listStatus(f);
    if (listing != null) {
      for (int i = 0; i < listing.length; i++) {
        if (filter.accept(listing[i].getPath())) {
          results.add(listing[i]);
        }
      }
    }

So you are right that it's not JobHistory that's creating all the FileStatus objects, it's org.apache.hadoop.fs.FileSystem that creates (potentially hundreds of thousands of) FileStatus objects, then asks only for their path attribute, and then returns just the ones that match -- which in the case of new job submission is zero.

Thanks for pointing out the other tickets; I should have searched before filing., Attached is a patch to make the filtering more efficient by passing the filter all the way down to the RawLocalFileSystem., I think addressing HADOOP-4372 is a good first step to fix this issue (HADOOP-4670 being the next). That should eliminate the need for doing listStatus for new jobs.. But yes, the listStatus implementation might be improved for performance and that could be done independently of this jira., Tim,
HADOOP-4372 removes  the job-dir searching for new jobs and MAPREDUCE-416 moves completed jobs to *done* folder hence keeping the job-history folder clean. MAPREDUCE-416 also introduced file-cache that caches the filenames that were used and hence makes the job-completion for recovered jobs faster. MAPREDUCE-11 intends to remove the searching completely. Still the locking is still an issue. Hopefully we will fix it sometime soon. MR doesnt depend on the files in the *done* folder and hence the *done* folder can be archived/cleanedup etc while the jobtracker is running. , I think locking the jobtracker cannot be avoided as its inline with heartbeat. MAPREDUCE-786 should make the JobHistory calls faster., I don't see a commit here... how is this issue 'FIXED' ? Is it a duplicate of some other bug?

If none of the above, we should mark this jira as 'wontfix'/'invalid' or keep it open if we haven't satisfied the request..., Think this is still a bug, people are seeing it on 20., Jobhistory directory structure will be fixed by MAPREDUCE-323. That should solve the issue.]