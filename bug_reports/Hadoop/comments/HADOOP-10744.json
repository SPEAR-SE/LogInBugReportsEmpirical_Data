[The problem is due to the below lines of code in the lz4.c file (src/main/native/src/org/apache/hadoop/io/compress/lz4/lz4.c)

// Little Endian or Big Endian ?
// Overwrite the #define below if you know your architecture endianess
#if defined (__GLIBC__)
#  include <endian.h>
#  if (__BYTE_ORDER == __BIG_ENDIAN)
#     define LZ4_BIG_ENDIAN 1
#  endif
#elif (defined(__BIG_ENDIAN__) || defined(__BIG_ENDIAN) || defined(_BIG_ENDIAN)) && !(defined(__LITTLE_ENDIAN__) || defined(__LITTLE_ENDIAN) || defined(_LITTLE_ENDIAN))
#  define LZ4_BIG_ENDIAN 1
#elif defined(__sparc) || defined(__sparc__) \
   || defined(__powerpc__) || defined(__ppc__) || defined(__PPC__) \
   || defined(__hpux)  || defined(__hppa) \
   || defined(_MIPSEB) || defined(__s390__)
#  define LZ4_BIG_ENDIAN 1
#else
// Little Endian assumed. PDP Endian and other very rare endian format are unsupported.
#endif

The flow goes like this in Power little Endian system. __GLIB__ is not defined , it falls on next elif. The condition fails due to __LITTLE_ENDIAN__... flags, falls on next elif and here it get satisfied! and sets LZ4_BIG_ENDIAN. The thing is these flags __powerpc__, __ppc__, __PPC__ are also defined in PowerPC Little Endian Architecture.

There is a similar file called lz4hc.c which also has the same lines code and still it correctly recognizes Little Endian Architecture. The reason behind that is..there is a include <stdlib.h> which actually turns on the __GLIBC__ flag.
And since now the decision is based on BYTE_ORDER, it identifies whether it is Big Endian or Little Endian.

So lz4.c file should also have the "include <stdlib.h>" to make it work correctly in Power Little Endian Architecture
, Seems related to :
https://code.google.com/p/lz4/issues/detail?id=131

Apparently solved within current LZ4 development version :
https://github.com/Cyan4973/lz4/tree/dev
, Okay.So any idea on when the latest LZ4 development version is made available to Hadoop ?, This Lz4 compression is one of the core files in hadoop-common. This issue is not related to testcase modification.Its related to a failure in a particular architecture.So i think latest Lz4 development version should made available in hadoop 2.5.0 version or atleast the above patch to 2.5.0 version, Any update on when the new LZ4 development version is picked up?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12652168/HADOOP-10744.patch
  against trunk revision caecd9f.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4955//console

This message is automatically generated., The fixed patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12677273/HADOOP-10744-v1.patch
  against trunk revision caecd9f.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4957//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4957//console

This message is automatically generated., This patch resolves existing compression related tests failure in Little-Endian architecture.
So new tests are required for this patch., No new tests are required for this patch, Any update on this ?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12677273/HADOOP-10744-v1.patch
  against trunk revision d336d13.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5400//console

This message is automatically generated., The patch succeeds with -p1 option

/usr/bin/patch -p1 < HADOOP-10744-v1.patch
Couldn't see which option was employed in jenkins.

, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12693871/HADOOP-10744-v2.patch
  against trunk revision 786dbdf.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5449//console

This message is automatically generated., The patch will succeed with -p1 option. Can any maintainer look into this issue ?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12696121/HADOOP-10744-v3.patch
  against trunk revision 8cb4731.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5562//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12696162/HADOOP-10744-v4.patch
  against trunk revision 8cb4731.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5563//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5563//console

This message is automatically generated., This patch resolves existing compression related tests failure in Little-Endian architecture.
So no new tests are required for this patch., It seems like the issue is resolved by HADOOP-11184 ( updating lz4 to r123 ). So i am closing this defect., Closing old tickets that are already part of a release.]