[Write timeouts are only possible by using async i/o.  So would you have each thread to create its own selector and loop on it?  Is that wise?  Otherwise, implementing this would require converting the entire datanode to use async i/o, which is probably a good idea, but not a short-term one., A new FilterInputStream would poll only when read or write fails with EAGAIN (some Java equivalent). So it does not slow down fast clients. I don't think a poll() costs much.. especially when we are polling when required. If there are a lot of clients reading from DataNode, bottleneck is most certainly going to be disk.

We don't strictly need this for 16., 
This patch implements write timeout on datanodes for block reads.  Currently only client reads have write timeout. Once the fix looks good , we can write timeout in other places (while writing mirror for e.g.).

This adds two classes SocketInputStream and SocketOutputStream in IOUtils. Please suggest better names.
, This looks nice!  How well does it work?

SocketInputStream and SocketOutputStream seem like fine names, but should they be nested classes in IOUtils, or perhaps independent classes in the 'net' package?

Also, we might make the error messages in the exceptions a bit more informative, e.g., including the address the socket is connected to, the timeout, etc., > How well does it work?

All the unit tests pass and I tested with (artificially) slow clients. Performance wise, I don't expect any change. JRE has to do something like this anyway. select() is invoked only when we need to wait. We will surely run benchmarks before this goes, may be after 0.16 branch is cut. 

> SocketInputStream and SocketOutputStream seem like fine names, but should they be nested classes in IOUtils, or perhaps independent classes in the 'net' package?

Yes, these can be independent classes in io or net package. Currently there is a ipc.SocketOutputStream (not currently used in Hadoop), which is just a special case of SocketOutputStream here. ipc.SocketOutputStream will be removed.

> Also, we might make the error messages in the exceptions a bit more informative, e.g., including the address the socket is connected to, the timeout, etc.
should do this.

When I prepare more complete patch for 0.17, I think we should replace all socket input/output streams in Datanode with these.

Also WRITE_TIMEOUT of 1 minute might be too short.

The patch attached does not have above changes, it just has some minor changes from previous patch., If you're preparing a more complete patch for Hadoop 0.17, can we apply this patch for Hadoop 0.16.1?
, Marco, is this bug causing real problems for your users?  If so, it might merit becoming a blocker for 0.16.1.

The patch introduces new public APIs, and thus we must be certain that these are APIs we wish to support long-term.  Since the new classes are network-specific, they belong in org.apache.hadoop.net, not org.apache.hadoop.io, where they are in the current patch.
, If remember correctly many cases that Koji noticed had DFSClient and one or more datanodes were stuck on socket writes (while writing new blocks). What happens is that when a datanode is writing block data to local disk, disk write gets stuck forever (due to various kernel problems... that mount might have spontaneously become read-only), this blocked write to disk essentially stalls write pipeline from that datanode up to DFSClient.

This is pre HADOOP-1707. I am not sure same condition still stalls the write pipeline in trunk, it might.
, > I am not sure same condition still stalls the write pipeline in trunk
Looks like trunk would be affected in the same way.

What should the write timeouts be? (my recommendation in the braces) : 

# Read : when datanode is serving data to client (10 min)
# Write : When client is writing data to DFS. Unlike read, this timeout is more 'disruptive' and thus needs to be more conservative. (10 min).

, 
Patch for trunk is attached. All of DataNode and DFSClient sockets have write timeouts. The read timeout remains the same as before. The new streams are in hadoop.net package (strictly, they work one any socket with a selectable channel).

There are multiple public APIs. Doug, please take a look. The static methods in NetUtils are required to support flexible SocketFactory implementations where the sockets might not have a channel. Since the default socket factory returns a socket with a channel, regular streams from Socket.getInput/OutputStream methods seem to have a [problem|http://www.nabble.com/blocking-read-on-a-socket-blocks-write-too--tt15294234.html]. 

3 files are added under hadoop/net and one file is removed from hadoop/ipc.

test-core passes., -1.  No regression test and new unit test(s) for new api's., 
Java Selector creation seems pretty heavy for a single filedescriptor polling. The current patch creates one selector for each stream. Looks like each selector takes up 3 fds: 2 for a pipe (used for {{wakeup()}, I guess) and for epoll().

Even if we are ok with these extra fds for each stream, it still requires users to close the stream explicitly (to close the selector). Opening and closing new selector each time we wait might be costly be because of this extra pipe it uses.

If these streams aim to be drop in replacements for Socket's own streams, they should either clean up  automatically when the channel is closed, or better, should not require a {{close()}}.

Anyone aware of a bare-bones selector or an alternate to a selector? Some thing that is a thin wrapper over {{poll()}}, without extra set up and extra fds for pipe and epoll?

I think it is still possible to implement these streams with a single global Selector, without an extra thread. Registering and deregistering a channel each time we want to wait won't be costly. This way, stream does not need a close().


, Given the above issues, this is probably not a 0.16.1 jira. I would like to implement these with single selector if there are no better alternatives. But it might not be suitable for 0.16.1.
, 
Updated patch that works well. SocketInputStream and SocketOutputStream are true drop in replacements for socket.getInputStream() and socket.getOutputStream() (i.e. they don't need to be closed).

Of course this takes easy route around for the issues mentioned above: it creates new Selector for each time the IO needs to wait.

Also this does not have unit tests. Review of rest of patch, especially the public API would be very useful., My recommendation for committing this patch :

- This is a change for low level streams and thus not appropriate for mostly stable 0.16. 
- This can go in to 0.17 sooner than later. Once it gets tested there, we can always back port it to 0.16 if we really need it.
- The current patch is pretty OK. I will have an improved implementation of {{SocketIOWithTimout}} when I get some more time in next couple of weeks., This looks reasonable to me.  +1 for 0.17., 
Update patch that I think is complete is attached.

This uses a pool of Selectors. This pool grows and shrinks with the number of threads blocked on these sockets. No extra thread is used. Selector is closed if it stays inactive for 30 sec (next time some thread blocks or wakes up). This should not have any perf penalty.

Earlier I was thinking of using just one selector all threads waiting on read and one for all threads waiting on write.. I don't think that complexity is required.

These streams can be used with other channels like pipes and UDP sockets. The unit test uses pipes.

I don't think this patch needs to wait till performance evaluation. 

Unit test: a new test is added to test timeout and read and write. Note that pretty much every DFS unit test test these streams.

, minor changes : mostly JavaDoc fixes., 
Updated patch. Added JavaDoc for private class SelectorPool in SocketIOWithTimeout., more comments., The ideas are really good.  Not able to finish reading the patch yet.  Got some comments:
- SocketIOWithTimeout.read is not needed.  It might be a local variable in doIO(ByteBuffer buf), i.e.
{code}
synchronized int doIO(ByteBuffer buf) throws IOException {
  boolean read = channel instanceof ReadableByteChannel;
  ...
}
{code}

- The class SocketIOWithTimeout serves both ReadableByteChannel and WritableByteChannel.  It might be better to make SocketIOWithTimeout abstract and create two sub-classes for ReadableByteChannel and WritableByteChannel.  Then, the runtime checking can be eliminated

- SocketIOWithTimeout.isClosed() should check channel.isOpen() and update SocketIOWithTimeout.closed if necessary.  Then SocketInputStream.isOpen() should just return !socketIO.isClosed().

- Instead of implementing a linked list by ProviderInfo.next, it is better to use a list class provided in java.util., - > [...] {{boolean read = channel instanceof ReadableByteChannel;}}
-- This won't work because most channels are both Readable and Writable.

- >[...] Then, the runtime checking can be eliminated
-- Can't really eliminate runtime checking. For e.g. SocketInputStream's channel should be both SelectableChannel and a ReadableByteChannel. How do we enforce that without runtime check?

- > SocketIOWithTimeout.isClosed() should check [...]
-- sure. Not much different but will  make the change.

- > Instead of implementing a linked list by ProviderInfo.next [...]
-- :) reminds of earlier days. I implemented only because we don't remove from the list. If we want an advantage, we iterate on the list (mostly has just one elemement) twice everytime we wait.. so avoids allocation of iterator twice. I think this is ok.. let me know if we should. Using java.util.LinkedList does not make number of lines less, with all the generics stuff, it surely takes more bytes :).

, more on LinkedList: I also needed a list that compares references. With LinkedList it calls equals. For this I can have a own small class that wraps a provider. But that implies we create a new object each time to search in the list and the code for the new class, etc., 
Updated patch attached.
- fixed couple of conflicts HADOOP-1985
- SocketIOWithTimeout.isOpen() checks channel.isOpen() as Nicholas suggested.
, - For ProviderInfo.next, I agreed that your implementation is more efficient and use less memory.  +1 since this class is a low level class.

- >This won't work because most channels are both Readable and Writable.
Actually, I think the boolean variable read can be eliminated.  See below.

- > Can't really eliminate runtime checking. For e.g. SocketInputStream's channel should be both SelectableChannel and a ReadableByteChannel. How do we enforce that without runtime check?

In the constructor of SocketIOWithTimeout, you already enforce if read is true, channel must be a ReadableByteChannel, otherwise, channel must be a WritableByteChannel.  I do not see a good reason to put ReadableByteChannel and WritableByteChannel in the same class and use a boolean to remember whether it is doing read or write.

I suggest to add two classes, say ReadableSocketIOWithTimeout and WritableSocketIOWithTimeout, both extending SocketIOWithTimeout.  Then, the fields layout will become:
{code}
abstract class SocketIOWithTimeout {
  private long timeout;
  private boolean closed = false;
}

class ReadableSocketIOWithTimeout extends SocketIOWithTimeout {
  private ReadableByteChannel in;
}

class WritableSocketIOWithTimeout extends SocketIOWithTimeout {
  private WritableByteChannel out;
}
{code}

- Also found some typs in SocketIOWithTimeout.java 
line 59, /* => /**
line 119, mutliple => multiple
line 247, canceled => canceled
, > Actually, I think the boolean variable read can be eliminated.
:) one variable can always be 'eliminated' using one or more different variables. 

What is the problem you want to fix? Is it that we don't want a boolean? Or we should not do runtime cast in doIO()?, > What is the problem you want to fix?

The class SocketIOWithTimeout has two different uses, reading and writing.  Why not create two classes?, > The class SocketIOWithTimeout has two different uses, reading and writing. Why not create two classes?

That's why we have SocketInputStream and SocketOutputStream, right? I don't know advantage of two more classes on top of 3 we already have.

SocketIOWithTimeout is just a helper class for reading and writing with a timeout. Its is not user facing. I still don't follow the problem completely. It will be best if you could modify the patch to how you wanted it to be.. that way I understand what you mean.
, My latest attempt at working around boolean and not do runtime check in doIO()., 
Updated patch makes SocketIOWithTimeout an abstract class.

Fixed typos except one. The comment above SocketIOWithTimeout  is not meant to be JavaDoc. 

Nicholas, please take a look again if this matches the hierarchy. Thanks for the reviews.
, +1.  Codes look good., Resolved conflicts with HADOOP-2758., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12377022/HADOOP-2346.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 3 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs -1.  The patch appears to introduce 3 new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1886/console

This message is automatically generated., Fixed findbugs warnings. Findbugs is smart enough to know that socket.getOutputStream() does not need to be closed..  it does not know hadoop.net.SocketOutputStream() is a true drop in replacement.  I think eventually we will write a 'FilterSocket' and override getOutputStream() and getInputStream().
, +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12377113/HADOOP-2346.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 3 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1892/console

This message is automatically generated., Resolved conflict with the trunk., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12377217/HADOOP-2346.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 3 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1900/console

This message is automatically generated., I just committed this., Integrated in Hadoop-trunk #421 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/421/])]