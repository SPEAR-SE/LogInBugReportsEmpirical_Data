[1. HftpFileSystem.initialize should throw a LoginException when login failed. Otherwise, A NullPointerException might be thrown when a URL is constructed.
2. ListPathsServlet and FileDataServlet talks to namenode through RPC not by direct method call. Shall we concern about the performance?
3. ListPathsServlet.writeInfo should also write a path's permission-related info back to the client.
4, For secondary namenode communication, I think it is better to check the user in getFileServer and getInfoServer. This means that these two methods can not be static.
5. Can we also enforce user checking for NamenodeProtocol?
6. The patch passes the user info to StreamFile servlets but the user info is not used. Since currently dfs does not check user authorization for client to datanode communications, I feel it is better to do it later on., Regarding to Hairong's comment:

1. Sure, I will make it throwing an IOException warpping a LoginException.  Then, we don't have to change the FileSystem API.

2. Comparing to file transfer time, RPC overhead is negligible.  So it is fine to do RPC calls.

Right now, we need RPC calls for passing ugi to name node.  Once we have changed the way for storing ugi (by thread local variable or by Subject) in name node late on, we could get rid of RPC.

3. They were already done by some previous patches.

4 & 5. Actually, I should not change the secondary namenode in this issue since it is not related.  I will create another issue for that and NamenodeProtocol.

6. StreamFile servlet first stores ugi to conf and then use it to create a DFSClient.  So the ugi is used indeed., +1 The patch looks good., resubmitting to Hudson, -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373804/2652_20080122.patch
against trunk revision 614721.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1659/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1659/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1659/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1659/console

This message is automatically generated., *This is an incompatible change* since distcp may not be able to copy files from cluster A (compiled with this patch) to cluster B (compiled with previous versions).  The reason is that distcp starts a Med/Reduce job in cluster B.  Then the job will use Hadoop library provided by cluster B to connect to cluster A.  If the connection scheme is hdfs://, it will work if they use the same RPC protocal.  If the connection scheme is hftp://, the job with old codes does not provide a ugi.  Then, the default web user account (see HADOOP-2614) will be used in cluster A for further permission checking.

For other cases listed below, distcp is tested to be working for hftp.
- cluster (compiled with this patch) -> cluster (compiled with this patch): *working* for both hftp and RPC
- cluster (compiled with previous versions) -> cluster (compiled with this patch): *working* for hftp
- cluster (compiled with previous versions) -> cluster (compiled with previous versions): *irrelevant*, -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373998/2652_20080124b.patch
against trunk revision 614721.

    @author +1.  The patch does not contain any @author tags.

    javadoc -1.  The javadoc tool appears to have generated  messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1676/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1676/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1676/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1676/console

This message is automatically generated., 2652_20080125.patch: Fixed javadoc problem, +1. The code looks good., I ran these tests against http://issues.apache.org/jira/secure/attachment/12374073/2652_20080125.patch

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

Looks ready to commit., I just committed this. Thanks Nicholas!, Integrated in Hadoop-trunk #380 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/380/])]