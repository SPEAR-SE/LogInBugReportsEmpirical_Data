[After much investigation, I was able to reproduce the problem. This is caused by the same datanode registers more than once. Each registeration puts the datanodeDescriptor in the heartbeat queue. When the heartbeat queue has more than one reference to the same DataNodeDescriptor and the datanode losts a heartbeat, heartbeatCheck will get into an infinite loop. 

This problem could be fixed either by doing a contains check before adding a datanodeDescriptor to the heartbeat queue or using a collection type that disallow duplicate entries for the heartbeat queue., I still get infinite loop with this patch.
But HADOOP-1256 fixes it.
, Konstantin, this is interesting! I will take a look at how HADOOP-1256 causes the infinite loop after I come back from my vacation., Just for the record, our namenode servers with release 0.12.3 got into this situation twice, once with a 1000-node cluster, once with a 500-node cluster. In this situation the server spits out 300+ messages per sec and becomes rather unresponsive to DFS clients., Whenever this happens, we have to restart the dfs., Update the patch to the latest trunk., +1. Code looks good. Let's get this into the next release as soon as possible., Many many thanks to Konstantin who spent time reproducing the infinite loop problem that he got sometime ago. I looked at his case and found out that the loop was caused by HADOOP-1256. Since 1256 already took care of his problem, I am going to mark this patch available., +1

http://issues.apache.org/jira/secure/attachment/12356681/heartbeat.patch applied and successfully tested against trunk revision r536239.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/123/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/123/console, I just committed this.  Thanks, Hairong!, Integrated in Hadoop-Nightly #83 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/83/)]