[Hi Pablo, thanks for filing the issue.

What you mention is not a valid use case. KMS can't use HDFS as the backing storage. As you could imagine, if HDFS is used for KMS, then each HDFS client file access would go through HDFS NameNode --> KMS --> HDFS NameNode --> KMS ....

The file based KMS can use keystore files on the local file system. , Hi Wei-Chiu,

Thank you very much for your quick response. So I have misunderstood the documentation. I thought the KMS could use any of the providers present in the provider type section of the Credential Provider API docs: [https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/CredentialProviderAPI.html#Provider_Types]

I understood that the HDFS NameNode was only consulted when an access to an encryption zone was requested because the metadata stored in the NameNode only contains the EDEK for the files in an encryption zone. I thought that, because the key provider is already encrypted by the KMS, it could be in a non-encrypted zone of HDFS. 

This case was great to have the KMS in HA  because they could share the key provider and be configured very easily.

Thank you again for your help., If I understand it correctly, you wanted to implement KMS-HA using HDFS for storing keystore?

While I can conceive that as a simple & quick solution, it makes little sense to store keystore in an unencrypted HDFS cluster. It also violates the initial design principal – separation of duty. With the keystore in non-EZ, A hdfs admin can easily decrypt anything in the cluster, voiding the need of KMS.

 

KMS HA is not a trivial task. Please consult this doc for reference: https://hadoop.apache.org/docs/current/hadoop-kms/index.html#High_Availability, Yes, I want to implement KMS-HA using HDFS for storing keystore.

As you said, this solution may be confronting the separation of duty design principle. However, If I understand how the KMS works correctly, an HDFS admin could access the keystore but, because the key provider is encrypted by the KMS and only KMS could decrypt the contents of it, the admin wouldn't be able to decrypt anything in the cluster.

The problem I am facing trying to configure KMS in HA is that the KMS doesn't manage the replication of the data in the keystore. So, for example, if two instances of KMS are deployed, the client could be configured so if a request to a KMS instance fails, clients retry with the next instance, but the data of the two KMS keystore would be different if you use a local filesystem. The only solution I could think is using a shared filesystem for the KMS instances, which may be fine enough, but if the HA algorithm is something like round robin, there could be locking problems in the concurrency trying if the instances try to access the keystore at the same time.

As you said, KMS HA is not an easy task at all.

Thank you very much for your comments and your help., Yeah... that's a problem. Even if you use a shared file system (like NFS?) you still need to make sure the network communication is authentication and encrypted., Filed HADOOP-15413 to get this documented. I'll close this Jira then.]