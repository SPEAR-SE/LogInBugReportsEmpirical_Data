[currently if globAndProcess() doesn't find any file that match with the pattern, does nothing. with the HDFS-1609.patch, raise FileNotFoundException if there's no matches, Same scenario can be applicable for cat, text, stat.. commands also.

So, instead of throwing FileNotFoundException from globAndProcess and catching it in each API and rethrowing the same by changing message, we can directly throw IOException with message.Because that will go directly to user.
 
if (null == globStatus || globStatus.length == 0) {
   throw new IOException("No such directory / file");
}

For Stat: 

inside stat API , we can handle the similar condition for wildcard characters.

FileStatus glob[] = srcFs.globStatus(srcPath);
if (null == glob || glob.length == 0)
  throw new IOException("cannot stat `" + src
	+ "': No such file or directory");
 

, If we want to follow the glob handling in unix, then it's a bit more tricky.

In Unix, non-matching globbing returns non-zero only when ALL of the globbings fail.

{quote}
[knoguchi ~/testo]$ ls
fileA
[knoguchi ~/testo]$ cat file*
ABCDEF

=======================
This is also success(return value 0) !?

[knoguchi ~/testo]$ cat file* nonexist*
ABCDEF
[knoguchi@gwbl4004 ~/testo]$ echo $?
0

=======================
And this is not? 
[knoguchi ~/testo]$ cat fileA nonexist*
cat: No match.
[knoguchi ~/testo]$ echo $?
1
{quote}, 
*Cat command behaviour in Linux:*

 linux222:/home/hadoop/bin # cat test.*
   content in test file
 linux222:/home/hadoop/bin # echo $?
   0
 linux222:/home/hadoop/bin # cat test.* nonexist*
   content in test file
   cat: nonexist*: No such file or directory
 linux222:/home/hadoop/bin # echo $?
   1
 linux222:/home/hadoop/bin # cat nonexist*
   cat: nonexist*: No such file or directory
 linux222:/home/hadoop/bin # echo $?
   1
 linux222:/home/hadoop/bin #


Here the issue in our filesystem, when we give nonexist path with *, we will not get any error message on console. In this case we will get globstatuslength will be zero.

After handling the above condition (globstatuslength  == 0 ) we can get that message on non matching directory with *. 
, Fix for this defect is in FsShell.java but the file present in COMMON project. Patch (HDFS-1609-src.patch) need to be updated in COMMON.
, I see. 
tcsh and bash behaves differently for multiple globbing.
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12472666/HDFS-1609-test.patch
  against trunk revision 1076696.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 7 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these core unit tests:
                  org.apache.hadoop.hdfs.server.datanode.TestBlockReport
                  org.apache.hadoop.hdfs.TestDFSShell
                  org.apache.hadoop.hdfs.TestFileConcurrentReader

    -1 contrib tests.  The patch failed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/229//testReport/
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/229//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/229//console

This message is automatically generated., > tcsh and bash behaves differently for multiple globbing.

If the behavior is not standardized, I suggest to keep the current implementation.

Marking this as "Incompatible Change"., I also have moved this to Common., Fix for this defect is in FsShell.java but the file present in COMMON project. Patch (HDFS-1609-src.patch) need to be updated in COMMON.

After applying this patch in Common, tests will pass., Related Tests are  org.apache.hadoop.hdfs.TestDFSShell.testInvalidPathPatternForCatStatRmr 
org.apache.hadoop.hdfs.TestDFSShell.testInvalidPathPatternForStat  
  This both test cases will pass with HDFS-1609-src.patch.
This is bacause testCode and sourceCode are vailable in HDFS,COMMON respectively., Would someone mind confirming that the error messages actually go to stderr?  They cannot go to stdout., it will be useful to user if we provide the error message instead of keep quite.
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12472666/HDFS-1609-test.patch
  against trunk revision 1094750.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 7 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/362//console

This message is automatically generated., In current trunk , looks this issue is fine .
Error messages standardized by HADOOP-7271


Tests:

linux-ybe6:/home/Uma/contributions/hadoop-hdfs-0.23.0-SNAPSHOT/bin # ./hdfs dfs -rm -r /NonExistant*
rm: `/NonExistant*': No such file or directory
linux-ybe6:/home/Uma/contributions/hadoop-hdfs-0.23.0-SNAPSHOT/bin #

Now looks it complaining to posix.

I will be closing this issue as duplicate to HADOOP-7271.]