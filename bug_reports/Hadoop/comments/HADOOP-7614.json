[-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12493317/HADOOP-7614-v1.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/144//console

This message is automatically generated., Fixed issues with first patch. Also using proper LOG instead of system.out., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12493327/HADOOP-7614-v2.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-common-project.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/145//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/145//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/145//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/145//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-annotations.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/145//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth-examples.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/145//console

This message is automatically generated., is this going to leak streams? , You are right; with currently proposed patch every Configuration will never close marking-supported inputstream. (How bad is this? When a Configuration is gc-ed, could we make sure all streams are closed, i.e. in a finalizer? I'm not sure if this is the way to go).

So what about another solution? Read and close the stream and somehow keep/cache the contents when the Configuration is reloaded?, Configurations last a long time and can get passed around, so I'm reluctant do anything that could leak things or even add XML files to the in-memory configuration.

removing the behaviour altogether would break things (it's hard to tell from the general Object interface)

I think in this situation, handling reloading by doing nothing may be the best tactic; possibly warning the user somehow. Once an inputstream has been loaded, the {{loadDefaults}} flag could be set to false. Yet that would change behaviour in copied configurations, that will not crash on a reload.
, A workaround to fix the testcode:
{code}
    Configuration conf = new Configuration();

    ByteArrayInputStream bais = new ByteArrayInputStream("<configuration></configuration>".getBytes());
    Configuration tmp = new Configuration();
    tmp.addResource(bais);
    
    Iterator<Map.Entry<String, String>> it = tmp.iterator();
    while (it.hasNext()) {
      Map.Entry<String, String> entry = it.next();
      conf.set(entry.getKey(), entry.getValue());
    }
    
    System.out.println(conf.get("blah"));
    conf.addResource("core-site.xml"); //just add a named resource, doesn't matter which one
    System.out.println(conf.get("blah"));
{code}, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12493327/HADOOP-7614-v2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6277/console |


This message was automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12493327/HADOOP-7614-v2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6296/console |


This message was automatically generated., Tested the issue in 2.7.0 and in trunk. Unable to reproduce using the testcase. Closing the issue. Feel free to reopen, Closing old tickets that are already part of a release.]