[The patch related to considering disk space for scheduling was committed to 0.19 and later (HADOOP-657). So, the difference between behaviour of 0.18 and that of 0.19 is expected. But, it is definitely weird for the estimate to shoot up to as high as 400 GB. Can you attach the whole JT log when this particular problem occured, so that we can find how the estimates performed/were calculated over time and when they started going wayward., Hm.. there does seem to be a bug in the estimation as Jothi pointed out quite some time back here (https://issues.apache.org/jira/browse/HADOOP-657?focusedCommentId=12622464#action_12622464). The estimate calculated in that case was ~1000GB!!

Logs would definitely help track this one down., I've attached the complete log of the JobTracker for a single MR job submission that hits this issue on 100 nodes., The high estimate is due to the reason that blow up ratio is added for each completed task. The maps which have 0 input create lot of skew. In the current code, consider this case:
1. first map completes blowupOnThisTask (output/input) = 1000/200 = 5
   mapBlowupRatio = 5
2. second map completes blowupOnThisTask  (output/input) = 50/1 = 50 (in this case the input was 0 and there is some output produced)
    mapBlowupRatio becomes 50/2 + ((2 - 1) / 2) * 5 = 27.5 
This leads to unreasonable blow up from 5 to 27.5

The fix I propose is as follows:
Instead of adding the blowup ratio, calculate the blow up based on (cumulative completed map output size)/(cumulative completed map input size). For above example, it works out as follows:
1. first map completes blowupOnThisTask (output/input) = 1000/200 = 5
   mapBlowupRatio = 5
2. second map completes blowupOnThisTask  (output/input) = 50/1 = 50 (in this case the input was 0 and there is some output produced)
    mapBlowupRatio becomes (1000+50)/(200+1) ~ 5.2
This leads to reasonable blow up from 5 to 5.2, attaching patch with the fix. Andy, could you try out this patch with your installation ?, JobTracker logfile running same benchmarks as before without any errors., Screenshot of running job with over 100% completion rate?, The benchmark is working again without any errors on 100 nodes with the full 600GB data set. I'm also getting roughly the same speed I was getting before. I think that Sharad's patch fixes my problem. I have two other experiments that I'll run tomorrow morning to double check whether this is truly fixed.

Lastly, I don't know whether this is a side-effect of the patch, but I noticed that one of my reduce tasks is reporting to be over 100% complete! The setup is as follows: I run the full PageRank experiment on all 100 nodes and then combine the results into a single file using a second MR job with a single reduce task. The execution time is about the same as 0.18, so I'm not seeing any performance problems., bq. one of my reduce tasks is reporting to be over 100% complete! 
this is a known bug. see HADOOP-5210 and HADOOP-4000, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12400381/hadoop_task_screenshot.png
  against trunk revision 746864.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3900/console

This message is automatically generated., Resubmitting the same patch, so that Hudson can pick the correct one., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12400731/5241_v1.patch
  against trunk revision 746864.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3901/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3901/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3901/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3901/console

This message is automatically generated., Test case failure is unrelated, I just committed this to the 0.20 and 0.21 branches. Thanks, Sharad! (After 0.19.1 is released, we should commit this to 0.19 branch as well), Integrated in Hadoop-trunk #763 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/763/])
    . Fixes a bug in disk-space resource estimation. Makes the estimation formula linear where blowUp = Total-Output/Total-Input. Contributed by Sharad Agarwal.
, I committed this to the 0.19 branch.]