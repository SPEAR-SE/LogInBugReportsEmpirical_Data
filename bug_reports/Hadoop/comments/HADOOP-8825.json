[This patch reinstates the constructors. I tested this by running Avro tests using Hadoop JARs built with the patch applied., Just out of curiosity how is Avro accessing these classes?  They are package private classes, and even though SequenceFile is @Public and @Stable being package private seems to indicate to me that they are not intended for general consumption.  If Avro is going to use them could we please mark them @LimitedPrivate for Avro, and perhaps even open them up more so they are public instead.  So Avro does not have to put their classes in an org.apache.hadoop.io package to use them., Avro is using the constructors via a class called SequenceFileBase in org.apache.hadoop.io to provide access. However, I agree that this is a poor way to do things, so making them public would be a lot better., I am not an expert on sequence files so I perhaps am not the best person to make that choice to open them up.  From a quick read through the code it look like they were not intended to be extension points.  Why does avro need access to the compression writers, and does not just rely on the key and value serializers as the extension points?  At a minimum they need to be @LimitedPrivate for Avro so we don't break Avro again in the future.  But before marking them public I want to understand the reasons why Avro needs access to them, and if there is some cleaner way we can provide an extension point so others can do the same thing., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545738/HADOOP-8825.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    -1 findbugs.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1485//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/1485//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1485//console

This message is automatically generated., It's to support a wrapper around SequenceFile for Avro types: http://avro.apache.org/docs/1.7.1/api/java/org/apache/avro/hadoop/io/AvroSequenceFile.html. But it would be preferable to use the existing constructors or createWriter methods. I'll take a look to see if that's possible. , I managed to change AvroSequenceFile so it doesn't need to use the BlockCompressWriter or RecordCompressWriter constructors. Thanks for the help Bobby! , Glad I could help.  I don't think I did much, you actually wrote the code, so thanks should mostly go to you.]