[first patch., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  19m  2s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:red}-1{color} | javac |   8m 48s | The applied patch generated  4  additional warning messages. |
| {color:green}+1{color} | javadoc |  10m 59s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   1m 19s | The applied patch generated  7 new checkstyle issues (total was 75, now 82). |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 30s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 35s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   2m  7s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:red}-1{color} | common tests |  22m 57s | Tests failed in hadoop-common. |
| | |  67m 42s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.ipc.TestDecayRpcScheduler |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12745378/HADOOP-12234.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 0a16ee6 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/7280/artifact/patchprocess/diffJavacWarnings.txt |
| checkstyle |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7280/artifact/patchprocess/diffcheckstylehadoop-common.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/7280/artifact/patchprocess/whitespace.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7280/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7280/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7280/console |


This message was automatically generated., Can you specify the concrete attack scenario that you're defending against?

I don't think it makes sense to make it available through a filter due to the variety requirements of the different projects. A better approach is to change the HTML code to ensure that the UI runs on the top frame., [~wheat9] I don't have enough context here. Can you please give me some examples of different requirements by other projects where this fix won't work.

bq.  A better approach is to change the HTML code to ensure that the UI runs on the top frame.

You mean something like this. https://www.owasp.org/index.php/Clickjacking_Defense_Cheat_Sheet#Best-for-now_Legacy_Browser_Frame_Breaking_Script
Is there a single place which can be changed to implement this, or will it require changing all pages individually?, oh btw, the implementation is from OWASP(Open Web Application Security Project) page [here|https://www.owasp.org/index.php/ClickjackFilter_for_Java_EE]. , bq. Can you specify the concrete attack scenario that you're defending against?

My understanding from reading the owasp.org page is that the attack scenario would be something like this following: the user somehow loads a malicious web site.  That malicious website redirects some of the user's clicks unexpectedly to the HDFS web UI, with malicious results.  This might be a way for users who don't have permission to access the HDFS web UI to take advantage of users who do.

bq. I don't think it makes sense to make it available through a filter due to the variety requirements of the different projects. A better approach is to change the HTML code to ensure that the UI runs on the top frame.

Interesting idea.  So the idea would be to change the web UI HTML directly rather than using this filter?, {quote}
I don't think it makes sense to make it available through a filter due to the variety requirements of the different projects. A better approach is to change the HTML code to ensure that the UI runs on the top frame.
{quote}

this seems inefficient, since it requires maintaining the fix on every HTML page. By far the common case is "I don't expect to be in a frame." Especially given a known attack vector, we should make folks opt-in to allowing it.

{quote}
oh btw, the implementation is from OWASP(Open Web Application Security Project) page here.
{quote}

Please update your patch to maintain the original authorship and license header (see [the source header policy for details, under "third party works"|http://www.apache.org/legal/src-headers.html]). Also please add the appropriate addition to the top-level LICENSE.txt file., bq. Please update your patch to maintain the original authorship and license header (see the source header policy for details, under "third party works"). Also please add the appropriate addition to the top-level LICENSE.txt file.

Sorry, didn't know about licensing stuff. Fixed now. Since tests were written by me, they still have the apache license.

Please let me know if it needs to be back-ported to other branches.
Thanks., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  16m 35s | Pre-patch trunk compilation is healthy. |
| {color:red}-1{color} | @author |   0m  0s | The patch appears to contain 2 @author tags which the Hadoop  community has agreed to not allow in code contributions. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:red}-1{color} | javac |   7m 33s | The applied patch generated  4  additional warning messages. |
| {color:green}+1{color} | javadoc |   9m 37s | There were no new javadoc warning messages. |
| {color:red}-1{color} | release audit |   0m 15s | The applied patch generated 1 release audit warnings. |
| {color:red}-1{color} | checkstyle |   1m 11s | The applied patch generated  10 new checkstyle issues (total was 75, now 85). |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 22s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 50s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  22m 13s | Tests passed in hadoop-common. |
| | |  61m 13s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12746460/HADOOP-12234-v2-master.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 31f1171 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/7321/artifact/patchprocess/diffJavacWarnings.txt |
| Release Audit | https://builds.apache.org/job/PreCommit-HADOOP-Build/7321/artifact/patchprocess/patchReleaseAuditProblems.txt |
| checkstyle |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7321/artifact/patchprocess/diffcheckstylehadoop-common.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/7321/artifact/patchprocess/whitespace.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7321/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7321/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7321/console |


This message was automatically generated., bq. this seems inefficient, since it requires maintaining the fix on every HTML page. By far the common case is "I don't expect to be in a frame." Especially given a known attack vector, we should make folks opt-in to allowing it.

I believe it needs to be taken care of each different project. Why not putting it in the project that needs it?

Take HDFS as example. (1) the HDFS UI has only two pages, and (2) I can see that there are valid use cases to embed the file browser in an iframe (e.g., integration with Amabri). Having a filter that deny framing is not a viable option.

bq. Interesting idea. So the idea would be to change the web UI HTML directly rather than using this filter?

Yes. To defend against clickjacking attack reliably, the HTML needs to deploy frame busting techniques anyway in order to support older browsers (e.g., IE 7)., bq. Take HDFS as example. (1) the HDFS UI has only two pages, and (2) I can see that there are valid use cases to embed the file browser in an iframe (e.g., integration with Amabri). Having a filter that deny framing is not a viable option.

In that case, Amabri users can set 'hadoop.http.xframeoptions.mode' to 'ALLOW'. I believe this setting will allow Amabri and future embedding use cases.

bq. Yes. To defend against clickjacking attack reliably, the HTML needs to deploy frame busting techniques anyway in order to support older browsers (e.g., IE 7).

If there is a single script/place where this change can be made, I think this will be better option, but if it requires changing every page individually, am a bit skeptical because if one forgets to add the script to new page(s) (in hadoop or other projects), it'll create holes in the security and might bite in the future., I think {{X-Frame-Options}} is a good thing to have but I don't see this is a fit in {{hadoop-common}}. I believe that should be done in a per-project basis.

bq. In that case, Amabri users can set 'hadoop.http.xframeoptions.mode' to 'ALLOW'. I believe this setting will allow Amabri and future embedding use cases.

This is far from useful. What happens if both HDFS and YARN, and other projects are deployed on the same configuration? In HDFS it requires a finer grain control. For example, only {{explorer.html}} can be framed for a particular origin but no more.

bq. am a bit skeptical because if one forgets to add the script to new page(s) (in hadoop or other projects), it'll create holes in the security and might bite in the future.

This is highly speculative. The requirements vary from projects to projects. In HDFS the DN runs netty as the primary HTTP server, how does the filter even apply?, [~wheat9]  you have some good points with which I agree and some with which I don't. However, my only point is, while this might not be the ideal and as finer grained as you want to support Amabri and same configuration use case, it's still better then current system. At least those not using Amabri can benefit from the better security and it doesn't have any negative effect on amabri users.

I am sorry, but I have only limited time that I can invest in this issue and designing a finer grained control system and implementing it seems out of that scope right now. We can create an issue to improve the filter and maybe someone else can collaborate with you on that.

bq. I believe that should be done in a per-project basis.

Am not sure, you may be right here. In that case, we can change the default to 'ALLOW' and projects can set it to deny if needed.

We should get this in because this is only making the system better., reviewing this, I am pleased to see that we don't need to care about IE7 any more. Which is good, as nobody was going to test it anyway.

a filter in hadoop-common seems the best place for it. The main issue is: what turns it on and where? I'm with Haohui here: make it something projects explicitly turn on/off if they choose. HDFS's needs "part of a management console" are different from a YARN app where that's not a perceived use case.

On that topic, we'd probably recommend that YARN apps use it too, wouldn't we? Or at least have the RM proxy add it when filtering requests, which would give it to the apps automatically., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HADOOP-12234 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12746655/HADOOP-12234-v3-master.patch |
| JIRA Issue | HADOOP-12234 |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8366/console |


This message was automatically generated.

, This is an issue that has come up for our users and I just spent a few days duplicating this work in https://issues.apache.org/jira/browse/HADOOP-13008. 

Can someone tell me why this patch has stalled?

A couple comments on the differences between the two implementations:

1. package of the class - mine is in the same package as CrossOriginFilter and RestCsrfPrevenetionFilter: org.apache.hadoop.security.http. I think that it makes sense to keep these web app security filters together. I don't really care for the "lib" in this package name but maybe this is an existing pattern in hadoop elsewhere?
2. configuration prefixes - in order to accommodate some ability for some components to override a global setting, I proposed the use of separate prefixes. A global one that would be used if a component specific one was not found. See the JIRA for comments around that.
3. filter initializer - it seems that this implementation has its own filter initializer where HADOOP-13008 introduces the filter and would rely on integration specific initializers which would be able to interrogate the prefixed configuration for each integration point.

I think that we should determine which implementation should be resolved as duplicate based on the sense of which one is closer to what we need and adjusting to accommodate the other. I don't have any problem discarding HADOOP-13008 but let's discuss here.

I would like to get this feature in as soon as we possibly can in order to address the needs and concerns of our customers/users., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HADOOP-12234 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12746655/HADOOP-12234-v3-master.patch |
| JIRA Issue | HADOOP-12234 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9139/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

, duplicates to reconcile, [~stevel@apache.org] and [~appy] - we need to reconcile this JIRA with HADOOP-13008 as I described in the earlier comment. I believe that this protection is needed for our UIs and would like to move this forward.

Is there a reason that this has stalled?, I'd say HADOOP-13008 doing all the things you mentioned above would be a better choice. Go with it., Great. Thanks, @appy!
Please feel free to review it and collaborate to make sure it meets your
needs as well.

, As discussed in the comments of this JIRA, we will move forward with HADOOP-13008 for this functionality. I'm setting this as a duplicate and as superceded by HADOOP-13008.]