[
This issue poped up while executing following command 

java  -cp <classpath> org.apache.hadoop.hdfs.NNBench  -operation create_write  -maps <no. of maps> -startTime <current time>+120 (in seconds) -numberOfFiles <no of files> -blockSize <blocks per file>  -bytesToWrite <bytes per block> -bytesPerChecksum <blocks per file>

where no. of maps= 1.5 times of cluster size
      bytesToWrite=20
      numberOfFiles=cluster size
and default values are being used for blockSize and bytesPerChecksum (which is 1).


Environment:
==========
20 Nodes Cluster
500 Nodes Cluster
Hadoop Version : 0.20.0 (with fairshare Scheduler), Tried to run it on 5 nodes and 20 nodes cluster. The only time when it failed - was when I specified a wrong config. Since creating control files is the first access to HDFS it would fail there if it was trying to access a wrong NameNode (for example default, because config points to a wrong place).
My conclusion - it is possible that the failure was result of running with wrong config. 
If you run into this again - please attache NameNode logs and specify exact configuration.

Meanwhile closing the bug.]