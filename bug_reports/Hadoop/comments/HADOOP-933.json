[-1, because the patch command could not apply the latest attachment (http://issues.apache.org/jira/secure/attachment/12349621/MapTask.patch) as a patch to trunk revision r499156. Please note that this message is automatically generated and may represent a problem with the automation system and not the patch., I think a better solution would be to do HADOOP-867, which will have the client write all of the input splits to disk. Then the MapTask would only need to keep the Path to the split file and an offset. The only place the splits would be instantiated would be the submitting program and the task jvm., 867 might be a better solution, but it is an enhancement. This is a bug. It would be nice to fix the bug., > 867 might be a better solution, but it is an enhancement. This is a bug.

Actually, it's a new feature that doesn't yet work!

The workaround is to put your split implementations on the classpath of your tasktrackers.  That may or may not be practical for you...
, Unfortunately, the workaround wouldn't work either. The MapTask does not write out the name of the InputSplit class, so the readFields() assumes that it is reading a FileSplit., For a fix that doesn't depend on HADOOP-867, I would propose:
  1. Replace the InputSplit in MapTask with:
      private byte[] inputSplit;
      private String inputSplitClassname;
  2. The MapTask constructor still takes a InputSplit and serializes it to set inputSplit and inputSplitClassname.
  3. The MapTask.run method uses the bytes and classname to reconstruct the InputSplit as a local variable in run.
  4. I don't think the change to set map.input.* properties to default values in the non-FileSplit case is reasonable. , I found another place that assumed FileSplit. See attached patch. Our test cases pass now, so that should be the end of it. (At least for our use of InputSplit.), 
What is the status of this issue?
, 0.10.1 has already been released, so this cannot be targetted for that release., This patch fixes this bug and HADOOP-867.

The JobClient creates an InputFormat object and generates the list of InputSplits using getSplits. The list of InputSplits are written to a dfs file next to the job.xml. (More precisely, a list of RawInputSplits are written to a file. The RawInputSplits consist of the serialized InputSplit, the class name, and the list of locations. When the JobTracker initializes the JobInProgress, it just has to read the serialized InputSplits and passes them down to the TaskTrackers and to the Task. When the MapTask starts, it deserializes the InputSplit and uses it to create the RecordReader. This has the advantage that non-FileSplit InputSplits work (since the class is recorded) and that the user code is never loaded by the JobTracker., This patch also fixes HADOOP-338., This patch fixes the conflicts from Nigel's patch for moving test files out of /tmp., Doug wanted the split file to have a fixed ascii header. I added "SPL", -1, because 3 attempts failed to build and test the latest attachment (http://issues.apache.org/jira/secure/attachment/12350806/client-split.patch) against trunk revision r505557. Please note that this message is automatically generated and may represent a problem with the automation system and not the patch., This latest patch doesn't compile.  Also, the unit test leaves a directory named "test_mini_mr_local" in $CWD., Latest patch doesn't compile :p
Attaching one that does., This patch fixes the problems mentioned previously including moving all of the temporary directories into build/test. It also adds a bit to the task tracker jsp that lists the tasks that aren't running, but being stored on the task tracker. (This can help in figuring out why the mini/mr cluster gets stuck.) I also changed one of the mini/mr flags to volatile since it is accessed without synchronization., This has been fixed by HADOOP-867.]