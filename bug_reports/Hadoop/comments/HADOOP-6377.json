[With FsShell modified to print stack traces:

{noformat}
todd@todd-laptop:~/git/hadoop-common$ ./bin/hadoop fs -du /tmp/
Found 29 items
java.lang.NullPointerException
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1060)
        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1083)
        at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:473)
        at org.apache.hadoop.fs.FileSystem.getContentSummary(FileSystem.java:1024)
        at org.apache.hadoop.fs.FsShell.du(FsShell.java:731)
        at org.apache.hadoop.fs.FsShell.run(FsShell.java:1894)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.fs.FsShell.main(FsShell.java:1973)
{noformat}

This occurs on trunk and branch-0.21, but not branch-0.20, Not sure what the correct recourse is here. Hadoop 0.20 reports the unreadable directories as 0 bytes with no warnings. Linux du prints a warning for each and does not include them in the stdout output.]