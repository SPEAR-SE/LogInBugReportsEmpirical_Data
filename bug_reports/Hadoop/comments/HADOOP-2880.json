[Urgent for grid ops., This might be termed as an "incompatible" change. , I'm setting to 0.18.  

This probably needs to be discussed by the libhdfs users.  
I believe we should introduce HADOOP_O_RDONLY/HADOOP_O_WRONLY  and disable O_RDONLY/WRONLY by returning an error if passed.

A little background.

{noformat} 
#include "hdfs.h"
#include <fcntl.h>
...
    hdfsOpenFile(...,..., O_RDONLY) 
...
{noformat} 

would read the hdfs file correctly, but 

{noformat} 
#include <fcntl.h>
#include "hdfs.h"

...
    hdfsOpenFile(...,..., O_RDONLY) 
...
{noformat} 

would try to overwrite the file., Alternetely, hdfs.h could just not define these., bq. Alternetely, hdfs.h could just not define these.

Yes, but I'm afraid of what would happen when users don't re-compile or use a stale hdfs.h.
I would rather have those calls fail instead of unintentionally overwriting the files..., Christian pointed out to me that,

bq. I ran into the problem in the past, but now hdfs.h (since hadoop-0.9.x, believe) already includes fcntl.h before defining the macros, i.e. on linux it should be 0 for O_RDONLY and 1 for O_WRONLY.

This makes complete sense.  I don't know what I was hitting, but my comments are all incorrect. I'll close this Jira as invalid once I confirm., Christian was right.  
It must have been my application bug.

Sorry for the confusing,misleading,incorrect Jira. Closing.]