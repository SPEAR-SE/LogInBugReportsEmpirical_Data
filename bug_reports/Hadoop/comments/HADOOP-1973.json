[Gautam, were you running 0.14 or pre-0.15 when this happened?, this was on trunk.. 

the task trackers try to fetch the FS from JobClient which in effect asks JT for it's correspoding FS.. which wasn't up yet.
This is the exception trace on teh TT

2007-10-03 14:18:21,132 INFO org.apache.hadoop.mapred.TaskTracker: Lost connection to JobTracker [[TT_address]/[TT_IP]:50020].  Retrying...
org.apache.hadoop.ipc.RemoteException: java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobTracker.getFilesystemName(JobTracker.java:1458)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:340)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

        at org.apache.hadoop.ipc.Client.call(Client.java:470)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:165)
        at org.apache.hadoop.mapred.$Proxy0.getFilesystemName(Unknown Source)
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:773)
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:1179)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:1870)
, let me correct myself from earlier.. the JT does not shutdown after these exceptions.. this problem has no effect on the cluster's health. Only that we see bunch of exceptions till the namenode is fully up with the data nodes registered., Marking it a blocker. I see it with the sort benchmarks, causing them to fail, I dont see a reason why this caused sort to fail.
I'm submitting the patch which adds ensureRunning RPC for InterTrackerProtocol. 
Now, Tasktracker  will check for jobtracker is running. And then continue offerService., Rather than add {{ensureRunning}} to the {{InterTrackerProtocol}} it's enough to just call {{JobTracker#ensureRunning}} from {{JobTracker#getFilesystemName}}, I'd avoid extending protocols wherever possible., I think instead of putting ensureRunning into the protocol, and requiring that the client call it. I'd propose instead that getFileSystemName should check fs == null and throw IllegalStateException. (You actually don't care if the name node is running yet, you just want to get the default file system name.), The other issue is that there must be a sleep between retries., I added check for fs==null in getFileSystemName and it throws IllegalStateException if it is null.
Retries on failures has sleep for 5secs already., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12367853/patch-1973.txt
against trunk revision r585366.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/961/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/961/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/961/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/961/console

This message is automatically generated., I just committed this. Thanks, Amareshwari!, Integrated in Hadoop-Nightly #275 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/275/])]