[is this causes because in the following, the "if(num_read < 0)" should be "if(num_read <= 0)"? 

This way, the error is caught and it should return an IO error and continue on. I think hdfs though should return -1 in this case, but regardless, the fuse code leaves this condition out and should catch it.

{code}
    while (dfs->rdbuffer_size  - total_read > 0 &&                                                                                                                                                         
             (num_read = hdfsPread(fh->fs, fh->hdfsFH, offset + total_read, fh->buf + total_read, dfs->rdbuffer_size - total_read)) > 0) {                                                                   
        total_read += num_read;                                                                                                                                                                              
      }                                                                                                                                                                                                      
                                                                                                                                                                                                             
      if (num_read < 0) {                                                                                                                                                                                    
        // invalidate the buffer                                                                                                                                                                             
        fh->bufferSize = 0;                                                                                                                                                                                  
        syslog(LOG_ERR, "Read error - pread failed for %s with return code %d %s:%d", path, (int)num_read, __FILE__, __LINE__);                                                                              
        ret = -EIO;                                                                                                                                                                                          
      } else {                                                                                                                                                                                               
        fh->bufferSize = total_read;                                                                                                                                                                         
        fh->buffersStartOffset = offset;                                                                                                                                                                     
                                                                                                                                                                                                             
        if (dfs->rdbuffer_size - total_read > 0) {                                                                                                                                                           
          isEOF = 1;                                                                                                                                                                                         
        }                                                                                                                                                                                                    
      }                                           
{code}
, sorry, looking at it more carefully,  this looks like the case where total read = 0, so the assertion is actually wrong as you say and should probably be instead:

{code}
    assert(bufferReadIndex >= 0 && bufferReadIndex <= fh->bufferSize);                                                                                                                                        
{code}

But, if this is that case, the fact that it read 0 bytes should probably mean it should return an EIO to be more posix compliant.  so, maybe the if should be 

{code}
  if(num_read < 0 || (total_read == 0 && size > 0)) {
{code}

and the assertion should also be as above to handle the case where size == 0.



, fixed by handling this case of the read immediately resulting in EOF with no bytes read.

, Fixed, although it seems there may be a bug in hdfs as  http://java.sun.com/j2se/1.5.0/docs/api/java/io/InputStream.html#read(byte[])  says the read should return -1 and not 0 in case of EOF or other error.

, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12393554/HADOOP-4616.txt
  against trunk revision 712344.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3560/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3560/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3560/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3560/console

This message is automatically generated., This is a more complete patch and also fixes the error codes.
, re-submitting to hudson. Marc, can you try this patch and see if it fixes things for you?

thanks, pete
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12393676/HADOOP-4616.txt
  against trunk revision 712962.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    -1 javac.  The applied patch generated 220 javac compiler warnings (more than the trunk's current 1011 warnings).

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3575/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3575/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3575/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3575/console

This message is automatically generated., I tested the patch, it seems to work fine, at least on missing data (I could not find a file that was corrupt, those are a bit harder to get)

I tested it by killing the datanodes, while keeping the namenode alive. When trying to copy a file to the local file system, I get the following error :

cp : reading <file name> : : Unknown error 255

Which is what we were supposed to get, I guess.

A possible improvement would be to get a better error code, but I don't know what kind of possibility you have regarding the error codes...

Thanks for the quick fix!

Marc-O, hi Marc-O,

Did you get a chance to look at the code? and if so, can you +1 it if you approve?

thanks, pete
, here is the 0.18.2 patch including generating a warning in libhdfs if it returns 0 from there and also fixing the memory leak of the mutex not being destroyed.
if this is good, i can supply the 0.19/trunk patch which is almost identical.
, had the ordering of the fprintf in libhdfs after setting noreadbytes=0 so always printing warning.
, this is for 0.19 and trunk
, re-submitting for hudson.
, Dhruba and I looked at this more and did reproduce the test of 1) all blocks going missing for a file and 2) a block being corrupt for a file (i edited the block) and all seems ok here but could not hit the condition of getting a non error code back from dfs but reading 0 bytes. But I can see how it is possible.

Note that this error does not happen for 0 size files normally as some higher level mechanism is returning EOF rather than fuse-dfs itself.  Otherwise, this assertion would be failing all the time for 0 sized files.

-- pete
, changing priority to blocker as this needs to get fixed in 0.19.1 and 0.18.3 (if there will be such a thing)., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12393751/HADOOP-4616_0.19.txt
  against trunk revision 713612.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3581/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3581/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3581/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3581/console

This message is automatically generated., re-submitting for hudson, including the fix to the group freeing problem., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12394123/HADOOP-4616_0.19.txt
  against trunk revision 719152.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3607/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3607/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3607/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3607/console

This message is automatically generated., ready to commit.

Please apply :

patch HADOOP-4616_0.19.txt to trunk and 0.19.1
patch HADOOP-4616_0.18.2.txt to 0.18.2

thanks, pete

, This patch introduces a debug print into stderr in libhdfs:

+            if (noReadBytes == 0 || noReadBytes < -1) {
+              fprintf(stderr, "WARN: FSDataInputStream.read returned invalid return code - libhdfs returning EOF, i.e., 0: %d\n", noReadBytes);
+            }

I am fine with it but would like to poll the user-community to see if this could break any application that is currently using libhdfs., I just committed this. Thanks Pete!, Integrated in Hadoop-trunk #668 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/668/])
    . Fuse-dfs can handle bad values from FileSystem.read call.
(Pete Wyckoff via dhruba)
]