[Attached is a simple patch to fix this. This patch also adds check for class.getSimpleName() while checking for inputformat class. In that case, users do not have to specify full class path for standard Class, instead they could just provide the simple class name.
Thanks, Making this patch available. , +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12366611/CatchInvalidInputFormat.patch
against trunk revision r586680.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/975/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/975/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/975/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/975/console

This message is automatically generated., I don't think it's relevant to log absence of combiner, partitioner etc. at INFO level, no? 

Most users probably don't specify them... I'd log them at DEBUG rather than have all users see it all the time.
, Thanks for looking into this Arun.
The use case here was when a user specifies a partition/combiner class and if we discover the class is not available, the earlier code used to just ignore it. So, I added the message to let them know that their specified class does not exists and we are defaulting. Should I move it to DEBUG and resubmit a patch?, Lohit,

A lot of users do not override partitioners, do not specify combiners etc. These users should not get spurious messages about absence of these at info level. I think the better fix would be in StreamUtil.goodClassOrNull method, which checks if the class is specified and when it is not found, logs it at info level and throws an exception. It should not silently ignore and continue., bq. I think the better fix would be in StreamUtil.goodClassOrNull method, which checks if the class is specified and when it is not found, logs it at info level and throws an exception. It should not silently ignore and continue.

+1, Ok, I should have mentioned that StreamUtil.goodClassOrNull actually is used to check if the map command passed is a class or an executable. So, -mapper could have either a class or just an executable. So, if that is not a valid class, a null (as the method name indicates) is returned and StreamJob treats it as a map executable. How about logging at info level inside the goodClassOrNull class and instead of throwing an exception we fail at appropriate places, when we do not allow null? If so, I will modify that and submit a patch., I am attaching an updated patch, which logs at info level inside goodClassOrNull method and fails for invalid class in partitioner/combiner/output format/inputformat. Fixed  streaming test cases which were using invalid combiner which again was ignored previously. , On the other hand if I think about it, should we log at info level inside goodClassOrNull ? If the mapper is 'cat' which is valid executable, we should not log saying cat class not found, no? I reverting back the loggin inside goodClassOrNull and handle the failures in StreamJob where needed. Thoughts? (Attached is a patch, which reverts only login changes), Thanks Arun. Making this PA, +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12368731/HADOOP-1952-2.patch
against trunk revision r590273.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1037/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1037/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1037/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1037/console

This message is automatically generated., Lohit, I see your latest patch removes some combiner options... are you sure about these changes? If so, are they related to this jira?

{noformat}
Index: src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingFailure.java
===================================================================
--- src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingFailure.java  (revision 588543)
+++ src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingFailure.java  (working copy)
@@ -47,7 +47,6 @@
       "-input", INVALID_INPUT_FILE.getAbsolutePath(),
       "-output", OUTPUT_DIR.getAbsolutePath(),
       "-mapper", map,
-      "-combiner", combine,
       "-reducer", reduce,
       //"-verbose",
       //"-jobconf", "stream.debug=set"
Index: src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestGzipInput.java
===================================================================
--- src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestGzipInput.java (revision 588543)
+++ src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestGzipInput.java (working copy)
@@ -47,7 +47,6 @@
       "-input", INPUT_FILE.getAbsolutePath(),
       "-output", OUTPUT_DIR.getAbsolutePath(),
       "-mapper", map,
-      "-combiner", combine,
       "-reducer", reduce,
       "-jobconf", "stream.recordreader.compression=gzip"
     };
Index: src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreaming.java
===================================================================
--- src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreaming.java (revision 588543)
+++ src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreaming.java (working copy)
@@ -40,7 +40,6 @@
   protected String map = StreamUtil.makeJavaCommand(TrApp.class, new String[]{".", "\\n"});
   // reduce behave like /usr/bin/uniq. But also prepend lines with R.
   // command-line combiner does not have any effect any more.
-  protected String combine  = StreamUtil.makeJavaCommand(UniqApp.class, new String[]{"C"});
   protected String reduce = StreamUtil.makeJavaCommand(UniqApp.class, new String[]{"R"});
   protected String outputExpect = "Rare\t\nRblue\t\nRbunnies\t\nRpink\t\nRred\t\nRroses\t\nRviolets\t\n";

@@ -66,7 +65,6 @@
       "-input", INPUT_FILE.getAbsolutePath(),
       "-output", OUTPUT_DIR.getAbsolutePath(),
       "-mapper", map,
-      "-combiner", combine,
       "-reducer", reduce,
       //"-verbose",
       //"-jobconf", "stream.debug=set"
{noformat}
, Hi Arun,
Yes, these were present in the testcases but never used by the actual streaming command in those test cases. The invalid option passed on were ignored by the previous streaming code. The patch now catches such invalid options, so I updated the depending test cases as well., I just committed this. Thanks, Lohit!, Integrated in Hadoop-Nightly #297 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/297/])]