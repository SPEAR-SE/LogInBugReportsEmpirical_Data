[Patch against branch-1, Patch against trunk, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12514006/HADOOP-8052.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests:
                  org.apache.hadoop.metrics2.util.TestSampleStat

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/582//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/582//console

This message is automatically generated., If the size of the constants is being reduced from double to float, the private variables min and max and the public method max() should also become float, shouldn't they?

Since the inputs can be double, I would also recommend doing clipping functions in appropriate places to prevent NaN ("Infinity") results from over/underflow, eg "if (value > Float.MAX_VALUE) value = Float.MAX_VALUE;" etc., where "value" is a double., Patch against branch-1, Patch against trunk, I chose to not change the data type housed in the MinMax class because that would, as is alluded to by your helpful hint about clipping, be a much bigger change with a wider-reaching impact. 

Instead, my justification for just changing the default values of 'max' and 'min' to Float.MIN_VALUE and Float.MAX_VALUE, respectively, is:

a) It is the smallest required change that fixes both problems with gmetad I mentioned in my original description.
b) It will likely be rare that we emit metrics outside of the range of [E-38:E+38], so the regions on the number line outside of that range (that Double.MAX_VALUE and Double.MIN_VALUE provide access to) are not really needed.

Also, I've left the types of the 2 new constants as 'double' in case we ever want to move back to using Double's extremes in the future - my current fix signifies (or at least I hope it does) that the *only* change we're making is in the default values of the 'min' and 'max' fields., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12514037/HADOOP-8052.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in .

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/584//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/584//console

This message is automatically generated., +1. Okay, I see now how this is a sufficient fix.  I'm going to comment them so future developers won't think the type/size mismatch is a mistake, then commit to 1.0 and trunk/0.23.  Thanks, Varun!, Integrated in Hadoop-Hdfs-0.23-Commit #530 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Commit/530/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243206)

     Result = SUCCESS
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243206
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Common-0.23-Commit #542 (See [https://builds.apache.org/job/Hadoop-Common-0.23-Commit/542/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243206)

     Result = SUCCESS
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243206
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Common-trunk-Commit #1718 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/1718/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243207)

     Result = SUCCESS
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243207
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Hdfs-trunk-Commit #1792 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/1792/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243207)

     Result = SUCCESS
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243207
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Mapreduce-0.23-Commit #546 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Commit/546/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243206)

     Result = SUCCESS
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243206
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Mapreduce-trunk-Commit #1729 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1729/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243207)

     Result = SUCCESS
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243207
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Mapreduce-trunk #987 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/987/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243207)

     Result = FAILURE
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243207
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Mapreduce-0.23-Build #190 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/190/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243206)

     Result = FAILURE
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243206
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Hdfs-trunk #954 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/954/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243207)

     Result = FAILURE
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243207
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Integrated in Hadoop-Hdfs-0.23-Build #167 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/167/])
    HADOOP-8052. Hadoop Metrics2 should emit Float.MAX_VALUE (instead of Double.MAX_VALUE) to avoid making Ganglia's gmetad core. Contributed by Varun Kapoor. (Revision 1243206)

     Result = FAILURE
mattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1243206
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/util/SampleStat.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/util/TestSampleStat.java
, Merged this into 0.23.1.]