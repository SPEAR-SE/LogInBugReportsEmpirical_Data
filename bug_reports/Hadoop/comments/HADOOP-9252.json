[Also humanReadableInt(..) uses oneDecimal without synchronization.  I think it is a bug., c9252_20130127.patch: use String.format(..) and TraditionalBinaryPrefix., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566699/c9252_20130127.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2054 javac compiler warnings (more than the trunk's current 2014 warnings).

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 1 warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2097//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2097//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2097//console

This message is automatically generated., All new javac warnings are deprecated warnings.

c9252_20130128.patch: fixes the javadoc warning., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566806/c9252_20130128.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2054 javac compiler warnings (more than the trunk's current 2014 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2106//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2106//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2106//console

This message is automatically generated., Hi Nicholas,

I'm assuming that for backwards-compatibility, {{StringUtils#limitDecimalTo2}} still needs to keep returning the same output after this patch.  (If that's not the case, please let me know.)

{code}
-  public static synchronized String limitDecimalTo2(double d) {
-    return decimalFormat.format(d);
+  /**
+   * @deprecated use {@link String#format(String, Object...)},
+   *             i.e. String.format("%.2f", d).
+   */
+  @Deprecated
+  public static String limitDecimalTo2(double d) {
+    return String.format("%.2f", d);
   }
{code}

The former DecimalFormat "#.##" is not quite equivalent to the new printf format "%.2f".  The former will truncate the output to an integer if there are only non-significant digits (zeroes) remaining on the right side of the decimal point after rounding.  The latter always maintains a precision of 2 digits to the right of the decimal point, even if those digits are zeroes.  This is easiest to see using example inputs like 123 (integral input) or 100.001 (float input, but only zeroes remaining to the right of the decimal point after rounding).

Here is a Scala REPL session showing that the 2 forms produce equivalent output for many cases, but then behave differently for 123 and 100.001.

{code}
scala> def printDouble(x: Double) {
  val decimalFormat = NumberFormat.getInstance(Locale.ENGLISH).asInstanceOf[DecimalFormat]
  decimalFormat.applyPattern("#.##")
  println("DecimalFormat: " + decimalFormat.format(x.asInstanceOf[java.lang.Double]))
  println("%.2f:          " + String.format("%.2f", x.asInstanceOf[java.lang.Double]))
}
def printDouble(x: Double) {
Of[DecimalFormat]
     |   decimalFormat.applyPattern("#.##")
ng.Double]))
ang.Double]))
     | }
printDouble: (x: Double)Unit

scala> List(123.456, 0.123, 10.01, 123, 100.001) foreach printDouble
List(123.456, 0.123, 10.01, 123, 100.001) foreach printDouble
DecimalFormat: 123.46
%.2f:          123.46
DecimalFormat: 0.12
%.2f:          0.12
DecimalFormat: 10.01
%.2f:          10.01
DecimalFormat: 123
%.2f:          123.00
DecimalFormat: 100
%.2f:          100.00
{code}

Unfortunately, I don't know how to accomplish the same kind of truncation using printf format codes alone.  Maybe we'd have to write our own truncation logic after the call to {{String#format}}?

There are also differences in handling some edge case values:

{code}
scala> List(Double.MaxValue, Double.MinValue, Double.NaN, Double.NegativeInfinity, Double.PositiveInfinity) foreach printDouble
y, Double.PositiveInfinity) foreach printDouble
DecimalFormat: 179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
%.2f:          179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.00
DecimalFormat: -179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
%.2f:          -179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.00
DecimalFormat: ?
%.2f:          NaN
DecimalFormat: -°
%.2f:          -Infinity
DecimalFormat: °
%.2f:          Infinity
{code}

Also, the {{NumberFormat}} version of the code had explicitly set locale to {{Locale.ENGLISH}}.  This form of {{String#format}} will use the JVM default locale, so this might cause surprises if anyone has deployed on a JVM where the default locale is not English.  I suggest using the overload of {{String#format}} that accepts {{Locale}} and passing in {{Locale.ENGLISH}}.

Thanks!
, Chris, thanks for the detail comparison.

> I'm assuming that for backwards-compatibility, StringUtils#limitDecimalTo2 still needs to keep returning the same output after this patch. (If that's not the case, please let me know.)

StringUtils#limitDecimalTo2 is @InterfaceAudience.Private and @InterfaceStability.Unstable so that this is no compatibility issue.

The change probably will cause some HDFS/MapReduce tests to fail.  I intent to fix those failing tests (if there is any) in separated JIRAs.

For 123 and 100.001, the output should be "123" and "100.00" since "123" is the exact value and "100.00" indicates that there is a round off. The two trailing zeros at the end are also significant figures., Thanks, Nicholas.  I should have looked for the interface annotations.

One of the test failures that I spotted was {{TestContainersMonitor}} in hadoop-yarn-server-nodemanager.  The test failed because of 2 changes in behavior in {{StringUtils#humanReadableInt}} with this patch:

# There is now a space between the number and the units.
# The unit is upper-case instead of lower-case.

For example, before the patch we would get results like "2.0m", and now we get "2.0 M".  I made the test pass by removing the append of the extra space and wrapping the unit with {{Character#toLowerCase}}.  The relevant lines in {{long2String}} with these changes are:

{code}
        return (unit.isEmpty()? b: b.append(unit)).toString();
...
        return b.append(Character.toLowerCase(prefix.symbol)).append(unit).toString();
{code}

I did not do a complete test run though, so I don't know yet if my change introduced other problems.

Would you want to incorporate something like this into the patch, or do you prefer to keep the new output and update any tests that depend on the old output?

BTW, I ran a quick non-exhaustive grep of other Hadoop projects and found that HBase has calls to {{humanReadableInt}} and {{limitDecimalTo2}}.  I don't know yet if there are any test impacts there.
, Chris, thanks for checking the tests.  Before the patch, the methods humanReadableInt and limitDecimalTo2 are very similar but they have minor difference such as one uses upper case 'M' and the other uses lower cases 'm'.  Let's decide the best format here and then change the individual tests accordingly (and in separated JIRAs.)

In the patch, I choose uppercase letter for the prefix K, M, G, T, P, E since it seems a standard according to http://en.wikipedia.org/wiki/Binary_prefix .  Then, I put a space between the number and the prefix; otherwise, values like "2.091MB" seem not very readable.  I don't really have a strong preference about the space.  What do you think?, Thanks, Nicholas.  It sounds like a good plan.  I agree with you that the new format is more easily readable.  I think we can find the broken tests, change them to accept either the old format or the new format, and then commit these changes.  For example, the failure I found in {{TestContainersMonitor}} is due to a regex match on the old format.  We can update that regex to match either the old format or the new format.  That way, other sub-projects shouldn't see an impact from this change.

Can we add more tests to {{TestStringUtils}} around boundary conditions, such as the minimum and maximum values of a long?  Here is what I am seeing for some boundary cases before and after the changes.

Before:
{code}
scala> println(StringUtils.humanReadableInt(Long.MaxValue))
8589934592.0g

scala> println(StringUtils.humanReadableInt(Long.MaxValue - 1))
8589934592.0g

scala> println(StringUtils.humanReadableInt(Long.MinValue))
-9223372036854775808

scala> println(StringUtils.humanReadableInt(Long.MinValue + 1))
-8589934592.0g
{code}

After:
{code}
scala> println(StringUtils.humanReadableInt(Long.MaxValue))
8.0 E

scala> println(StringUtils.humanReadableInt(Long.MaxValue - 1))
8.0 E

scala> println(StringUtils.humanReadableInt(Long.MinValue))
--9223372036854775808

scala> println(StringUtils.humanReadableInt(Long.MinValue + 1))
-8.0 E
{code}

Notice that there is an odd behavior on {{Long#MIN_VALUE}}: 2 negative signs.  That's because of this part of the code:

{code}
+      if (n < 0) {
+        b.append('-');
+        n = -n;
+      }
{code}

{{Long#MIN_VALUE}} is a really irritating case, because the data type cannot represent the positive conversion.  It would be 1 greater than {{Long#MAX_VALUE}}, so negating it or taking its absolute value overflows back to the same value:

{code}
scala> println(Long.MinValue)
-9223372036854775808

scala> println(-Long.MinValue)
-9223372036854775808

scala> println(-(-Long.MinValue))
-9223372036854775808

scala> println(Math.abs(Long.MinValue))
-9223372036854775808
{code}

Maybe we need to special-case this to prevent 2 negative signs.  It looks like the old version of the code wasn't able to get the units right either.
, Good catch!  We have to take care the Long.MIN_VALUE special case.  I found another special cases such as 2^20 - 1 will be converted to "1024.00 K" instead of "1.00 M" due to rounding up.

c9252_20130203.patch: fixes the special cases and adds more tests., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12567793/c9252_20130203.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2053 javac compiler warnings (more than the trunk's current 2013 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2139//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2139//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2139//console

This message is automatically generated., The changes look great.  I applied the patch and ran the new tests and saw them pass.  I think there is one more change we need to make: force locale to English on the {{String#format}} calls.  The old code always used English for the locale:

{code}
-  private static final DecimalFormat decimalFormat;
-  static {
-          NumberFormat numberFormat = NumberFormat.getNumberInstance(Locale.ENGLISH);
-          decimalFormat = (DecimalFormat) numberFormat;
-          decimalFormat.applyPattern("#.##");
-  }
-
{code}

The current version of the patch uses the platform default locale.  Here is an example that demonstrates what happens when running on a JVM where the default locale has been set to French, which uses comma instead of period for the decimal separator.

{code}
scala> Locale.setDefault(Locale.ENGLISH)

scala> println(StringUtils.formatPercent(0.1234, 2))
12.34%

scala> println(StringUtils.humanReadableInt(123456))
warning: there were 1 deprecation warnings; re-run with -deprecation for details
120.6 K

scala> println(StringUtils.limitDecimalTo2(876.5432))
warning: there were 1 deprecation warnings; re-run with -deprecation for details
876.54

scala> println(StringUtils.TraditionalBinaryPrefix.long2String(3L << 9, null, 2))
1.50 K

scala> Locale.setDefault(Locale.FRENCH)

scala> println(StringUtils.formatPercent(0.1234, 2))
12,34%

scala> println(StringUtils.humanReadableInt(123456))
warning: there were 1 deprecation warnings; re-run with -deprecation for details
120,6 K

scala> println(StringUtils.limitDecimalTo2(876.5432))
warning: there were 1 deprecation warnings; re-run with -deprecation for details
876,54

scala> println(StringUtils.TraditionalBinaryPrefix.long2String(3L << 9, null, 2))
1,50 K
{code}

I'm guessing that we want to stick with English, because the surrounding pieces that use these methods, like the NameNode UI, aren't currently localizable and are basically hard-coded to US-style English.  Also, the tests could fail for developers using a system with a different default locale.  The {{String#format}} calls would change from this:

{code}
+    return String.format("%." + decimalPlaces + "f%%", fraction*100);

+          b.append(String.format("%." + decimalPlaces + "f", d));

+    return String.format("%.2f", d);
{code}

to this:

{code}
+    return String.format(Locale.ENGLISH, "%." + decimalPlaces + "f%%", fraction*100);

+          b.append(String.format(Locale.ENGLISH, "%." + decimalPlaces + "f", d));

+    return String.format(Locale.ENGLISH, "%.2f", d);
{code}

Thanks!
, Oops, I forgot add Locale.ENGLISH in my previous patch.

c9252_20130204.patch:
- adds StringUtils.format(..) which uses Locale.ENGLISH;
- adds bitShift and bitMash so that integer division / and remaindering % can be avoided., +1 for this version of the patch

Thanks so much for incorporating all of my feedback!
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12567878/c9252_20130204.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 2053 javac compiler warnings (more than the trunk's current 2013 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2141//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2141//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2141//console

This message is automatically generated., Regarding the -1 from Jenkins on javac warnings, I reviewed the list.  They are all deprecation warnings caused by marking some of these methods deprecated, so this is expected., Chris, thanks a lot for the careful review!

(Changed the issue type to Bug, and revised the summary and the description.), I have committed this.

See Linked Issues for the followup issues., Integrated in Hadoop-trunk-Commit #3319 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3319/])
    HADOOP-9252. In StringUtils, humanReadableInt(..) has a race condition and the synchronization of limitDecimalTo2(double) can be avoided. (Revision 1442386)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442386
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/FsUsage.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Ls.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/StringUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestStringUtils.java
, Integrated in Hadoop-Yarn-trunk #118 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/118/])
    HADOOP-9252. In StringUtils, humanReadableInt(..) has a race condition and the synchronization of limitDecimalTo2(double) can be avoided. (Revision 1442386)

     Result = FAILURE
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442386
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/FsUsage.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Ls.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/StringUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestStringUtils.java
, Integrated in Hadoop-Hdfs-trunk #1307 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1307/])
    HADOOP-9252. In StringUtils, humanReadableInt(..) has a race condition and the synchronization of limitDecimalTo2(double) can be avoided. (Revision 1442386)

     Result = FAILURE
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442386
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/FsUsage.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Ls.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/StringUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestStringUtils.java
, Integrated in Hadoop-Mapreduce-trunk #1335 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1335/])
    HADOOP-9252. In StringUtils, humanReadableInt(..) has a race condition and the synchronization of limitDecimalTo2(double) can be avoided. (Revision 1442386)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442386
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/FsUsage.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Ls.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/StringUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestStringUtils.java
, Integrated in Hadoop-trunk-Commit #3326 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3326/])
    HDFS-4468.  Use the new StringUtils methods added by HADOOP-9252 and fix TestHDFSCLI and TestQuota. (Revision 1442824)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442824
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ClusterJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/testHDFSConf.xml
, Integrated in Hadoop-Yarn-trunk #119 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/119/])
    HDFS-4468.  Use the new StringUtils methods added by HADOOP-9252 and fix TestHDFSCLI and TestQuota. (Revision 1442824)

     Result = FAILURE
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442824
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ClusterJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/testHDFSConf.xml
, Integrated in Hadoop-Hdfs-trunk #1308 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1308/])
    HDFS-4468.  Use the new StringUtils methods added by HADOOP-9252 and fix TestHDFSCLI and TestQuota. (Revision 1442824)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442824
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ClusterJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/testHDFSConf.xml
, Integrated in Hadoop-Mapreduce-trunk #1336 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1336/])
    HDFS-4468.  Use the new StringUtils methods added by HADOOP-9252 and fix TestHDFSCLI and TestQuota. (Revision 1442824)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1442824
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ClusterJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/testHDFSConf.xml
, Integrated in Hadoop-trunk-Commit #3343 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3343/])
    YARN-377. Use the new StringUtils methods added by HADOOP-9252 and fix TestContainersMonitor.  Contributed by Chris Nauroth (Revision 1443796)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443796
Files : 
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/ContainersMonitorImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/TestContainersMonitor.java
, Integrated in Hadoop-Yarn-trunk #121 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/121/])
    YARN-377. Use the new StringUtils methods added by HADOOP-9252 and fix TestContainersMonitor.  Contributed by Chris Nauroth (Revision 1443796)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443796
Files : 
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/ContainersMonitorImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/TestContainersMonitor.java
, Integrated in Hadoop-Hdfs-trunk #1310 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1310/])
    YARN-377. Use the new StringUtils methods added by HADOOP-9252 and fix TestContainersMonitor.  Contributed by Chris Nauroth (Revision 1443796)

     Result = FAILURE
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443796
Files : 
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/ContainersMonitorImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/TestContainersMonitor.java
, Integrated in Hadoop-Mapreduce-trunk #1338 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1338/])
    YARN-377. Use the new StringUtils methods added by HADOOP-9252 and fix TestContainersMonitor.  Contributed by Chris Nauroth (Revision 1443796)

     Result = FAILURE
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443796
Files : 
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/ContainersMonitorImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/TestContainersMonitor.java
]