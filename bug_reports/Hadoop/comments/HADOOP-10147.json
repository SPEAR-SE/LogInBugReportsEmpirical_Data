[For those interested in the details, here are the stack traces exhibiting the deadlock.  

Upon further reflection, this is actually caused by starting two DataNode instances _in parallel_, which {{MiniDFSCluster}} itself does _not_ do.  However, we are using an alternative JUnit test fixture that does initialize DataNode instances in parallel.  Regardless, it would be beneficial to upgrade commons-logging to avoid this potential deadlock scenario.

{noformat}
"thread-1":
	at org.apache.commons.logging.impl.WeakHashtable.purge(WeakHashtable.java:321)
	- waiting to lock <0x00000002213134f0> (a java.lang.ref.ReferenceQueue)
	at org.apache.commons.logging.impl.WeakHashtable.rehash(WeakHashtable.java:312)
	at java.util.Hashtable.put(Hashtable.java:429)
	- locked <0x00000002213356c8> (a org.apache.commons.logging.impl.WeakHashtable)
	at org.apache.commons.logging.impl.WeakHashtable.put(WeakHashtable.java:242)
	at org.apache.commons.logging.LogFactory.cacheFactory(LogFactory.java:1004)
	at org.apache.commons.logging.LogFactory.getFactory(LogFactory.java:657)
	at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:685)
	at org.apache.jasper.servlet.JspServlet.<init>(JspServlet.java:59)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at java.lang.Class.newInstance0(Class.java:372)
	at java.lang.Class.newInstance(Class.java:325)
	at org.mortbay.jetty.servlet.Holder.newInstance(Holder.java:153)
	- locked <0x0000000249f446d8> (a org.mortbay.jetty.servlet.ServletHolder)
	at org.mortbay.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:428)
	at org.mortbay.jetty.servlet.ServletHolder.doStart(ServletHolder.java:263)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249f44750> (a java.lang.Object)
	at org.mortbay.jetty.servlet.ServletHandler.initialize(ServletHandler.java:736)
	at org.mortbay.jetty.servlet.Context.startContext(Context.java:140)
	at org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1282)
	at org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:518)
	at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:499)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249ee34b0> (a java.lang.Object)
	at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
	at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249ede4d8> (a java.lang.Object)
	at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
	at org.mortbay.jetty.Server.doStart(Server.java:224)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249ede0b8> (a java.lang.Object)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:824)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startInfoServer(DataNode.java:392)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:738)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:311)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1814)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1714)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1752)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1743)
{noformat}

{noformat}
"thread-2":
	at java.util.Hashtable.remove(Hashtable.java:452)
	- waiting to lock <0x00000002213356c8> (a org.apache.commons.logging.impl.WeakHashtable)
	at org.apache.commons.logging.impl.WeakHashtable.purgeOne(WeakHashtable.java:338)
	- locked <0x00000002213134f0> (a java.lang.ref.ReferenceQueue)
	at org.apache.commons.logging.impl.WeakHashtable.put(WeakHashtable.java:238)
	at org.apache.commons.logging.LogFactory.cacheFactory(LogFactory.java:1004)
	at org.apache.commons.logging.LogFactory.getFactory(LogFactory.java:657)
	at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:685)
	at org.apache.jasper.servlet.JspServlet.<init>(JspServlet.java:59)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
	at java.lang.Class.newInstance0(Class.java:372)
	at java.lang.Class.newInstance(Class.java:325)
	at org.mortbay.jetty.servlet.Holder.newInstance(Holder.java:153)
	- locked <0x0000000249f3e988> (a org.mortbay.jetty.servlet.ServletHolder)
	at org.mortbay.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:428)
	at org.mortbay.jetty.servlet.ServletHolder.doStart(ServletHolder.java:263)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249f3ea00> (a java.lang.Object)
	at org.mortbay.jetty.servlet.ServletHandler.initialize(ServletHandler.java:736)
	at org.mortbay.jetty.servlet.Context.startContext(Context.java:140)
	at org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1282)
	at org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:518)
	at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:499)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249ee0888> (a java.lang.Object)
	at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
	at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249ee03b8> (a java.lang.Object)
	at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
	at org.mortbay.jetty.Server.doStart(Server.java:224)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	- locked <0x0000000249edb990> (a java.lang.Object)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:824)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startInfoServer(DataNode.java:392)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:738)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:311)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1814)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1714)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1752)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1743)
{noformat}, I'd be happy with the upgrade under the big  HADOOP-9991 pom upgrade banner: if you do the update and run the full hadoop test suite *and whatever is breaking your code* I'll put the patch in to branch-2+, patch to update hadoop-project/pom.xml, link to HDFS-5678, which files this problem as an HDFS issue, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12619321/HADOOP-10147-001.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3369//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3369//console

This message is automatically generated., SUCCESS: Integrated in Hadoop-trunk-Commit #4946 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4946/])
HADOOP-10147 HDFS-5678 Upgrade to commons-logging 1.1.3 to avoid potential deadlock in MiniDFSCluster (stevel: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1554803)
* /hadoop/common/trunk
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml
, FAILURE: Integrated in Hadoop-Yarn-trunk #441 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/441/])
HADOOP-10147 HDFS-5678 Upgrade to commons-logging 1.1.3 to avoid potential deadlock in MiniDFSCluster (stevel: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1554803)
* /hadoop/common/trunk
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1633 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1633/])
HADOOP-10147 HDFS-5678 Upgrade to commons-logging 1.1.3 to avoid potential deadlock in MiniDFSCluster (stevel: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1554803)
* /hadoop/common/trunk
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1658 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1658/])
HADOOP-10147 HDFS-5678 Upgrade to commons-logging 1.1.3 to avoid potential deadlock in MiniDFSCluster (stevel: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1554803)
* /hadoop/common/trunk
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml
]