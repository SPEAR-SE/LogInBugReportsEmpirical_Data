[There are multiple negative callIds to signal out of band operations, such as ping and sasl.  Is the intention to change the protobuf def to a signed int?, Making it sint32 makes sense. But this is going to be incompatible. BTW I am not sure how the pings are working currently?, Yes, I think we should change it to int32 asap rather than have it be wrong forever., Hi Daryn, it is probably late to change now, but what's the reason not to specify ping/connectionContext/sasl nagotiation/sasl encryption in OperationProto, why reuse callId instead?
, Straight-fwd patch to change to int32. No new tests required., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12603335/HADOOP-9944.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3100//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3100//console

This message is automatically generated., +1 for the change., Thanks for the review [~sureshms]. 

Here is another rev with another minor fix in ProtobufRpcEngine.proto where-in the sequence number for RequestHeaderProto fields is off-by-one., +1 for the new patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12603356/HADOOP-9944.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3101//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3101//console

This message is automatically generated., Hi Arun,
Currently change uint32 to int32 still keeps wire compatibility, cause uint32 and int32 uses the same encoding. But change field id will break compatibility.  If we do permit breaking compatibility, sint32 is better cause it uses ZigZag encoding which uses much less spaces for small negative intergers.
See https://developers.google.com/protocol-buffers/docs/encoding , bq. If we do permit breaking compatibility, sint32 is better cause it uses ZigZag encoding which uses much less spaces for small negative intergers.
CallID will not be negative value. No?
, Updated to use sint32 on [~decster]'s suggestion., Forget my above comments, +1 on change from int32 to sint32., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12603509/HADOOP-9944.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3103//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3103//console

This message is automatically generated., Thanks for all the reviews, I just committed this to allow me to roll hadoop-2.1.1-beta., SUCCESS: Integrated in Hadoop-trunk-Commit #4428 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4428/])
HADOOP-9944. Fix RpcRequestHeaderProto.callId to be sint32 rather than uint32 since ipc.Client.CONNECTION_CONTEXT_CALL_ID is signed (i.e. -3). Contributed by Arun C. Murthy. (acmurthy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523885)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/ProtobufRpcEngine.proto
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/RpcHeader.proto
, SUCCESS: Integrated in Hadoop-Yarn-trunk #335 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/335/])
HADOOP-9944. Fix RpcRequestHeaderProto.callId to be sint32 rather than uint32 since ipc.Client.CONNECTION_CONTEXT_CALL_ID is signed (i.e. -3). Contributed by Arun C. Murthy. (acmurthy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523885)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/ProtobufRpcEngine.proto
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/RpcHeader.proto
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1525 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1525/])
HADOOP-9944. Fix RpcRequestHeaderProto.callId to be sint32 rather than uint32 since ipc.Client.CONNECTION_CONTEXT_CALL_ID is signed (i.e. -3). Contributed by Arun C. Murthy. (acmurthy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523885)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/ProtobufRpcEngine.proto
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/RpcHeader.proto
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1551 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1551/])
HADOOP-9944. Fix RpcRequestHeaderProto.callId to be sint32 rather than uint32 since ipc.Client.CONNECTION_CONTEXT_CALL_ID is signed (i.e. -3). Contributed by Arun C. Murthy. (acmurthy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523885)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/ProtobufRpcEngine.proto
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/proto/RpcHeader.proto
, This patch made 2.1.1 wire-incompatible with 2.1.0. I thought were were supposed to stop making incompatible wire changes now that we're in beta? I guess it's too late to argue now that it's been released, but we should be clear on this policy, and we should also get some practice making sure our protobuf evolution is compatible now that we're in beta., !http://i.imgur.com/2ClmQri.gif!

Where to start... I don't even ...

Was there NO WAY you could have worked around this in your Java code?  Really?
Especially after having cut already 2 major releases with this code?

When will Hadoop finally grow up and provide guarantees both in terms of API compatibility and wire-level compatibility?

If you got the API wrong, well, too bad.  Live with it.  Don't fucking break it.

(ノಠ益ಠ)ノ彡┻━┻, Hey Guys,

I discovered the callid for a request and its response do not always match while writing a protocol analyzer to analyze application data. A simple test case can demonstrate this problem:

An unauthorized access to a file which causes a client to send setOwner request rpc to a Namenode server which in turn sends back the client a response includes org.apache.hadoop.security.AccessControlException. And the callid of the request and response doesn't match.

Could someone please take a look at this?

Thanks.
Charlene Sun
]