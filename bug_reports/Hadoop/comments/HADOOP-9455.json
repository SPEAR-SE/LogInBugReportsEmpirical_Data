[HADOOP_CLIENT_OPTS is added by hadoop-env.sh and then by hadoop/hdfs/mapred again., Hi, Sangjin.  I've been reviewing this and HIVE-3936.  I haven't been able to repro this problem running just the hadoop script, but I do see how an interaction between the hive script and the hadoop script could cause this problem if running hive with both the --debug option and a HADOOP_CLIENT_OPTS environment variable containing the JDWP options:

# hive with --debug option calls get_debug_params in ext/debug.sh.
# get_debug_params exports HIVE_MAIN_CLIENT_DEBUG_OPTS with value set to JDWP options.
# hive appends HIVE_MAIN_CLIENT_DEBUG_OPTS to HADOOP_CLIENT_OPTS.  If your HADOOP_CLIENT_OPTS already contained the JDWP options, then they would be duplicated after this step executes.
# hive service scripts like ext/hiveserver.sh and ext/jar.sh run hadoop.
# hadoop launches JVM, and we get the failure you described.

This problem would be triggered only by running hive with both --debug and HADOOP_CLIENT_OPTS containing the JDWP options.  Can you check to see if this is how you were running it?  , [~cnauroth], I am able to reproduce it without hive (in fact I don't have hive installed on the machine where I saw this). I can download the 2.0.3-alpha build into a new directory, and reproduce this.

{noformat}
which hadoop (ensure hadoop is not present and not in the path)
tar -zxvf hadoop-2.0.3-alpha.tar.gz
HADOOP_CLIENT_OPTS='-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y' hadoop-2.0.3-alpha/bin/hadoop jar anything
{noformat}

Could you try the above and see if you see a different behavior?

From what I can see, the hadoop script calls hadoop-config.sh which in turn calls hadoop-env.sh. Both the hadoop script and the hadoop-env.sh script append the value of HADOOP_CLIENT_OPTS to HADOOP_OPTS., Sangjin, thank you for the extra details.  I can repro now.  I tend to override my hadoop-env.sh locally, so I didn't notice it at first.

I think we can remove the append of HADOOP_CLIENT_OPS from hadoop-env.sh, considering that the main entry points all take care of appending it.  The hadoop script appends HADOOP_CLIENT_OPTS, the hdfs script appends HADOOP_CLIENT_OPTS, and the yarn script appends YARN_CLIENT_OPTS.  I'm uploading a patch.

[~eli], you added this version of hadoop-env.sh in HADOOP-8287.  Can I please get your opinion on whether or not this patch is a safe change?  Thanks!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12577835/HADOOP-9455.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2432//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2432//console

This message is automatically generated., Jenkins reported no new tests, because the patch changes a shell script only., Wouldn't it be better to only append HADOOP_CLIENT_OPTS once in hadoop-env.sh rather than in each per-project bin script?  Each can have a per-project variable like Yarn if needed.

It looks like hadoop-config.sh handles the case where hadoop-env.sh doesn't exist which is perhaps why all the bin scripts set it, but I don't think we need to worry about hadoop-env.sh not existing post HADOOP-8287., Eli, thank you for taking a look.

{quote}
Wouldn't it be better to only append HADOOP_CLIENT_OPTS once in hadoop-env.sh rather than in each per-project bin script?
{quote}

This would cause a subtle change in behavior.  Right now, the hdfs script only appends HADOOP_CLIENT_OPTS for a subset of the interactive commands: dfs, dfsadmin, haadmin, and fsck.  This is not done for the daemon commands: namenode, datanode, secondarynamenode, etc.  It appears that the intent is that when you want to override options to a daemon, you use the daemon-specific environment variable instead: HADOOP_NAMENODE_OPTS, HADOOP_DATANODE_OPTS, HADOOP_SECONDARYNAMENODE_OPTS, etc.  It could be erroneous to combine options set in HADOOP_CLIENT_OPTS with options set for a daemon.  For example, I could imagine an operator wanting to maintain a single hadoop-env.sh that sets both HADOOP_NAMENODE_OPTS and HADOOP_CLIENT_OPTS, but set different values for max heap size within each one.
, Makes sense, thanks Chris., Attaching an updated patch to do the same thing in the Windows cmd script.  I tested this on Windows., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12578954/HADOOP-9455.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2451//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2451//console

This message is automatically generated., {quote}
-1 tests included. The patch doesn't appear to include any new or modified tests.
Please justify why no new tests are needed for this patch.
Also please list what manual steps were performed to verify this patch.
{quote}

No tests, because this is a change in scripting only.  I built distribution tarballs on both Mac and Windows and tested using HADOOP_CLIENT_OPTS to specify the remote debugging options that Sangjin used in the bug report., +1

Thanks Chris., +1. Thanks!, Attaching a separate patch for branch-2, because branch-2 doesn't have the Windows cmd scripts., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12581221/HADOOP-9455-branch-2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2497//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2497//console

This message is automatically generated., bq. Attaching a separate patch for branch-2, because branch-2 doesn't have the Windows cmd scripts.
I would rather see this done in two jiras - one for windows that is only in trunk and second one for shell scripts that is applicable to both branch-2 and trunk. That way when a jira change is merged, it does not have different content for trunk and branch-2., Suresh, I'm attaching HADOOP-9455.3.patch, which contains just the sh script change.  This patch applies cleanly to trunk and branch-2.

For Windows, I've filed HADOOP-9532 and attached a separate patch there., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12581365/HADOOP-9455.3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2504//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2504//console

This message is automatically generated., {quote}
-1 tests included. The patch doesn't appear to include any new or modified tests.
Please justify why no new tests are needed for this patch.
Also please list what manual steps were performed to verify this patch.
{quote}

This is a script change only.  I manually tested by building the distro and verifying that I could run client commands with the remote debugging options specified in HADOOP_CLIENT_OPTS., I have committed the patch to trunk and branch-2. Thank you Chris., Integrated in Hadoop-trunk-Commit #3706 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3706/])
    HADOOP-9455. HADOOP_CLIENT_OPTS appended twice causes JVM failures. Contributed by Chris Nauroth. (Revision 1478067)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1478067
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/conf/hadoop-env.sh
, Integrated in Hadoop-Yarn-trunk #201 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/201/])
    HADOOP-9455. HADOOP_CLIENT_OPTS appended twice causes JVM failures. Contributed by Chris Nauroth. (Revision 1478067)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1478067
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/conf/hadoop-env.sh
, Integrated in Hadoop-Hdfs-trunk #1390 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1390/])
    HADOOP-9455. HADOOP_CLIENT_OPTS appended twice causes JVM failures. Contributed by Chris Nauroth. (Revision 1478067)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1478067
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/conf/hadoop-env.sh
, Integrated in Hadoop-Mapreduce-trunk #1417 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1417/])
    HADOOP-9455. HADOOP_CLIENT_OPTS appended twice causes JVM failures. Contributed by Chris Nauroth. (Revision 1478067)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1478067
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/conf/hadoop-env.sh
]