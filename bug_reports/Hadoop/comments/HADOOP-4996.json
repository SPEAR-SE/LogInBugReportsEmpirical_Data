[looking at JobControl code :
{code}
      running = jc.getJob(this.mapredJobID);
      if (running.isComplete()) {
        if (running.isSuccessful()) {
          this.state = Job.SUCCESS;
        } else {
          this.state = Job.FAILED;
          this.message = "Job failed!";
          try {
            running.killJob();
          } catch (IOException e1) {

          }
          try {
            this.jc.close();
          } catch (IOException e2) {

          }
        }
      }
{code}
This says that Killed jobs are informed to jobControl properly, though they are present in failedJobs list.

Olga, what is the problem you are seeing there? Can you please elaborate? or attach a testcase where this can be reproduced?, I wrote two tests for jobcontrol, one with failed dependent job and another with killed dependent job. Both the tests passed. , Amareshwari, if I remember right - the problem is that there is no way to query JobControl for KILLED jobs.

HADOOP-3924 didn't fix o.a.h.m.jobcontrol.* to account for the newly introduced KILLED state., With the current code, if a job is FAILED/KILLED the JobControl shows the status as FAILED.  If a dependent is FAILED/KILLED, the JobControl shows the status as DEPENDENT_FAILED. And all these jobs are available in failedJobs list, which can be queried through getFailedJobs() api. 

Is it that JobControl should also have new state KILLED and DEPENDENT_KILLED and a new api getKilledJobs() for these jobs?
then, is it blocker?, Pig uses getFailedJobs API to retrieve any job that did not succeed. As long as this API returns both killed and failed jobs, our code would work fine., Existing code/api is sufficient for the requirement.]