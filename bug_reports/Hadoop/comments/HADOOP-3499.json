[Hi,

I found where the problem is:
I gave the hostname of decommission nodes in the excludesFile, but
those hostnames were not the full name(no xx.com suffix). the namenode
would look about if a datanode's name(ip:port) or host(ip) or hostname
contained by the excludelist. And the hostname is the full name, not
equal to the name in the excludelist, so nodes weren't considered in
the excludelist. Decommission had never successed actually!  the nodes
in excludesFile were seemed as other new nodes.

I guess if converting hostname of exclude node to ip for compare will
be better. Because one ip can have lots hostname. anyhow, no change is
also ok. if so the bug could be end?

thanks

, lixiangna, thanks for confirming this. We could update the twiki or docs about this and then close the bug. , I have added a line to the FAQ about this: http://wiki.apache.org/hadoop/FAQ#17 No other Wiki pages seem to address decommissioning. , HADOOP-3720 added info to help message and dfs user guide. Thanks Erik for updating the twiki. I will close this bug as invalid (although we updated twiki) as there were no code changes. ]