[We've thus far avoided loading job-specific code in the JobTracker and TaskTracker, in order to keep these more reliable.  File splitting is performed by the job tracker.  So if you're overriding InputFormat.getSplits(), then fixing this is harder.  But if you're simply overriding getRecordReader(), then this should be easier to fix.  In that case one could fix this by moving getSplits() to a new interface that's used only by the TaskTracker.  If this is important to you, please submit a patch to this effect., Wouldn't it be appropriate to make input splitting into a task, so that getSplits could be run by the TaskTrackerChild? That way the current interfaces would remain and the user could override it from the job.jar. 

An example where we would find it useful is where the map input is coming from external servers over sockets. getSplits could return splits of the form FileSplit("host:port", 0 ,1000) and the RecordReader needs to know how to translate that name into a data stream., I think the reason to keep getSplits() in the jobtracker, is because the result of getSplits() determines the actual number of map tasks that's run, and the job tracker does more setup and tracking *after* getSplits(). How would you separate that out?, I would schedule the getSplits task and when it completed, I would schedule the map jobs. It would be pretty parallel to the way the completion of the map tasks causes the reduces to be scheduled. I think the right place to hook it would be in JobTracker.JobInProgress.completedTask(String). One difference that I'm aware of, is that until getSplits returns, you don't have any idea how many maps will be needed, so you can't create the map tasks when the job is created., I fixed this by having the JobTracker load the InputFormat from the job's jar.]