[-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12483406/HADOOP-7414.patch
  against trunk revision 1137724.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/664//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/664//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/664//console

This message is automatically generated., Hey Ben, does Jetty mind if there are multiple slashes at the end of the path? That's the only potential problem I can imagine with this patch.

Also, is there a way to write a unit test for this?, the only way there would be multiple slashes is if the name was "" or had a slash at the end of it. i don't think we hit either case.

note that there is a corresponding bug report in jetty: http://jira.codehaus.org/browse/JETTY-1307

the test case would need to run hadoop with the webapps in a jar file. i don't know of any easy way to do that., I had a look through the Jetty source on this, then into jar: URLs, and ended up more confused than ever, so exchanged emails with Greg Wilkins, because it seemed to me that WAR files were overkill compared to creating and configuring a servlet context. His reply

"I tend to agree that Hadoop should not be using WebAppContext, as that
drags in all the war mechanisms of special classloaders, security,
sessions etc. that I suspect that hadoop does not need.   It would be
more light weight to program at the ContextHandler level and add only
the handlers that you need (probably just ServletHandler).   If you
are interested, I can point you at the jetty embedded examples.

For this specific issue, adding a / to the end of the path does
suggest to jetty that it is a directory rather than a WAR file.   If
it is a WAR file, then you don't need the /.  The extraction into temp
files is controlled by the setExtractWar method on WebAppContext and
not the trailing /"

What is trying to be achieved here? To deploy some servlets in the Hadoop JVM? off the normal classpath? If so, I don't think WebApp contexts are the right way. Jetty's context handling may seem a bit trickier to write, but I use them in-JVM regularly and don't have many problems (many - the main one was SLF4J, but I fixed that), bq. What is trying to be achieved here?

The problem is not about war. It's about picking up the compiled jsp classes from the webapps directory inside a jar. Without this patch the directory must be a fs directory and not a resource inside a jar, which Ben wants. This is useful to create a single jar installation of hadoop for easy deployment (in Ben's case, show-off :))

As for the patch, I think it'll be prudent to check if the name endsWith("/"), as there might exist code trying to compensate the same problem and that testing whether "//" works with jetty's different versions seems a lot more work., this patch only adds a / on the end if it is needed., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12484485/HADOOP-7414_2.patch
  against trunk revision 1140442.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/682//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/682//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/682//console

This message is automatically generated., Canceling the patch as it no longer applies to trunk.]