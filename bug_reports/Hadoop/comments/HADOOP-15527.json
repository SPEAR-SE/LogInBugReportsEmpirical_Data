[Here is the info from some debug logs I added to hadoop/libexec/hadoop-functions.sh and after adding a while loop around the "ps" check.
{code}
=========== 2018-06-10 00:43:31,754 vinodkv inside scripts sending SIGTERM
=========== 2018-06-10 00:43:31,756 vinodkv inside scripts SIGTERM sent, sleeping
=========== 2018-06-10 00:43:36,759 vinodkv inside scripts 3989960 still alive! sending sig-kill
=========== 2018-06-10 00:43:36,797 vinodkv inside scripts sigkill sent
=========== 2018-06-10 00:43:36,827 vinodkv inside scripts.. unable to kill 3989960
=========== 2018-06-10 00:43:36,846 vinodkv inside scripts.. unable to kill 3989960
=========== 2018-06-10 00:43:36,866 vinodkv inside scripts.. unable to kill 3989960
=========== 2018-06-10 00:43:36,885 vinodkv inside scripts.. unable to kill 3989960
=========== 2018-06-10 00:43:36,904 vinodkv inside scripts.. unable to kill 3989960
=========== 2018-06-10 00:43:36,924 vinodkv inside scripts.. process 3989960 finally dead
{code}
{code}
=========== 2018-06-10 00:48:00,884 vinodkv inside scripts sending SIGTERM
=========== 2018-06-10 00:48:00,886 vinodkv inside scripts SIGTERM sent, sleeping
=========== 2018-06-10 00:48:05,890 vinodkv inside scripts 3992747 still alive! sending sig-kill
=========== 2018-06-10 00:48:05,898 vinodkv inside scripts sigkill sent
=========== 2018-06-10 00:48:05,921 vinodkv inside scripts.. unable to kill 3992747
=========== 2018-06-10 00:48:05,938 vinodkv inside scripts.. unable to kill 3992747
=========== 2018-06-10 00:48:05,953 vinodkv inside scripts.. unable to kill 3992747
=========== 2018-06-10 00:48:05,970 vinodkv inside scripts.. unable to kill 3992747
=========== 2018-06-10 00:48:05,987 vinodkv inside scripts.. unable to kill 3992747
=========== 2018-06-10 00:48:06,006 vinodkv inside scripts.. unable to kill 3992747
=========== 2018-06-10 00:48:06,024 vinodkv inside scripts.. unable to kill 3992747
=========== 2018-06-10 00:48:06,042 vinodkv inside scripts.. process 3992747 finally dead
{code}

It takes roughly 125-145 milliseconds for RM to come down once a "kill -9" is sent.

It is possible that it may be due to system load.

I don't have any other explanation as to why this is only happening now., In JDK 8, there is a new feature to control OS processes, notably destroyForcibly method.  However, this tooling is somewhat OS dependent.  It is best effort to terminate child processes.  This could leave dangling child processes around until the child processes are notified of parent process is shutting down.   When kill -9 is executed, ps -p output may still contain the list of child threads and this is mistaken for parent process is still alive.

Java 9 has another set of improvement around this area, which has a blog written for [process handling|https://javax0.wordpress.com/2017/07/19/process-handling-in-java-9/].  That might improve the child process handling.  For Hadoop shell script improvement, we probably want to make sure that child thread is not listed for ps -p or use -f /proc/[pid] to identify the liveness of the process, and implement a loop for the check to ensure the process is gone before script exit., Uploaded a patch that loops around for HADOOP_STOP_TIMEOUT after kill -9.

It also optimizes the wait before kill -9. Earlier, we would always unnecessarily wait for HADOOP_STOP_TIMEOUT after SIGTERM, even if the process disappeared in the mean while., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} patch {color} | {color:blue}  0m  3s{color} | {color:blue} The patch file was not named according to hadoop's naming conventions. Please see https://wiki.apache.org/hadoop/HowToContribute for instructions. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 58s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} shellcheck {color} | {color:red}  0m  4s{color} | {color:red} The patch generated 1 new + 20 unchanged - 0 fixed = 21 total (was 20) {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 11s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 19s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 15s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 24s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 56m 13s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15527 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12927431/HADOOP-15527.txt |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  |
| uname | Linux f8d160a6775c 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2b2f672 |
| maven | version: Apache Maven 3.3.9 |
| shellcheck | v0.4.6 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/14757/artifact/out/diff-patch-shellcheck.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14757/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/14757/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 334 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14757/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, In the batch file, hadoop_stop_daemon is renamed to hadoop_stop_daemon_changing_pid.  Is this change necessary?, bq. In the batch file, hadoop_stop_daemon is renamed to hadoop_stop_daemon_changing_pid. Is this change necessary?
It's not necessary, but earlier there was only one test and so it was okay to have a generic name. We now have two tests so modified to disambiguate what each test is doing., Updated new patch addressing the complaints from Jenkins., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} patch {color} | {color:blue}  0m  2s{color} | {color:blue} The patch file was not named according to hadoop's naming conventions. Please see https://wiki.apache.org/hadoop/HowToContribute for instructions. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 14s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} shellcheck {color} | {color:red}  0m  4s{color} | {color:red} The patch generated 1 new + 20 unchanged - 0 fixed = 21 total (was 20) {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 12s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 27s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 23s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 57m 10s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15527 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12927524/HADOOP-15527.1.txt |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  |
| uname | Linux b8cd6bdde67d 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a16623d |
| maven | version: Apache Maven 3.3.9 |
| shellcheck | v0.4.6 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/14764/artifact/out/diff-patch-shellcheck.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14764/testReport/ |
| Max. process+thread count | 334 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14764/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, {code}
timeout=$(printf "%.0f\n" ${timeout})
{code}

Can be simplified to:

{code}
timeout=$((0 + ${timeout}))
{code}

To avoid shellcheck warning.
, Addressing shellcheck issue., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 23m 13s{color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} patch {color} | {color:blue}  0m  2s{color} | {color:blue} The patch file was not named according to hadoop's naming conventions. Please see https://wiki.apache.org/hadoop/HowToContribute for instructions. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 28m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 58s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green}  0m  4s{color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} shelldocs {color} | {color:green}  0m 11s{color} | {color:green} There were no new shelldocs issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 17s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 17s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 80m 58s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15527 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12927538/HADOOP-15527.2.txt |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  |
| uname | Linux 8a88e0c60072 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 5670e89 |
| maven | version: Apache Maven 3.3.9 |
| shellcheck | v0.4.6 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14767/testReport/ |
| Max. process+thread count | 348 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14767/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, +1 looks good to me., FAILURE: Integrated in Jenkins build Hadoop-trunk-Commit #14416 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14416/])
HADOOP-15527.  Improve delay check for stopping processes.               (eyang: rev 108da85320d65e37fe835de65866b818e5420587)
* (edit) hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* (edit) hadoop-common-project/hadoop-common/src/test/scripts/hadoop_stop_daemon.bats
, Jenkins failure is due to protoc version mismatch, not caused by the commit.

Thank you [~vinodkv] for the patch., normal {{kill}} calls can hang if something blocks in shutdown, including HDFS. If you implement your entry point atop {{org.apache.hadoop.service.launcher}}, you'll see its interrupt handler, {{InterruptEscalator}} will (a) add a timeout to shutdown and call JVM exit if it takes too long, and (b) treat a second kill as a request to exit hard, not retry a clean shutdown. It should be picked up as the entry point., Hi [~eyang], process_with_sigterm_trap.sh is missing in the commit. Would you fix it?, FAILURE: Integrated in Jenkins build Hadoop-trunk-Commit #14447 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14447/])
HADOOP-15527.  Improve delay check for stopping processes.               (eyang: rev 2c87ec5affefeb1dc794c4eaae685a4e544f1841)
* (add) hadoop-common/src/test/scripts/process_with_sigterm_trap.sh
, [~ajisakaa] Thanks for catching the mistake.  Process_with_sigterm_trap.sh has been committed to trunk and branch-3.1., Thanks! Probably this additional commit will fixes bats test failure., FYI: this patch is a bit fragile due to some assumptions made about the environment., bq. FYI: this patch is a bit fragile due to some assumptions made about the environment.
[~aw], I did try to to minimize problems like that to my knowledge, but if you can point out the specific issues, I can fix them.., Hi [~eyang],

It turns out the fix is not in the correct place. Could you re-fix it into hadoop-common-project?
{noformat}

$ ls -R hadoop-common
src

hadoop-common/src:
test

hadoop-common/src/test:
scripts

hadoop-common/src/test/scripts:
process_with_sigterm_trap.sh{noformat}, [~xiaochen] Good catch, sorry about the wrong location.  This has been fixed in trunk and branch-3.1., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14450 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14450/])
HADOOP-15527.  Improve delay check for stopping processes.               (eyang: rev 2d87592fc6a56bfe77dd3c11953caea2b701c846)
* (delete) hadoop-common/src/test/scripts/process_with_sigterm_trap.sh
* (add) hadoop-common-project/hadoop-common/src/test/scripts/process_with_sigterm_trap.sh
]