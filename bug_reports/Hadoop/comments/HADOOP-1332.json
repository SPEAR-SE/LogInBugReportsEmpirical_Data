[Nigel, could you try this patch and see if things improve? 

Basically I've made both stdout & stderr run in separate threads (previously stdout was run in the main thread) and seems like that fixes a weird case in Windows where when the task dies the stdout stream doesn't get shut down cleanly and hence the TaskTracker couldn't clean out the task... which easily could lead to the issues you've run into.

Devaraj & I could run TestMiniMRLocalFS almost 100 times continuously with this patch without issues; whereas previously it would hang in the same scenario.
, Should we fix this for 0.13.0? Thoughts?, +1

http://issues.apache.org/jira/secure/attachment/12358416/HADOOP-1332_1_20070529.patch applied and successfully tested against trunk revision r541792.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/209/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/209/console, To support windows, this needs to go in., The threads should be interrupted after the waitfor is finished to make sure the threads don't linger in the task tracker., Interrupting threads and ensuring they are cleaned up... , +1

http://issues.apache.org/jira/secure/attachment/12358477/HADOOP-1332_2_20070530.patch applied and successfully tested against trunk revision r542595.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/212/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/212/console, -1, tests still fail on Windows

One or more of these tests still fail in three separate runs on Windows., This patch takes Arun's and tweaks it a bit to make the copy threads check for being interrupted., +1, submitting the patch..., +1

http://issues.apache.org/jira/secure/attachment/12358509/copy-thread.patch applied and successfully tested against trunk revision r542595.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/216/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/216/console, How does adding Thread.sleep(1sec) help? It seems like unnecessary wait. I don't see how stream.available() help with the problem.

, *Sigh* The problem is that read(byte[], int, int) doesn't get interrupted by Thread.interrupt. So you use the available to see if there are bytes available, and read them. So the thread is never blocked in the read. On a side note, available usually returns 0 or 1 depending on whether there is data available., 
But it is a blocking read and we are not reading just what is available. So it only makes the problem less severe but not fix it. Does read() or interrupt explicitly state that it does not get interrupted?
, 
May be the thread that interrupts could close the both the streams so that read or write returns.
, Raghu has a point, though the thread that interrupts will have to *assume* the read call will block forever which isnt' the case all the time... 

I can think of some contrived ways to get around it (the thread that interrupts could wait for a while to check the thread died, if not close the stream else just call join), I'm not sure that complexity is worth it at this point... what do others think?, 
Or we could just do a non blocking read and poll. I don't think that will look much more complex. Are we sure that read() can not be interrupted? That is a bit strange. Either way, we could just note this as a work around rather than a fix with out any changes.
, Sure, long term using a non-blocking read is the correct solution and this is a short-term fix for 0.13.0. 

Yes, read() can't be interrupted... *sigh*, +1

copy-thread.patch does seem to fix the timed out tests., I just committed this.  Thanks, Owen!, Integrated in Hadoop-Nightly #107 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/107/)]