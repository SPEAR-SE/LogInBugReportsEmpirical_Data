[
Attached patch prints a warning and throws the IOException received.

The new log entry looks like this:

2007-04-02 12:59:15,940 WARN org.apache.hadoop.dfs.DataNode: No space left on device while writing blk_8638782110649810591 (length: 67108864) to /export/crawlspace/rangadi/tmp/ramfs (Cur available space : 20554389)
2007-04-02 12:59:15,943 ERROR org.apache.hadoop.dfs.DataNode: DataXCeiver java.io.IOException: No space left on device
        at java.io.FileOutputStream.writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:260)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)
        at java.io.DataOutputStream.write(DataOutputStream.java:90)
        at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:837)
        at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:603)
        at java.lang.Thread.run(Thread.java:619)
, +1

This patch is intended for identifying the problem. So we probably still need to keep the issue open after the patch is committed., Thanks Hairong. Yes, this only improves log message. I'm no sure how such patches are handled. I making this patch available and you can change it to 'open' after the patch is submitted.
, +1, because http://issues.apache.org/jira/secure/attachment/12354781/HADOOP-1189.patch applied and successfully tested against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/525268. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, 
I think we found the problem. Consider the following 'du .' out put:

Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/sda3            950877384 148532012 792685008  16% /export/workspace

'Capacity - Used' is 80234537 and available is 792685008. A little bit of mismatch is expected. But this could be very large. On one node, we saw 'Capacity - Used' was 21GB and available was 0. In our code we use 'Capacity - Used' instead of MIN(Capacity - Used, Available).

I will submit a new patch.

, On one node with full drive, it showed  something like

  _____:  /dev/_            190451020 181125476         0 100% /___/____

Total, used and available space.
It doesn't add up because  os reserve some space for disk de-frag.
Could this be a reason?

, Attached 2.patch. It contains the change to log message and fixes getAvailable(). This could go in to 0.12.3., 
Update the patch to remove changes to log message etc. It just fixes the calculation in getAvailable().
Hairong, could you check the patch again?
, +1, because http://issues.apache.org/jira/secure/attachment/12354967/HADOOP-1189-3.patch applied and successfully tested against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/526215. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, Also, this should probably go into 0.12.4.. I guess its safe to assume there would be at least one more release before 13.0 :-), Hairong, are you able to check that this patch fixes the problem for you, before this is committed? Thanks., 
Yes. We are actually using it in our cluster.
, I've just committed this. Thanks Raghu!, Integrated in Hadoop-Nightly #55 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/55/)]