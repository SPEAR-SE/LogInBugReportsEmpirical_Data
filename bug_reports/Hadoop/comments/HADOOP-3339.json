[TestDatanodeDeath tests killing different datanodes in the pipeline and it works. The main difference is that whether the downstream datanode's error is detected depends on which of the two threads (the main data receiver or the "PacketResonder") detects it. 

In TestDatanodeDeath, its always the PacketResponder that detects it. But when a downstream datanode timeouts (or when the connection is busy) its the main IO thread that detects it. The fix I am thinking of is to make main thread inform the 'PacketResponder' about the failure.
, Assigning to 0.18.  This isn't a blocker for 0.17, +1 on Raghu's proposal. , 
The attached patch fixes the main problem described (practically all the time). It informs upstream properly about the the down stream failure.

Similar problem exists on client side as well. So if 2nd datanode timesout, most of the time client removes the first datanode as the bad one. The issues on DataNode and Client are similar but similar fix can not work, because on DataNode the responder needs properly write its state upstream and Client needs to properly read all the remaining data on the socket from first datanode.

The main issue is that BlockReceiver thread (and DataStreamer in the case of DFSClient) {{interrupt()}} the 'responder' thread. But interrupting is a pretty coarse control. We don't know what state the responder is in and interrupting has different effects depending on responder state. To fix this properly we need to redesign how we handle these interactions.

I am trying out a fix for DFSClient., The attached patch fixes the main problem described in the description. This handles the case when 3rd datanode (or 4th etc) fails properly. Regd failure at the 2nd datanode, it needs a fix at DFSClient and I don't have fix for it yet. I will file another jira for that.
, +1 patch looks good., Thanks Nicholas., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12382218/HADOOP-3339.patch
  against trunk revision 656939.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2496/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2496/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2496/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2496/console

This message is automatically generated., The test failure is another case of HADOOP-3354 and is not related to this patch. Also HADOOP-3416 is filed regd DFSClient., I just committed this., Integrated in Hadoop-trunk #499 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/499/])]