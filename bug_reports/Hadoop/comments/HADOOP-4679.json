[This patch changes DataNode.shouldRun to be false when a disk error is detected while receiving a block. It also sets a timeout of 10s on DataXceiverServer's server sokcet so the dataXceverServer is able to wake up periodically to check if it should continue to run or not., Link this to HADOOP-3574: Better Datanode DiskOutOfSpaceException handling., A new patch with minor change to handle a failed test., Could you also include the course e in the new DiskOutOfSpaceException in checkDiskError(...)?, After talking to Hairong:

  # DataXceiverServer should handle SocketTimeoutException. Right now an idle DN prints exception every 10 seconds.
  # the timeout for serever socket could be lower.. that test will finish faster.
  # The unit test need not create files in a tight loop.
  # immedateShutdown is not really necessary. The way shutdown() works, it should only be called from offerService() thread. I think javadoc JavaDoc should state it explicitly. 
  # The reason log was printed in a tight infinite loop (with out sleep) is that thread inturrupts itself before calling sleep().. so sleep returns immediately!

I think this should go into 0.18. No one likes disks filling up with these log messages.
  , This patch incorporates Raghu's comments except for comment 3. The unit test does not create files in a tight loop. It waits for all replications are created before moving to the next iteration. I tried a few other ways of writing this test. It seems that the current one is most efficient.

In addition, I made a change to BlockReceiver. If BlockReceiver constructor fails, it checks if it caused by a read-only disk. Since checking read-only disks is an expensive operation, it is performed only when creating the temporary block file fails. , 
# writeToBlock() creates files in two places. The patch catches only one of them.
# There is inherent requirement that shutdown() should only be called from offerService thread. It would be better if JavaDoc for shutdown() says this explicitly.  Otherwise, this deadlock and logging in tight infinite loop could occur again with future changes., I do not think it is necessary to check read-only disk for both block flle & meta data file. Checking block file is good enough. I will update the javadoc for shutdown., ant test-core passed:
BUILD SUCCESSFUL
Total time: 118 minutes 28 seconds

and so did ant patch:
     [exec] +1 overall.

     [exec]     +1 @author.  The patch does not contain any @author tags.

     [exec]     +1 tests included.  The patch appears to include 4 new or modified tests.

     [exec]     +1 javadoc.  The javadoc tool did not generate any warningmessages.

     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.

     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
, A patch for branch 0.18., I just committed this., Integrated in Hadoop-trunk #680 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/680/])
    ]