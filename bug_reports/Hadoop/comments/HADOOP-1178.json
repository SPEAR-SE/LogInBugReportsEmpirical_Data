[Start the namenode RPC server only after the namesystem is configured. , I have the same problem. The order of starting RPC and constructing FSNamespace() was changed by HADOOP-1085.
For me it appears a little different, when I restart the name-node in the same process after it failed to start first time.
Even with this patch I see

Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:119)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:185)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:626)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:323)
        at org.apache.hadoop.ipc.RPC.getServer(RPC.java:293)
        at org.apache.hadoop.dfs.NameNode.init(NameNode.java:164)
        at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:205)
        at org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:820)
        at org.apache.hadoop.dfs.UpgradeUtilities.startCluster(UpgradeUtilities.java:144)
        at org.apache.hadoop.dfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:157)

This means the socket has not been closed properly.
I think that hadoop.ipc.Server.Listener.doStop() should close the socket:
acceptChannel.socket().close()
We can also interrupt the Listener thread in Server.stop()
, As Konstantin pointed out this is an artefact of HADOOP-1085 ...

+1

, Close listener socket connection. Also, interrupt all RPC server handler threads. , This removes a unnecessary newline introduced by the last patch. Thanks Nigel for pointing it out., +1, because http://issues.apache.org/jira/secure/attachment/12354544/namenodestart2.patch applied and successfully tested against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/523840. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, I just committed this.  Thanks, Dhruba!, Integrated in Hadoop-Nightly #42 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/42/)]