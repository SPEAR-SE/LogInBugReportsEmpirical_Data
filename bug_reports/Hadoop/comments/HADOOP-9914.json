[We do not intentionally use shortnames. Many OSes out there are getting their /etc/hosts wrong, and specify the format as "IP SHORT FULL" when it should be "IP FULL SHORT" per the standard. Please check if that may be your issue as well?

Do your nodes use FQDN in /etc/sysconfig/network and/or /etc/hostname?, I spent a day to get the /etc/hosts and /etc/avahi/hosts right, when I created the setup for hadoop 1.1.2 and that works fine. The namenode is actually still working correctly: When you browse the file system, it uses the fully qualified names of the datanodes, meaning everything works as I expect it. The resourcemanager does not have the same same behaviour.

Here are my hosts:

$ cat /etc/hosts
127.0.0.1       localhost
192.168.7.10  master.local  master 
192.168.7.11  backup.local  backup 
192.168.7.12  hadoop1.local hadoop1
192.168.7.13  hadoop2.local hadoop2
192.168.7.14  hadoop3.local hadoop3

$ cat /etc/avahi/hosts 
127.0.0.1       localhost
192.168.7.10  master.local  master 
192.168.7.11  backup.local  backup 
192.168.7.12  hadoop1.local hadoop1
192.168.7.13  hadoop2.local hadoop2
192.168.7.14  hadoop3.local hadoop3

The hostnames are also correct:

$ for host in master hadoop1 hadoop2 hadoop3; do vagrant ssh $host --command hostname ; done
master.local
hadoop1.local
hadoop2.local
hadoop3.local

and just to be sure:

$ for host in master hadoop1 hadoop2 hadoop3; do vagrant ssh $host --command 'cat /etc/hostname' ; done
master.local
hadoop1.local
hadoop2.local
hadoop3.local

I also attached a screenshot of the webinterface.

, Sorry, I hit submit, but did not intend to. I found the issue, that /etc/hostname was not exactly right. Funny enough, HDFS always worked fine. PEBKAC. Closing the issue.]