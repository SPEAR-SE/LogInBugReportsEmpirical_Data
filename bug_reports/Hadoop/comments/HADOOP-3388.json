[ svn diff
Index: src/test/org/apache/hadoop/dfs/TestDatanodeBlockScanner.java
===================================================================
--- src/test/org/apache/hadoop/dfs/TestDatanodeBlockScanner.java        (revision 656131)
+++ src/test/org/apache/hadoop/dfs/TestDatanodeBlockScanner.java        (working copy)
@@ -174,7 +174,7 @@
     fs = cluster.getFileSystem();
     Path file1 = new Path("/tmp/testBlockVerification/file1");
     DFSTestUtil.createFile(fs, file1, 1024, (short)3, 0);
-    String block = DFSTestUtil.getFirstBlock(fs, file1).toString();
+    String block = DFSTestUtil.getFirstBlock(fs, file1).getBlockName();
     dfsClient = new DFSClient(new InetSocketAddress("localhost", 
                                         cluster.getNameNodePort()), conf);

The above patch fixes only part of the problem. The other part is probably related to the CorruptReplicaMap that has recently been committed., I would like to request Lohit to review this patch., Integrated in Hadoop-trunk #491 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/491/]), -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12382020/patch.txt
  against trunk revision 656270.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2465/console

This message is automatically generated., +1
I hit the same failure yesterday and had this change locally. , I just committed this.]