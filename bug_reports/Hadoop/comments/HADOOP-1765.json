[This is namenode log excerpt at DEBUG level.  To find the problematic file, search for the string 8020883803428152097 (or for the IOException).

The creation scenario that seems to be bringing on the failure is as follows:

{code}
Create file named X
Fill it
Close it.
Rename it as file named Y
Create new file named X
Fill it
Try to close it <-- IOException
{code}, The following does not provoke the exception:
{code}
    Configuration c = new Configuration();
    FileSystem fs = FileSystem.get(c);
    Text t = new Text("x");
    Path src = new Path("/tmp/x");
    Path tgt = new Path("/tmp/y");
    fs.mkdirs(src);
    MapFile.Writer writer =
      new MapFile.Writer(c, fs, src.toString(), Text.class, Text.class);
    writer.append(t, t);
    writer.close();
    if (!fs.rename(src, tgt)) {
      throw new IOException("Rename failed");
    }
    writer =
      new MapFile.Writer(c, fs, src.toString(), Text.class, Text.class);
    writer.append(t, t);
    writer.close();
{code}, On retest, it does not look like reuse of a filename following a rename has anything to do with the failure.  The attached debug log includes an IOE w/o an intermediate rename.

Workarounds or suggestions appreciated (I get this doing large uploads into hbase).  Thanks., Here are all logs related to failing file pulled from attached DEBUG log:

{code}
2007-08-22 23:48:59,515 DEBUG org.apache.hadoop.dfs.StateChange: *DIR* NameNode.create: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data for DFSClient_-2109891694 at 208.76.44.140
2007-08-22 23:48:59,515 DEBUG org.apache.hadoop.dfs.StateChange: DIR* NameSystem.startFile: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data for DFSClient_-2109891694 at 208.76.44.1402007-08-22 23:48:59,515 DEBUG org.apache.hadoop.dfs.StateChange: DIR* NameSystem.startFile: add /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data to pendingCreates for DFSClient_-2109891694
2007-08-22 23:48:59,515 DEBUG org.apache.hadoop.dfs.StateChange: DIR* FSDirectory.addFile: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data with 0 blocks is added to the file system
2007-08-22 23:49:00,811 DEBUG org.apache.hadoop.dfs.StateChange: *BLOCK* NameNode.addBlock: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data for DFSClient_-2109891694
2007-08-22 23:49:00,811 DEBUG org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.getAdditionalBlock: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data for DFSClient_-2109891694
2007-08-22 23:49:00,812 INFO org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.allocateBlock: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data. blk_-7962476260520498222 is created and added to pendingCreates and pendingCreateBlocks
2007-08-22 23:49:03,352 DEBUG org.apache.hadoop.dfs.StateChange: *DIR* NameNode.complete: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data for DFSClient_-21098916942007-08-22 23:49:03,352 DEBUG org.apache.hadoop.dfs.StateChange: DIR* NameSystem.completeFile: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data for DFSClient_-2109891694
2007-08-22 23:49:03,354 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call complete(/bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data, DFSClient_-2109891694) from 208.76.44.140:56731: error: java.io.IOException: Unknown file: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,F2pGuwUpH4RWZY5e1ZqKjF==,8020883803428152097/repo/mapfiles/-1/data
{code}

Looks like a block is added to a file known by the filesystem, then another, but then on 'complete', IOE., Thanks for the detailed report. This looks something we need to investigate and fix soon. I am not sure of a workaround yet.
, Thanks Raghu.  I upped priority from minor to major since this issue results in data loss.  What strikes me as odd is that the FSDirectory.addFile log happens at the end of the addBlocks method.  At the head of this method it does the lookup of the associated node and succeeds.  When the same addBlocks method is called out of the completeFile as part of the close, it fails to find the node.

Here is another example of the failure done with an update to TRUNK -- turns out the above log maybe a week or more old -- and a newly formatted filesystem:
{code}
2007-08-23 16:16:22,647 DEBUG org.apache.hadoop.dfs.StateChange: *DIR* NameNode.create: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025 at 208.76.44.142
2007-08-23 16:16:22,648 DEBUG org.apache.hadoop.dfs.StateChange: DIR* NameSystem.startFile: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025 at 208.76.44.142
2007-08-23 16:16:22,648 DEBUG org.apache.hadoop.dfs.StateChange: DIR* NameSystem.startFile: add /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data to pendingCreates for DFSClient_1851346025
2007-08-23 16:16:22,653 DEBUG org.apache.hadoop.dfs.StateChange: DIR* FSDirectory.addFile: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data with 0 blocks is added to the file system
2007-08-23 16:16:24,254 DEBUG org.apache.hadoop.dfs.StateChange: *BLOCK* NameNode.addBlock: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025
2007-08-23 16:16:24,255 DEBUG org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.getAdditionalBlock: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025
2007-08-23 16:16:24,255 INFO org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.allocateBlock: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data. blk_-7923302926655854738 is created and added to pendingCreates and pendingCreateBlocks
2007-08-23 16:16:29,002 DEBUG org.apache.hadoop.dfs.StateChange: *DIR* NameNode.complete: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025
2007-08-23 16:16:29,984 DEBUG org.apache.hadoop.dfs.StateChange: DIR* NameSystem.completeFile: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025
2007-08-23 16:16:29,986 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call complete(/bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data, DFSClient_1851346025) from 208.76.44.142:36252: error: java.io.IOException: Unknown file: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data
java.io.IOException: Unknown file: /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data2007-08-23 16:16:37,428 DEBUG org.apache.hadoop.dfs.StateChange: *DIR* NameNode.create: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025 at 208.76.44.142
2007-08-23 16:16:37,428 DEBUG org.apache.hadoop.dfs.StateChange: DIR* NameSystem.startFile: file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025 at 208.76.44.1422007-08-23 16:16:37,428 WARN org.apache.hadoop.dfs.StateChange: DIR* NameSystem.startFile: failed to create file /bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/hregion_hbaserepository,UwSTZDqGkjRNQIYAPaNXRV==,5123329232858704969/repo/mapfiles/-1/data for DFSClient_1851346025 on client 208.76.44.142 because current leaseholder is trying to recreate file.
{code}

Only lines related to the failing file are listed., > What strikes me as odd is that the FSDirectory.addFile log happens at the end of the addBlocks method.
> At the head of this method it does the lookup of the associated node and succeeds. When the same addBlocks 
> method is called out of the completeFile as part of the close, it fails to find the node.

addBlocks() is called only once inside completeFile(). addBlock() (no 's') does not look up the file in global directory. 
It just looks up the name in 'pendingCreates'.

I wish jira could could limit of width of regular formatted text instead of extending it as far as lines under { noformat } go.., Probably related to HADOOP-1708., In the log file you have attached, {{/bfd/hadoop-stack-data/tmp/hbase/compaction.tmp/}}
 is deleted after a file under it is created but before the file closed. 
Before HADOOP-1708, close() would just recreate the required parent directories.
This explains the exception. 
, Thanks for the observation Raghu.  I addressed the fact that another thread could remove the parent directory.  This gets me over the fact that close sometimes failed (It took some time verifying this).  I'll resolve this issue since the real action is happening over in HADOOP-1708 (and you've added a pointer here from HADOOP-1708 as an illustration of issues w/ currently applied patch).]