[Attaching the patch., +1 with a minor comment.

In MAPREDUCE-4510 I added a Shell.LINUX
Makes sense to run LTC test when Shell.LINUX instead of when !Shell.WINDOWS? I think it reads better.
, Thanks for reviewing Bikas.

bq. Makes sense to run LTC test when Shell.LINUX instead of when !Shell.WINDOWS? I think it reads better
Sure. Just to confirm, this would prevent running the test on all platforms that are not Linux (Mac for example). Is something we want?, LTC does not run on anything other than Linux., Thanks for clarifying! Attaching updated patch., Running thru dos2unix., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12544033/HADOOP-8733-scripts.2.patch
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1445//console

This message is automatically generated., Looks good overall, Ivan.

One minor point: In TestJvmManager, instead of creating dummy file for WINDOWS, will it be possible to simulate the Child code like on Linux. Is "final String jvmName = ManagementFactory.getRuntimeMXBean().getName();" in Child.java the call that is used to send pid from Child to TT? If so, we should just simulate that code., Thanks again for reviewing Vinod!

bq. One minor point: In TestJvmManager, instead of creating dummy file for WINDOWS, will it be possible to simulate the Child code like on Linux. Is "final String jvmName = ManagementFactory.getRuntimeMXBean().getName();" in Child.java the call that is used to send pid from Child to TT? If so, we should just simulate that code.
I'm not sure I understand your comment. Do you mind clarifying a bit? 

Just to provide some context from my side. On Windows, we don't use ProcessID to identify the task process, instead we used attemptId string. This ID is tied to the child task using Windows [JobObjects|http://msdn.microsoft.com/en-us/library/windows/desktop/ms684161(v=vs.85).aspx], and TT uses this ID to kill the task if needed.

Now, in TestJvmManager we are verifying that the task is killed properly, and on Windows there is no need to circulate the PID from the task back to the TT, as the TT has this info already. Hope this helps., Actually, the TT is informed of the spawned process identifier by the child process (via TaskUmbilicalProtocol.getTask()). On Linux, this is the Linux OS pid set via the shell script. On Windows it is the job object identifier set by the TT (currently set to task attempt id). The child obtains the value from ENV variable.
The MXBean code is a fallback to get the process OS pid in case the ENV var is not set. This works cross platform on most JDK's. This is relevant in Windows only when we dont use job objects for spawning processes (ie directly spawning Windows processes)., Thanks for additional clarification Bikas.

Do you feel we should make some changes to the test? From the TestJvmManager perspective, there is no need to circulate the PID value back thru the pidFile, right? , TestJVMManager is simulating the kill code-path in case of linux. So yes, unless it is very difficult, please change the test to verify that the attemptid that is sent across can be successfully used for killing processes in case of Windows., Attaching updated patch. I added the part where attempt id is passed as part of the child task environment and circulated back for taskkill. 

Vinod, let me know if you have any comments on the latest patch.

Thanks!, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545993/HADOOP-8733-scripts.3.patch
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1489//console

This message is automatically generated., This looks natural. Tx for the update.

Verified that tests are passing on my local box. +1. Pushing this., Just committed this to branch-1-win. Thanks Ivan!]