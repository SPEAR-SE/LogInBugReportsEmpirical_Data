[As we can see from the hadoop namenode log:
{{16/04/20 07:19:54 INFO namenode.NameNode: createNameNode []}}

the {{-Dhadoop.security.group.mapping.ldap.bind.password.file =BIND_PASSWORD_FILE_PATH}} is not passed into the code as argument to main. The Namenode#main() like many hadoop component relies on GenericOptionsParser class to handle the -D argument. 

I have not find hadoop document around this or  it is a known issue. Below is a few work around:

1. run {{hadoop namenode -Dhadoop.security.group.mapping.ldap.bind.password.file =BIND_PASSWORD_FILE_PATH}} directly without relying on HADOOP_NAMENODE_OPTS

2. use a intermediate environment variable in hadoop-env.sh and core-site.xml

hadoop-env.sh
export LDAP_OPTS="-Dldap.bind.password.file=BIND_PASSWORD_FILE_PATH"
export HADOOP_NAMENODE_OPTS="${HADOOP_NAMENODE_OPTS} ${LDAP_OPTS}"

core-site.xml
<property>
    <name>hadoop.security.group.mapping.ldap.bind.password.file</name>
    <value>${ldap.bind.password.file}</value>
  </property>, What does {{hdfs --debug}} say?  i.e., is this a Java problem or a shell problem?

EDIT:

Looking like a java issue:

{{grep password etc/hadoop/hadoop-env.sh}}:
{code}
export HADOOP_NAMENODE_OPTS="-Dhadoop.security.group.mapping.ldap.bind.password.file=/my/file/path" 
{code}


{{bin/hdfs --debug namenode 2>&1 | grep 'Final HADOOP_OPTS'}}:
{code}
DEBUG: Final HADOOP_OPTS: -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm=  -Djava.security.krb5.kdc=  -Djava.security.krb5.conf=  -Dhadoop.security.group.mapping.ldap.bind.password.file=/my/file/path -Dhdfs.audit.logger=INFO,NullAppender -Dyarn.log.dir=/Users/aw/H/hadoop-3.0.0-SNAPSHOT/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/Users/aw/H/hadoop-3.0.0-SNAPSHOT -Dyarn.root.logger=INFO,console -Dhadoop.log.dir=/Users/aw/H/hadoop-3.0.0-SNAPSHOT/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/Users/aw/H/hadoop-3.0.0-SNAPSHOT -Dhadoop.id.str=aw -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender
{code}

It's up there., Does HADOOP_OPTS get added as environment variable or part of the command line argument? Looks like the command line argument is empty.

{code}
DEBUG: Final JAVA_HOME: /Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home
DEBUG: java: /Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/bin/java
DEBUG: Class name: org.apache.hadoop.hdfs.server.namenode.NameNode
DEBUG: Command line options: 
{code}

{code}
hdfs --debug namenode 2>&1 | grep 'Final HADOOP_OPTS'
DEBUG: Final HADOOP_OPTS: -Djava.net.preferIPv4Stack=true -Djava.library.path=/Users/xyz/deploy/hadoop/lib/native -Djava.security.krb5.realm=  -Djava.security.krb5.kdc=  -Djava.security.krb5.conf=  -Dhadoop.security.group.mapping.ldap.bind.password.file=CUSTOMERFILELOCATION  -Dhadoop.security.group.mapping.ldap.bind.password.file=Nondefault.ldap.bind.password.file=nondefault.hello -Dhdfs.audit.logger=INFO,NullAppender -Dyarn.log.dir=/Users/xyz/deploy/hadoop-3.0.0-SNAPSHOT/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/Users/xyz/deploy/hadoop-3.0.0-SNAPSHOT -Dyarn.root.logger=INFO,console -Dhadoop.log.dir=/Users/xyz/deploy/hadoop-3.0.0-SNAPSHOT/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/Users/xyz/deploy/hadoop-3.0.0-SNAPSHOT -Dhadoop.id.str=xyz -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender
{code}, bq. Does HADOOP_OPTS get added as environment variable or part of the command line argument? 

It's passed as a Java system property on the command line. 

bin/hdfs in branch-2:
{code}
exec "$JAVA" -Dproc_$COMMAND $JAVA_HEAP_MAX $HADOOP_OPTS $CLASS "$@" 
{code}

hadoop_java_exec in hadoop-functions.sh in trunk:
{code}
  exec "${JAVA}" "-Dproc_${command}" ${HADOOP_OPTS} "${class}" "$@"
{code}
, Thanks [~aw]! This seems like a limitation of the org.apache.hadoop.conf.Configuration class. It requires the configuration key in either core-site.xml or hdfs-site.xml before the system property passed via HADOOP_NAMENODE_OPTS can be honored. That's why the work around works. Otherwise, the default will be returned for Configuration#get() as show below.  Here is my test with only {{export HADOOP_NAMENODE_OPTS="-Dhadoop.security.group.mapping.ldap.bind.password.file=CUSTOMERFILELOCATION" }}

{code}
6/04/20 16:58:20 INFO namenode.NameNode: hadoop.security.group.mapping.ldap.bind.password.file (from Configuration#get) = Default.bind.password.file
16/04/20 16:58:20 INFO namenode.NameNode: hadoop.security.group.mapping.ldap.bind.password.file (from System#getProperty) = CUSTOMERFILELOCATION
{code}, Yup, that sounds like a bug in Configuration.  It's kind of odd though, given that at least a null value for hadoop.security.group.mapping.ldap.bind.password.file should be coming from the core-default.xml file bundled in the jar though.   But whatever.  There have been a lot of changes in that part of code since the "interface" of using system properties to pass config info was set up eons ago.  It's gotten significantly complicated enough that breakages like this shouldn't be too surprising.

Anyway, I'll let you update the JIRA issue to reflect reality, since this isn't a script bug. :)  Thanks., Closing this since it's not a bug in the shell scripts.]