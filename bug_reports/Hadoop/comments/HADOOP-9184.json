[{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563616/example.pig
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1998//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563633/hadoop-9184.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1999//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563633/hadoop-9184.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2001//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563633/hadoop-9184.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2004//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563745/HADOOP-9184-branch-0.20.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2012//console

This message is automatically generated., I'm not sure what's wrong with the patch.  It seems to apply fine when I do it locally., The PreCommit builds run only against trunk. Target your patch for branch-1 and run it through the test-patch process (ant test-patch or run the script manually). If everything passes, you can post the result to this jira.
, When I run:

ant test-patch -Dpatch.file=../HADOOP-9184-branch-0.20.patch -Dforrest.home=$FORREST_HOME -Dfindbugs.home=$FINDBUGS_HOME -Djava5.home=$JAVA_5_HOME

It fails with:

     [exec] ======================================================================
     [exec]     Pre-building trunk to determine trunk number
     [exec]     of release audit, javac, and Findbugs warnings.
     [exec] ======================================================================
     [exec] ======================================================================
     [exec] 
     [exec] 
     [exec] /bin/ant -Dversion=PATCH-HADOOP-9184-branch-0.20.patch -Djavac.args=-Xlint -Xmaxwarns 1000  -Djava5.home=/home/ubuntu/jdk1.5.0_22 -Dforrest.home=/home/ubuntu/apache-forrest-0.8 -DHadoopPatchProcess= clean tar > /home/ubuntu/tmp/trunkJavacWarnings.txt 2>&1
     [exec] Trunk compilation is broken?

But I can successfully run: 

ant clean tar -Djavac.args="-Xlint -Xmaxwarns 1000" -Dforrest.home=$FORREST_HOME -Dfindbugs.home=$FINDBUGS_HOME -Djava5.home=$JAVA_5_HOME -DHadoopPatchProcess= clean tar

Any ideas?, This has bitten me many times. Happy to see the source of the bug has been found and looking forward to the fix making it in., The patch won't apply as it's in the branch 1 layout and build, trunk is split up and Mavenized. If you could do it for there and try and reduce the odd spurious change, that would be good.

I see three possible causes
# you've hit eventual consistency at play in S3. 
 * Which S3 location are you working with? US-default?
 * Have a go on US-west and see if replicates there.
# There's just a race condition between {{isFile()}} (which calls {{getFileStatus()}} and the {{getFileStatus()}} in the  following condition. I'd switch to a single {{getFileStatus()}} up front to eliminate that race, and eliminate the cost of another round trip (which is more expensive to remote filesystems)
# Atomicity: {{mv}} and {{rm -rf}} aren't atomic on blobstores. We know about this and do need to come up with a better solution at the end of MR jobs for filesystems that declare they are blobstores.

Steve, I don't think the bug actually applies to trunk since it looks like the latest FileOutputCommitter successfully handles the else condition in moveTaskOutputs.  

The problem I'm having is that its not clear to me how to submit a patch for the old branch 1 layout.  Any documentation I'm finding references maven and the test-patch script which don't seem to work with the older branches., you are right, it's not in trunk.

just do that patch and those of us who worry about blobstore support will have a look -though I need to get a lot of filesystem changes out the way first, including some unrelated fixes to S3n, Ok, Then I think HADOOP-9184-branch-0.20.patch is ready for review., One question - what the patch seems to do is assert that if a path was listed initially (in the parent moveTaskOutputs() call) - then it must be listable in the child call (if it's neither a Dir nor a File - then basically it's not listable). One thing I don't understand is what is the guarantee that the FileSystem will accurately list the child paths in the parent function call? (assuming this happens because of eventual consistency issues with S3)

On a different note - changing the moveTaskOutputs signature to carry a FileStatus (of the output path) instead of the Path argument removes the need to throw an exception (since the parent call just passes the status down to the child - there can never be any disagreement between the two), unfortunately the patch doesn't fix this issue completely. as mentioned above - the initial listing of the task output directory may lie - and we are seeing this in testing. 

we suspect this line of attack is ultimately futile. It's hard for FileOutputCommitter to know exactly how many files have been produced by the recordwriter. Most likely - writing directly to final output location in S3 (and exploiting the atomicity of the S3 'put' operation) and just avoiding the rename operation is the only long term fix., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12563745/HADOOP-9184-branch-0.20.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6281/console |


This message was automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12563745/HADOOP-9184-branch-0.20.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6295/console |


This message was automatically generated.]