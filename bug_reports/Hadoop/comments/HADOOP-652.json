[
This will touch addBlock() in FSDataset.java. As part of this I would like the fix the following as well:

a) currently subdirectories are created only in the last sub directory (e.g. subdir63). 
b) remove siblings array I think it only increase s recursion in addBlock().

, I create and delete a lot of files in DFS, so I see that speed of DataNode extremely go down!

> a) currently subdirectories are created only in the last sub directory (e.g. subdir63).

Not only subdir63. After the DataNode restarts, subdirectories will be created in other subdirXY, because "File[] files = dir.listFiles();" in FSDir constructor lists subdirectories and files in arbitrary order and last subdirectory will be other. Two branches: subdir63 and other one. It is not bug. Other code process this type of tree properly.

> b) remove siblings array I think it only increase s recursion in addBlock().

Recursion is not good idea, because it very slow when DataNode stores a lot of blocks. I think this algorithm should be changed in the future.



Here is my tested solution of this bug:

New method clearPath() in FSDir:

>        void clearPath( File f ) {
>         if ( dir.compareTo( f ) == 0 ) numBlocks--;
>         else {
>          if ( ( siblings != null ) && ( myIdx != ( siblings.length - 1 ) ) )
>           siblings[ myIdx + 1 ].clearPath( f );
>          else if ( children != null )
>           children[ 0 ].clearPath( f );
>         }
>        }

New method clearPath() in FSVolume:

>      void clearPath( File f ) {
>          dataDir.clearPath( f );
>      }

Changes in invalidate() method in FSDataset:

<        blockMap.remove(invalidBlks[i]);

>        synchronized ( ongoingCreates ) {
>        blockMap.remove( invalidBlks[ i ] );
>             FSVolume v = volumeMap.get( invalidBlks[ i ] );
>        volumeMap.remove( invalidBlks[ i ] );
>        v.clearPath( f.getParentFile() );
>       }

And changes in getFile() method in FSDataset:

<     return blockMap.get(b);

>     synchronized ( ongoingCreates ) {
>      return blockMap.get( b );
>     }

Now I will try to create patch file properly.

P.S. Also I set dfs.blockreport.intervalMsec = 10000 ( 10 - 30 sec ) in order to prevent lowering NameNode's speed. Because NameNode holds deleted blocks in its datastructures across block reports.
, diff FSDataset.java.org FSDataset.java.my > FSDataset.java.patch, 
You should update your code. FSDataset.java  has changed recently. Also do a 'diff -u' for submitting a patch.

This fixes only updating numBlock and does not fix recursion. I am thinking of fixing both (a) and (b) in comment #1 above.
, Yes. Synchronization in FSDataset already changed. But I think synchronized block in invalidate() method should be smaller, because getFile() call is already synchronized and f.delete() call may be blocked in OS in some situations. So I submit the patch with these changes and with "-u" option, as you instruct me., 
Thanks Vladimir.

I have couple of suggestions: 

regd locking: synchronizing getFile() and removing from maps seperately is not currect (we will have situation where a block exists in the map but file does not exist). I would suggest moving f.delete() to outside synchronize(). So we delete after removing from maps. 

clearPath(): Currently its cost (in compareTo() and in recursion) and  proportional to number of directories instead of depth of dir tree. One option to go to the currect child based on the path. On second thoght, you can leave it as it is we will fix it when we fix addBlock() (to remove siblings variable).

For now you just move f.delete() to outside synchrnoized block and submit the patch., OK. I just moved f.delete() to outside synchronized block and left recursion as it is. Thanks Raghu., I just committed this.  Thanks Vladimir & Raghu!]