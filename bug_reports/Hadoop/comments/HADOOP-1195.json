[Check for null return value before using DatanodeDescriptor., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373473/datanodeNullPointer.patch
against trunk revision r613115.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1642/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1642/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1642/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1642/console

This message is automatically generated., In all these cases is there valid reasons for expecting null? For. e.g. I am not sure if setDatanodeDead() should handle null.. its an internal member., +1 for 1st and 3rd hunks in the patch., setDatanodeDead() sets the dead bit on the datanode if it finds the datanode. Otherwise it does nothing. The current code in the "trunk" will throw a NPE if this condition occurs. The premise of this bug fix is that a "Null Pointer Exception" is very bad. The namenode code should be able to throw explicit exceptions on error conditions., > The premise of this bug fix is that a "Null Pointer Exception" is very bad. 
IMHO it is bad when null is expected (e.g. user arguments, RPC calls), no need to check for null when the context does not expect a null. I mean it does not need cover up some other bug. But I am not strongly against it. Your choice.

how about replacing the 2nd hunk with:

{noformat}
@@ -1967,8 +1967,7 @@
             (now() - heartbeatExpireInterval));
   }
     
-  void setDatanodeDead(DatanodeID nodeID) throws IOException {
-    DatanodeDescriptor node = getDatanode(nodeID);
+  private void setDatanodeDead(DatanodeDescriptor node) throws IOException {
     node.setLastUpdate(0);
   }
 
{noformat}

, Incorporated Raghu's comments., Re-submitting to trigger Hudson tests., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373979/datanodeNullPointer.patch
against trunk revision 614721.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1672/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1672/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1672/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1672/console

This message is automatically generated., I just committed this., Integrated in Hadoop-trunk #379 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/379/])]