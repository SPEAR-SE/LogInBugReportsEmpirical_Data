[Just FYI for whomever takes this: this is fixed on trunk so take a look there. I don't recall if it was part of the FsShell overhaul, or part of a FileUtils change., Ben, would you interested to contribute a find and file a fix patch for this?

For 1.0 (formerly 0.20.205), the relevant class/filename would be FsShell.java (Nested under src/core/)., @Harsh: I can take a look. Would the idea be to fix it in the .20.205 tag since it's already been fixed in trunk (apparently)?, Ben, Thanks! And yes, you'd need to checkout the branch-1 or the release tag 1.0.0 for the current sources.

Iff you need some starter help, I have some instructions for building branch-1 at http://wiki.apache.org/hadoop/QwertyManiac/BuildingHadoopTrunk (see bottom). For eclipse integration, just run {{ant eclipse}} and then import the root clone/checkout directory as a project in Eclipse. But let me know if you need anything else to get you going :), Forgot to grant license last time, Added a small patch. I am not sure how to run the unit tests (wiki says to use maven, but 1.0 appears to not use maven, so...) but I'm doubtful that it would affect anything.

I believe that the only reason the mkdirs() call could fail is permissions (so the second "if" is redundant), but it seemed like a could idea to check its return value anyway.

My first hadoop patch, so comments are appreciated :)

PS: Harsh: thanks for your help. FYI, at the bottom of your page you talk about both branches 0.1 and 1.0 - I was confused for a bit :), -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12511400/hadoop-7943.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/522//console

This message is automatically generated., Misnamed the patch last time; trying again., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12511402/hadoop-7943-1.0.0.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/523//console

This message is automatically generated., The exception when mkdirs fails is a bit misleading.  It's not the temp file generation that failed, it's the directory creation., Daryn: Good point. What should it say? "Could not create parent directories for temp file"?, Maybe "Failed to create directory"?  It shouldn't mention a temp file since it's actually creating the subdirectory for a recursive copy.  The real files will be copied into it, and the temp is just an implementation detail of the file copy., Changing error message as per Daryn., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12511524/hadoop-7943-1.0.0v2.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/524//console

This message is automatically generated., Looks good as long as a test is added., This is turning out to be harder than I thought. The canWrite method is only valid if the file already exists, so it's kind of useless for us.

I think the best we can do is to use the path to determine if mkdirs should do anything, and then give the generic "couldn't create directories" error if it doesn't.

Unless someone else knows of a better method? It would be nice if there was a mkdirsAndReturnErrors function., Patch includes tests for copying a directory and copying a single file. Also had to refactor the shell class to expose error messages., Hi Ben, the patch is empty except for filenames., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12513450/hadoop-7943-1.0v3.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/565//console

This message is automatically generated., whoops, wrong file last time..., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12513455/hadoop-7943-1.0v4.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/566//console

This message is automatically generated., Daryn reports this is fixed in trunk and it's unlikely we'll ever do another 1.x release, given the last one was over a year ago at this point...

Closing as won't fix.]