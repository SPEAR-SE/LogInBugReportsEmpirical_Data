[
Here's the trace:
{code}
2009-02-26 10:41:31,975 WARN org.apache.hadoop.net.ScriptBasedMapping: java.io.IOException: Cannot run program "<myPath>/topologyProgram" (in directory "<my-hadoop-home>"): java.io.IOException: error=13, Permission denied
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:459)
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:149)
        at org.apache.hadoop.util.Shell.run(Shell.java:134)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)
        at org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:148)
        at org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:94)
        at org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:59)
        at org.apache.hadoop.mapred.JobTracker.resolveAndAddToTopology(JobTracker.java:2120)
        at org.apache.hadoop.mapred.JobTracker.addNewTracker(JobTracker.java:2113)
        at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:2489)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2289)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
Caused by: java.io.IOException: java.io.IOException: error=13, Permission denied
        at java.lang.UNIXProcess.<init>(UNIXProcess.java:148)
        at java.lang.ProcessImpl.start(ProcessImpl.java:65)
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:452)
        ... 19 more
{code}

{code}
2009-02-26 10:41:31,975 INFO org.apache.hadoop.ipc.Server: IPC Server handler 62 on 52000, call heartbeat(org.apache.hadoop.mapred.TaskTrackerStatus@1b79c945, true, true, true, -1) from 
98.137.102.152:47264: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobTracker.resolveAndAddToTopology(JobTracker.java:2121)
        at org.apache.hadoop.mapred.JobTracker.addNewTracker(JobTracker.java:2113)
        at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:2489)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2289)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
{code}

JT is alive all along, returning NPEs in TTs heartbeats., I've seen logs in emails that indicate this is still possible to arise in the 0.20.20x series.

The problem is that the {{ScriptBasedMapping.RawScriptMapping.resolve()} method behaves as follows
 # return "/default-rack" if there is no script
 # return null if the script fails
 # {{CachedDNSToSwitchMapping.resolve()} (which invokes this inner resolve) sees the null pointer, doesn't add those entries to its cache, then builds a list of results for each supplied argument -and for unknown hosts returns null.
 # The JobTracker doesn't expect null.

What to do?
 * The WARN could somehow be raised to a higher level so that it doesn't get lost to the user -or the error message changed to be more meaningful to users who don't want to delve into the source. 
 * The JT (and its YARN successor) need a policy of handling null-ness.
 * Better preflight checking of the shell script

Unit tests could verify how the Namenode, JT and RM handle null entries with a switch mapping that returns null always; trivial., Note that the {{DNSToSwitchMapping}} says nothing about returning null on any problem; the behaviour of the implementation is not consistent with the javadocs, Hi Steve, Vinod,

I've run into the similar problem to this one. In my case, JobTracker started failing jobs because the network topology resolution started failing for a single node in the cluster:
{code}
2013-04-27 08:33:08,204 ERROR org.apache.hadoop.mapred.JobTracker: Job initialization failed:
java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobTracker.resolveAndAddToTopology(JobTracker.java:3205)
	at org.apache.hadoop.mapred.JobInProgress.createCache(JobInProgress.java:550)
	at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:734)
	at org.apache.hadoop.mapred.JobTracker.initJob(JobTracker.java:4214)
	at org.apache.hadoop.mapred.EagerTaskInitializationListener$InitJob.run(EagerTaskInitializationListener.java:79)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)
{code}

What happens is that some input split blocks are located on the datanode with the same IP/hostname as the TT. As a side effect this results in many of the customer jobs to fail during initialization.

NN on the other hand has a fallback logic that defaults to /default-rack, and this inconsistency actually makes this problem more severe :)
{code}
2013-04-27 04:36:47,185 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: The resolve call returned null! Using /default-rack for host [100.64.34.3]
2013-04-27 04:36:47,185 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/100.64.34.3:50010			
{code}

In terms of the fix, my proposal would be to add the same fallback logic to the JobTracker. In our case, we actually had a network topology script that worked fine for a year or so, and now started failing for a single node for a reason we cannot explain yet.

Let me know what you think. I'll take up this Jira if you don't mind., To help others who encounter this:

This problem can occur where the "<myPath>/topologyProgram" cannot be executed not because the script does not exist, but because of an operating system restriction.  

In the case of a standard Ubuntu Server, this prohibits execution on the /run mount point.  Simply solved by executing:
sudo mount -o remount,exec /run

See https://groups.google.com/a/cloudera.org/forum/#!msg/scm-users/mDlnpWSfXMI/39cDl2C7gSUJ

Cloudera install should detect and warn/remedy this.  But that's another ticket..., We should verify if this condition still exists in 2.x and if so, fix it.]