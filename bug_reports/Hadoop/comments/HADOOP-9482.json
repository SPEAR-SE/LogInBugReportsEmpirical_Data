[Code of mine that used to be able to create files using the {{file:///}} fs are now failing saying that I haven't set up the hadoop home directory properly. 

This appears due to HADOOP-8952; the {{chmod}} command is being treated as something that must be exec'd from {{$HADOOP_HOME/bin}} if the native libraries aren't installed. On linux, chmod is on the shell and the value of {{HADOOP_HOME_DIR}} or {{hadoop.home.dir}} is irrelevant., stack trace
{code}
Running org.apache.hadoop.fs.swift.integration.generate.GenerateMassiveFilesTest
2013-04-17 14:14:23.507 java[57614:1203] Unable to load realm info from SCDynamicStore
2013-04-17 14:14:23,516 [main] WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-04-17 14:14:23,727 [main] ERROR util.Shell (Shell.java:checkHadoopHome(180)) - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:617)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:441)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:411)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:888)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:869)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:768)
	at org.apache.hadoop.fs.FileSystem$create.call(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:42)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:108)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:120)
	at org.apache.hadoop.fs.swift.integration.generate.GenerateMassiveFilesTest.testGenerateKilobytes(GenerateMassiveFilesTest.groovy:54)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:208)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:158)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:86)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:95)
Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.999 sec <<< FAILURE!
testGenerateKilobytes(org.apache.hadoop.fs.swift.integration.generate.GenerateMassiveFilesTest)  Time elapsed: 0.554 sec  <<< ERROR!
{code}, Did you mean to reference HADOOP-8562?  HADOOP-8952 was never committed, although apparently a typo during the checkin of HADOOP-8562 accidentally referenced it., HADOOP-8562 did introduce a bug related to requiring HADOOP_HOME to launch shell commands.  HADOOP-9422 already tracks the bug., I just grabbed that JIRA reference from the commit logs -HADOOP-8562 looks like the root cause. 

This also looks like an instance of HADOOP-9422: file creations calls {{chmod()}}, which uses shell, which failed.

Looking at the source (my local branch/fork for HADOOP-8545, not been rebased for a while), the IOE is thrown and then caught; a clean mvn install stops this problem re-occurring. I think my machine may have been contaminated by some other snapshot of the hadoop-common JAR. ]