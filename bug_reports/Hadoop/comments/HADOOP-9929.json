[I added 2.1.0-beta for affects version, since I have seen it there as well., In a way the current behavior is more secure. Is it not?
A person who does not have permission to cd into a directory should not be able to discover the presence or absence of a file in the directory. 
Am I missing something?
, This is a good catch, Jason.

The solution to this might be a bit tricky.

If we're listing a single path (like /a/b/c), we definitely want to throw AccessControlException if we can't get to c.

If we're listing a glob like /a/*/c, I'm not sure if we want to abort the whole glob (by throwing an exception), just because one path was not accessible to us.  Perhaps we should just return the things we can get to?  For what it's worth, the old behavior in branch-1 is to abort the whole glob, I believe.

Another aspect is that exceptions such as StandbyException, etc. should *always* just propagate to the top level.  Basically any IOException that we don't specifically catch (like permission denied, etc.) we should propagate to the top level, aborting the globStatus., I don't believe the globbing code I cleaned up for v23+ has these issues.  You want want to use it for reference., bq. A person who does not have permission to cd into a directory should not be able to discover the presence or absence of a file in the directory.

No, we're not suggesting that the user can probe for paths.  Like *nix, you should receive the permission denied exception for _any_ path under a directory you can't access.  The glob rewrite makes it claim the entire path doesn't exist which it didn't do in 23 and earlier., Here's a patch which lets all exceptions except FileNotFound propagate, effectively restoring the old behavior.  This means that, as before, your glob will fail if you encounter permission issues.  It's probably best to keep it this way for compatibility reasons.

I also added a unit test for this., Thanks Darryn for the clarification on my  last quesiton:
Question:  In a way the current behavior is more secure...?, Hi Dilli,

Neither the current (buggy) nor the fixed behavior allows users to list directories that they shouldn't.  The question is whether an exception should be thrown, or the offending paths should silently be left out of the glob.

Users are allowed to know that the inaccessible directory exists, because it exists in a directory which they do have list access to.

For example if you had

{code}
/           with permission 0755
/secret     with permission 0700
/mundane    with permission 0777
{code}

The question is whether /* by an unprivileged user should throw an exception, or simply return "/mundane".  The unprivileged user is allowed to know that /secret exists, since it is located in a directory which he has list permission for, e.g. the root directory., ok, that was a bad example since it would succeed.  (Wish I could edit comments!)  The point is that something like /*/foo would fail since it would try to recurse into the /secret subdirectory., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12601536/HADOOP-9929.001.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3064//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3064//console

This message is automatically generated., Andre, I tried to reproduce this on branch-2.1-beta, and was unable to do so.

{code}
cmccabe@keter:~/hadoopST/branch-2.1-beta> /h/bin/hadoop fs -ls /
cmccabe@keter:~/hadoopST/branch-2.1-beta> /h/bin/hadoop fs -mkdir /a
cmccabe@keter:~/hadoopST/branch-2.1-beta> /h/bin/hadoop fs -chmod 0000 /a
cmccabe@keter:~/hadoopST/branch-2.1-beta> /h/bin/hadoop fs -mkdir /a/b
su other
d---------   - cmccabe supergroup          0 2013-09-18 13:57 hdfs://localhost:6000/a
other@keter:/home/cmccabe/hadoopST/branch-2.1-beta> /h/bin/hadoop fs -ls hdfs://localhost:6000/a/b
ls: Permission denied: user=other, access=EXECUTE, inode="/a":cmccabe:supergroup:d---------
other@keter:/home/cmccabe/hadoopST/branch-2.1-beta> /h/bin/hadoop fs -ls hdfs://localhost:6000/*/b
ls: Permission denied: user=other, access=EXECUTE, inode="/a":cmccabe:supergroup:d---------
{code}

I also looked at the code in branch-2.1-beta, and was unable to see why this bug would exist there.  So I would like to remove branch-2.1-beta from the versions fields, unless someone else can reproduce this., Just to be clear, the bug exists in branch-2.  Just not in branch-2.1-beta.  Let's update the JIRA accordingly., I also fired up a pseudodistributed 2.1 cluster and can't reproduce, so I think it's related to the Globber rewrite which is only in branch-2. Setting affects version appropriately., Patch looks good to me, but needs to be rebased a bit since we reverted HADOOP-9877.

+1 pending rebase and Jenkins., fixed in 2.3, SUCCESS: Integrated in Hadoop-trunk-Commit #4439 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4439/])
HADOOP-9929. Insufficient permission for a path reported as file not found.  (Contributed by Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524611)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Globber.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java
, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12603965/HADOOP-9929.002.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3110//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3110//console

This message is automatically generated., SUCCESS: Integrated in Hadoop-Yarn-trunk #337 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/337/])
HADOOP-9929. Insufficient permission for a path reported as file not found.  (Contributed by Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524611)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Globber.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1553 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1553/])
HADOOP-9929. Insufficient permission for a path reported as file not found.  (Contributed by Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524611)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Globber.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1527 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1527/])
HADOOP-9929. Insufficient permission for a path reported as file not found.  (Contributed by Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1524611)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Globber.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java
]