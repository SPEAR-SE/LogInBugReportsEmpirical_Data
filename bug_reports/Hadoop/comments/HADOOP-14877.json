[I'm getting different failures

Issue 1: command line for javah too big. Fix: build local maven-native-plugin java 1.0.9-SNAPSHOT and set the <useenv> option. This gets hadoop-common to build.
Issue 2: hadoop-hdfs not compiling with xref issues. Not seen this before. protoc? Paths? Case logic? 

Oddly enough, it's imports of inner enums which aren't being found.
{code}
[ERROR] /C:/Work/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java:[77,72] cannot find symbol
[ERROR] symbol:   class AccessMode
[ERROR] location: class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier
{code}

This file is in hadoop-client, and I've verified that the file BlockTokenIdentified$AccessMode.class is in the compiled directory tree. Not getting into JAR, wrong JAR version, CP setup for javac?, patch 001: On windows builds, use the 1.0-alpha-9-SNAPSHOT native maven plugin, and so switch to the CLASSPATH env var, avoiding command line length problems.

I was  having problems with my build because the maven clean wasn't taking until the hadoop maven plugin was built; there's a bootstrap problem. Until have done a full clean, old cruft can hang around, creating problems.


# run mvn clean to purge old bits, and make sure that it had completed
# run mvn install -DskipTests -DskipShade to do the install, making sure that the hadoop-maven-plugin had been built.
# rerun mvn clean
# rerun mvn install
# do the mvn package -Pdist -DskipTests -Dmaven.javadoc.skip=true -DskipShade 

, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  8s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 43m 27s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  6s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 19s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 15s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 80m 44s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |
|   | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HADOOP-14877 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12903076/HADOOP-14877-001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  xml  |
| uname | Linux 1e20b9784012 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 13ad747 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13862/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13862/testReport/ |
| Max. process+thread count | 1766 (vs. ulimit of 5000) |
| modules | C: hadoop-project hadoop-common-project/hadoop-common U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13862/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, bq.Issue 1: command line for javah too big. Fix: build local maven-native-plugin java 1.0.9-SNAPSHOT and set the <useenv> option. This gets hadoop-common to build.
This I fixed by setting the repo path shorter (i.e -Dmaven.repo.local=D:/repo).Same I have suggested in user [mailing list|https://mail-archives.apache.org/mod_mbox/hadoop-common-dev/201702.mbox/%3CDM3PR18MB079583B2B7578530E7657FDDE14C0@DM3PR18MB0795.namprd18.prod.outlook.com%3E].Hope you also getting the same. Your patch make sense to me,as we can't retrict. 
bq.Issue 2: hadoop-hdfs not compiling with xref issues. Not seen this before. protoc? Paths? Case logic?
I didn't face this issue.and {{mvn package -Pdist -DskipTests -Dmaven.javadoc.skip=true -DskipShade}} will success in my PC.

Coming to this jira, this will come always,if we execute without "{{-DskipShade}}"(i.e {{mvn clean install -DskipTests}}) since winddows path seperator is not handled in [ensure-jars-have-correct-contents.sh|https://github.com/apache/hadoop/blob/trunk/hadoop-client-modules/hadoop-client-check-invariants/src/test/resources/ensure-jars-have-correct-contents.sh#L63], {{ -Dmaven.repo.local=D:/repo).}} should do, & better than using snapshot plugins. 

Needs a doc update, bq.Needs a doc update
Ok,this can be handle in seperate jira.? Since this jira is for different..?

and better to update [TroubleShooting|https://wiki.apache.org/hadoop/TroubleShooting]..?
, * we need to move the old wiki entries to confluent
* given this JIRA exists, I think the docs can go in here]