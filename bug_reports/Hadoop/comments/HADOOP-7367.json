[A few points:

* The inclusion of this routine is preventing the native code from being compiled on platforms where it previously worked.

* We have multiple ways to try to solve this:
a) Rewrite the entire routine to remove the dependency on getgrouplist()
b) Do auto-detection to use the built-in getgrouplist, otherwise use one we supply
c) Use the current version when getgrouplist is present, otherwise use a completely different code stream that uses getgrent() etc., It also appears this code doesn't work on OS X... which is... interesting., From the bit of playing I've done, getgrouplist on OS X doesn't update ngroups to have the total number of groups the user is in.  Since the first call uses 0, it returns 0, which then dumps out of the rest of the loop.

So a fix here needs to take that into consideration.  (It may be worthwhile to just use sysconf(_POSIX_NGROUPS_MAX) for the first call so that getgrouplist mostly works on OS X and others with different semantics than the Linux version)., Several things about this patch:

* A check has been added to configure to look for a getgrouplist routine
* If it is found, we use a getgrouplist routine that tries to do it all in one pass, based upon allocating POSIX_NGROUPS_MAX groups (up to 32) for the initial buffer.  If the user has more than 32, we depend upon getgrouplist properly returning the number of groups for the user.  (So this will only match the first 32 on Darwin)
* If getgrouplist isn't there, we run through the entire groups db, looking for entries.

Please note that at least Solaris requires _POSIX_PTHREAD_SEMANTICS defined for the 5 param version of get*_r.  I'll cover that in a separate patch., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12481884/hadoop-7367.patch
  against trunk revision 1133125.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/596//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/596//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/596//console

This message is automatically generated., Adding the regression and 0.20.203 info, since this broke functionality that previously worked due to the compression codecs being in the same library.  (Maybe libhadoop.so needs to get broken up?), Hadoop is not focused on portability.  Patch is here for those that need it though., I've been posting these as one since it is easier that way.]