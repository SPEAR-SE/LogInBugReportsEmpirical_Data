[This is captured from our test output, seems like the DataBlockScanner is really slow coming up with verification results even though our data/file generated in the tests are minimal.

{noformat}
13/05/04 06:50:55 INFO hdfs.StateChange: BLOCK* NameSystem.allocateBlock: <our_test_file_name.lzo>-f773a37f-3dac-4337-a6cb-004fb94c1d31. blk_-8485988660073681466_1002
13/05/04 06:50:55 INFO datanode.DataNode: Receiving block blk_-8485988660073681466_1002 src: /127.0.0.1:42563 dest: /127.0.0.1:35830
13/05/04 06:50:55 INFO DataNode.clienttrace: src: /127.0.0.1:42563, dest: /127.0.0.1:35830, bytes: 303, op: HDFS_WRITE, cliID: DFSClient_-854844208, offset: 0, srvID: DS-1070312150-10.35.8.106-35830-1367650255272, blockid: blk_-8485988660073681466_1002, duration: 778000
13/05/04 06:50:55 INFO datanode.DataNode: PacketResponder 0 for block blk_-8485988660073681466_1002 terminating
13/05/04 06:50:55 INFO hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:35830 is added to blk_-8485988660073681466_1002 size 303
13/05/04 06:52:48 INFO datanode.DataBlockScanner: Verification succeeded for blk_-8485988660073681466_1002
13/05/04 07:00:40 INFO datanode.DataBlockScanner: Verification succeeded for blk_586310994067086116_1001
{noformat}


Could this be related to this bug: HADOOP-4584?, What's the thread doing on the NN side? Keep in mind you're on a very old version (and a twitter-local build that no one else has), so you may not have a lot of luck getting people to help you diagnose farther., Can you please see if you can duplicate this issue on an Apache release. It most likely will happen on Apache release as well. If not, is it a good idea to move this to CDH related jiras?, Will try to see if this is something specific to environment and update this JIRA. ]