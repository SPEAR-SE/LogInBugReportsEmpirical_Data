[Here are the counters from the two run. 

First ====
	Counter 	Map 	Reduce 	Total
Job Counters 	Launched map tasks 	0 	0 	512
Launched reduce tasks 	0 	0 	60
Data-local map tasks 	0 	0 	41
Map-Reduce Framework 	Map input records 	311,740,575 	0 	311,740,575
Map output records 	*311,740,575* 	0 	311,740,575
Map input bytes 	41,488,968,916 	0 	41,488,968,916
Map output bytes 	129,088,071,619 	0 	129,088,071,619
Reduce input groups 	0 	53,332,945 	53,332,945
Reduce input records 	0 	*311,680,380* 	311,680,380
Reduce output records 	0 	311,680,380 	311,680,380

Second.====

	Counter 	Map 	Reduce 	Total
Job Counters 	Launched map tasks 	0 	0 	512
Launched reduce tasks 	0 	0 	60
Data-local map tasks 	0 	0 	42
Map-Reduce Framework 	Map input records 	311,740,575 	0 	311,740,575
Map output records 	*311,740,575* 	0 	311,740,575
Map input bytes 	41,488,968,916 	0 	41,488,968,916
Map output bytes 	129,088,071,619 	0 	129,088,071,619
Reduce input groups 	0 	53,343,415 	53,343,415
Reduce input records 	0 	*311,740,575* 	311,740,575
Reduce output records 	0 	311,740,575 	311,740,575
, Thanks Koji for this excellent bug report! I found a problem. Here's the scenario:

Thread1: 
1) The ramfs merge thread is waiting to do InMemoryFileSystem.getFiles()

Thread2:
1) The ReduceTask locks itself.
2) It invokes rename for a file, F1, that it just shuffled, in the ramfs.
3) The rename in the ChecksumFileSystem gets called and finishes renaming the actual file but before it could not do rename of the checksum file, thread switch happened. Thread1 gets control.

Thread1:
2) It now calls InMemoryFileSystem.getFiles(), and initiates merge. In the process of merge, it deletes the ramfs file, F1. Note that the checksum file is optional and if it is not found, ChecksumFSInputChecker silently ignores it.

At some point later on, Thread2 gets control and tries to do rename of the checksum file and since the real file is not there anymore, the second call to isDirectory in ChecksumFileSystem.rename results in a NPE (as in the reported stack trace).

Attached is a patch that will address the above problem. Just makes the call to getFiles synchronized on the ReduceTask object., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12372141/2486.patch
against trunk revision r606333.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1423/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1423/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1423/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1423/console

This message is automatically generated., I just committed this., Integrated in Hadoop-Nightly #346 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/346/])]