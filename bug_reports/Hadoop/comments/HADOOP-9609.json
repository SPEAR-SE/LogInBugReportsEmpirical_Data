[Attach a patch. The fix is simple, i.e. I just reused the code in 'package' target., Thanks Chuan for reporting the problem and for the patch!

Your patch seem to introduce a different behavior on Linux platforms. I don’t think we want to do this (see HADOOP-8037 for some history on what it’s done in packageBinNativeHadoop.sh). I see two possible alternatives we can move forward with:
1.	Use packageNativeHadoop.py for both package and bin-package target when on Windows, but still use packageBinNativeHadoop.sh when on Linux. This would be a quick and simple fix for this Jira.
2.	Create packageBinNativeHadoop.py that would be a Windows equivalent of packageBinNativeHadoop.sh. This would however require a bit more work, as we’d want to satisfy the idea behind the bin-package target, which is to produce a platform specific target (for example, on Windows this would be hadoop-x.y.z-amd64-bin.winpkg.zip). 

I am personally fine with both approaches. Let me know what you think. , Thanks for reviewing the patch! I did notice the difference between packageNativeHadoop and packageBinNativeHadoop.

After taking a look at HADOOP-8037, I think your approach 1 makes more sense. In HADOOP-8037, the main reason to create platform (x64 vs amd64) dependent destinations was to accommodate Linux packaging requirements. On Linux, we have install scripts that will install the binaries to different destinations (/usr/lib vs /usr/lib64) and set java.library.path accordingly in .deb and .rpm packages. On Windows, we don't do such things, and it makes more sense to use 'package' settings, i.e. put the binary under 'lib/native'. Also the platform is already part of the path, so there will be no confusing.

I still need to create a packageBinNativeHadoop.py because [Ant exec|http://ant.apache.org/manual/Tasks/exec.html] does not support 'if' condition.

I have tested building on Windows and Ubuntu, and both passes., Thanks Chuan, sounds good.

I noticed one difference between the new script and original sh script. You will copy hadoop libraries to $DIST_LIB_DIR/platform, while the original script copied them to $DIST_LIB_DIR when on Linux. right?, bq. You will copy hadoop libraries to $DIST_LIB_DIR/platform, while the original script copied them to $DIST_LIB_DIR when on Linux. right?

Nice catch! Attaching a new patch., +1 for the patch.  I believe the latest patch has addressed the last round of feedback.  I'm going to wait a day before committing, just in case [~ivanmi] has additional feedback., I've committed this to branch-1-win.  Thank you to Chuan for contributing the patch, and thank you to Ivan for the code reviews.]