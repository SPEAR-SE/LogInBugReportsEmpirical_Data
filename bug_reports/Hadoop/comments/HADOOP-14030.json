[Saw the failure in other PreCommit tests as early as 12/29/16: https://issues.apache.org/jira/browse/HADOOP-13433?focusedCommentId=15784819&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15784819, Also seeing these here HADOOP-14041, I'm also seeing it at https://builds.apache.org/job/PreCommit-HADOOP-Build/11651/testReport/

FYI [~steve_l]. Thanks.
, Also seeing this in HADOOP-14062., Looking at this; not seeing anything obvious. It's appearing in promptForPassm, implying the keytab wasn't working for login and it fell back to password input, which of course failed. 

Looking at the code, the only thing which appears to have changed immediately before this JIRA was filed in HADOOP-13433, which went near UGI relogin, but not, at least on a quick glance, the initial login.

I'm going to tag this as caused by that work; the timetable lines up. Why only on precommit tests? JVM/platform, I suspect, Provisionally tagging as caused by HADOOP-13433

[~Apache9] : could you look at this. We may need to get some extra diags into trunk just so we can diagnose what's happening in the JVM. That may not be so bad: kdiag should be fielding that stuff. Indeed, maybe it should be looking at strack traces some more, Yeah we only change the code in relogin in HADOOP-13433. Let me see what's going on here., [~stevel@apache.org] Usually a '-Dsun.security.krb5.debug=true' can tell you everything. But seems the output files of precommit job does not include the test output, so how can we get the extra logs out?, we can try and look at a new patch, it won't have the old stuff lost. Otherwise, we could submit a patch here which just turned on the logging and cranked up log4j just for diagnostics, OK, seems we can the logs from this page

https://builds.apache.org/job/PreCommit-HADOOP-Build/11847/testReport/junit/org.apache.hadoop.security/TestKDiag/testKeytabAndPrincipal/

So let me see how can we add the ''-Dsun.security.krb5.debug=true' when running tests., Any update on this?  This test keeps popping up on precommit builds., I am pretty sure I've got to the bottom of it. Will post a patch soon.

Basically it has race condition with the tests in TestRaceWhenRelogin, which overwrites the same keytab file., Thanks for taking this up. For TestRaceWhenRelogin, IIRC it sometimes fails locally either. There is a UT to test the code added in HADOOP-13433 directly, and the TestRaceWhenRelogin is something like a monkey test to make sure that there is no other problem, but seems we do have other problems, maybe deep in the JDK implementation.

So if after your patch the TestRaceWhenRelogin is still flakey then I suggest we just remove it.

Thanks., aah, its to do with parallel test runs. Lovely find, I started with this Jenkins precommit build: https://builds.apache.org/job/PreCommit-HADOOP-Build/13543
If you look at any of the TestKDiag output, like this one: https://builds.apache.org/job/PreCommit-HADOOP-Build/13543/testReport/org.apache.hadoop.security/TestKDiag/testKeytabAndPrincipal/

You will find 12 principals in the keytab: client, server, server1 through server10, which suggests the keytab is generated by someone else, maybe a leftover or a race condition.

{noformat}
== Examining keytab /testptch/hadoop/hadoop-common-project/hadoop-common/target/keytab ==

keytab principal count: 12
 server/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server9/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server9/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server7/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server7/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server8/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server8/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server2/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server2/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server3/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server3/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 client@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 client@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server1/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server1/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server4/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server4/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server0/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server0/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server6/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server6/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
 server5/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=DES3_CBC_SHA1
 server5/localhost@EXAMPLE.COM: version=1 expires=generalized time [tag=0x18, len=2+15] Wed Oct 18 11:27:16 UTC 2017 encryption=AES128_CTS_HMAC_SHA1_96
keytab entry count: 24
{noformat}

The only test that generates that many keytab principals is TestRaceWhenRelogin.

Further, this set of TestKDiag tests started at Wed Oct 18 11:27:16, and TestRaceWhenRelogin also started around the same time: https://builds.apache.org/job/PreCommit-HADOOP-Build/13543/testReport/org.apache.hadoop.security/TestRaceWhenRelogin/test/
{noformat}
2017-10-18 11:27:16,715 INFO  minikdc.MiniKdc (MiniKdc.java:<init>(225)) - Configuration:
{noformat}

If you look at keytab location of both tests, they actually generate keytabs at the same directory, same file name. So it looks like a race condition between parallel tests for me.

I suggest we use a randomized file name or directory for keytabs. Other tests are likely prone to this bug as well., Posting a one-liner fix in TestKDiag.

This patch stops sharing keytab file location with other tests. The new keytab file is at target/test/data/TestKDiag/keytab., LGTM. Have you looked at where other mini KDCs are being instantiated? Do we need this fix more broadly?, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} docker {color} | {color:red}  2m 50s{color} | {color:red} Docker failed to build yetus/hadoop:0de40f0. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-14030 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893036/HADOOP-14030.001.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13553/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Thanks [~stevel@apache.org] for the review.
This is TestKDiag only. I've studied a few other KDC usage a bit, but it's quite broad and I've not seen errors happening from them that often. Will file another jira to investigate that further., OK. see if you can get yetus to run the tests; I'm pretty happy with what you've done, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  8m 54s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 24s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 4 unchanged - 1 fixed = 4 total (was 5) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 47s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 28s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 45s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 84m 20s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.net.TestClusterTopology |
|   | hadoop.ha.TestZKFailoverController |
|   | hadoop.net.TestDNS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:ca8ddc6 |
| JIRA Issue | HADOOP-14030 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893036/HADOOP-14030.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux ad5362e612c5 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b90750c |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13564/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13564/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13564/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Well, TestKDiag didn't fail

+1

well done for tracking this down, +1, thanks!, Committed this to trunk and branch-3.0. Thanks [~jojochuang] for the fix, and thanks [~stevel@apache.org] for the review, and thanks all who contributed to this issue!]