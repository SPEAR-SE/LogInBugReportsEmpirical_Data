[Which file/line is making your IDE unhappy?  I don't see the exact line, but I think you are referring to the copymerge command?  I see that it's opening the file inside of a try block with a finally clause that closes the stream.  It looks like the open - the first line of the try - should be moved to line before the try., 
Sorry, I should have given more detail.
yes, that's what it's complaining about, and yes, moving it up would be the other solution. 

If done rigorously a test ought to go with the patch too, but it is a very small change..., Moved the {{is=src.fs.open()}} out the try/catch block, Patch as suggested by Daryn, pull the assignment up. No tests., +1 Perfect.  I was about to throw up the same patch., I'll see if I can find some of the tests I wrote for getmerge but didn't post because the hdfs cli tests were broken at the time., Didn't find them.  I tried to write a test, but I don't think it's (easily) possible.  I tried inducing an open failure via permissions.  Even setting the perms on a file to 000, the test user is considered a superuser to the mini cluster, so it walks right through the permissions..., On second thought, do you think it would be better to scope the var and do:
{code}
       try {
-        FSDataInputStream in = null;
         for (PathData src : srcs) {
+          FSDataInputStream in = src.fs.open(src.path);
           try {
-            in = src.fs.open(src.path);
             IOUtils.copyBytes(in, out, getConf(), false);
{code}, My previous suggestion, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12518735/HADOOP-8179.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in .

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/723//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/723//console

This message is automatically generated., Regarding no test, I was able to test locally by: starting a mini-cluster, creating a file with insufficient privs for different user (non-superuser) to access, then tried to access the file with that different user.  I saw the NPE before, but not after, the patch., Hi Daryn, Patch mostly looks good. I have other suggestion to do.

{code}
             if (delimiter != null) {
               out.write(delimiter.getBytes("UTF-8"));
             }
-          } finally {
             in.close();
-          }
+	    in = null;
+	  } finally {
+	    IOUtils.closeStream(in);
+	  }
         }
+        out.close();
+	 out = null;
       } finally {
-        out.close();
+	 IOUtils.closeStream(out);
       }      
     }

{code}

closing stream in finally may mask the root exceptions if any exception in finally.
So, i would prefer this pattern to close the streams. Let's close the stream in try itself and nullify if that is success. We can use IOUtils.closeStream in finally. It won't try to close the stream if that is null., Good eye, but I'm actually fixing the close issue on a separate jira.  Just an aside, using IOUtils to close the output stream is inappropriate because it will mask exceptions that may be related to finalizing the block., On further thought, you are right that it may be useful to conditionally use IOStreams.close on the output stream based on whether an exception has already thrown., The patch looks simple enough that no unit tests are needed and it fixes the observed issue.  +1, Thanks Daryn, I just put this into trunk, branch-2, and branch-0.23, Integrated in Hadoop-Hdfs-trunk-Commit #2072 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2072/])
    HADOOP-8179. risk of NPE in CopyCommands processArguments() (Daryn Sharp via bobby) (Revision 1309572)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1309572
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java
, Integrated in Hadoop-Common-trunk-Commit #1997 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/1997/])
    HADOOP-8179. risk of NPE in CopyCommands processArguments() (Daryn Sharp via bobby) (Revision 1309572)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1309572
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java
, Integrated in Hadoop-Mapreduce-trunk-Commit #2009 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2009/])
    HADOOP-8179. risk of NPE in CopyCommands processArguments() (Daryn Sharp via bobby) (Revision 1309572)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1309572
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java
, Integrated in Hadoop-Hdfs-0.23-Build #219 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/219/])
    svn merge -c 1309572 from trunk.  FIXES HADOOP-8179. risk of NPE in CopyCommands processArguments() (Daryn Sharp via bobby) (Revision 1309574)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1309574
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java
, Integrated in Hadoop-Hdfs-trunk #1006 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1006/])
    HADOOP-8179. risk of NPE in CopyCommands processArguments() (Daryn Sharp via bobby) (Revision 1309572)

     Result = FAILURE
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1309572
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java
, Integrated in Hadoop-Mapreduce-trunk #1041 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1041/])
    HADOOP-8179. risk of NPE in CopyCommands processArguments() (Daryn Sharp via bobby) (Revision 1309572)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1309572
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java
]