[Hi, can you tell us what is the configuration for the capacity scheduler ? Have you changed any of the defaults ? Have you added any queues ?, I've added a single queue and has not changed any defaluts. I'm using hadoop-0.20.0.  I used the capcity scheduler in contrib/ of hadoop. The fair scheduler is working fine. The queues of capacity scheduler are also being listed in the jobtrackerUI as long as namenode is in safemode. Once the namenode goes out of the safemode the jobtracker gets stopped. , It would help me if you can provide the following information:

- The value of mapred.queue.names from mapred-site.xml (or hadoop-site.xml, if you're using the older format)
- The contents of capacity-scheduler.xml on the jobtracker node (if you can attach the file to this JIRA, that would help).

FYI, I am trying to debug the exception you've reported in the description above. It may or may not be related to the jobtracker 'stopping' to work after the namenode comes out of safemode. We can go one problem at a time.

, I am attching the files hadoop-site.xml and capacity-scheduler.xml in hadoop-0.19.1. While working with this version too the same errors are being generated.
, I think the problem is that the key mapred.queue.names in hadoop-site.xml has a space at the end. AFAIK, this does not work. Can you please try removing the space and try ?, Thank you.I'll try it out. It never came to my notice. Thanks a lot., Sir, I tried removing the space, but still it does not work. This is the case with both 0.19.1 as well as 0.20.0. The same errors are being generated even after removing the space. , Yikes. I noticed another error, probably the more important one. You have this in the mapred-site.xml:

{noformat}
  <property>
    <name>mapred.job.tracker</name>
    <value>hdfs://localhost:9001</value>
  </property>
{noformat}

The value of this configuration variable should just be localhost:9001. It is not a URI, and definitely should not be prepended with 'hdfs://' which is the name of a filesystem URI. Can you please retry with this ?, sorry sir... but this too does not work. I tried this out too. can you think of any reason why the namenode is going to the safemode as soon as we start running it. , The namenode goes into the safemode if you are starting on an existing installation of HDFS. This is the time when it reconstructs state from the transaction logs that it has written. It also waits until it has information from the datanodes about blocks they have, etc. It is not a problem for the namenode to go into safemode at startup. If it doesn't automatically come out of it, then that could be a problem. So, is the namenode coming out of safemode ? And if you don't want to start on an existing installation, you must format the filesystem before you start. All this information is available at the Forrest documentation here: http://hadoop.apache.org/core/docs/r0.20.0/hdfs_user_guide.html.

So, let us step back and see the problem statement: You are starting a cluster. The namenode goes into safemode and comes out of it (maybe you forcibly do this - using the dfsadmin command). Then the jobtracker goes down. This is happening only if you use the capacity scheduler, but not if you use the fairshare scheduler. Is this right so far ?

Now that we've fixed the configuration, I think we could look at the logs. Can you please upload the jobtracker log to begin with ?

 

, sorry abt the late response. whatever you have reported is right. that is the problem.
the namenode is automaticaly coming out of the safemode without forcing it out. No job can be run because the jobtracker stops as soon as the namenode comes out of the safemode.
The jobtracker log is attached. , the attachment is of version-0.19.1.  , 2009-06-22 18:20:38,850 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2009-06-22 18:20:38,961 FATAL org.apache.hadoop.mapred.JobTracker: org.apache.hadoop.mapred.JobTracker$IllegalStateException: System has no default queue configured
	at org.apache.hadoop.mapred.CapacityTaskScheduler.start(CapacityTaskScheduler.java:1033)
	at org.apache.hadoop.mapred.JobTracker.offerService(JobTracker.java:1283)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:2791)


I can see following exception in the log , in the earlier versions of capacity scheduler we are specifically checking for a queue Name 
"default".

Please create 1 more queue by name "default" and also add respective entries in capacity-scheduler.xml with proper settings , or change your existing queue name "q1" to "default" .

I hope this helps. 
If you say further issues , do attach the logs and respective config files.

, I tried that too. But still the problem persists. Two queues q1 and default were used. Attaching the log files. Now it also shows the problem of the namenode not coming out of the safemode automatically. Once it is forced out of safemode, the jobtracker stops running.   , Should be moved to the list.]