[[~cnauroth]

Could you take a look?, Good catch Duo. Thanks for fixing this., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12695335/HADOOP-11523.1.patch
  against trunk revision 89b0749.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-azure.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5536//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5536//artifact/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5536//console

This message is automatically generated., Hi Duo.  Thank you for the patch.

The current patch would acquire the lease for all {{rename}} operations, covering both block blobs and page blobs.  During initial development of atomic rename, we were careful to limit the scope to only page blobs (typically used by HBase logs).  Existing applications using block blobs might not be expecting the leases, so I think we need to make sure the lease acquisition only happens after checking {{AzureNativeFileSystemStore#isAtomicRenameKey}}.

In the error handling, if an exception is thrown from the try block, and then another exception is also thrown from freeing the lease, then this would drop the original exception and throw the exception from freeing the lease.  I suspect in general the main exception from the try block is going to be more interesting for root cause analysis, so I recommend throwing that one and just logging the one from freeing the lease, like so:

{code}
        } finally {
          try {
            if (lease != null) {
              lease.free();
            }
          } catch (Exception e) {
            LOG.error("Unable to free lease on " + parentKey, e);
          }
        }
{code}

In addition to the unit tests, I ran the test suite against a live Azure storage account and confirmed that everything passed.

The release audit warning from Jenkins is unrelated to this patch., Hi, [~cnauroth]

Current HBase clusters in Azure, our configuration is
{code}
"Name": "fs.azure.page.blob.dir", "Value": "\/hbase\/WALs,\/hbase\/oldWALs"
{code}

In the exception above, WASB tried to update folder/blob "hbase/data/default/tdelrowtbl/3c842e8823c192d1028dc72ac3f22886/recovered.edits". This is apparently not a page blob. So lease acquisition is needed in block blob, at least for HBase.

For the error handling, agree and I have attached a new patch., bq. This is apparently not a page blob.

Sorry, I mixed up 2 different concepts: page blobs and atomic rename.  If a path is configured for atomic rename, that doesn't necessarily imply that it's a page blob.

What is your setting for {{fs.azure.atomic.rename.dir}}?  I suspect it covers the path that you mentioned.  This is why I suggested a check on {{AzureNativeFileSystemStore#isAtomicRenameKey}}.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12695364/HADOOP-11523.2.patch
  against trunk revision ad55083.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-azure.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5537//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5537//artifact/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5537//console

This message is automatically generated., [~cnauroth]

I looked at AzureNativeFileSystemStore#isAtomicRenameKey, it will check if the key is in the set of atomicRenameDirs. And from AzureNativeFileSystemStore#initialize, I saw it will add hbase root dir into it. 
{code}
      // Add to this the hbase root directory, or /hbase is that is not set.
      hbaseRoot = verifyAndConvertToStandardFormat(
          sessionConfiguration.get("hbase.rootdir", "hbase"));
      atomicRenameDirs.add(hbaseRoot);
{code}

This means all HBase folders are eligible for atomic rename, right? For fs.azure.atomic.rename.dir, in our PROD clusters, it is not set. So atomicRenameDirs only contains "/hbase".

In this way, I am OK to add it, so that lease acquisition e will only apply to folders under /hbase.

I have updated the patch.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12695371/HADOOP-11523.3.patch
  against trunk revision ad55083.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-azure.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5538//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5538//artifact/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5538//console

This message is automatically generated., Thanks, [~onpduo].  I have just 2 more minor nitpicks.  I suggest changing this:
{code}
              LOG.error("Unable to free lease on " + parentKey);
{code}

to this:
{code}
              LOG.error("Unable to free lease on " + parentKey, e);
{code}

This way, we'll log the full stack trace on lease free errors and have more information for troubleshooting.

This is just a minor style point, but for the following, the keyword should be inline with the closing brace.  Instead of this:

{code}
          }
          finally {
{code}

We do this:
{code}
          } finally {
{code}

Instead of this:
{code}
        }
        else {
{code}

We do this:
{code}
        } else {
{code}
, [~cnauroth]

Thanks for pointing these out. I have updated the patch., +1 for patch v4 pending a fresh Jenkins run., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12695400/HADOOP-11523.4.patch
  against trunk revision e36ef3b.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-azure.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5541//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5541//artifact/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5541//console

This message is automatically generated., I have committed this to trunk and branch-2.  Duo, thank you for the contribution., FAILURE: Integrated in Hadoop-trunk-Commit #6968 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6968/])
HADOOP-11523. StorageException complaining " no lease ID" when updating FolderLastModifiedTime in WASB. Contributed by Duo Xu. (cnauroth: rev f2c91098c400da6db0f5e8e49e9bf0e6444af531)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #89 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/89/])
HADOOP-11523. StorageException complaining " no lease ID" when updating FolderLastModifiedTime in WASB. Contributed by Duo Xu. (cnauroth: rev f2c91098c400da6db0f5e8e49e9bf0e6444af531)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #823 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/823/])
HADOOP-11523. StorageException complaining " no lease ID" when updating FolderLastModifiedTime in WASB. Contributed by Duo Xu. (cnauroth: rev f2c91098c400da6db0f5e8e49e9bf0e6444af531)
* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk #2021 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2021/])
HADOOP-11523. StorageException complaining " no lease ID" when updating FolderLastModifiedTime in WASB. Contributed by Duo Xu. (cnauroth: rev f2c91098c400da6db0f5e8e49e9bf0e6444af531)
* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #86 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/86/])
HADOOP-11523. StorageException complaining " no lease ID" when updating FolderLastModifiedTime in WASB. Contributed by Duo Xu. (cnauroth: rev f2c91098c400da6db0f5e8e49e9bf0e6444af531)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #90 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/90/])
HADOOP-11523. StorageException complaining " no lease ID" when updating FolderLastModifiedTime in WASB. Contributed by Duo Xu. (cnauroth: rev f2c91098c400da6db0f5e8e49e9bf0e6444af531)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #2040 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2040/])
HADOOP-11523. StorageException complaining " no lease ID" when updating FolderLastModifiedTime in WASB. Contributed by Duo Xu. (cnauroth: rev f2c91098c400da6db0f5e8e49e9bf0e6444af531)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java
]