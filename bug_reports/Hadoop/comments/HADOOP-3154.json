[Once the disk problem was away, jobs ran as expected. 

Comparing the output, we saw that size of the final output differed in all the reducers. 

Looking at one of the successful mapper userlogs, 


userlogs/task_200803290844_0001_m_000012_0/syslog
{noformat}
2008-03-29 08:46:40,731 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=MAP, sessionId=
2008-03-29 08:46:40,985 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 15
2008-03-29 08:46:41,208 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2008-03-29 08:46:41,210 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2008-03-29 08:50:36,115 INFO org.apache.hadoop.mapred.TaskRunner: Task 'task_200803290844_0001_m_000012_0' done.
{noformat}

userlogs/task_200803290844_0001_m_000012_0/stderr
{noformat}Exception in thread "SortSpillThread" org.apache.hadoop.fs.FSError: java.io.IOException: No space left on device
        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:171)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:41)
        at java.io.DataOutputStream.write(DataOutputStream.java:90)
        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.writeChunk(ChecksumFileSystem.java:339)
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:141)
        at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:100)
        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:86)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:41)
        at java.io.DataOutputStream.write(DataOutputStream.java:90)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:990)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.spill(MapTask.java:555)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpillToDisk(MapTask.java:497)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.access$200(MapTask.java:264)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer$1.run(MapTask.java:439)
Caused by: java.io.IOException: No space left on device
        at java.io.FileOutputStream.writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:260)
        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:169)
        ... 15 more
{noformat}

I didn't see task_200803290844_0001_m_000012 retried elsewhere.

Seems like SortSpillThread is not catching the FSError and dying silently.
(Note the ' java.io.IOException: No space left on device' is converted to FSError in RawLocalFileSystem.java)
, This patch is for trunk. I wonder whether we should fix this in 16 too., Thanks for the quick patch!

bq. I wonder whether we should fix this in 16 too.

+1. Please.
, I am assigning this issue to Chris since the patch for HADOOP-3166 makes this patch redundant. I'll submit a separate patch for 0.16., This patch is intended for the 0.16 branch., +1

I just committed this to the 0.16 branch. Thanks, Deveraj!, Integrated in Hadoop-trunk #451 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/451/])]