[
You can add following code to files "hdfs-config.sh" and "mapred-config.sh".

this="${BASH_SOURCE-$0}"
while [ -h "$this" ]; do
  ls=`ls -ld "$this"`
  link=`expr "$ls" : '.*-> \(.*\)$'`
  if expr "$link" : '.*/.*' > /dev/null; then
    this="$link"
  else
    this=`dirname "$this"`/"$link"
  fi  
done

# convert relative path to absolute path
common_bin=`dirname "$this"`
script=`basename "$this"`
common_bin=`cd "$common_bin"; pwd`
this="$common_bin/$script"

# the root of the Hadoop installation
#TODO: change the env variable when dir structure is changed
export HADOOP_HOME=`dirname "$this"`/..
export HADOOP_COMMON_HOME="${HADOOP_HOME}"
, Sorry for the weird formatting in my last comment.

this="${BASH_SOURCE-$0}"
while [ -h "$this" ]; do
  ls=`ls -ld "$this"`
  link=`expr "$ls" : '.*-> \(.*\)$'`
  if expr "$link" : '.*/.*' > /dev/null; then
    this="$link"
  else
    this=`dirname "$this"`/"$link"
  fi  
done

\# convert relative path to absolute path
common_bin=`dirname "$this"`
script=`basename "$this"`
common_bin=`cd "$common_bin"; pwd`
this="$common_bin/$script"

\# the root of the Hadoop installation
\#TODO: change the env variable when dir structure is changed
export HADOOP_HOME=`dirname "$this"`/..
export HADOOP_COMMON_HOME="${HADOOP_HOME}", From Tom: this is a regression from 0.20, To avoid this issue, you can configure HADOOP_HOME in environment.

For example in Cygwin, just do as below:
  export HADOOP_HOME=/cygdrive/c/hadoop/, Tom, any update on this for 0.22?, Yes, please see the linked JIRAs HDFS-1823 and MAPREDUCE-2428 for the patches. There is no common part, so this JIRA can be closed when the linked JIRAs are.]