[We should also check for zero input files in {{FileInputFormat.validateInput(JobConf)}} and throw an {{InvalidInputException}} in the first place. 

Something along the lines of:
{noformat}
Index: /home/arun/dev/java/hadoop/HADOOP-1881/src/java/org/apache/hadoop/mapred/FileInputFormat.java
===================================================================
---src/java/org/apache/hadoop/mapred/FileInputFormat.java	(revision 588140)
+++ src/java/org/apache/hadoop/mapred/FileInputFormat.java	(working copy)
@@ -150,6 +150,9 @@
         }
       }
     }
+    if (totalFiles == 0) {
+      result.add(new IOException("Found zero input files"));
+    }
     if (!result.isEmpty()) {
       throw new InvalidInputException(result);
     }
{noformat}
, @Arun : I did as suggested but then the test {{Test org.apache.hadoop.mapred.TestEmptyJobWithDFS}} failed which kind of makes sense. So as of now I will make submit this patch and lets discuss it out here., Good point.

Anyone cares to chime in on why a job without input-files should not be treated as *invalid*?, No, I don't think throwing an exception is the right answer. It is perfectly reasonable to setup a map/reduce job that reads from a directory every 30 minutes. It should not be an error for the input directory to be empty. It would be like "cat < /dev/null" causing an error..., Ok, I withdraw my objection. I'll commit this one as-is., I just committed this. Thanks, Amar!, Integrated in Hadoop-Nightly #283 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/283/])]