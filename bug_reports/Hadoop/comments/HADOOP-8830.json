[Moritz,

Do you mean that there are effectively 2 HTTP requests?  If so, this happens when the initial request is not authenticated, a NEGOTIATE response is sent back which will trigger the SPNEGO/Kerberos authentication on the client. After a successful authentication a signed cookie is issued and used for subsequent requests.

, No, it looks as if org.apache.hadoop.security.authentication.server.AuthenticationFilter is added twice to the jetty filter chain configuration.
As soon as the authentication succeeds and the AuthenticationFilter calls filterChain.doFilter, the AuthenticationFilter is called again. Stack trace looks like this:

org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:356)
org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:356)
org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1075)

The NoCacheFilter servlet is also called twice, but that is probably because it is added both in the constructor and in addDefaultApps in org.apache.hadoop.http.HttpServer.

Right now (using CDH 4.2.0) i still have to patch the AuthenticationFilter to directly call filterChain.doFilter;return if the filter was already called before.


, Before going into the issue, this JIRA is for Apache Hadoop, if using a CDH release, you should use Cloudera JIRA or Cloudera support to report the problem.

Does this issue happen with an Apache release as well? The correct thing to do would be to find out where the 2 registrations of the filter happen and get rid of one.


, Even I saw the similar problem to HttpServer adding NoCacheFilter and AuthenticationFilter twice...any resolution for this?, I have question here about setting up the cookie.. [~tucu00] [~moritzmoeller] [~daryn] why not add the cookie in HttpRequest also?? I don't think it will have any side effects plus we won't run in such replay errors even if someone adds extra AuthenticationFilters... please let me know your inputs?, I guess I'm missing something here, what would you gain by adding the cookie to the request?, If we look at the AuthenticationFilter.doFilter code

{code}
      try {
        token = getToken(httpRequest);
        LOG.info(AuthenticationFilter.class.getName() + " token :"
            + (token == null));
      }
{code}
then here it is getting the token from the cookie present in request. The underlying problem is
* we have 2 AuthenticationFilter
* AuthenticationFilter if doesn't see the 'hadoop.auth' cookie in the request then today
** first it is trying to authenticate
** second it sets the token information into to the cookie and add it *only in the HttpResponse*.
* Therefore future AuthenticationFilter calls don't see the cookie and thinks that request is still not authenticated. So they try to authenticate again and fails with replay error. So basically we need a way to forward the authenticated information to the other filters once it is authenticated.

Please let me know if this sounds correct., Attaching a patch. I tested this on my secured cluster., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605364/HADOOP-8830.20131026.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3132//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3132//console

This message is automatically generated., I did a quick review, seems fine. Will look closer. But I think YARN should avoid adding duplicate filters. I'm reopening YARN-621 for YARN side changes., servlets or other filters after the AuthenticationFilter should not deal with the auth cookie. The current contract is as follows:

* if the request passed the AuthenticationFilter, authentication was successful
* the principal of the authenticated user is available via the HttpServletRequest.getAuthType()/getRemoteUser()/getUserPrincipal() methods

if the filter is called twice is because is twice defined in the filter chain, it should be once., [~tucu00] I agree to what you are saying but definitely there is a missing part in the AuthenticationFilter.
* either we should update the request with the newly created cookie the way we are doing it for response.
* or we can skip authentication if httpRequest.getRemoteUser() returns non null.
I have 2 patches with 2 different approaches., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605624/HADOOP-8830.20131027.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3141//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3141//console

This message is automatically generated., [~tucu00] can you take a look at the other patch [patch-2|https://issues.apache.org/jira/secure/attachment/12605624/HADOOP-8830.20131027.1.patch]. It is as per [~vinodkv] suggestion. I think both approaches are trying to solve the same problem. However why I preferred updating cookies was that for AuthenticationFilter it is very clear to check cookie first (assuming it is getting called for the first time only) if not found then try to create one. Today even if AuthenticationFilter finds auth cookie then it DOESN'T remove it from request but it is just passed on. So clearly there is a behavior difference between cookie (isPressent and isAbsent). Also please take a look at YARN-621. Issues like that are quite annoying. , \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12605624/HADOOP-8830.20131027.1.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6314/console |


This message was automatically generated., Hi,

Is this ticket still valid or solved elsewhere like YARN-621 ?, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  4s{color} | {color:red} HADOOP-8830 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-8830 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12605624/HADOOP-8830.20131027.1.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11897/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]