[We are seeing the same issue under Centos.  The NameNode and SecondaryNameNode come up, but the DataNodes fail on startup:

2008-08-25 23:21:53,743 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/10.2.11.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2008-08-25 23:21:53,885 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2008-08-25 23:21:53,887 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2008-08-25 23:21:53,888 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2008-08-25 23:21:53,941 INFO org.mortbay.util.Credential: Checking Resource aliases
2008-08-25 23:21:53,994 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2008-08-25 23:21:53,994 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2008-08-25 23:21:53,995 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2008-08-25 23:21:54,172 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@94af2f
2008-08-25 23:21:54,197 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2008-08-25 23:21:54,199 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2008-08-25 23:21:54,199 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@14d7745
2008-08-25 23:21:54,202 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2008-08-25 23:21:54,210 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
        at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
        at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:119)
        at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:359)
        at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
        at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
        at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
        at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
        at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2008-08-25 23:21:54,211 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/10.2.11.1
************************************************************/
, For us, the issue is that we were using an out-of-date hadoop-defaults.xml file...

In DataNode.java:359:

    //init ipc server
    InetSocketAddress ipcAddr = NetUtils.createSocketAddr(
        conf.get("dfs.datanode.ipc.address"));
    ipcServer = RPC.getServer(this, ipcAddr.getHostName(), ipcAddr.getPort(), 
        conf.getInt("dfs.datanode.handler.count", 3), false, conf);
    ipcServer.start();
    dnRegistration.setIpcPort(ipcServer.getListenerAddress().getPort());

"dfs.datanode.ipc.address" was not set in our default or site configuration files.  Copying the hadoop-defaults.xml file from the 0.18.0 release tarball to our grid configuration directories resolves the NullPointerException and allows HDFS to come up normally.

, The get(String) method in Configuration returns null when it can't find a particular configuration variable.  I wonder if it would be worth the effort to add a method, something called getOrFail(String) perhaps, that logs a more descriptive error message than the NullPointerException stack trace?

]