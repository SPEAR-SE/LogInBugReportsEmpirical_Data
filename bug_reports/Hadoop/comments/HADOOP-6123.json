[The scripts won't run as it is for common and hdfs as the ivy lib path has changed. Classpath in hadoop-config.sh needs to include new paths., This patch updates the classpath after the project split.
Apply this patch and copy the bin folder in hdfs project. All scripts should work as it is. This eventually has to be fixed in build file of mapred and hdfs which can extract the bin folder out of the common jar.
, I tried the change. It works.

I noticed that unlike before I have to setup JAVA_HOME in hadoop-env.sh. This is not picked up from JAVA_HOME environment variable from my shell., {code}
+if [ -d "$HADOOP_CORE_HOME/build/ivy/lib/Hadoop-Core/common" ]; then
+for f in $HADOOP_CORE_HOME/build/ivy/lib/Hadoop-Core/common/*.jar; do
+  CLASSPATH=${CLASSPATH}:$f;
+done
+fi
{code}

The for-loop above can be eliminated by keeping the wild card (shown below) as what we does in the bin/hadoop script.
{code}
if [ -d "$HADOOP_CORE_HOME/build/ivy/lib/Hadoop-Core/common" ]; then
  CLASSPATH=${CLASSPATH}:$HADOOP_CORE_HOME/build/ivy/lib/Hadoop-Core/common/*.jar;
fi
{code}

Try also the new "bin/hadoop classpath" command committed (HADOOP-5976) recently., when is this change going to be committed?, You never mark the jira "patch available"., Hi Sharad, do you think [my previous comment|https://issues.apache.org/jira/browse/HADOOP-6123?focusedCommentId=12728409&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12728409] making sense?, bq. do you think my previous comment making sense?
I don't think the "for loop" can be replaced by using the wildcard. It won't expand the path in CLASSPATH., > I don't think the "for loop" can be replaced by using the wildcard. It won't expand the path in CLASSPATH.
In the [java man page|http://java.sun.com/javase/6/docs/technotes/tools/solaris/java.html], it says,
{quote}
-classpath classpath
-cp classpath

... As a special convenience, a class path element containing a basename of * is considered equivalent to specifying a list of all the files in the directory with the extension .jar or .JAR (a java program cannot tell the difference between the two invocations).

For example, if directory foo contains a.jar and b.JAR, then the class path element foo/* is expanded to a A.jar:b.JAR, except that the order of jar files is unspecified.  ...
{quote}, @Tsz When I tried, it didn't work for me. May be I am missing something. Have you tried it? If it works for you, can you post a patch?, I tried your for-loop patch.  It does not work.
{noformat}
bash-3.2$ ./bin/hdfs namenode
java.lang.NoClassDefFoundError: org/apache/hadoop/hdfs/server/namenode/NameNode
...
{noformat}

> ... Have you tried it? If it works for you, can you post a patch? 
I have not tried it., bq. I tried your for-loop patch. It does not work.
It works for me with latest trunk. By any chance you are running the command in common itself ? It should be run in HDFS. See my [comment |https://issues.apache.org/jira/browse/HADOOP-6123?focusedCommentId=12725932&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12725932] above., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12412236/6123_v1.patch
  against trunk revision 798093.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/586/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/586/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/586/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/586/console

This message is automatically generated., Tried again the patch.  It worked fine.  I probably did something wrong last time.

Since the for-loop approach is already used in hadoop-config.sh, we should keep the new codes consistent with the existing codes.

+1 patch looks good., No new tests since this is a script change.

I have committed this.  Thanks, Sharad!, Integrated in Hadoop-Common-trunk #37 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/37/])
    . Add missing classpaths in hadoop-config.sh.  Contributed by Sharad Agarwal
, Editorial pass over all release notes prior to publication of 0.21. Just a bug.]