[[Scenario 1]
I installed a BI cluster using trunk build on HadoopNode1, and then could copy file from a ftp installed on Linux to hdfs using command:
hadoop distcp ftp://user1:user1@9.185.68.201/home/user1/ftp.txt hdfs://HadoopNode1:9000/tmp/

[Scenario 2]
[Success on FileZilla ftp server on Windows7]:
[hdfs@hostname2.com ~]$ hadoop distcp ftp://ftp:ftp@hostname1.com:121/ftp_test.txt /tmp/
15/04/26 22:56:20 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[ftp://ftp:ftp@hostname1.com:121/ftp_test.txt], targetPath=/tmp, targetPathExists=true, preserveRawXattrs=false}
15/04/26 22:56:21 INFO impl.TimelineClientImpl: Timeline service address: http://hostname2.com:8188/ws/v1/timeline/
15/04/26 22:56:21 INFO client.RMProxy: Connecting to ResourceManager at hostname2.com/9.32.249.181:8050
15/04/26 22:56:43 INFO impl.TimelineClientImpl: Timeline service address: http://hostname2.com:8188/ws/v1/timeline/
15/04/26 22:56:43 INFO client.RMProxy: Connecting to ResourceManager at hostname2.com/9.32.249.181:8050
15/04/26 22:56:43 INFO mapreduce.JobSubmitter: number of splits:1
15/04/26 22:56:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1429858372957_0002
15/04/26 22:56:44 INFO impl.YarnClientImpl: Submitted application application_1429858372957_0002
15/04/26 22:56:44 INFO mapreduce.Job: The url to track the job: http://hostname2.com:8088/proxy/application_1429858372957_0002/
15/04/26 22:56:44 INFO tools.DistCp: DistCp job-id: job_1429858372957_0002
15/04/26 22:56:44 INFO mapreduce.Job: Running job: job_1429858372957_0002
15/04/26 22:56:51 INFO mapreduce.Job: Job job_1429858372957_0002 running in uber mode : false
15/04/26 22:56:51 INFO mapreduce.Job:  map 0% reduce 0%

[Scenario 3]
On the same hadoop node, I can copy file from a remote ftp server installed on Windows7 using command:
wget ftp://Viewer:password1@9.126.148.79/ftp-win.txt.

But I failed to copy file from a ftp installed on Windows7 to hdfs using command:
[user1@HadoopNode1 ~]$ hadoop distcp ftp://Viewer:password1@9.126.148.79/ftp-win.txt /tmp/
15/02/01 23:03:37 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[ftp://Viewer:password1@9.126.148.79/ftp-win.txt], targetPath=/tmp, targetPathExists=true}
15/02/01 23:03:38 INFO client.RMProxy: Connecting to ResourceManager at HadoopNode1/9.30.239.166:8032
15/02/01 23:05:50 ERROR tools.DistCp: Exception encountered
org.apache.commons.net.ftp.FTPConnectionClosedException: Connection closed without indication.
        at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:313)
        at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:290)
        at org.apache.commons.net.ftp.FTP.sendCommand(FTP.java:479)
        at org.apache.commons.net.ftp.FTP.sendCommand(FTP.java:552)
        at org.apache.commons.net.ftp.FTP.sendCommand(FTP.java:601)
        at org.apache.commons.net.ftp.FTP.quit(FTP.java:809)
        at org.apache.commons.net.ftp.FTPClient.logout(FTPClient.java:979)
        at org.apache.hadoop.fs.ftp.FTPFileSystem.disconnect(FTPFileSystem.java:151)
        at org.apache.hadoop.fs.ftp.FTPFileSystem.getFileStatus(FTPFileSystem.java:395)
        at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:57)
        at org.apache.hadoop.fs.Globber.glob(Globber.java:248)
        at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1632)
        at org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)
        at org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:80)
        at org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:342)
        at org.apache.hadoop.tools.DistCp.execute(DistCp.java:154)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:121)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:390)
, I found the FTPClient code will hang on the line 'client.setFileTransferMode(FTP.BLOCK_TRANSFER_MODE)' against IIS ftp server on Windows, and then it will failed with some FTP connection exception. 

So I removed the line 'client.setFileTransferMode(FTP.BLOCK_TRANSFER_MODE)' from hadoop/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ftp/FTPFileSystem.java#connect(), and then found some things improved: now the distcp tool could launch the MR job(it could not before changing the code) agsint IIS ftp server on Windows, but still always failed on the step 'map 100% reduce 0%':

hadoop distcp ftp://Viewer:passw0rd@hostname1.com:1121/ftp_file1.txt /tmp/
15/04/28 01:28:48 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[ftp://Viewer:passw0rd@hostname1.com:1121/ftp_file1.txt], targetPath=/tmp, targetPathExists=true, preserveRawXattrs=false}
15/04/28 01:28:49 INFO impl.TimelineClientImpl: Timeline service address: http://hostname2.com:8188/ws/v1/timeline/
15/04/28 01:28:50 INFO client.RMProxy: Connecting to ResourceManager at hostname2.com/9.30.249.187:8050
15/04/28 01:29:12 INFO impl.TimelineClientImpl: Timeline service address: http://hostname2.com:8188/ws/v1/timeline/
15/04/28 01:29:12 INFO client.RMProxy: Connecting to ResourceManager at hostname2.com/9.30.249.187:8050
15/04/28 01:29:13 INFO mapreduce.JobSubmitter: number of splits:1
15/04/28 01:29:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1430212928460_0002
15/04/28 01:29:13 INFO impl.YarnClientImpl: Submitted application application_1430212928460_0002
15/04/28 01:29:13 INFO mapreduce.Job: The url to track the job: http://hostname2.com:8088/proxy/application_1430212928460_0002/
15/04/28 01:29:13 INFO tools.DistCp: DistCp job-id: job_1430212928460_0002
15/04/28 01:29:13 INFO mapreduce.Job: Running job: job_1430212928460_0002
15/04/28 01:29:20 INFO mapreduce.Job: Job job_1430212928460_0002 running in uber mode : false
15/04/28 01:29:20 INFO mapreduce.Job:  map 0% reduce 0%
15/04/28 01:29:31 INFO mapreduce.Job:  map 100% reduce 0%
15/04/28 01:31:38 INFO mapreduce.Job: Task Id : attempt_1430212928460_0002_m_000000_0, Status : FAILED
Error: java.net.SocketException: Connection reset
        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118)
        at java.net.SocketOutputStream.write(SocketOutputStream.java:159)
        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221)
        at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:291)
        at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:295)
        at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:141)
        at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:229)
        at java.io.BufferedWriter.flush(BufferedWriter.java:254)
        at org.apache.commons.net.ftp.FTP.__send(FTP.java:501)
        at org.apache.commons.net.ftp.FTP.sendCommand(FTP.java:475)
        at org.apache.commons.net.ftp.FTP.sendCommand(FTP.java:552)
        at org.apache.commons.net.ftp.FTP.sendCommand(FTP.java:601)
        at org.apache.commons.net.ftp.FTP.quit(FTP.java:809)
        at org.apache.commons.net.ftp.FTPClient.logout(FTPClient.java:979)
        at org.apache.hadoop.fs.ftp.FTPFileSystem.disconnect(FTPFileSystem.java:162)
        at org.apache.hadoop.fs.ftp.FTPFileSystem.getFileStatus(FTPFileSystem.java:410)
        at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:218)
        at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:50)
        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158), On windows os ,you could set fs.ftp.transfer.mode to FTP.STREAM_TRANSFER_MODE which is equal to  10.]