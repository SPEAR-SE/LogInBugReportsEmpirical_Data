[This patch should also have a fix for JobInProgress.kill() so that calling this on an uninitialized job kills the job completely.

At present, calling JIP.kill() will just mark the job for killing, but job is truly not killed completely. A job is completely killed only when JIP.terminateJob()) is called on it, which does things like logging to JobHistory and marking JobStatus as killed. Currently, this method isn't called until a clean-up task is scheduled and runs to completion, but for uninitialized jobs there are no clean-up tasks and so job-kill remains incomplete for ever., bq. At present, calling JIP.kill() will just mark the job for killing, but job is truly not killed completely. A job is completely killed only when JIP.terminateJob()) is called on it, which does things like logging to JobHistory and marking JobStatus as killed. Currently, this method isn't called until a clean-up task is scheduled and runs to completion, but for uninitialized jobs there are no clean-up tasks and so job-kill remains incomplete for ever.

This will be fixed in HADOOP-4261, 
bq. This will be fixed in HADOOP-4261

HADOOP-4261 didn't solve this issue, but it did facilitate a work around by making JobInProgress.terminateJob() package private. So, callers that wish to kill a job should do something like this:
{code}
if (job.inited()) {
  job.kill();
} else {
  job.terminateJob(JobStatus.KILLED);
}
{code}

It will be good if we can wrap this into a single useful method for easy use., bq. This patch should also have a fix for JobInProgress.kill() so that calling this on an uninitialized job kills the job completely.
This should have been taken care in HADOOP-4261. The task-initializer should call {{job.kill()}} which should do one of the 3 things
- {{garbageCollect()}} is the job has not _started_ (HADOOP-4261)
- mark for kill if the job is in _init_ (this issue)
- mark for cleanup if the job is _running_

Ideally there should be only one api to kill a job (say {{killJob()}}) which internally does the switching. Having 2 apis ({{killJob()}} and {{terminateJob()}}) is confusing. , +1 for not exposing 2 apis., this patch tries to solve the problem by setting flags. however, the ideal way to solve would be to have granular and one directional locking in jobtracker - HADOOP-869. 
- also it makes the terminateJob api back to private. Now EagerTaskInitializationListener uses fail().
, JobInProgess.kill() should be made re-entrant. We need this as some schedulers may wish to kill jobs that violate certain resource requirements and we don't want to waste cycles on terminating a job that is already killed.

Additionally, we will somehow need to inform job-clients which try to terminate jobs for which a kill has already been issued. Currently, on re-kill attempts, it just keeps saying "job is killed successfully"., kill() in JobInProgress has been made reentrant.
Informing clients about the already issued kill is non-trivial as it will require interface change. Also, we don't do this for others commands like kill task. So I think it shouldn't be done as part of this jira., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12391989/4236_v2.patch
  against trunk revision 703923.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 1 new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3449/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3449/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3449/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3449/console

This message is automatically generated., Shouldn't the change in kill() method be done in terminate() method, because the same is valid for JobInProgress.fail() also., >> Shouldn't the change in kill() method be done in terminate() method, because the same is valid for JobInProgress.fail() also.
we don't need for fail() as it is never called from user, also Jobtracker/scheduler should not call fail and initTasks simultaneously., got away with the extra flag, reused jobKilled flag.
also changed synchronization in obtainCleanupTask and obtainSetupTask. now taskInited flag is checked before taking lock on JobInProgress., test patch returned following:
[exec] -1 overall.

     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec]     -1 tests included.  The patch doesn't appear to include any new or modified tests.
     [exec]                         Please justify why no tests are needed for this patch.
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec]     -1 findbugs.  The patch appears to introduce 1 new Findbugs warnings.
     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

Findbugs warning is :
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobInProgress<br/>Field org.apache.hadoop.mapred.JobInProgress.initStarted<br/>Synchronized 50% of the time<br/>Unsynchronized access at JobInProgress.java:[line 1980]<br/>Synchronized access at JobInProgress.java:[line 349]<br/>Synchronized access at JobInProgress.java:[line 145]<br/>Synchronized access at JobInProgress.java:[line 145]</p>


However initStarted is synchronized everywhere. Seems like findbugs is getting confused., Ok, I had a long discussion with Sameer and Owen about this and here is a slightly modfied approach we feel is slightly more maintainable:

1. Introduce a new job-status class with 2 booleans: killJob and initTasks.
2. JobInProgress.kill should synchronize on the new status object, set the 'killJob' boolean to true (via a setter) and then check the 'initTasks' and call terminate if necessary while holding the lock on the status object.
3. Similarly JobInProgress.initTasks should synchronize on the status object at the _end_ (not at the beginning, there-by eliminating the need for the 'initStarted' flag) and call terminate if necessary while holding the lock on the status object.

Basically, the proposal is to keep a single object which tracks killJob and initTasks simultaneously rather than relying on too many pieces.

Thoughts?, When is a JobInProgress created, as soon as a job is submitted or when it is considered for running??

If the former then having a 'initStarted' flag would make sense. Because {{if (!initStarted)}} then it could be a long time before a job is considered for running and it'll hang around in the queue, killed but not purged. If so, I think this patch does the right thing.

Regardless of whether or not we need an {{initStarted}} flag,  I think it's cleaner to create a {{JobInitKillStatus}} class with the flags as members and synchronizie around an instance of this class.

As far as this patch goes, I think
{code}
synchronized(tasksInited){
  if(jobKilled) {
    terminateJob(JobStatus.KILLED);
    return;
  }
  initStarted = true;
}
{code}

should just be

{code}
synchronized(tasksInited){
  if(jobKilled) {
    return;
  }
  initStarted = true;
}
{code}





  , You need to explicitly terminateJob to make sure all of the tasks are marked as killed.

Sameer has a good point that since the schedulers may delay initializing jobs for an arbitrary length of time, we should probably kill jobs before they get to init. It would be far better if we could always make the kill method do the kill and block if it is in the middle of initialization., bq. Sameer has a good point that since the schedulers may delay initializing jobs for an arbitrary length of time, we should probably kill jobs before they get to init.
the current patch is already doing it. As far I understand, Arun and Sameer have suggested to move those flags to a class.

bq. It would be far better if we could always make the kill method do the kill and block if it is in the middle of initialization.
Agreed, that would be ideal and cleaner as well (just make kill as synchronized). But we are trying to deal with the problem of jobtracker locking - see HADOOP-3864. Currently during the kill job, the jobtracker is locked and we can't afford to block the kill job if its in the middle of initTasks(). 
HADOOP-869 is seemingly becoming more important., bq. Sameer:When is a JobInProgress created, as soon as a job is submitted or when it is considered for running?
as soon as a job is submitted, As suggested by Arun/Sameer, moved the flags to a private class JobInitKillStatus.
I have retained initStarted for the reason that schedulers may take time to get to initTasks for the job if there are lot of jobs or scheduler threads are busy with doing init of other jobs., also fixed the code as rightly pointed by Sameer., There still is a race condn. in kill() - it might lead to terminate being called more than once i.e. from initTasks() and kill() ..., I take my previous comment back... I apologise for my brain's comatose state. 

One minor comment is that we need to heavily document the fact that 'terminate' is re-entrant..., added some documentation around terminate and made terminate explicitly re-entrant., test-patch output
{code}
[exec] -1 overall.

     [exec] +1 @author. The patch does not contain any @author tags.

     [exec] -1 tests included. The patch doesn't appear to include any new or modified tests.
     [exec] Please justify why no tests are needed for this patch.

     [exec] +1 javadoc. The javadoc tool did not generate any warning messages.

     [exec] +1 javac. The applied patch does not increase the total number of javac compiler warnings.

     [exec] +1 findbugs. The patch does not introduce any new Findbugs warnings.

     [exec] +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
{code}

all core tests passed on my machine, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12392172/4236_v5.patch
  against trunk revision 704818.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3464/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3464/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3464/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3464/console

This message is automatically generated., I just committed this. Thanks, Sharad!, Integrated in Hadoop-trunk #635 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/635/])
    . Ensure un-initialized jobs are killed correctly on user-demand. Contributed by Sharad Agarwal.
]