[Is anyone else seeing this?  There were changes to DF.java in 0.14, but none that should cause this.  Are you still running under a Cygwin shell?  We depend on Cygwin binaries being on $PATH, including at least 'df' and 'bash'., It use to work without cygwin in the path var.

I added it and it work yes.

But I don't understand why it use to work before, that's weird ?!, I got this problem too:  It appears DF is being used to compute available disk space before creating files.  While Java does not appears to have support for this (see [bug 4057701|http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4057701]), it does appear that another Apache project (sort of) does:

[org.apache.commons.FileSystemUtils.freeSpaceKb|http://commons.apache.org/io/api-release/org/apache/commons/io/FileSystemUtils.html#freeSpaceKb(java.lang.String)]

...at least it wouldn't require that Hadoop users on Windows install Cygwin., looks like this has been fixed and works with cygwin as intended. resolving for now., I had this problem and the comments here were not very clear. I solved it by trying various things...so here is how I got it to work:

My environment:
- Windows XP
- Eclipse running under Windows
- Eclipse includes the IBM plugin for mapreduce/hadoop
- I was trying to run the mapreduce job as a java application via Eclipse

Solution:
- Installed the latest stable version of Cygwin
- Added "c:\Cygwin\bin " (or equivalent) to Path on windows
- Started the Cygwin shell
- Ran the mapreduce job as a java application while the Cygwin shell was running.

Hope this helps clarify things for other newbies., Hello, I've done all this, but when I run my job in eclipse, I get the Visual Studio just-in-time debugger for df.exe, as if it is finding it, but it's not running correctly. 
Has anyone else had this problem?
It seems to occur when the map job completes...

-Steve]