[Here's the jobtracker log.  Follow the life cycle of task_0005_m_000004.  This is a TestDFSIO map task that should be writing data.

Note that task_0005_m_000004_1 is created right after task_0005_m_000004_0 even though speculative execution should be off.  task_0005_m_000004_0 seems to complete fine (task_0005_m_000004_1 fails with AlreadyBeingCreatedException -- see namenode.log) but the file it creates (/benchmarks/TestDFSIO/io_data/test_io_12) seems to get lost., Attaching namenode.log.  , Is it possible that setting speculation off in mapred-default.xml on my job submission host has no effect and that i really need to set it off in hadoop-site.xml?  

If that is the case, then speculation would be on -- which explains perfectly the immediate execution of task_0005_m_000004_1.  In which case this should be filed as a dfs bug since the file created by the first map (task_0005_m_000004_0) is getting lost., It looks like the JobTracker is ignoring the mapred-default.xml config items and hence the speculative execution setting in mapred-default.xml is not reflected. However, on the tasktrackers, the mapred-default.xml indeed overrides the config in hadoop-site/hadoop-default.xml, and hence sees speculative execution switched off.
This could be the cause of the dfs file-lost problem. Here's the theory (not yet validated from the source code): When the maps tries to create files on dfs, they try to the create the "final" files (as opposed to the speculative case where the output path for the files would point to task specific directories). Hence the spec instance of a map gets the AlreadyBeingCreatedException. Finally the JT, which thinks that spec exec is turned on, tries to rename the empty file path to its final destination and that overwrites the real file that the task originally created., This seems like a blocker until we understand what is happening., For now, I've reverted HADOOP-1440, which fixes this problem., HADOOP-1440 needs to be re-created as a new issue, but this bug is fixed.]