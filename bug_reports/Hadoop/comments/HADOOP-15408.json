[Hi Rushabh, thanks for filing the jira.

It looks like the Java process has both versions of hadoop-common jar files, causing confusion. Is it a valid use case?, Thanks [~jojochuang] for taking a look.
bq. Is it a valid use case?
I think yes.
If we can come up with a simple fix the IMO we should fix it.
In our cluster, there are many services (like oozie, hive) which can bundle an older versions of hadoop jar and they expect backwards compatibility between minor hadoop versions.
Would like to hear more opinions., ouch, didn't test it but feels like a scenario that we have to support....

Maybe we can split the new class {{KMSDelegationToken}} into 2 separate classes, so there will be no dependency on each other. I didn't check how the class loader would work because it would see 'kms-dt' and be able to map to both the legacy identifier from the new jar, and the only identifier from the old jar. But I think if we do it this way either jar would work.... Thoughts?, This fix also broke Ranger, for the same reason., {quote}This fix also broke Ranger, for the same reason.
Â {quote}
Thanks Arpit for chiming in. Since there are multiple components affected by this change, it makes sense to fix in hadoop itself.

bq. I didn't check how the class loader would work because it would see 'kms-dt' and be able to map to both the legacy identifier from the new jar, and the only identifier from the old jar.
Thanks [~xiaochen] for the comment.
I don't completely grasp the idea. I would really appreciate if you can share sample pseudo code explaining the idea., Sorry I have not debugged this, so could be missing something. Only from the description:
{quote}
This is because the container loaded KMSDelegationToken class from an older jar and KMSLegacyDelegationTokenIdentifier from new jar and it fails when KMSLegacyDelegationTokenIdentifier wants to read TOKEN_LEGACY_KIND from KMSDelegationToken which doesn't exist before.
{quote}
Would something like  [^split.patch] work?, We've always had a "don't mix hadoop-* jars" policy, though never one on "what if you have >1 version on the same CP" 
Ignoring strict policy "because we said so" rules, it'd be good for at least on those minor x.y.z releases for thing not to break., Thanks [~xiaochen] for the patch.
Had an offline chat with [~daryn] on the proposed fix.
Below is the summary.
Identifier for both the tokens (i.e KMS_DELEGATION_TOKEN and kms-dt) are the same (byte-to-byte) so we don't need to have another class {{KMSLegacyDelegationTokenIdentifier}} for legacy token identifier.
 Kind in Identifier doesn't mean much.

After removing {{KMSLegacyDelegationTokenIdentifier}} class and {{KMSLegacyDelegationTokenIdentifier}} from {{org.apache.hadoop.security.token.TokenIdentifier}}, 4 tests are failing in TestKMS because they are trying to decodeIdentifier with kind {{kms-dt}} and Serviceloader is not able to find any Identifier which corresponds to {{kms-dt}} kind.
 Since it is test-only code, we can change the test.
 Let me know if this makes sense., Hi [~shahrs87], comments below and a request in the end.
Comments:
bq. Identifier for both the tokens are the same
Correct, and that's exactly why we can do the trick at KMSCP to copy a new kind.

bq. 4 tests are failing in TestKMS because they are trying to decodeIdentifier with kind kms-dt and Serviceloader is not able to find any Identifier which corresponds to kms-dt kind.
Thanks for testing. The patch was to express the idea - seems it won't compile on trunk. I have cleaned up compilation, and don't see any test failures. Attaching a new patch and we can run pre-commit to see. 

Back to the problem itself, which I think is another compatibility dimension as Steve mentioned, is that when old jars and new jars are both present, we should behave the same way as if only new jars or only old jars are present.

The specific issue, as you discovered in the description, is that service loader will load things in accumulation. This means {{org.apache.hadoop.crypto.key.kms.KMSDelegationToken$KMSDelegationTokenIdentifier}} from both jars, and {{org.apache.hadoop.crypto.key.kms.KMSDelegationToken$KMSLegacyDelegationTokenIdentifier}} from the new jar. I think this would trigger [service loader|https://docs.oracle.com/javase/6/docs/api/java/util/ServiceLoader.html] to ignore duplicates, so in the order you provided, we'll end up with token identifier from the old jar, and legacy token identifier from the new jar, which are both kms-dt. It seems then in the job, kms-dt mapped to the legacy token (new jar), which upon looking up the {{TOKEN_LEGACY_KIND}} field reached the old jar's {{KMSDelegationToken}} class. (I'm not totally sure but this seems to be the only explanation for the stacetrace)

So, in split.patch what I tried to do is to make sure:
# {{org.apache.hadoop.security.token.TokenIdentifier}} have different classes between old jar and new jar
# new jar's legacy token do not collide with old classes, and everything is self-contained (within {{KMSDelegationTokenLegacy.java}}).

I think this should make service loader happy, and no matter kms-dt at run time maps to {{KMSDelegationTokenIdentifier}} in the old jar, or {{KMSLegacyDelegationTokenIdentifier}} in the new jar, the identifier can be initialized.

Request:
Sorry I won't have cycles this week to try reproduce and debug on a real spark case. Since you have a failing Spark job already, do you think you can test this with the failing spark use case, and verify whether this fixes the issue? Would be great if [~arpitagarwal] could try on the Ranger case as well.... Thanks!, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m  1s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 26m  5s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 26m  5s{color} | {color:red} root generated 5 new + 1276 unchanged - 0 fixed = 1281 total (was 1276) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 55s{color} | {color:orange} hadoop-common-project: The patch generated 1 new + 106 unchanged - 0 fixed = 107 total (was 106) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 23s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 35s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 37s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}128m  2s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:b78c94f |
| JIRA Issue | HADOOP-15408 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12920580/split.prelim.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux f4f9acf4047c 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / bb3c504 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/14520/artifact/out/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/14520/artifact/out/diff-checkstyle-hadoop-common-project.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14520/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/14520/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 1506 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14520/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, bq. Thanks for testing. The patch was to express the idea - seems it won't compile on trunk.
Thanks [~xiaochen] for the patch. I should have been more clear. I didn't test with your patch (split.patch).
{quote}
Identifier for both the tokens (i.e KMS_DELEGATION_TOKEN and kms-dt) are the same (byte-to-byte) so we don't need to have another class KMSLegacyDelegationTokenIdentifier for legacy token identifier.
{quote}
I have a different idea. I am uploading the patch (HADOOP-15408-001.patch) . Please don't think I am intruding.
Lets see if we agree on one approach.
, bq. Please don't think I am intruding.
not at all. More than happy to see you working on it.

bq. HADOOP-15408-001.patch
Could you elaborate? It seems if we do it this way, the new jar alone won't be able to decode kms-dt?, bq. the new jar alone won't be able to decode kms-dt?
We do we want to decode in the first place ?
We just want TokenRenewer to renew the token and the kind field in Token class will be able to find the right TokenRenewer (i.e KMSLegacyTokenRenewer)., {noformat}
2018-04-20 21:09:53,273 ERROR [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster
java.util.ServiceConfigurationError: org.apache.hadoop.security.token.TokenIdentifier: Provider org.apache.hadoop.crypto.key.kms.KMSDelegationToken$
KMSLegacyDelegationTokenIdentifier could not be instantiated
at java.util.ServiceLoader.fail(ServiceLoader.java:232)
at java.util.ServiceLoader.access$100(ServiceLoader.java:185)
at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384)
at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)
at java.util.ServiceLoader$1.next(ServiceLoader.java:480)
at org.apache.hadoop.security.token.Token.getClassForIdentifier(Token.java:117)
at org.apache.hadoop.security.token.Token.decodeIdentifier(Token.java:138)
at org.apache.hadoop.security.token.Token.identifierToString(Token.java:393)
at org.apache.hadoop.security.token.Token.toString(Token.java:413)
at java.lang.String.valueOf(String.java:2994)
at org.apache.commons.logging.impl.SLF4JLocationAwareLog.info(SLF4JLocationAwareLog.java:155)
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1634)
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1583)
{noformat}
This isn't about renewal, but the decoding of token identifier. And because the new jar will meet kms-dt (e.g. rolling upgrade), we need to fix it... I think renewer is not affected here, {quote}And because the new jar will meet kms-dt (e.g. rolling upgrade), we need to fix it.
{quote}
My bad. Ignore my patch then., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 25s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 30m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 43s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 28m 27s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  0s{color} | {color:orange} hadoop-common-project: The patch generated 1 new + 93 unchanged - 0 fixed = 94 total (was 93) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 15s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 24s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 45s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 48s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}137m  2s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:b78c94f |
| JIRA Issue | HADOOP-15408 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12920636/HADOOP-15408-trunk.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 2837a7f657f5 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6266906 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/14522/artifact/out/diff-checkstyle-hadoop-common-project.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14522/testReport/ |
| Max. process+thread count | 1356 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14522/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, No worries Rushabh. Would you be able to test whether the split approach helps on the failing spark job?

FWIW I don't care about the ownership of jiras etc., so feel free to grab it and carry on. (As explained I don't have cycles this week to dive into this at real spark jobs, and would like to see this fixed asap, as I'm sure you and Arpit do as well), bq.  Would you be able to test whether the split approach helps on the failing spark job?
I am planning to put this patch in my internal build tonight and will request spark team to test it., Thanks a lot!, {quote}
java.util.ServiceConfigurationError: org.apache.hadoop.security.token.TokenIdentifier: Provider org.apache.hadoop.crypto.key.kms.KMSDelegationToken$
KMSLegacyDelegationTokenIdentifier could not be instantiated
{quote}
Just going back to old approach. Now if I see the stack trace again, how did the application know about {{KMSLegacyDelegationTokenIdentifier}}.
It seems like you forgot to remove {{org.apache.hadoop.crypto.key.kms.KMSDelegationToken$KMSLegacyDelegationTokenIdentifier}} from {{hadoop-common-project/hadoop-common/src/main/resources/META-INF/services/org.apache.hadoop.security.token.TokenIdentifier}}.
I have put {{HADOOP-15408-trunk.001.patch}} internally and will update tomorrow., Thanks for testing [~shahrs87].

With both jars present you can see KMSLegacyDelegationTokenIdentifier from the new jar right? But it seems to track to the KMSDelegationToken class of the old jar. In split.prelim.path that becomes {{KMSDelegationTokenLegacy$KMSLegacyDelegationTokenIdentifier}}, which is only in the new jar.

What exception did you see with this case?, Looks like previous patch doesn't land on 2.9.1 branch so replace target version to 2.9.2. cc [~Sammi]., {quote}What exception did you see with this case?
{quote}
I didn't see any exceptions with this case.
{quote}Just going back to old approach.
{quote}
Sorry I wasn't clear with my previous comment. Let me be more clear this time.
 We internally fixed this issue with {{HADOOP-15408-trunk.001.patch}} and the spark jobs ran successfully after this fix.

Going back to [this comment|https://issues.apache.org/jira/browse/HADOOP-15408?focusedCommentId=16452594&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16452594], I was asking that where did you see this stack trace ?
 I assume you applied {{HADOOP-15408-trunk.001.patch}} patch and you encountered some failure which showed that stack trace.
Let me know if still I am not clear., bq. I was asking that where did you see this stack trace ?
That was copied from the jira description, so I assumed that was the st you saw...

So to conclude, is my understanding correct? (listing below for easier pointing)
# patch 1 fixed the spark issue
# patch 1 does not work with kms-dt
# split.patch does not fix the spark issue

On a separate note, we've also had an hbase internal test failure last friday. I'm looking into that..., bq. so I assumed that was the st you saw...
Yes.

bq. patch 1 fixed the spark issue
Yes.
Just for clarification, patch 1 =  HADOOP-15408-trunk.001.patch

bq. patch 1 does not work with kms-dt
It does work with kms-dt. Just for reference, internally we only use {{kms-dt}} since we have uri in the token service since the beginning of EZ.

bq. split.patch does not fix the spark issue
I haven't tested internally with {{split.prelim.patch}}, Thanks for the explanation, that feels better. :)

But as patch 1 stands, the test shows exactly how kms-dt won't work with the token identifier, right?
In other words, even though the bytes are the same for both kinds, {{Token#decodeIdentifier()}} is broken by patch 1, because service loader cannot find a class to decode {{kms-dt}}., bq. In other words, even though the bytes are the same for both kinds, Token#decodeIdentifier() is broken by patch 1,
Trying to understand why we want to decode TokenIdentifier ?

{quote}
In other words, even though the bytes are the same for both kinds, Token#decodeIdentifier() is broken by patch 1, because service loader cannot find a class to decode kms-dt.
{quote}
I assume you are saying this because of the stack trace that I pasted in description.
It failed in our build because we had {{KMSLegacyDelegationTokenIdentifier}} in {{hadoop-common-project/hadoop-common/src/main/resources/META-INF/services/org.apache.hadoop.security.token.TokenIdentifier}} file and service loader was unable to find {{KMSLegacyDelegationTokenIdentifier}}.
But after removing {{KMSLegacyDelegationTokenIdentifier}} from {{hadoop-common-project/hadoop-common/src/main/resources/META-INF/services/org.apache.hadoop.security.token.TokenIdentifier}}, the job is able to run successfully., I was saying this because in patch 1, TestKMS was changed to let the tests pass. Otherwise, in the test you will run into the equivalent of new jar seeing kms-dt, which can't decodeIdentifier. And...

bq. Trying to understand why we want to decode TokenIdentifier ?
Because [it is a public API|https://github.com/apache/hadoop/blob/branch-3.0.0/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/Token.java#L169]..., I find cycles to test this today, and was able to reproduce that 'TOKEN_LEGACY_KIND' NoSuchFieldError. Below is the command I used:
{noformat}
SPARK_CLASSPATH=~/hadoop-common-pre-HADOOP-14445.jar:$SPARK_CLASSPATH spark-submit --class  org.apache.spark.examples.HdfsTest --deploy-mode client --master yarn /opt/cloudera/parcels/CDH/lib/spark/lib/spark-examples.jar  DIR_TO_FILE_IN_EZ
{noformat}

Also confirmed job is passing with split.prelim.patch. (Also after HADOOP-15431, anecdotally I used that issue's cluster).

[~shahrs87], do you want to give that patch a try? I can clean up the patch if it works for you. Or I could help with reviews if you have other approaches or interested in revving it. Don't think patch 1 is the correct way as reasons stated above., bq. Because it is a public API...

It is but it isn't.  Clients must always treat the identifier as an opaque blob of bytes.  The token wrapper with kind/service exists so identifiers don't have to be decodable.  Rushabh's patch completely conforms to the api in the javadoc.  There is no guarantee an identifier is decodable. The method is allowed to return null.

Background: Pre-1.x, {{decodeIdentifier}} didn't exist and tokens logged their identifiers as hex bytes.  For easier debugging I added {{decodeIdentifier}} to make a best-effort attempt to decode the identifier for logging (which I also added) in tasks via stringifying the token.

Decoding is not guaranteed.  +1 on Rushabh's patch.
, Thanks [~daryn] for the comment and background.

I want this fixed asap too, but I'm afraid with the current compat policy, we can't move away from it... I searched for {{decodeIdentifier }} across CDH and found 94 references. Although most of them look irrelavant / ok to kms tokens, I think the following would be problematic:
# https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/security/HadoopFSDelegationTokenProvider.scala#L59
# https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkHadoopUtil.scala#L353

#1 looks like would make spark's "renew" logic fail. #2 is minor logging so only surprise points.

IMO we can try mark this method to be Private in the future following compat guidelines, but for this immediate issue we'd need a more compatible fix. Thoughts?

I will cleanup my patch and upload later today for a code review., bq. I want this fixed asap too, but I'm afraid with the current compat policy, we can't move away from it...
Sigh.  Technically it's not an incompatibility but maybe we will have to "temporarily" add a dummy identifier class.  Please file jiras against the components you've identified.  We can't cater to components violating the documented api.  This seems pretty clear:
{code}
  /**
   * Get the token identifier object, or null if it could not be constructed
   * (because the class could not be loaded, for example).
   * @return the token identifier, or null
   * @throws IOException 
   */
{code}

This infuriates me because clients that depend on decoding the identifier have completely screwed us from changing the token format to something more flexible. :(. I knew the RM did it but that's easier to fix than a downstream project., bq. I want this fixed asap too,
We have fixed it internally by removing {{KMSLegacyTokenIdentifier}} class and requested one of our spark devs to verify whether their jobs are running successfully.
I got a +1 from him. We believe we are running the latest version of spark which has that change.
I have again requested him to add logging in that specific area and verifies that scala is not somehow filtering nulls.
Will post the result later today., bq. We believe we are running the latest version of spark which has that change.
Could you let him try running a long-running job that requires token auth, and see if it can pass the first renew-interval?
Probably need to change the renew-interval from 24 hours down to something like 10 minutes for a quicker test. This need to be set on BOTH the KMS server issuing the token, AND the spark job where the config is read from. (I know... that's how it works now), bq. Please file jiras against the components you've identified
Will do..

bq. infuriates
understand that feeling. :) That javadoc is crystal clear, but admittedly I didn't read it until you pointed out - I was only looking at the class annotations. With all the sympathy, I may have a way to let this work for now, will throw a patch for demonstrating purpose soon.., Uploaded a poc.patch for discussion. Idea is simple: do not change the existing KMSDelegationToken class. Added a new class for service loader, so even if both jars present, there is no collision - only duplicates. This basically undoes part of HADOOP-14445, to change its {{token(kms-dt -> KMS_D_T), add legacyToken(kms-dt)}} to {{token(kms-dt unchanged), add standardToken(KMS_D_T)}}.

Tested to work with above spark command. It also has the benefit to be able to decode kms-dt. As Daryn explained that's not a must-do, but nice-to-hive for debugging purposes IMO.

Any thoughts?, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 35s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 25s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 35s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 56s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 27m 56s{color} | {color:red} root generated 5 new + 1469 unchanged - 0 fixed = 1474 total (was 1469) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  3m 45s{color} | {color:orange} root: The patch generated 1 new + 112 unchanged - 0 fixed = 113 total (was 112) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 20s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 16s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 49s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 37s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 98m 20s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 40s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}246m 39s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |
|   | hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy |
|   | hadoop.hdfs.TestSafeMode |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15408 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12921471/HADOOP-15408.trunk.poc.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux d11655937625 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8f42daf |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/14548/artifact/out/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/14548/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14548/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14548/testReport/ |
| Max. process+thread count | 2716 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14548/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, {quote}
https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/security/HadoopFSDelegationTokenProvider.scala#L59
https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkHadoopUtil.scala#L353
{quote}
It turns out that in scala {{null.instanceof(Object)}} returns false.
So I think {{decodeIdentifier}} returning null should be fine.
, Could you please clarify?
Fine as in "won't NPE" or fine as in "tested spark can get the new token once the current one reaches 75% of its expiration time"?, bq. Fine as in "won't NPE"
It won't throw NPE.

bq. "tested spark can get the new token once the current one reaches 75% of its expiration time"?
IIUC spark is going through all the tokens in the credentials cache which will contain {{KMS_D_T}} and {{kms-dt}}.
Spark is reading {{identifier.getIssueDate}} from the token and both tokens will have the same {{issueDate}} so we can safely _not implement_ {{KMSLegacyDelegationTokenIdentifier}}.
As long as spark doesn't throw NPE, I think we are good here.
Hope it makes sense., With HADOOP-14445 reverted (see [discussion|https://issues.apache.org/jira/browse/HADOOP-14445?focusedCommentId=16464600&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16464600]), this is no longer an issue.
Thanks all for the report and investigation.]