[Could somebody please review this., Trunk is already on metrics 2. HADOOP-7190 added back the old package to make it compatible with legacy tools. 0.20-2xx release is on metrics 2 since the beginning and is in production for many months., I wonder what you're trying to achieve. The patch completely breaks metrics2 instrumentation (i.e. people already on metrics2 will not see the metrics, especially JMX metrics support in JT and TT).

If you just want to make Ganglia work, porting Ganglia plugin to metrics2 is a much smaller patch., I am not doing anything with metrix2 except trying not to break it.
My motivation is to make the original metrics work, which doesn't for me in 0.20-security branch.

> The patch completely breaks metrics2 instrumentation

Are you saying metrics2 are broken in 0.22?, bq. I am not doing anything with metrix2 except trying not to break it.

The patch completely removes the instrumentation and tests of metrics v2 in RPC and HDFS.

bq. My motivation is to make the original metrics work, which doesn't for me in 0.20-security branch.

Can you tell me what's missing for you in metrics v2, except for Gangalia? I can help you porting...

bq. Are you saying metrics2 are broken in 0.22?

metrics2 is never in 0.22. It's in 0.20.2xx and trunk (targeting 0.23)

Last September, after we deployed 0.20.200 internally, I asked the community about the evolution paths of metrics on [the mailing list|http://goo.gl/Rjb1], and the people who care to answer [chose #2|http://goo.gl/NLLs], which was exactly what we did for 0.20.203 and trunk.

Your goal now seems to be #3, but your patch doesn't do that. I anticipated possibility of #3 or #3a and put all metrics instrumentation behind interfaces in 0.20.2xx, so it's at least possible without changing the instrumentation code (besides the updater or metrics source implementation). As I pointed out in the original post in the mailing lists, there are down sides for #3, I'd really like to know the reasons for that. I can certainly help you implementing #3, if you can convince the community that it's really needed for 0.20.2xx releases.
, Luke, I don't know how you can make decisions based only on one comment. I don't think Gary (the only one who cared) would be happy with the solution, when he sees it, as he was asking for "a phased transition" to metrics2 for HBase. I sure missed your email.

Let's see how we can use metrics2 instead of the original metrics, before we attempt option #3, which is make both metrics frameworks work.

Could you please elaborate or post links on how to get metrics2 run. We use Ganglia., I should've mentioned, I haven't been following metrics closely, so any help from you, Luke, is greatly appreciated., bq. Luke, I don't know how you can make decisions based only on one comment.

Well, it was approved by Y dev/ops, of course :). The post was sent to both general and common-dev. People have many weeks to voice their opinions. The main consumers of the metrics system are ops and perf guys. I guess that they don't have strong opinions on how it should work as long as it can be easily made to work. I'm sure that you heard of lazy consensus.

bq. I don't think Gary (the only one who cared) would be happy with the solution, when he sees it, as he was asking for "a phased transition" to metrics2 for HBase.

#2 the OP clearly outlined the pros and cons of the approach. HBase will continue sending their specific metrics with metrics1 and Hadoop (common, hdfs, mapreduce) will send hadoop framework metrics with metrics2. i.e., in the transition period, ops would need to configure both hadoop-metrics.properties for HBase and hadoop-metrics2.properties for Hadoop. It's a working solution for the transition period.

bq. Could you please elaborate or post links on how to get metrics2 run. We use Ganglia.

The syntax to configure a consumer/sink for metrics (in the hadoop-metrics2.properties):
{noformat}
[service-name].sink.[sink-name].[option]=value
{noformat}
Some examples are included in the trunk conf/hadoop-metrics2.properties for common and hdfs, as well as the [configuration section|http://wiki.apache.org/hadoop/HADOOP-6728-MetricsV2#Configuration] of the [design doc|http://wiki.apache.org/hadoop/HADOOP-6728-MetricsV2].

An example of metrics2 config using ganglia (3.0.x or 3.1.x?) would be:
{noformat}
*.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.Ganglia31
*.period=10

namenode.sink.ganglia.address=localhost:8649
jobtracker.sink.ganglia.address=localhost:8649
tasktracker.sink.ganglia.address=localhost:8649
{noformat}

Of course, the org.apache.hadoop.metrics2.sink.ganglia.* classes don't exist yet. We'll have to implement them (sink examples can be found in the FileSink or the EchoPlugin in the design doc.).
, bq. I should've mentioned, I haven't been following metrics closely, so any help from you, Luke, is greatly appreciated.

No problem. I'm committed to make the transition as painless as possible :), Hi Luke, I need to have Ganglia working with Metrics2.  I guess I need to code something like GangliaSink which writes/adapts to say GangliaContext41. Can you please provide me some hints so that I don't spend lot of time going the wrong way?  Your help much appreciated.  
Thanks
Priyo, Hi Priyo, let's discuss the design of the Ganglia plugin on HADOOP-7324. Since I'm not familiar with Ganglia internals, I have some questions to ask. Can you answer them there?

, 204 should be feature parity (and then some) with 0.20.2, Hadoop 0.20.204.0 was released today.]