[The getRestrictedParserDefault method was added to address CVE-2017-15713 and shipped as part of 2.7.5.  The idea behind the fix is to restrict the parsing of XML entities from a configuration Resource when that Resource may not be trusted.  Untrusted resources that are parsed from Resources that come from the classpath are trusted, but resources that come from file streams as a proxy user are not.  When parsing configs outside of the classpath as a proxy user, the contents are likely coming from conf data provided by a cluster user, and we would need to restrict certain XML entities in those cases.  Failing to do so could expose the contents of local files on the server to the cluster user which is the crux of the CVE.

I'll try to work through the repro steps listed in SPARK-25330 to see if I can reproduce the issue locally.  If successful it should be relatively straightforward to see where the suspect conf is coming from and why it breaks when parsing of that conf is restricted. Note that restricted parsing doesn't mean the contents are not parsed at all, rather that the parser won't honor certain requested directives in the XML stream.
, I haven't been able to reproduce the issue yet, but looking closer at the logs I think it's related to variable expansion.  Another aspect of restricted parsing is they are unable to access system properties or environment variables from the config since those could potentially contain secrets.  Looks like in the following log snippets for the good and bad runs, the user.name system property is not getting expanded in the bad run because the conf resource is untrusted:

Log excerpt from the session with hadoop 2.7.3:
{noformat}
18/09/06 08:12:04 INFO SessionState: Created HDFS directory: /tmp/hive-admin/user_b/799640f8-3d34-4cb7-90fe-5368c22881d5
{noformat}

Log excerpt from the session with hadoop 2.7.7:
{noformat}
18/09/06 07:23:09 INFO SessionState: Created HDFS directory: /tmp/hive-${user.name}/user_b
{noformat}

[~yumwang] would you mind running with the following patch to Hadoop 2.7.7's Configuration to see if this fixes the issue or at least gets significantly farther?  That would help validate my theory as to what's going on here.  The patch keeps XML directives restricted for untrusted sources but re-enables system property access.
{noformat}
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
index 5ce3e65..4df8491 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
@@ -905,7 +905,7 @@ public synchronized void reloadConfiguration() {
   
   private synchronized void addResourceObject(Resource resource) {
     resources.add(resource);                      // add to resources
-    restrictSystemProps |= resource.isParserRestricted();
+    restrictSystemProps = false;
     reloadConfiguration();
   }
{noformat}

If it indeed is the issue then we may need to reconsider the restriction on system properties.  Choices include:
- Removing the property expansion restriction completely so all system and env properties are available, and it would be up to admins to sanitize these when starting proxy servers
- Allowing system properties but restricting environment variables, if we feel env variables are more common for passing secrets
- Using a whitelist for system properties]