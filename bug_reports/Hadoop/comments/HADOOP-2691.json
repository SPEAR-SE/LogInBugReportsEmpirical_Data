[Triggering hudson test because this problem occurs only on the Hudson test runs., I see this problem even on a large cluster running the sort benchmark:

{noformat}2008-01-23 23:31:50,212 WARN org.apache.hadoop.fs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_1708782005609649024java.io.IOException: Bad response 1 for block blk_1708782005609649024 from datanode XXX.YYY.43.208:51582
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:1750)

2008-01-23 23:31:50,226 INFO org.apache.hadoop.fs.DFSClient: Closing old block blk_1708782005609649024
2008-01-23 23:31:50,226 WARN org.apache.hadoop.fs.DFSClient: Error Recovery for block blk_1708782005609649024 bad datanode[1] XXX.YYY.43.208:51582
2008-01-23 23:31:50,227 WARN org.apache.hadoop.fs.DFSClient: Error Recovery for block blk_1708782005609649024 bad datanode XXX.YYY.43.208:51582
2008-01-23 23:31:50,227 INFO org.apache.hadoop.fs.DFSClient: pipeline = XXX.YYY.44.144:58986
2008-01-23 23:31:50,227 INFO org.apache.hadoop.fs.DFSClient: pipeline = XXX.YYY.44.140:55589
2008-01-23 23:31:50,227 INFO org.apache.hadoop.fs.DFSClient: Connecting to XXX.YYY.44.144:58986
2008-01-23 23:31:50,285 INFO org.apache.hadoop.fs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink XXX.YYY.44.140:55589
2008-01-23 23:31:50,285 WARN org.apache.hadoop.fs.DFSClient: Error Recovery for block blk_1708782005609649024 bad datanode XXX.YYY.44.144:58986
2008-01-23 23:31:50,285 INFO org.apache.hadoop.fs.DFSClient: pipeline = XXX.YYY.44.140:55589
2008-01-23 23:31:50,285 INFO org.apache.hadoop.fs.DFSClient: Connecting to XXX.YYY.44.140:55589
2008-01-23 23:31:50,309 INFO org.apache.hadoop.fs.DFSClient: Exception in createBlockOutputStream java.io.EOFException
2008-01-23 23:31:50,346 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.io.IOException: All datanodes are bad. Aborting...
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:1831)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.access$1100(DFSClient.java:1479)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1571)
{noformat}, As of revision 614793, this problem is always reproducible in the HBase test case TestTableMapReduce on my dual core Dell laptop running windows. 

This test runs a MiniMRCluster and a MiniHBaseCluster on top of a MiniDFSCluster.

Since we normally set the Hadoop log level to WARN so we can more easily see HBase log messages, I am attaching a patch that will set the Hadoop log level to INFO for this test. 

Additionally, I am attaching the log file from a test run. The log file is truncated, because one of the HBase servers takes a real long time to shut down, and that part of the log is irrelevant to this issue (other than the fact, that the 'All datanodes are bad' error is what causes it to go psychotic., Patch to enable INFO level logging for Hadoop in TestTableMapReduce., Log file from failed test run., -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373905/build.log
against trunk revision 614721.

    @author +1.  The patch does not contain any @author tags.

    patch -1.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1661/console

This message is automatically generated., I did a Sort 100 run with the patch ( datanodesBad1.patch ) and did not see the errors., Hi Jim, I am unable to reproduce this problem on demand. Since you can reproduce this problem on your machine using a unit test, would it be possible for you to apply the patch datanodesBad1.patch and rerun this unit test on ur machine? If it fails, can you pl attach the output of the unit test? Really appreciate your help in this regard. thanks. , More debug messages in case this problem recurs. , I'm also seeing this problem with some hbase tasks that I'm running... I'll see if I can reliably reproduce the error without the patch, and then I'll try the patch
, Log file for patch datanodesBad1.patch, Log file for datanodesBad2.patch, Dhruba,

I tried both datanodesBad1.patch and datanodesBad2.patch and am still seeing the problem. I have attached log files for each run., Replaced old file because dfs log level was not set properly in the previous one., Upload again so that this is the latest uploaded patch file. Otherwise hudson will pick up the log file as a patch file., It must be something about Windows. After a reboot, the test works either with or without the patch. Once it fails, however, it continues to fail until the next reboot., +1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373962/datanodesBad3.patch
against trunk revision 614721.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1666/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1666/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1666/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1666/console

This message is automatically generated., I just committed this., Integrated in Hadoop-trunk #379 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/379/])]