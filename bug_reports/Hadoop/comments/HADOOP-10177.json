[Given a configured provider list the expected behavior will be:

-create, -delete, -roll: will affect the first non-transient provider (UserProvider is a transient context for job access to key material)
-list: the first provider

isTransient will be added to the KeyProvider interface.

The CLI will support a flag for indicating the specific provider to use as well for overriding the configured list.
Deleting keys will result in the old store being moved to the Trash in hdfs.

CLI output will indicate the provider/store being affected by the command and will indicate whether it is choosing the first of many - indicating that a deleted key may be recovered from Trash. Recovery will need some further thought however - considering that other keys may have been affected by subsequent CLI interactions. We may need have to introduce an addKey to the providers to move in a single key (and versions) at a time., Initial contribution of Key Provider CLI and related changes., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12622723/10177.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3429//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3429//console

This message is automatically generated., Comments:
* Add tests.
* Please keep the text to 79 columns.
* allow Command.execute to throw Exception.
* Add a help command including the non-standard options like --provider.
* All of the commands should use the first non-transient provider unless there is only one provider. (typically because the user specified --provider)
* make all of the commands throw out of execute so that the cli tool exits with a non-zero exit code.
* the CreateCommand shouldn't create a Metadata directly, since that isn't public API. Maybe we should change createKey so that it doesn't create any key versions and then add a follow up call to rollNewVersion., "All of the commands should use the first non-transient provider unless there is only one provider. (typically because the user specified --provider)"

Let's make sure that this is clear:

* if there is more than one provider configured then ALL commands will try and find the first non-transient
    - if there are none then we will choose the first?
* if there is only one provider configured or indicated via the --provider then that provider is used irrespective of it being transient or not.
* these requirements end up allowing keys to be "created" in transient providers - i'm not sure that the semantics of our versioning hold up in that context. When the transient provider expires so does the entire set of keyversions., My real goal is to have the default be the first non-transient provider, but that if they explicitly set the provider we use it regardless of whether it is transient or not. You can either use the singleton provider as a flag for the explicit provider set or create a new flag to specify that option.

* All commands should have the same way of finding the provider.
* If there are no non-transient providers and the user didn't specify, the command should fail.
* Doing a modify operation on a transient provider isn't very useful and should probably generate a warning.
, Latest revision + tests., removed unused imports., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12623249/10177-3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3437//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3437//console

This message is automatically generated., +1, I just committed this. Thanks, Larry!, SUCCESS: Integrated in Hadoop-trunk-Commit #5010 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5010/])
HADOOP-10177. Create CLI tools for managing keys. (Larry McCay via omalley) (omalley: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1558867)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyShell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/UserProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyShell.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #455 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/455/])
HADOOP-10177. Create CLI tools for managing keys. (Larry McCay via omalley) (omalley: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1558867)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyShell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/UserProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyShell.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1647 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1647/])
HADOOP-10177. Create CLI tools for managing keys. (Larry McCay via omalley) (omalley: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1558867)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyShell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/UserProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyShell.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1672 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1672/])
HADOOP-10177. Create CLI tools for managing keys. (Larry McCay via omalley) (omalley: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1558867)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyShell.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/UserProvider.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyShell.java
,     I've build trunk code, and try the "hadoop key" functions, finding that the command is only runnable when excluding dash from genericOptions, as follows I used. I know this is a tricky question, but dashless genericOptions seams being not consistent with Hadoop command principle. Isn't it? Or, I misuse the command?
{code}
% hadoop key create key1
% hadoop key roll key1
% hadoop key delete key1
{code}, Hi Kyle - I am surprised that it works with no dashes. I believe that it is built assuming double dashes - since the options are full words rather than abbreviated to a single letter. The help should indicate double dashes as well., Actually, I think that I misunderstood your expectations.
"key" and "create" are examples of command and subcommand.
"key1" is an argument to the subcommand.
The thinking was that they were subcommands which required no dashes and then the options required double dashes - since they were full words.
Again, the help should illustrate what is expected., Hello Larry

The help is very clear.

Actually, I use the following command and system prompt the usage, so I know what I typed is a wrong syntax.
{code}
% hadoop key -create key1
{code}

Then, I change to following command and the system accepted the command.
{code}
% hadoop key create key1
{code}, Usage with commands like svn and git has made the standard Unix usage to not have dashes on the subcommands.

On the other hand, the hadoop fs subcommands have had dashes before it was called Hadoop. I think we should change the hadoop fs command to make the dashes optional. (Obviously we can't completely remove them without breaking a *lot* of scripts.)
]