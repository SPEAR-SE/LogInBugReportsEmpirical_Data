[Hi Yang,

Please add more description on what logic difference you speak of here, and which versions of Apache Hadoop is affected by it.

Thanks! :), bq. i.e. we don't have goal size anymore

I believe this was intentional and to remove confusion around "specify number of maps to run" kind of needs, that doesn't sit well with files as input.

For the issue with the min/max size, do you mean to report that setting min-split-size has no impact in increasing number of input splits (i.e. mappers)? If possible, can you also attach in code form the bug you wish to report (like, a test case of whats to be expected vs. reality)?, Harsh:

this is an issue in PIG, which uses the same config for multiple jobs in the same pig script. (one pig script normally translates to several MR jobs)


let's say, for the first PIG stage, I have a huge input file (10G). by default hadoop launches about 10G/128MB = 100 mappers.

if I have 400 mapper slots, I want to launch 400 mappers.  with the old InputFormat code, I could set min.split.size=25MB, with the new code, I could also set max.split.size=25MB, both would work fine.


but the next stage in pig script would take an input of 100GB, now, with 25MB split size,it's going to generate 4000 mappers, which is too much for my 400 slots.
in the old code, I could set "mapred.map.tasks=400" to control the upper limit of map tasks number, or the lower limit of split size (which takes into effect in the Math.max() in computeSplitSize()  ). so I can still maintain 400 mappers.  but the new code would lead to 4000 mappers, which don't make sense anymore.




, here is a patch to use the new mapreduce.job.maps  config param

it's the same spirit as the old mapred.map.tasks


I have not tested this since the github source I pulled does not build . Harsh could you please try this?

Thanks
Yang]