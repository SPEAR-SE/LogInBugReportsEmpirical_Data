[[~stevel@apache.org] Should we consider to solve the colon issue in object storage? It is very common in OSS/S3 or some other object storage., cc [~drankye], Thanks [~uncleGen] for the ping.

I'm not sure about this, but could you give some point to some doc that says such special char(s) is allowed? Or some examples? If yes, surely we should support and conform to it., Every filesystem has invalid paths and characters. I Dont' see why we should explicilty be blocking ":"; in fact I think the format of gcs logs uses it.

What is blocking it? {{Path}} itself? Or {{java.net.URI}}?, [~drankye] and [~stevel@apache.org] Please take a look at SPARK-20061. I think it is a good case. It is valid to create object whose key name contains colon. We will fail to read them in some scenes., Also this doc: http://labs.totango.com/spark-read-file-with-colon/, Hi Genmao,

I have the same question as [~stevel@apache.org] asked:
bq. What is blocking it? Path itself? Or java.net.URI?

What's your filepath like in your question? Can you give me a file/path example? Thanks. An URI surely can contain a colon, like {{s3a://mybucket}} or {{oss://mybucket}}. Do you mean to support colons in other URI components?, Unable to support ':' is a long standing issue, as early as HDFS-13.  I have a patch ([2066_20071022.patch|https://issues.apache.org/jira/secure/attachment/12368184/2066_20071022.patch]) there (wow) almost 10 years ago.

One problem is that the general URI syntax is very general.  We could safely assume that our URIs are [hierarchical URIs|http://docs.oracle.com/javase/8/docs/api/java/net/URI.html], i.e. 
{code}
[scheme:][//authority][path][?query][#fragment] 
{code}
or even
{code}
[[scheme:]//authority]path
{code}
Then, the problem becomes fixable as shown in [this comment|https://issues.apache.org/jira/browse/HDFS-13?focusedCommentId=12536875&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-12536875].  , Nicholas has pointed out the history of this —looks like it's old and fairly fundamental.

Quick case-by-case workarounds aren't the right place to do it. As an example, those globber fixes are at best going to handle the case where the last element in a path contains a ":", code in which a parent path contains a colon, e,g "s3a://bucket/elt1:name/child2 is probably doomed, if not immediately, certainly when later things happen like it gets sent over the wire, deserialized, saved to the list of files to distcp, reloaded, etc. etc.

Fixing this is a major piece of work, which will include tests (if HDFS adds ":" support, miniHDFS can be the test FS, otherwise some mock ramfs is needed). Along with the changes to the FS spec, we'd need a contract test for all supporting filesystems to implement, including the object stores, testing all those corner case and operations we can think of. Probably time to do a decent set of globber tests there too, which the contract lacks.

I think that could be good, HADOOP-3257 would the be place, and HDFS the team to collaborate with., Thanks Nicholas and Steve for the history and very interesting. Yes it looks like a major work, maybe need a community wide discussion and decision regarding fixing it or not. Not sure how many users want to support this, but guess cloud storages would like it? Support HDFS is OK not to support colon so the work can be limited to Hadoop FileSystem and the common library., like you say, HDFS support is irrelevant. It's about the Path type, the FS APIs and the implementation, Oh, and the new contract test suite, obviously,

It's precisely because ":" works in blobstores that some systems generate blobs with it in, google logs are a key example...that's data to be analysed. What I don't want is piecemeal patches which only support some use cases "glob for spark queries" which fail on others (create files with : in, them; recursive list files of directory trees with ":" in the path, directories with colon, etc)
Probably all are valid
{code}
x://dir:name/file
x://dir/dir:2/file
x://dir:name/dir:2/file
x://dir/d3/log:file.gz
{code}
What is interesting is: would a colon be valid as the sole path element?
{code}
x://:/:/:.gz
x://:/:/:
{code}
It's not automatic that this has to hold; you can use a "." in a path element, but "." and ".." cannot be path elements themselves

Anway, something for HADOOP-3257.



, I voted for this issue it will enable Hive tables over private home directories in S3.  The Home directories over S3 are required to have a colon in their object path as:  aws:username, aws:userid, and aws:principaltype
http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_variables.html

3257 has been open for 8+ years now - hoping enough Hadoop users have interest for it to get attention.
, Yes, we should fix it.

We probably should first define a grammar so that our implementation stands on a more rigorous ground., bq. The Home directories over S3 are required to have a colon in their object path as: aws:username, aws:userid, and aws:principaltype

that's unrelated to hadoop paths, as that's information in resource policies. There's no support in hadoop for IAM permissions; client code assumes the ability to write all the way down the root of a bucket. Separate buckets with separate permissions is the standard practise, Hello there,
I wanted to continue this discussion regarding support of colon ( : ) in Path.
I am attaching a proposal with changes as well as a reference to the changes I have made so far (I can definitely submit a PR).
Would be glad to hear opinions., Apparently I can't attach anything to this JIRA since I did not open it. So I attached a proposal to https://issues.apache.org/jira/browse/HADOOP-14829, [~yufeldman] just adding you as a Hadoop contributor, assigned this to you. Now you should be able to play with this issue now. Enjoy!, Proposal to support colon in Path, [~drankye] Thanks :), # I am supportive of an attempt to fix this
# The HDFS team really need to be the core reviewers
# The filesystem.md spec will need to be changed to match
# we're going to need a lot of tests, because, well, its important. I could imagine a new subclass of FS Contract test to actually check the handling of : in different filesystems, e.g what does HDFS do, windows, the different object stores. If another fs contract option is added so that filesystems under test can declare whether or not they handle ports, it'll be more visible what filesystems don't. Again, Windows is a suspect.

Speaking of windows, that has to work as today...there's work there for it.

Also:  needs to handle round trip Path -> String -> Path, or at least Path -> URI -> Path and Path -> URI -> String -> Path

Once that is done, I can help with some downstream tests for Spark

, Thank you [~stevel@apache.org] for the support.
I am wondering if we should concentrate first on supporting S3 and RawLocalFS with colon since those are the FileSystems that allow colons.
Though definitely other FileSystems should be thoroughly tested as well.
I have a patch (and/or can submit a PR) with unit tests for Path itself to handle colon that I will enhance to test:

{noformat}
round trip Path -> String -> Path, or at least Path -> URI -> Path and Path -> URI -> String -> Path
{noformat}

As well as probably adding some tests for RawLocalFS, S3 if possible and HDFS, GitHub user yufeldman opened a pull request:

    https://github.com/apache/hadoop/pull/269

    HADOOP-14217. Support colon in Hadoop Path

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/yufeldman/hadoop HADOOP-14217

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/hadoop/pull/269.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #269
    
----
commit c3c7225bd1f324ae3a9e6f6875e3d23d5725eb68
Author: Yuliya Feldman <yuliya@dremio.com>
Date:   2017-09-02T23:53:16Z

    HADOOP-14217. Support colon in Hadoop Path

----
, Github user steveloughran commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    I think some new Abstract FS Contract test will be needed to see how filesystems actually handle ":" chars; having the path support it is just one part of the problem
, Github user yufeldman commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    will do
, I have added few tests to FileSystemContractBaseTest and updated HDFS and WebHDFS to not run those tests, as HDFS and subsequently WebHdfs currently do not support colon in any portion of the path including FileName(s).
I did test with RawLocalFileSystem, S3(a,n). 
Since I can't test Azure, Swift, other FSs would be great to get feedback whether they support colon and can run those tests., Ping [~stevel@apache.org] and others
Any more feedback?, Github user vrozov commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    It will be good to change Path constructors that take `String child` as an argument to use `new Path(null, null, child)` instead of `new Path(child)`. It should help to handle cases like `new Path("file:/", "abc:/def");`.
, Github user yufeldman commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    @vrozov I don't think we can change existing constructors, only add one and one can use at their discretion, but we can't change all the code that is already written and uses existing constructors, especially the code that we use in our applications implicitly (two, three, ..., times removed from what we are trying to do)
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r143782941
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    --- End diff --
    
    Try to avoid code duplication by introducing `initialize(scheme, authority, path)` that both `Path(String)` and `Path(String, String, String)` may use.
, Github user vrozov commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    @yufeldman My suggestion is not to change all the code that is already written. I refer to `Path(String parent, String child)` constructor on line 114 that calls `new Path(child)`. There is no need to parse `child`, only `parent` may have scheme and authority.
, Github user yufeldman commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    @vrozov  I agree in principal that in Hadoop we do not consider that "child" can have scheme and it would help handling cases with ":/" in "child portion of path, but  according to URI resolve method it can be different configurations of merging parent and child.
    We would need very extensive testing to cover those cases. Also I believe there is method in Path:
    `mergePaths` that people are using to signify what you were saying.
    I would like to here more opinions on changing behavior of `Path(Path, Path)` to make it behave more like `mergePaths` method

, Github user vrozov commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    @yufeldman I am not sure that URI `resolve()` method (RFC2396 5.2) is directly applicable here even though `Path` uses `URI.resolve()` in its implementation. `Path` constructor refers to `parent` and `child`, that is different from constructing absolute URI from base and current, where current may be an absolute URI. For `Path(parent, child)`, I would not expect `child` to be an absolute Path.
, Github user yufeldman commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    @vrozov I don't disagree with you. I would like to get consensus (more input from stakeholders) on changing this behavior. This JIRA is least invasive.
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144105643
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    --- End diff --
    
    @yufeldman Also, it is not clear why is this change necessary? The comment is misleading as `scheme` is already initialized.
, Github user yufeldman commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144134499
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    --- End diff --
    
    Imagine string passed to that ctor is: `a:b` so with new changes `a:` is not really a scheme.
    Now when you try to construct URI with null scheme and authority URI will interpret `a:` as scheme unless path is started with `/`
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144171771
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    --- End diff --
    
    Should there be an explicit check for `null` scheme? Also, how ":/abc" is handled? Should it be considered as "abc" under ":", instead of an empty scheme that is not valid?
, Github user yufeldman commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144173326
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    --- End diff --
    
    Please check URI ctor for the behaviors you mentioned. Precautions I am taking is to avoid exceptions in URI ctor.
    Also I suggest you look at the doc I attached to JIRA (below is a paragraph from the doc):
    There are couple of cases that will not be handled by this approach or behavior will change.
    Namely:
    1. URI that consists only of the scheme - e.g. “x:” will result in Path: “./x:” (Today trying to
    create a URI from this string will result in error: “Relative path in absolute URI”)
    2. Path that has colon as last character before “/” - e.g. “abc:/bcd”. This will be interpreted
    as scheme “abc” and path “/bcd” - the same as today
    3. String such as: “urn:example:animal:ferret:nose” will be interpreted as
    “./urn:example:animal:ferret:nose” (Today trying to create a URI from this string will
    result in error: “Relative path in absolute URI”)
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144178845
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    --- End diff --
    
    I refer to a check for `scheme == null` prior to making path relative on Linux (`path = "./ + path`).
    According to your specification (item 2), ":/abc" will be interpreted as "/abc" with an empty scheme and still throw an exception. Will it be better to handle it as "./:/abc" path? 
, Github user yufeldman commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    @vrozov how about having a hangout meeting - maybe it's simpler that way?
, Github user vrozov commented on the issue:

    https://github.com/apache/hadoop/pull/269
  
    @yufeldman sure, if that will be easier.
, Github user yufeldman commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144330296
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -196,8 +196,7 @@ public Path(String pathString) throws IllegalArgumentException {
         // parse uri scheme, if any
         int colon = pathString.indexOf(':');
         int slash = pathString.indexOf('/');
    -    if ((colon != -1) &&
    -        ((slash == -1) || (colon < slash))) {     // has a scheme
    +    if ((colon != -1) && (colon == (slash-1))) {     // has a scheme
    --- End diff --
    
    @vrozov You have a point - if I change behavior here to colon > 0 it will support parts of path that are just ":".
    The only thing is different behavior when you merge two paths - `URI.resolve()` resolves it differently
    E.g:
    `/abc/:` and `:/:/` versus `/abc/:` and `/:/:/` 
    In first case result will be `/abc/:/:/:/` and in the second case `/abc/:/:/`
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144343525
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -196,8 +196,7 @@ public Path(String pathString) throws IllegalArgumentException {
         // parse uri scheme, if any
         int colon = pathString.indexOf(':');
         int slash = pathString.indexOf('/');
    -    if ((colon != -1) &&
    -        ((slash == -1) || (colon < slash))) {     // has a scheme
    +    if ((colon != -1) && (colon == (slash-1))) {     // has a scheme
    --- End diff --
    
    @yufeldman In the first case, you merge absolute and relative path, in the second case, there is an attempt to merge two absolute path, should they be handled differently if merging two absolute path should be allowed at all?
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144345844
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    +    // a colon e.q. "a:b" will not be interpreted as scheme "a".
    +    if (!WINDOWS && !path.isEmpty() && path.charAt(0) != '/') {
    --- End diff --
    
    Will it be better to change the condition to `if (!WINDOWS && scheme == null && colon != -1)`? I also have a concern regarding `WINDOWS`, as ":" is file system dependent, not OS specific, but this concern is beyond this PR and JIRA.
, Github user yufeldman commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144421230
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    +    // a colon e.q. "a:b" will not be interpreted as scheme "a".
    +    if (!WINDOWS && !path.isEmpty() && path.charAt(0) != '/') {
    --- End diff --
    
    What if it is: `/abc:bcd`. scheme == null, colon != -1? I don't think we want to add `/` once more. It will be than: `.//abc:bcd`
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144424600
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    +    // a colon e.q. "a:b" will not be interpreted as scheme "a".
    +    if (!WINDOWS && !path.isEmpty() && path.charAt(0) != '/') {
    --- End diff --
    
    `(scheme == null && slash > colon)`? What should happen in case of "./abc" and "./abc:"?
, Github user yufeldman commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144428228
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    +    // a colon e.q. "a:b" will not be interpreted as scheme "a".
    +    if (!WINDOWS && !path.isEmpty() && path.charAt(0) != '/') {
    --- End diff --
    
    sorry, I don't understand what you are implying. slash can be after colon - there could be many slashes and many colons.
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144434195
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    +    // a colon e.q. "a:b" will not be interpreted as scheme "a".
    +    if (!WINDOWS && !path.isEmpty() && path.charAt(0) != '/') {
    --- End diff --
    
    I refer to the first slash and the first colon in the passed `pathString` parameter:
    ```
    int colon = pathString.indexOf(':');
    int slash = pathString.indexOf('/');
    ```
    My understanding is that prepending "./" to the path, ensures that "/" is before ":" to avoid interpreting character sequence that `Path` does not recognized as scheme to be interpreted as scheme by `URI`. If there is no colon or slash is already before a colon, there is no need to add "./".
, Github user yufeldman commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144436106
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    +    // a colon e.q. "a:b" will not be interpreted as scheme "a".
    +    if (!WINDOWS && !path.isEmpty() && path.charAt(0) != '/') {
    --- End diff --
    
    Yes we have more info to make the check.  What is the advantage of this change?
    Three params ctor does have this check in place as well.
, Github user vrozov commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/269#discussion_r144437556
  
    --- Diff: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java ---
    @@ -214,6 +213,12 @@ public Path(String pathString) throws IllegalArgumentException {
         // uri path is the rest of the string -- query & fragment not supported
         String path = pathString.substring(start, pathString.length());
     
    +    // add "./" in front of Linux relative paths so that a path containing
    +    // a colon e.q. "a:b" will not be interpreted as scheme "a".
    +    if (!WINDOWS && !path.isEmpty() && path.charAt(0) != '/') {
    --- End diff --
    
    To avoid String concatenation and creation of unnecessary String objects. Prior to the patch, there was no "./" in case of a long path and it can (should?) be avoided with the patch if that long path does not contain ":".
    I am not a committer for Hadoop and it is a recommendation to consider only.
]