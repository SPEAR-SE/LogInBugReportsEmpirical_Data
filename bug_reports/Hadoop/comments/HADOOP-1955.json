[Hi Raghu, can you pl take a look into this one and suggest what could be done? Thanks. Possible options are:

1. Try different source locations for the replication,
2. Delete corrupted source replica
3. If all replicas are corrupt, stop replication., Yes, this is an issue. 

Koji, as a crude work around, could you try reading the file ? If reading succeeds, you could just manually remove the courrupt source block.
, Koji, did the work around help? I would like to know if asking different datanode to replicate would 
have helped in this case., For 0.14.x, I will implement using different source replica for different retries of the replication. will discuss with Dhruba.

Deleting corrupted replicas might be more involved for 0.14.x. 
Stopping replication after a few attempts requires a permenent structure in 'neededReplication'. This might be ok to do.

, 
Even in my dev set up, Namenode always asks the same datanode to replicate all the time.
I think the reason is that when there is not much for datanodes, {{computeDatanodeWork()}} always 
traverses from first node to the last one.  So in normal case, it always asks the same node to replicate. 

Fixing this might be the simplest thing for 0.14.x. I will try out a patch.

, 
When NameNode is not heavily loaded, each time {{computeDatanodeWork()}} goes through the nodes in the same order.  A side affect of this is that it asks the same node to replicate a block each time it tries to replicate it. 

When {{computeDatanodeWork}} runs through all the datanodes, this patch sets start index for next iteration to one after the datanode that was asked to replicate a node in the current iteration. This fixes the the problem seen in this jira (assuming the untried replica was not currpted). Initailly I thought of starting at random index but on a large cluster, it can take very long time before the second node is tried especially if the two source nodes are close to each other.

If all the remaining replicas are corrupted, Namenode will keep on trying. Thats ok, we would like the users to report such cases., +1. Code looks good. It would be nice to have a unit test for this one.

There should be a separate JIRA that allows detection & deletion of corrupted replicas. Can you pl file that one (if it does not already exists) and link it to this one? Thanks.
, I am adding a test case as part of TestPendingReplication.java., bq. If all the remaining replicas are corrupted, Namenode will keep on trying. Thats ok, we would like the users to report such cases.

I didn't get this part.  In my case, this infinite loop was started when one datanode went down and the namenode started replicating.  Does this mean, namenode will keep on trying until someone access the file and notice that it's corrupted?, bq. Koji, as a crude work around, could you try reading the file ? If reading succeeds, you could just manually remove the courrupt source block.

Thanks Raghu.  I haven't done this yet, but yes, this should work., bq. In my case, this infinite loop was started when one datanode went down and the namenode started replicating. Does this mean, namenode will keep on trying until someone access the file and notice that it's corrupted?

Yes, if there is no valid replica. In your case it is not clear if all the replicas are corrupted.

With this patch, Namenode will try all the remaining replicas for replicating a block.
If none of these succeed  (because all the replicas are corrupted), there is not much
Namenode can do about it. It will just keep on trying (evey 10 min) eventually someone
will notice the error.

In your case, if there is a good replica, it will be used in subsequent retries.

, 
The latest patch includes unit test for proper replication with corrupted blocks. 

The actual fix for the jira is confined to FSNamesystem.java. Rest of the changes are for the unit test.

I reluctantly added two config variables (not public in hadoop-default.xml) to make this test stable. One is a timeout for pendingReplication and other is timeout used by datanode to deleted the failed blocks from tmp directory. In the case of Datanode, an altrnative is to delete the tmp files immediately when a write fails. There is no reason to keep those failed blocks around.

Dhruba, could you scan through the test and other changes? Thanks.
, Code looks good. A few minor comments:

1. This test corrupts replicas of a block and checks to see that the Namenode detects this situation and replicates the remaining good copy. Does it really belong to TestReplication? Maybe TestCrcCorruption makes more sense.
2. The test waits for 60 seconds for waitForBlockReplication. I vote that we remove this timeout and make the test wait indefinitely. It might not be a good idea to put adhoc wait periods in the test. The test framework already enforces a timeout of 10 minutes per test.
3. Why do we need dfs.replication in the conf?, Code looks good. 

However, one minor point is that none of our tests should have a fixed timeout values. This might cause problems on different platforms. I would vote for removing the fixed time of 60 seconds and wait indefinitely. I would like Nigel's input on this one., Updated patches have infinite time. Only to change is to change '60' to '-1'. One issue with not having a timeout is that when the test framework times out, we don't have access to the log, which makes it hard to debug., I like this. +1., > 1. This test corrupts replicas of a block and checks to see that the Namenode detects this situation and replicates the remaining good copy. Does it really belong to TestReplication? Maybe TestCrcCorruption makes more sense.

Sorry I missed this one earlier. The fix is for replication code. Corrupting the block is just one way of
making sure that if Namenode does not use all available replicas, the test fails. This is a test for Namenode replication policy.
, Also there is TestReplication.java, may be we should move the test there. Let me know. 
Currently it is under TestPendingReplication.java
, -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12367036/HADOOP-1955.patch
against trunk revision r581745.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs -1.  The patch appears to introduce 1 new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/882/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/882/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/882/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/882/console

This message is automatically generated., fixed findbugs warning. 

Also moved the unit test to TestReplication.java from TestPendingReplication.java, -1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12367096/HADOOP-1955.patch
against trunk revision r581982.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/887/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/887/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/887/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/887/console

This message is automatically generated., +1, finally! build test failed is not related to this patch., I just committed this.Thanks Raghu., Integrated in Hadoop-Nightly #261 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/261/]), when all replicas are corrupt]