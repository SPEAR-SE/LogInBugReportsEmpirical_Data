[Post my v001 patch. It has a simple fix: adding delegation tokens from all KMS providers.

The unit test runs two KMS to form KMS HA, using ZooKeeper to store delegation tokens, and use delegation tokens to access without Kerberos to induce the error (if without the fix)., Hi [~jojochuang], Thanks for working on this. Seems you forgot to include the fix code in the patch.
, Sorry about that. Here's the patch that includes both fix and test., No problem [~jojochuang]. 

Thanks for the updated patch. I looked at have a high level comment:

Looks to me that the following operations need to have similar fix, given a token to renew and cancel, we can either derive the KMS from the service field in the token, and operate on this KMS directly, or use a loop like the one you changed with addDelegationToken.

{code}
 @Override
  public long renewDelegationToken(final Token<?> token) throws IOException {
    return doOp(new ProviderCallable<Long>() {
      @Override
      public Long call(KMSClientProvider provider) throws IOException {
        return provider.renewDelegationToken(token);
      }
    }, nextIdx());
  }

  @Override
  public Void cancelDelegationToken(final Token<?> token) throws IOException {
    return doOp(new ProviderCallable<Void>() {
      @Override
      public Void call(KMSClientProvider provider) throws IOException {
        provider.cancelDelegationToken(token);
        return null;
      }
    }, nextIdx());
  }
{code}
Do you agree?

Thanks.
, Hi [~yzhangal] thanks for chiming in.
I've thought about that too, but if renew/cancel fails for a specific KMS, the client re-tries with the next KMS in a round robin fashion. So these operations will succeed eventually. Renew in particular is issued once in a few days., But I don't see the catch/retry in Hadoop code. Do we expect client code to do so? It seems we should do it within Hadoop. [~jojochuang].
 , The LoadBalancingKMSClientProvider#doOp() does so. 

Thanks, The LoadBalancingKMSClientProvider#doOp() only try one index at a time. I don't see retry there. Thanks.

, the doOp() has a for loop. If one KMS provider fails for the request, the exception is caught and it goes to the next one, until all of them are tried., Oops sorry, somehow I missed that. Thanks!
, Hi [~jojochuang], 

The fix side looks good to me. I'd suggest to add some comment in the test code, to explain/indicate the expected outcome of the different parts in doKMSHAWithZKWithDelegationToken.

Thanks.
, Thanks [~yzhangal] for the review. Attaching rev 003 to add comments to explain the test code., [~jojochuang] We run sort of kms-ha with having 2 servers behind vip.
We don't face this issue. We have back-end zookeeper to sync the state between multiple kms servers.
Even if you have zookeeper enabled, what is the value of this config {{hadoop.kms.authentication.zk-dt-secret-manager.enable}} ?
Can you post some stack trace ?
I don't think the correct fix is to get delegation token from all the servers.
Even after the fix, the jobs can fail if one the servers went temporarily down and came back later and if the job was launched in between these time frame., Hi [~shahrs87], There are two ways to configure KMS-HA: one is to use KMS servers behind VIP, and the other is via LoadBalancingKMSClientProvider, which is adopted by Cloudera. From a high level perspective, clients are not aware of KMS HA in the former configuration, and the VIP is responsible for routing the requests; while in the latter, the client are aware there are multiple KMS servers and itself is responsible for routing the requests to the KMS servers.

The bug described here is purely a problem using LoadBalancingKMSClientProvider configuration. When a KMS client requests a delegation token from KMS server, it uses the server address/port as the key to store dt in its UGI Credentials map:

{code:title=DelegationTokenAuthenticatedURL#getDelegationToken}
public org.apache.hadoop.security.token.Token<AbstractDelegationTokenIdentifier>
      getDelegationToken(URL url, Token token, String renewer, String doAsUser)
          throws IOException, AuthenticationException {
    Preconditions.checkNotNull(url, "url");
    Preconditions.checkNotNull(token, "token");
    try {
      token.delegationToken =
          ((KerberosDelegationTokenAuthenticator) getAuthenticator()).
              getDelegationToken(url, token, renewer, doAsUser);
      return token.delegationToken;
    } catch (IOException ex) {
      token.delegationToken = null;
      throw ex;
    }
  }
{code}
The problem is that the client is aware of the real server addreess/port, so when it looks up its Credentials map, the delegation token acquired from one KMS server can not be used for another KMS server.

The test case attached to this jira accurately capture the problem and the error.

bq. Even after the fix, the jobs can fail if one the servers went temporarily down and came back later and if the job was launched in between these time frame.
I agree this is a problem. Presumably there's a way for KMS to share the same URL, but the current Hadoop Authentication framework is shared by multiple agents including YARN client, so I am not sure what would be a better approach to fix it without affect other agents., I agree with [~shahrs87]. If the KMS is configured to use the ZK delegationtoken secret manager, you would not need to add the DTs from all KMS instances.
Since a DT issued by 1 KMS instance will be validated by any of its peers., Here's some sample stack trace. Note I added additional debug logs so it's quite cluttered. In summary, the client has delegation tokens, but it's not for this particular KMS instance.

2017-05-17 18:44:53,382 DEBUG LoadBalancingKMSClientProvider - trying provider https://weichiu-foo-3.example.com:16000/kms/v1/
2017-05-17 18:44:53,383 WARN  Token - Cannot find class for token kind kms-dt
2017-05-17 18:44:53,384 WARN  Token - Cannot find class for token kind kms-dt
2017-05-17 18:44:53,384 DEBUG KMSClientProvider - KMS provider [https://weichiu-foo-3.example.com:16000/kms/v1/] actual ugi = foo (auth:KERBEROS) subject=Subject:
        Principal: UnixPrincipal: foo
        Principal: UnixNumericUserPrincipal: 2004
        Principal: UnixNumericGroupPrincipal [Primary Group]: 2004
        Principal: foo
        Private Credential: tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f
55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
key=ha-hdfs:ns1 value=Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo);
key=172.31.123.173:16000 value=Kind: kms-dt, Service: 172.31.123.173:16000, Ident: 00 07 61 74 74 69 76 69 6f 04 79 61 72 6e 00 8a 01 5c 19 39 a4 43 8a 01 5c 3d 46 28 43 25 22;
secretKeysMap:
 current ugi=foo (auth:KERBEROS) subject=Subject:
        Principal: UnixPrincipal: foo
        Principal: UnixNumericUserPrincipal: 2004
        Principal: UnixNumericGroupPrincipal [Primary Group]: 2004
        Principal: foo
        Private Credential: tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
key=ha-hdfs:ns1 value=Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo);
key=172.31.123.173:16000 value=Kind: kms-dt, Service: 172.31.123.173:16000, Ident: 00 07 61 74 74 69 76 69 6f 04 79 61 72 6e 00 8a 01 5c 19 39 a4 43 8a 01 5c 3d 46 28 43 25 22;
secretKeysMap:
 url=https://weichiu-foo-3.example.com:16000/kms/v1/keyversion/yH32H7e2tnhd38HGrb45OlrG4xHYJheOs4ITA5NhZbr/_eek?eek_op=decrypt authToken=null doAsUser=null
2017-05-17 18:44:53,385 WARN  Token - Cannot find class for token kind kms-dt
2017-05-17 18:44:53,386 WARN  Token - Cannot find class for token kind kms-dt
2017-05-17 18:44:53,388 DEBUG UserGroupInformation - PrivilegedAction as:foo (auth:KERBEROS) subject=Subject:
        Principal: UnixPrincipal: foo
        Principal: UnixNumericUserPrincipal: 2004
        Principal: UnixNumericGroupPrincipal [Primary Group]: 2004
        Principal: foo
        Private Credential: tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
key=ha-hdfs:ns1 value=Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo);
key=172.31.123.173:16000 value=Kind: kms-dt, Service: 172.31.123.173:16000, Ident: 00 07 61 74 74 69 76 69 6f 04 79 61 72 6e 00 8a 01 5c 19 39 a4 43 8a 01 5c 3d 46 28 43 25 22;
secretKeysMap:
 from:org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(KMSClientProvider.java:489). subject=Subject:
        Principal: UnixPrincipal: foo
        Principal: UnixNumericUserPrincipal: 2004
        Principal: UnixNumericGroupPrincipal [Primary Group]: 2004
        Principal: foo
        Private Credential: tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
key=ha-hdfs:ns1 value=Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo);
key=172.31.123.173:16000 value=Kind: kms-dt, Service: 172.31.123.173:16000, Ident: 00 07 61 74 74 69 76 69 6f 04 79 61 72 6e 00 8a 01 5c 19 39 a4 43 8a 01 5c 3d 46 28 43 25 22;
secretKeysMap:
.java.lang.Throwable
        at org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction(UserGroupInformation.java:1687)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1662)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(KMSClientProvider.java:489)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.decryptEncryptedKey(KMSClientProvider.java:787)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$3.call(LoadBalancingKMSClientProvider.java:192)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$3.call(LoadBalancingKMSClientProvider.java:188)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:97)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.decryptEncryptedKey(LoadBalancingKMSClientProvider.java:188)
        at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.decryptEncryptedKey(KeyProviderCryptoExtension.java:388)
        at org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(DFSClient.java:1381)
        at org.apache.hadoop.hdfs.DFSClient.createWrappedInputStream(DFSClient.java:1451)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:305)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:299)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:312)
2017-05-17 18:44:53,388 DEBUG DelegationTokenAuthenticatedURL - token is not set
2017-05-17 18:44:53,389 DEBUG Credentials - addAll: called by java.lang.Throwable
        at org.apache.hadoop.security.Credentials.addAll(Credentials.java:315)
        at org.apache.hadoop.security.Credentials.addAll(Credentials.java:302)
        at org.apache.hadoop.security.Credentials.<init>(Credentials.java:77)
        at org.apache.hadoop.security.UserGroupInformation.getCredentials(UserGroupInformation.java:1480)
        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.openConnection(DelegationTokenAuthenticatedURL.java:294)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider$1.run(KMSClientProvider.java:494)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider$1.run(KMSClientProvider.java:489)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1663)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(KMSClientProvider.java:489)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.decryptEncryptedKey(KMSClientProvider.java:787)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$3.call(LoadBalancingKMSClientProvider.java:192)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$3.call(LoadBalancingKMSClientProvider.java:188)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:97)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.decryptEncryptedKey(LoadBalancingKMSClientProvider.java:188)
        at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.decryptEncryptedKey(KeyProviderCryptoExtension.java:388)
        at org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(DFSClient.java:1381)
        at org.apache.hadoop.hdfs.DFSClient.createWrappedInputStream(DFSClient.java:1451)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:305)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:299)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:312)

2017-05-17 18:44:53,390 DEBUG Credentials - addAll token key 172.31.117.206:8032 to this=tokenMap: secretKeysMap: : Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02
2017-05-17 18:44:53,390 DEBUG Credentials - addAll token key ha-hdfs:ns1 to this=tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
secretKeysMap: : Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo)
2017-05-17 18:44:53,391 WARN  Token - Cannot find class for token kind kms-dt
2017-05-17 18:44:53,391 DEBUG Credentials - addAll token key 172.31.123.173:16000 to this=tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
key=ha-hdfs:ns1 value=Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo);
secretKeysMap: : Kind: kms-dt, Service: 172.31.123.173:16000, Ident: 00 07 61 74 74 69 76 69 6f 04 79 61 72 6e 00 8a 01 5c 19 39 a4 43 8a 01 5c 3d 46 28 43 25 22
2017-05-17 18:44:53,392 WARN  Token - Cannot find class for token kind kms-dt
2017-05-17 18:44:53,392 DEBUG DelegationTokenAuthenticatedURL - credentials: tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00
 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
key=ha-hdfs:ns1 value=Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo);
key=172.31.123.173:16000 value=Kind: kms-dt, Service: 172.31.123.173:16000, Ident: 00 07 61 74 74 69 76 69 6f 04 79 61 72 6e 00 8a 01 5c 19 39 a4 43 8a 01 5c 3d 46 28 43 25 22;
secretKeysMap:
2017-05-17 18:44:53,392 DEBUG DelegationTokenAuthenticatedURL - credentials is not empty. Fetching tokens now
2017-05-17 18:44:53,392 DEBUG DelegationTokenAuthenticatedURL - serviceAddr=weichiu-foo-3.example.com/172.31.123.166:16000 text=172.31.123.166:16000
2017-05-17 18:44:53,392 DEBUG DelegationTokenAuthenticatedURL - dToken=null
2017-05-17 18:44:53,392 DEBUG DelegationTokenAuthenticator - do I have delegation token? false
2017-05-17 18:44:53,427 DEBUG KerberosAuthenticator - Performing our own SPNEGO sequence.
2017-05-17 18:44:53,428 DEBUG KerberosAuthenticator - No subject in context, logging in
2017-05-17 18:44:53,428 DEBUG KerberosAuthenticator - Using subject: Subject:
        Principal: UnixPrincipal: foo
        Principal: UnixNumericUserPrincipal: 2004
        Principal: UnixNumericGroupPrincipal [Primary Group]: 2004

2017-05-17 18:44:53,431 WARN  Token - Cannot find class for token kind kms-dt
2017-05-17 18:44:53,431 DEBUG UserGroupInformation - PrivilegedActionException as:foo (auth:KERBEROS) subject=Subject:
        Principal: UnixPrincipal: foo
        Principal: UnixNumericUserPrincipal: 2004
        Principal: UnixNumericGroupPrincipal [Primary Group]: 2004
        Principal: foo
        Private Credential: tokenMap: key=172.31.117.206:8032 value=Kind: RM_DELEGATION_TOKEN, Service: 172.31.117.206:8032, Ident: 00 18 61 74 74 69 76 69 6f 40 47 43 45 2e 43 4c 4f 55 44 45 52 41 2e 43 4f 4d 04 79 61 72 6e 00 8a 01 5c 19 39 a4 55 8a 01 5c 3d 46 28 55 1a 02;
key=ha-hdfs:ns1 value=Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ns1, Ident: (HDFS_DELEGATION_TOKEN token 110 for foo);
key=172.31.123.173:16000 value=Kind: kms-dt, Service: 172.31.123.173:16000, Ident: 00 07 61 74 74 69 76 69 6f 04 79 61 72 6e 00 8a 01 5c 19 39 a4 43 8a 01 5c 3d 46 28 43 25 22;
secretKeysMap:
 cause:org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
2017-05-17 18:44:53,431 WARN  LoadBalancingKMSClientProvider - KMS provider at [https://weichiu-foo-3.example.com:16000/kms/v1/] threw an IOException [org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]!!
2017-05-17 18:44:53,433 WARN  LoadBalancingKMSClientProvider - stacktrace=java.io.IOException: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(KMSClientProvider.java:500)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.decryptEncryptedKey(KMSClientProvider.java:787)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$3.call(LoadBalancingKMSClientProvider.java:192)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$3.call(LoadBalancingKMSClientProvider.java:188)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:97)
        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.decryptEncryptedKey(LoadBalancingKMSClientProvider.java:188)
        at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.decryptEncryptedKey(KeyProviderCryptoExtension.java:388)
        at org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(DFSClient.java:1381)
        at org.apache.hadoop.hdfs.DFSClient.createWrappedInputStream(DFSClient.java:1451)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:305)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:299)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:312)foo, Hi [~asuresh] thanks for commenting on this.
bq. I agree with Rushabh S Shah. If the KMS is configured to use the ZK delegationtoken secret manager, you would not need to add the DTs from all KMS instances.
My test uses doKMSWithZK() which has hadoop.kms.authentication.zk-dt-secret-manager.enable = true.
bq. Since a DT issued by 1 KMS instance will be validated by any of its peers.
I agree with you completely.
The problem is the client side does not know that it should authenticate the KMS#2 using the delegation token obtained from KMS#1. Please take a look at the following code:

{code:title=DelegationTokenAuthenticatedURL#openConnection}
// delegation token
      Credentials creds = UserGroupInformation.getCurrentUser().
          getCredentials();
      if (!creds.getAllTokens().isEmpty()) {
        InetSocketAddress serviceAddr = new InetSocketAddress(url.getHost(),
            url.getPort());
        Text service = SecurityUtil.buildTokenService(serviceAddr);
        dToken = creds.getToken(service); <----- this becomes null in my test case.
        if (dToken != null) {
          if (useQueryStringForDelegationToken()) {
            // delegation token will go in the query string, injecting it
            extraParams.put(
                KerberosDelegationTokenAuthenticator.DELEGATION_PARAM,
                dToken.encodeToUrlString());
          } else {
            // delegation token will go as request header, setting it in the
            // auth-token to ensure no authentication handshake is triggered
            // (if we have a delegation token, we are authenticated)
            // the delegation token header is injected in the connection request
            // at the end of this method.
            token.delegationToken = (org.apache.hadoop.security.token.Token
                <AbstractDelegationTokenIdentifier>) dToken;
          }
        }
      }
{code}, Thanks for the clarification [~jojochuang]..
I see your point. So I guess there are possibly 2 ways to fix this:
# As you suggested, perhaps have the LBKMSProvider collect delegation tokens from EACH kms instance and store it in the client credential against it corresponding service url. This would mean we might not need to use ZKDTSM to replicate the DTs across all KMS instances.
# First time we get a DT from any one of the kms instances, we store the same DT against ALL the service urls in the user credential. This would require the ZKDTSM to be configured, to replicate the DT to all kms instances.
Not sure about how involved the changes for option 2 would be though.
, I agree this is a problem.
Right now we can fix it temporarily but getting delegation tokens from all the providers would pose problems at scale.
We need to rethink for a scalable solution later on.

, Can we wait till EOD before checking in this patch ?, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 31s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 22s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 33s{color} | {color:red} hadoop-common-project/hadoop-common in trunk has 19 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 23s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 43s{color} | {color:orange} hadoop-common-project: The patch generated 4 new + 101 unchanged - 3 fixed = 105 total (was 104) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 42s{color} | {color:red} hadoop-common-project/hadoop-common generated 1 new + 19 unchanged - 0 fixed = 20 total (was 19) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 18s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  8s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 75m 40s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-common-project/hadoop-common |
|  |  instanceof will always return true for all non-null values in org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.addDelegationTokens(String, Credentials), since all RuntimeException are instances of RuntimeException  At LoadBalancingKMSClientProvider.java:for all non-null values in org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.addDelegationTokens(String, Credentials), since all RuntimeException are instances of RuntimeException  At LoadBalancingKMSClientProvider.java:[line 153] |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14441 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12869273/HADOOP-14441.003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux edab20cf5ac6 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b6f66b0 |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12372/artifact/patchprocess/branch-findbugs-hadoop-common-project_hadoop-common-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/12372/artifact/patchprocess/diff-checkstyle-hadoop-common-project.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12372/artifact/patchprocess/new-findbugs-hadoop-common-project_hadoop-common.html |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12372/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12372/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Sure. Thanks, I sort of have a sample patch ready which will not need getting delegation token from all the providers.
While writing the test case, I found that there is no way to create LoadBalancingKmsClientProvider uri with different port for each provider.
Since unit tests will always have hostname as localhost, the only differentiating factor would be the port number.
In the source code there is comment which says the same thing.
{code:title=KMSClientProvider.java|borderStyle=solid}
 public KeyProvider createProvider(URI providerUri, Configuration conf)
{
    ....
    ....
  // Check if port is present in authority
        // In the current scheme, all hosts have to run on the same port
        int port = -1;
        String hostsPart = authority;
        if (authority.contains(":")) {
          String[] t = authority.split(":");
          try {
            port = Integer.parseInt(t[1]);
          } catch (Exception e) {
            throw new IOException(
                "Could not parse port in kms uri [" + origUrl + "]");
          }
          hostsPart = t[0];
        }
        return createProvider(providerUri, conf, origUrl, port, hostsPart);
}
{code}
Does anyone know how to create LBKMSClientProviderUrl with different ports ?, [~shahrs87], have you tried this by any chance ?
bq. First time we get a DT from any one of the kms instances, we store the same DT against ALL the service urls in the user credential. This would require the ZKDTSM to be configured, to replicate the DT to all kms instances.
And yeah, the LBKMSClientProvider requires all services to use the same port., bq. Does anyone know how to create LBKMSClientProviderUrl with different ports ?
Using the default factory, you can't. The way around this is to create a dummy KeyProviderFactory that extends the KMSKeyProviderFactory that constructs the LBKMSClientProvider the way your test case desires. The name of the Dummy Key Provider should then be added to the resources/META-INF/services/org.apache.hadoop.crypto.key.KeyProviderFactory file so that it can be instantiated., You can take a look at the test in my patch. I had to workaround that limitation as well. (See: createHAProvider()), If this helps, RM HA gets around the problem of different host:port for different RMs by setting the token's service to {{host1:port1,host2:port2}} (which gets stored in ZK and used by both RMs).
https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/client/ClientRMProxy.java#L144, bq. If this helps, RM HA gets around the problem of different host:port for different RMs by setting the token's service to host1:port1,host2:port2 (which gets stored in ZK and used by both RMs).
Thanks [~rkanter].
That's exactly what I am trying to do.
The test case attached in the patch works on my local machine.
Trying to create a good patch., [~shahrs87] thanks for your comments and your effort in creating the patch. I've been thinking about alternative way to fix it, but they all turn out to be either incompatible (adding extra parameters to public API), or unable to allow a client to get delegation tokens from multiple KMS clusters. If your patch is incompatible, would you mind to move over to HADOOP-14445 and use this one for a short term fix?

Thanks, Thanks for working on the issue here guys.

Hi [~shahrs87], it seems your patch fit HADOOP-14445 better. If HADOOP-14445 works compatibly, we may not need HADOOP-14441. Would you please post your patch there even though you are polishing the test now?

Thanks., HI [~shahrs87],

Would you mind posting your patch to HADOOP-14445 so that we can iterate? 

Thanks a lot.
, Post my rev 004 patch. This patch updates log message and prints kms delegation token obtained. I believe this will help troubleshotting KMS bugs easier in the future. With this patch, it print message similar to the following:

2017-05-25 10:36:57,468 INFO  LoadBalancingKMSClientProvider - Added delegation token Kind: kms-dt, Service: 127.0.0.1:51233, Ident: (kms-dt owner=SET_KEY_MATERIAL, renewer=foo, realUser=, issueDate=1495733816938, maxDate=1496338616938, sequenceNumber=1, masterKeyId=2) from http://localhost:51233/kms/v1/, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 18s{color} | {color:red} hadoop-common-project/hadoop-common in trunk has 19 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 39s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 34s{color} | {color:orange} hadoop-common-project: The patch generated 4 new + 100 unchanged - 3 fixed = 104 total (was 103) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 35s{color} | {color:red} hadoop-common-project/hadoop-common generated 1 new + 19 unchanged - 0 fixed = 20 total (was 19) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m  1s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 47s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 26s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 65m 11s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-common-project/hadoop-common |
|  |  instanceof will always return true for all non-null values in org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.addDelegationTokens(String, Credentials), since all RuntimeException are instances of RuntimeException  At LoadBalancingKMSClientProvider.java:for all non-null values in org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.addDelegationTokens(String, Credentials), since all RuntimeException are instances of RuntimeException  At LoadBalancingKMSClientProvider.java:[line 154] |
| Failed junit tests | hadoop.fs.sftp.TestSFTPFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14441 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12869902/HADOOP-14441.004.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 551d1c7ee8a2 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 29b7df9 |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12397/artifact/patchprocess/branch-findbugs-hadoop-common-project_hadoop-common-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/12397/artifact/patchprocess/diff-checkstyle-hadoop-common-project.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12397/artifact/patchprocess/new-findbugs-hadoop-common-project_hadoop-common.html |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12397/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12397/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12397/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, bq. Would you mind posting your patch to HADOOP-14445 so that we can iterate?
[~yzhangal]: Posted branch-2.8 patch on HADOOP-14445.
Will appreciate your feedback., Moving target version to 2.7.5 due to 2.7.4 release., This jira is not moving forward and is a duplicate of HADOOP-14445. Let's concentrate the discussion at HADOOP-14445 instead.]