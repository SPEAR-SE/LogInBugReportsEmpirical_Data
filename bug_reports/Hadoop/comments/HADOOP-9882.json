[Jean! This change has recently been made as part of HADOOP-9845. What I am noticing is this:

[ERROR] Failed to execute goal org.apache.hadoop:hadoop-maven-plugins:3.0.0-SNAPSHOT:protoc (compile-protoc) on project hadoop-common: java.lang.NullPointerException -> [Help 1]

This problem magically goes away if I continue the build using -rf :hadoop-common flag. Were you planning to fix that?
, > ... protoc version is 'libprotoc 2.4.1', expected version is '2.5.0' ...

As indicated in the error message, please upgrade protoc to 2.5.0, clean all generated files and then rebuild.  So I think this JIRA is invalid., {noformat}
[WARNING] [protoc, --version] failed with error code 1
{noformat}

This will be the first message you will see if you don't have the correct version of protoc.  If you need to keep the old version of protoc, please consult the updated instruction in BUILDING.txt. , Yes, but I never installed protoc on my machine and it built without problem before.
I'm agree that the update to protobuf is a good one, but it's disturbing for the users.

I started from a mvn clean. So it's supposed to cleanup all the files. So:
1/ the clean goal doesn't purge all files
2/ the clean is not enough

On the other hand, we have the NPE, which is also "disturbing"., > Yes, but I never installed protoc on my machine ...

I guess someone might have installed protoc without your notice.  Otherwise, hadoop wouldn't build.

> ..., but it's disturbing for the users.

We consider you are a developer/an advanced user since you are compiling trunk.  :), Hi Jean

you already must have protoc-2.4.1 installed. (protoc --version). Try upgrading to 2.5.0

1. Download protocol buffer. 
2. Check if g++ compiler is installed on box. Protocol buffer needs g++ compiler to be present on your box before it can be builded. This is a crisp post on how to install g++ compiler on your box. Install g++ compiler.
3. Extract the protocol buffer archive and switch to the extracted directory.
4. Inside the extracted directory hit the below commands to install protocol buffer. These may take a while, kindly be patient.

$ sudo ./configure
$ sudo make
$ sudo make check
$ sudo make install
$ protoc --version, I now have an opposite-ish problem I think.  I followed all of the directions, but now my protoc is at 3.0.0 and hadoop is still looking for 2.5.0.  I tried modifying hadoop-project/pom.xml ... but that just caused an issue finding the 3.0.0 on the java and jar.  oi!!  Even if I can get it to allow me to use the 3.0.0 ... is there any way to be sure I won't cause issues down the road.  I am building on my notebook and only do basic unit testing there ... another X86-64 linux system is the target.  Not sure if protoc level is really that crucial ... but I guess if it is, I'm not going to help matters any., protobuf is version-locked because protobuf itself isn't forward/backward compatible with itself.  Hadoop requires v2.5.0, no higher, no lower., Try installing 2.5.0 and follow these instructions from BUILDING.txt.  My system has some newer version as the default, but I can point to an older installation and it works fine for me.

=====

Protocol Buffer compiler

The version of Protocol Buffer compiler, protoc, must match the version of the
protobuf JAR.

If you have multiple versions of protoc in your system, you can set in your
build shell the HADOOP_PROTOC_PATH environment variable to point to the one you
want to use for the Hadoop build. If you don't define this environment variable,
protoc is looked up in the PATH., more precisely, the java code generated by protoc is only compatible with the protobuf.jar of that exact version, and classpath setup means the entire Hadoop stack needs to agree on which version of the JAR to use. The wire format is compatible over time, just not the source layer., Thanks all.  You got me thru it.  I found and built 2.5.0 and that worked for Hadoop.  Had more problems w/Hadoop and IBM JVM (so I had to switch to Oracle) ... but moving forward and I thank you all.]