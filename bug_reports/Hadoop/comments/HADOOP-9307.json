[An example sequence of seeks which returns the wrong data is as follows, assuming a 4096-byte buffer:

{code}
seek(0);
readFully(1);
{code}

This primes the buffer. After this, the current state of the buffered stream is {{pos=0, count=4096, filepos=4096}}

{code}
seek(2000);
{code}

The seek sees that the required data is in already in the buffer, and just sets {{pos=2000}}

{code}
readFully(10000);
{code}

This first copies the remaining bytes from the buffer and sets {{pos=4096}}. Then, because 5904 bytes are remaining, and this is larger than the buffer size, it copies them directly into the user-supplied output buffer. This leaves the state of the stream at {{pos=4096, count=4096, filepos=12000}}

{code}
seek(11000);
{code}

The "optimization" in BufferedFSInputStream sees that there are 4096 buffered bytes, and that this seek is supposedly within the window, assuming that those 4096 bytes directly precede filepos. So, it erroneously just sets {{pos=3096}}.

The next read will then get the wrong results for the first 1000 bytes -- yielding bytes 3096-4096 of the file instead of bytes 11000-12000., I believe this may be the root cause of the behavior that [~eclark] was seeing in HADOOP-8336., Interesting. I saw some quirks with data read/writes talking to OpenStack swift, but felt that was eventual consistency related, not buffering. If you look in {{FileSystemContractBaseTest}} there's some updated code for creating test datasets and comparing byte arrays in files -that comparison code could be teased out, and/or a new test added to the contract "if you seek(offset) then readFully(bytes[]), you get the data at file[offset]...file[offset+bytes.length-1]"

Let me add that to my list of things we assume that a filesystem does.
, Yea, I have a randomized test case that finds this bug within a few seconds - basically a copy of one that I wrote for HDFS a couple years ago. Will upload it with a bugfix patch hopefully later today, but maybe early next week (pretty busy next two days). FWIW the fix is simple -- just need to add {{(this.pos != this.count)}} into the condition to run the seek-in-buffer optimization, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12577294/hadoop-9307.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2421//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2421//console

This message is automatically generated., [~stevel@apache.org], mind taking a look?, standardised seek tests must find this bug -or the tests are broken., Hey Steve. I agree that improving the general cross-filesystem testing is a worthy goal. But, this is a simple bug in an existing implementation, and the patch adds a specific unit test. Given that this breaks HBase running on the local filesystem, I don't think it makes sense to block fixing it on a much bigger project like standardizing tests., +1 - The change and the added regression test looks good. I tested it without the fix as well. Nice find Todd!, I committed to branch-2 and trunk. Here's a backport to branch-1 as well, Integrated in Hadoop-Yarn-trunk #210 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/210/])
    HADOOP-9307. BufferedFSInputStream.read returns wrong results after certain seeks. Contributed by Todd Lipcon. (Revision 1482377)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1482377
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/BufferedFSInputStream.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
, Integrated in Hadoop-Hdfs-trunk #1399 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1399/])
    HADOOP-9307. BufferedFSInputStream.read returns wrong results after certain seeks. Contributed by Todd Lipcon. (Revision 1482377)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1482377
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/BufferedFSInputStream.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
, Integrated in Hadoop-Mapreduce-trunk #1426 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1426/])
    HADOOP-9307. BufferedFSInputStream.read returns wrong results after certain seeks. Contributed by Todd Lipcon. (Revision 1482377)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1482377
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/BufferedFSInputStream.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
, Hearing no objections, committed to branch-1 as well., Doug pointed me here.

I see a similar error while reading Avro file, doing random number of seeks.


Details
=====
Hello,
I have a 340 MB avro data file that contains records sorted and identified by unique id (duplicate records exists). At the beginning of every unique record a synchronization point is created with DataFileWriter.sync(). (I cannot or do not want to save the sync points and i do not want to use SortedKeyValueFile as output format for M/R job)  

There are at-least 25k synchronization points in a 340 MB file.

Ex:
Marker1_RecordA1_RecordA2_RecordA3_Marker2_RecordB1_RecordB2


As records are sorted, for efficient retrieval, binary search is performed using the attached code.

Most of the times the search is successful, at times the code throws the following exception
------
org.apache.avro.AvroRuntimeException: java.io.IOException: Invalid sync! at org.apache.avro.file.DataFileStream.hasNext(DataFileStream.java:210 
------



Questions
1) Is it ok to have 25k sycn points for 300 MB file ? Does it cost in performance while reading ?
2) I note down the position that was used to invoke fileReader.sync(mid);. If i catch AvroRuntimeException, close and open the file and sync(mid) i do not see exception. Why should Avro throw exception before and not later ?
3) Is there a limit on number of times sync() is invoked ?
4) When sync(position) is invoked, are any 0 >= position <= file.size()  valid ? If yes why do i see AvroRuntimeException (#2) ?

======

Some of the questions are irrelevant here.

As the patch has been committed, what version of hadoop-core will have this fix ? , I am using hadoop-core-1.1.2.21, Hello Deepak,

The Fix Versions lists the versions 2.1.0-beta (and onwards) for
Hadoop 2.x, or 1.3.0 (and onwards) for Hadoop 1.x.




-- 
Harsh J
]