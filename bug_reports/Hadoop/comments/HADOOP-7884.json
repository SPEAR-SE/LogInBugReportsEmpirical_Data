[The test-patch builds run with the base directory set to hadoop-{common,hdfs,mapreduce}-project. We could change common so it is run from the top-level, thus allowing cross-project patches, but it would mean that i) unit tests for every project are run for every change, and ii) only patches relative to the top-level would apply. i) is probably a good thing (changes to common should result in HDFS and MapReduce tests being run). For ii), do folks generally produce patches from the top-level anyway?, My take is:

* all patches should be from top-level
* all patches should do a full build from top level (this ensures not API breaking)
* patches should run tests in the project of their changes (otherwise every test-patch would be too long)
* nighty builds should do a test run from trunk

, As things stand, test-patch will always do a build from the top-level to check that there are no breakages, but tests are run from hadoop-{common,hdfs,mapreduce}-project so only tests from the relevant project are run.

Re: nightly builds, there is one for each project that does a full test-run and build: https://builds.apache.org/job/Hadoop-Common-trunk/, https://builds.apache.org/job/Hadoop-Hdfs-trunk/, https://builds.apache.org/job/Hadoop-Mapreduce-trunk/. Perhaps we need a top-level one., No longer a problem after HADOOP-8308.]