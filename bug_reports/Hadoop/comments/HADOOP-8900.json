[


It’s a quirk of Java to treat masks of integer values as integer types even when applying to a long value – legitimate, yet somewhat imposing.

/**
 @Hadoo Gzip issue repro
•@author viatk
 */

public class Repro {

public static void main(String[] args) {

long smallLongValue = 665615408L; //0x027AC7C30
 long largeLongValue = 9255550000L; //0x227AC7C30
 long largeValueWithIntMask = (largeLongValue & 0xffffffff);
 long largeValueWithLongMask = (largeLongValue & 0xffffffffL);

System.out.println("smallLongValue= "+smallLongValue);
 System.out.println("largeLongValue= "+largeLongValue);
 System.out.println("largeValueWithIntMask ="+largeValueWithIntMask);
 System.out.println("largeValueWithLongMask ="+largeValueWithLongMask);
 System.out.println();

if (largeValueWithIntMask != largeValueWithLongMask) 
{ System.out.println("Here is your repro - largeValueWithIntMask != largeValueWithLongMask"); } 
if (smallLongValue != largeValueWithIntMask) 
{ System.out.println("Thus smallLongValue != largeValueWithIntMask"); } 
if (smallLongValue == largeValueWithLongMask) 
{ System.out.println("The fix is to compare Long values with long values with long masks."); } 
}
 }

smallLongValue= 665615408
 largeLongValue= 9255550000
 largeValueWithIntMask =9255550000
 largeValueWithLongMask =665615408

Here is your repro - largeValueWithIntMask != largeValueWithLongMask
 Thus smallLongValue != largeValueWithIntMask
 The fix is to compare Long values with long values with long masks.



.


  

Chuan Liu added a comment - 24/Aug/12 11:32 AM - edited 


+1
 We found this bug while working with an internal customer.
 The bug exists on Linux as well.
 The root cause is we are comparing long values with a int mask.
, Attaching patch which corrects this mask issue and adds a testcase which fails without the fix.

Unfortunately the testcase takes more than 30 seconds to run on my 2.5GHz Core i5, so I doubt that it should be run by default.  The total runtime for TestCodec goes from 16 seconds to 99 seconds with testGzipLongOverflow enabled., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12548337/hadoop8900.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1581//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1581//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12548348/BuiltInGzipDecompressor2.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1585//console

This message is automatically generated., The http://issues.apache.org/jira/secure/attachment/12548348/BuiltInGzipDecompressor2.patch is for 1-win branch., Looks good to me., New patch for trunk:
* fix all examples of {{long&0xffffffff}} in the tree (adds TestVLong).
* verified that 4GB+1 is the relevant edge case, 2GB+1 does not trigger the failure.

I'm still a bit unhappy at the long runtime, but 100 seconds is not *that* long by the standards of this test suite, so maybe it's worthwhile., It seems like the long runtime could be avoided by implementing an InputStream subclass that returns synthetic data.  GZip is a block-based compression algorithm-- could one simply keep returning the same block over and over, followed by the 4-byte footer?

It's kind of annoying to have to use 4GB of temporary space for the unit tests as well.  I only have 9GB free in total on my drive now-- a test like this could easily push me over the limit., Another, perhaps easier way to avoid the disk space cost would be to have a gzip output stream and feed it into the gzip input stream (never touch disk)., Andy, let's go with your patch. 
+1
Could you please port it to branch-1 that that we could integrate it to branch-1-win , Andy, let's go with your patch. 
+1
Could you please port it to branch-1 that that we could integrate it to branch-1-win, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12548490/hadoop8900-2.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1592//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1592//console

This message is automatically generated., bq. It's kind of annoying to have to use 4GB of temporary space

Nope, it only writes the compressed file to disk; {{gzip -1}} compresses 4GB of zeros to 18 MiB.

bq. Could you please port it to branch-1 that that we could integrate it to branch-1-win

Slavik, thanks for the review!

I don't have very much experience on branch-1, would you like to take a shot at the port?  Especially I don't know very much about the test framework differences.  I will figure out the details and do the port later this week if you don't get to it first., bq. Nope, it only writes the compressed file to disk; gzip -1 compresses 4GB of zeros to 18 MiB.

Sorry, I missed the fact that the uncompressed file was never written to disk.

Looks good to me., Andy, sounds good, I'll port to branch-1., Integrated in Hadoop-trunk-Commit #2882 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/2882/])
    HADOOP-8900. BuiltInGzipDecompressor throws IOException - stored gzip size doesn't match decompressed size. Contributed by Slavik Krassovsky. (Revision 1399377)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1399377
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/zlib/BuiltInGzipDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodec.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
, +1 for the patch.

I committed the patch to trunk and branch-2. I will post it to branch-1, once the patch for it is posted., Integrated in Hadoop-Yarn-trunk #7 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/7/])
    HADOOP-8900. BuiltInGzipDecompressor throws IOException - stored gzip size doesn't match decompressed size. Contributed by Slavik Krassovsky. (Revision 1399377)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1399377
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/zlib/BuiltInGzipDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodec.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
, Integrated in Hadoop-Hdfs-trunk #1199 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1199/])
    HADOOP-8900. BuiltInGzipDecompressor throws IOException - stored gzip size doesn't match decompressed size. Contributed by Slavik Krassovsky. (Revision 1399377)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1399377
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/zlib/BuiltInGzipDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodec.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
, Integrated in Hadoop-Mapreduce-trunk #1229 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1229/])
    HADOOP-8900. BuiltInGzipDecompressor throws IOException - stored gzip size doesn't match decompressed size. Contributed by Slavik Krassovsky. (Revision 1399377)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1399377
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/zlib/BuiltInGzipDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodec.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
, Merged patch for branch-1., Andy or Colin, can you please review the merged branch-1 patch., bq. Andy or Colin, can you please review the merged branch-1 patch.

hadoop-8900.branch-1.patch looks good to me.  Thanks for the backport!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12550367/hadoop-8900.branch-1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1660//console

This message is automatically generated., I committed the patch branch-1 also. Thank you Andy and Slavik., Sorry I had mistakenly credited this patch to Slavik. I changed the CHANGES.txt to give the credit for this jira to Andy., Integrated in Hadoop-trunk-Commit #2910 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/2910/])
    HADOOP-8900. I had mistakenly not credited the patch to the right person. Changing the contributor to Andy Isaacson. (Revision 1401144)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1401144
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
, Integrated in Hadoop-Yarn-trunk #12 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/12/])
    HADOOP-8900. I had mistakenly not credited the patch to the right person. Changing the contributor to Andy Isaacson. (Revision 1401144)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1401144
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
, Integrated in Hadoop-Hdfs-trunk #1204 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1204/])
    HADOOP-8900. I had mistakenly not credited the patch to the right person. Changing the contributor to Andy Isaacson. (Revision 1401144)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1401144
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
, Integrated in Hadoop-Mapreduce-trunk #1234 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1234/])
    HADOOP-8900. I had mistakenly not credited the patch to the right person. Changing the contributor to Andy Isaacson. (Revision 1401144)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1401144
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
]