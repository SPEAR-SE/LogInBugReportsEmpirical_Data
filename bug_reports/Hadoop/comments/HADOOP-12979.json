[full stack
{code}

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:809)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:809)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:809)
  ...
  Cause: java.io.IOException: ${hadoop.tmp.dir}/s3a not configured
  at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.confChanged(LocalDirAllocator.java:269)
  at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:349)
  at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.createTmpFileForWrite(LocalDirAllocator.java:421)
  at org.apache.hadoop.fs.LocalDirAllocator.createTmpFileForWrite(LocalDirAllocator.java:198)
  at org.apache.hadoop.fs.s3a.S3AOutputStream.<init>(S3AOutputStream.java:91)
  at org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:488)
  at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:921)
  at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:814)
  at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:123)
  at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
{code}, The problem is the branch take if there's no s3 buffer dir defined. the else clause is broken; it's looking for a config option which isn't there.
{code}
    if (conf.get(BUFFER_DIR, null) != null) {
      lDirAlloc = new LocalDirAllocator(BUFFER_DIR);
    } else {
      lDirAlloc = new LocalDirAllocator("${hadoop.tmp.dir}/s3a");   // HERE
    }
{code}

The fix should be to set {{BUFFER_DIR}} to the full path desired, create the {{LocalDirAllocator(BUFFER_DIR)}} from the (possibly enhanced) config]