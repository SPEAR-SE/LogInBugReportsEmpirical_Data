[We faced the same issue and the workaround that we did was to register a SIGNAL handler in the application code that would re
cieve a the TERM signal before shutdown hooks are invoked. However this introduces a dependency on Sun's misc package which generates a compiler warning stating the package might be de-supported in Sun's JDK.

I think a better solution would be for FileSystem to expose an API to register application cleanup code and guarantee that the code is invoked ahead of the code in filesystem shutdown hook., bq. I think a better solution would be for FileSystem to expose an API to register application cleanup code and guarantee that the code is invoked ahead of the code in filesystem shutdown hook.

I'm not sure how you would do that.  AFAIK there's no guaranteed ordering of shutdown hooks.  Another option would be to let FileSystems be created in shutdown hooks with the caveat that the creator is responsible for closing the filesystem before the hook ends., > This makes it impossible to access a FileSystem from within your own ShutdownHook threads, say for deleting incomplete output.

For deleting file on exit, we should use FileSystem.deleteOnExit(Path f), instead of a ShutdownHook., bq. For deleting file on exit, we should use FileSystem.deleteOnExit(Path f), instead of a ShutdownHook.

This doesn't seem to fit my use case.  I want to delete an unfinished MapRed output directory from HDFS *only* if the user terminates the process., A trick not sure it will work for you: First create files and call FileSystem.deleteOnExit(...) for them.  Then, do rename at the end of the application.  If user terminates the process, they file won't be renamed and will be deleted.

It will be more efficient if you put everything in a directory and do deleteOnExit and rename on that directory.
, in SmartFrog we had fun with Sun JVM signal handling, which provides extra compatibility problems with the clean-room OSS implementations and are pretty hard to test. 

Maybe the classname of the class to run as a filesystem hook could be configurable, so someoneone could subclass and extend its shutdown code, rather than run race condition pain in shutdown. Which, for anyone who has tried, is essentially non-debuggable and therefore to be feared. , My experience is that it is better If the appliction uses  deleteOnExit, rather than depend on the behaviour of the shutdown hook. does that work for you?, The use case that we hit upon was client flushing data from Apache servers directly onto hadoop clusters and client dying because of unexpected server failures in which case the client receives SIGTERM and gets killed. What we want to do here is simply close our output stream before exiting so that data isn't lost. 

But I can see other use cases where people might want to do additional operations in the client like renaming, moving etc (besides deleting and closing).

So I see a couple of approaches for this. 
1. Provide additional API's like closeOnExit(..),  moveOnExit(...) etc. which I think would not be so elegant and somewhat limited in the control they provide.

2. Provide additional API in FileSystem, something like FileSystem.addShutdownEventReciever() that allows clients to register there custom cleanup code. In the shutdown hook, make sure that all the exit handlers registered by client are invoked before any code in the shutdown hook. This is more flexible but relies on the fact there is only one shutdown hook thread that runs once JVM starts to shutdown which currently is the case,  I think. 
, > What we want to do here is simply close our output stream before exiting so that data isn't lost. 

We already have automatic files closing during shutdown.  It is done by the FileSystem shutdown hook., Cool! Though I am not sure if this was always there or just got introduced a via some JIRA for 0.18 release. The behavior we saw with 0.17 release is that if a client in the middle of writing data gets a SIGTERM, then all the data is lost., Out of date]