[On one of the clusters, a map attempt was expired as a lost task in ExpireLaunchingTasks thread, but it was not removed from taskidToTIPMap. All the reducers were informed that the map has failed. In the next heartbeat the TT came back reporting the attempt as a success, thereby preventing launch of any new map attempts for this task. 
Subsequently, all the reduces just got stalled waiting for the output from this map task and the whole job got stock with no progress. , Attaching patch. Vinod, could you please test things out with this patch? Thanks!, The original circumstances under which this bug was revealed was HADOOP-5285.  With the above patch, and without patch for HADOOP-5285, the symptom of stuck reducers waiting for output from already failed tasks doesn't seem to be visible any more.

The patch uploaded prevents tasks from wrongly going from FAILED state to any of UNASSIGNED, RUNNING, COMMI_PENDING or SUCCEEDED and looks fine.

`ant test` and `ant test-patch` passed successfully on my local machine. +1 overall., I just committed this to the 0.20 and 0.21 branches. We should commit this to the 0.19 branch after the release of 0.19.1., I committed this to the 0.19 branch., Integrated in Hadoop-trunk #766 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/766/])
    ]