[patch uploaded., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12641632/HADOOP-10523.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3842//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3842//console

This message is automatically generated., Can someone please review or commit this patch?, No, the patch is not adding valid behavior.  Silently ignoring the cancel of a non-existent token is wrong, and returning success to the client will lead to different confusion.

The goal appears to be an attempt to mask a problem:  Why is the token being doubled cancelled?, Thanks [~daryn] for the comments.

I agree with your observation.

> The goal appears to be an attempt to mask a problem: Why is the token being doubled cancelled?

The scenarios of token double cancellation:
1. Owner of the token cancels it first.
2. After that, services also cancel the token. This second one created the unnecessary exception trace.

In most of the case, Step #1 was not done (e.g. Oozie). But others are canceling it explicitly.

What do you think will be a do approach?

Approach 1: Services like NN. RM can check if the token is already canceled or removed.
 Approach 2: When the user cancel the token, the services should update its list accordingly.
Approach 3: something else


, I see.  In your scenarios, I'd say the user shouldn't be canceling tokens that have been submitted with a job unless they are trying to pre-maturely abort the job.  I know that oozie tokens aren't cancelled which is unfortunate.  I think last year I posted a patch that would cancel after all jobs using the tokens completed but it ran into roadblocks.  I need to lookup and revisit that jira.

In the two suggested approach, I'm not sure how they would be implemented if I understand them correctly.  For #1, the RM can't really test the validity/existence of a token w/o issuing a renew or cancel and catching the exception.  For #2, the RM still won't know that the token was externally cancelled, and the issuing service like the NN must cache cancelled tokens and periodically clean the cache.  Due to the complexity, I'd be reluctant to endorse the approach.  I'd also be reluctant to not return errors to a client - instead returning a token already cancelled instead of token doesn't exist exception.

I think the better solution is for users to not cancel tokens.  Tokens are supposed to be an "invisible" implementation detail of job submission and thus not require user manipulation.  I'd suggest modifying the RM to either swallow the cancel error on job completion, or to simply emit a single line in the log instead of a backtrace., Very good explanations!
Mostly agreed with the following comments:

> I think the better solution is for users to not cancel tokens. Tokens are supposed to be an "invisible" implementation detail of job submission and thus not require user manipulation.

I was told every (delegation) token creates an overhead on the process  memory. So try to close it early. If that thinking is changed, i'm open for any option. Btw, long running process like Azkaban explicitly cancels its delegation  token.

> I'd suggest modifying the RM to either swallow the cancel error on job completion, or to simply emit a single line in the log instead of a backtrace.

So this will be added as a WARN message in the caller of cancelToken(). It includes RM, JHS and NN. right? Can you please give little more details about " on job completion"?

, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12641632/HADOOP-10523.1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4480//console

This message is automatically generated., Re-reading the description, I'm a bit confused with:
bq. the system (such as RM, NN and JHS) also periodically tries to cancel the same token.  During the second cancel (originated by RM/NN/JHS)".
and
bq. So this will be added as a WARN message in the caller of cancelToken(). It includes RM, JHS and NN. right?

Perhaps I'm misunderstanding your use of "originated by".  Token issuers like the NN and JHS do not try to cancel tokens, at least not each other's.  Their secret manager periodically purges their own tokens and won't ever emit the exception trace in the description.  A client, which is what the RM is while renewing on behalf of the job, will receive an exception for an already cancelled token if something else cancelled it.

I should have asked before where the log snippet is from?  The RM?  A task?  Etc?  Can you please check if the latest 2.x exhibits the same logging behavior?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12641632/HADOOP-10523.1.patch
  against trunk revision 1556f86.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5138//console

This message is automatically generated., Cancelling patch, as it no longer applies., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HADOOP-10523 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12641632/HADOOP-10523.1.patch |
| JIRA Issue | HADOOP-10523 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8547/console |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]