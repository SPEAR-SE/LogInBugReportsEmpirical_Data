[The checksum patch did not overwrite the method getContentLength in DistributedFileSystem. This leads to the use of the default slower version of getContentLength defined in FileSystem. This patch fixed the du problem. It also fixed the dus problem by declaring the totalSize to be long., +1 Code looks fine.

While reviewing this I noticed that FsShell.dus() seem to be doing one level recursion into the paths it wants to du. I would have thought we either need not recurse at all or to recurse recurse fully. This patch does not change this logic. Hairong is taking a look at this. If there is some issue here (either correctness or just code efficiency), that could be a different jira.
, +1 

Now, dfs -du works fine  on our cluster.
, +1, because http://issues.apache.org/jira/secure/attachment/12354782/du.patch applied and successfully tested against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/524929. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, I just committed this.  Thanks, Hairong!, Integrated in Hadoop-Nightly #47 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/47/)]