[Look closely at the order the config files are loaded.  This code has been in flux, and may have bugs., Ok, I found the problem and it was a config file ordering problem.

The problem is that the job's config file is loaded as a default resource and the site config file is a final resource and I had set the number of reduces to one in the site file, because on a single node cluster that seemed like a reasonable default.

Obviously, removing the default in the site file is necessary.

I realize now that is why you created the separate mapred-default.xml. It doesn't feel right to have a config file that is specific for map/reduce, but I think there should be some kind of default config file that the user can override in the job but that is editted by the site.

Things that probably belong there:
  fs.default.name
  mapred.job.tracker
  mapred.map.tasks
  mapred.reduce.tasks, Integrated in flume-trunk #320 (See [https://builds.apache.org/job/flume-trunk/320/])
    FLUME-1653: Update Hadoop-23 profile to point to hadoop-2 alpha artifacts (Revision 831a86fc5501a8624b184ea65e53749df31692b8)

     Result = SUCCESS, Integrated in HBase-0.94-security #176 (See [https://builds.apache.org/job/HBase-0.94-security/176/])
    HBASE-8743 upgrade hadoop-23 version to 0.23.7 (Revision 1495626)

     Result = SUCCESS, Integrated in HBase-0.94 #1021 (See [https://builds.apache.org/job/HBase-0.94/1021/])
    HBASE-8743 upgrade hadoop-23 version to 0.23.7 (Revision 1495626)

     Result = SUCCESS]