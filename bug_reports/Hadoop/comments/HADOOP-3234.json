[I did not get stack traces but I think this is what happens on the second datanode during second attempt :

- It receives the request for the block with 'isRecovery' set to true. 
- In side {{FSDataset.writeToBlock()}} it interrupts the main receive thread and waits for the thread to exit.
- The main receive thread from the first attempt waits for {{responder}} thread to exit, but it does not interrupt it.

One fix could be to interrupt {{responder}} inside the main receiver thread., This is not an issue while using non-blocking I/O. Looks like read and write using regular sockets is not interruptible (really?). So this will be a very rare problem when  HADOOP-3124 is committed and "dfs.datanode.socket.write.timeout" is set to 0 and something like HADOOP-3132 happens. On 16, it not much of an issue since there is no write timeout at all., Mostly this can be closed.. unless there is a way around blocked writes. We could try closing the socket before interrupting the thread.. but not sure if close will block until write is done.]