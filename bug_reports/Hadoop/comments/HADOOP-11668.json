[Attaching the patch.

Delimited hostnames with comma(,)
Using the latest 'hdfs --slaves' script in start-dfs.sh and stop-dfs.sh, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12702417/HADOOP-11668-01.patch
  against trunk revision 3560180.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.conf.TestConfigurationDeprecation
org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5841//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5841//console

This message is automatically generated., Closing this in favor of HADOOP-11590, which rewrites these scripts., Re-opening.  The problem here isn't start/stop, it's *-daemons.sh, which are now broken., -02:
* This fixes hadoop-daemons.sh and yarn-daemons.sh so that they work with multiple hosts.

The problem was two fold:
* We were not preserving quotes around parameters that contained $IFS due to lack of quoting around the array deletion
* The then deleted array elements were retained and show up as an empty argument., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12702627/HADOOP-11668-02.patch
  against trunk revision ed70fa1.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5849//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5849//console

This message is automatically generated., Thanks [~aw].
{quote}
The problem was two fold:
We were not preserving quotes around parameters that contained $IFS due to lack of quoting around the array deletion
The then deleted array elements were retained and show up as an empty argument.
{quote}
I don't think the problem is having empty arguments, I have verified in my case, there were no empty arguments.
In my case
1.  start-dfs.sh will call hadoop-daemons.sh as below
*hadoop-daemons.sh --config /home/vinay/install/conf --hostnames 'server3 server1' start namenode*
2. hadoop-daemons.sh passes these args to hdfscript as below
*hdfs --slaves --daemon start --config /home/vinay/install/conf --hostnames server3 server1 namenode*

So the actual problem found is, in Original *HADOOP_USER_PARAMS* array, *'server3 server1'* will be one element. But after this {code}argv=(${HADOOP_USER_PARAMS[@]/start}){code} it becomes two separate elements in {{argv}}. Even when original HADOOP_USER_PARAMS printed as {code}${HADOOP_USER_PARAMS [@]}{code} it shows without quotes, which means separate arguments to hdfsscript.

IMO, best way to solve this is by making hostnames delimited by (,)

Any thoughts?, -03:
* just switch to a loop entirely. see below....

bq. IMO, best way to solve this is by making hostnames delimited by (,)

Nope, definitely not.

The start of the problems are definitely here:

{code}
argv=(${HADOOP_USER_PARAMS[@]/start})
{code}

This construction has two key issues:

Without quotes, the array of HADOOP_USER_PARAMS will always have its metachars expanded.  This means that an array of 4 elements will now become 4+n elements, depending upon what else is in there. So if a user passes:

{code}
--config "my cool dir" 
{code}

elements 2 3 4 just got expanded into my, cool, and dir rather than just the single "my cool dir".

So if we change the construction to

{code}
argv=("${HADOOP_USER_PARAMS[@]/start}")
{code}

That element expansion no longer happens.  But now we've introduced a new problem.  We're doing a substitution, but turning those elements empty!  This is where the empty parameter problem comes in, because this means that if we had:

{code}
hadoop-daemons.sh --hostnames "1 2" start namenode
{code}

We'd end up with:

argv[0]=--hostnames
argv[1]="1 2"
argv[2]=""
argv[3]="namenode"

after the substitution.

Then when we get to

{code}
"${argv[@]}" 
{code}

on the exec line, it turns into:

hdfs --slaves --daemon "start" --hostnames "1 2" "" namenode

Thus we also need to filter out this empty element array.

So why don't we just switch to using commas here?  Because as evidenced by the above, it doesn't actually fix all the problems with metachar expansion.  If any other parameter has them, it's going to blow up in our face.  The other problem we've got is backward compatibility.  A lot of people use hadoop/yarn-daemons.sh in scripts, and changing this to use commas would be a pretty hefty tax especially when we know we can fix it another way.

One of the goals I had in mind with this code was to avoid a loop.  But there's still another problem here:

if a hostname has start, stop, or status, it's going to get removed.  Since we already have the loop now to deal with the empty element, we might as well fix that bug too by using a loop rather than cheating.  We still have a problem if some other param is specifically start/stop/status (e.g., --config start), but there's not much we can do about that without building a pretty complex test for what mode we're in., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12702828/HADOOP-11668-03.patch
  against trunk revision 1b67209.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5858//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5858//console

This message is automatically generated., Thanks [~aw] for the detailed explanation.
Latest updated patch fixes the argument parsing problem.
Still didnt fix the end-to-end problem. Still starting of Nodes fails.

Similar treatment required in {{hadoop_common_slave_mode_execute}} to remove --slaves, --hostnames and its values.

Attaching the patch for the same., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12703007/HADOOP-11668-04.patch
  against trunk revision 95bfd08.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-common-project/hadoop-common:

org.apache.hadoop.http.TestHttpServerLifecycle

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5868//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5868//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12703007/HADOOP-11668-04.patch
  against trunk revision 95bfd08.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5870//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5870//console

This message is automatically generated., Oh! Good catch! 

We should probably also handle the --hosts case as well.  If you can update the patch to handle that, we'll get this committed!

Thanks!, Hi [~aw], Attached the updated patch to remove '--hosts' as well.
Please review., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12703298/HADOOP-11668-05.patch
  against trunk revision 6444349.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.http.TestHttpServer

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5883//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5883//console

This message is automatically generated., Missed an update:

{code}
 ${hdfsscript} --slaves --daemon "${daemonmode}" "${argv[@]}"
{code}

that argv should be HADOOP_USER_PARARMS in hadoop-daemon.sh, Thanks [~aw].
Updated again., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12703332/HADOOP-11668-06.patch
  against trunk revision 790aa67.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5885//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5885//console

This message is automatically generated., +1 committing to trunk.

Thanks!, FAILURE: Integrated in Hadoop-trunk-Commit #7295 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7295/])
HADOOP-11668. hadoop-daemons.sh bw compat broke with --slaves change (Vinayakumar B via aw) (aw: rev 7711049837d69d0eeabad27f2e30fab606a4adc2)
* hadoop-yarn-project/hadoop-yarn/bin/yarn-daemons.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemons.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #128 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/128/])
HADOOP-11668. hadoop-daemons.sh bw compat broke with --slaves change (Vinayakumar B via aw) (aw: rev 7711049837d69d0eeabad27f2e30fab606a4adc2)
* hadoop-yarn-project/hadoop-yarn/bin/yarn-daemons.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemons.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk #862 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/862/])
HADOOP-11668. hadoop-daemons.sh bw compat broke with --slaves change (Vinayakumar B via aw) (aw: rev 7711049837d69d0eeabad27f2e30fab606a4adc2)
* hadoop-yarn-project/hadoop-yarn/bin/yarn-daemons.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemons.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk #2060 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2060/])
HADOOP-11668. hadoop-daemons.sh bw compat broke with --slaves change (Vinayakumar B via aw) (aw: rev 7711049837d69d0eeabad27f2e30fab606a4adc2)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemons.sh
* hadoop-yarn-project/hadoop-yarn/bin/yarn-daemons.sh
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #119 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/119/])
HADOOP-11668. hadoop-daemons.sh bw compat broke with --slaves change (Vinayakumar B via aw) (aw: rev 7711049837d69d0eeabad27f2e30fab606a4adc2)
* hadoop-yarn-project/hadoop-yarn/bin/yarn-daemons.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemons.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #128 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/128/])
HADOOP-11668. hadoop-daemons.sh bw compat broke with --slaves change (Vinayakumar B via aw) (aw: rev 7711049837d69d0eeabad27f2e30fab606a4adc2)
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemons.sh
* hadoop-yarn-project/hadoop-yarn/bin/yarn-daemons.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #2078 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2078/])
HADOOP-11668. hadoop-daemons.sh bw compat broke with --slaves change (Vinayakumar B via aw) (aw: rev 7711049837d69d0eeabad27f2e30fab606a4adc2)
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-daemons.sh
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-yarn-project/hadoop-yarn/bin/yarn-daemons.sh
]