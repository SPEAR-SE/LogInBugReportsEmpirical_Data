[{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12620833/hadoop-10195.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3385//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12620844/hadoop-10195.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-openstack.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3386//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3386//console

This message is automatically generated., Looks reasonable. Have you tested this against throttled endpoints like rackspace UK? The many-small-file operations used to hit problems at delete time, and we may want to increase the test timeouts there, I have manually tested it against rackspace UK and it did eventually complete successfully.  I didn't see any problems, other than it is *really* slow to delete 10K+ files. , Is there anything else I need to do here?, What else needs to be done here to get this merged?, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12620844/hadoop-10195.patch
  against trunk revision 4a5c3a4.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-openstack.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5426//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5426//console

This message is automatically generated., I had lots of problems with socket timeouts on long-haul work; after a test failure of {{testLongDirectoryList()}} I was
invariably left with lots of files of the form {{testfile-00004}}, which then led to follow-on failures


# move {{testLongDirectoryList()}} to its own class, something like ScaleTestLs; to be run with any other scale tests {{mvn test -Dtest=ScaleTest\*}}
# test files to be created in a subdir
# setup operation to delete this directory before recreating it 
# finally operation to delete this directory afterwards]