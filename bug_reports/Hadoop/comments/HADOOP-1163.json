[My patch (I can't attach in the standard way since this issue is still open):

--- src/java/org/apache/hadoop/metrics/ganglia/GangliaContext.java      (revision 522712)
+++ src/java/org/apache/hadoop/metrics/ganglia/GangliaContext.java      (working copy)
@@ -122,19 +122,6 @@
     public void emitRecord(String contextName, String recordName, OutputRecord outRec) 
         throws IOException
     {
-        
-        // metric name formed from record name and tag values
-        StringBuffer nameBuf = new StringBuffer(recordName);
-        // for (String tagName : outRec.getTagNames()) {
-        Iterator tagIt = outRec.getTagNames().iterator();
-        while (tagIt.hasNext()) {
-            String tagName = (String) tagIt.next();
-            nameBuf.append('.');
-            nameBuf.append(outRec.getTag(tagName));
-        }
-        nameBuf.append('.');
-        String namePrefix = new String(nameBuf);
-        
         // emit each metric in turn
         // for (String metricName : outRec.getMetricNames()) {
         Iterator metricIt = outRec.getMetricNames().iterator();
@@ -142,9 +129,8 @@
             String metricName = (String) metricIt.next();
             Object metric = outRec.getMetric(metricName);
             String type = (String) typeTable.get(metric.getClass());
-            emitMetric(namePrefix + metricName, type, metric.toString());
+            emitMetric(metricName, type, metric.toString());
         }
-        
     }
     
     private void emitMetric(String name, String type,  String value) 
, +1 code reviewed.  Looks good.


, Attach my patch the jira way, -1, because the patch command could not apply the latest attachment http://issues.apache.org as a patch to trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/524929. Please note that this message is automatically generated and may represent a problem with the automation system and not the patch. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, +1, because http://issues.apache.org/jira/secure/attachment/12354789/hostname-not-part-of-ganglia-record.patch applied and successfully tested against trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/524929. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch, Michael,
The patch no longer applies cleanly due to a conflict with HADOOP-1190 (which has been committed) - would you be able to regenerate it please? Thanks., attaching updated patch, I've just committed this. Thanks Michael!, Integrated in Hadoop-Nightly #48 (See http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/48/)]