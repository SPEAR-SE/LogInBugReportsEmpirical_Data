[> I restarted the namenode, with no success.

Do you still see the blocks on the data-nodes after restarting?

In 0.17 there was no so called lease recovery for files that were not closed properly.
Do you know whether the 0-size files were closed before becoming empty?, They were created 11/16 (I found the corresponding log messages on the Namenode, no other log messages referring to these blocks) and used as non-empty files by subsequent jobs (non-empty otherwise they would have failed as mentioned in the description). They must have been become empty within the last few days.

I checked one of the blocks on one of the datanodes after namenode restart. Still there and still non-empty.

I will now move the empty files away into a different location (they will still be available for examination) and re-create the original files from the non-empty blocks., All 0 size files had similar log messages like (initial size 0 --> update to non-zero during closing)

2008-11-16 22:52:04,302 INFO org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: xxx.yyy.zzz.vvv:port is added to blk_6021851155145233808 size 0
2008-11-16 22:52:04,540 WARN org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.addStoredBlock: Redundant addStoredBlock request received for blk_6021851155145233808 on xxx.yyy.zzz.vvv:port size 38807484

Also I checked that the file corruption started after a single namenode restart after the file creation.
So I would conclude that the edits file must have contained the initial 0 size instead of the final size. The fact that the files continue to exist after the namenode restart indicates that they got properly closed. Correct? Unfortunately, there are no log messages about closing the file.

I start to suspect that there is rare race condition between updating the block with the correct size and storing it to the edits file during the closing process. Would that be possible?, Currently no longer seen., hi christian, we are starting to see similar problems in our old 0.17 cluster. Files that were written a coupel of days earlier tunr out to be zero size files. The replicas of the blocks of these files on the datanode actually have valid data. Stopping one of the datanodes causes the block to get replciaed, and updates the length of the file correctly on the namenode. Do you remember what fixes you migth have pulled in to avoid this problem? Thanks., Dhruba, we did not have any fix for it.
We just reconstructed the files from the non-empty blocks we found on the datanodes, and hoped that we will not see it happen anymore.]