[Attached patch, [~jira.shegalov] can you please check..?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12699998/HADOOP-11618.patch
  against trunk revision 0d6af57.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5750//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5750//console

This message is automatically generated., [~brahmareddy], thanks for working on this patch. 
Please fix the code style and add a test., [~jira.shegalov] thanks a lot for review..Updated patch..( Added the testcase, Init of ftps is enough to reproduce this bug), {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12701380/HADOOP-11618-001.patch
  against trunk revision 01a1621.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5793//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5793//console

This message is automatically generated., Thanks for the 001 patch [~brahmareddy]. 

The current regression test covers one important facet, the inability to create an {{DelegateToFileSystem}} instance with required authority if the default uri does not have a port.

However, It would pass for the original implementation of {{DelegateToFileSystem}} if you add 
{code}
FileSystem.setDefaultUri(conf, "hdfs://dummy-host:4321");
{code}
that has nothing to do with FTP  before the FtpFs construction. 

Because the issue is about the default port, I recommend to use a port-less URI to init FtpFs {{ftp://dummy-host}} for both cases.
# default URI with port "hdfs://dummy-host:4321"
# default URI without port "hdfs://dummy-host"

In both cases, we are going to assert that {{ftpFs.getUri()}} results in {{ftp://dummy-host:21}}

Since the problem is not specific to FtpFs, we are better off to have these tests in {{org.apache.hadoop.fs.TestDelegateToFileSystem}}. Instead of using the FtpFs constructor directly, we should use the standard idiom: {{AbstractFileSystem#get(uri, conf)}}. We can specify  {{fs.AbstractFileSystem.ftp.impl}} either in the test configuration,  or add it to core-default.xml, Thanks a lot for review..
{quote}
In both cases, we are going to assert that ftpFs.getUri() results in ftp://dummy-host:21
{quote}
will not return default port where URI having port..whenever port=-1(not configured)then  only default port will be return..Please check following code for same..
{code}
 private URI getUri(URI uri, String supportedScheme,
      boolean authorityNeeded, int defaultPort) throws URISyntaxException {
    checkScheme(uri, supportedScheme);
    // A file system implementation that requires authority must always
    // specify default port
    if (defaultPort < 0 && authorityNeeded) {
      throw new HadoopIllegalArgumentException(
          "FileSystem implementation error -  default port " + defaultPort
              + " is not valid");
    }
    String authority = uri.getAuthority();
    if (authority == null) {
       if (authorityNeeded) {
         throw new HadoopIllegalArgumentException("Uri without authority: " + uri);
       } else {
         return new URI(supportedScheme + ":///");
       }   
    }
    // authority is non null  - AuthorityNeeded may be true or false.
    int port = uri.getPort();
    port = (port == -1 ? defaultPort : port);
    if (port == -1) { // no port supplied and default port is not specified
      return new URI(supportedScheme, authority, "/", null);
    }
    return new URI(supportedScheme + "://" + uri.getHost() + ":" + port);
  }
{code}

and 001 patch also will call this method only...Anyway I updated patch,,kindly review the same.., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12702572/HADOOP-11618-002.patch
  against trunk revision 03cc229.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5845//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5845//console

This message is automatically generated., Thanks for updating the patch, [~brahmareddy]. The latest patch still does not quite test what was broken, and what I was suggesting in the previous comment. Although the test names 002 include defaultURI, they actually don't call {{FileSystem.setDefaultUri}}. 

It's a also not necessary to cast to (FtpFs). 

Both tests also should use the same ftp URI without port in both tests.
Assuming we move fs.AbstractFileSystem.ftp.impl to core-default.xml (I now think it makes more sense), that is what I am looking for in the test class.
{code}
public class TestDelegateToFileSystem {

  private static final String FTP_DUMMYHOST = "ftp://dummyhost";
  private static final URI FTP_URI_NO_PORT = URI.create(FTP_DUMMYHOST);
  private static final URI FTP_URI_WITH_PORT =
      URI.create(FTP_DUMMYHOST + ":" + FTP.DEFAULT_PORT);

  private void testDefaultUriInternal(String defaultUri)
      throws UnsupportedFileSystemException {
    final Configuration conf = new Configuration();
    FileSystem.setDefaultUri(conf, defaultUri);
    final AbstractFileSystem ftpFs = AbstractFileSystem.get(FTP_URI_NO_PORT,
        conf);
    Assert.assertEquals(FTP_URI_WITH_PORT, ftpFs.getUri());
  }

  @Test
  public void testDefaultURIwithOutPort() throws Exception {
    testDefaultUriInternal("hdfs://dummyhost");
  }

  @Test
  public void testDefaultURIwithPort() throws Exception {
    testDefaultUriInternal("hdfs://dummyhost:8020");
  }
}
{code}

{{testDefaultURIwithPort}} without your fix breaks as explained:
{code}
java.lang.AssertionError: expected:<ftp://dummyhost:21> but was:<ftp://dummyhost:8020>
{code}, {quote}
Although the test names 002 include defaultURI, they actually don't call FileSystem.setDefaultUri.
{quote}

yes, It will not called..:(


Updated the patch based on your comments.., Thanks a lot for review.., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12703231/HADOOP-11618-003.patch
  against trunk revision 608ebd5.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5882//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5882//console

This message is automatically generated., +1, will just drop unused Path import from DelegateToFileSystem, Thanks [~brahmareddy] for contribution! Committed to trunk, branch-2, branch-2.7., Thanks [~jira.shegalov] for committing , Unfortunately, this patch introduced a regression that breaks usage of wasb, s3, and other alternative file systems as the default file system.  I have filed a patch on HADOOP-12304 to fix it.]