[I've posted the script used to reproduce the case as repro.sh, The option #1 is preferable from my understanding. Option #2 is a high risky fundamental change across stack. Option #3 is not universally applicable. They are posted here with a hope of sourcing collective opinions. Please feel free to comment on it. Thanks., [~daryn] what's your thought on this? Thanks. HDFS-7597 cached UGI to avoid new connections being created., We encountered this exact problem, fixed it, but apparently haven't pushed back to the community.  I think #1 is the correct approach.  Below is the quick & dirty patch we used.  I'd suggest scrubbing all the policies for correctness.  Plus re-building strings for hashCode/equals is a horrible thing that should be changed.

{code}
index 0000000..5aab5c2
--- /dev/null
+++ b/Y-CHANGES/YHADOOP-977
@@ -0,0 +1 @@
+[YHADOOP-977] Webhdfs causes datanodes to create excessive connections.
index fab406d..032e38e 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/retry/RetryUtils.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/retry/RetryUtils.java
@@ -115,6 +115,16 @@ public RetryAction shouldRetry(Exception e, int retries, int failovers,
         }
 
         @Override
+        public int hashCode() {
+          return multipleLinearRandomRetry.hashCode();
+        }
+
+        @Override
+        public boolean equals(final Object that) {
+          return this.toString().equals(that.toString());
+        }
+
+        @Override
         public String toString() {
           return "RetryPolicy[" + multipleLinearRandomRetry + ", "
               + RetryPolicies.TRY_ONCE_THEN_FAIL.getClass().getSimpleName();
{code}
, Thank you [~daryn] for your inputs. There is a similar patch in my mind.  

bq. re-building strings for hashCode/equals is a horrible thing that should be changed.
Does it mean it leads to performance issues?, By pulling out all subclasses of RetryPolicy, only RetryForever and TryOnceThenFail don't have any member fields, which means it's not always possible to follow the pattern that multiple instances with equivalent fields' values are viewed as equal (i.e. being part of ConnectionId#equals) to avoid creating new connections. This makes exceptions for option #1, which is a dilemma since we can't go to option #2 and #3. Any thoughts? Thanks., Nice catch, [~xiaobingo]!

{{RetryPolicy}} states that
{quote}
Implementations of this interface should be immutable.
{quote}
which is not enough. Since the {{RetryPolicy}}'s equality is used by {{ConnectionId#equals()}}, every class that implements {{RetryPolicy}} should also override {{equals()}} method. For the sake of new retry policies, I suggest we also note this in the javadoc of {{RetryPolicy}}. Although I see very few immutable classes could perform like a charm without overriding {{equals()}}/{{hashCode()}} methods, it's not a strict rule to call a class _immutable_., bq. Does it mean it leads to performance issues?

Technically yes, but if the total code path was profiled it's probably not even a blip.  I took a look at {{MultipleLinearRandomRetry}} and actually caches the {{toString()}} value so it's not an issue with that policy.

Now the problem is making sure all current and future policies properly adhere to a contract required to ensure connection lookups work correctly.  I'd suggest that {{RetryPolicy}} should be an abstract class rather than an interface.  This will ensure the contract is enforced.

{{RetryPolicy}} would implement {{hashCode}}, {{equals}}, and {{toString}} as final methods using the impl of {{MultipleLinearRandomRetry}}.  Except {{toString}} would call a new abstract {{getName}} as the value it will cache.

If compatibility is an overriding concern then I guess a new abstract class, ex. {{AbstractRetryPolicy}}, that implements {{RetryPolicy}} could be created.  Existing polices would then extend that class.  This has the downside of future policies re-introducing this jira's buggy behavior., I'm in favor of making {{RetryPolicy}} an abstract class. In Java we can't add those methods to an interface.  Implementing final {{hashCode}}/{{equals}}/{{toString}} methods; or make {{hashCode}}/{{equals}} abstract, both approach should work IMO.

How about different implementations in {{branch-2}} and {{trunk}}? In {{trunk}}, we make {{RetryPolicy}} an abstract class, while in {{branch-2}}, we add a new {{AbstractRetryPolicy}} class and revisit all the policies by extending for correctness. This way, we can defend the compatibility vs. fix debate for {{branch-2}} but still, make the future a better place., Thank you [~daryn] and [~liuml07] for your comments. How about defining a new interface ConnectionRetryPolicy that extends RetryPolicy with extension of ConnectionRetryPolicy#reuseConnection? ConnectionId#equals should instead compare ConnectionRetryPolicy#reuseConnection to conclude if a new connection needs be created. Without the specific interface, there are several issues:

1. Exception checks in RetryInvocationHandler level could be tightly coupled with those in connection level. It's error prone to mix them together since the same RetryPolicy can be used in both levels. A good case in point is RetryUtils#getDefaultRetryPolicy. It composed checks of ServiceException and IOException, whereas ServiceException is never thrown in connection level. 

2. For the same reason, it's hard to correctly implement retry logic in those  exceptions dependent retry polices, e.g. ExceptionDependentRetry, OtherThanRemoteExceptionDependentRetry and RemoteExceptionDependentRetry. Their logic should be separated to two distinct categories.

We need to avoid the jumbo retry policy anyway.

I will start with a couple of sub tasks addressing the issue aforementioned.

Thank you [~jingzhao] very much for your suggestions., Based on considerate discussion, we came up with different fixes for 2.x and 3.x. Simply put, one is to do in-place fix for Hadoop 2.x, the other is to introduce ConnectionRetryPolicy for Hadoop 3.x, since ConnectionRetryPolicy needs fundamental changes of function signatures in the space of ipc.RPC and ipc.Client, which will break back compatibility in 2.x. I posted a proposal. Any feedback is appreciated. Thanks [~jingzhao] so your precious input.]