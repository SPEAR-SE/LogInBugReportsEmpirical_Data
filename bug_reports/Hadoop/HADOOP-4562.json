{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [],
        "created": "2008-10-31T19:02:52.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "stack",
            "key": "stack",
            "name": "stack",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=stack",
            "timeZone": "America/Los_Angeles"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2008-10-31T20:46:29.473+0000",
        "customfield_12310222": "1_*:*_1_*:*_11349065_*|*_6_*:*_1_*:*_0_*|*_5_*:*_1_*:*_1732105839",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "126601",
        "customfield_12310920": "104249",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i0i74n:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Fri Oct 31 22:12:01 UTC 2008",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Updating hbase to use 0.19.0RC0 or latest from branch-0.19, I see reams of this in logs:\n\n{code}\n2008-10-31 18:33:41,296 INFO org.apache.hadoop.fs.FSInputChecker: java.io.IOException: Checksum ok was sent and should not be sent again\n        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1064)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1613)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1590)\n        at java.io.DataInputStream.readByte(DataInputStream.java:248)\n        at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:325)\n        at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:346)\n        at org.apache.hadoop.io.Text.readString(Text.java:400)\n        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1471)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)\n        at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:293)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$HbaseMapFile$HbaseReader.<init>(HStoreFile.java:632)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader.<init>(HStoreFile.java:714)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:413)\n        at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:262)\n        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1729)\n        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:469)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1004)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:976)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:901)\n        at java.lang.Thread.run(Thread.java:619)\n\n2008-10-31 18:33:41,272 DEBUG org.apache.hadoop.hbase.regionserver.HStore: loaded /hbasetrunk/-ROOT-/70236052/info/info/1689673398714621203, isReference=false, sequence id=1\n2008-10-31 18:33:41,274 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Loaded 1 file(s) in hstore 70236052/info, max sequence id 1\n2008-10-31 18:33:41,296 INFO org.apache.hadoop.fs.FSInputChecker: java.io.IOException: Checksum ok was sent and should not be sent again\n        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1064)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1613)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1590)\n        at java.io.DataInputStream.readByte(DataInputStream.java:248)\n        at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:325)\n        at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:346)\n        at org.apache.hadoop.io.Text.readString(Text.java:400)\n        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1471)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)\n        at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:293)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$HbaseMapFile$HbaseReader.<init>(HStoreFile.java:632)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader.<init>(HStoreFile.java:714)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:413)\n        at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:262)\n        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1729)\n        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:469)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1004)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:976)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:901)\n        at java.lang.Thread.run(Thread.java:619)\n\n2008-10-31 18:33:41,298 INFO org.apache.hadoop.fs.FSInputChecker: java.io.IOException: Checksum ok was sent and should not be sent again\n        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1064)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1613)\n        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)\n        at java.io.DataInputStream.readFully(DataInputStream.java:178)\n        at org.apache.hadoop.io.Text.readString(Text.java:402)\n        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1471)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)\n        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)\n        at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:293)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$HbaseMapFile$HbaseReader.<init>(HStoreFile.java:632)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader.<init>(HStoreFile.java:714)\n        at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:413)\n        at org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:262)\n        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1729)\n        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:469)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1004)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:976)\n        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:901)\n        at java.lang.Thread.run(Thread.java:619)\n{code}\n\nHBase is just opening a mapfile.\n\nHere is from svn blame and history:\n\n{code}\n706798    hairong         if (sentChecksumOk) {\n706798    hairong            // this should not happen; log the error for the debugging purpose\n706798    hairong            LOG.info(StringUtils.stringifyException(new IOException(\n708724    rangadi              \"Checksum ok was sent and should not be sent again\")));\n\n\nr708724 | rangadi | 2008-10-28 16:33:40 -0700 (Tue, 28 Oct 2008) | 1 line\n\nHADOOP-4499. DFSClient should invoke checksumOk only once. (Raghu Angadi)\n------------------------------------------------------------------------\nr706798 | hairong | 2008-10-21 15:19:07 -0700 (Tue, 21 Oct 2008) | 1 line\n\nMerge -r 706795:706796 from trunk to main to move the change log of HADOOP-3914.\n{code}\n\nCode comment says this condition should never happen.\n\nLooking at code, IIUC, we get this exception if we reread inside a block.\n\nFor now, I've marked it a blocker.  HBase can't use 0.19.0 if this is the carry-on.\n\nI'll dig in some more.",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
            "id": "1",
            "name": "Blocker",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/1"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310240&avatarId=10095",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310240&avatarId=10095",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310240&avatarId=10095",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310240&avatarId=10095"
            },
            "id": "12310240",
            "key": "HADOOP",
            "name": "Hadoop Common",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310240"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "stack",
            "key": "stack",
            "name": "stack",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=stack",
            "timeZone": "America/Los_Angeles"
        },
        "resolution": {
            "description": "The problem is a duplicate of an existing issue.",
            "id": "3",
            "name": "Duplicate",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/3"
        },
        "resolutiondate": "2008-10-31T22:12:01.000+0000",
        "status": {
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "id": "6",
            "name": "Closed",
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Logs filled with \"IOException: Checksum ok was sent and should not be sent again\"",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2009-07-08T16:43:23.000+0000",
        "versions": [{
            "archived": false,
            "description": "",
            "id": "12313211",
            "name": "0.19.0",
            "releaseDate": "2008-11-20",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12313211"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4562/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HADOOP-4562/watchers",
            "watchCount": 1
        },
        "workratio": -1
    },
    "id": "12407619",
    "key": "HADOOP-4562",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12407619"
}